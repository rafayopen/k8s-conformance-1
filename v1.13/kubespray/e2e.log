I0416 11:31:33.104763      15 test_context.go:358] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-454217481
I0416 11:31:33.105020      15 e2e.go:224] Starting e2e run "2f490ef8-603b-11e9-be7e-0a580ae9423f" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1555414292 - Will randomize all specs
Will run 201 of 1946 specs

Apr 16 11:31:33.311: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
Apr 16 11:31:33.315: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Apr 16 11:31:33.356: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Apr 16 11:31:33.387: INFO: 17 / 17 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Apr 16 11:31:33.387: INFO: expected 4 pod replicas in namespace 'kube-system', 4 are Running and Ready.
Apr 16 11:31:33.387: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Apr 16 11:31:33.397: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-flannel' (0 seconds elapsed)
Apr 16 11:31:33.397: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Apr 16 11:31:33.397: INFO: e2e test version: v1.13.0
Apr 16 11:31:33.400: INFO: kube-apiserver version: v1.13.5
SSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:31:33.403: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename downward-api
Apr 16 11:31:33.566: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Apr 16 11:31:33.606: INFO: Waiting up to 5m0s for pod "downward-api-2ff9240c-603b-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-downward-api-nqhqw" to be "success or failure"
Apr 16 11:31:33.611: INFO: Pod "downward-api-2ff9240c-603b-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.219906ms
Apr 16 11:31:35.617: INFO: Pod "downward-api-2ff9240c-603b-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011450541s
STEP: Saw pod success
Apr 16 11:31:35.617: INFO: Pod "downward-api-2ff9240c-603b-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 11:31:35.621: INFO: Trying to get logs from node k8s-3 pod downward-api-2ff9240c-603b-11e9-be7e-0a580ae9423f container dapi-container: <nil>
STEP: delete the pod
Apr 16 11:31:35.660: INFO: Waiting for pod downward-api-2ff9240c-603b-11e9-be7e-0a580ae9423f to disappear
Apr 16 11:31:35.664: INFO: Pod downward-api-2ff9240c-603b-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:31:35.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-nqhqw" for this suite.
Apr 16 11:31:41.689: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:31:41.803: INFO: namespace: e2e-tests-downward-api-nqhqw, resource: bindings, ignored listing per whitelist
Apr 16 11:31:41.844: INFO: namespace e2e-tests-downward-api-nqhqw deletion completed in 6.174208835s

• [SLOW TEST:8.441 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:31:41.845: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-lq8cw
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-lq8cw
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-lq8cw
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-lq8cw
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-lq8cw
Apr 16 11:31:44.043: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-lq8cw, name: ss-0, uid: 35d4678f-603b-11e9-8978-0800277031c6, status phase: Pending. Waiting for statefulset controller to delete.
Apr 16 11:31:44.771: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-lq8cw, name: ss-0, uid: 35d4678f-603b-11e9-8978-0800277031c6, status phase: Failed. Waiting for statefulset controller to delete.
Apr 16 11:31:44.782: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-lq8cw, name: ss-0, uid: 35d4678f-603b-11e9-8978-0800277031c6, status phase: Failed. Waiting for statefulset controller to delete.
Apr 16 11:31:44.794: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-lq8cw
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-lq8cw
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-lq8cw and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr 16 11:31:48.845: INFO: Deleting all statefulset in ns e2e-tests-statefulset-lq8cw
Apr 16 11:31:48.848: INFO: Scaling statefulset ss to 0
Apr 16 11:32:08.890: INFO: Waiting for statefulset status.replicas updated to 0
Apr 16 11:32:08.893: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:32:08.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-lq8cw" for this suite.
Apr 16 11:32:14.936: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:32:14.983: INFO: namespace: e2e-tests-statefulset-lq8cw, resource: bindings, ignored listing per whitelist
Apr 16 11:32:15.073: INFO: namespace e2e-tests-statefulset-lq8cw deletion completed in 6.155368464s

• [SLOW TEST:33.228 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:32:15.074: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Apr 16 11:32:15.161: INFO: Waiting up to 5m0s for pod "downwardapi-volume-48c0ae46-603b-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-downward-api-z4hw5" to be "success or failure"
Apr 16 11:32:15.172: INFO: Pod "downwardapi-volume-48c0ae46-603b-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.868462ms
Apr 16 11:32:17.177: INFO: Pod "downwardapi-volume-48c0ae46-603b-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016573135s
STEP: Saw pod success
Apr 16 11:32:17.177: INFO: Pod "downwardapi-volume-48c0ae46-603b-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 11:32:17.181: INFO: Trying to get logs from node k8s-3 pod downwardapi-volume-48c0ae46-603b-11e9-be7e-0a580ae9423f container client-container: <nil>
STEP: delete the pod
Apr 16 11:32:17.220: INFO: Waiting for pod downwardapi-volume-48c0ae46-603b-11e9-be7e-0a580ae9423f to disappear
Apr 16 11:32:17.225: INFO: Pod downwardapi-volume-48c0ae46-603b-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:32:17.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-z4hw5" for this suite.
Apr 16 11:32:23.244: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:32:23.305: INFO: namespace: e2e-tests-downward-api-z4hw5, resource: bindings, ignored listing per whitelist
Apr 16 11:32:23.342: INFO: namespace e2e-tests-downward-api-z4hw5 deletion completed in 6.114069379s

• [SLOW TEST:8.269 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:32:23.343: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-4dae2cd5-603b-11e9-be7e-0a580ae9423f
STEP: Creating a pod to test consume configMaps
Apr 16 11:32:23.430: INFO: Waiting up to 5m0s for pod "pod-configmaps-4dafb8e4-603b-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-configmap-c5lqn" to be "success or failure"
Apr 16 11:32:23.443: INFO: Pod "pod-configmaps-4dafb8e4-603b-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 12.46649ms
Apr 16 11:32:25.448: INFO: Pod "pod-configmaps-4dafb8e4-603b-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018018289s
STEP: Saw pod success
Apr 16 11:32:25.448: INFO: Pod "pod-configmaps-4dafb8e4-603b-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 11:32:25.453: INFO: Trying to get logs from node k8s-1 pod pod-configmaps-4dafb8e4-603b-11e9-be7e-0a580ae9423f container configmap-volume-test: <nil>
STEP: delete the pod
Apr 16 11:32:25.486: INFO: Waiting for pod pod-configmaps-4dafb8e4-603b-11e9-be7e-0a580ae9423f to disappear
Apr 16 11:32:25.491: INFO: Pod pod-configmaps-4dafb8e4-603b-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:32:25.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-c5lqn" for this suite.
Apr 16 11:32:31.514: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:32:31.578: INFO: namespace: e2e-tests-configmap-c5lqn, resource: bindings, ignored listing per whitelist
Apr 16 11:32:31.644: INFO: namespace e2e-tests-configmap-c5lqn deletion completed in 6.149377923s

• [SLOW TEST:8.301 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:32:31.645: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-52a12d2f-603b-11e9-be7e-0a580ae9423f
STEP: Creating a pod to test consume secrets
Apr 16 11:32:31.731: INFO: Waiting up to 5m0s for pod "pod-secrets-52a290ce-603b-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-secrets-km9rz" to be "success or failure"
Apr 16 11:32:31.736: INFO: Pod "pod-secrets-52a290ce-603b-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.21358ms
Apr 16 11:32:33.744: INFO: Pod "pod-secrets-52a290ce-603b-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013478592s
STEP: Saw pod success
Apr 16 11:32:33.744: INFO: Pod "pod-secrets-52a290ce-603b-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 11:32:33.748: INFO: Trying to get logs from node k8s-2 pod pod-secrets-52a290ce-603b-11e9-be7e-0a580ae9423f container secret-volume-test: <nil>
STEP: delete the pod
Apr 16 11:32:33.831: INFO: Waiting for pod pod-secrets-52a290ce-603b-11e9-be7e-0a580ae9423f to disappear
Apr 16 11:32:33.837: INFO: Pod pod-secrets-52a290ce-603b-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:32:33.837: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-km9rz" for this suite.
Apr 16 11:32:39.865: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:32:39.918: INFO: namespace: e2e-tests-secrets-km9rz, resource: bindings, ignored listing per whitelist
Apr 16 11:32:40.020: INFO: namespace e2e-tests-secrets-km9rz deletion completed in 6.179211727s

• [SLOW TEST:8.375 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:32:40.021: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Apr 16 11:32:40.109: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 create -f - --namespace=e2e-tests-kubectl-x8dqn'
Apr 16 11:32:40.740: INFO: stderr: ""
Apr 16 11:32:40.740: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 16 11:32:40.741: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-x8dqn'
Apr 16 11:32:40.868: INFO: stderr: ""
Apr 16 11:32:40.868: INFO: stdout: "update-demo-nautilus-qgmmj update-demo-nautilus-qhg8w "
Apr 16 11:32:40.868: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 get pods update-demo-nautilus-qgmmj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-x8dqn'
Apr 16 11:32:40.957: INFO: stderr: ""
Apr 16 11:32:40.957: INFO: stdout: ""
Apr 16 11:32:40.957: INFO: update-demo-nautilus-qgmmj is created but not running
Apr 16 11:32:45.958: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-x8dqn'
Apr 16 11:32:46.039: INFO: stderr: ""
Apr 16 11:32:46.039: INFO: stdout: "update-demo-nautilus-qgmmj update-demo-nautilus-qhg8w "
Apr 16 11:32:46.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 get pods update-demo-nautilus-qgmmj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-x8dqn'
Apr 16 11:32:46.131: INFO: stderr: ""
Apr 16 11:32:46.131: INFO: stdout: "true"
Apr 16 11:32:46.131: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 get pods update-demo-nautilus-qgmmj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-x8dqn'
Apr 16 11:32:46.203: INFO: stderr: ""
Apr 16 11:32:46.203: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 16 11:32:46.203: INFO: validating pod update-demo-nautilus-qgmmj
Apr 16 11:32:46.212: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 16 11:32:46.212: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 16 11:32:46.212: INFO: update-demo-nautilus-qgmmj is verified up and running
Apr 16 11:32:46.212: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 get pods update-demo-nautilus-qhg8w -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-x8dqn'
Apr 16 11:32:46.281: INFO: stderr: ""
Apr 16 11:32:46.282: INFO: stdout: "true"
Apr 16 11:32:46.282: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 get pods update-demo-nautilus-qhg8w -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-x8dqn'
Apr 16 11:32:46.353: INFO: stderr: ""
Apr 16 11:32:46.353: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 16 11:32:46.353: INFO: validating pod update-demo-nautilus-qhg8w
Apr 16 11:32:46.362: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 16 11:32:46.362: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 16 11:32:46.362: INFO: update-demo-nautilus-qhg8w is verified up and running
STEP: rolling-update to new replication controller
Apr 16 11:32:46.364: INFO: scanned /root for discovery docs: <nil>
Apr 16 11:32:46.365: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-x8dqn'
Apr 16 11:33:08.823: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Apr 16 11:33:08.823: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 16 11:33:08.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-x8dqn'
Apr 16 11:33:08.910: INFO: stderr: ""
Apr 16 11:33:08.910: INFO: stdout: "update-demo-kitten-bxhcc update-demo-kitten-m4m6z "
Apr 16 11:33:08.910: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 get pods update-demo-kitten-bxhcc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-x8dqn'
Apr 16 11:33:08.979: INFO: stderr: ""
Apr 16 11:33:08.979: INFO: stdout: "true"
Apr 16 11:33:08.980: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 get pods update-demo-kitten-bxhcc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-x8dqn'
Apr 16 11:33:09.060: INFO: stderr: ""
Apr 16 11:33:09.060: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Apr 16 11:33:09.060: INFO: validating pod update-demo-kitten-bxhcc
Apr 16 11:33:09.068: INFO: got data: {
  "image": "kitten.jpg"
}

Apr 16 11:33:09.068: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Apr 16 11:33:09.068: INFO: update-demo-kitten-bxhcc is verified up and running
Apr 16 11:33:09.068: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 get pods update-demo-kitten-m4m6z -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-x8dqn'
Apr 16 11:33:09.139: INFO: stderr: ""
Apr 16 11:33:09.139: INFO: stdout: "true"
Apr 16 11:33:09.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 get pods update-demo-kitten-m4m6z -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-x8dqn'
Apr 16 11:33:09.211: INFO: stderr: ""
Apr 16 11:33:09.211: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Apr 16 11:33:09.211: INFO: validating pod update-demo-kitten-m4m6z
Apr 16 11:33:09.220: INFO: got data: {
  "image": "kitten.jpg"
}

Apr 16 11:33:09.220: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Apr 16 11:33:09.220: INFO: update-demo-kitten-m4m6z is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:33:09.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-x8dqn" for this suite.
Apr 16 11:33:31.247: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:33:31.339: INFO: namespace: e2e-tests-kubectl-x8dqn, resource: bindings, ignored listing per whitelist
Apr 16 11:33:31.350: INFO: namespace e2e-tests-kubectl-x8dqn deletion completed in 22.126658432s

• [SLOW TEST:51.329 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:33:31.351: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Apr 16 11:33:33.963: INFO: Successfully updated pod "labelsupdate76369448-603b-11e9-be7e-0a580ae9423f"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:33:35.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-b5jgv" for this suite.
Apr 16 11:33:58.004: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:33:58.108: INFO: namespace: e2e-tests-downward-api-b5jgv, resource: bindings, ignored listing per whitelist
Apr 16 11:33:58.133: INFO: namespace e2e-tests-downward-api-b5jgv deletion completed in 22.146468365s

• [SLOW TEST:26.782 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:33:58.134: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Apr 16 11:33:58.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 cluster-info'
Apr 16 11:33:58.336: INFO: stderr: ""
Apr 16 11:33:58.336: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.233.0.1:443\x1b[0m\n\x1b[0;32mcoredns\x1b[0m is running at \x1b[0;33mhttps://10.233.0.1:443/api/v1/namespaces/kube-system/services/coredns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://10.233.0.1:443/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:33:58.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-pl2gq" for this suite.
Apr 16 11:34:04.371: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:34:04.445: INFO: namespace: e2e-tests-kubectl-pl2gq, resource: bindings, ignored listing per whitelist
Apr 16 11:34:04.471: INFO: namespace e2e-tests-kubectl-pl2gq deletion completed in 6.129908523s

• [SLOW TEST:6.337 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:34:04.472: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Apr 16 11:34:04.539: INFO: Waiting up to 5m0s for pod "downwardapi-volume-89f39097-603b-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-downward-api-vdnnh" to be "success or failure"
Apr 16 11:34:04.544: INFO: Pod "downwardapi-volume-89f39097-603b-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.056545ms
Apr 16 11:34:06.551: INFO: Pod "downwardapi-volume-89f39097-603b-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011712292s
STEP: Saw pod success
Apr 16 11:34:06.551: INFO: Pod "downwardapi-volume-89f39097-603b-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 11:34:06.556: INFO: Trying to get logs from node k8s-3 pod downwardapi-volume-89f39097-603b-11e9-be7e-0a580ae9423f container client-container: <nil>
STEP: delete the pod
Apr 16 11:34:06.586: INFO: Waiting for pod downwardapi-volume-89f39097-603b-11e9-be7e-0a580ae9423f to disappear
Apr 16 11:34:06.589: INFO: Pod downwardapi-volume-89f39097-603b-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:34:06.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-vdnnh" for this suite.
Apr 16 11:34:12.616: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:34:12.690: INFO: namespace: e2e-tests-downward-api-vdnnh, resource: bindings, ignored listing per whitelist
Apr 16 11:34:12.720: INFO: namespace e2e-tests-downward-api-vdnnh deletion completed in 6.127719271s

• [SLOW TEST:8.249 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:34:12.723: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-99kzq
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Apr 16 11:34:12.809: INFO: Found 0 stateful pods, waiting for 3
Apr 16 11:34:22.823: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 16 11:34:22.823: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 16 11:34:22.823: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Apr 16 11:34:22.854: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Apr 16 11:34:32.900: INFO: Updating stateful set ss2
Apr 16 11:34:32.908: INFO: Waiting for Pod e2e-tests-statefulset-99kzq/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Apr 16 11:34:43.006: INFO: Found 1 stateful pods, waiting for 3
Apr 16 11:34:53.020: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 16 11:34:53.020: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 16 11:34:53.020: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Apr 16 11:34:53.048: INFO: Updating stateful set ss2
Apr 16 11:34:53.060: INFO: Waiting for Pod e2e-tests-statefulset-99kzq/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr 16 11:35:03.100: INFO: Updating stateful set ss2
Apr 16 11:35:03.111: INFO: Waiting for StatefulSet e2e-tests-statefulset-99kzq/ss2 to complete update
Apr 16 11:35:03.111: INFO: Waiting for Pod e2e-tests-statefulset-99kzq/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr 16 11:35:13.125: INFO: Waiting for StatefulSet e2e-tests-statefulset-99kzq/ss2 to complete update
Apr 16 11:35:13.125: INFO: Waiting for Pod e2e-tests-statefulset-99kzq/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr 16 11:35:23.120: INFO: Deleting all statefulset in ns e2e-tests-statefulset-99kzq
Apr 16 11:35:23.137: INFO: Scaling statefulset ss2 to 0
Apr 16 11:35:53.221: INFO: Waiting for statefulset status.replicas updated to 0
Apr 16 11:35:53.224: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:35:53.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-99kzq" for this suite.
Apr 16 11:35:59.269: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:35:59.344: INFO: namespace: e2e-tests-statefulset-99kzq, resource: bindings, ignored listing per whitelist
Apr 16 11:35:59.373: INFO: namespace e2e-tests-statefulset-99kzq deletion completed in 6.127608578s

• [SLOW TEST:106.650 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:35:59.374: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-ce72d72b-603b-11e9-be7e-0a580ae9423f
STEP: Creating a pod to test consume configMaps
Apr 16 11:35:59.467: INFO: Waiting up to 5m0s for pod "pod-configmaps-ce73e927-603b-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-configmap-w2fmt" to be "success or failure"
Apr 16 11:35:59.475: INFO: Pod "pod-configmaps-ce73e927-603b-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.059988ms
Apr 16 11:36:01.480: INFO: Pod "pod-configmaps-ce73e927-603b-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012694213s
Apr 16 11:36:03.490: INFO: Pod "pod-configmaps-ce73e927-603b-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022182216s
STEP: Saw pod success
Apr 16 11:36:03.490: INFO: Pod "pod-configmaps-ce73e927-603b-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 11:36:03.495: INFO: Trying to get logs from node k8s-1 pod pod-configmaps-ce73e927-603b-11e9-be7e-0a580ae9423f container configmap-volume-test: <nil>
STEP: delete the pod
Apr 16 11:36:03.521: INFO: Waiting for pod pod-configmaps-ce73e927-603b-11e9-be7e-0a580ae9423f to disappear
Apr 16 11:36:03.524: INFO: Pod pod-configmaps-ce73e927-603b-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:36:03.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-w2fmt" for this suite.
Apr 16 11:36:09.552: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:36:09.614: INFO: namespace: e2e-tests-configmap-w2fmt, resource: bindings, ignored listing per whitelist
Apr 16 11:36:09.704: INFO: namespace e2e-tests-configmap-w2fmt deletion completed in 6.177001031s

• [SLOW TEST:10.330 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:36:09.705: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Apr 16 11:36:09.786: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d49abf6e-603b-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-projected-nwftf" to be "success or failure"
Apr 16 11:36:09.798: INFO: Pod "downwardapi-volume-d49abf6e-603b-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 12.446671ms
Apr 16 11:36:11.805: INFO: Pod "downwardapi-volume-d49abf6e-603b-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019564175s
STEP: Saw pod success
Apr 16 11:36:11.805: INFO: Pod "downwardapi-volume-d49abf6e-603b-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 11:36:11.809: INFO: Trying to get logs from node k8s-2 pod downwardapi-volume-d49abf6e-603b-11e9-be7e-0a580ae9423f container client-container: <nil>
STEP: delete the pod
Apr 16 11:36:11.855: INFO: Waiting for pod downwardapi-volume-d49abf6e-603b-11e9-be7e-0a580ae9423f to disappear
Apr 16 11:36:11.861: INFO: Pod downwardapi-volume-d49abf6e-603b-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:36:11.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-nwftf" for this suite.
Apr 16 11:36:17.880: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:36:17.951: INFO: namespace: e2e-tests-projected-nwftf, resource: bindings, ignored listing per whitelist
Apr 16 11:36:17.981: INFO: namespace e2e-tests-projected-nwftf deletion completed in 6.117236876s

• [SLOW TEST:8.276 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:36:17.983: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Apr 16 11:36:18.046: INFO: namespace e2e-tests-kubectl-kbx5t
Apr 16 11:36:18.046: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 create -f - --namespace=e2e-tests-kubectl-kbx5t'
Apr 16 11:36:18.202: INFO: stderr: ""
Apr 16 11:36:18.202: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Apr 16 11:36:19.209: INFO: Selector matched 1 pods for map[app:redis]
Apr 16 11:36:19.209: INFO: Found 0 / 1
Apr 16 11:36:20.207: INFO: Selector matched 1 pods for map[app:redis]
Apr 16 11:36:20.208: INFO: Found 1 / 1
Apr 16 11:36:20.208: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr 16 11:36:20.211: INFO: Selector matched 1 pods for map[app:redis]
Apr 16 11:36:20.212: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 16 11:36:20.212: INFO: wait on redis-master startup in e2e-tests-kubectl-kbx5t 
Apr 16 11:36:20.212: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 logs redis-master-4rm2g redis-master --namespace=e2e-tests-kubectl-kbx5t'
Apr 16 11:36:20.299: INFO: stderr: ""
Apr 16 11:36:20.299: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 16 Apr 11:36:19.031 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 16 Apr 11:36:19.032 # Server started, Redis version 3.2.12\n1:M 16 Apr 11:36:19.032 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 16 Apr 11:36:19.032 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Apr 16 11:36:20.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-kbx5t'
Apr 16 11:36:20.397: INFO: stderr: ""
Apr 16 11:36:20.397: INFO: stdout: "service/rm2 exposed\n"
Apr 16 11:36:20.401: INFO: Service rm2 in namespace e2e-tests-kubectl-kbx5t found.
STEP: exposing service
Apr 16 11:36:22.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-kbx5t'
Apr 16 11:36:22.513: INFO: stderr: ""
Apr 16 11:36:22.513: INFO: stdout: "service/rm3 exposed\n"
Apr 16 11:36:22.516: INFO: Service rm3 in namespace e2e-tests-kubectl-kbx5t found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:36:24.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-kbx5t" for this suite.
Apr 16 11:36:46.566: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:36:46.607: INFO: namespace: e2e-tests-kubectl-kbx5t, resource: bindings, ignored listing per whitelist
Apr 16 11:36:46.744: INFO: namespace e2e-tests-kubectl-kbx5t deletion completed in 22.207411346s

• [SLOW TEST:28.762 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:36:46.747: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Apr 16 11:36:46.842: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
Apr 16 11:36:46.865: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-zcdln/daemonsets","resourceVersion":"15318"},"items":null}

Apr 16 11:36:46.869: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-zcdln/pods","resourceVersion":"15318"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:36:46.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-zcdln" for this suite.
Apr 16 11:36:52.915: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:36:52.928: INFO: namespace: e2e-tests-daemonsets-zcdln, resource: bindings, ignored listing per whitelist
Apr 16 11:36:53.036: INFO: namespace e2e-tests-daemonsets-zcdln deletion completed in 6.140342578s

S [SKIPPING] [6.290 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Apr 16 11:36:46.843: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:36:53.038: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Apr 16 11:36:53.133: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 api-versions'
Apr 16 11:36:53.224: INFO: stderr: ""
Apr 16 11:36:53.224: INFO: stdout: "admissionregistration.k8s.io/v1alpha1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:36:53.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-z9jxx" for this suite.
Apr 16 11:36:59.251: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:36:59.343: INFO: namespace: e2e-tests-kubectl-z9jxx, resource: bindings, ignored listing per whitelist
Apr 16 11:36:59.383: INFO: namespace e2e-tests-kubectl-z9jxx deletion completed in 6.15359095s

• [SLOW TEST:6.344 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:36:59.383: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Apr 16 11:36:59.486: INFO: Waiting up to 5m0s for pod "pod-f23a1636-603b-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-emptydir-9sp2l" to be "success or failure"
Apr 16 11:36:59.491: INFO: Pod "pod-f23a1636-603b-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.646197ms
Apr 16 11:37:01.496: INFO: Pod "pod-f23a1636-603b-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01050694s
Apr 16 11:37:03.502: INFO: Pod "pod-f23a1636-603b-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015523718s
Apr 16 11:37:05.506: INFO: Pod "pod-f23a1636-603b-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.020380515s
STEP: Saw pod success
Apr 16 11:37:05.506: INFO: Pod "pod-f23a1636-603b-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 11:37:05.510: INFO: Trying to get logs from node k8s-1 pod pod-f23a1636-603b-11e9-be7e-0a580ae9423f container test-container: <nil>
STEP: delete the pod
Apr 16 11:37:05.544: INFO: Waiting for pod pod-f23a1636-603b-11e9-be7e-0a580ae9423f to disappear
Apr 16 11:37:05.548: INFO: Pod pod-f23a1636-603b-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:37:05.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-9sp2l" for this suite.
Apr 16 11:37:11.573: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:37:11.619: INFO: namespace: e2e-tests-emptydir-9sp2l, resource: bindings, ignored listing per whitelist
Apr 16 11:37:11.706: INFO: namespace e2e-tests-emptydir-9sp2l deletion completed in 6.150717126s

• [SLOW TEST:12.323 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:37:11.707: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-f9906a03-603b-11e9-be7e-0a580ae9423f
STEP: Creating a pod to test consume configMaps
Apr 16 11:37:11.802: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f99199eb-603b-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-projected-77h7f" to be "success or failure"
Apr 16 11:37:11.820: INFO: Pod "pod-projected-configmaps-f99199eb-603b-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 17.861472ms
Apr 16 11:37:13.826: INFO: Pod "pod-projected-configmaps-f99199eb-603b-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023589192s
STEP: Saw pod success
Apr 16 11:37:13.826: INFO: Pod "pod-projected-configmaps-f99199eb-603b-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 11:37:13.829: INFO: Trying to get logs from node k8s-2 pod pod-projected-configmaps-f99199eb-603b-11e9-be7e-0a580ae9423f container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 16 11:37:13.865: INFO: Waiting for pod pod-projected-configmaps-f99199eb-603b-11e9-be7e-0a580ae9423f to disappear
Apr 16 11:37:13.869: INFO: Pod pod-projected-configmaps-f99199eb-603b-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:37:13.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-77h7f" for this suite.
Apr 16 11:37:19.891: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:37:19.994: INFO: namespace: e2e-tests-projected-77h7f, resource: bindings, ignored listing per whitelist
Apr 16 11:37:20.005: INFO: namespace e2e-tests-projected-77h7f deletion completed in 6.132471745s

• [SLOW TEST:8.298 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:37:20.006: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-x6fp8/secret-test-fe813771-603b-11e9-be7e-0a580ae9423f
STEP: Creating a pod to test consume secrets
Apr 16 11:37:20.090: INFO: Waiting up to 5m0s for pod "pod-configmaps-fe827763-603b-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-secrets-x6fp8" to be "success or failure"
Apr 16 11:37:20.098: INFO: Pod "pod-configmaps-fe827763-603b-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.506441ms
Apr 16 11:37:22.105: INFO: Pod "pod-configmaps-fe827763-603b-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01498372s
STEP: Saw pod success
Apr 16 11:37:22.105: INFO: Pod "pod-configmaps-fe827763-603b-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 11:37:22.108: INFO: Trying to get logs from node k8s-3 pod pod-configmaps-fe827763-603b-11e9-be7e-0a580ae9423f container env-test: <nil>
STEP: delete the pod
Apr 16 11:37:22.141: INFO: Waiting for pod pod-configmaps-fe827763-603b-11e9-be7e-0a580ae9423f to disappear
Apr 16 11:37:22.145: INFO: Pod pod-configmaps-fe827763-603b-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:37:22.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-x6fp8" for this suite.
Apr 16 11:37:28.175: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:37:28.196: INFO: namespace: e2e-tests-secrets-x6fp8, resource: bindings, ignored listing per whitelist
Apr 16 11:37:28.280: INFO: namespace e2e-tests-secrets-x6fp8 deletion completed in 6.131364193s

• [SLOW TEST:8.274 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:37:28.281: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-037098c8-603c-11e9-be7e-0a580ae9423f
STEP: Creating a pod to test consume secrets
Apr 16 11:37:28.367: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-03719374-603c-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-projected-nt4wf" to be "success or failure"
Apr 16 11:37:28.377: INFO: Pod "pod-projected-secrets-03719374-603c-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 9.841701ms
Apr 16 11:37:30.384: INFO: Pod "pod-projected-secrets-03719374-603c-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017063035s
STEP: Saw pod success
Apr 16 11:37:30.384: INFO: Pod "pod-projected-secrets-03719374-603c-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 11:37:30.388: INFO: Trying to get logs from node k8s-1 pod pod-projected-secrets-03719374-603c-11e9-be7e-0a580ae9423f container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 16 11:37:30.423: INFO: Waiting for pod pod-projected-secrets-03719374-603c-11e9-be7e-0a580ae9423f to disappear
Apr 16 11:37:30.438: INFO: Pod pod-projected-secrets-03719374-603c-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:37:30.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-nt4wf" for this suite.
Apr 16 11:37:36.458: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:37:36.558: INFO: namespace: e2e-tests-projected-nt4wf, resource: bindings, ignored listing per whitelist
Apr 16 11:37:36.610: INFO: namespace e2e-tests-projected-nt4wf deletion completed in 6.16790992s

• [SLOW TEST:8.329 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:37:36.610: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0416 11:38:07.237301      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr 16 11:38:07.238: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:38:07.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-bbm2p" for this suite.
Apr 16 11:38:13.272: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:38:13.370: INFO: namespace: e2e-tests-gc-bbm2p, resource: bindings, ignored listing per whitelist
Apr 16 11:38:13.433: INFO: namespace e2e-tests-gc-bbm2p deletion completed in 6.191072514s

• [SLOW TEST:36.824 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:38:13.436: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-q88v5
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-q88v5 to expose endpoints map[]
Apr 16 11:38:13.638: INFO: Get endpoints failed (11.116744ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Apr 16 11:38:14.643: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-q88v5 exposes endpoints map[] (1.01641602s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-q88v5
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-q88v5 to expose endpoints map[pod1:[100]]
Apr 16 11:38:16.689: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-q88v5 exposes endpoints map[pod1:[100]] (2.034225364s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-q88v5
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-q88v5 to expose endpoints map[pod1:[100] pod2:[101]]
Apr 16 11:38:18.756: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-q88v5 exposes endpoints map[pod1:[100] pod2:[101]] (2.058501579s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-q88v5
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-q88v5 to expose endpoints map[pod2:[101]]
Apr 16 11:38:18.785: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-q88v5 exposes endpoints map[pod2:[101]] (14.458915ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-q88v5
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-q88v5 to expose endpoints map[]
Apr 16 11:38:18.814: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-q88v5 exposes endpoints map[] (8.181447ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:38:18.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-q88v5" for this suite.
Apr 16 11:38:40.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:38:41.012: INFO: namespace: e2e-tests-services-q88v5, resource: bindings, ignored listing per whitelist
Apr 16 11:38:41.079: INFO: namespace e2e-tests-services-q88v5 deletion completed in 22.195495156s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:27.644 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:38:41.081: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-c854w.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-c854w.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-c854w.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-c854w.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-c854w.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-c854w.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 16 11:39:05.303: INFO: Unable to read jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-c854w.svc.cluster.local from pod e2e-tests-dns-c854w/dns-test-2ed8cdae-603c-11e9-be7e-0a580ae9423f: the server could not find the requested resource (get pods dns-test-2ed8cdae-603c-11e9-be7e-0a580ae9423f)
Apr 16 11:39:05.308: INFO: Unable to read jessie_hosts@dns-querier-1 from pod e2e-tests-dns-c854w/dns-test-2ed8cdae-603c-11e9-be7e-0a580ae9423f: the server could not find the requested resource (get pods dns-test-2ed8cdae-603c-11e9-be7e-0a580ae9423f)
Apr 16 11:39:05.313: INFO: Unable to read jessie_udp@PodARecord from pod e2e-tests-dns-c854w/dns-test-2ed8cdae-603c-11e9-be7e-0a580ae9423f: the server could not find the requested resource (get pods dns-test-2ed8cdae-603c-11e9-be7e-0a580ae9423f)
Apr 16 11:39:05.318: INFO: Unable to read jessie_tcp@PodARecord from pod e2e-tests-dns-c854w/dns-test-2ed8cdae-603c-11e9-be7e-0a580ae9423f: the server could not find the requested resource (get pods dns-test-2ed8cdae-603c-11e9-be7e-0a580ae9423f)
Apr 16 11:39:05.318: INFO: Lookups using e2e-tests-dns-c854w/dns-test-2ed8cdae-603c-11e9-be7e-0a580ae9423f failed for: [jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-c854w.svc.cluster.local jessie_hosts@dns-querier-1 jessie_udp@PodARecord jessie_tcp@PodARecord]

Apr 16 11:39:10.409: INFO: Unable to read jessie_hosts@dns-querier-1 from pod e2e-tests-dns-c854w/dns-test-2ed8cdae-603c-11e9-be7e-0a580ae9423f: the server could not find the requested resource (get pods dns-test-2ed8cdae-603c-11e9-be7e-0a580ae9423f)
Apr 16 11:39:10.413: INFO: Unable to read jessie_udp@PodARecord from pod e2e-tests-dns-c854w/dns-test-2ed8cdae-603c-11e9-be7e-0a580ae9423f: the server could not find the requested resource (get pods dns-test-2ed8cdae-603c-11e9-be7e-0a580ae9423f)
Apr 16 11:39:10.417: INFO: Unable to read jessie_tcp@PodARecord from pod e2e-tests-dns-c854w/dns-test-2ed8cdae-603c-11e9-be7e-0a580ae9423f: the server could not find the requested resource (get pods dns-test-2ed8cdae-603c-11e9-be7e-0a580ae9423f)
Apr 16 11:39:10.417: INFO: Lookups using e2e-tests-dns-c854w/dns-test-2ed8cdae-603c-11e9-be7e-0a580ae9423f failed for: [jessie_hosts@dns-querier-1 jessie_udp@PodARecord jessie_tcp@PodARecord]

Apr 16 11:39:15.410: INFO: DNS probes using e2e-tests-dns-c854w/dns-test-2ed8cdae-603c-11e9-be7e-0a580ae9423f succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:39:15.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-c854w" for this suite.
Apr 16 11:39:21.456: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:39:21.498: INFO: namespace: e2e-tests-dns-c854w, resource: bindings, ignored listing per whitelist
Apr 16 11:39:21.574: INFO: namespace e2e-tests-dns-c854w deletion completed in 6.136091897s

• [SLOW TEST:40.493 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:39:21.574: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-97f5h/configmap-test-46f7093c-603c-11e9-be7e-0a580ae9423f
STEP: Creating a pod to test consume configMaps
Apr 16 11:39:21.658: INFO: Waiting up to 5m0s for pod "pod-configmaps-46f82440-603c-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-configmap-97f5h" to be "success or failure"
Apr 16 11:39:21.681: INFO: Pod "pod-configmaps-46f82440-603c-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 22.603843ms
Apr 16 11:39:23.687: INFO: Pod "pod-configmaps-46f82440-603c-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028592135s
Apr 16 11:39:25.696: INFO: Pod "pod-configmaps-46f82440-603c-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038254544s
STEP: Saw pod success
Apr 16 11:39:25.696: INFO: Pod "pod-configmaps-46f82440-603c-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 11:39:25.699: INFO: Trying to get logs from node k8s-1 pod pod-configmaps-46f82440-603c-11e9-be7e-0a580ae9423f container env-test: <nil>
STEP: delete the pod
Apr 16 11:39:25.732: INFO: Waiting for pod pod-configmaps-46f82440-603c-11e9-be7e-0a580ae9423f to disappear
Apr 16 11:39:25.737: INFO: Pod pod-configmaps-46f82440-603c-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:39:25.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-97f5h" for this suite.
Apr 16 11:39:31.759: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:39:31.818: INFO: namespace: e2e-tests-configmap-97f5h, resource: bindings, ignored listing per whitelist
Apr 16 11:39:31.899: INFO: namespace e2e-tests-configmap-97f5h deletion completed in 6.15856737s

• [SLOW TEST:10.325 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:39:31.900: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Apr 16 11:39:34.558: INFO: Successfully updated pod "annotationupdate4d1f6b29-603c-11e9-be7e-0a580ae9423f"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:39:36.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-249xj" for this suite.
Apr 16 11:39:58.610: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:39:58.674: INFO: namespace: e2e-tests-projected-249xj, resource: bindings, ignored listing per whitelist
Apr 16 11:39:58.712: INFO: namespace e2e-tests-projected-249xj deletion completed in 22.123765768s

• [SLOW TEST:26.812 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:39:58.712: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-kwj5t
Apr 16 11:40:02.813: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-kwj5t
STEP: checking the pod's current state and verifying that restartCount is present
Apr 16 11:40:02.817: INFO: Initial restart count of pod liveness-http is 0
Apr 16 11:40:20.888: INFO: Restart count of pod e2e-tests-container-probe-kwj5t/liveness-http is now 1 (18.070947971s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:40:20.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-kwj5t" for this suite.
Apr 16 11:40:26.932: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:40:27.008: INFO: namespace: e2e-tests-container-probe-kwj5t, resource: bindings, ignored listing per whitelist
Apr 16 11:40:27.028: INFO: namespace e2e-tests-container-probe-kwj5t deletion completed in 6.115468186s

• [SLOW TEST:28.316 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:40:27.030: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Apr 16 11:40:33.198: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 16 11:40:33.202: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 16 11:40:35.202: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 16 11:40:35.207: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 16 11:40:37.202: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 16 11:40:37.208: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 16 11:40:39.202: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 16 11:40:39.214: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 16 11:40:41.203: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 16 11:40:41.207: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 16 11:40:43.202: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 16 11:40:43.212: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 16 11:40:45.203: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 16 11:40:45.207: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 16 11:40:47.203: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 16 11:40:47.207: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 16 11:40:49.203: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 16 11:40:49.208: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 16 11:40:51.203: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 16 11:40:51.217: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 16 11:40:53.202: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 16 11:40:53.212: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:40:53.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-pdjf4" for this suite.
Apr 16 11:41:15.253: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:41:15.350: INFO: namespace: e2e-tests-container-lifecycle-hook-pdjf4, resource: bindings, ignored listing per whitelist
Apr 16 11:41:15.375: INFO: namespace e2e-tests-container-lifecycle-hook-pdjf4 deletion completed in 22.154635539s

• [SLOW TEST:48.346 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:41:15.377: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-8acdd8ff-603c-11e9-be7e-0a580ae9423f
Apr 16 11:41:15.469: INFO: Pod name my-hostname-basic-8acdd8ff-603c-11e9-be7e-0a580ae9423f: Found 0 pods out of 1
Apr 16 11:41:20.474: INFO: Pod name my-hostname-basic-8acdd8ff-603c-11e9-be7e-0a580ae9423f: Found 1 pods out of 1
Apr 16 11:41:20.474: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-8acdd8ff-603c-11e9-be7e-0a580ae9423f" are running
Apr 16 11:41:20.478: INFO: Pod "my-hostname-basic-8acdd8ff-603c-11e9-be7e-0a580ae9423f-r76pd" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-16 11:41:15 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-16 11:41:17 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-16 11:41:17 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-16 11:41:15 +0000 UTC Reason: Message:}])
Apr 16 11:41:20.478: INFO: Trying to dial the pod
Apr 16 11:41:25.497: INFO: Controller my-hostname-basic-8acdd8ff-603c-11e9-be7e-0a580ae9423f: Got expected result from replica 1 [my-hostname-basic-8acdd8ff-603c-11e9-be7e-0a580ae9423f-r76pd]: "my-hostname-basic-8acdd8ff-603c-11e9-be7e-0a580ae9423f-r76pd", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:41:25.497: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-hq4n4" for this suite.
Apr 16 11:41:31.521: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:41:31.551: INFO: namespace: e2e-tests-replication-controller-hq4n4, resource: bindings, ignored listing per whitelist
Apr 16 11:41:31.623: INFO: namespace e2e-tests-replication-controller-hq4n4 deletion completed in 6.122970985s

• [SLOW TEST:16.247 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:41:31.625: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Apr 16 11:41:31.706: INFO: Waiting up to 5m0s for pod "downwardapi-volume-947bf462-603c-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-downward-api-m2dp4" to be "success or failure"
Apr 16 11:41:31.709: INFO: Pod "downwardapi-volume-947bf462-603c-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.130286ms
Apr 16 11:41:33.717: INFO: Pod "downwardapi-volume-947bf462-603c-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010350916s
STEP: Saw pod success
Apr 16 11:41:33.717: INFO: Pod "downwardapi-volume-947bf462-603c-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 11:41:33.722: INFO: Trying to get logs from node k8s-1 pod downwardapi-volume-947bf462-603c-11e9-be7e-0a580ae9423f container client-container: <nil>
STEP: delete the pod
Apr 16 11:41:33.762: INFO: Waiting for pod downwardapi-volume-947bf462-603c-11e9-be7e-0a580ae9423f to disappear
Apr 16 11:41:33.766: INFO: Pod downwardapi-volume-947bf462-603c-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:41:33.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-m2dp4" for this suite.
Apr 16 11:41:39.796: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:41:39.847: INFO: namespace: e2e-tests-downward-api-m2dp4, resource: bindings, ignored listing per whitelist
Apr 16 11:41:39.928: INFO: namespace e2e-tests-downward-api-m2dp4 deletion completed in 6.157542516s

• [SLOW TEST:8.303 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:41:39.929: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Apr 16 11:41:42.080: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-99717eb9-603c-11e9-be7e-0a580ae9423f,GenerateName:,Namespace:e2e-tests-events-ddc9q,SelfLink:/api/v1/namespaces/e2e-tests-events-ddc9q/pods/send-events-99717eb9-603c-11e9-be7e-0a580ae9423f,UID:9973e19b-603c-11e9-8569-0800277031c6,ResourceVersion:16245,Generation:0,CreationTimestamp:2019-04-16 11:41:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 16714015,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-slhj5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-slhj5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-slhj5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00124c8e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00124c900}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 11:41:40 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 11:41:41 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 11:41:41 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 11:41:40 +0000 UTC  }],Message:,Reason:,HostIP:172.17.8.102,PodIP:10.233.65.58,StartTime:2019-04-16 11:41:40 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-04-16 11:41:40 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://597842ca6e734aa1d3b7d147a13d8d43678816dbce8aea7af78ee3b0e43e943f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Apr 16 11:41:44.089: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Apr 16 11:41:46.104: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:41:46.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-ddc9q" for this suite.
Apr 16 11:42:24.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:42:24.284: INFO: namespace: e2e-tests-events-ddc9q, resource: bindings, ignored listing per whitelist
Apr 16 11:42:24.294: INFO: namespace e2e-tests-events-ddc9q deletion completed in 38.166955452s

• [SLOW TEST:44.366 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:42:24.296: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-b3f13a22-603c-11e9-be7e-0a580ae9423f
STEP: Creating a pod to test consume secrets
Apr 16 11:42:24.498: INFO: Waiting up to 5m0s for pod "pod-secrets-b3f2d248-603c-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-secrets-9c9cr" to be "success or failure"
Apr 16 11:42:24.520: INFO: Pod "pod-secrets-b3f2d248-603c-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 22.679523ms
Apr 16 11:42:26.525: INFO: Pod "pod-secrets-b3f2d248-603c-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027168148s
STEP: Saw pod success
Apr 16 11:42:26.525: INFO: Pod "pod-secrets-b3f2d248-603c-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 11:42:26.528: INFO: Trying to get logs from node k8s-3 pod pod-secrets-b3f2d248-603c-11e9-be7e-0a580ae9423f container secret-volume-test: <nil>
STEP: delete the pod
Apr 16 11:42:26.562: INFO: Waiting for pod pod-secrets-b3f2d248-603c-11e9-be7e-0a580ae9423f to disappear
Apr 16 11:42:26.567: INFO: Pod pod-secrets-b3f2d248-603c-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:42:26.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-9c9cr" for this suite.
Apr 16 11:42:32.593: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:42:32.625: INFO: namespace: e2e-tests-secrets-9c9cr, resource: bindings, ignored listing per whitelist
Apr 16 11:42:32.702: INFO: namespace e2e-tests-secrets-9c9cr deletion completed in 6.128438459s

• [SLOW TEST:8.407 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:42:32.704: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1527
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 16 11:42:32.765: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-m5gn9'
Apr 16 11:42:32.854: INFO: stderr: ""
Apr 16 11:42:32.854: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1532
Apr 16 11:42:32.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-m5gn9'
Apr 16 11:42:39.554: INFO: stderr: ""
Apr 16 11:42:39.554: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:42:39.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-m5gn9" for this suite.
Apr 16 11:42:45.579: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:42:45.659: INFO: namespace: e2e-tests-kubectl-m5gn9, resource: bindings, ignored listing per whitelist
Apr 16 11:42:45.677: INFO: namespace e2e-tests-kubectl-m5gn9 deletion completed in 6.116606184s

• [SLOW TEST:12.973 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:42:45.678: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-c09edf49-603c-11e9-be7e-0a580ae9423f
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:42:47.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-tnrxh" for this suite.
Apr 16 11:43:09.818: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:43:09.883: INFO: namespace: e2e-tests-configmap-tnrxh, resource: bindings, ignored listing per whitelist
Apr 16 11:43:09.916: INFO: namespace e2e-tests-configmap-tnrxh deletion completed in 22.114522117s

• [SLOW TEST:24.239 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:43:09.921: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Apr 16 11:43:10.008: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-hw9tf" to be "success or failure"
Apr 16 11:43:10.020: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 12.589563ms
Apr 16 11:43:12.026: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017806501s
STEP: Saw pod success
Apr 16 11:43:12.026: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Apr 16 11:43:12.030: INFO: Trying to get logs from node k8s-3 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Apr 16 11:43:12.061: INFO: Waiting for pod pod-host-path-test to disappear
Apr 16 11:43:12.065: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:43:12.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-hw9tf" for this suite.
Apr 16 11:43:18.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:43:18.125: INFO: namespace: e2e-tests-hostpath-hw9tf, resource: bindings, ignored listing per whitelist
Apr 16 11:43:18.202: INFO: namespace e2e-tests-hostpath-hw9tf deletion completed in 6.132365458s

• [SLOW TEST:8.281 seconds]
[sig-storage] HostPath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:43:18.202: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-4vxlj/configmap-test-d4008786-603c-11e9-be7e-0a580ae9423f
STEP: Creating a pod to test consume configMaps
Apr 16 11:43:18.278: INFO: Waiting up to 5m0s for pod "pod-configmaps-d401ba02-603c-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-configmap-4vxlj" to be "success or failure"
Apr 16 11:43:18.283: INFO: Pod "pod-configmaps-d401ba02-603c-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.251488ms
Apr 16 11:43:20.288: INFO: Pod "pod-configmaps-d401ba02-603c-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009876997s
STEP: Saw pod success
Apr 16 11:43:20.288: INFO: Pod "pod-configmaps-d401ba02-603c-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 11:43:20.292: INFO: Trying to get logs from node k8s-1 pod pod-configmaps-d401ba02-603c-11e9-be7e-0a580ae9423f container env-test: <nil>
STEP: delete the pod
Apr 16 11:43:20.331: INFO: Waiting for pod pod-configmaps-d401ba02-603c-11e9-be7e-0a580ae9423f to disappear
Apr 16 11:43:20.341: INFO: Pod pod-configmaps-d401ba02-603c-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:43:20.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-4vxlj" for this suite.
Apr 16 11:43:26.378: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:43:26.480: INFO: namespace: e2e-tests-configmap-4vxlj, resource: bindings, ignored listing per whitelist
Apr 16 11:43:26.514: INFO: namespace e2e-tests-configmap-4vxlj deletion completed in 6.165473058s

• [SLOW TEST:8.312 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:43:26.515: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-v2qsq
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 16 11:43:26.610: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr 16 11:43:52.763: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.65.61:8080/dial?request=hostName&protocol=udp&host=10.233.65.60&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-v2qsq PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 16 11:43:52.763: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
Apr 16 11:43:52.859: INFO: Waiting for endpoints: map[]
Apr 16 11:43:52.865: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.65.61:8080/dial?request=hostName&protocol=udp&host=10.233.64.75&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-v2qsq PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 16 11:43:52.865: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
Apr 16 11:43:52.952: INFO: Waiting for endpoints: map[]
Apr 16 11:43:52.958: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.65.61:8080/dial?request=hostName&protocol=udp&host=10.233.66.83&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-v2qsq PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 16 11:43:52.958: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
Apr 16 11:43:53.048: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:43:53.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-v2qsq" for this suite.
Apr 16 11:44:17.074: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:44:17.192: INFO: namespace: e2e-tests-pod-network-test-v2qsq, resource: bindings, ignored listing per whitelist
Apr 16 11:44:17.196: INFO: namespace e2e-tests-pod-network-test-v2qsq deletion completed in 24.143026929s

• [SLOW TEST:50.682 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:44:17.198: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-f72b38ec-603c-11e9-be7e-0a580ae9423f
STEP: Creating a pod to test consume configMaps
Apr 16 11:44:17.278: INFO: Waiting up to 5m0s for pod "pod-configmaps-f72c5462-603c-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-configmap-t7kgr" to be "success or failure"
Apr 16 11:44:17.282: INFO: Pod "pod-configmaps-f72c5462-603c-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.878976ms
Apr 16 11:44:19.293: INFO: Pod "pod-configmaps-f72c5462-603c-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014183817s
STEP: Saw pod success
Apr 16 11:44:19.293: INFO: Pod "pod-configmaps-f72c5462-603c-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 11:44:19.296: INFO: Trying to get logs from node k8s-1 pod pod-configmaps-f72c5462-603c-11e9-be7e-0a580ae9423f container configmap-volume-test: <nil>
STEP: delete the pod
Apr 16 11:44:19.325: INFO: Waiting for pod pod-configmaps-f72c5462-603c-11e9-be7e-0a580ae9423f to disappear
Apr 16 11:44:19.328: INFO: Pod pod-configmaps-f72c5462-603c-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:44:19.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-t7kgr" for this suite.
Apr 16 11:44:25.348: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:44:25.411: INFO: namespace: e2e-tests-configmap-t7kgr, resource: bindings, ignored listing per whitelist
Apr 16 11:44:25.477: INFO: namespace e2e-tests-configmap-t7kgr deletion completed in 6.145671112s

• [SLOW TEST:8.280 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:44:25.478: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Apr 16 11:44:25.554: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fc1abd27-603c-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-projected-9qgvh" to be "success or failure"
Apr 16 11:44:25.561: INFO: Pod "downwardapi-volume-fc1abd27-603c-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.783249ms
Apr 16 11:44:27.566: INFO: Pod "downwardapi-volume-fc1abd27-603c-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012184002s
STEP: Saw pod success
Apr 16 11:44:27.566: INFO: Pod "downwardapi-volume-fc1abd27-603c-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 11:44:27.570: INFO: Trying to get logs from node k8s-3 pod downwardapi-volume-fc1abd27-603c-11e9-be7e-0a580ae9423f container client-container: <nil>
STEP: delete the pod
Apr 16 11:44:27.601: INFO: Waiting for pod downwardapi-volume-fc1abd27-603c-11e9-be7e-0a580ae9423f to disappear
Apr 16 11:44:27.606: INFO: Pod downwardapi-volume-fc1abd27-603c-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:44:27.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9qgvh" for this suite.
Apr 16 11:44:33.627: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:44:33.649: INFO: namespace: e2e-tests-projected-9qgvh, resource: bindings, ignored listing per whitelist
Apr 16 11:44:33.746: INFO: namespace e2e-tests-projected-9qgvh deletion completed in 6.136130344s

• [SLOW TEST:8.268 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:44:33.747: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-010ae21c-603d-11e9-be7e-0a580ae9423f
STEP: Creating secret with name s-test-opt-upd-010ae254-603d-11e9-be7e-0a580ae9423f
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-010ae21c-603d-11e9-be7e-0a580ae9423f
STEP: Updating secret s-test-opt-upd-010ae254-603d-11e9-be7e-0a580ae9423f
STEP: Creating secret with name s-test-opt-create-010ae261-603d-11e9-be7e-0a580ae9423f
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:46:08.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-l6p6n" for this suite.
Apr 16 11:46:30.785: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:46:30.848: INFO: namespace: e2e-tests-projected-l6p6n, resource: bindings, ignored listing per whitelist
Apr 16 11:46:30.901: INFO: namespace e2e-tests-projected-l6p6n deletion completed in 22.132855557s

• [SLOW TEST:117.154 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:46:30.902: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-k8m22
Apr 16 11:46:32.999: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-k8m22
STEP: checking the pod's current state and verifying that restartCount is present
Apr 16 11:46:33.003: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:50:33.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-k8m22" for this suite.
Apr 16 11:50:39.921: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:50:40.042: INFO: namespace: e2e-tests-container-probe-k8m22, resource: bindings, ignored listing per whitelist
Apr 16 11:50:40.061: INFO: namespace e2e-tests-container-probe-k8m22 deletion completed in 6.157647178s

• [SLOW TEST:249.159 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:50:40.062: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-c274g
Apr 16 11:50:42.166: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-c274g
STEP: checking the pod's current state and verifying that restartCount is present
Apr 16 11:50:42.169: INFO: Initial restart count of pod liveness-exec is 0
Apr 16 11:51:32.349: INFO: Restart count of pod e2e-tests-container-probe-c274g/liveness-exec is now 1 (50.179995529s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:51:32.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-c274g" for this suite.
Apr 16 11:51:38.398: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:51:38.426: INFO: namespace: e2e-tests-container-probe-c274g, resource: bindings, ignored listing per whitelist
Apr 16 11:51:38.504: INFO: namespace e2e-tests-container-probe-c274g deletion completed in 6.124973431s

• [SLOW TEST:58.442 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:51:38.505: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-cd55
STEP: Creating a pod to test atomic-volume-subpath
Apr 16 11:51:38.600: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-cd55" in namespace "e2e-tests-subpath-cchfd" to be "success or failure"
Apr 16 11:51:38.609: INFO: Pod "pod-subpath-test-configmap-cd55": Phase="Pending", Reason="", readiness=false. Elapsed: 8.303204ms
Apr 16 11:51:40.614: INFO: Pod "pod-subpath-test-configmap-cd55": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013279021s
Apr 16 11:51:42.619: INFO: Pod "pod-subpath-test-configmap-cd55": Phase="Running", Reason="", readiness=false. Elapsed: 4.018178422s
Apr 16 11:51:44.630: INFO: Pod "pod-subpath-test-configmap-cd55": Phase="Running", Reason="", readiness=false. Elapsed: 6.029288848s
Apr 16 11:51:46.635: INFO: Pod "pod-subpath-test-configmap-cd55": Phase="Running", Reason="", readiness=false. Elapsed: 8.034409446s
Apr 16 11:51:48.640: INFO: Pod "pod-subpath-test-configmap-cd55": Phase="Running", Reason="", readiness=false. Elapsed: 10.039415795s
Apr 16 11:51:50.647: INFO: Pod "pod-subpath-test-configmap-cd55": Phase="Running", Reason="", readiness=false. Elapsed: 12.045975463s
Apr 16 11:51:52.653: INFO: Pod "pod-subpath-test-configmap-cd55": Phase="Running", Reason="", readiness=false. Elapsed: 14.051996442s
Apr 16 11:51:54.666: INFO: Pod "pod-subpath-test-configmap-cd55": Phase="Running", Reason="", readiness=false. Elapsed: 16.06529984s
Apr 16 11:51:56.671: INFO: Pod "pod-subpath-test-configmap-cd55": Phase="Running", Reason="", readiness=false. Elapsed: 18.070417613s
Apr 16 11:51:58.675: INFO: Pod "pod-subpath-test-configmap-cd55": Phase="Running", Reason="", readiness=false. Elapsed: 20.074493127s
Apr 16 11:52:00.682: INFO: Pod "pod-subpath-test-configmap-cd55": Phase="Running", Reason="", readiness=false. Elapsed: 22.081113295s
Apr 16 11:52:02.687: INFO: Pod "pod-subpath-test-configmap-cd55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.08629017s
STEP: Saw pod success
Apr 16 11:52:02.687: INFO: Pod "pod-subpath-test-configmap-cd55" satisfied condition "success or failure"
Apr 16 11:52:02.692: INFO: Trying to get logs from node k8s-2 pod pod-subpath-test-configmap-cd55 container test-container-subpath-configmap-cd55: <nil>
STEP: delete the pod
Apr 16 11:52:02.737: INFO: Waiting for pod pod-subpath-test-configmap-cd55 to disappear
Apr 16 11:52:02.741: INFO: Pod pod-subpath-test-configmap-cd55 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-cd55
Apr 16 11:52:02.741: INFO: Deleting pod "pod-subpath-test-configmap-cd55" in namespace "e2e-tests-subpath-cchfd"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:52:02.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-cchfd" for this suite.
Apr 16 11:52:08.767: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:52:08.798: INFO: namespace: e2e-tests-subpath-cchfd, resource: bindings, ignored listing per whitelist
Apr 16 11:52:08.869: INFO: namespace e2e-tests-subpath-cchfd deletion completed in 6.121025151s

• [SLOW TEST:30.364 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:52:08.871: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Apr 16 11:52:08.940: INFO: Creating deployment "test-recreate-deployment"
Apr 16 11:52:08.949: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Apr 16 11:52:08.959: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Apr 16 11:52:10.969: INFO: Waiting deployment "test-recreate-deployment" to complete
Apr 16 11:52:10.977: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Apr 16 11:52:10.996: INFO: Updating deployment test-recreate-deployment
Apr 16 11:52:10.997: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr 16 11:52:11.139: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-jhlkb,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-jhlkb/deployments/test-recreate-deployment,UID:104fc0ce-603e-11e9-8569-0800277031c6,ResourceVersion:17687,Generation:2,CreationTimestamp:2019-04-16 11:52:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-04-16 11:52:11 +0000 UTC 2019-04-16 11:52:11 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-04-16 11:52:11 +0000 UTC 2019-04-16 11:52:08 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-697fbf54bf" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Apr 16 11:52:11.147: INFO: New ReplicaSet "test-recreate-deployment-697fbf54bf" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf,GenerateName:,Namespace:e2e-tests-deployment-jhlkb,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-jhlkb/replicasets/test-recreate-deployment-697fbf54bf,UID:11931291-603e-11e9-8978-0800277031c6,ResourceVersion:17683,Generation:1,CreationTimestamp:2019-04-16 11:52:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 104fc0ce-603e-11e9-8569-0800277031c6 0xc0018003e7 0xc0018003e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr 16 11:52:11.147: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Apr 16 11:52:11.147: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5dfdcc846d,GenerateName:,Namespace:e2e-tests-deployment-jhlkb,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-jhlkb/replicasets/test-recreate-deployment-5dfdcc846d,UID:1051b650-603e-11e9-8978-0800277031c6,ResourceVersion:17675,Generation:2,CreationTimestamp:2019-04-16 11:52:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 104fc0ce-603e-11e9-8569-0800277031c6 0xc001800267 0xc001800268}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr 16 11:52:11.155: INFO: Pod "test-recreate-deployment-697fbf54bf-rmnqx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf-rmnqx,GenerateName:test-recreate-deployment-697fbf54bf-,Namespace:e2e-tests-deployment-jhlkb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jhlkb/pods/test-recreate-deployment-697fbf54bf-rmnqx,UID:119428fc-603e-11e9-8978-0800277031c6,ResourceVersion:17686,Generation:0,CreationTimestamp:2019-04-16 11:52:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-697fbf54bf 11931291-603e-11e9-8978-0800277031c6 0xc001d92207 0xc001d92208}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-47hsr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-47hsr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-47hsr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d923f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d92410}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 11:52:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 11:52:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 11:52:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 11:52:11 +0000 UTC  }],Message:,Reason:,HostIP:172.17.8.101,PodIP:,StartTime:2019-04-16 11:52:11 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:52:11.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-jhlkb" for this suite.
Apr 16 11:52:17.190: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:52:17.259: INFO: namespace: e2e-tests-deployment-jhlkb, resource: bindings, ignored listing per whitelist
Apr 16 11:52:17.305: INFO: namespace e2e-tests-deployment-jhlkb deletion completed in 6.13231773s

• [SLOW TEST:8.434 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:52:17.306: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-sf9dv in namespace e2e-tests-proxy-njs29
I0416 11:52:17.406533      15 runners.go:184] Created replication controller with name: proxy-service-sf9dv, namespace: e2e-tests-proxy-njs29, replica count: 1
I0416 11:52:18.465150      15 runners.go:184] proxy-service-sf9dv Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0416 11:52:19.466284      15 runners.go:184] proxy-service-sf9dv Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0416 11:52:20.467403      15 runners.go:184] proxy-service-sf9dv Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0416 11:52:21.467769      15 runners.go:184] proxy-service-sf9dv Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0416 11:52:22.468139      15 runners.go:184] proxy-service-sf9dv Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0416 11:52:23.468342      15 runners.go:184] proxy-service-sf9dv Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0416 11:52:24.468601      15 runners.go:184] proxy-service-sf9dv Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0416 11:52:25.468849      15 runners.go:184] proxy-service-sf9dv Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0416 11:52:26.469080      15 runners.go:184] proxy-service-sf9dv Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0416 11:52:27.470043      15 runners.go:184] proxy-service-sf9dv Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0416 11:52:28.470464      15 runners.go:184] proxy-service-sf9dv Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 16 11:52:28.479: INFO: setup took 11.103585888s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Apr 16 11:52:28.494: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:160/proxy/: foo (200; 15.162415ms)
Apr 16 11:52:28.496: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:1080/proxy/rewri... (200; 16.498304ms)
Apr 16 11:52:28.496: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:162/proxy/: bar (200; 16.30376ms)
Apr 16 11:52:28.506: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:460/proxy/: tls baz (200; 26.087008ms)
Apr 16 11:52:28.506: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:1080/proxy/... (200; 25.986359ms)
Apr 16 11:52:28.515: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:160/proxy/: foo (200; 34.483656ms)
Apr 16 11:52:28.515: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:162/proxy/: bar (200; 34.517275ms)
Apr 16 11:52:28.516: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-njs29/services/http:proxy-service-sf9dv:portname2/proxy/: bar (200; 35.463871ms)
Apr 16 11:52:28.517: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-njs29/services/https:proxy-service-sf9dv:tlsportname1/proxy/: tls baz (200; 37.170058ms)
Apr 16 11:52:28.517: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r/proxy/rewriteme"... (200; 37.402213ms)
Apr 16 11:52:28.520: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-njs29/services/proxy-service-sf9dv:portname1/proxy/: foo (200; 38.593737ms)
Apr 16 11:52:28.521: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-njs29/services/proxy-service-sf9dv:portname2/proxy/: bar (200; 40.866075ms)
Apr 16 11:52:28.522: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-njs29/services/http:proxy-service-sf9dv:portname1/proxy/: foo (200; 41.333723ms)
Apr 16 11:52:28.524: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:443/proxy/... (200; 43.34508ms)
Apr 16 11:52:28.526: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-njs29/services/https:proxy-service-sf9dv:tlsportname2/proxy/: tls qux (200; 46.409245ms)
Apr 16 11:52:28.526: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:462/proxy/: tls qux (200; 45.447192ms)
Apr 16 11:52:28.555: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:1080/proxy/rewri... (200; 27.973405ms)
Apr 16 11:52:28.555: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:160/proxy/: foo (200; 27.674539ms)
Apr 16 11:52:28.556: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:162/proxy/: bar (200; 28.306851ms)
Apr 16 11:52:28.556: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:162/proxy/: bar (200; 28.064422ms)
Apr 16 11:52:28.556: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:462/proxy/: tls qux (200; 28.851396ms)
Apr 16 11:52:28.570: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-njs29/services/proxy-service-sf9dv:portname1/proxy/: foo (200; 43.460643ms)
Apr 16 11:52:28.571: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-njs29/services/https:proxy-service-sf9dv:tlsportname2/proxy/: tls qux (200; 42.988064ms)
Apr 16 11:52:28.571: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:460/proxy/: tls baz (200; 42.713777ms)
Apr 16 11:52:28.571: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-njs29/services/https:proxy-service-sf9dv:tlsportname1/proxy/: tls baz (200; 43.103104ms)
Apr 16 11:52:28.571: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:160/proxy/: foo (200; 42.172907ms)
Apr 16 11:52:28.571: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-njs29/services/http:proxy-service-sf9dv:portname2/proxy/: bar (200; 42.291396ms)
Apr 16 11:52:28.571: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r/proxy/rewriteme"... (200; 42.494142ms)
Apr 16 11:52:28.571: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:443/proxy/... (200; 43.899752ms)
Apr 16 11:52:28.571: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:1080/proxy/... (200; 42.434978ms)
Apr 16 11:52:28.571: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-njs29/services/proxy-service-sf9dv:portname2/proxy/: bar (200; 42.637741ms)
Apr 16 11:52:28.571: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-njs29/services/http:proxy-service-sf9dv:portname1/proxy/: foo (200; 42.807906ms)
Apr 16 11:52:28.585: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:1080/proxy/... (200; 14.006342ms)
Apr 16 11:52:28.597: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:162/proxy/: bar (200; 25.390622ms)
Apr 16 11:52:28.598: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:462/proxy/: tls qux (200; 26.199466ms)
Apr 16 11:52:28.608: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r/proxy/rewriteme"... (200; 35.324999ms)
Apr 16 11:52:28.608: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:460/proxy/: tls baz (200; 35.749949ms)
Apr 16 11:52:28.608: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:443/proxy/... (200; 36.907267ms)
Apr 16 11:52:28.611: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:160/proxy/: foo (200; 38.658487ms)
Apr 16 11:52:28.611: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:1080/proxy/rewri... (200; 39.464697ms)
Apr 16 11:52:28.611: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-njs29/services/proxy-service-sf9dv:portname1/proxy/: foo (200; 39.589221ms)
Apr 16 11:52:28.611: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-njs29/services/proxy-service-sf9dv:portname2/proxy/: bar (200; 38.423112ms)
Apr 16 11:52:28.611: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-njs29/services/https:proxy-service-sf9dv:tlsportname2/proxy/: tls qux (200; 38.910413ms)
Apr 16 11:52:28.611: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-njs29/services/http:proxy-service-sf9dv:portname1/proxy/: foo (200; 38.568066ms)
Apr 16 11:52:28.611: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-njs29/services/https:proxy-service-sf9dv:tlsportname1/proxy/: tls baz (200; 39.018985ms)
Apr 16 11:52:28.611: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:162/proxy/: bar (200; 38.788256ms)
Apr 16 11:52:28.612: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-njs29/services/http:proxy-service-sf9dv:portname2/proxy/: bar (200; 41.314263ms)
Apr 16 11:52:28.612: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:160/proxy/: foo (200; 41.221865ms)
Apr 16 11:52:28.630: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:462/proxy/: tls qux (200; 17.946189ms)
Apr 16 11:52:28.636: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r/proxy/rewriteme"... (200; 21.937371ms)
Apr 16 11:52:28.637: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:1080/proxy/... (200; 23.01195ms)
Apr 16 11:52:28.644: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:160/proxy/: foo (200; 29.855624ms)
Apr 16 11:52:28.648: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:162/proxy/: bar (200; 32.514135ms)
Apr 16 11:52:28.648: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-njs29/services/proxy-service-sf9dv:portname1/proxy/: foo (200; 33.4201ms)
Apr 16 11:52:28.648: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:1080/proxy/rewri... (200; 33.419418ms)
Apr 16 11:52:28.648: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-njs29/services/http:proxy-service-sf9dv:portname1/proxy/: foo (200; 34.514681ms)
Apr 16 11:52:28.648: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-njs29/services/https:proxy-service-sf9dv:tlsportname1/proxy/: tls baz (200; 35.486668ms)
Apr 16 11:52:28.648: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:160/proxy/: foo (200; 35.168007ms)
Apr 16 11:52:28.648: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:460/proxy/: tls baz (200; 34.843805ms)
Apr 16 11:52:28.648: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:162/proxy/: bar (200; 35.0483ms)
Apr 16 11:52:28.648: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:443/proxy/... (200; 34.072931ms)
Apr 16 11:52:28.648: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-njs29/services/https:proxy-service-sf9dv:tlsportname2/proxy/: tls qux (200; 35.613468ms)
Apr 16 11:52:28.648: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-njs29/services/http:proxy-service-sf9dv:portname2/proxy/: bar (200; 34.418171ms)
Apr 16 11:52:28.649: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-njs29/services/proxy-service-sf9dv:portname2/proxy/: bar (200; 35.004463ms)
Apr 16 11:52:28.667: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:462/proxy/: tls qux (200; 18.477187ms)
Apr 16 11:52:28.668: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:160/proxy/: foo (200; 18.405286ms)
Apr 16 11:52:28.675: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:460/proxy/: tls baz (200; 25.557231ms)
Apr 16 11:52:28.675: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:1080/proxy/... (200; 25.617644ms)
Apr 16 11:52:28.675: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r/proxy/rewriteme"... (200; 25.790325ms)
Apr 16 11:52:28.679: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:160/proxy/: foo (200; 29.410993ms)
Apr 16 11:52:28.680: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:162/proxy/: bar (200; 29.174675ms)
Apr 16 11:52:28.680: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:162/proxy/: bar (200; 30.282499ms)
Apr 16 11:52:28.680: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-njs29/services/https:proxy-service-sf9dv:tlsportname2/proxy/: tls qux (200; 30.882864ms)
Apr 16 11:52:28.681: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:1080/proxy/rewri... (200; 30.535834ms)
Apr 16 11:52:28.685: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-njs29/services/proxy-service-sf9dv:portname2/proxy/: bar (200; 35.161033ms)
Apr 16 11:52:28.685: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-njs29/services/https:proxy-service-sf9dv:tlsportname1/proxy/: tls baz (200; 36.03711ms)
Apr 16 11:52:28.685: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:443/proxy/... (200; 35.003283ms)
Apr 16 11:52:28.685: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-njs29/services/http:proxy-service-sf9dv:portname2/proxy/: bar (200; 35.254555ms)
Apr 16 11:52:28.685: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-njs29/services/proxy-service-sf9dv:portname1/proxy/: foo (200; 35.009827ms)
Apr 16 11:52:28.685: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-njs29/services/http:proxy-service-sf9dv:portname1/proxy/: foo (200; 35.739994ms)
Apr 16 11:52:28.704: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:1080/proxy/... (200; 18.549665ms)
Apr 16 11:52:28.704: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-njs29/services/http:proxy-service-sf9dv:portname2/proxy/: bar (200; 18.910813ms)
Apr 16 11:52:28.705: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:160/proxy/: foo (200; 18.884249ms)
Apr 16 11:52:28.710: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:460/proxy/: tls baz (200; 22.866332ms)
Apr 16 11:52:28.715: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:1080/proxy/rewri... (200; 28.830926ms)
Apr 16 11:52:28.715: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r/proxy/rewriteme"... (200; 27.992318ms)
Apr 16 11:52:28.716: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:462/proxy/: tls qux (200; 29.363321ms)
Apr 16 11:52:28.720: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:160/proxy/: foo (200; 33.673139ms)
Apr 16 11:52:28.721: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:162/proxy/: bar (200; 34.414857ms)
Apr 16 11:52:28.721: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:162/proxy/: bar (200; 33.820485ms)
Apr 16 11:52:28.721: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-njs29/services/proxy-service-sf9dv:portname2/proxy/: bar (200; 33.991479ms)
Apr 16 11:52:28.721: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:443/proxy/... (200; 35.570276ms)
Apr 16 11:52:28.722: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-njs29/services/https:proxy-service-sf9dv:tlsportname2/proxy/: tls qux (200; 35.087691ms)
Apr 16 11:52:28.722: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-njs29/services/https:proxy-service-sf9dv:tlsportname1/proxy/: tls baz (200; 35.230388ms)
Apr 16 11:52:28.722: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-njs29/services/proxy-service-sf9dv:portname1/proxy/: foo (200; 35.661768ms)
Apr 16 11:52:28.722: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-njs29/services/http:proxy-service-sf9dv:portname1/proxy/: foo (200; 34.506556ms)
Apr 16 11:52:28.737: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:160/proxy/: foo (200; 14.648715ms)
Apr 16 11:52:28.740: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r/proxy/rewriteme"... (200; 17.226435ms)
Apr 16 11:52:28.746: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:162/proxy/: bar (200; 22.883121ms)
Apr 16 11:52:28.753: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:160/proxy/: foo (200; 30.726186ms)
Apr 16 11:52:28.754: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:460/proxy/: tls baz (200; 30.690559ms)
Apr 16 11:52:28.755: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-njs29/services/https:proxy-service-sf9dv:tlsportname1/proxy/: tls baz (200; 31.642908ms)
Apr 16 11:52:28.755: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:443/proxy/... (200; 33.084815ms)
Apr 16 11:52:28.756: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-njs29/services/http:proxy-service-sf9dv:portname1/proxy/: foo (200; 34.357464ms)
Apr 16 11:52:28.756: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:462/proxy/: tls qux (200; 33.900096ms)
Apr 16 11:52:28.756: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-njs29/services/https:proxy-service-sf9dv:tlsportname2/proxy/: tls qux (200; 33.782012ms)
Apr 16 11:52:28.757: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:162/proxy/: bar (200; 34.269965ms)
Apr 16 11:52:28.757: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:1080/proxy/rewri... (200; 34.432437ms)
Apr 16 11:52:28.757: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-njs29/services/proxy-service-sf9dv:portname1/proxy/: foo (200; 34.25074ms)
Apr 16 11:52:28.757: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-njs29/services/proxy-service-sf9dv:portname2/proxy/: bar (200; 33.710113ms)
Apr 16 11:52:28.757: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-njs29/services/http:proxy-service-sf9dv:portname2/proxy/: bar (200; 34.869512ms)
Apr 16 11:52:28.757: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:1080/proxy/... (200; 33.824511ms)
Apr 16 11:52:28.776: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:162/proxy/: bar (200; 19.217118ms)
Apr 16 11:52:28.779: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r/proxy/rewriteme"... (200; 21.220795ms)
Apr 16 11:52:28.784: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-njs29/services/http:proxy-service-sf9dv:portname1/proxy/: foo (200; 27.084953ms)
Apr 16 11:52:28.785: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-njs29/services/proxy-service-sf9dv:portname2/proxy/: bar (200; 27.680474ms)
Apr 16 11:52:28.787: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:1080/proxy/... (200; 28.972955ms)
Apr 16 11:52:28.798: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:443/proxy/... (200; 39.948867ms)
Apr 16 11:52:28.799: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:1080/proxy/rewri... (200; 40.791391ms)
Apr 16 11:52:28.799: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:460/proxy/: tls baz (200; 40.581924ms)
Apr 16 11:52:28.799: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:462/proxy/: tls qux (200; 40.70203ms)
Apr 16 11:52:28.799: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:162/proxy/: bar (200; 40.93617ms)
Apr 16 11:52:28.801: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:160/proxy/: foo (200; 42.960907ms)
Apr 16 11:52:28.801: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:160/proxy/: foo (200; 42.429298ms)
Apr 16 11:52:28.805: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-njs29/services/https:proxy-service-sf9dv:tlsportname2/proxy/: tls qux (200; 46.370571ms)
Apr 16 11:52:28.806: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-njs29/services/https:proxy-service-sf9dv:tlsportname1/proxy/: tls baz (200; 46.888096ms)
Apr 16 11:52:28.806: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-njs29/services/http:proxy-service-sf9dv:portname2/proxy/: bar (200; 48.054277ms)
Apr 16 11:52:28.806: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-njs29/services/proxy-service-sf9dv:portname1/proxy/: foo (200; 47.798417ms)
Apr 16 11:52:28.827: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:443/proxy/... (200; 21.379666ms)
Apr 16 11:52:28.828: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:462/proxy/: tls qux (200; 21.62991ms)
Apr 16 11:52:28.829: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:1080/proxy/rewri... (200; 22.535156ms)
Apr 16 11:52:28.829: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-njs29/services/proxy-service-sf9dv:portname1/proxy/: foo (200; 22.763159ms)
Apr 16 11:52:28.841: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:160/proxy/: foo (200; 34.014952ms)
Apr 16 11:52:28.842: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:460/proxy/: tls baz (200; 35.106295ms)
Apr 16 11:52:28.842: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r/proxy/rewriteme"... (200; 34.670449ms)
Apr 16 11:52:28.842: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:1080/proxy/... (200; 35.098992ms)
Apr 16 11:52:28.844: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:160/proxy/: foo (200; 35.626066ms)
Apr 16 11:52:28.844: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:162/proxy/: bar (200; 37.637964ms)
Apr 16 11:52:28.844: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:162/proxy/: bar (200; 37.615495ms)
Apr 16 11:52:28.845: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-njs29/services/http:proxy-service-sf9dv:portname1/proxy/: foo (200; 37.232192ms)
Apr 16 11:52:28.845: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-njs29/services/https:proxy-service-sf9dv:tlsportname2/proxy/: tls qux (200; 38.190039ms)
Apr 16 11:52:28.845: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-njs29/services/https:proxy-service-sf9dv:tlsportname1/proxy/: tls baz (200; 38.458315ms)
Apr 16 11:52:28.846: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-njs29/services/proxy-service-sf9dv:portname2/proxy/: bar (200; 38.147432ms)
Apr 16 11:52:28.846: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-njs29/services/http:proxy-service-sf9dv:portname2/proxy/: bar (200; 38.420222ms)
Apr 16 11:52:28.862: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:460/proxy/: tls baz (200; 15.949857ms)
Apr 16 11:52:28.868: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:162/proxy/: bar (200; 20.491776ms)
Apr 16 11:52:28.873: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:1080/proxy/rewri... (200; 25.317997ms)
Apr 16 11:52:28.873: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:462/proxy/: tls qux (200; 25.634351ms)
Apr 16 11:52:28.875: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:160/proxy/: foo (200; 27.987724ms)
Apr 16 11:52:28.875: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:160/proxy/: foo (200; 27.353771ms)
Apr 16 11:52:28.877: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:443/proxy/... (200; 29.772861ms)
Apr 16 11:52:28.877: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-njs29/services/https:proxy-service-sf9dv:tlsportname2/proxy/: tls qux (200; 29.632229ms)
Apr 16 11:52:28.877: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-njs29/services/https:proxy-service-sf9dv:tlsportname1/proxy/: tls baz (200; 29.799756ms)
Apr 16 11:52:28.877: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r/proxy/rewriteme"... (200; 30.707155ms)
Apr 16 11:52:28.878: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:1080/proxy/... (200; 30.699242ms)
Apr 16 11:52:28.878: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-njs29/services/http:proxy-service-sf9dv:portname2/proxy/: bar (200; 30.831487ms)
Apr 16 11:52:28.878: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-njs29/services/http:proxy-service-sf9dv:portname1/proxy/: foo (200; 31.385029ms)
Apr 16 11:52:28.878: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:162/proxy/: bar (200; 30.066164ms)
Apr 16 11:52:28.878: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-njs29/services/proxy-service-sf9dv:portname1/proxy/: foo (200; 30.801268ms)
Apr 16 11:52:28.878: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-njs29/services/proxy-service-sf9dv:portname2/proxy/: bar (200; 31.482655ms)
Apr 16 11:52:28.896: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:1080/proxy/... (200; 17.620722ms)
Apr 16 11:52:28.913: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:1080/proxy/rewri... (200; 34.162576ms)
Apr 16 11:52:28.914: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:462/proxy/: tls qux (200; 34.600296ms)
Apr 16 11:52:28.914: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:162/proxy/: bar (200; 34.905176ms)
Apr 16 11:52:28.914: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r/proxy/rewriteme"... (200; 34.053631ms)
Apr 16 11:52:28.914: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:460/proxy/: tls baz (200; 34.37982ms)
Apr 16 11:52:28.914: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:160/proxy/: foo (200; 35.907577ms)
Apr 16 11:52:28.914: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:162/proxy/: bar (200; 34.50784ms)
Apr 16 11:52:28.914: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:160/proxy/: foo (200; 34.590835ms)
Apr 16 11:52:28.914: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:443/proxy/... (200; 35.46943ms)
Apr 16 11:52:28.916: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-njs29/services/proxy-service-sf9dv:portname2/proxy/: bar (200; 35.90776ms)
Apr 16 11:52:28.916: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-njs29/services/https:proxy-service-sf9dv:tlsportname2/proxy/: tls qux (200; 36.544035ms)
Apr 16 11:52:28.916: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-njs29/services/https:proxy-service-sf9dv:tlsportname1/proxy/: tls baz (200; 36.700062ms)
Apr 16 11:52:28.916: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-njs29/services/http:proxy-service-sf9dv:portname1/proxy/: foo (200; 36.30074ms)
Apr 16 11:52:28.916: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-njs29/services/proxy-service-sf9dv:portname1/proxy/: foo (200; 37.336344ms)
Apr 16 11:52:28.917: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-njs29/services/http:proxy-service-sf9dv:portname2/proxy/: bar (200; 38.197553ms)
Apr 16 11:52:28.943: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:462/proxy/: tls qux (200; 25.910563ms)
Apr 16 11:52:28.952: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r/proxy/rewriteme"... (200; 33.913719ms)
Apr 16 11:52:28.952: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:1080/proxy/rewri... (200; 35.144754ms)
Apr 16 11:52:28.952: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:1080/proxy/... (200; 34.229855ms)
Apr 16 11:52:28.952: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:160/proxy/: foo (200; 34.830269ms)
Apr 16 11:52:28.952: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:162/proxy/: bar (200; 35.262153ms)
Apr 16 11:52:28.952: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:443/proxy/... (200; 35.786543ms)
Apr 16 11:52:28.952: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-njs29/services/https:proxy-service-sf9dv:tlsportname1/proxy/: tls baz (200; 35.214869ms)
Apr 16 11:52:28.953: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:162/proxy/: bar (200; 35.001779ms)
Apr 16 11:52:28.953: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:460/proxy/: tls baz (200; 35.006262ms)
Apr 16 11:52:28.953: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:160/proxy/: foo (200; 34.470804ms)
Apr 16 11:52:28.955: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-njs29/services/proxy-service-sf9dv:portname1/proxy/: foo (200; 38.426846ms)
Apr 16 11:52:28.958: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-njs29/services/https:proxy-service-sf9dv:tlsportname2/proxy/: tls qux (200; 40.382258ms)
Apr 16 11:52:28.958: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-njs29/services/http:proxy-service-sf9dv:portname1/proxy/: foo (200; 40.584408ms)
Apr 16 11:52:28.958: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-njs29/services/proxy-service-sf9dv:portname2/proxy/: bar (200; 40.536296ms)
Apr 16 11:52:28.958: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-njs29/services/http:proxy-service-sf9dv:portname2/proxy/: bar (200; 40.257033ms)
Apr 16 11:52:28.984: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:460/proxy/: tls baz (200; 24.935048ms)
Apr 16 11:52:28.985: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:462/proxy/: tls qux (200; 25.530744ms)
Apr 16 11:52:28.985: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:1080/proxy/... (200; 26.852792ms)
Apr 16 11:52:28.992: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:160/proxy/: foo (200; 32.862552ms)
Apr 16 11:52:28.995: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:1080/proxy/rewri... (200; 35.937307ms)
Apr 16 11:52:28.996: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-njs29/services/http:proxy-service-sf9dv:portname2/proxy/: bar (200; 37.180898ms)
Apr 16 11:52:29.004: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-njs29/services/http:proxy-service-sf9dv:portname1/proxy/: foo (200; 43.668214ms)
Apr 16 11:52:29.004: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:162/proxy/: bar (200; 43.971157ms)
Apr 16 11:52:29.004: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r/proxy/rewriteme"... (200; 43.741013ms)
Apr 16 11:52:29.004: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-njs29/services/proxy-service-sf9dv:portname2/proxy/: bar (200; 43.923968ms)
Apr 16 11:52:29.004: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-njs29/services/proxy-service-sf9dv:portname1/proxy/: foo (200; 45.103472ms)
Apr 16 11:52:29.004: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:160/proxy/: foo (200; 45.576917ms)
Apr 16 11:52:29.004: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:162/proxy/: bar (200; 45.081878ms)
Apr 16 11:52:29.004: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-njs29/services/https:proxy-service-sf9dv:tlsportname2/proxy/: tls qux (200; 44.881654ms)
Apr 16 11:52:29.004: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-njs29/services/https:proxy-service-sf9dv:tlsportname1/proxy/: tls baz (200; 45.010582ms)
Apr 16 11:52:29.004: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:443/proxy/... (200; 45.553595ms)
Apr 16 11:52:29.033: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:462/proxy/: tls qux (200; 28.862595ms)
Apr 16 11:52:29.035: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-njs29/services/http:proxy-service-sf9dv:portname1/proxy/: foo (200; 30.211394ms)
Apr 16 11:52:29.043: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:1080/proxy/... (200; 37.745367ms)
Apr 16 11:52:29.044: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-njs29/services/https:proxy-service-sf9dv:tlsportname2/proxy/: tls qux (200; 39.080709ms)
Apr 16 11:52:29.044: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-njs29/services/proxy-service-sf9dv:portname2/proxy/: bar (200; 39.002646ms)
Apr 16 11:52:29.044: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:460/proxy/: tls baz (200; 39.284127ms)
Apr 16 11:52:29.044: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-njs29/services/https:proxy-service-sf9dv:tlsportname1/proxy/: tls baz (200; 39.806488ms)
Apr 16 11:52:29.045: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:162/proxy/: bar (200; 39.534711ms)
Apr 16 11:52:29.045: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:160/proxy/: foo (200; 39.683427ms)
Apr 16 11:52:29.045: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:443/proxy/... (200; 38.718814ms)
Apr 16 11:52:29.045: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r/proxy/rewriteme"... (200; 39.321943ms)
Apr 16 11:52:29.049: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-njs29/services/proxy-service-sf9dv:portname1/proxy/: foo (200; 42.852053ms)
Apr 16 11:52:29.050: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:160/proxy/: foo (200; 43.745725ms)
Apr 16 11:52:29.050: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-njs29/services/http:proxy-service-sf9dv:portname2/proxy/: bar (200; 43.980445ms)
Apr 16 11:52:29.050: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:162/proxy/: bar (200; 43.564588ms)
Apr 16 11:52:29.050: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:1080/proxy/rewri... (200; 43.69989ms)
Apr 16 11:52:29.064: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:160/proxy/: foo (200; 13.453099ms)
Apr 16 11:52:29.074: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r/proxy/rewriteme"... (200; 22.119562ms)
Apr 16 11:52:29.075: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:1080/proxy/rewri... (200; 24.758733ms)
Apr 16 11:52:29.079: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:460/proxy/: tls baz (200; 28.212389ms)
Apr 16 11:52:29.080: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:1080/proxy/... (200; 27.856849ms)
Apr 16 11:52:29.081: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:162/proxy/: bar (200; 30.053806ms)
Apr 16 11:52:29.081: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:162/proxy/: bar (200; 30.051348ms)
Apr 16 11:52:29.081: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:160/proxy/: foo (200; 30.138586ms)
Apr 16 11:52:29.081: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:462/proxy/: tls qux (200; 30.575902ms)
Apr 16 11:52:29.082: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-njs29/services/https:proxy-service-sf9dv:tlsportname2/proxy/: tls qux (200; 30.685788ms)
Apr 16 11:52:29.082: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-njs29/services/proxy-service-sf9dv:portname2/proxy/: bar (200; 30.121601ms)
Apr 16 11:52:29.085: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-njs29/services/proxy-service-sf9dv:portname1/proxy/: foo (200; 34.324275ms)
Apr 16 11:52:29.085: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-njs29/services/https:proxy-service-sf9dv:tlsportname1/proxy/: tls baz (200; 33.807255ms)
Apr 16 11:52:29.085: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:443/proxy/... (200; 34.878315ms)
Apr 16 11:52:29.085: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-njs29/services/http:proxy-service-sf9dv:portname2/proxy/: bar (200; 34.76588ms)
Apr 16 11:52:29.086: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-njs29/services/http:proxy-service-sf9dv:portname1/proxy/: foo (200; 35.810288ms)
Apr 16 11:52:29.110: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:462/proxy/: tls qux (200; 24.051199ms)
Apr 16 11:52:29.116: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-njs29/services/https:proxy-service-sf9dv:tlsportname1/proxy/: tls baz (200; 30.237023ms)
Apr 16 11:52:29.118: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:160/proxy/: foo (200; 31.252922ms)
Apr 16 11:52:29.118: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-njs29/services/proxy-service-sf9dv:portname2/proxy/: bar (200; 30.805944ms)
Apr 16 11:52:29.118: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:460/proxy/: tls baz (200; 31.183985ms)
Apr 16 11:52:29.121: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:162/proxy/: bar (200; 34.708622ms)
Apr 16 11:52:29.127: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:1080/proxy/... (200; 39.487269ms)
Apr 16 11:52:29.127: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r/proxy/rewriteme"... (200; 40.318085ms)
Apr 16 11:52:29.128: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:1080/proxy/rewri... (200; 39.51389ms)
Apr 16 11:52:29.128: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:443/proxy/... (200; 39.768319ms)
Apr 16 11:52:29.128: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:162/proxy/: bar (200; 39.680629ms)
Apr 16 11:52:29.128: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-njs29/services/https:proxy-service-sf9dv:tlsportname2/proxy/: tls qux (200; 41.556105ms)
Apr 16 11:52:29.128: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-njs29/services/http:proxy-service-sf9dv:portname1/proxy/: foo (200; 41.00763ms)
Apr 16 11:52:29.128: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:160/proxy/: foo (200; 40.172069ms)
Apr 16 11:52:29.131: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-njs29/services/http:proxy-service-sf9dv:portname2/proxy/: bar (200; 43.709639ms)
Apr 16 11:52:29.131: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-njs29/services/proxy-service-sf9dv:portname1/proxy/: foo (200; 43.550536ms)
Apr 16 11:52:29.151: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:160/proxy/: foo (200; 18.973291ms)
Apr 16 11:52:29.155: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:443/proxy/... (200; 22.774011ms)
Apr 16 11:52:29.155: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:1080/proxy/rewri... (200; 22.914342ms)
Apr 16 11:52:29.155: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:162/proxy/: bar (200; 23.223095ms)
Apr 16 11:52:29.162: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r/proxy/rewriteme"... (200; 28.933533ms)
Apr 16 11:52:29.162: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:1080/proxy/... (200; 29.061335ms)
Apr 16 11:52:29.165: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:462/proxy/: tls qux (200; 32.223065ms)
Apr 16 11:52:29.166: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:460/proxy/: tls baz (200; 32.82671ms)
Apr 16 11:52:29.169: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:160/proxy/: foo (200; 36.215606ms)
Apr 16 11:52:29.170: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:162/proxy/: bar (200; 36.787133ms)
Apr 16 11:52:29.174: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-njs29/services/https:proxy-service-sf9dv:tlsportname2/proxy/: tls qux (200; 40.972025ms)
Apr 16 11:52:29.175: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-njs29/services/https:proxy-service-sf9dv:tlsportname1/proxy/: tls baz (200; 41.82736ms)
Apr 16 11:52:29.176: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-njs29/services/proxy-service-sf9dv:portname1/proxy/: foo (200; 43.052817ms)
Apr 16 11:52:29.176: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-njs29/services/proxy-service-sf9dv:portname2/proxy/: bar (200; 42.744476ms)
Apr 16 11:52:29.176: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-njs29/services/http:proxy-service-sf9dv:portname1/proxy/: foo (200; 44.465441ms)
Apr 16 11:52:29.176: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-njs29/services/http:proxy-service-sf9dv:portname2/proxy/: bar (200; 44.096947ms)
Apr 16 11:52:29.202: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:162/proxy/: bar (200; 25.69908ms)
Apr 16 11:52:29.204: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-njs29/services/https:proxy-service-sf9dv:tlsportname2/proxy/: tls qux (200; 27.883648ms)
Apr 16 11:52:29.205: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:460/proxy/: tls baz (200; 27.823977ms)
Apr 16 11:52:29.205: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r/proxy/rewriteme"... (200; 27.96731ms)
Apr 16 11:52:29.205: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:160/proxy/: foo (200; 28.686163ms)
Apr 16 11:52:29.205: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-njs29/services/proxy-service-sf9dv:portname1/proxy/: foo (200; 29.1402ms)
Apr 16 11:52:29.218: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:1080/proxy/rewri... (200; 40.245109ms)
Apr 16 11:52:29.218: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:443/proxy/... (200; 40.833538ms)
Apr 16 11:52:29.218: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:162/proxy/: bar (200; 40.786033ms)
Apr 16 11:52:29.219: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-njs29/services/http:proxy-service-sf9dv:portname1/proxy/: foo (200; 41.682316ms)
Apr 16 11:52:29.219: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-njs29/services/https:proxy-service-sf9dv:tlsportname1/proxy/: tls baz (200; 42.50933ms)
Apr 16 11:52:29.219: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:462/proxy/: tls qux (200; 41.486298ms)
Apr 16 11:52:29.220: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:160/proxy/: foo (200; 42.705092ms)
Apr 16 11:52:29.220: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:1080/proxy/... (200; 42.969582ms)
Apr 16 11:52:29.220: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-njs29/services/proxy-service-sf9dv:portname2/proxy/: bar (200; 43.226168ms)
Apr 16 11:52:29.220: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-njs29/services/http:proxy-service-sf9dv:portname2/proxy/: bar (200; 42.74553ms)
Apr 16 11:52:29.248: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:1080/proxy/... (200; 27.446376ms)
Apr 16 11:52:29.249: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-njs29/services/http:proxy-service-sf9dv:portname2/proxy/: bar (200; 28.909745ms)
Apr 16 11:52:29.251: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:443/proxy/... (200; 30.487888ms)
Apr 16 11:52:29.252: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:162/proxy/: bar (200; 30.889808ms)
Apr 16 11:52:29.253: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:462/proxy/: tls qux (200; 31.637245ms)
Apr 16 11:52:29.253: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-njs29/services/https:proxy-service-sf9dv:tlsportname2/proxy/: tls qux (200; 31.739393ms)
Apr 16 11:52:29.253: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:160/proxy/: foo (200; 32.474834ms)
Apr 16 11:52:29.264: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r/proxy/rewriteme"... (200; 42.065642ms)
Apr 16 11:52:29.265: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:160/proxy/: foo (200; 43.640975ms)
Apr 16 11:52:29.265: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:162/proxy/: bar (200; 44.300713ms)
Apr 16 11:52:29.265: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:1080/proxy/rewri... (200; 44.540568ms)
Apr 16 11:52:29.266: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-njs29/services/proxy-service-sf9dv:portname1/proxy/: foo (200; 45.007327ms)
Apr 16 11:52:29.266: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-njs29/services/https:proxy-service-sf9dv:tlsportname1/proxy/: tls baz (200; 44.765925ms)
Apr 16 11:52:29.266: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:460/proxy/: tls baz (200; 44.406225ms)
Apr 16 11:52:29.266: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-njs29/services/proxy-service-sf9dv:portname2/proxy/: bar (200; 44.456581ms)
Apr 16 11:52:29.266: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-njs29/services/http:proxy-service-sf9dv:portname1/proxy/: foo (200; 44.645627ms)
Apr 16 11:52:29.290: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:460/proxy/: tls baz (200; 23.949019ms)
Apr 16 11:52:29.293: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:1080/proxy/... (200; 26.418097ms)
Apr 16 11:52:29.294: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r/proxy/rewriteme"... (200; 26.713073ms)
Apr 16 11:52:29.297: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:1080/proxy/rewri... (200; 30.111918ms)
Apr 16 11:52:29.298: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:443/proxy/... (200; 30.748288ms)
Apr 16 11:52:29.299: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:162/proxy/: bar (200; 31.780286ms)
Apr 16 11:52:29.299: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/https:proxy-service-sf9dv-57m2r:462/proxy/: tls qux (200; 31.751779ms)
Apr 16 11:52:29.299: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:160/proxy/: foo (200; 32.361292ms)
Apr 16 11:52:29.307: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-njs29/services/proxy-service-sf9dv:portname1/proxy/: foo (200; 39.256008ms)
Apr 16 11:52:29.307: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/http:proxy-service-sf9dv-57m2r:160/proxy/: foo (200; 38.760224ms)
Apr 16 11:52:29.308: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-njs29/services/proxy-service-sf9dv:portname2/proxy/: bar (200; 40.82183ms)
Apr 16 11:52:29.308: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-njs29/pods/proxy-service-sf9dv-57m2r:162/proxy/: bar (200; 39.596354ms)
Apr 16 11:52:29.308: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-njs29/services/http:proxy-service-sf9dv:portname1/proxy/: foo (200; 41.52415ms)
Apr 16 11:52:29.309: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-njs29/services/http:proxy-service-sf9dv:portname2/proxy/: bar (200; 41.544235ms)
Apr 16 11:52:29.309: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-njs29/services/https:proxy-service-sf9dv:tlsportname1/proxy/: tls baz (200; 40.844228ms)
Apr 16 11:52:29.309: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-njs29/services/https:proxy-service-sf9dv:tlsportname2/proxy/: tls qux (200; 40.712062ms)
STEP: deleting ReplicationController proxy-service-sf9dv in namespace e2e-tests-proxy-njs29, will wait for the garbage collector to delete the pods
Apr 16 11:52:29.375: INFO: Deleting ReplicationController proxy-service-sf9dv took: 9.809453ms
Apr 16 11:52:29.476: INFO: Terminating ReplicationController proxy-service-sf9dv pods took: 100.676499ms
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:52:39.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-njs29" for this suite.
Apr 16 11:52:45.707: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:52:45.786: INFO: namespace: e2e-tests-proxy-njs29, resource: bindings, ignored listing per whitelist
Apr 16 11:52:45.846: INFO: namespace e2e-tests-proxy-njs29 deletion completed in 6.157916382s

• [SLOW TEST:28.540 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:52:45.848: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-265ba5a0-603e-11e9-be7e-0a580ae9423f
STEP: Creating a pod to test consume secrets
Apr 16 11:52:45.950: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-265cc207-603e-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-projected-m7p4f" to be "success or failure"
Apr 16 11:52:45.955: INFO: Pod "pod-projected-secrets-265cc207-603e-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.405541ms
Apr 16 11:52:47.960: INFO: Pod "pod-projected-secrets-265cc207-603e-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009401785s
STEP: Saw pod success
Apr 16 11:52:47.960: INFO: Pod "pod-projected-secrets-265cc207-603e-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 11:52:47.969: INFO: Trying to get logs from node k8s-3 pod pod-projected-secrets-265cc207-603e-11e9-be7e-0a580ae9423f container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 16 11:52:48.035: INFO: Waiting for pod pod-projected-secrets-265cc207-603e-11e9-be7e-0a580ae9423f to disappear
Apr 16 11:52:48.040: INFO: Pod pod-projected-secrets-265cc207-603e-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:52:48.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-m7p4f" for this suite.
Apr 16 11:52:54.071: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:52:54.190: INFO: namespace: e2e-tests-projected-m7p4f, resource: bindings, ignored listing per whitelist
Apr 16 11:52:54.205: INFO: namespace e2e-tests-projected-m7p4f deletion completed in 6.158377218s

• [SLOW TEST:8.358 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:52:54.207: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Apr 16 11:52:54.275: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:53:00.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-6bf2m" for this suite.
Apr 16 11:53:06.396: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:53:06.453: INFO: namespace: e2e-tests-custom-resource-definition-6bf2m, resource: bindings, ignored listing per whitelist
Apr 16 11:53:06.492: INFO: namespace e2e-tests-custom-resource-definition-6bf2m deletion completed in 6.113307285s

• [SLOW TEST:12.285 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:53:06.493: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Apr 16 11:53:06.611: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-6r29k,SelfLink:/api/v1/namespaces/e2e-tests-watch-6r29k/configmaps/e2e-watch-test-resource-version,UID:32a79fa0-603e-11e9-8569-0800277031c6,ResourceVersion:17902,Generation:0,CreationTimestamp:2019-04-16 11:53:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr 16 11:53:06.611: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-6r29k,SelfLink:/api/v1/namespaces/e2e-tests-watch-6r29k/configmaps/e2e-watch-test-resource-version,UID:32a79fa0-603e-11e9-8569-0800277031c6,ResourceVersion:17903,Generation:0,CreationTimestamp:2019-04-16 11:53:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:53:06.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-6r29k" for this suite.
Apr 16 11:53:12.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:53:12.743: INFO: namespace: e2e-tests-watch-6r29k, resource: bindings, ignored listing per whitelist
Apr 16 11:53:12.773: INFO: namespace e2e-tests-watch-6r29k deletion completed in 6.158122818s

• [SLOW TEST:6.281 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:53:12.774: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Apr 16 11:53:12.847: INFO: Waiting up to 5m0s for pod "downward-api-366580eb-603e-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-downward-api-thjlm" to be "success or failure"
Apr 16 11:53:12.852: INFO: Pod "downward-api-366580eb-603e-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.069347ms
Apr 16 11:53:14.858: INFO: Pod "downward-api-366580eb-603e-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010677672s
STEP: Saw pod success
Apr 16 11:53:14.858: INFO: Pod "downward-api-366580eb-603e-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 11:53:14.862: INFO: Trying to get logs from node k8s-3 pod downward-api-366580eb-603e-11e9-be7e-0a580ae9423f container dapi-container: <nil>
STEP: delete the pod
Apr 16 11:53:14.899: INFO: Waiting for pod downward-api-366580eb-603e-11e9-be7e-0a580ae9423f to disappear
Apr 16 11:53:14.902: INFO: Pod downward-api-366580eb-603e-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:53:14.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-thjlm" for this suite.
Apr 16 11:53:20.928: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:53:21.051: INFO: namespace: e2e-tests-downward-api-thjlm, resource: bindings, ignored listing per whitelist
Apr 16 11:53:21.062: INFO: namespace e2e-tests-downward-api-thjlm deletion completed in 6.156654498s

• [SLOW TEST:8.288 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:53:21.064: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-hs7x
STEP: Creating a pod to test atomic-volume-subpath
Apr 16 11:53:21.163: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-hs7x" in namespace "e2e-tests-subpath-swp9p" to be "success or failure"
Apr 16 11:53:21.182: INFO: Pod "pod-subpath-test-projected-hs7x": Phase="Pending", Reason="", readiness=false. Elapsed: 19.456109ms
Apr 16 11:53:23.192: INFO: Pod "pod-subpath-test-projected-hs7x": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0289061s
Apr 16 11:53:25.197: INFO: Pod "pod-subpath-test-projected-hs7x": Phase="Running", Reason="", readiness=false. Elapsed: 4.034077484s
Apr 16 11:53:27.201: INFO: Pod "pod-subpath-test-projected-hs7x": Phase="Running", Reason="", readiness=false. Elapsed: 6.038572633s
Apr 16 11:53:29.206: INFO: Pod "pod-subpath-test-projected-hs7x": Phase="Running", Reason="", readiness=false. Elapsed: 8.043543501s
Apr 16 11:53:31.220: INFO: Pod "pod-subpath-test-projected-hs7x": Phase="Running", Reason="", readiness=false. Elapsed: 10.056896022s
Apr 16 11:53:33.224: INFO: Pod "pod-subpath-test-projected-hs7x": Phase="Running", Reason="", readiness=false. Elapsed: 12.061275609s
Apr 16 11:53:35.229: INFO: Pod "pod-subpath-test-projected-hs7x": Phase="Running", Reason="", readiness=false. Elapsed: 14.066528457s
Apr 16 11:53:37.235: INFO: Pod "pod-subpath-test-projected-hs7x": Phase="Running", Reason="", readiness=false. Elapsed: 16.072154177s
Apr 16 11:53:39.241: INFO: Pod "pod-subpath-test-projected-hs7x": Phase="Running", Reason="", readiness=false. Elapsed: 18.077966196s
Apr 16 11:53:41.256: INFO: Pod "pod-subpath-test-projected-hs7x": Phase="Running", Reason="", readiness=false. Elapsed: 20.093738638s
Apr 16 11:53:43.266: INFO: Pod "pod-subpath-test-projected-hs7x": Phase="Running", Reason="", readiness=false. Elapsed: 22.103102436s
Apr 16 11:53:45.270: INFO: Pod "pod-subpath-test-projected-hs7x": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.107814608s
STEP: Saw pod success
Apr 16 11:53:45.271: INFO: Pod "pod-subpath-test-projected-hs7x" satisfied condition "success or failure"
Apr 16 11:53:45.275: INFO: Trying to get logs from node k8s-1 pod pod-subpath-test-projected-hs7x container test-container-subpath-projected-hs7x: <nil>
STEP: delete the pod
Apr 16 11:53:45.308: INFO: Waiting for pod pod-subpath-test-projected-hs7x to disappear
Apr 16 11:53:45.313: INFO: Pod pod-subpath-test-projected-hs7x no longer exists
STEP: Deleting pod pod-subpath-test-projected-hs7x
Apr 16 11:53:45.314: INFO: Deleting pod "pod-subpath-test-projected-hs7x" in namespace "e2e-tests-subpath-swp9p"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:53:45.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-swp9p" for this suite.
Apr 16 11:53:51.350: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:53:51.386: INFO: namespace: e2e-tests-subpath-swp9p, resource: bindings, ignored listing per whitelist
Apr 16 11:53:51.457: INFO: namespace e2e-tests-subpath-swp9p deletion completed in 6.136782107s

• [SLOW TEST:30.394 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:53:51.459: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Apr 16 11:53:54.090: INFO: Successfully updated pod "annotationupdate4d768c2f-603e-11e9-be7e-0a580ae9423f"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:53:58.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-zdx68" for this suite.
Apr 16 11:54:20.147: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:54:20.222: INFO: namespace: e2e-tests-downward-api-zdx68, resource: bindings, ignored listing per whitelist
Apr 16 11:54:20.253: INFO: namespace e2e-tests-downward-api-zdx68 deletion completed in 22.122679038s

• [SLOW TEST:28.794 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:54:20.254: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-5e9f056d-603e-11e9-be7e-0a580ae9423f
STEP: Creating a pod to test consume configMaps
Apr 16 11:54:20.358: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5ea099ea-603e-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-projected-cwsmf" to be "success or failure"
Apr 16 11:54:20.371: INFO: Pod "pod-projected-configmaps-5ea099ea-603e-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 12.418561ms
Apr 16 11:54:22.376: INFO: Pod "pod-projected-configmaps-5ea099ea-603e-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017222903s
STEP: Saw pod success
Apr 16 11:54:22.376: INFO: Pod "pod-projected-configmaps-5ea099ea-603e-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 11:54:22.380: INFO: Trying to get logs from node k8s-3 pod pod-projected-configmaps-5ea099ea-603e-11e9-be7e-0a580ae9423f container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 16 11:54:22.411: INFO: Waiting for pod pod-projected-configmaps-5ea099ea-603e-11e9-be7e-0a580ae9423f to disappear
Apr 16 11:54:22.414: INFO: Pod pod-projected-configmaps-5ea099ea-603e-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:54:22.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-cwsmf" for this suite.
Apr 16 11:54:28.435: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:54:28.575: INFO: namespace: e2e-tests-projected-cwsmf, resource: bindings, ignored listing per whitelist
Apr 16 11:54:28.592: INFO: namespace e2e-tests-projected-cwsmf deletion completed in 6.17454098s

• [SLOW TEST:8.338 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:54:28.592: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:54:33.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-jm4rv" for this suite.
Apr 16 11:54:55.748: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:54:55.859: INFO: namespace: e2e-tests-replication-controller-jm4rv, resource: bindings, ignored listing per whitelist
Apr 16 11:54:55.883: INFO: namespace e2e-tests-replication-controller-jm4rv deletion completed in 22.155821592s

• [SLOW TEST:27.291 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:54:55.885: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Apr 16 11:54:55.989: INFO: Waiting up to 5m0s for pod "pod-73df0111-603e-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-emptydir-4z9np" to be "success or failure"
Apr 16 11:54:56.006: INFO: Pod "pod-73df0111-603e-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 17.07119ms
Apr 16 11:54:58.017: INFO: Pod "pod-73df0111-603e-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027772439s
STEP: Saw pod success
Apr 16 11:54:58.017: INFO: Pod "pod-73df0111-603e-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 11:54:58.021: INFO: Trying to get logs from node k8s-2 pod pod-73df0111-603e-11e9-be7e-0a580ae9423f container test-container: <nil>
STEP: delete the pod
Apr 16 11:54:58.055: INFO: Waiting for pod pod-73df0111-603e-11e9-be7e-0a580ae9423f to disappear
Apr 16 11:54:58.061: INFO: Pod pod-73df0111-603e-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:54:58.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-4z9np" for this suite.
Apr 16 11:55:04.087: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:55:04.188: INFO: namespace: e2e-tests-emptydir-4z9np, resource: bindings, ignored listing per whitelist
Apr 16 11:55:04.196: INFO: namespace e2e-tests-emptydir-4z9np deletion completed in 6.1308469s

• [SLOW TEST:8.312 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:55:04.197: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Apr 16 11:55:04.288: INFO: Waiting up to 5m0s for pod "pod-78d195d2-603e-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-emptydir-fjtn9" to be "success or failure"
Apr 16 11:55:04.294: INFO: Pod "pod-78d195d2-603e-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.919285ms
Apr 16 11:55:06.299: INFO: Pod "pod-78d195d2-603e-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010844925s
STEP: Saw pod success
Apr 16 11:55:06.299: INFO: Pod "pod-78d195d2-603e-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 11:55:06.304: INFO: Trying to get logs from node k8s-3 pod pod-78d195d2-603e-11e9-be7e-0a580ae9423f container test-container: <nil>
STEP: delete the pod
Apr 16 11:55:06.335: INFO: Waiting for pod pod-78d195d2-603e-11e9-be7e-0a580ae9423f to disappear
Apr 16 11:55:06.339: INFO: Pod pod-78d195d2-603e-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:55:06.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-fjtn9" for this suite.
Apr 16 11:55:12.361: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:55:12.425: INFO: namespace: e2e-tests-emptydir-fjtn9, resource: bindings, ignored listing per whitelist
Apr 16 11:55:12.467: INFO: namespace e2e-tests-emptydir-fjtn9 deletion completed in 6.123777902s

• [SLOW TEST:8.269 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:55:12.468: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-7dbf1f2e-603e-11e9-be7e-0a580ae9423f
STEP: Creating configMap with name cm-test-opt-upd-7dbf1f57-603e-11e9-be7e-0a580ae9423f
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-7dbf1f2e-603e-11e9-be7e-0a580ae9423f
STEP: Updating configmap cm-test-opt-upd-7dbf1f57-603e-11e9-be7e-0a580ae9423f
STEP: Creating configMap with name cm-test-opt-create-7dbf1f63-603e-11e9-be7e-0a580ae9423f
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:55:16.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-g8jsn" for this suite.
Apr 16 11:55:38.693: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:55:38.716: INFO: namespace: e2e-tests-configmap-g8jsn, resource: bindings, ignored listing per whitelist
Apr 16 11:55:38.799: INFO: namespace e2e-tests-configmap-g8jsn deletion completed in 22.122841786s

• [SLOW TEST:26.330 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:55:38.800: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-8d70ade6-603e-11e9-be7e-0a580ae9423f
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-8d70ade6-603e-11e9-be7e-0a580ae9423f
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:55:42.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-k7cz5" for this suite.
Apr 16 11:56:04.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:56:05.017: INFO: namespace: e2e-tests-projected-k7cz5, resource: bindings, ignored listing per whitelist
Apr 16 11:56:05.172: INFO: namespace e2e-tests-projected-k7cz5 deletion completed in 22.22199475s

• [SLOW TEST:26.372 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:56:05.173: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0416 11:56:15.413361      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr 16 11:56:15.413: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:56:15.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-r2q8k" for this suite.
Apr 16 11:56:23.435: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:56:23.538: INFO: namespace: e2e-tests-gc-r2q8k, resource: bindings, ignored listing per whitelist
Apr 16 11:56:23.587: INFO: namespace e2e-tests-gc-r2q8k deletion completed in 8.169794035s

• [SLOW TEST:18.414 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:56:23.589: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Apr 16 11:56:23.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 --namespace=e2e-tests-kubectl-9j8bc run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Apr 16 11:56:26.037: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Apr 16 11:56:26.037: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:56:28.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9j8bc" for this suite.
Apr 16 11:56:34.067: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:56:34.097: INFO: namespace: e2e-tests-kubectl-9j8bc, resource: bindings, ignored listing per whitelist
Apr 16 11:56:34.202: INFO: namespace e2e-tests-kubectl-9j8bc deletion completed in 6.15445011s

• [SLOW TEST:10.613 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:56:34.203: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-kgtl9
I0416 11:56:34.280916      15 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-kgtl9, replica count: 1
I0416 11:56:35.331437      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0416 11:56:36.332354      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 16 11:56:36.447: INFO: Created: latency-svc-jfpwb
Apr 16 11:56:36.463: INFO: Got endpoints: latency-svc-jfpwb [31.134829ms]
Apr 16 11:56:36.486: INFO: Created: latency-svc-nb7lv
Apr 16 11:56:36.497: INFO: Got endpoints: latency-svc-nb7lv [33.9543ms]
Apr 16 11:56:36.499: INFO: Created: latency-svc-2v6xx
Apr 16 11:56:36.512: INFO: Created: latency-svc-vfzll
Apr 16 11:56:36.512: INFO: Got endpoints: latency-svc-2v6xx [47.994605ms]
Apr 16 11:56:36.523: INFO: Created: latency-svc-2mx5c
Apr 16 11:56:36.531: INFO: Got endpoints: latency-svc-2mx5c [66.235637ms]
Apr 16 11:56:36.532: INFO: Got endpoints: latency-svc-vfzll [67.048283ms]
Apr 16 11:56:36.538: INFO: Created: latency-svc-sw4cj
Apr 16 11:56:36.542: INFO: Got endpoints: latency-svc-sw4cj [77.824288ms]
Apr 16 11:56:36.552: INFO: Created: latency-svc-7fqtz
Apr 16 11:56:36.563: INFO: Created: latency-svc-ccw8m
Apr 16 11:56:36.563: INFO: Got endpoints: latency-svc-7fqtz [98.52877ms]
Apr 16 11:56:36.577: INFO: Created: latency-svc-pgmlr
Apr 16 11:56:36.577: INFO: Got endpoints: latency-svc-ccw8m [112.416619ms]
Apr 16 11:56:36.596: INFO: Created: latency-svc-wpmjh
Apr 16 11:56:36.609: INFO: Got endpoints: latency-svc-pgmlr [143.574416ms]
Apr 16 11:56:36.612: INFO: Got endpoints: latency-svc-wpmjh [146.596669ms]
Apr 16 11:56:36.629: INFO: Created: latency-svc-grgmq
Apr 16 11:56:36.643: INFO: Got endpoints: latency-svc-grgmq [177.662622ms]
Apr 16 11:56:36.679: INFO: Created: latency-svc-9mqvn
Apr 16 11:56:36.689: INFO: Got endpoints: latency-svc-9mqvn [223.900586ms]
Apr 16 11:56:36.709: INFO: Created: latency-svc-xgtlw
Apr 16 11:56:36.717: INFO: Got endpoints: latency-svc-xgtlw [251.414591ms]
Apr 16 11:56:36.735: INFO: Created: latency-svc-9wg7j
Apr 16 11:56:36.744: INFO: Got endpoints: latency-svc-9wg7j [279.08975ms]
Apr 16 11:56:36.755: INFO: Created: latency-svc-sf8ld
Apr 16 11:56:36.768: INFO: Got endpoints: latency-svc-sf8ld [298.869703ms]
Apr 16 11:56:36.783: INFO: Created: latency-svc-cjjqc
Apr 16 11:56:36.793: INFO: Got endpoints: latency-svc-cjjqc [324.30457ms]
Apr 16 11:56:36.801: INFO: Created: latency-svc-g6lld
Apr 16 11:56:36.820: INFO: Created: latency-svc-9sjfx
Apr 16 11:56:36.821: INFO: Got endpoints: latency-svc-g6lld [321.823698ms]
Apr 16 11:56:36.832: INFO: Got endpoints: latency-svc-9sjfx [319.767411ms]
Apr 16 11:56:36.843: INFO: Created: latency-svc-9cqnz
Apr 16 11:56:36.856: INFO: Got endpoints: latency-svc-9cqnz [325.156459ms]
Apr 16 11:56:36.870: INFO: Created: latency-svc-7cm59
Apr 16 11:56:36.879: INFO: Got endpoints: latency-svc-7cm59 [346.812983ms]
Apr 16 11:56:36.891: INFO: Created: latency-svc-kwvwn
Apr 16 11:56:36.902: INFO: Got endpoints: latency-svc-kwvwn [358.603897ms]
Apr 16 11:56:36.908: INFO: Created: latency-svc-5xmmx
Apr 16 11:56:36.919: INFO: Got endpoints: latency-svc-5xmmx [355.83723ms]
Apr 16 11:56:36.934: INFO: Created: latency-svc-6522n
Apr 16 11:56:36.948: INFO: Got endpoints: latency-svc-6522n [370.503009ms]
Apr 16 11:56:36.960: INFO: Created: latency-svc-7c8w4
Apr 16 11:56:36.976: INFO: Got endpoints: latency-svc-7c8w4 [366.701018ms]
Apr 16 11:56:36.995: INFO: Created: latency-svc-t8hbq
Apr 16 11:56:36.999: INFO: Got endpoints: latency-svc-t8hbq [386.853682ms]
Apr 16 11:56:37.018: INFO: Created: latency-svc-n4qjn
Apr 16 11:56:37.033: INFO: Got endpoints: latency-svc-n4qjn [390.038865ms]
Apr 16 11:56:37.047: INFO: Created: latency-svc-pf88v
Apr 16 11:56:37.053: INFO: Got endpoints: latency-svc-pf88v [364.276345ms]
Apr 16 11:56:37.068: INFO: Created: latency-svc-w4sdw
Apr 16 11:56:37.082: INFO: Got endpoints: latency-svc-w4sdw [364.980297ms]
Apr 16 11:56:37.086: INFO: Created: latency-svc-ljdln
Apr 16 11:56:37.106: INFO: Got endpoints: latency-svc-ljdln [52.112322ms]
Apr 16 11:56:37.115: INFO: Created: latency-svc-z687r
Apr 16 11:56:37.118: INFO: Got endpoints: latency-svc-z687r [373.924719ms]
Apr 16 11:56:37.131: INFO: Created: latency-svc-d6fwt
Apr 16 11:56:37.150: INFO: Got endpoints: latency-svc-d6fwt [382.387154ms]
Apr 16 11:56:37.164: INFO: Created: latency-svc-w26d9
Apr 16 11:56:37.169: INFO: Got endpoints: latency-svc-w26d9 [376.054267ms]
Apr 16 11:56:37.176: INFO: Created: latency-svc-l2fgt
Apr 16 11:56:37.192: INFO: Got endpoints: latency-svc-l2fgt [371.281235ms]
Apr 16 11:56:37.201: INFO: Created: latency-svc-kln7c
Apr 16 11:56:37.213: INFO: Got endpoints: latency-svc-kln7c [380.691699ms]
Apr 16 11:56:37.220: INFO: Created: latency-svc-tsw7m
Apr 16 11:56:37.231: INFO: Got endpoints: latency-svc-tsw7m [373.870652ms]
Apr 16 11:56:37.241: INFO: Created: latency-svc-6x95f
Apr 16 11:56:37.250: INFO: Got endpoints: latency-svc-6x95f [370.690231ms]
Apr 16 11:56:37.262: INFO: Created: latency-svc-wcbnb
Apr 16 11:56:37.278: INFO: Got endpoints: latency-svc-wcbnb [376.335918ms]
Apr 16 11:56:37.283: INFO: Created: latency-svc-2tlvv
Apr 16 11:56:37.293: INFO: Got endpoints: latency-svc-2tlvv [372.488321ms]
Apr 16 11:56:37.304: INFO: Created: latency-svc-s7l8q
Apr 16 11:56:37.320: INFO: Got endpoints: latency-svc-s7l8q [372.331978ms]
Apr 16 11:56:37.326: INFO: Created: latency-svc-bkdxh
Apr 16 11:56:37.335: INFO: Got endpoints: latency-svc-bkdxh [358.404211ms]
Apr 16 11:56:37.345: INFO: Created: latency-svc-xqvss
Apr 16 11:56:37.355: INFO: Got endpoints: latency-svc-xqvss [355.732804ms]
Apr 16 11:56:37.365: INFO: Created: latency-svc-vs6bz
Apr 16 11:56:37.369: INFO: Got endpoints: latency-svc-vs6bz [336.189775ms]
Apr 16 11:56:37.395: INFO: Created: latency-svc-r5ccj
Apr 16 11:56:37.407: INFO: Got endpoints: latency-svc-r5ccj [324.157976ms]
Apr 16 11:56:37.409: INFO: Created: latency-svc-h4znq
Apr 16 11:56:37.416: INFO: Got endpoints: latency-svc-h4znq [309.840908ms]
Apr 16 11:56:37.429: INFO: Created: latency-svc-gdrpj
Apr 16 11:56:37.441: INFO: Got endpoints: latency-svc-gdrpj [322.228731ms]
Apr 16 11:56:37.450: INFO: Created: latency-svc-d8zd8
Apr 16 11:56:37.466: INFO: Got endpoints: latency-svc-d8zd8 [315.676311ms]
Apr 16 11:56:37.480: INFO: Created: latency-svc-xbfn4
Apr 16 11:56:37.488: INFO: Got endpoints: latency-svc-xbfn4 [318.549277ms]
Apr 16 11:56:37.496: INFO: Created: latency-svc-gdcw2
Apr 16 11:56:37.503: INFO: Got endpoints: latency-svc-gdcw2 [310.265304ms]
Apr 16 11:56:37.524: INFO: Created: latency-svc-xzdfd
Apr 16 11:56:37.536: INFO: Got endpoints: latency-svc-xzdfd [322.70886ms]
Apr 16 11:56:37.541: INFO: Created: latency-svc-2jb6q
Apr 16 11:56:37.559: INFO: Got endpoints: latency-svc-2jb6q [327.634155ms]
Apr 16 11:56:37.562: INFO: Created: latency-svc-psjhv
Apr 16 11:56:37.584: INFO: Got endpoints: latency-svc-psjhv [332.943168ms]
Apr 16 11:56:37.587: INFO: Created: latency-svc-85lqw
Apr 16 11:56:37.596: INFO: Created: latency-svc-j5xw8
Apr 16 11:56:37.608: INFO: Created: latency-svc-584zk
Apr 16 11:56:37.615: INFO: Got endpoints: latency-svc-85lqw [336.937464ms]
Apr 16 11:56:37.618: INFO: Created: latency-svc-8l7cf
Apr 16 11:56:37.630: INFO: Created: latency-svc-bvjp6
Apr 16 11:56:37.637: INFO: Got endpoints: latency-svc-j5xw8 [344.14376ms]
Apr 16 11:56:37.649: INFO: Created: latency-svc-nth5c
Apr 16 11:56:37.666: INFO: Created: latency-svc-n69mv
Apr 16 11:56:37.666: INFO: Got endpoints: latency-svc-584zk [344.85297ms]
Apr 16 11:56:37.680: INFO: Created: latency-svc-7s4n9
Apr 16 11:56:37.694: INFO: Created: latency-svc-955sn
Apr 16 11:56:37.703: INFO: Created: latency-svc-959vd
Apr 16 11:56:37.707: INFO: Got endpoints: latency-svc-8l7cf [371.870117ms]
Apr 16 11:56:37.717: INFO: Created: latency-svc-prgwz
Apr 16 11:56:37.726: INFO: Created: latency-svc-g972f
Apr 16 11:56:37.737: INFO: Created: latency-svc-28lp9
Apr 16 11:56:37.754: INFO: Created: latency-svc-mqc4n
Apr 16 11:56:37.759: INFO: Got endpoints: latency-svc-bvjp6 [403.374792ms]
Apr 16 11:56:37.764: INFO: Created: latency-svc-fxmzh
Apr 16 11:56:37.774: INFO: Created: latency-svc-8mf7k
Apr 16 11:56:37.786: INFO: Created: latency-svc-585d7
Apr 16 11:56:37.798: INFO: Created: latency-svc-fcq8v
Apr 16 11:56:37.806: INFO: Got endpoints: latency-svc-nth5c [436.54552ms]
Apr 16 11:56:37.811: INFO: Created: latency-svc-6gktt
Apr 16 11:56:37.823: INFO: Created: latency-svc-mzgjw
Apr 16 11:56:37.830: INFO: Created: latency-svc-js7gz
Apr 16 11:56:37.853: INFO: Got endpoints: latency-svc-n69mv [446.282373ms]
Apr 16 11:56:37.866: INFO: Created: latency-svc-k8x5z
Apr 16 11:56:37.908: INFO: Got endpoints: latency-svc-7s4n9 [492.116925ms]
Apr 16 11:56:37.927: INFO: Created: latency-svc-lnlmw
Apr 16 11:56:37.954: INFO: Got endpoints: latency-svc-955sn [512.936013ms]
Apr 16 11:56:37.975: INFO: Created: latency-svc-pcm4c
Apr 16 11:56:38.022: INFO: Got endpoints: latency-svc-959vd [555.815462ms]
Apr 16 11:56:38.034: INFO: Created: latency-svc-5jzg6
Apr 16 11:56:38.055: INFO: Got endpoints: latency-svc-prgwz [567.157348ms]
Apr 16 11:56:38.066: INFO: Created: latency-svc-rtzmd
Apr 16 11:56:38.101: INFO: Got endpoints: latency-svc-g972f [597.676487ms]
Apr 16 11:56:38.113: INFO: Created: latency-svc-mp2v5
Apr 16 11:56:38.155: INFO: Got endpoints: latency-svc-28lp9 [617.832ms]
Apr 16 11:56:38.168: INFO: Created: latency-svc-jcbrt
Apr 16 11:56:38.202: INFO: Got endpoints: latency-svc-mqc4n [643.23189ms]
Apr 16 11:56:38.214: INFO: Created: latency-svc-75swz
Apr 16 11:56:38.260: INFO: Got endpoints: latency-svc-fxmzh [675.356525ms]
Apr 16 11:56:38.295: INFO: Created: latency-svc-dmwcz
Apr 16 11:56:38.302: INFO: Got endpoints: latency-svc-8mf7k [685.780321ms]
Apr 16 11:56:38.321: INFO: Created: latency-svc-svpcn
Apr 16 11:56:38.357: INFO: Got endpoints: latency-svc-585d7 [719.623372ms]
Apr 16 11:56:38.397: INFO: Created: latency-svc-bz994
Apr 16 11:56:38.401: INFO: Got endpoints: latency-svc-fcq8v [734.692459ms]
Apr 16 11:56:38.436: INFO: Created: latency-svc-l2cr8
Apr 16 11:56:38.453: INFO: Got endpoints: latency-svc-6gktt [746.076252ms]
Apr 16 11:56:38.482: INFO: Created: latency-svc-wsrv9
Apr 16 11:56:38.505: INFO: Got endpoints: latency-svc-mzgjw [745.445727ms]
Apr 16 11:56:38.525: INFO: Created: latency-svc-vl86k
Apr 16 11:56:38.552: INFO: Got endpoints: latency-svc-js7gz [745.949154ms]
Apr 16 11:56:38.587: INFO: Created: latency-svc-gqfvz
Apr 16 11:56:38.603: INFO: Got endpoints: latency-svc-k8x5z [750.01543ms]
Apr 16 11:56:38.627: INFO: Created: latency-svc-87nkt
Apr 16 11:56:38.655: INFO: Got endpoints: latency-svc-lnlmw [746.496412ms]
Apr 16 11:56:38.685: INFO: Created: latency-svc-xsxjc
Apr 16 11:56:38.704: INFO: Got endpoints: latency-svc-pcm4c [749.53315ms]
Apr 16 11:56:38.720: INFO: Created: latency-svc-6jdnp
Apr 16 11:56:38.760: INFO: Got endpoints: latency-svc-5jzg6 [738.214715ms]
Apr 16 11:56:38.782: INFO: Created: latency-svc-mj7b7
Apr 16 11:56:38.805: INFO: Got endpoints: latency-svc-rtzmd [750.189935ms]
Apr 16 11:56:38.820: INFO: Created: latency-svc-2jcf6
Apr 16 11:56:38.856: INFO: Got endpoints: latency-svc-mp2v5 [754.766652ms]
Apr 16 11:56:38.871: INFO: Created: latency-svc-5sdcw
Apr 16 11:56:38.904: INFO: Got endpoints: latency-svc-jcbrt [749.212317ms]
Apr 16 11:56:38.923: INFO: Created: latency-svc-hhn6p
Apr 16 11:56:38.956: INFO: Got endpoints: latency-svc-75swz [753.338033ms]
Apr 16 11:56:38.974: INFO: Created: latency-svc-nqhx9
Apr 16 11:56:39.005: INFO: Got endpoints: latency-svc-dmwcz [745.704907ms]
Apr 16 11:56:39.022: INFO: Created: latency-svc-c5c7v
Apr 16 11:56:39.055: INFO: Got endpoints: latency-svc-svpcn [753.172106ms]
Apr 16 11:56:39.076: INFO: Created: latency-svc-lfcwf
Apr 16 11:56:39.106: INFO: Got endpoints: latency-svc-bz994 [748.652592ms]
Apr 16 11:56:39.125: INFO: Created: latency-svc-29mnf
Apr 16 11:56:39.162: INFO: Got endpoints: latency-svc-l2cr8 [759.169126ms]
Apr 16 11:56:39.192: INFO: Created: latency-svc-4fc2t
Apr 16 11:56:39.206: INFO: Got endpoints: latency-svc-wsrv9 [752.732446ms]
Apr 16 11:56:39.221: INFO: Created: latency-svc-p8dks
Apr 16 11:56:39.257: INFO: Got endpoints: latency-svc-vl86k [752.368232ms]
Apr 16 11:56:39.269: INFO: Created: latency-svc-tkmdx
Apr 16 11:56:39.307: INFO: Got endpoints: latency-svc-gqfvz [754.772784ms]
Apr 16 11:56:39.326: INFO: Created: latency-svc-zv8ff
Apr 16 11:56:39.357: INFO: Got endpoints: latency-svc-87nkt [753.721678ms]
Apr 16 11:56:39.374: INFO: Created: latency-svc-ncsd2
Apr 16 11:56:39.404: INFO: Got endpoints: latency-svc-xsxjc [749.143867ms]
Apr 16 11:56:39.416: INFO: Created: latency-svc-5tj8m
Apr 16 11:56:39.455: INFO: Got endpoints: latency-svc-6jdnp [751.011227ms]
Apr 16 11:56:39.468: INFO: Created: latency-svc-gxcf2
Apr 16 11:56:39.503: INFO: Got endpoints: latency-svc-mj7b7 [743.013569ms]
Apr 16 11:56:39.528: INFO: Created: latency-svc-mjsgq
Apr 16 11:56:39.565: INFO: Got endpoints: latency-svc-2jcf6 [759.224304ms]
Apr 16 11:56:39.595: INFO: Created: latency-svc-bbkh9
Apr 16 11:56:39.612: INFO: Got endpoints: latency-svc-5sdcw [756.338353ms]
Apr 16 11:56:39.642: INFO: Created: latency-svc-qswmx
Apr 16 11:56:39.656: INFO: Got endpoints: latency-svc-hhn6p [751.626113ms]
Apr 16 11:56:39.671: INFO: Created: latency-svc-qfw85
Apr 16 11:56:39.706: INFO: Got endpoints: latency-svc-nqhx9 [750.374948ms]
Apr 16 11:56:39.726: INFO: Created: latency-svc-vtxbw
Apr 16 11:56:39.753: INFO: Got endpoints: latency-svc-c5c7v [747.421667ms]
Apr 16 11:56:39.767: INFO: Created: latency-svc-q55pp
Apr 16 11:56:39.804: INFO: Got endpoints: latency-svc-lfcwf [749.090606ms]
Apr 16 11:56:39.824: INFO: Created: latency-svc-5g6k4
Apr 16 11:56:39.856: INFO: Got endpoints: latency-svc-29mnf [750.233465ms]
Apr 16 11:56:39.872: INFO: Created: latency-svc-n4p4t
Apr 16 11:56:39.902: INFO: Got endpoints: latency-svc-4fc2t [739.816878ms]
Apr 16 11:56:39.918: INFO: Created: latency-svc-8fzs2
Apr 16 11:56:39.953: INFO: Got endpoints: latency-svc-p8dks [746.895812ms]
Apr 16 11:56:39.965: INFO: Created: latency-svc-szqjv
Apr 16 11:56:40.004: INFO: Got endpoints: latency-svc-tkmdx [746.987593ms]
Apr 16 11:56:40.019: INFO: Created: latency-svc-4tmvk
Apr 16 11:56:40.056: INFO: Got endpoints: latency-svc-zv8ff [748.664901ms]
Apr 16 11:56:40.098: INFO: Created: latency-svc-p8fs9
Apr 16 11:56:40.110: INFO: Got endpoints: latency-svc-ncsd2 [752.523ms]
Apr 16 11:56:40.141: INFO: Created: latency-svc-d8qcf
Apr 16 11:56:40.161: INFO: Got endpoints: latency-svc-5tj8m [756.815168ms]
Apr 16 11:56:40.191: INFO: Created: latency-svc-dddp7
Apr 16 11:56:40.205: INFO: Got endpoints: latency-svc-gxcf2 [750.196166ms]
Apr 16 11:56:40.227: INFO: Created: latency-svc-v4lpv
Apr 16 11:56:40.254: INFO: Got endpoints: latency-svc-mjsgq [750.763645ms]
Apr 16 11:56:40.273: INFO: Created: latency-svc-vvsdg
Apr 16 11:56:40.305: INFO: Got endpoints: latency-svc-bbkh9 [739.85055ms]
Apr 16 11:56:40.325: INFO: Created: latency-svc-sxhcq
Apr 16 11:56:40.357: INFO: Got endpoints: latency-svc-qswmx [744.147829ms]
Apr 16 11:56:40.372: INFO: Created: latency-svc-mcqf9
Apr 16 11:56:40.406: INFO: Got endpoints: latency-svc-qfw85 [749.125331ms]
Apr 16 11:56:40.435: INFO: Created: latency-svc-khbzn
Apr 16 11:56:40.456: INFO: Got endpoints: latency-svc-vtxbw [749.950298ms]
Apr 16 11:56:40.495: INFO: Created: latency-svc-4q4m7
Apr 16 11:56:40.504: INFO: Got endpoints: latency-svc-q55pp [750.591906ms]
Apr 16 11:56:40.541: INFO: Created: latency-svc-mtqps
Apr 16 11:56:40.558: INFO: Got endpoints: latency-svc-5g6k4 [753.464332ms]
Apr 16 11:56:40.596: INFO: Created: latency-svc-tgb9z
Apr 16 11:56:40.608: INFO: Got endpoints: latency-svc-n4p4t [751.096608ms]
Apr 16 11:56:40.638: INFO: Created: latency-svc-bzqns
Apr 16 11:56:40.656: INFO: Got endpoints: latency-svc-8fzs2 [753.847526ms]
Apr 16 11:56:40.681: INFO: Created: latency-svc-5rl7m
Apr 16 11:56:40.708: INFO: Got endpoints: latency-svc-szqjv [754.599968ms]
Apr 16 11:56:40.729: INFO: Created: latency-svc-ll7r6
Apr 16 11:56:40.756: INFO: Got endpoints: latency-svc-4tmvk [751.434123ms]
Apr 16 11:56:40.780: INFO: Created: latency-svc-5z5kx
Apr 16 11:56:40.804: INFO: Got endpoints: latency-svc-p8fs9 [748.259396ms]
Apr 16 11:56:40.833: INFO: Created: latency-svc-fdnk5
Apr 16 11:56:40.856: INFO: Got endpoints: latency-svc-d8qcf [745.534918ms]
Apr 16 11:56:40.892: INFO: Created: latency-svc-gd7gc
Apr 16 11:56:40.910: INFO: Got endpoints: latency-svc-dddp7 [748.475437ms]
Apr 16 11:56:40.930: INFO: Created: latency-svc-vp4bd
Apr 16 11:56:40.957: INFO: Got endpoints: latency-svc-v4lpv [752.05182ms]
Apr 16 11:56:40.973: INFO: Created: latency-svc-zbmjb
Apr 16 11:56:41.001: INFO: Got endpoints: latency-svc-vvsdg [746.52779ms]
Apr 16 11:56:41.022: INFO: Created: latency-svc-qbvmq
Apr 16 11:56:41.057: INFO: Got endpoints: latency-svc-sxhcq [751.796831ms]
Apr 16 11:56:41.069: INFO: Created: latency-svc-g29x5
Apr 16 11:56:41.109: INFO: Got endpoints: latency-svc-mcqf9 [752.229707ms]
Apr 16 11:56:41.126: INFO: Created: latency-svc-n48wm
Apr 16 11:56:41.152: INFO: Got endpoints: latency-svc-khbzn [746.424908ms]
Apr 16 11:56:41.168: INFO: Created: latency-svc-gt2pm
Apr 16 11:56:41.202: INFO: Got endpoints: latency-svc-4q4m7 [745.32728ms]
Apr 16 11:56:41.216: INFO: Created: latency-svc-5hqnv
Apr 16 11:56:41.257: INFO: Got endpoints: latency-svc-mtqps [753.322023ms]
Apr 16 11:56:41.270: INFO: Created: latency-svc-9s4bv
Apr 16 11:56:41.305: INFO: Got endpoints: latency-svc-tgb9z [747.211515ms]
Apr 16 11:56:41.317: INFO: Created: latency-svc-z8d2g
Apr 16 11:56:41.357: INFO: Got endpoints: latency-svc-bzqns [748.875028ms]
Apr 16 11:56:41.370: INFO: Created: latency-svc-pf6dt
Apr 16 11:56:41.419: INFO: Got endpoints: latency-svc-5rl7m [763.080067ms]
Apr 16 11:56:41.435: INFO: Created: latency-svc-s756b
Apr 16 11:56:41.456: INFO: Got endpoints: latency-svc-ll7r6 [747.895082ms]
Apr 16 11:56:41.469: INFO: Created: latency-svc-z97l7
Apr 16 11:56:41.502: INFO: Got endpoints: latency-svc-5z5kx [746.344312ms]
Apr 16 11:56:41.522: INFO: Created: latency-svc-gb89g
Apr 16 11:56:41.557: INFO: Got endpoints: latency-svc-fdnk5 [753.223943ms]
Apr 16 11:56:41.570: INFO: Created: latency-svc-cdl96
Apr 16 11:56:41.607: INFO: Got endpoints: latency-svc-gd7gc [751.414729ms]
Apr 16 11:56:41.621: INFO: Created: latency-svc-c5455
Apr 16 11:56:41.652: INFO: Got endpoints: latency-svc-vp4bd [741.710008ms]
Apr 16 11:56:41.674: INFO: Created: latency-svc-nw4x9
Apr 16 11:56:41.708: INFO: Got endpoints: latency-svc-zbmjb [750.147369ms]
Apr 16 11:56:41.724: INFO: Created: latency-svc-7wggl
Apr 16 11:56:41.754: INFO: Got endpoints: latency-svc-qbvmq [752.420577ms]
Apr 16 11:56:41.766: INFO: Created: latency-svc-9n2nf
Apr 16 11:56:41.804: INFO: Got endpoints: latency-svc-g29x5 [746.796156ms]
Apr 16 11:56:41.815: INFO: Created: latency-svc-7gblw
Apr 16 11:56:41.854: INFO: Got endpoints: latency-svc-n48wm [745.225674ms]
Apr 16 11:56:41.870: INFO: Created: latency-svc-v754m
Apr 16 11:56:41.902: INFO: Got endpoints: latency-svc-gt2pm [749.941645ms]
Apr 16 11:56:41.912: INFO: Created: latency-svc-pppsg
Apr 16 11:56:41.960: INFO: Got endpoints: latency-svc-5hqnv [757.619253ms]
Apr 16 11:56:41.973: INFO: Created: latency-svc-m6qms
Apr 16 11:56:42.006: INFO: Got endpoints: latency-svc-9s4bv [748.274539ms]
Apr 16 11:56:42.021: INFO: Created: latency-svc-7p7ws
Apr 16 11:56:42.057: INFO: Got endpoints: latency-svc-z8d2g [751.9149ms]
Apr 16 11:56:42.074: INFO: Created: latency-svc-g8b8t
Apr 16 11:56:42.104: INFO: Got endpoints: latency-svc-pf6dt [747.660835ms]
Apr 16 11:56:42.119: INFO: Created: latency-svc-gpqhd
Apr 16 11:56:42.156: INFO: Got endpoints: latency-svc-s756b [736.787859ms]
Apr 16 11:56:42.182: INFO: Created: latency-svc-gp7p9
Apr 16 11:56:42.204: INFO: Got endpoints: latency-svc-z97l7 [747.983599ms]
Apr 16 11:56:42.236: INFO: Created: latency-svc-kmbs2
Apr 16 11:56:42.251: INFO: Got endpoints: latency-svc-gb89g [748.891544ms]
Apr 16 11:56:42.271: INFO: Created: latency-svc-l8h4m
Apr 16 11:56:42.307: INFO: Got endpoints: latency-svc-cdl96 [749.669764ms]
Apr 16 11:56:42.328: INFO: Created: latency-svc-259w4
Apr 16 11:56:42.361: INFO: Got endpoints: latency-svc-c5455 [753.939387ms]
Apr 16 11:56:42.378: INFO: Created: latency-svc-556rd
Apr 16 11:56:42.403: INFO: Got endpoints: latency-svc-nw4x9 [751.017913ms]
Apr 16 11:56:42.418: INFO: Created: latency-svc-kmhqr
Apr 16 11:56:42.456: INFO: Got endpoints: latency-svc-7wggl [748.063058ms]
Apr 16 11:56:42.471: INFO: Created: latency-svc-k8z8b
Apr 16 11:56:42.519: INFO: Got endpoints: latency-svc-9n2nf [764.494613ms]
Apr 16 11:56:42.554: INFO: Created: latency-svc-qx65z
Apr 16 11:56:42.581: INFO: Got endpoints: latency-svc-7gblw [777.63817ms]
Apr 16 11:56:42.611: INFO: Got endpoints: latency-svc-v754m [753.674747ms]
Apr 16 11:56:42.612: INFO: Created: latency-svc-69lcx
Apr 16 11:56:42.641: INFO: Created: latency-svc-pddk4
Apr 16 11:56:42.663: INFO: Got endpoints: latency-svc-pppsg [760.559903ms]
Apr 16 11:56:42.711: INFO: Got endpoints: latency-svc-m6qms [751.269641ms]
Apr 16 11:56:42.712: INFO: Created: latency-svc-9ngtl
Apr 16 11:56:42.730: INFO: Created: latency-svc-lcmf2
Apr 16 11:56:42.757: INFO: Got endpoints: latency-svc-7p7ws [750.891041ms]
Apr 16 11:56:42.771: INFO: Created: latency-svc-qt826
Apr 16 11:56:42.806: INFO: Got endpoints: latency-svc-g8b8t [748.017085ms]
Apr 16 11:56:42.823: INFO: Created: latency-svc-dsb59
Apr 16 11:56:42.855: INFO: Got endpoints: latency-svc-gpqhd [750.525588ms]
Apr 16 11:56:42.869: INFO: Created: latency-svc-lrm9q
Apr 16 11:56:42.904: INFO: Got endpoints: latency-svc-gp7p9 [747.144582ms]
Apr 16 11:56:42.919: INFO: Created: latency-svc-hwk5m
Apr 16 11:56:42.952: INFO: Got endpoints: latency-svc-kmbs2 [747.876465ms]
Apr 16 11:56:42.968: INFO: Created: latency-svc-fxlxt
Apr 16 11:56:43.008: INFO: Got endpoints: latency-svc-l8h4m [756.365043ms]
Apr 16 11:56:43.019: INFO: Created: latency-svc-d9b5w
Apr 16 11:56:43.057: INFO: Got endpoints: latency-svc-259w4 [749.730472ms]
Apr 16 11:56:43.068: INFO: Created: latency-svc-sp4wx
Apr 16 11:56:43.103: INFO: Got endpoints: latency-svc-556rd [741.507913ms]
Apr 16 11:56:43.115: INFO: Created: latency-svc-gmhl9
Apr 16 11:56:43.174: INFO: Got endpoints: latency-svc-kmhqr [771.148374ms]
Apr 16 11:56:43.186: INFO: Created: latency-svc-q6mg4
Apr 16 11:56:43.208: INFO: Got endpoints: latency-svc-k8z8b [752.139934ms]
Apr 16 11:56:43.220: INFO: Created: latency-svc-mbb8l
Apr 16 11:56:43.252: INFO: Got endpoints: latency-svc-qx65z [733.371301ms]
Apr 16 11:56:43.275: INFO: Created: latency-svc-zf27g
Apr 16 11:56:43.305: INFO: Got endpoints: latency-svc-69lcx [723.867744ms]
Apr 16 11:56:43.317: INFO: Created: latency-svc-dd5t7
Apr 16 11:56:43.358: INFO: Got endpoints: latency-svc-pddk4 [746.350852ms]
Apr 16 11:56:43.377: INFO: Created: latency-svc-7mmf9
Apr 16 11:56:43.406: INFO: Got endpoints: latency-svc-9ngtl [742.069282ms]
Apr 16 11:56:43.429: INFO: Created: latency-svc-pbxkl
Apr 16 11:56:43.458: INFO: Got endpoints: latency-svc-lcmf2 [746.384301ms]
Apr 16 11:56:43.487: INFO: Created: latency-svc-zj8rc
Apr 16 11:56:43.522: INFO: Got endpoints: latency-svc-qt826 [765.312348ms]
Apr 16 11:56:43.556: INFO: Created: latency-svc-f745q
Apr 16 11:56:43.561: INFO: Got endpoints: latency-svc-dsb59 [755.147714ms]
Apr 16 11:56:43.599: INFO: Created: latency-svc-tv69r
Apr 16 11:56:43.604: INFO: Got endpoints: latency-svc-lrm9q [749.329201ms]
Apr 16 11:56:43.637: INFO: Created: latency-svc-nt962
Apr 16 11:56:43.656: INFO: Got endpoints: latency-svc-hwk5m [752.072489ms]
Apr 16 11:56:43.699: INFO: Created: latency-svc-rxdfz
Apr 16 11:56:43.709: INFO: Got endpoints: latency-svc-fxlxt [756.467782ms]
Apr 16 11:56:43.734: INFO: Created: latency-svc-rxzxp
Apr 16 11:56:43.752: INFO: Got endpoints: latency-svc-d9b5w [743.706775ms]
Apr 16 11:56:43.776: INFO: Created: latency-svc-r5mt8
Apr 16 11:56:43.806: INFO: Got endpoints: latency-svc-sp4wx [748.689687ms]
Apr 16 11:56:43.835: INFO: Created: latency-svc-gxf7v
Apr 16 11:56:43.855: INFO: Got endpoints: latency-svc-gmhl9 [751.930653ms]
Apr 16 11:56:43.898: INFO: Created: latency-svc-ph5sj
Apr 16 11:56:43.907: INFO: Got endpoints: latency-svc-q6mg4 [732.682384ms]
Apr 16 11:56:43.937: INFO: Created: latency-svc-sdxf4
Apr 16 11:56:43.953: INFO: Got endpoints: latency-svc-mbb8l [744.181721ms]
Apr 16 11:56:43.982: INFO: Created: latency-svc-dmn2q
Apr 16 11:56:44.003: INFO: Got endpoints: latency-svc-zf27g [750.421202ms]
Apr 16 11:56:44.027: INFO: Created: latency-svc-bjpzp
Apr 16 11:56:44.054: INFO: Got endpoints: latency-svc-dd5t7 [748.536975ms]
Apr 16 11:56:44.079: INFO: Created: latency-svc-vs5fc
Apr 16 11:56:44.103: INFO: Got endpoints: latency-svc-7mmf9 [745.115642ms]
Apr 16 11:56:44.129: INFO: Created: latency-svc-x8rx7
Apr 16 11:56:44.157: INFO: Got endpoints: latency-svc-pbxkl [751.137461ms]
Apr 16 11:56:44.175: INFO: Created: latency-svc-qfq6m
Apr 16 11:56:44.205: INFO: Got endpoints: latency-svc-zj8rc [747.136793ms]
Apr 16 11:56:44.219: INFO: Created: latency-svc-4zths
Apr 16 11:56:44.259: INFO: Got endpoints: latency-svc-f745q [736.373931ms]
Apr 16 11:56:44.272: INFO: Created: latency-svc-wkzxc
Apr 16 11:56:44.307: INFO: Got endpoints: latency-svc-tv69r [745.293634ms]
Apr 16 11:56:44.353: INFO: Got endpoints: latency-svc-nt962 [748.282947ms]
Apr 16 11:56:44.415: INFO: Got endpoints: latency-svc-rxdfz [753.067775ms]
Apr 16 11:56:44.453: INFO: Got endpoints: latency-svc-rxzxp [744.558114ms]
Apr 16 11:56:44.505: INFO: Got endpoints: latency-svc-r5mt8 [752.738845ms]
Apr 16 11:56:44.556: INFO: Got endpoints: latency-svc-gxf7v [749.38749ms]
Apr 16 11:56:44.607: INFO: Got endpoints: latency-svc-ph5sj [751.649152ms]
Apr 16 11:56:44.656: INFO: Got endpoints: latency-svc-sdxf4 [748.542663ms]
Apr 16 11:56:44.708: INFO: Got endpoints: latency-svc-dmn2q [755.130925ms]
Apr 16 11:56:44.770: INFO: Got endpoints: latency-svc-bjpzp [766.819127ms]
Apr 16 11:56:44.810: INFO: Got endpoints: latency-svc-vs5fc [755.107142ms]
Apr 16 11:56:44.855: INFO: Got endpoints: latency-svc-x8rx7 [751.608375ms]
Apr 16 11:56:44.903: INFO: Got endpoints: latency-svc-qfq6m [745.57995ms]
Apr 16 11:56:44.954: INFO: Got endpoints: latency-svc-4zths [749.089492ms]
Apr 16 11:56:45.003: INFO: Got endpoints: latency-svc-wkzxc [743.552957ms]
Apr 16 11:56:45.003: INFO: Latencies: [33.9543ms 47.994605ms 52.112322ms 66.235637ms 67.048283ms 77.824288ms 98.52877ms 112.416619ms 143.574416ms 146.596669ms 177.662622ms 223.900586ms 251.414591ms 279.08975ms 298.869703ms 309.840908ms 310.265304ms 315.676311ms 318.549277ms 319.767411ms 321.823698ms 322.228731ms 322.70886ms 324.157976ms 324.30457ms 325.156459ms 327.634155ms 332.943168ms 336.189775ms 336.937464ms 344.14376ms 344.85297ms 346.812983ms 355.732804ms 355.83723ms 358.404211ms 358.603897ms 364.276345ms 364.980297ms 366.701018ms 370.503009ms 370.690231ms 371.281235ms 371.870117ms 372.331978ms 372.488321ms 373.870652ms 373.924719ms 376.054267ms 376.335918ms 380.691699ms 382.387154ms 386.853682ms 390.038865ms 403.374792ms 436.54552ms 446.282373ms 492.116925ms 512.936013ms 555.815462ms 567.157348ms 597.676487ms 617.832ms 643.23189ms 675.356525ms 685.780321ms 719.623372ms 723.867744ms 732.682384ms 733.371301ms 734.692459ms 736.373931ms 736.787859ms 738.214715ms 739.816878ms 739.85055ms 741.507913ms 741.710008ms 742.069282ms 743.013569ms 743.552957ms 743.706775ms 744.147829ms 744.181721ms 744.558114ms 745.115642ms 745.225674ms 745.293634ms 745.32728ms 745.445727ms 745.534918ms 745.57995ms 745.704907ms 745.949154ms 746.076252ms 746.344312ms 746.350852ms 746.384301ms 746.424908ms 746.496412ms 746.52779ms 746.796156ms 746.895812ms 746.987593ms 747.136793ms 747.144582ms 747.211515ms 747.421667ms 747.660835ms 747.876465ms 747.895082ms 747.983599ms 748.017085ms 748.063058ms 748.259396ms 748.274539ms 748.282947ms 748.475437ms 748.536975ms 748.542663ms 748.652592ms 748.664901ms 748.689687ms 748.875028ms 748.891544ms 749.089492ms 749.090606ms 749.125331ms 749.143867ms 749.212317ms 749.329201ms 749.38749ms 749.53315ms 749.669764ms 749.730472ms 749.941645ms 749.950298ms 750.01543ms 750.147369ms 750.189935ms 750.196166ms 750.233465ms 750.374948ms 750.421202ms 750.525588ms 750.591906ms 750.763645ms 750.891041ms 751.011227ms 751.017913ms 751.096608ms 751.137461ms 751.269641ms 751.414729ms 751.434123ms 751.608375ms 751.626113ms 751.649152ms 751.796831ms 751.9149ms 751.930653ms 752.05182ms 752.072489ms 752.139934ms 752.229707ms 752.368232ms 752.420577ms 752.523ms 752.732446ms 752.738845ms 753.067775ms 753.172106ms 753.223943ms 753.322023ms 753.338033ms 753.464332ms 753.674747ms 753.721678ms 753.847526ms 753.939387ms 754.599968ms 754.766652ms 754.772784ms 755.107142ms 755.130925ms 755.147714ms 756.338353ms 756.365043ms 756.467782ms 756.815168ms 757.619253ms 759.169126ms 759.224304ms 760.559903ms 763.080067ms 764.494613ms 765.312348ms 766.819127ms 771.148374ms 777.63817ms]
Apr 16 11:56:45.003: INFO: 50 %ile: 746.52779ms
Apr 16 11:56:45.003: INFO: 90 %ile: 754.599968ms
Apr 16 11:56:45.003: INFO: 99 %ile: 771.148374ms
Apr 16 11:56:45.003: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:56:45.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-kgtl9" for this suite.
Apr 16 11:57:01.043: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:57:01.162: INFO: namespace: e2e-tests-svc-latency-kgtl9, resource: bindings, ignored listing per whitelist
Apr 16 11:57:01.215: INFO: namespace e2e-tests-svc-latency-kgtl9 deletion completed in 16.201469149s

• [SLOW TEST:27.012 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:57:01.216: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 16 11:57:01.337: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-j42fp'
Apr 16 11:57:01.450: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr 16 11:57:01.450: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1268
Apr 16 11:57:03.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-j42fp'
Apr 16 11:57:03.574: INFO: stderr: ""
Apr 16 11:57:03.574: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:57:03.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-j42fp" for this suite.
Apr 16 11:57:09.646: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:57:09.750: INFO: namespace: e2e-tests-kubectl-j42fp, resource: bindings, ignored listing per whitelist
Apr 16 11:57:09.773: INFO: namespace e2e-tests-kubectl-j42fp deletion completed in 6.18133083s

• [SLOW TEST:8.557 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:57:09.774: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Apr 16 11:57:11.942: INFO: Pod pod-hostip-c3af88c4-603e-11e9-be7e-0a580ae9423f has hostIP: 172.17.8.101
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:57:11.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-m9j4p" for this suite.
Apr 16 11:57:33.963: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:57:34.007: INFO: namespace: e2e-tests-pods-m9j4p, resource: bindings, ignored listing per whitelist
Apr 16 11:57:34.104: INFO: namespace e2e-tests-pods-m9j4p deletion completed in 22.158382021s

• [SLOW TEST:24.330 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:57:34.105: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Apr 16 11:57:34.219: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d22e9f00-603e-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-projected-6mcdj" to be "success or failure"
Apr 16 11:57:34.229: INFO: Pod "downwardapi-volume-d22e9f00-603e-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.347927ms
Apr 16 11:57:36.236: INFO: Pod "downwardapi-volume-d22e9f00-603e-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017110455s
STEP: Saw pod success
Apr 16 11:57:36.236: INFO: Pod "downwardapi-volume-d22e9f00-603e-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 11:57:36.240: INFO: Trying to get logs from node k8s-3 pod downwardapi-volume-d22e9f00-603e-11e9-be7e-0a580ae9423f container client-container: <nil>
STEP: delete the pod
Apr 16 11:57:36.273: INFO: Waiting for pod downwardapi-volume-d22e9f00-603e-11e9-be7e-0a580ae9423f to disappear
Apr 16 11:57:36.283: INFO: Pod downwardapi-volume-d22e9f00-603e-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:57:36.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6mcdj" for this suite.
Apr 16 11:57:42.324: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:57:42.435: INFO: namespace: e2e-tests-projected-6mcdj, resource: bindings, ignored listing per whitelist
Apr 16 11:57:42.494: INFO: namespace e2e-tests-projected-6mcdj deletion completed in 6.20700946s

• [SLOW TEST:8.390 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:57:42.505: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Apr 16 11:57:42.735: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 16 11:57:42.762: INFO: Waiting for terminating namespaces to be deleted...
Apr 16 11:57:42.774: INFO: 
Logging pods the kubelet thinks is on node k8s-1 before test
Apr 16 11:57:42.795: INFO: kube-apiserver-k8s-1 from kube-system started at <nil> (0 container statuses recorded)
Apr 16 11:57:42.795: INFO: kube-scheduler-k8s-1 from kube-system started at <nil> (0 container statuses recorded)
Apr 16 11:57:42.795: INFO: kube-proxy-zmk77 from kube-system started at 2019-04-16 09:04:35 +0000 UTC (1 container statuses recorded)
Apr 16 11:57:42.796: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 16 11:57:42.796: INFO: sonobuoy-systemd-logs-daemon-set-bd0902ee46574666-xtxss from heptio-sonobuoy started at 2019-04-16 11:31:01 +0000 UTC (2 container statuses recorded)
Apr 16 11:57:42.796: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 16 11:57:42.796: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 16 11:57:42.797: INFO: kube-controller-manager-k8s-1 from kube-system started at <nil> (0 container statuses recorded)
Apr 16 11:57:42.797: INFO: kube-flannel-fnd59 from kube-system started at 2019-04-16 09:04:20 +0000 UTC (2 container statuses recorded)
Apr 16 11:57:42.797: INFO: 	Container install-cni ready: true, restart count 0
Apr 16 11:57:42.797: INFO: 	Container kube-flannel ready: true, restart count 0
Apr 16 11:57:42.797: INFO: 
Logging pods the kubelet thinks is on node k8s-2 before test
Apr 16 11:57:42.820: INFO: kube-apiserver-k8s-2 from kube-system started at <nil> (0 container statuses recorded)
Apr 16 11:57:42.820: INFO: kube-proxy-zbpwt from kube-system started at 2019-04-16 09:04:46 +0000 UTC (1 container statuses recorded)
Apr 16 11:57:42.820: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 16 11:57:42.820: INFO: kube-flannel-zhgc5 from kube-system started at 2019-04-16 09:04:20 +0000 UTC (2 container statuses recorded)
Apr 16 11:57:42.820: INFO: 	Container install-cni ready: true, restart count 0
Apr 16 11:57:42.820: INFO: 	Container kube-flannel ready: true, restart count 0
Apr 16 11:57:42.820: INFO: sonobuoy-systemd-logs-daemon-set-bd0902ee46574666-6pmwz from heptio-sonobuoy started at 2019-04-16 11:31:01 +0000 UTC (2 container statuses recorded)
Apr 16 11:57:42.820: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 16 11:57:42.820: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 16 11:57:42.821: INFO: kube-controller-manager-k8s-2 from kube-system started at <nil> (0 container statuses recorded)
Apr 16 11:57:42.821: INFO: kube-scheduler-k8s-2 from kube-system started at <nil> (0 container statuses recorded)
Apr 16 11:57:42.821: INFO: coredns-644c686c9-xkwgk from kube-system started at 2019-04-16 09:04:45 +0000 UTC (1 container statuses recorded)
Apr 16 11:57:42.821: INFO: 	Container coredns ready: true, restart count 0
Apr 16 11:57:42.821: INFO: 
Logging pods the kubelet thinks is on node k8s-3 before test
Apr 16 11:57:42.833: INFO: nginx-proxy-k8s-3 from kube-system started at <nil> (0 container statuses recorded)
Apr 16 11:57:42.833: INFO: kube-flannel-ct7gl from kube-system started at 2019-04-16 09:04:19 +0000 UTC (2 container statuses recorded)
Apr 16 11:57:42.833: INFO: 	Container install-cni ready: true, restart count 0
Apr 16 11:57:42.833: INFO: 	Container kube-flannel ready: true, restart count 0
Apr 16 11:57:42.833: INFO: coredns-644c686c9-bjmcw from kube-system started at 2019-04-16 09:04:41 +0000 UTC (1 container statuses recorded)
Apr 16 11:57:42.834: INFO: 	Container coredns ready: true, restart count 0
Apr 16 11:57:42.834: INFO: dns-autoscaler-586f58b8bf-rhxhm from kube-system started at 2019-04-16 09:04:43 +0000 UTC (1 container statuses recorded)
Apr 16 11:57:42.834: INFO: 	Container autoscaler ready: true, restart count 0
Apr 16 11:57:42.834: INFO: kubernetes-dashboard-8457c55f89-sqzmm from kube-system started at 2019-04-16 09:04:46 +0000 UTC (1 container statuses recorded)
Apr 16 11:57:42.834: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Apr 16 11:57:42.834: INFO: sonobuoy-e2e-job-112a3508806440e9 from heptio-sonobuoy started at 2019-04-16 11:31:01 +0000 UTC (2 container statuses recorded)
Apr 16 11:57:42.834: INFO: 	Container e2e ready: true, restart count 0
Apr 16 11:57:42.834: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 16 11:57:42.835: INFO: kube-proxy-7rzm9 from kube-system started at 2019-04-16 09:04:23 +0000 UTC (1 container statuses recorded)
Apr 16 11:57:42.835: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 16 11:57:42.835: INFO: sonobuoy from heptio-sonobuoy started at 2019-04-16 11:30:59 +0000 UTC (1 container statuses recorded)
Apr 16 11:57:42.835: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr 16 11:57:42.835: INFO: sonobuoy-systemd-logs-daemon-set-bd0902ee46574666-rcqwb from heptio-sonobuoy started at 2019-04-16 11:31:01 +0000 UTC (2 container statuses recorded)
Apr 16 11:57:42.836: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 16 11:57:42.836: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1595f27c81009ae4], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:57:43.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-ztbqp" for this suite.
Apr 16 11:57:49.917: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:57:49.963: INFO: namespace: e2e-tests-sched-pred-ztbqp, resource: bindings, ignored listing per whitelist
Apr 16 11:57:50.024: INFO: namespace e2e-tests-sched-pred-ztbqp deletion completed in 6.123368974s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.519 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:57:50.025: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Apr 16 11:57:50.126: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dba968a4-603e-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-projected-zvhk5" to be "success or failure"
Apr 16 11:57:50.131: INFO: Pod "downwardapi-volume-dba968a4-603e-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.89875ms
Apr 16 11:57:52.137: INFO: Pod "downwardapi-volume-dba968a4-603e-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010071872s
STEP: Saw pod success
Apr 16 11:57:52.137: INFO: Pod "downwardapi-volume-dba968a4-603e-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 11:57:52.141: INFO: Trying to get logs from node k8s-2 pod downwardapi-volume-dba968a4-603e-11e9-be7e-0a580ae9423f container client-container: <nil>
STEP: delete the pod
Apr 16 11:57:52.177: INFO: Waiting for pod downwardapi-volume-dba968a4-603e-11e9-be7e-0a580ae9423f to disappear
Apr 16 11:57:52.181: INFO: Pod downwardapi-volume-dba968a4-603e-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:57:52.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zvhk5" for this suite.
Apr 16 11:57:58.209: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:57:58.309: INFO: namespace: e2e-tests-projected-zvhk5, resource: bindings, ignored listing per whitelist
Apr 16 11:57:58.376: INFO: namespace e2e-tests-projected-zvhk5 deletion completed in 6.190556447s

• [SLOW TEST:8.352 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:57:58.378: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Apr 16 11:57:58.490: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e0a6e87f-603e-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-projected-bwjvf" to be "success or failure"
Apr 16 11:57:58.494: INFO: Pod "downwardapi-volume-e0a6e87f-603e-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.307224ms
Apr 16 11:58:00.499: INFO: Pod "downwardapi-volume-e0a6e87f-603e-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009839431s
STEP: Saw pod success
Apr 16 11:58:00.499: INFO: Pod "downwardapi-volume-e0a6e87f-603e-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 11:58:00.504: INFO: Trying to get logs from node k8s-3 pod downwardapi-volume-e0a6e87f-603e-11e9-be7e-0a580ae9423f container client-container: <nil>
STEP: delete the pod
Apr 16 11:58:00.534: INFO: Waiting for pod downwardapi-volume-e0a6e87f-603e-11e9-be7e-0a580ae9423f to disappear
Apr 16 11:58:00.539: INFO: Pod downwardapi-volume-e0a6e87f-603e-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 11:58:00.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bwjvf" for this suite.
Apr 16 11:58:06.564: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 11:58:06.825: INFO: namespace: e2e-tests-projected-bwjvf, resource: bindings, ignored listing per whitelist
Apr 16 11:58:06.838: INFO: namespace e2e-tests-projected-bwjvf deletion completed in 6.296581537s

• [SLOW TEST:8.461 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 11:58:06.841: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-wnxt9
Apr 16 11:58:15.125: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-wnxt9
STEP: checking the pod's current state and verifying that restartCount is present
Apr 16 11:58:15.130: INFO: Initial restart count of pod liveness-http is 0
Apr 16 11:58:35.318: INFO: Restart count of pod e2e-tests-container-probe-wnxt9/liveness-http is now 1 (20.186972574s elapsed)
Apr 16 11:58:53.617: INFO: Restart count of pod e2e-tests-container-probe-wnxt9/liveness-http is now 2 (38.486617317s elapsed)
Apr 16 11:59:13.704: INFO: Restart count of pod e2e-tests-container-probe-wnxt9/liveness-http is now 3 (58.573331113s elapsed)
Apr 16 11:59:33.785: INFO: Restart count of pod e2e-tests-container-probe-wnxt9/liveness-http is now 4 (1m18.65439029s elapsed)
Apr 16 12:00:42.046: INFO: Restart count of pod e2e-tests-container-probe-wnxt9/liveness-http is now 5 (2m26.91562353s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:00:42.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-wnxt9" for this suite.
Apr 16 12:00:48.101: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:00:48.128: INFO: namespace: e2e-tests-container-probe-wnxt9, resource: bindings, ignored listing per whitelist
Apr 16 12:00:48.213: INFO: namespace e2e-tests-container-probe-wnxt9 deletion completed in 6.13163055s

• [SLOW TEST:161.372 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:00:48.214: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Apr 16 12:00:52.370: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 16 12:00:52.373: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 16 12:00:54.373: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 16 12:00:54.378: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 16 12:00:56.374: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 16 12:00:56.386: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 16 12:00:58.373: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 16 12:00:58.380: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 16 12:01:00.374: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 16 12:01:00.380: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 16 12:01:02.373: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 16 12:01:02.378: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 16 12:01:04.374: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 16 12:01:04.378: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 16 12:01:06.374: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 16 12:01:06.380: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 16 12:01:08.374: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 16 12:01:08.384: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 16 12:01:10.373: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 16 12:01:10.379: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 16 12:01:12.373: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 16 12:01:12.380: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 16 12:01:14.373: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 16 12:01:14.378: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 16 12:01:16.373: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 16 12:01:16.378: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 16 12:01:18.374: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 16 12:01:18.378: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:01:18.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-wdkd4" for this suite.
Apr 16 12:01:40.420: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:01:40.462: INFO: namespace: e2e-tests-container-lifecycle-hook-wdkd4, resource: bindings, ignored listing per whitelist
Apr 16 12:01:40.520: INFO: namespace e2e-tests-container-lifecycle-hook-wdkd4 deletion completed in 22.122528241s

• [SLOW TEST:52.306 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:01:40.522: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Apr 16 12:01:40.600: INFO: Waiting up to 5m0s for pod "downwardapi-volume-650a7696-603f-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-downward-api-j28gc" to be "success or failure"
Apr 16 12:01:40.603: INFO: Pod "downwardapi-volume-650a7696-603f-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.175774ms
Apr 16 12:01:42.608: INFO: Pod "downwardapi-volume-650a7696-603f-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008366269s
STEP: Saw pod success
Apr 16 12:01:42.608: INFO: Pod "downwardapi-volume-650a7696-603f-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 12:01:42.612: INFO: Trying to get logs from node k8s-1 pod downwardapi-volume-650a7696-603f-11e9-be7e-0a580ae9423f container client-container: <nil>
STEP: delete the pod
Apr 16 12:01:42.647: INFO: Waiting for pod downwardapi-volume-650a7696-603f-11e9-be7e-0a580ae9423f to disappear
Apr 16 12:01:42.655: INFO: Pod downwardapi-volume-650a7696-603f-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:01:42.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-j28gc" for this suite.
Apr 16 12:01:48.680: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:01:48.739: INFO: namespace: e2e-tests-downward-api-j28gc, resource: bindings, ignored listing per whitelist
Apr 16 12:01:48.789: INFO: namespace e2e-tests-downward-api-j28gc deletion completed in 6.128408789s

• [SLOW TEST:8.267 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:01:48.789: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-w2th
STEP: Creating a pod to test atomic-volume-subpath
Apr 16 12:01:48.955: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-w2th" in namespace "e2e-tests-subpath-rrvwg" to be "success or failure"
Apr 16 12:01:48.961: INFO: Pod "pod-subpath-test-downwardapi-w2th": Phase="Pending", Reason="", readiness=false. Elapsed: 5.740957ms
Apr 16 12:01:50.973: INFO: Pod "pod-subpath-test-downwardapi-w2th": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018058745s
Apr 16 12:01:52.979: INFO: Pod "pod-subpath-test-downwardapi-w2th": Phase="Running", Reason="", readiness=false. Elapsed: 4.023503302s
Apr 16 12:01:54.984: INFO: Pod "pod-subpath-test-downwardapi-w2th": Phase="Running", Reason="", readiness=false. Elapsed: 6.028722221s
Apr 16 12:01:56.990: INFO: Pod "pod-subpath-test-downwardapi-w2th": Phase="Running", Reason="", readiness=false. Elapsed: 8.034215734s
Apr 16 12:01:58.995: INFO: Pod "pod-subpath-test-downwardapi-w2th": Phase="Running", Reason="", readiness=false. Elapsed: 10.039769968s
Apr 16 12:02:01.009: INFO: Pod "pod-subpath-test-downwardapi-w2th": Phase="Running", Reason="", readiness=false. Elapsed: 12.053466952s
Apr 16 12:02:03.014: INFO: Pod "pod-subpath-test-downwardapi-w2th": Phase="Running", Reason="", readiness=false. Elapsed: 14.058293461s
Apr 16 12:02:05.019: INFO: Pod "pod-subpath-test-downwardapi-w2th": Phase="Running", Reason="", readiness=false. Elapsed: 16.063979149s
Apr 16 12:02:07.024: INFO: Pod "pod-subpath-test-downwardapi-w2th": Phase="Running", Reason="", readiness=false. Elapsed: 18.069056795s
Apr 16 12:02:09.029: INFO: Pod "pod-subpath-test-downwardapi-w2th": Phase="Running", Reason="", readiness=false. Elapsed: 20.074062035s
Apr 16 12:02:11.043: INFO: Pod "pod-subpath-test-downwardapi-w2th": Phase="Running", Reason="", readiness=false. Elapsed: 22.087507602s
Apr 16 12:02:13.048: INFO: Pod "pod-subpath-test-downwardapi-w2th": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.092355449s
STEP: Saw pod success
Apr 16 12:02:13.048: INFO: Pod "pod-subpath-test-downwardapi-w2th" satisfied condition "success or failure"
Apr 16 12:02:13.052: INFO: Trying to get logs from node k8s-2 pod pod-subpath-test-downwardapi-w2th container test-container-subpath-downwardapi-w2th: <nil>
STEP: delete the pod
Apr 16 12:02:13.083: INFO: Waiting for pod pod-subpath-test-downwardapi-w2th to disappear
Apr 16 12:02:13.091: INFO: Pod pod-subpath-test-downwardapi-w2th no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-w2th
Apr 16 12:02:13.091: INFO: Deleting pod "pod-subpath-test-downwardapi-w2th" in namespace "e2e-tests-subpath-rrvwg"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:02:13.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-rrvwg" for this suite.
Apr 16 12:02:19.115: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:02:19.185: INFO: namespace: e2e-tests-subpath-rrvwg, resource: bindings, ignored listing per whitelist
Apr 16 12:02:19.237: INFO: namespace e2e-tests-subpath-rrvwg deletion completed in 6.13789769s

• [SLOW TEST:30.448 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:02:19.237: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0416 12:02:20.377958      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr 16 12:02:20.378: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:02:20.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-rh77h" for this suite.
Apr 16 12:02:26.399: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:02:26.419: INFO: namespace: e2e-tests-gc-rh77h, resource: bindings, ignored listing per whitelist
Apr 16 12:02:26.507: INFO: namespace e2e-tests-gc-rh77h deletion completed in 6.126169674s

• [SLOW TEST:7.270 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:02:26.509: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-8073b2d0-603f-11e9-be7e-0a580ae9423f
STEP: Creating a pod to test consume secrets
Apr 16 12:02:26.634: INFO: Waiting up to 5m0s for pod "pod-secrets-807ada5d-603f-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-secrets-79fwt" to be "success or failure"
Apr 16 12:02:26.638: INFO: Pod "pod-secrets-807ada5d-603f-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.378128ms
Apr 16 12:02:28.644: INFO: Pod "pod-secrets-807ada5d-603f-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009701312s
STEP: Saw pod success
Apr 16 12:02:28.644: INFO: Pod "pod-secrets-807ada5d-603f-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 12:02:28.648: INFO: Trying to get logs from node k8s-2 pod pod-secrets-807ada5d-603f-11e9-be7e-0a580ae9423f container secret-volume-test: <nil>
STEP: delete the pod
Apr 16 12:02:28.687: INFO: Waiting for pod pod-secrets-807ada5d-603f-11e9-be7e-0a580ae9423f to disappear
Apr 16 12:02:28.691: INFO: Pod pod-secrets-807ada5d-603f-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:02:28.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-79fwt" for this suite.
Apr 16 12:02:34.717: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:02:34.757: INFO: namespace: e2e-tests-secrets-79fwt, resource: bindings, ignored listing per whitelist
Apr 16 12:02:34.815: INFO: namespace e2e-tests-secrets-79fwt deletion completed in 6.119298891s
STEP: Destroying namespace "e2e-tests-secret-namespace-4w698" for this suite.
Apr 16 12:02:40.831: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:02:40.911: INFO: namespace: e2e-tests-secret-namespace-4w698, resource: bindings, ignored listing per whitelist
Apr 16 12:02:40.935: INFO: namespace e2e-tests-secret-namespace-4w698 deletion completed in 6.119572864s

• [SLOW TEST:14.427 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:02:40.937: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Apr 16 12:02:41.024: INFO: Waiting up to 5m0s for pod "pod-890e4037-603f-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-emptydir-269mn" to be "success or failure"
Apr 16 12:02:41.029: INFO: Pod "pod-890e4037-603f-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.519898ms
Apr 16 12:02:43.041: INFO: Pod "pod-890e4037-603f-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016862912s
STEP: Saw pod success
Apr 16 12:02:43.042: INFO: Pod "pod-890e4037-603f-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 12:02:43.047: INFO: Trying to get logs from node k8s-3 pod pod-890e4037-603f-11e9-be7e-0a580ae9423f container test-container: <nil>
STEP: delete the pod
Apr 16 12:02:43.079: INFO: Waiting for pod pod-890e4037-603f-11e9-be7e-0a580ae9423f to disappear
Apr 16 12:02:43.082: INFO: Pod pod-890e4037-603f-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:02:43.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-269mn" for this suite.
Apr 16 12:02:49.102: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:02:49.140: INFO: namespace: e2e-tests-emptydir-269mn, resource: bindings, ignored listing per whitelist
Apr 16 12:02:49.233: INFO: namespace e2e-tests-emptydir-269mn deletion completed in 6.148131673s

• [SLOW TEST:8.297 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:02:49.235: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 16 12:02:49.316: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-xq4dx'
Apr 16 12:02:49.413: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr 16 12:02:49.413: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Apr 16 12:02:49.424: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-bhhtj]
Apr 16 12:02:49.424: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-bhhtj" in namespace "e2e-tests-kubectl-xq4dx" to be "running and ready"
Apr 16 12:02:49.428: INFO: Pod "e2e-test-nginx-rc-bhhtj": Phase="Pending", Reason="", readiness=false. Elapsed: 3.993114ms
Apr 16 12:02:51.434: INFO: Pod "e2e-test-nginx-rc-bhhtj": Phase="Running", Reason="", readiness=true. Elapsed: 2.009424803s
Apr 16 12:02:51.434: INFO: Pod "e2e-test-nginx-rc-bhhtj" satisfied condition "running and ready"
Apr 16 12:02:51.434: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-bhhtj]
Apr 16 12:02:51.434: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-xq4dx'
Apr 16 12:02:51.529: INFO: stderr: ""
Apr 16 12:02:51.529: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1303
Apr 16 12:02:51.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-xq4dx'
Apr 16 12:02:51.617: INFO: stderr: ""
Apr 16 12:02:51.618: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:02:51.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xq4dx" for this suite.
Apr 16 12:03:13.641: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:03:13.735: INFO: namespace: e2e-tests-kubectl-xq4dx, resource: bindings, ignored listing per whitelist
Apr 16 12:03:13.735: INFO: namespace e2e-tests-kubectl-xq4dx deletion completed in 22.109649827s

• [SLOW TEST:24.500 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:03:13.736: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Apr 16 12:03:13.835: INFO: Number of nodes with available pods: 0
Apr 16 12:03:13.835: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:03:14.844: INFO: Number of nodes with available pods: 0
Apr 16 12:03:14.844: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:03:15.850: INFO: Number of nodes with available pods: 3
Apr 16 12:03:15.851: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Apr 16 12:03:15.876: INFO: Number of nodes with available pods: 2
Apr 16 12:03:15.876: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:03:16.887: INFO: Number of nodes with available pods: 2
Apr 16 12:03:16.887: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:03:17.887: INFO: Number of nodes with available pods: 2
Apr 16 12:03:17.887: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:03:18.888: INFO: Number of nodes with available pods: 2
Apr 16 12:03:18.888: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:03:19.892: INFO: Number of nodes with available pods: 2
Apr 16 12:03:19.892: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:03:20.887: INFO: Number of nodes with available pods: 2
Apr 16 12:03:20.887: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:03:21.885: INFO: Number of nodes with available pods: 2
Apr 16 12:03:21.885: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:03:22.888: INFO: Number of nodes with available pods: 2
Apr 16 12:03:22.888: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:03:23.888: INFO: Number of nodes with available pods: 2
Apr 16 12:03:23.888: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:03:24.893: INFO: Number of nodes with available pods: 2
Apr 16 12:03:24.893: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:03:25.892: INFO: Number of nodes with available pods: 2
Apr 16 12:03:25.892: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:03:26.886: INFO: Number of nodes with available pods: 2
Apr 16 12:03:26.886: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:03:27.888: INFO: Number of nodes with available pods: 2
Apr 16 12:03:27.888: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:03:28.889: INFO: Number of nodes with available pods: 2
Apr 16 12:03:28.889: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:03:29.889: INFO: Number of nodes with available pods: 2
Apr 16 12:03:29.890: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:03:30.885: INFO: Number of nodes with available pods: 2
Apr 16 12:03:30.886: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:03:31.894: INFO: Number of nodes with available pods: 2
Apr 16 12:03:31.894: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:03:32.887: INFO: Number of nodes with available pods: 2
Apr 16 12:03:32.887: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:03:33.886: INFO: Number of nodes with available pods: 2
Apr 16 12:03:33.886: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:03:34.886: INFO: Number of nodes with available pods: 2
Apr 16 12:03:34.886: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:03:35.888: INFO: Number of nodes with available pods: 2
Apr 16 12:03:35.888: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:03:36.899: INFO: Number of nodes with available pods: 2
Apr 16 12:03:36.899: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:03:37.894: INFO: Number of nodes with available pods: 2
Apr 16 12:03:37.894: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:03:38.889: INFO: Number of nodes with available pods: 2
Apr 16 12:03:38.889: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:03:39.887: INFO: Number of nodes with available pods: 2
Apr 16 12:03:39.888: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:03:40.886: INFO: Number of nodes with available pods: 2
Apr 16 12:03:40.886: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:03:41.890: INFO: Number of nodes with available pods: 2
Apr 16 12:03:41.890: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:03:42.886: INFO: Number of nodes with available pods: 2
Apr 16 12:03:42.886: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:03:43.885: INFO: Number of nodes with available pods: 2
Apr 16 12:03:43.885: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:03:44.888: INFO: Number of nodes with available pods: 2
Apr 16 12:03:44.888: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:03:45.887: INFO: Number of nodes with available pods: 2
Apr 16 12:03:45.887: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:03:46.885: INFO: Number of nodes with available pods: 2
Apr 16 12:03:46.885: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:03:47.899: INFO: Number of nodes with available pods: 2
Apr 16 12:03:47.899: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:03:48.887: INFO: Number of nodes with available pods: 2
Apr 16 12:03:48.887: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:03:49.885: INFO: Number of nodes with available pods: 2
Apr 16 12:03:49.885: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:03:50.887: INFO: Number of nodes with available pods: 2
Apr 16 12:03:50.887: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:03:51.884: INFO: Number of nodes with available pods: 2
Apr 16 12:03:51.884: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:03:52.884: INFO: Number of nodes with available pods: 2
Apr 16 12:03:52.884: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:03:53.886: INFO: Number of nodes with available pods: 2
Apr 16 12:03:53.886: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:03:54.886: INFO: Number of nodes with available pods: 2
Apr 16 12:03:54.887: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:03:55.885: INFO: Number of nodes with available pods: 2
Apr 16 12:03:55.885: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:03:56.885: INFO: Number of nodes with available pods: 2
Apr 16 12:03:56.885: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:03:57.885: INFO: Number of nodes with available pods: 2
Apr 16 12:03:57.886: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:03:58.891: INFO: Number of nodes with available pods: 2
Apr 16 12:03:58.892: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:03:59.907: INFO: Number of nodes with available pods: 2
Apr 16 12:03:59.907: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:04:00.888: INFO: Number of nodes with available pods: 2
Apr 16 12:04:00.889: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:04:01.890: INFO: Number of nodes with available pods: 3
Apr 16 12:04:01.890: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-h67zf, will wait for the garbage collector to delete the pods
Apr 16 12:04:01.963: INFO: Deleting DaemonSet.extensions daemon-set took: 9.158998ms
Apr 16 12:04:02.064: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.38002ms
Apr 16 12:04:35.674: INFO: Number of nodes with available pods: 0
Apr 16 12:04:35.674: INFO: Number of running nodes: 0, number of available pods: 0
Apr 16 12:04:35.677: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-h67zf/daemonsets","resourceVersion":"21342"},"items":null}

Apr 16 12:04:35.680: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-h67zf/pods","resourceVersion":"21342"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:04:35.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-h67zf" for this suite.
Apr 16 12:04:41.713: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:04:41.772: INFO: namespace: e2e-tests-daemonsets-h67zf, resource: bindings, ignored listing per whitelist
Apr 16 12:04:41.824: INFO: namespace e2e-tests-daemonsets-h67zf deletion completed in 6.127961773s

• [SLOW TEST:88.088 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:04:41.825: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Apr 16 12:04:42.413: INFO: Waiting up to 5m0s for pod "pod-service-account-d168750d-603f-11e9-be7e-0a580ae9423f-dqfzq" in namespace "e2e-tests-svcaccounts-jkvb2" to be "success or failure"
Apr 16 12:04:42.434: INFO: Pod "pod-service-account-d168750d-603f-11e9-be7e-0a580ae9423f-dqfzq": Phase="Pending", Reason="", readiness=false. Elapsed: 20.264311ms
Apr 16 12:04:44.441: INFO: Pod "pod-service-account-d168750d-603f-11e9-be7e-0a580ae9423f-dqfzq": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027661322s
STEP: Saw pod success
Apr 16 12:04:44.441: INFO: Pod "pod-service-account-d168750d-603f-11e9-be7e-0a580ae9423f-dqfzq" satisfied condition "success or failure"
Apr 16 12:04:44.446: INFO: Trying to get logs from node k8s-2 pod pod-service-account-d168750d-603f-11e9-be7e-0a580ae9423f-dqfzq container token-test: <nil>
STEP: delete the pod
Apr 16 12:04:44.513: INFO: Waiting for pod pod-service-account-d168750d-603f-11e9-be7e-0a580ae9423f-dqfzq to disappear
Apr 16 12:04:44.524: INFO: Pod pod-service-account-d168750d-603f-11e9-be7e-0a580ae9423f-dqfzq no longer exists
STEP: Creating a pod to test consume service account root CA
Apr 16 12:04:44.531: INFO: Waiting up to 5m0s for pod "pod-service-account-d168750d-603f-11e9-be7e-0a580ae9423f-wq5sk" in namespace "e2e-tests-svcaccounts-jkvb2" to be "success or failure"
Apr 16 12:04:44.541: INFO: Pod "pod-service-account-d168750d-603f-11e9-be7e-0a580ae9423f-wq5sk": Phase="Pending", Reason="", readiness=false. Elapsed: 10.057109ms
Apr 16 12:04:46.556: INFO: Pod "pod-service-account-d168750d-603f-11e9-be7e-0a580ae9423f-wq5sk": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024221434s
Apr 16 12:04:48.562: INFO: Pod "pod-service-account-d168750d-603f-11e9-be7e-0a580ae9423f-wq5sk": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030465324s
STEP: Saw pod success
Apr 16 12:04:48.562: INFO: Pod "pod-service-account-d168750d-603f-11e9-be7e-0a580ae9423f-wq5sk" satisfied condition "success or failure"
Apr 16 12:04:48.566: INFO: Trying to get logs from node k8s-3 pod pod-service-account-d168750d-603f-11e9-be7e-0a580ae9423f-wq5sk container root-ca-test: <nil>
STEP: delete the pod
Apr 16 12:04:48.595: INFO: Waiting for pod pod-service-account-d168750d-603f-11e9-be7e-0a580ae9423f-wq5sk to disappear
Apr 16 12:04:48.598: INFO: Pod pod-service-account-d168750d-603f-11e9-be7e-0a580ae9423f-wq5sk no longer exists
STEP: Creating a pod to test consume service account namespace
Apr 16 12:04:48.607: INFO: Waiting up to 5m0s for pod "pod-service-account-d168750d-603f-11e9-be7e-0a580ae9423f-g4pld" in namespace "e2e-tests-svcaccounts-jkvb2" to be "success or failure"
Apr 16 12:04:48.620: INFO: Pod "pod-service-account-d168750d-603f-11e9-be7e-0a580ae9423f-g4pld": Phase="Pending", Reason="", readiness=false. Elapsed: 12.674621ms
Apr 16 12:04:50.625: INFO: Pod "pod-service-account-d168750d-603f-11e9-be7e-0a580ae9423f-g4pld": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018062512s
Apr 16 12:04:52.630: INFO: Pod "pod-service-account-d168750d-603f-11e9-be7e-0a580ae9423f-g4pld": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023581967s
STEP: Saw pod success
Apr 16 12:04:52.631: INFO: Pod "pod-service-account-d168750d-603f-11e9-be7e-0a580ae9423f-g4pld" satisfied condition "success or failure"
Apr 16 12:04:52.635: INFO: Trying to get logs from node k8s-1 pod pod-service-account-d168750d-603f-11e9-be7e-0a580ae9423f-g4pld container namespace-test: <nil>
STEP: delete the pod
Apr 16 12:04:52.669: INFO: Waiting for pod pod-service-account-d168750d-603f-11e9-be7e-0a580ae9423f-g4pld to disappear
Apr 16 12:04:52.681: INFO: Pod pod-service-account-d168750d-603f-11e9-be7e-0a580ae9423f-g4pld no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:04:52.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-jkvb2" for this suite.
Apr 16 12:04:58.701: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:04:58.752: INFO: namespace: e2e-tests-svcaccounts-jkvb2, resource: bindings, ignored listing per whitelist
Apr 16 12:04:58.803: INFO: namespace e2e-tests-svcaccounts-jkvb2 deletion completed in 6.118242242s

• [SLOW TEST:16.977 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:04:58.803: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-xsq62
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 16 12:04:58.875: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr 16 12:05:21.055: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.65.80:8080/dial?request=hostName&protocol=http&host=10.233.64.94&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-xsq62 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 16 12:05:21.055: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
Apr 16 12:05:21.142: INFO: Waiting for endpoints: map[]
Apr 16 12:05:21.148: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.65.80:8080/dial?request=hostName&protocol=http&host=10.233.66.104&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-xsq62 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 16 12:05:21.148: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
Apr 16 12:05:21.239: INFO: Waiting for endpoints: map[]
Apr 16 12:05:21.245: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.65.80:8080/dial?request=hostName&protocol=http&host=10.233.65.79&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-xsq62 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 16 12:05:21.245: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
Apr 16 12:05:21.334: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:05:21.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-xsq62" for this suite.
Apr 16 12:05:43.380: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:05:43.461: INFO: namespace: e2e-tests-pod-network-test-xsq62, resource: bindings, ignored listing per whitelist
Apr 16 12:05:43.642: INFO: namespace e2e-tests-pod-network-test-xsq62 deletion completed in 22.300631092s

• [SLOW TEST:44.839 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:05:43.644: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Apr 16 12:05:43.706: INFO: Creating deployment "nginx-deployment"
Apr 16 12:05:43.714: INFO: Waiting for observed generation 1
Apr 16 12:05:45.723: INFO: Waiting for all required pods to come up
Apr 16 12:05:45.728: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Apr 16 12:05:49.767: INFO: Waiting for deployment "nginx-deployment" to complete
Apr 16 12:05:49.773: INFO: Updating deployment "nginx-deployment" with a non-existent image
Apr 16 12:05:49.785: INFO: Updating deployment nginx-deployment
Apr 16 12:05:49.785: INFO: Waiting for observed generation 2
Apr 16 12:05:51.798: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Apr 16 12:05:51.801: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Apr 16 12:05:51.804: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Apr 16 12:05:51.812: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Apr 16 12:05:51.812: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Apr 16 12:05:51.816: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Apr 16 12:05:51.824: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Apr 16 12:05:51.824: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Apr 16 12:05:51.839: INFO: Updating deployment nginx-deployment
Apr 16 12:05:51.840: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Apr 16 12:05:51.847: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Apr 16 12:05:53.857: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr 16 12:05:53.865: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-2xwj5,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-2xwj5/deployments/nginx-deployment,UID:f5f34126-603f-11e9-8569-0800277031c6,ResourceVersion:21913,Generation:3,CreationTimestamp:2019-04-16 12:05:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-04-16 12:05:51 +0000 UTC 2019-04-16 12:05:51 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-04-16 12:05:52 +0000 UTC 2019-04-16 12:05:43 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-65bbdb5f8" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Apr 16 12:05:53.871: INFO: New ReplicaSet "nginx-deployment-65bbdb5f8" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8,GenerateName:,Namespace:e2e-tests-deployment-2xwj5,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-2xwj5/replicasets/nginx-deployment-65bbdb5f8,UID:f991a81f-603f-11e9-8978-0800277031c6,ResourceVersion:21910,Generation:3,CreationTimestamp:2019-04-16 12:05:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment f5f34126-603f-11e9-8569-0800277031c6 0xc0012967b7 0xc0012967b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr 16 12:05:53.871: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Apr 16 12:05:53.873: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965,GenerateName:,Namespace:e2e-tests-deployment-2xwj5,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-2xwj5/replicasets/nginx-deployment-555b55d965,UID:f5f4f392-603f-11e9-8978-0800277031c6,ResourceVersion:21897,Generation:3,CreationTimestamp:2019-04-16 12:05:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment f5f34126-603f-11e9-8569-0800277031c6 0xc001296667 0xc001296668}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Apr 16 12:05:53.884: INFO: Pod "nginx-deployment-555b55d965-2ctzz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-2ctzz,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-2xwj5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2xwj5/pods/nginx-deployment-555b55d965-2ctzz,UID:fad8526f-603f-11e9-8978-0800277031c6,ResourceVersion:21964,Generation:0,CreationTimestamp:2019-04-16 12:05:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f5f4f392-603f-11e9-8978-0800277031c6 0xc0012972c7 0xc0012972c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-25jwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-25jwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-25jwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001297340} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001297360}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:52 +0000 UTC  }],Message:,Reason:,HostIP:172.17.8.103,PodIP:,StartTime:2019-04-16 12:05:52 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 16 12:05:53.885: INFO: Pod "nginx-deployment-555b55d965-2qwrq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-2qwrq,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-2xwj5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2xwj5/pods/nginx-deployment-555b55d965-2qwrq,UID:face8fe1-603f-11e9-8978-0800277031c6,ResourceVersion:21886,Generation:0,CreationTimestamp:2019-04-16 12:05:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f5f4f392-603f-11e9-8978-0800277031c6 0xc001297417 0xc001297418}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-25jwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-25jwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-25jwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001297490} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0012974b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:51 +0000 UTC  }],Message:,Reason:,HostIP:172.17.8.103,PodIP:,StartTime:2019-04-16 12:05:51 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 16 12:05:53.885: INFO: Pod "nginx-deployment-555b55d965-7wlxz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-7wlxz,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-2xwj5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2xwj5/pods/nginx-deployment-555b55d965-7wlxz,UID:face7f08-603f-11e9-8978-0800277031c6,ResourceVersion:21894,Generation:0,CreationTimestamp:2019-04-16 12:05:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f5f4f392-603f-11e9-8978-0800277031c6 0xc001297597 0xc001297598}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-25jwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-25jwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-25jwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001297610} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001297630}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:51 +0000 UTC  }],Message:,Reason:,HostIP:172.17.8.102,PodIP:,StartTime:2019-04-16 12:05:51 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 16 12:05:53.886: INFO: Pod "nginx-deployment-555b55d965-bbhws" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-bbhws,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-2xwj5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2xwj5/pods/nginx-deployment-555b55d965-bbhws,UID:fad193f5-603f-11e9-8978-0800277031c6,ResourceVersion:21903,Generation:0,CreationTimestamp:2019-04-16 12:05:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f5f4f392-603f-11e9-8978-0800277031c6 0xc0012976e7 0xc0012976e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-25jwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-25jwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-25jwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001297760} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001297780}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:51 +0000 UTC  }],Message:,Reason:,HostIP:172.17.8.101,PodIP:,StartTime:2019-04-16 12:05:51 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 16 12:05:53.886: INFO: Pod "nginx-deployment-555b55d965-bl5xb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-bl5xb,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-2xwj5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2xwj5/pods/nginx-deployment-555b55d965-bl5xb,UID:fad1805b-603f-11e9-8978-0800277031c6,ResourceVersion:21884,Generation:0,CreationTimestamp:2019-04-16 12:05:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f5f4f392-603f-11e9-8978-0800277031c6 0xc001297837 0xc001297838}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-25jwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-25jwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-25jwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0012978b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0012978d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:51 +0000 UTC  }],Message:,Reason:,HostIP:172.17.8.101,PodIP:,StartTime:2019-04-16 12:05:51 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 16 12:05:53.886: INFO: Pod "nginx-deployment-555b55d965-bsxxm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-bsxxm,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-2xwj5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2xwj5/pods/nginx-deployment-555b55d965-bsxxm,UID:fad856dc-603f-11e9-8978-0800277031c6,ResourceVersion:21925,Generation:0,CreationTimestamp:2019-04-16 12:05:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f5f4f392-603f-11e9-8978-0800277031c6 0xc001297987 0xc001297988}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-25jwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-25jwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-25jwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001297a00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001297a20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:52 +0000 UTC  }],Message:,Reason:,HostIP:172.17.8.102,PodIP:,StartTime:2019-04-16 12:05:52 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 16 12:05:53.886: INFO: Pod "nginx-deployment-555b55d965-dfqv4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-dfqv4,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-2xwj5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2xwj5/pods/nginx-deployment-555b55d965-dfqv4,UID:facc747c-603f-11e9-8978-0800277031c6,ResourceVersion:21863,Generation:0,CreationTimestamp:2019-04-16 12:05:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f5f4f392-603f-11e9-8978-0800277031c6 0xc001297ad7 0xc001297ad8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-25jwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-25jwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-25jwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001297b50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001297b70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:51 +0000 UTC  }],Message:,Reason:,HostIP:172.17.8.101,PodIP:,StartTime:2019-04-16 12:05:51 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 16 12:05:53.886: INFO: Pod "nginx-deployment-555b55d965-f7hfs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-f7hfs,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-2xwj5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2xwj5/pods/nginx-deployment-555b55d965-f7hfs,UID:fad19870-603f-11e9-8978-0800277031c6,ResourceVersion:21914,Generation:0,CreationTimestamp:2019-04-16 12:05:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f5f4f392-603f-11e9-8978-0800277031c6 0xc001297c27 0xc001297c28}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-25jwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-25jwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-25jwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001297ca0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001297cc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:51 +0000 UTC  }],Message:,Reason:,HostIP:172.17.8.102,PodIP:,StartTime:2019-04-16 12:05:51 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 16 12:05:53.886: INFO: Pod "nginx-deployment-555b55d965-g4mcj" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-g4mcj,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-2xwj5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2xwj5/pods/nginx-deployment-555b55d965-g4mcj,UID:f605dfe8-603f-11e9-8978-0800277031c6,ResourceVersion:21746,Generation:0,CreationTimestamp:2019-04-16 12:05:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f5f4f392-603f-11e9-8978-0800277031c6 0xc001297d77 0xc001297d78}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-25jwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-25jwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-25jwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001297df0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001297e10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:43 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:46 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:46 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:43 +0000 UTC  }],Message:,Reason:,HostIP:172.17.8.103,PodIP:10.233.66.107,StartTime:2019-04-16 12:05:43 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-16 12:05:45 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://81ad16485ae980a55bdf3664625695b2e5abfbff8e64a1c2f1c19e59dfbabdfa}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 16 12:05:53.887: INFO: Pod "nginx-deployment-555b55d965-gp5vq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-gp5vq,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-2xwj5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2xwj5/pods/nginx-deployment-555b55d965-gp5vq,UID:fad847f3-603f-11e9-8978-0800277031c6,ResourceVersion:21918,Generation:0,CreationTimestamp:2019-04-16 12:05:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f5f4f392-603f-11e9-8978-0800277031c6 0xc001297ed7 0xc001297ed8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-25jwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-25jwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-25jwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001297f50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001297f70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:51 +0000 UTC  }],Message:,Reason:,HostIP:172.17.8.102,PodIP:,StartTime:2019-04-16 12:05:52 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 16 12:05:53.887: INFO: Pod "nginx-deployment-555b55d965-hpz2x" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-hpz2x,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-2xwj5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2xwj5/pods/nginx-deployment-555b55d965-hpz2x,UID:f6061d4b-603f-11e9-8978-0800277031c6,ResourceVersion:21771,Generation:0,CreationTimestamp:2019-04-16 12:05:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f5f4f392-603f-11e9-8978-0800277031c6 0xc002c480b7 0xc002c480b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-25jwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-25jwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-25jwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c48130} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c48150}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:43 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:47 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:47 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:43 +0000 UTC  }],Message:,Reason:,HostIP:172.17.8.101,PodIP:10.233.64.96,StartTime:2019-04-16 12:05:43 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-16 12:05:46 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://9114bf67074ea1447862f7a1a198e13ef1816df97c8372cce4ef7fc85e015e49}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 16 12:05:53.887: INFO: Pod "nginx-deployment-555b55d965-j46qq" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-j46qq,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-2xwj5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2xwj5/pods/nginx-deployment-555b55d965-j46qq,UID:f60617b1-603f-11e9-8978-0800277031c6,ResourceVersion:21751,Generation:0,CreationTimestamp:2019-04-16 12:05:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f5f4f392-603f-11e9-8978-0800277031c6 0xc002c48217 0xc002c48218}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-25jwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-25jwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-25jwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c483e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c48400}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:43 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:46 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:46 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:43 +0000 UTC  }],Message:,Reason:,HostIP:172.17.8.102,PodIP:10.233.65.83,StartTime:2019-04-16 12:05:43 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-16 12:05:45 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://a31e49650661771c9d31c456a0b3c4f45fa6c10c5097174550c85285732382e5}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 16 12:05:53.887: INFO: Pod "nginx-deployment-555b55d965-k8fr6" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-k8fr6,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-2xwj5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2xwj5/pods/nginx-deployment-555b55d965-k8fr6,UID:f5fa7848-603f-11e9-8978-0800277031c6,ResourceVersion:21754,Generation:0,CreationTimestamp:2019-04-16 12:05:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f5f4f392-603f-11e9-8978-0800277031c6 0xc002c48547 0xc002c48548}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-25jwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-25jwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-25jwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c487d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c487f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:43 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:46 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:46 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:43 +0000 UTC  }],Message:,Reason:,HostIP:172.17.8.103,PodIP:10.233.66.105,StartTime:2019-04-16 12:05:43 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-16 12:05:45 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://384b7d6250876783fbd7f71e6bca32650124f2afa3f527d6742748055b5eadd3}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 16 12:05:53.887: INFO: Pod "nginx-deployment-555b55d965-mhxm8" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-mhxm8,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-2xwj5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2xwj5/pods/nginx-deployment-555b55d965-mhxm8,UID:f5fcecae-603f-11e9-8978-0800277031c6,ResourceVersion:21749,Generation:0,CreationTimestamp:2019-04-16 12:05:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f5f4f392-603f-11e9-8978-0800277031c6 0xc002c48927 0xc002c48928}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-25jwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-25jwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-25jwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c48b70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c48b90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:43 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:46 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:46 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:43 +0000 UTC  }],Message:,Reason:,HostIP:172.17.8.103,PodIP:10.233.66.106,StartTime:2019-04-16 12:05:43 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-16 12:05:45 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://9665c7afb439d538e67eaf8ad2207278066c39d0cbb4d70112b363700d4c2e8a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 16 12:05:53.889: INFO: Pod "nginx-deployment-555b55d965-psv5n" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-psv5n,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-2xwj5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2xwj5/pods/nginx-deployment-555b55d965-psv5n,UID:fad85b54-603f-11e9-8978-0800277031c6,ResourceVersion:21959,Generation:0,CreationTimestamp:2019-04-16 12:05:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f5f4f392-603f-11e9-8978-0800277031c6 0xc002c48c57 0xc002c48c58}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-25jwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-25jwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-25jwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c48d80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c48e80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:51 +0000 UTC  }],Message:,Reason:,HostIP:172.17.8.103,PodIP:,StartTime:2019-04-16 12:05:52 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 16 12:05:53.889: INFO: Pod "nginx-deployment-555b55d965-sjqqh" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-sjqqh,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-2xwj5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2xwj5/pods/nginx-deployment-555b55d965-sjqqh,UID:f5fa8f0c-603f-11e9-8978-0800277031c6,ResourceVersion:21757,Generation:0,CreationTimestamp:2019-04-16 12:05:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f5f4f392-603f-11e9-8978-0800277031c6 0xc002c48fa7 0xc002c48fa8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-25jwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-25jwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-25jwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c49020} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c49040}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:43 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:46 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:46 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:43 +0000 UTC  }],Message:,Reason:,HostIP:172.17.8.102,PodIP:10.233.65.82,StartTime:2019-04-16 12:05:43 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-16 12:05:45 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://511d693926c640f05aa8f2ef039dc3356fe6eee24f00a07142ce684fb56fbc24}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 16 12:05:53.890: INFO: Pod "nginx-deployment-555b55d965-thlvp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-thlvp,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-2xwj5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2xwj5/pods/nginx-deployment-555b55d965-thlvp,UID:fad18eab-603f-11e9-8978-0800277031c6,ResourceVersion:21915,Generation:0,CreationTimestamp:2019-04-16 12:05:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f5f4f392-603f-11e9-8978-0800277031c6 0xc002c49247 0xc002c49248}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-25jwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-25jwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-25jwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c492c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c492e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:51 +0000 UTC  }],Message:,Reason:,HostIP:172.17.8.103,PodIP:,StartTime:2019-04-16 12:05:52 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 16 12:05:53.890: INFO: Pod "nginx-deployment-555b55d965-wkhg6" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-wkhg6,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-2xwj5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2xwj5/pods/nginx-deployment-555b55d965-wkhg6,UID:f5f98e0d-603f-11e9-8978-0800277031c6,ResourceVersion:21768,Generation:0,CreationTimestamp:2019-04-16 12:05:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f5f4f392-603f-11e9-8978-0800277031c6 0xc002c494d7 0xc002c494d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-25jwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-25jwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-25jwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c49550} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c496b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:43 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:47 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:47 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:43 +0000 UTC  }],Message:,Reason:,HostIP:172.17.8.101,PodIP:10.233.64.97,StartTime:2019-04-16 12:05:43 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-16 12:05:47 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://4f4c00e0d99bc3ed0606a3defc432b38a6bed226530f12932bb526bd20049d71}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 16 12:05:53.890: INFO: Pod "nginx-deployment-555b55d965-wrcsf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-wrcsf,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-2xwj5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2xwj5/pods/nginx-deployment-555b55d965-wrcsf,UID:fad84ddc-603f-11e9-8978-0800277031c6,ResourceVersion:21920,Generation:0,CreationTimestamp:2019-04-16 12:05:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f5f4f392-603f-11e9-8978-0800277031c6 0xc002c497c7 0xc002c497c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-25jwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-25jwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-25jwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c49980} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c499a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:51 +0000 UTC  }],Message:,Reason:,HostIP:172.17.8.101,PodIP:,StartTime:2019-04-16 12:05:52 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 16 12:05:53.890: INFO: Pod "nginx-deployment-555b55d965-xzptf" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-xzptf,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-2xwj5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2xwj5/pods/nginx-deployment-555b55d965-xzptf,UID:f5fccc4a-603f-11e9-8978-0800277031c6,ResourceVersion:21760,Generation:0,CreationTimestamp:2019-04-16 12:05:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f5f4f392-603f-11e9-8978-0800277031c6 0xc002c49a57 0xc002c49a58}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-25jwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-25jwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-25jwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c49c20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c49c40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:43 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:46 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:46 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:43 +0000 UTC  }],Message:,Reason:,HostIP:172.17.8.102,PodIP:10.233.65.81,StartTime:2019-04-16 12:05:43 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-16 12:05:45 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://a900f341040fecac862a96ceff2e05d7224e4bd1e0458c57dfca2b07d7d238d4}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 16 12:05:53.890: INFO: Pod "nginx-deployment-65bbdb5f8-2mscw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-2mscw,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-2xwj5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2xwj5/pods/nginx-deployment-65bbdb5f8-2mscw,UID:fad85fad-603f-11e9-8978-0800277031c6,ResourceVersion:21921,Generation:0,CreationTimestamp:2019-04-16 12:05:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 f991a81f-603f-11e9-8978-0800277031c6 0xc002c49d07 0xc002c49d08}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-25jwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-25jwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-25jwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c49eb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c49ed0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:51 +0000 UTC  }],Message:,Reason:,HostIP:172.17.8.103,PodIP:,StartTime:2019-04-16 12:05:52 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 16 12:05:53.890: INFO: Pod "nginx-deployment-65bbdb5f8-4dl6s" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-4dl6s,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-2xwj5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2xwj5/pods/nginx-deployment-65bbdb5f8-4dl6s,UID:fae093ff-603f-11e9-8978-0800277031c6,ResourceVersion:21896,Generation:0,CreationTimestamp:2019-04-16 12:05:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 f991a81f-603f-11e9-8978-0800277031c6 0xc002c49f90 0xc002c49f91}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-25jwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-25jwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-25jwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028dc3b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028dc440}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:52 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 16 12:05:53.890: INFO: Pod "nginx-deployment-65bbdb5f8-52nk6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-52nk6,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-2xwj5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2xwj5/pods/nginx-deployment-65bbdb5f8-52nk6,UID:faea0c87-603f-11e9-8978-0800277031c6,ResourceVersion:21904,Generation:0,CreationTimestamp:2019-04-16 12:05:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 f991a81f-603f-11e9-8978-0800277031c6 0xc0028dc4b0 0xc0028dc4b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-25jwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-25jwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-25jwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028dc530} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028dc550}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:52 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 16 12:05:53.892: INFO: Pod "nginx-deployment-65bbdb5f8-5sdgd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-5sdgd,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-2xwj5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2xwj5/pods/nginx-deployment-65bbdb5f8-5sdgd,UID:f9aef75b-603f-11e9-8978-0800277031c6,ResourceVersion:21830,Generation:0,CreationTimestamp:2019-04-16 12:05:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 f991a81f-603f-11e9-8978-0800277031c6 0xc0028dc840 0xc0028dc841}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-25jwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-25jwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-25jwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028dc8c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028dc8e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:50 +0000 UTC  }],Message:,Reason:,HostIP:172.17.8.101,PodIP:,StartTime:2019-04-16 12:05:50 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 16 12:05:53.892: INFO: Pod "nginx-deployment-65bbdb5f8-6gd45" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-6gd45,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-2xwj5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2xwj5/pods/nginx-deployment-65bbdb5f8-6gd45,UID:fad2824c-603f-11e9-8978-0800277031c6,ResourceVersion:21905,Generation:0,CreationTimestamp:2019-04-16 12:05:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 f991a81f-603f-11e9-8978-0800277031c6 0xc0028dc9a0 0xc0028dc9a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-25jwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-25jwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-25jwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028dca80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028dcaa0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:51 +0000 UTC  }],Message:,Reason:,HostIP:172.17.8.103,PodIP:,StartTime:2019-04-16 12:05:52 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 16 12:05:53.893: INFO: Pod "nginx-deployment-65bbdb5f8-6jmsq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-6jmsq,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-2xwj5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2xwj5/pods/nginx-deployment-65bbdb5f8-6jmsq,UID:fadf334b-603f-11e9-8978-0800277031c6,ResourceVersion:21960,Generation:0,CreationTimestamp:2019-04-16 12:05:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 f991a81f-603f-11e9-8978-0800277031c6 0xc0028dcb60 0xc0028dcb61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-25jwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-25jwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-25jwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028dcc20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028dcc40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:52 +0000 UTC  }],Message:,Reason:,HostIP:172.17.8.102,PodIP:,StartTime:2019-04-16 12:05:52 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 16 12:05:53.893: INFO: Pod "nginx-deployment-65bbdb5f8-799kx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-799kx,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-2xwj5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2xwj5/pods/nginx-deployment-65bbdb5f8-799kx,UID:fae0da26-603f-11e9-8978-0800277031c6,ResourceVersion:21965,Generation:0,CreationTimestamp:2019-04-16 12:05:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 f991a81f-603f-11e9-8978-0800277031c6 0xc0028dcd00 0xc0028dcd01}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-25jwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-25jwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-25jwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028dcdc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028dcde0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:52 +0000 UTC  }],Message:,Reason:,HostIP:172.17.8.102,PodIP:,StartTime:2019-04-16 12:05:52 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 16 12:05:53.893: INFO: Pod "nginx-deployment-65bbdb5f8-8w65n" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-8w65n,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-2xwj5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2xwj5/pods/nginx-deployment-65bbdb5f8-8w65n,UID:f994c28e-603f-11e9-8978-0800277031c6,ResourceVersion:21802,Generation:0,CreationTimestamp:2019-04-16 12:05:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 f991a81f-603f-11e9-8978-0800277031c6 0xc0028dcea0 0xc0028dcea1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-25jwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-25jwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-25jwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028dcf20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028dcf40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:49 +0000 UTC  }],Message:,Reason:,HostIP:172.17.8.101,PodIP:,StartTime:2019-04-16 12:05:49 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 16 12:05:53.893: INFO: Pod "nginx-deployment-65bbdb5f8-m29zh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-m29zh,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-2xwj5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2xwj5/pods/nginx-deployment-65bbdb5f8-m29zh,UID:f992aa6c-603f-11e9-8978-0800277031c6,ResourceVersion:21805,Generation:0,CreationTimestamp:2019-04-16 12:05:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 f991a81f-603f-11e9-8978-0800277031c6 0xc0028dd030 0xc0028dd031}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-25jwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-25jwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-25jwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028dd0b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028dd0d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:49 +0000 UTC  }],Message:,Reason:,HostIP:172.17.8.102,PodIP:,StartTime:2019-04-16 12:05:49 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 16 12:05:53.896: INFO: Pod "nginx-deployment-65bbdb5f8-qkw4n" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-qkw4n,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-2xwj5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2xwj5/pods/nginx-deployment-65bbdb5f8-qkw4n,UID:fad80774-603f-11e9-8978-0800277031c6,ResourceVersion:21907,Generation:0,CreationTimestamp:2019-04-16 12:05:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 f991a81f-603f-11e9-8978-0800277031c6 0xc0028dd1c0 0xc0028dd1c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-25jwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-25jwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-25jwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028dd240} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028dd260}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:51 +0000 UTC  }],Message:,Reason:,HostIP:172.17.8.101,PodIP:,StartTime:2019-04-16 12:05:52 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 16 12:05:53.896: INFO: Pod "nginx-deployment-65bbdb5f8-rh695" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-rh695,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-2xwj5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2xwj5/pods/nginx-deployment-65bbdb5f8-rh695,UID:fae0d28e-603f-11e9-8978-0800277031c6,ResourceVersion:21955,Generation:0,CreationTimestamp:2019-04-16 12:05:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 f991a81f-603f-11e9-8978-0800277031c6 0xc0028dd3a0 0xc0028dd3a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-25jwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-25jwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-25jwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028dd420} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028dd440}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:52 +0000 UTC  }],Message:,Reason:,HostIP:172.17.8.101,PodIP:,StartTime:2019-04-16 12:05:52 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 16 12:05:53.896: INFO: Pod "nginx-deployment-65bbdb5f8-trhg7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-trhg7,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-2xwj5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2xwj5/pods/nginx-deployment-65bbdb5f8-trhg7,UID:f99441b2-603f-11e9-8978-0800277031c6,ResourceVersion:21807,Generation:0,CreationTimestamp:2019-04-16 12:05:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 f991a81f-603f-11e9-8978-0800277031c6 0xc0028dd570 0xc0028dd571}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-25jwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-25jwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-25jwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028dd5f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028dd610}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:49 +0000 UTC  }],Message:,Reason:,HostIP:172.17.8.103,PodIP:,StartTime:2019-04-16 12:05:49 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 16 12:05:53.897: INFO: Pod "nginx-deployment-65bbdb5f8-vhlh4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-vhlh4,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-2xwj5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2xwj5/pods/nginx-deployment-65bbdb5f8-vhlh4,UID:f9acb1fc-603f-11e9-8978-0800277031c6,ResourceVersion:21828,Generation:0,CreationTimestamp:2019-04-16 12:05:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 f991a81f-603f-11e9-8978-0800277031c6 0xc0028dd6d0 0xc0028dd6d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-25jwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-25jwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-25jwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028dd7c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028dd7e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:05:49 +0000 UTC  }],Message:,Reason:,HostIP:172.17.8.102,PodIP:,StartTime:2019-04-16 12:05:49 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:05:53.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-2xwj5" for this suite.
Apr 16 12:06:03.937: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:06:03.963: INFO: namespace: e2e-tests-deployment-2xwj5, resource: bindings, ignored listing per whitelist
Apr 16 12:06:04.106: INFO: namespace e2e-tests-deployment-2xwj5 deletion completed in 10.204121262s

• [SLOW TEST:20.462 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:06:04.107: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Apr 16 12:06:04.295: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0233bb57-6040-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-downward-api-kw7dt" to be "success or failure"
Apr 16 12:06:04.305: INFO: Pod "downwardapi-volume-0233bb57-6040-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.153575ms
Apr 16 12:06:06.311: INFO: Pod "downwardapi-volume-0233bb57-6040-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01586368s
STEP: Saw pod success
Apr 16 12:06:06.311: INFO: Pod "downwardapi-volume-0233bb57-6040-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 12:06:06.315: INFO: Trying to get logs from node k8s-3 pod downwardapi-volume-0233bb57-6040-11e9-be7e-0a580ae9423f container client-container: <nil>
STEP: delete the pod
Apr 16 12:06:06.345: INFO: Waiting for pod downwardapi-volume-0233bb57-6040-11e9-be7e-0a580ae9423f to disappear
Apr 16 12:06:06.348: INFO: Pod downwardapi-volume-0233bb57-6040-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:06:06.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-kw7dt" for this suite.
Apr 16 12:06:12.368: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:06:12.468: INFO: namespace: e2e-tests-downward-api-kw7dt, resource: bindings, ignored listing per whitelist
Apr 16 12:06:12.497: INFO: namespace e2e-tests-downward-api-kw7dt deletion completed in 6.145623117s

• [SLOW TEST:8.390 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:06:12.498: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:06:16.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-5brfl" for this suite.
Apr 16 12:06:22.635: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:06:22.687: INFO: namespace: e2e-tests-kubelet-test-5brfl, resource: bindings, ignored listing per whitelist
Apr 16 12:06:22.757: INFO: namespace e2e-tests-kubelet-test-5brfl deletion completed in 6.140698598s

• [SLOW TEST:10.259 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:06:22.757: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-0d4c6f0a-6040-11e9-be7e-0a580ae9423f
STEP: Creating a pod to test consume configMaps
Apr 16 12:06:22.901: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0d4df6b3-6040-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-projected-l98v9" to be "success or failure"
Apr 16 12:06:22.911: INFO: Pod "pod-projected-configmaps-0d4df6b3-6040-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.279321ms
Apr 16 12:06:24.916: INFO: Pod "pod-projected-configmaps-0d4df6b3-6040-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01530754s
STEP: Saw pod success
Apr 16 12:06:24.916: INFO: Pod "pod-projected-configmaps-0d4df6b3-6040-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 12:06:24.920: INFO: Trying to get logs from node k8s-1 pod pod-projected-configmaps-0d4df6b3-6040-11e9-be7e-0a580ae9423f container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 16 12:06:24.955: INFO: Waiting for pod pod-projected-configmaps-0d4df6b3-6040-11e9-be7e-0a580ae9423f to disappear
Apr 16 12:06:24.961: INFO: Pod pod-projected-configmaps-0d4df6b3-6040-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:06:24.961: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-l98v9" for this suite.
Apr 16 12:06:31.011: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:06:31.152: INFO: namespace: e2e-tests-projected-l98v9, resource: bindings, ignored listing per whitelist
Apr 16 12:06:31.207: INFO: namespace e2e-tests-projected-l98v9 deletion completed in 6.241801697s

• [SLOW TEST:8.450 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:06:31.208: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-vl8c
STEP: Creating a pod to test atomic-volume-subpath
Apr 16 12:06:31.325: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-vl8c" in namespace "e2e-tests-subpath-w6w22" to be "success or failure"
Apr 16 12:06:31.340: INFO: Pod "pod-subpath-test-configmap-vl8c": Phase="Pending", Reason="", readiness=false. Elapsed: 14.503783ms
Apr 16 12:06:33.345: INFO: Pod "pod-subpath-test-configmap-vl8c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01954965s
Apr 16 12:06:35.350: INFO: Pod "pod-subpath-test-configmap-vl8c": Phase="Running", Reason="", readiness=false. Elapsed: 4.025280143s
Apr 16 12:06:37.355: INFO: Pod "pod-subpath-test-configmap-vl8c": Phase="Running", Reason="", readiness=false. Elapsed: 6.030033934s
Apr 16 12:06:39.361: INFO: Pod "pod-subpath-test-configmap-vl8c": Phase="Running", Reason="", readiness=false. Elapsed: 8.035544582s
Apr 16 12:06:41.370: INFO: Pod "pod-subpath-test-configmap-vl8c": Phase="Running", Reason="", readiness=false. Elapsed: 10.045284336s
Apr 16 12:06:43.375: INFO: Pod "pod-subpath-test-configmap-vl8c": Phase="Running", Reason="", readiness=false. Elapsed: 12.050182393s
Apr 16 12:06:45.382: INFO: Pod "pod-subpath-test-configmap-vl8c": Phase="Running", Reason="", readiness=false. Elapsed: 14.057322802s
Apr 16 12:06:47.388: INFO: Pod "pod-subpath-test-configmap-vl8c": Phase="Running", Reason="", readiness=false. Elapsed: 16.062827605s
Apr 16 12:06:49.394: INFO: Pod "pod-subpath-test-configmap-vl8c": Phase="Running", Reason="", readiness=false. Elapsed: 18.069300444s
Apr 16 12:06:51.406: INFO: Pod "pod-subpath-test-configmap-vl8c": Phase="Running", Reason="", readiness=false. Elapsed: 20.081042883s
Apr 16 12:06:53.414: INFO: Pod "pod-subpath-test-configmap-vl8c": Phase="Running", Reason="", readiness=false. Elapsed: 22.08883023s
Apr 16 12:06:55.418: INFO: Pod "pod-subpath-test-configmap-vl8c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.093192916s
STEP: Saw pod success
Apr 16 12:06:55.418: INFO: Pod "pod-subpath-test-configmap-vl8c" satisfied condition "success or failure"
Apr 16 12:06:55.422: INFO: Trying to get logs from node k8s-2 pod pod-subpath-test-configmap-vl8c container test-container-subpath-configmap-vl8c: <nil>
STEP: delete the pod
Apr 16 12:06:55.457: INFO: Waiting for pod pod-subpath-test-configmap-vl8c to disappear
Apr 16 12:06:55.463: INFO: Pod pod-subpath-test-configmap-vl8c no longer exists
STEP: Deleting pod pod-subpath-test-configmap-vl8c
Apr 16 12:06:55.463: INFO: Deleting pod "pod-subpath-test-configmap-vl8c" in namespace "e2e-tests-subpath-w6w22"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:06:55.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-w6w22" for this suite.
Apr 16 12:07:01.492: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:07:01.618: INFO: namespace: e2e-tests-subpath-w6w22, resource: bindings, ignored listing per whitelist
Apr 16 12:07:01.633: INFO: namespace e2e-tests-subpath-w6w22 deletion completed in 6.162508545s

• [SLOW TEST:30.425 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:07:01.634: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Apr 16 12:07:01.720: INFO: Waiting up to 5m0s for pod "client-containers-247142db-6040-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-containers-nqb5p" to be "success or failure"
Apr 16 12:07:01.724: INFO: Pod "client-containers-247142db-6040-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.200046ms
Apr 16 12:07:03.730: INFO: Pod "client-containers-247142db-6040-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009891086s
Apr 16 12:07:05.733: INFO: Pod "client-containers-247142db-6040-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013659338s
Apr 16 12:07:07.739: INFO: Pod "client-containers-247142db-6040-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.019409684s
STEP: Saw pod success
Apr 16 12:07:07.739: INFO: Pod "client-containers-247142db-6040-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 12:07:07.743: INFO: Trying to get logs from node k8s-3 pod client-containers-247142db-6040-11e9-be7e-0a580ae9423f container test-container: <nil>
STEP: delete the pod
Apr 16 12:07:07.778: INFO: Waiting for pod client-containers-247142db-6040-11e9-be7e-0a580ae9423f to disappear
Apr 16 12:07:07.783: INFO: Pod client-containers-247142db-6040-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:07:07.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-nqb5p" for this suite.
Apr 16 12:07:13.806: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:07:13.828: INFO: namespace: e2e-tests-containers-nqb5p, resource: bindings, ignored listing per whitelist
Apr 16 12:07:13.917: INFO: namespace e2e-tests-containers-nqb5p deletion completed in 6.130634991s

• [SLOW TEST:12.283 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:07:13.918: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:07:14.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-wjnwx" for this suite.
Apr 16 12:07:20.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:07:20.125: INFO: namespace: e2e-tests-kubelet-test-wjnwx, resource: bindings, ignored listing per whitelist
Apr 16 12:07:20.182: INFO: namespace e2e-tests-kubelet-test-wjnwx deletion completed in 6.14457872s

• [SLOW TEST:6.264 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:07:20.182: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-2f82211e-6040-11e9-be7e-0a580ae9423f
STEP: Creating secret with name s-test-opt-upd-2f822162-6040-11e9-be7e-0a580ae9423f
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-2f82211e-6040-11e9-be7e-0a580ae9423f
STEP: Updating secret s-test-opt-upd-2f822162-6040-11e9-be7e-0a580ae9423f
STEP: Creating secret with name s-test-opt-create-2f822174-6040-11e9-be7e-0a580ae9423f
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:08:38.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-24z9b" for this suite.
Apr 16 12:09:01.006: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:09:01.066: INFO: namespace: e2e-tests-secrets-24z9b, resource: bindings, ignored listing per whitelist
Apr 16 12:09:01.104: INFO: namespace e2e-tests-secrets-24z9b deletion completed in 22.114878791s

• [SLOW TEST:100.922 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:09:01.105: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Apr 16 12:09:01.177: INFO: PodSpec: initContainers in spec.initContainers
Apr 16 12:09:43.315: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-6ba6c0f3-6040-11e9-be7e-0a580ae9423f", GenerateName:"", Namespace:"e2e-tests-init-container-k2ktt", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-k2ktt/pods/pod-init-6ba6c0f3-6040-11e9-be7e-0a580ae9423f", UID:"6ba7acde-6040-11e9-8569-0800277031c6", ResourceVersion:"22808", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63691013341, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"time":"177474845", "name":"foo"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-rbklv", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001f24280), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-rbklv", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-rbklv", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}, "cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-rbklv", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001f5c328), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"k8s-3", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0008e0060), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001f5c400)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001f5c420)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001f5c428), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001f5c42c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691013341, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691013341, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691013341, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691013341, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.17.8.103", PodIP:"10.233.66.119", StartTime:(*v1.Time)(0xc002282100), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0018a41c0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0018a4230)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://3b7a7e2539593fce051f3ac407e7ea5ad04c0be9b4ab8f205f2037fbeeeb042d"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002282140), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002282120), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:09:43.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-k2ktt" for this suite.
Apr 16 12:10:05.360: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:10:05.416: INFO: namespace: e2e-tests-init-container-k2ktt, resource: bindings, ignored listing per whitelist
Apr 16 12:10:05.456: INFO: namespace e2e-tests-init-container-k2ktt deletion completed in 22.126469048s

• [SLOW TEST:64.351 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:10:05.457: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:10:05.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-9jhld" for this suite.
Apr 16 12:10:11.580: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:10:11.639: INFO: namespace: e2e-tests-services-9jhld, resource: bindings, ignored listing per whitelist
Apr 16 12:10:11.719: INFO: namespace e2e-tests-services-9jhld deletion completed in 6.156889549s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:6.262 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:10:11.720: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:10:13.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-qf5cg" for this suite.
Apr 16 12:11:05.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:11:06.020: INFO: namespace: e2e-tests-kubelet-test-qf5cg, resource: bindings, ignored listing per whitelist
Apr 16 12:11:06.056: INFO: namespace e2e-tests-kubelet-test-qf5cg deletion completed in 52.113601403s

• [SLOW TEST:54.336 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:11:06.057: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:11:08.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-2fqqk" for this suite.
Apr 16 12:11:14.240: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:11:14.311: INFO: namespace: e2e-tests-emptydir-wrapper-2fqqk, resource: bindings, ignored listing per whitelist
Apr 16 12:11:14.341: INFO: namespace e2e-tests-emptydir-wrapper-2fqqk deletion completed in 6.126641311s

• [SLOW TEST:8.284 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:11:14.342: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-bb101f72-6040-11e9-be7e-0a580ae9423f
STEP: Creating a pod to test consume secrets
Apr 16 12:11:14.424: INFO: Waiting up to 5m0s for pod "pod-secrets-bb114b47-6040-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-secrets-9gbxn" to be "success or failure"
Apr 16 12:11:14.428: INFO: Pod "pod-secrets-bb114b47-6040-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.228488ms
Apr 16 12:11:16.435: INFO: Pod "pod-secrets-bb114b47-6040-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010411415s
STEP: Saw pod success
Apr 16 12:11:16.435: INFO: Pod "pod-secrets-bb114b47-6040-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 12:11:16.438: INFO: Trying to get logs from node k8s-3 pod pod-secrets-bb114b47-6040-11e9-be7e-0a580ae9423f container secret-volume-test: <nil>
STEP: delete the pod
Apr 16 12:11:16.470: INFO: Waiting for pod pod-secrets-bb114b47-6040-11e9-be7e-0a580ae9423f to disappear
Apr 16 12:11:16.474: INFO: Pod pod-secrets-bb114b47-6040-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:11:16.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-9gbxn" for this suite.
Apr 16 12:11:22.493: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:11:22.525: INFO: namespace: e2e-tests-secrets-9gbxn, resource: bindings, ignored listing per whitelist
Apr 16 12:11:22.607: INFO: namespace e2e-tests-secrets-9gbxn deletion completed in 6.129423343s

• [SLOW TEST:8.265 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:11:22.607: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Apr 16 12:11:25.226: INFO: Successfully updated pod "pod-update-activedeadlineseconds-bffebbc7-6040-11e9-be7e-0a580ae9423f"
Apr 16 12:11:25.226: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-bffebbc7-6040-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-pods-bhkcm" to be "terminated due to deadline exceeded"
Apr 16 12:11:25.230: INFO: Pod "pod-update-activedeadlineseconds-bffebbc7-6040-11e9-be7e-0a580ae9423f": Phase="Running", Reason="", readiness=true. Elapsed: 3.717897ms
Apr 16 12:11:27.235: INFO: Pod "pod-update-activedeadlineseconds-bffebbc7-6040-11e9-be7e-0a580ae9423f": Phase="Running", Reason="", readiness=true. Elapsed: 2.008629988s
Apr 16 12:11:29.239: INFO: Pod "pod-update-activedeadlineseconds-bffebbc7-6040-11e9-be7e-0a580ae9423f": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.013135775s
Apr 16 12:11:29.239: INFO: Pod "pod-update-activedeadlineseconds-bffebbc7-6040-11e9-be7e-0a580ae9423f" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:11:29.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-bhkcm" for this suite.
Apr 16 12:11:35.269: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:11:35.328: INFO: namespace: e2e-tests-pods-bhkcm, resource: bindings, ignored listing per whitelist
Apr 16 12:11:35.414: INFO: namespace e2e-tests-pods-bhkcm deletion completed in 6.169949202s

• [SLOW TEST:12.807 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:11:35.415: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Apr 16 12:11:35.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 create -f - --namespace=e2e-tests-kubectl-9mk4r'
Apr 16 12:11:36.209: INFO: stderr: ""
Apr 16 12:11:36.209: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 16 12:11:36.209: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-9mk4r'
Apr 16 12:11:36.332: INFO: stderr: ""
Apr 16 12:11:36.332: INFO: stdout: "update-demo-nautilus-qdjxh update-demo-nautilus-zmvr6 "
Apr 16 12:11:36.332: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 get pods update-demo-nautilus-qdjxh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9mk4r'
Apr 16 12:11:36.404: INFO: stderr: ""
Apr 16 12:11:36.404: INFO: stdout: ""
Apr 16 12:11:36.404: INFO: update-demo-nautilus-qdjxh is created but not running
Apr 16 12:11:41.404: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-9mk4r'
Apr 16 12:11:41.478: INFO: stderr: ""
Apr 16 12:11:41.478: INFO: stdout: "update-demo-nautilus-qdjxh update-demo-nautilus-zmvr6 "
Apr 16 12:11:41.478: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 get pods update-demo-nautilus-qdjxh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9mk4r'
Apr 16 12:11:41.559: INFO: stderr: ""
Apr 16 12:11:41.559: INFO: stdout: "true"
Apr 16 12:11:41.559: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 get pods update-demo-nautilus-qdjxh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9mk4r'
Apr 16 12:11:41.638: INFO: stderr: ""
Apr 16 12:11:41.638: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 16 12:11:41.638: INFO: validating pod update-demo-nautilus-qdjxh
Apr 16 12:11:41.651: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 16 12:11:41.651: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 16 12:11:41.651: INFO: update-demo-nautilus-qdjxh is verified up and running
Apr 16 12:11:41.651: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 get pods update-demo-nautilus-zmvr6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9mk4r'
Apr 16 12:11:41.727: INFO: stderr: ""
Apr 16 12:11:41.727: INFO: stdout: "true"
Apr 16 12:11:41.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 get pods update-demo-nautilus-zmvr6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9mk4r'
Apr 16 12:11:41.792: INFO: stderr: ""
Apr 16 12:11:41.792: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 16 12:11:41.792: INFO: validating pod update-demo-nautilus-zmvr6
Apr 16 12:11:41.803: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 16 12:11:41.803: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 16 12:11:41.803: INFO: update-demo-nautilus-zmvr6 is verified up and running
STEP: using delete to clean up resources
Apr 16 12:11:41.803: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-9mk4r'
Apr 16 12:11:41.892: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 16 12:11:41.892: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Apr 16 12:11:41.892: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-9mk4r'
Apr 16 12:11:42.062: INFO: stderr: "No resources found.\n"
Apr 16 12:11:42.062: INFO: stdout: ""
Apr 16 12:11:42.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 get pods -l name=update-demo --namespace=e2e-tests-kubectl-9mk4r -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 16 12:11:42.210: INFO: stderr: ""
Apr 16 12:11:42.210: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:11:42.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9mk4r" for this suite.
Apr 16 12:11:48.231: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:11:48.261: INFO: namespace: e2e-tests-kubectl-9mk4r, resource: bindings, ignored listing per whitelist
Apr 16 12:11:48.340: INFO: namespace e2e-tests-kubectl-9mk4r deletion completed in 6.125942529s

• [SLOW TEST:12.926 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:11:48.340: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-b7cxf
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 16 12:11:48.408: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr 16 12:12:10.571: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.64.110:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-b7cxf PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 16 12:12:10.571: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
Apr 16 12:12:10.685: INFO: Found all expected endpoints: [netserver-0]
Apr 16 12:12:10.690: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.65.97:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-b7cxf PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 16 12:12:10.690: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
Apr 16 12:12:10.767: INFO: Found all expected endpoints: [netserver-1]
Apr 16 12:12:10.774: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.66.122:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-b7cxf PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 16 12:12:10.774: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
Apr 16 12:12:10.856: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:12:10.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-b7cxf" for this suite.
Apr 16 12:12:32.886: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:12:32.956: INFO: namespace: e2e-tests-pod-network-test-b7cxf, resource: bindings, ignored listing per whitelist
Apr 16 12:12:32.992: INFO: namespace e2e-tests-pod-network-test-b7cxf deletion completed in 22.131276452s

• [SLOW TEST:44.652 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:12:32.995: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-e9f44c22-6040-11e9-be7e-0a580ae9423f
STEP: Creating a pod to test consume configMaps
Apr 16 12:12:33.105: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e9f58ffb-6040-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-projected-vwn5s" to be "success or failure"
Apr 16 12:12:33.112: INFO: Pod "pod-projected-configmaps-e9f58ffb-6040-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.724109ms
Apr 16 12:12:35.119: INFO: Pod "pod-projected-configmaps-e9f58ffb-6040-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013977787s
STEP: Saw pod success
Apr 16 12:12:35.120: INFO: Pod "pod-projected-configmaps-e9f58ffb-6040-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 12:12:35.124: INFO: Trying to get logs from node k8s-3 pod pod-projected-configmaps-e9f58ffb-6040-11e9-be7e-0a580ae9423f container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 16 12:12:35.160: INFO: Waiting for pod pod-projected-configmaps-e9f58ffb-6040-11e9-be7e-0a580ae9423f to disappear
Apr 16 12:12:35.165: INFO: Pod pod-projected-configmaps-e9f58ffb-6040-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:12:35.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vwn5s" for this suite.
Apr 16 12:12:41.190: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:12:41.235: INFO: namespace: e2e-tests-projected-vwn5s, resource: bindings, ignored listing per whitelist
Apr 16 12:12:41.309: INFO: namespace e2e-tests-projected-vwn5s deletion completed in 6.14039725s

• [SLOW TEST:8.314 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:12:41.310: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-eee9def2-6040-11e9-be7e-0a580ae9423f
STEP: Creating a pod to test consume secrets
Apr 16 12:12:41.417: INFO: Waiting up to 5m0s for pod "pod-secrets-eeeacb87-6040-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-secrets-bwz2p" to be "success or failure"
Apr 16 12:12:41.421: INFO: Pod "pod-secrets-eeeacb87-6040-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.326423ms
Apr 16 12:12:43.426: INFO: Pod "pod-secrets-eeeacb87-6040-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008769758s
STEP: Saw pod success
Apr 16 12:12:43.426: INFO: Pod "pod-secrets-eeeacb87-6040-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 12:12:43.429: INFO: Trying to get logs from node k8s-1 pod pod-secrets-eeeacb87-6040-11e9-be7e-0a580ae9423f container secret-volume-test: <nil>
STEP: delete the pod
Apr 16 12:12:43.475: INFO: Waiting for pod pod-secrets-eeeacb87-6040-11e9-be7e-0a580ae9423f to disappear
Apr 16 12:12:43.480: INFO: Pod pod-secrets-eeeacb87-6040-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:12:43.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-bwz2p" for this suite.
Apr 16 12:12:49.501: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:12:49.568: INFO: namespace: e2e-tests-secrets-bwz2p, resource: bindings, ignored listing per whitelist
Apr 16 12:12:49.613: INFO: namespace e2e-tests-secrets-bwz2p deletion completed in 6.129596275s

• [SLOW TEST:8.304 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:12:49.614: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Apr 16 12:12:49.733: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Apr 16 12:12:49.753: INFO: Number of nodes with available pods: 0
Apr 16 12:12:49.753: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Apr 16 12:12:49.786: INFO: Number of nodes with available pods: 0
Apr 16 12:12:49.786: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:12:50.792: INFO: Number of nodes with available pods: 0
Apr 16 12:12:50.792: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:12:51.798: INFO: Number of nodes with available pods: 1
Apr 16 12:12:51.798: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Apr 16 12:12:51.820: INFO: Number of nodes with available pods: 1
Apr 16 12:12:51.820: INFO: Number of running nodes: 0, number of available pods: 1
Apr 16 12:12:52.828: INFO: Number of nodes with available pods: 0
Apr 16 12:12:52.828: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Apr 16 12:12:52.843: INFO: Number of nodes with available pods: 0
Apr 16 12:12:52.843: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:12:53.848: INFO: Number of nodes with available pods: 0
Apr 16 12:12:53.848: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:12:54.849: INFO: Number of nodes with available pods: 0
Apr 16 12:12:54.849: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:12:55.850: INFO: Number of nodes with available pods: 0
Apr 16 12:12:55.850: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:12:56.871: INFO: Number of nodes with available pods: 0
Apr 16 12:12:56.871: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:12:57.849: INFO: Number of nodes with available pods: 0
Apr 16 12:12:57.850: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:12:58.848: INFO: Number of nodes with available pods: 0
Apr 16 12:12:58.848: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:12:59.848: INFO: Number of nodes with available pods: 0
Apr 16 12:12:59.848: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:13:00.849: INFO: Number of nodes with available pods: 0
Apr 16 12:13:00.849: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:13:01.854: INFO: Number of nodes with available pods: 0
Apr 16 12:13:01.854: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:13:02.851: INFO: Number of nodes with available pods: 0
Apr 16 12:13:02.851: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:13:03.848: INFO: Number of nodes with available pods: 0
Apr 16 12:13:03.848: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:13:04.848: INFO: Number of nodes with available pods: 0
Apr 16 12:13:04.848: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:13:05.848: INFO: Number of nodes with available pods: 0
Apr 16 12:13:05.848: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:13:06.850: INFO: Number of nodes with available pods: 0
Apr 16 12:13:06.850: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:13:07.849: INFO: Number of nodes with available pods: 0
Apr 16 12:13:07.849: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:13:08.850: INFO: Number of nodes with available pods: 0
Apr 16 12:13:08.850: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:13:09.848: INFO: Number of nodes with available pods: 0
Apr 16 12:13:09.849: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:13:10.849: INFO: Number of nodes with available pods: 0
Apr 16 12:13:10.849: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:13:11.849: INFO: Number of nodes with available pods: 0
Apr 16 12:13:11.849: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:13:12.854: INFO: Number of nodes with available pods: 0
Apr 16 12:13:12.854: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:13:13.848: INFO: Number of nodes with available pods: 0
Apr 16 12:13:13.848: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:13:14.848: INFO: Number of nodes with available pods: 0
Apr 16 12:13:14.848: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:13:15.848: INFO: Number of nodes with available pods: 0
Apr 16 12:13:15.848: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:13:16.848: INFO: Number of nodes with available pods: 0
Apr 16 12:13:16.848: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:13:17.848: INFO: Number of nodes with available pods: 0
Apr 16 12:13:17.848: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:13:18.848: INFO: Number of nodes with available pods: 0
Apr 16 12:13:18.848: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:13:19.848: INFO: Number of nodes with available pods: 0
Apr 16 12:13:19.848: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:13:20.848: INFO: Number of nodes with available pods: 0
Apr 16 12:13:20.848: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:13:21.848: INFO: Number of nodes with available pods: 0
Apr 16 12:13:21.848: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:13:22.848: INFO: Number of nodes with available pods: 0
Apr 16 12:13:22.848: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:13:23.856: INFO: Number of nodes with available pods: 0
Apr 16 12:13:23.856: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:13:24.848: INFO: Number of nodes with available pods: 0
Apr 16 12:13:24.848: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:13:25.848: INFO: Number of nodes with available pods: 0
Apr 16 12:13:25.848: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:13:26.849: INFO: Number of nodes with available pods: 0
Apr 16 12:13:26.849: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:13:27.849: INFO: Number of nodes with available pods: 0
Apr 16 12:13:27.849: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:13:28.849: INFO: Number of nodes with available pods: 0
Apr 16 12:13:28.849: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:13:29.848: INFO: Number of nodes with available pods: 0
Apr 16 12:13:29.848: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:13:30.848: INFO: Number of nodes with available pods: 1
Apr 16 12:13:30.848: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-hjfbk, will wait for the garbage collector to delete the pods
Apr 16 12:13:30.918: INFO: Deleting DaemonSet.extensions daemon-set took: 7.852276ms
Apr 16 12:13:31.018: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.73614ms
Apr 16 12:14:09.629: INFO: Number of nodes with available pods: 0
Apr 16 12:14:09.629: INFO: Number of running nodes: 0, number of available pods: 0
Apr 16 12:14:09.633: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-hjfbk/daemonsets","resourceVersion":"23597"},"items":null}

Apr 16 12:14:09.636: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-hjfbk/pods","resourceVersion":"23597"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:14:09.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-hjfbk" for this suite.
Apr 16 12:14:15.678: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:14:15.780: INFO: namespace: e2e-tests-daemonsets-hjfbk, resource: bindings, ignored listing per whitelist
Apr 16 12:14:15.800: INFO: namespace e2e-tests-daemonsets-hjfbk deletion completed in 6.137049736s

• [SLOW TEST:86.186 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:14:15.801: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Apr 16 12:14:15.877: INFO: Waiting up to 5m0s for pod "pod-2738c164-6041-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-emptydir-vrptl" to be "success or failure"
Apr 16 12:14:15.881: INFO: Pod "pod-2738c164-6041-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.796605ms
Apr 16 12:14:17.886: INFO: Pod "pod-2738c164-6041-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008792324s
STEP: Saw pod success
Apr 16 12:14:17.886: INFO: Pod "pod-2738c164-6041-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 12:14:17.890: INFO: Trying to get logs from node k8s-2 pod pod-2738c164-6041-11e9-be7e-0a580ae9423f container test-container: <nil>
STEP: delete the pod
Apr 16 12:14:17.931: INFO: Waiting for pod pod-2738c164-6041-11e9-be7e-0a580ae9423f to disappear
Apr 16 12:14:17.934: INFO: Pod pod-2738c164-6041-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:14:17.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-vrptl" for this suite.
Apr 16 12:14:23.960: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:14:24.017: INFO: namespace: e2e-tests-emptydir-vrptl, resource: bindings, ignored listing per whitelist
Apr 16 12:14:24.091: INFO: namespace e2e-tests-emptydir-vrptl deletion completed in 6.15288877s

• [SLOW TEST:8.290 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:14:24.092: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Apr 16 12:14:24.157: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:14:26.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-qk772" for this suite.
Apr 16 12:14:32.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:14:32.650: INFO: namespace: e2e-tests-init-container-qk772, resource: bindings, ignored listing per whitelist
Apr 16 12:14:32.691: INFO: namespace e2e-tests-init-container-qk772 deletion completed in 6.12506941s

• [SLOW TEST:8.600 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:14:32.692: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Apr 16 12:14:35.312: INFO: Successfully updated pod "labelsupdate314b2f8e-6041-11e9-be7e-0a580ae9423f"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:14:39.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gz2c8" for this suite.
Apr 16 12:15:01.363: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:15:01.458: INFO: namespace: e2e-tests-projected-gz2c8, resource: bindings, ignored listing per whitelist
Apr 16 12:15:01.492: INFO: namespace e2e-tests-projected-gz2c8 deletion completed in 22.147364884s

• [SLOW TEST:28.800 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:15:01.494: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Apr 16 12:15:01.579: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Apr 16 12:15:01.579: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 create -f - --namespace=e2e-tests-kubectl-wzkx5'
Apr 16 12:15:01.784: INFO: stderr: ""
Apr 16 12:15:01.784: INFO: stdout: "service/redis-slave created\n"
Apr 16 12:15:01.785: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Apr 16 12:15:01.785: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 create -f - --namespace=e2e-tests-kubectl-wzkx5'
Apr 16 12:15:02.150: INFO: stderr: ""
Apr 16 12:15:02.150: INFO: stdout: "service/redis-master created\n"
Apr 16 12:15:02.151: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Apr 16 12:15:02.151: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 create -f - --namespace=e2e-tests-kubectl-wzkx5'
Apr 16 12:15:02.392: INFO: stderr: ""
Apr 16 12:15:02.392: INFO: stdout: "service/frontend created\n"
Apr 16 12:15:02.393: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Apr 16 12:15:02.393: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 create -f - --namespace=e2e-tests-kubectl-wzkx5'
Apr 16 12:15:02.647: INFO: stderr: ""
Apr 16 12:15:02.647: INFO: stdout: "deployment.extensions/frontend created\n"
Apr 16 12:15:02.648: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Apr 16 12:15:02.648: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 create -f - --namespace=e2e-tests-kubectl-wzkx5'
Apr 16 12:15:02.896: INFO: stderr: ""
Apr 16 12:15:02.896: INFO: stdout: "deployment.extensions/redis-master created\n"
Apr 16 12:15:02.896: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Apr 16 12:15:02.896: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 create -f - --namespace=e2e-tests-kubectl-wzkx5'
Apr 16 12:15:03.286: INFO: stderr: ""
Apr 16 12:15:03.286: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Apr 16 12:15:03.286: INFO: Waiting for all frontend pods to be Running.
Apr 16 12:15:43.366: INFO: Waiting for frontend to serve content.
Apr 16 12:15:44.407: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection refused [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection refu...', 111)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stream in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Apr 16 12:15:49.425: INFO: Trying to add a new entry to the guestbook.
Apr 16 12:15:49.440: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Apr 16 12:15:49.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-wzkx5'
Apr 16 12:15:49.555: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 16 12:15:49.555: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Apr 16 12:15:49.555: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-wzkx5'
Apr 16 12:15:49.717: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 16 12:15:49.717: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Apr 16 12:15:49.717: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-wzkx5'
Apr 16 12:15:49.892: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 16 12:15:49.892: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Apr 16 12:15:49.892: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-wzkx5'
Apr 16 12:15:50.040: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 16 12:15:50.040: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Apr 16 12:15:50.040: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-wzkx5'
Apr 16 12:15:50.226: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 16 12:15:50.226: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Apr 16 12:15:50.227: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-wzkx5'
Apr 16 12:15:50.392: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 16 12:15:50.392: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:15:50.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wzkx5" for this suite.
Apr 16 12:16:30.438: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:16:30.520: INFO: namespace: e2e-tests-kubectl-wzkx5, resource: bindings, ignored listing per whitelist
Apr 16 12:16:30.549: INFO: namespace e2e-tests-kubectl-wzkx5 deletion completed in 40.149921553s

• [SLOW TEST:89.056 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:16:30.551: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Apr 16 12:16:30.646: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-nh4cj,SelfLink:/api/v1/namespaces/e2e-tests-watch-nh4cj/configmaps/e2e-watch-test-watch-closed,UID:778bf036-6041-11e9-8569-0800277031c6,ResourceVersion:24116,Generation:0,CreationTimestamp:2019-04-16 12:16:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr 16 12:16:30.646: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-nh4cj,SelfLink:/api/v1/namespaces/e2e-tests-watch-nh4cj/configmaps/e2e-watch-test-watch-closed,UID:778bf036-6041-11e9-8569-0800277031c6,ResourceVersion:24117,Generation:0,CreationTimestamp:2019-04-16 12:16:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Apr 16 12:16:30.676: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-nh4cj,SelfLink:/api/v1/namespaces/e2e-tests-watch-nh4cj/configmaps/e2e-watch-test-watch-closed,UID:778bf036-6041-11e9-8569-0800277031c6,ResourceVersion:24118,Generation:0,CreationTimestamp:2019-04-16 12:16:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr 16 12:16:30.676: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-nh4cj,SelfLink:/api/v1/namespaces/e2e-tests-watch-nh4cj/configmaps/e2e-watch-test-watch-closed,UID:778bf036-6041-11e9-8569-0800277031c6,ResourceVersion:24119,Generation:0,CreationTimestamp:2019-04-16 12:16:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:16:30.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-nh4cj" for this suite.
Apr 16 12:16:36.697: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:16:36.764: INFO: namespace: e2e-tests-watch-nh4cj, resource: bindings, ignored listing per whitelist
Apr 16 12:16:36.796: INFO: namespace e2e-tests-watch-nh4cj deletion completed in 6.115684129s

• [SLOW TEST:6.245 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:16:36.797: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-9n4n2
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-9n4n2
STEP: Deleting pre-stop pod
Apr 16 12:16:49.956: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:16:49.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-9n4n2" for this suite.
Apr 16 12:17:31.999: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:17:32.051: INFO: namespace: e2e-tests-prestop-9n4n2, resource: bindings, ignored listing per whitelist
Apr 16 12:17:32.114: INFO: namespace e2e-tests-prestop-9n4n2 deletion completed in 42.138492378s

• [SLOW TEST:55.318 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:17:32.115: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1052
STEP: creating the pod
Apr 16 12:17:32.184: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 create -f - --namespace=e2e-tests-kubectl-m6g8d'
Apr 16 12:17:32.357: INFO: stderr: ""
Apr 16 12:17:32.357: INFO: stdout: "pod/pause created\n"
Apr 16 12:17:32.357: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Apr 16 12:17:32.357: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-m6g8d" to be "running and ready"
Apr 16 12:17:32.365: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 8.292731ms
Apr 16 12:17:34.372: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.015573648s
Apr 16 12:17:34.372: INFO: Pod "pause" satisfied condition "running and ready"
Apr 16 12:17:34.372: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Apr 16 12:17:34.373: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-m6g8d'
Apr 16 12:17:34.457: INFO: stderr: ""
Apr 16 12:17:34.457: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Apr 16 12:17:34.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 get pod pause -L testing-label --namespace=e2e-tests-kubectl-m6g8d'
Apr 16 12:17:34.531: INFO: stderr: ""
Apr 16 12:17:34.531: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Apr 16 12:17:34.531: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 label pods pause testing-label- --namespace=e2e-tests-kubectl-m6g8d'
Apr 16 12:17:34.631: INFO: stderr: ""
Apr 16 12:17:34.631: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Apr 16 12:17:34.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 get pod pause -L testing-label --namespace=e2e-tests-kubectl-m6g8d'
Apr 16 12:17:34.711: INFO: stderr: ""
Apr 16 12:17:34.711: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1059
STEP: using delete to clean up resources
Apr 16 12:17:34.711: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-m6g8d'
Apr 16 12:17:34.810: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 16 12:17:34.810: INFO: stdout: "pod \"pause\" force deleted\n"
Apr 16 12:17:34.811: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-m6g8d'
Apr 16 12:17:35.000: INFO: stderr: "No resources found.\n"
Apr 16 12:17:35.000: INFO: stdout: ""
Apr 16 12:17:35.000: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 get pods -l name=pause --namespace=e2e-tests-kubectl-m6g8d -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 16 12:17:35.175: INFO: stderr: ""
Apr 16 12:17:35.175: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:17:35.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-m6g8d" for this suite.
Apr 16 12:17:41.211: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:17:41.261: INFO: namespace: e2e-tests-kubectl-m6g8d, resource: bindings, ignored listing per whitelist
Apr 16 12:17:41.336: INFO: namespace e2e-tests-kubectl-m6g8d deletion completed in 6.157167895s

• [SLOW TEST:9.222 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:17:41.337: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Apr 16 12:17:43.524: INFO: Waiting up to 5m0s for pod "client-envvars-a2f8a870-6041-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-pods-mxrhg" to be "success or failure"
Apr 16 12:17:43.546: INFO: Pod "client-envvars-a2f8a870-6041-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 21.681548ms
Apr 16 12:17:45.552: INFO: Pod "client-envvars-a2f8a870-6041-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027937977s
STEP: Saw pod success
Apr 16 12:17:45.552: INFO: Pod "client-envvars-a2f8a870-6041-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 12:17:45.555: INFO: Trying to get logs from node k8s-2 pod client-envvars-a2f8a870-6041-11e9-be7e-0a580ae9423f container env3cont: <nil>
STEP: delete the pod
Apr 16 12:17:45.592: INFO: Waiting for pod client-envvars-a2f8a870-6041-11e9-be7e-0a580ae9423f to disappear
Apr 16 12:17:45.598: INFO: Pod client-envvars-a2f8a870-6041-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:17:45.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-mxrhg" for this suite.
Apr 16 12:18:31.620: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:18:31.665: INFO: namespace: e2e-tests-pods-mxrhg, resource: bindings, ignored listing per whitelist
Apr 16 12:18:31.749: INFO: namespace e2e-tests-pods-mxrhg deletion completed in 46.146628517s

• [SLOW TEST:50.412 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:18:31.750: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:19:31.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-27tzp" for this suite.
Apr 16 12:19:53.877: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:19:53.914: INFO: namespace: e2e-tests-container-probe-27tzp, resource: bindings, ignored listing per whitelist
Apr 16 12:19:53.991: INFO: namespace e2e-tests-container-probe-27tzp deletion completed in 22.132927876s

• [SLOW TEST:82.242 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:19:53.992: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Apr 16 12:19:54.076: INFO: Waiting up to 5m0s for pod "pod-f0cd8ce1-6041-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-emptydir-sjwrh" to be "success or failure"
Apr 16 12:19:54.080: INFO: Pod "pod-f0cd8ce1-6041-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.468719ms
Apr 16 12:19:56.085: INFO: Pod "pod-f0cd8ce1-6041-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008055203s
STEP: Saw pod success
Apr 16 12:19:56.085: INFO: Pod "pod-f0cd8ce1-6041-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 12:19:56.088: INFO: Trying to get logs from node k8s-1 pod pod-f0cd8ce1-6041-11e9-be7e-0a580ae9423f container test-container: <nil>
STEP: delete the pod
Apr 16 12:19:56.118: INFO: Waiting for pod pod-f0cd8ce1-6041-11e9-be7e-0a580ae9423f to disappear
Apr 16 12:19:56.121: INFO: Pod pod-f0cd8ce1-6041-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:19:56.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-sjwrh" for this suite.
Apr 16 12:20:02.144: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:20:02.244: INFO: namespace: e2e-tests-emptydir-sjwrh, resource: bindings, ignored listing per whitelist
Apr 16 12:20:02.276: INFO: namespace e2e-tests-emptydir-sjwrh deletion completed in 6.151179052s

• [SLOW TEST:8.284 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:20:02.277: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Apr 16 12:20:02.336: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 16 12:20:02.344: INFO: Waiting for terminating namespaces to be deleted...
Apr 16 12:20:02.348: INFO: 
Logging pods the kubelet thinks is on node k8s-1 before test
Apr 16 12:20:02.353: INFO: kube-flannel-fnd59 from kube-system started at 2019-04-16 09:04:20 +0000 UTC (2 container statuses recorded)
Apr 16 12:20:02.353: INFO: 	Container install-cni ready: true, restart count 0
Apr 16 12:20:02.353: INFO: 	Container kube-flannel ready: true, restart count 0
Apr 16 12:20:02.353: INFO: kube-apiserver-k8s-1 from kube-system started at <nil> (0 container statuses recorded)
Apr 16 12:20:02.353: INFO: kube-proxy-zmk77 from kube-system started at 2019-04-16 09:04:35 +0000 UTC (1 container statuses recorded)
Apr 16 12:20:02.353: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 16 12:20:02.353: INFO: kube-controller-manager-k8s-1 from kube-system started at <nil> (0 container statuses recorded)
Apr 16 12:20:02.353: INFO: kube-scheduler-k8s-1 from kube-system started at <nil> (0 container statuses recorded)
Apr 16 12:20:02.353: INFO: sonobuoy-systemd-logs-daemon-set-bd0902ee46574666-xtxss from heptio-sonobuoy started at 2019-04-16 11:31:01 +0000 UTC (2 container statuses recorded)
Apr 16 12:20:02.353: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 16 12:20:02.353: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 16 12:20:02.353: INFO: 
Logging pods the kubelet thinks is on node k8s-2 before test
Apr 16 12:20:02.358: INFO: kube-scheduler-k8s-2 from kube-system started at <nil> (0 container statuses recorded)
Apr 16 12:20:02.359: INFO: coredns-644c686c9-xkwgk from kube-system started at 2019-04-16 09:04:45 +0000 UTC (1 container statuses recorded)
Apr 16 12:20:02.359: INFO: 	Container coredns ready: true, restart count 0
Apr 16 12:20:02.359: INFO: sonobuoy-systemd-logs-daemon-set-bd0902ee46574666-6pmwz from heptio-sonobuoy started at 2019-04-16 11:31:01 +0000 UTC (2 container statuses recorded)
Apr 16 12:20:02.359: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 16 12:20:02.359: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 16 12:20:02.359: INFO: kube-flannel-zhgc5 from kube-system started at 2019-04-16 09:04:20 +0000 UTC (2 container statuses recorded)
Apr 16 12:20:02.359: INFO: 	Container install-cni ready: true, restart count 0
Apr 16 12:20:02.359: INFO: 	Container kube-flannel ready: true, restart count 0
Apr 16 12:20:02.359: INFO: kube-controller-manager-k8s-2 from kube-system started at <nil> (0 container statuses recorded)
Apr 16 12:20:02.359: INFO: kube-apiserver-k8s-2 from kube-system started at <nil> (0 container statuses recorded)
Apr 16 12:20:02.359: INFO: kube-proxy-zbpwt from kube-system started at 2019-04-16 09:04:46 +0000 UTC (1 container statuses recorded)
Apr 16 12:20:02.359: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 16 12:20:02.359: INFO: 
Logging pods the kubelet thinks is on node k8s-3 before test
Apr 16 12:20:02.365: INFO: nginx-proxy-k8s-3 from kube-system started at <nil> (0 container statuses recorded)
Apr 16 12:20:02.365: INFO: coredns-644c686c9-bjmcw from kube-system started at 2019-04-16 09:04:41 +0000 UTC (1 container statuses recorded)
Apr 16 12:20:02.365: INFO: 	Container coredns ready: true, restart count 0
Apr 16 12:20:02.365: INFO: kubernetes-dashboard-8457c55f89-sqzmm from kube-system started at 2019-04-16 09:04:46 +0000 UTC (1 container statuses recorded)
Apr 16 12:20:02.365: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Apr 16 12:20:02.365: INFO: sonobuoy-e2e-job-112a3508806440e9 from heptio-sonobuoy started at 2019-04-16 11:31:01 +0000 UTC (2 container statuses recorded)
Apr 16 12:20:02.366: INFO: 	Container e2e ready: true, restart count 0
Apr 16 12:20:02.366: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 16 12:20:02.366: INFO: sonobuoy-systemd-logs-daemon-set-bd0902ee46574666-rcqwb from heptio-sonobuoy started at 2019-04-16 11:31:01 +0000 UTC (2 container statuses recorded)
Apr 16 12:20:02.366: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 16 12:20:02.366: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 16 12:20:02.366: INFO: kube-flannel-ct7gl from kube-system started at 2019-04-16 09:04:19 +0000 UTC (2 container statuses recorded)
Apr 16 12:20:02.366: INFO: 	Container install-cni ready: true, restart count 0
Apr 16 12:20:02.366: INFO: 	Container kube-flannel ready: true, restart count 0
Apr 16 12:20:02.366: INFO: dns-autoscaler-586f58b8bf-rhxhm from kube-system started at 2019-04-16 09:04:43 +0000 UTC (1 container statuses recorded)
Apr 16 12:20:02.366: INFO: 	Container autoscaler ready: true, restart count 0
Apr 16 12:20:02.366: INFO: kube-proxy-7rzm9 from kube-system started at 2019-04-16 09:04:23 +0000 UTC (1 container statuses recorded)
Apr 16 12:20:02.366: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 16 12:20:02.366: INFO: sonobuoy from heptio-sonobuoy started at 2019-04-16 11:30:59 +0000 UTC (1 container statuses recorded)
Apr 16 12:20:02.366: INFO: 	Container kube-sonobuoy ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-f6fa6d6f-6041-11e9-be7e-0a580ae9423f 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-f6fa6d6f-6041-11e9-be7e-0a580ae9423f off the node k8s-2
STEP: verifying the node doesn't have the label kubernetes.io/e2e-f6fa6d6f-6041-11e9-be7e-0a580ae9423f
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:20:06.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-b7fkx" for this suite.
Apr 16 12:20:14.544: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:20:14.602: INFO: namespace: e2e-tests-sched-pred-b7fkx, resource: bindings, ignored listing per whitelist
Apr 16 12:20:14.715: INFO: namespace e2e-tests-sched-pred-b7fkx deletion completed in 8.200150469s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:12.438 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:20:14.716: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Apr 16 12:20:15.178: INFO: Pod name wrapped-volume-race-fd5ec834-6041-11e9-be7e-0a580ae9423f: Found 0 pods out of 5
Apr 16 12:20:20.185: INFO: Pod name wrapped-volume-race-fd5ec834-6041-11e9-be7e-0a580ae9423f: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-fd5ec834-6041-11e9-be7e-0a580ae9423f in namespace e2e-tests-emptydir-wrapper-gjmcq, will wait for the garbage collector to delete the pods
Apr 16 12:22:02.281: INFO: Deleting ReplicationController wrapped-volume-race-fd5ec834-6041-11e9-be7e-0a580ae9423f took: 9.00016ms
Apr 16 12:22:02.382: INFO: Terminating ReplicationController wrapped-volume-race-fd5ec834-6041-11e9-be7e-0a580ae9423f pods took: 100.518365ms
STEP: Creating RC which spawns configmap-volume pods
Apr 16 12:22:40.618: INFO: Pod name wrapped-volume-race-540e07e9-6042-11e9-be7e-0a580ae9423f: Found 0 pods out of 5
Apr 16 12:22:45.625: INFO: Pod name wrapped-volume-race-540e07e9-6042-11e9-be7e-0a580ae9423f: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-540e07e9-6042-11e9-be7e-0a580ae9423f in namespace e2e-tests-emptydir-wrapper-gjmcq, will wait for the garbage collector to delete the pods
Apr 16 12:24:39.720: INFO: Deleting ReplicationController wrapped-volume-race-540e07e9-6042-11e9-be7e-0a580ae9423f took: 9.888417ms
Apr 16 12:24:39.821: INFO: Terminating ReplicationController wrapped-volume-race-540e07e9-6042-11e9-be7e-0a580ae9423f pods took: 100.803214ms
STEP: Creating RC which spawns configmap-volume pods
Apr 16 12:25:20.063: INFO: Pod name wrapped-volume-race-b3169ca7-6042-11e9-be7e-0a580ae9423f: Found 0 pods out of 5
Apr 16 12:25:25.073: INFO: Pod name wrapped-volume-race-b3169ca7-6042-11e9-be7e-0a580ae9423f: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-b3169ca7-6042-11e9-be7e-0a580ae9423f in namespace e2e-tests-emptydir-wrapper-gjmcq, will wait for the garbage collector to delete the pods
Apr 16 12:28:11.180: INFO: Deleting ReplicationController wrapped-volume-race-b3169ca7-6042-11e9-be7e-0a580ae9423f took: 18.66408ms
Apr 16 12:28:11.280: INFO: Terminating ReplicationController wrapped-volume-race-b3169ca7-6042-11e9-be7e-0a580ae9423f pods took: 100.369438ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:28:50.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-gjmcq" for this suite.
Apr 16 12:28:58.196: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:28:58.301: INFO: namespace: e2e-tests-emptydir-wrapper-gjmcq, resource: bindings, ignored listing per whitelist
Apr 16 12:28:58.301: INFO: namespace e2e-tests-emptydir-wrapper-gjmcq deletion completed in 8.124626266s

• [SLOW TEST:523.585 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:28:58.301: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Apr 16 12:28:58.362: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-454217481 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:28:58.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-57hcl" for this suite.
Apr 16 12:29:04.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:29:04.513: INFO: namespace: e2e-tests-kubectl-57hcl, resource: bindings, ignored listing per whitelist
Apr 16 12:29:04.582: INFO: namespace e2e-tests-kubectl-57hcl deletion completed in 6.155173602s

• [SLOW TEST:6.281 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:29:04.582: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Apr 16 12:29:04.658: INFO: Waiting up to 5m0s for pod "var-expansion-38f973d4-6043-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-var-expansion-5sxq2" to be "success or failure"
Apr 16 12:29:04.662: INFO: Pod "var-expansion-38f973d4-6043-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.994609ms
Apr 16 12:29:06.668: INFO: Pod "var-expansion-38f973d4-6043-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010471028s
STEP: Saw pod success
Apr 16 12:29:06.668: INFO: Pod "var-expansion-38f973d4-6043-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 12:29:06.673: INFO: Trying to get logs from node k8s-3 pod var-expansion-38f973d4-6043-11e9-be7e-0a580ae9423f container dapi-container: <nil>
STEP: delete the pod
Apr 16 12:29:06.703: INFO: Waiting for pod var-expansion-38f973d4-6043-11e9-be7e-0a580ae9423f to disappear
Apr 16 12:29:06.707: INFO: Pod var-expansion-38f973d4-6043-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:29:06.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-5sxq2" for this suite.
Apr 16 12:29:12.739: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:29:12.770: INFO: namespace: e2e-tests-var-expansion-5sxq2, resource: bindings, ignored listing per whitelist
Apr 16 12:29:12.912: INFO: namespace e2e-tests-var-expansion-5sxq2 deletion completed in 6.196994204s

• [SLOW TEST:8.330 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:29:12.914: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Apr 16 12:29:13.068: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-zsbdb,SelfLink:/api/v1/namespaces/e2e-tests-watch-zsbdb/configmaps/e2e-watch-test-configmap-a,UID:3dfd546a-6043-11e9-8569-0800277031c6,ResourceVersion:26092,Generation:0,CreationTimestamp:2019-04-16 12:29:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr 16 12:29:13.068: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-zsbdb,SelfLink:/api/v1/namespaces/e2e-tests-watch-zsbdb/configmaps/e2e-watch-test-configmap-a,UID:3dfd546a-6043-11e9-8569-0800277031c6,ResourceVersion:26092,Generation:0,CreationTimestamp:2019-04-16 12:29:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Apr 16 12:29:23.088: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-zsbdb,SelfLink:/api/v1/namespaces/e2e-tests-watch-zsbdb/configmaps/e2e-watch-test-configmap-a,UID:3dfd546a-6043-11e9-8569-0800277031c6,ResourceVersion:26108,Generation:0,CreationTimestamp:2019-04-16 12:29:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Apr 16 12:29:23.088: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-zsbdb,SelfLink:/api/v1/namespaces/e2e-tests-watch-zsbdb/configmaps/e2e-watch-test-configmap-a,UID:3dfd546a-6043-11e9-8569-0800277031c6,ResourceVersion:26108,Generation:0,CreationTimestamp:2019-04-16 12:29:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Apr 16 12:29:33.104: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-zsbdb,SelfLink:/api/v1/namespaces/e2e-tests-watch-zsbdb/configmaps/e2e-watch-test-configmap-a,UID:3dfd546a-6043-11e9-8569-0800277031c6,ResourceVersion:26127,Generation:0,CreationTimestamp:2019-04-16 12:29:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr 16 12:29:33.104: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-zsbdb,SelfLink:/api/v1/namespaces/e2e-tests-watch-zsbdb/configmaps/e2e-watch-test-configmap-a,UID:3dfd546a-6043-11e9-8569-0800277031c6,ResourceVersion:26127,Generation:0,CreationTimestamp:2019-04-16 12:29:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Apr 16 12:29:43.123: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-zsbdb,SelfLink:/api/v1/namespaces/e2e-tests-watch-zsbdb/configmaps/e2e-watch-test-configmap-a,UID:3dfd546a-6043-11e9-8569-0800277031c6,ResourceVersion:26144,Generation:0,CreationTimestamp:2019-04-16 12:29:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr 16 12:29:43.123: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-zsbdb,SelfLink:/api/v1/namespaces/e2e-tests-watch-zsbdb/configmaps/e2e-watch-test-configmap-a,UID:3dfd546a-6043-11e9-8569-0800277031c6,ResourceVersion:26144,Generation:0,CreationTimestamp:2019-04-16 12:29:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Apr 16 12:29:53.138: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-zsbdb,SelfLink:/api/v1/namespaces/e2e-tests-watch-zsbdb/configmaps/e2e-watch-test-configmap-b,UID:55dfacaa-6043-11e9-8569-0800277031c6,ResourceVersion:26160,Generation:0,CreationTimestamp:2019-04-16 12:29:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr 16 12:29:53.139: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-zsbdb,SelfLink:/api/v1/namespaces/e2e-tests-watch-zsbdb/configmaps/e2e-watch-test-configmap-b,UID:55dfacaa-6043-11e9-8569-0800277031c6,ResourceVersion:26160,Generation:0,CreationTimestamp:2019-04-16 12:29:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Apr 16 12:30:03.179: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-zsbdb,SelfLink:/api/v1/namespaces/e2e-tests-watch-zsbdb/configmaps/e2e-watch-test-configmap-b,UID:55dfacaa-6043-11e9-8569-0800277031c6,ResourceVersion:26176,Generation:0,CreationTimestamp:2019-04-16 12:29:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr 16 12:30:03.179: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-zsbdb,SelfLink:/api/v1/namespaces/e2e-tests-watch-zsbdb/configmaps/e2e-watch-test-configmap-b,UID:55dfacaa-6043-11e9-8569-0800277031c6,ResourceVersion:26176,Generation:0,CreationTimestamp:2019-04-16 12:29:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:30:13.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-zsbdb" for this suite.
Apr 16 12:30:19.210: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:30:19.305: INFO: namespace: e2e-tests-watch-zsbdb, resource: bindings, ignored listing per whitelist
Apr 16 12:30:19.326: INFO: namespace e2e-tests-watch-zsbdb deletion completed in 6.134130976s

• [SLOW TEST:66.412 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:30:19.330: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Apr 16 12:30:19.443: INFO: Pod name pod-release: Found 0 pods out of 1
Apr 16 12:30:24.455: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:30:24.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-lgzsg" for this suite.
Apr 16 12:30:30.523: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:30:30.580: INFO: namespace: e2e-tests-replication-controller-lgzsg, resource: bindings, ignored listing per whitelist
Apr 16 12:30:30.680: INFO: namespace e2e-tests-replication-controller-lgzsg deletion completed in 6.19240383s

• [SLOW TEST:11.350 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:30:30.681: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Apr 16 12:30:30.807: INFO: Waiting up to 5m0s for pod "pod-6c50d8ca-6043-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-emptydir-l4vhh" to be "success or failure"
Apr 16 12:30:30.836: INFO: Pod "pod-6c50d8ca-6043-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 28.384844ms
Apr 16 12:30:32.840: INFO: Pod "pod-6c50d8ca-6043-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032704795s
Apr 16 12:30:34.852: INFO: Pod "pod-6c50d8ca-6043-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.044275113s
Apr 16 12:30:36.857: INFO: Pod "pod-6c50d8ca-6043-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.049362961s
Apr 16 12:30:38.863: INFO: Pod "pod-6c50d8ca-6043-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.055364799s
STEP: Saw pod success
Apr 16 12:30:38.863: INFO: Pod "pod-6c50d8ca-6043-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 12:30:38.867: INFO: Trying to get logs from node k8s-3 pod pod-6c50d8ca-6043-11e9-be7e-0a580ae9423f container test-container: <nil>
STEP: delete the pod
Apr 16 12:30:38.901: INFO: Waiting for pod pod-6c50d8ca-6043-11e9-be7e-0a580ae9423f to disappear
Apr 16 12:30:38.906: INFO: Pod pod-6c50d8ca-6043-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:30:38.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-l4vhh" for this suite.
Apr 16 12:30:44.932: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:30:44.969: INFO: namespace: e2e-tests-emptydir-l4vhh, resource: bindings, ignored listing per whitelist
Apr 16 12:30:45.033: INFO: namespace e2e-tests-emptydir-l4vhh deletion completed in 6.123336386s

• [SLOW TEST:14.353 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:30:45.034: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-74d968bc-6043-11e9-be7e-0a580ae9423f
STEP: Creating a pod to test consume configMaps
Apr 16 12:30:45.115: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-74da73f6-6043-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-projected-vlr5m" to be "success or failure"
Apr 16 12:30:45.128: INFO: Pod "pod-projected-configmaps-74da73f6-6043-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 12.689092ms
Apr 16 12:30:47.136: INFO: Pod "pod-projected-configmaps-74da73f6-6043-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020973506s
STEP: Saw pod success
Apr 16 12:30:47.136: INFO: Pod "pod-projected-configmaps-74da73f6-6043-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 12:30:47.217: INFO: Trying to get logs from node k8s-1 pod pod-projected-configmaps-74da73f6-6043-11e9-be7e-0a580ae9423f container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 16 12:30:47.256: INFO: Waiting for pod pod-projected-configmaps-74da73f6-6043-11e9-be7e-0a580ae9423f to disappear
Apr 16 12:30:47.270: INFO: Pod pod-projected-configmaps-74da73f6-6043-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:30:47.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vlr5m" for this suite.
Apr 16 12:30:53.308: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:30:53.330: INFO: namespace: e2e-tests-projected-vlr5m, resource: bindings, ignored listing per whitelist
Apr 16 12:30:53.440: INFO: namespace e2e-tests-projected-vlr5m deletion completed in 6.160440227s

• [SLOW TEST:8.406 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:30:53.442: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Apr 16 12:30:53.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 version --client'
Apr 16 12:30:53.664: INFO: stderr: ""
Apr 16 12:30:53.664: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Apr 16 12:30:53.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 create -f - --namespace=e2e-tests-kubectl-bswxs'
Apr 16 12:30:54.284: INFO: stderr: ""
Apr 16 12:30:54.284: INFO: stdout: "replicationcontroller/redis-master created\n"
Apr 16 12:30:54.284: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 create -f - --namespace=e2e-tests-kubectl-bswxs'
Apr 16 12:30:54.715: INFO: stderr: ""
Apr 16 12:30:54.715: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Apr 16 12:30:55.733: INFO: Selector matched 1 pods for map[app:redis]
Apr 16 12:30:55.733: INFO: Found 0 / 1
Apr 16 12:30:56.721: INFO: Selector matched 1 pods for map[app:redis]
Apr 16 12:30:56.721: INFO: Found 1 / 1
Apr 16 12:30:56.721: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr 16 12:30:56.725: INFO: Selector matched 1 pods for map[app:redis]
Apr 16 12:30:56.725: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 16 12:30:56.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 describe pod redis-master-dqg9f --namespace=e2e-tests-kubectl-bswxs'
Apr 16 12:30:56.837: INFO: stderr: ""
Apr 16 12:30:56.837: INFO: stdout: "Name:               redis-master-dqg9f\nNamespace:          e2e-tests-kubectl-bswxs\nPriority:           0\nPriorityClassName:  <none>\nNode:               k8s-2/172.17.8.102\nStart Time:         Tue, 16 Apr 2019 12:30:54 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.233.65.105\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://6a3c5b319ddd641e36d6e6d9bdd517b72b1cf1edadf1b707998dc94882bbeff5\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 16 Apr 2019 12:30:55 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-2bsfr (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-2bsfr:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-2bsfr\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned e2e-tests-kubectl-bswxs/redis-master-dqg9f to k8s-2\n  Normal  Pulled     1s    kubelet, k8s-2     Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, k8s-2     Created container\n  Normal  Started    1s    kubelet, k8s-2     Started container\n"
Apr 16 12:30:56.837: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 describe rc redis-master --namespace=e2e-tests-kubectl-bswxs'
Apr 16 12:30:56.971: INFO: stderr: ""
Apr 16 12:30:56.971: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-bswxs\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-dqg9f\n"
Apr 16 12:30:56.971: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 describe service redis-master --namespace=e2e-tests-kubectl-bswxs'
Apr 16 12:30:57.080: INFO: stderr: ""
Apr 16 12:30:57.080: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-bswxs\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.233.34.139\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.233.65.105:6379\nSession Affinity:  None\nEvents:            <none>\n"
Apr 16 12:30:57.086: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 describe node k8s-1'
Apr 16 12:30:57.219: INFO: stderr: ""
Apr 16 12:30:57.219: INFO: stdout: "Name:               k8s-1\nRoles:              master,node\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/hostname=k8s-1\n                    node-role.kubernetes.io/master=\n                    node-role.kubernetes.io/node=\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"e6:66:a8:49:1e:33\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 172.17.8.101\n                    kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 16 Apr 2019 09:02:47 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Tue, 16 Apr 2019 12:30:52 +0000   Tue, 16 Apr 2019 09:02:39 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Tue, 16 Apr 2019 12:30:52 +0000   Tue, 16 Apr 2019 09:02:39 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Tue, 16 Apr 2019 12:30:52 +0000   Tue, 16 Apr 2019 09:02:39 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Tue, 16 Apr 2019 12:30:52 +0000   Tue, 16 Apr 2019 09:04:35 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  172.17.8.101\n  Hostname:    k8s-1\nCapacity:\n cpu:                1\n ephemeral-storage:  30435260Ki\n hugepages-2Mi:      0\n memory:             2041304Ki\n pods:               110\nAllocatable:\n cpu:                800m\n ephemeral-storage:  28049135570\n hugepages-2Mi:      0\n memory:             1438904Ki\n pods:               110\nSystem Info:\n Machine ID:                 30568a068af44703af9619bbb6dfcf03\n System UUID:                3EB07BBB-E66A-4E7C-A4BD-02CEFDDEF5FD\n Boot ID:                    cd068b36-761e-4d88-b1d5-d081ad100fa8\n Kernel Version:             4.15.0-44-generic\n OS Image:                   Ubuntu 18.04.1 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.2\n Kubelet Version:            v1.13.5\n Kube-Proxy Version:         v1.13.5\nPodCIDR:                     10.233.64.0/24\nNon-terminated Pods:         (6 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-bd0902ee46574666-xtxss    0 (0%)        0 (0%)      0 (0%)           0 (0%)         59m\n  kube-system                kube-apiserver-k8s-1                                       250m (31%)    0 (0%)      0 (0%)           0 (0%)         3h18m\n  kube-system                kube-controller-manager-k8s-1                              200m (25%)    0 (0%)      0 (0%)           0 (0%)         3h27m\n  kube-system                kube-flannel-fnd59                                         150m (18%)    300m (37%)  64M (4%)         500M (33%)     3h26m\n  kube-system                kube-proxy-zmk77                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         3h26m\n  kube-system                kube-scheduler-k8s-1                                       100m (12%)    0 (0%)      0 (0%)           0 (0%)         3h27m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                700m (87%)  300m (37%)\n  memory             64M (4%)    500M (33%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:              <none>\n"
Apr 16 12:30:57.219: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 describe namespace e2e-tests-kubectl-bswxs'
Apr 16 12:30:57.437: INFO: stderr: ""
Apr 16 12:30:57.437: INFO: stdout: "Name:         e2e-tests-kubectl-bswxs\nLabels:       e2e-framework=kubectl\n              e2e-run=2f490ef8-603b-11e9-be7e-0a580ae9423f\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:30:57.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bswxs" for this suite.
Apr 16 12:31:21.479: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:31:21.813: INFO: namespace: e2e-tests-kubectl-bswxs, resource: bindings, ignored listing per whitelist
Apr 16 12:31:21.814: INFO: namespace e2e-tests-kubectl-bswxs deletion completed in 24.368080802s

• [SLOW TEST:28.372 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:31:21.820: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-8ae5cc1f-6043-11e9-be7e-0a580ae9423f
STEP: Creating a pod to test consume configMaps
Apr 16 12:31:22.189: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8aea4957-6043-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-projected-hnxkw" to be "success or failure"
Apr 16 12:31:22.250: INFO: Pod "pod-projected-configmaps-8aea4957-6043-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 60.825261ms
Apr 16 12:31:24.277: INFO: Pod "pod-projected-configmaps-8aea4957-6043-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.088093422s
Apr 16 12:31:26.286: INFO: Pod "pod-projected-configmaps-8aea4957-6043-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.096397846s
STEP: Saw pod success
Apr 16 12:31:26.286: INFO: Pod "pod-projected-configmaps-8aea4957-6043-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 12:31:26.300: INFO: Trying to get logs from node k8s-3 pod pod-projected-configmaps-8aea4957-6043-11e9-be7e-0a580ae9423f container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 16 12:31:26.442: INFO: Waiting for pod pod-projected-configmaps-8aea4957-6043-11e9-be7e-0a580ae9423f to disappear
Apr 16 12:31:26.456: INFO: Pod pod-projected-configmaps-8aea4957-6043-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:31:26.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hnxkw" for this suite.
Apr 16 12:31:32.523: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:31:32.964: INFO: namespace: e2e-tests-projected-hnxkw, resource: bindings, ignored listing per whitelist
Apr 16 12:31:32.978: INFO: namespace e2e-tests-projected-hnxkw deletion completed in 6.506728721s

• [SLOW TEST:11.159 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:31:32.978: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-9177f91f-6043-11e9-be7e-0a580ae9423f
STEP: Creating a pod to test consume secrets
Apr 16 12:31:33.153: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-917adbbd-6043-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-projected-845h9" to be "success or failure"
Apr 16 12:31:33.175: INFO: Pod "pod-projected-secrets-917adbbd-6043-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 21.908486ms
Apr 16 12:31:35.179: INFO: Pod "pod-projected-secrets-917adbbd-6043-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02609179s
Apr 16 12:31:37.197: INFO: Pod "pod-projected-secrets-917adbbd-6043-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.043197187s
STEP: Saw pod success
Apr 16 12:31:37.197: INFO: Pod "pod-projected-secrets-917adbbd-6043-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 12:31:37.217: INFO: Trying to get logs from node k8s-1 pod pod-projected-secrets-917adbbd-6043-11e9-be7e-0a580ae9423f container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 16 12:31:37.466: INFO: Waiting for pod pod-projected-secrets-917adbbd-6043-11e9-be7e-0a580ae9423f to disappear
Apr 16 12:31:37.486: INFO: Pod pod-projected-secrets-917adbbd-6043-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:31:37.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-845h9" for this suite.
Apr 16 12:31:43.743: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:31:43.967: INFO: namespace: e2e-tests-projected-845h9, resource: bindings, ignored listing per whitelist
Apr 16 12:31:44.165: INFO: namespace e2e-tests-projected-845h9 deletion completed in 6.493687135s

• [SLOW TEST:11.186 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:31:44.165: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Apr 16 12:31:44.349: INFO: Creating ReplicaSet my-hostname-basic-982a3afd-6043-11e9-be7e-0a580ae9423f
Apr 16 12:31:44.389: INFO: Pod name my-hostname-basic-982a3afd-6043-11e9-be7e-0a580ae9423f: Found 0 pods out of 1
Apr 16 12:31:49.399: INFO: Pod name my-hostname-basic-982a3afd-6043-11e9-be7e-0a580ae9423f: Found 1 pods out of 1
Apr 16 12:31:49.399: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-982a3afd-6043-11e9-be7e-0a580ae9423f" is running
Apr 16 12:31:49.409: INFO: Pod "my-hostname-basic-982a3afd-6043-11e9-be7e-0a580ae9423f-b7kj5" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-16 12:31:44 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-16 12:31:46 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-16 12:31:46 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-16 12:31:44 +0000 UTC Reason: Message:}])
Apr 16 12:31:49.409: INFO: Trying to dial the pod
Apr 16 12:31:54.722: INFO: Controller my-hostname-basic-982a3afd-6043-11e9-be7e-0a580ae9423f: Got expected result from replica 1 [my-hostname-basic-982a3afd-6043-11e9-be7e-0a580ae9423f-b7kj5]: "my-hostname-basic-982a3afd-6043-11e9-be7e-0a580ae9423f-b7kj5", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:31:54.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-hvnxp" for this suite.
Apr 16 12:32:04.976: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:32:05.086: INFO: namespace: e2e-tests-replicaset-hvnxp, resource: bindings, ignored listing per whitelist
Apr 16 12:32:07.042: INFO: namespace e2e-tests-replicaset-hvnxp deletion completed in 12.284365569s

• [SLOW TEST:22.881 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:32:07.053: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Apr 16 12:32:11.060: INFO: Waiting up to 5m0s for pod "client-containers-a7e68506-6043-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-containers-fwhcd" to be "success or failure"
Apr 16 12:32:11.112: INFO: Pod "client-containers-a7e68506-6043-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 51.354963ms
Apr 16 12:32:13.125: INFO: Pod "client-containers-a7e68506-6043-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.064586733s
Apr 16 12:32:15.317: INFO: Pod "client-containers-a7e68506-6043-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.25672484s
Apr 16 12:32:17.420: INFO: Pod "client-containers-a7e68506-6043-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.359546746s
STEP: Saw pod success
Apr 16 12:32:17.420: INFO: Pod "client-containers-a7e68506-6043-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 12:32:17.446: INFO: Trying to get logs from node k8s-3 pod client-containers-a7e68506-6043-11e9-be7e-0a580ae9423f container test-container: <nil>
STEP: delete the pod
Apr 16 12:32:17.741: INFO: Waiting for pod client-containers-a7e68506-6043-11e9-be7e-0a580ae9423f to disappear
Apr 16 12:32:17.752: INFO: Pod client-containers-a7e68506-6043-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:32:17.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-fwhcd" for this suite.
Apr 16 12:32:23.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:32:23.892: INFO: namespace: e2e-tests-containers-fwhcd, resource: bindings, ignored listing per whitelist
Apr 16 12:32:24.013: INFO: namespace e2e-tests-containers-fwhcd deletion completed in 6.243899258s

• [SLOW TEST:16.960 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:32:24.014: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-afd8a8ea-6043-11e9-be7e-0a580ae9423f
STEP: Creating a pod to test consume configMaps
Apr 16 12:32:24.097: INFO: Waiting up to 5m0s for pod "pod-configmaps-afd9f399-6043-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-configmap-ss6z9" to be "success or failure"
Apr 16 12:32:24.104: INFO: Pod "pod-configmaps-afd9f399-6043-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.699817ms
Apr 16 12:32:26.117: INFO: Pod "pod-configmaps-afd9f399-6043-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019620254s
STEP: Saw pod success
Apr 16 12:32:26.117: INFO: Pod "pod-configmaps-afd9f399-6043-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 12:32:26.129: INFO: Trying to get logs from node k8s-1 pod pod-configmaps-afd9f399-6043-11e9-be7e-0a580ae9423f container configmap-volume-test: <nil>
STEP: delete the pod
Apr 16 12:32:26.195: INFO: Waiting for pod pod-configmaps-afd9f399-6043-11e9-be7e-0a580ae9423f to disappear
Apr 16 12:32:26.203: INFO: Pod pod-configmaps-afd9f399-6043-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:32:26.203: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-ss6z9" for this suite.
Apr 16 12:32:32.232: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:32:32.298: INFO: namespace: e2e-tests-configmap-ss6z9, resource: bindings, ignored listing per whitelist
Apr 16 12:32:32.334: INFO: namespace e2e-tests-configmap-ss6z9 deletion completed in 6.125644244s

• [SLOW TEST:8.321 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:32:32.336: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Apr 16 12:32:37.467: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:32:37.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-bjdln" for this suite.
Apr 16 12:32:59.530: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:32:59.610: INFO: namespace: e2e-tests-replicaset-bjdln, resource: bindings, ignored listing per whitelist
Apr 16 12:32:59.628: INFO: namespace e2e-tests-replicaset-bjdln deletion completed in 22.131842703s

• [SLOW TEST:27.292 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:32:59.630: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-c514002a-6043-11e9-be7e-0a580ae9423f
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-c514002a-6043-11e9-be7e-0a580ae9423f
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:33:03.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-xhls2" for this suite.
Apr 16 12:33:25.799: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:33:25.858: INFO: namespace: e2e-tests-configmap-xhls2, resource: bindings, ignored listing per whitelist
Apr 16 12:33:25.901: INFO: namespace e2e-tests-configmap-xhls2 deletion completed in 22.121186002s

• [SLOW TEST:26.271 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:33:25.904: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Apr 16 12:33:25.977: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-454217481 proxy --unix-socket=/tmp/kubectl-proxy-unix596983508/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:33:26.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-59xxn" for this suite.
Apr 16 12:33:32.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:33:32.104: INFO: namespace: e2e-tests-kubectl-59xxn, resource: bindings, ignored listing per whitelist
Apr 16 12:33:32.163: INFO: namespace e2e-tests-kubectl-59xxn deletion completed in 6.131355645s

• [SLOW TEST:6.259 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:33:32.164: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-d876f90c-6043-11e9-be7e-0a580ae9423f
STEP: Creating a pod to test consume configMaps
Apr 16 12:33:32.242: INFO: Waiting up to 5m0s for pod "pod-configmaps-d8782a4b-6043-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-configmap-scz7x" to be "success or failure"
Apr 16 12:33:32.253: INFO: Pod "pod-configmaps-d8782a4b-6043-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.976223ms
Apr 16 12:33:34.258: INFO: Pod "pod-configmaps-d8782a4b-6043-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015770746s
STEP: Saw pod success
Apr 16 12:33:34.258: INFO: Pod "pod-configmaps-d8782a4b-6043-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 12:33:34.262: INFO: Trying to get logs from node k8s-2 pod pod-configmaps-d8782a4b-6043-11e9-be7e-0a580ae9423f container configmap-volume-test: <nil>
STEP: delete the pod
Apr 16 12:33:34.300: INFO: Waiting for pod pod-configmaps-d8782a4b-6043-11e9-be7e-0a580ae9423f to disappear
Apr 16 12:33:34.304: INFO: Pod pod-configmaps-d8782a4b-6043-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:33:34.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-scz7x" for this suite.
Apr 16 12:33:40.324: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:33:40.414: INFO: namespace: e2e-tests-configmap-scz7x, resource: bindings, ignored listing per whitelist
Apr 16 12:33:40.422: INFO: namespace e2e-tests-configmap-scz7x deletion completed in 6.114219443s

• [SLOW TEST:8.258 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:33:40.423: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0416 12:34:20.545443      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr 16 12:34:20.545: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:34:20.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-gr8v4" for this suite.
Apr 16 12:34:26.579: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:34:26.738: INFO: namespace: e2e-tests-gc-gr8v4, resource: bindings, ignored listing per whitelist
Apr 16 12:34:26.861: INFO: namespace e2e-tests-gc-gr8v4 deletion completed in 6.30750851s

• [SLOW TEST:46.437 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:34:26.861: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Apr 16 12:34:27.115: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 create -f - --namespace=e2e-tests-kubectl-4flzg'
Apr 16 12:34:27.502: INFO: stderr: ""
Apr 16 12:34:27.502: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Apr 16 12:34:28.513: INFO: Selector matched 1 pods for map[app:redis]
Apr 16 12:34:28.513: INFO: Found 0 / 1
Apr 16 12:34:29.507: INFO: Selector matched 1 pods for map[app:redis]
Apr 16 12:34:29.507: INFO: Found 1 / 1
Apr 16 12:34:29.507: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Apr 16 12:34:29.515: INFO: Selector matched 1 pods for map[app:redis]
Apr 16 12:34:29.515: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 16 12:34:29.515: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 patch pod redis-master-6wcq8 --namespace=e2e-tests-kubectl-4flzg -p {"metadata":{"annotations":{"x":"y"}}}'
Apr 16 12:34:29.604: INFO: stderr: ""
Apr 16 12:34:29.604: INFO: stdout: "pod/redis-master-6wcq8 patched\n"
STEP: checking annotations
Apr 16 12:34:29.609: INFO: Selector matched 1 pods for map[app:redis]
Apr 16 12:34:29.609: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:34:29.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-4flzg" for this suite.
Apr 16 12:34:51.632: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:34:51.720: INFO: namespace: e2e-tests-kubectl-4flzg, resource: bindings, ignored listing per whitelist
Apr 16 12:34:51.727: INFO: namespace e2e-tests-kubectl-4flzg deletion completed in 22.113442883s

• [SLOW TEST:24.866 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:34:51.729: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Apr 16 12:34:51.801: INFO: Waiting up to 5m0s for pod "pod-07e3b622-6044-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-emptydir-92ncz" to be "success or failure"
Apr 16 12:34:51.805: INFO: Pod "pod-07e3b622-6044-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.63866ms
Apr 16 12:34:53.817: INFO: Pod "pod-07e3b622-6044-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015826626s
STEP: Saw pod success
Apr 16 12:34:53.817: INFO: Pod "pod-07e3b622-6044-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 12:34:53.821: INFO: Trying to get logs from node k8s-2 pod pod-07e3b622-6044-11e9-be7e-0a580ae9423f container test-container: <nil>
STEP: delete the pod
Apr 16 12:34:53.857: INFO: Waiting for pod pod-07e3b622-6044-11e9-be7e-0a580ae9423f to disappear
Apr 16 12:34:53.861: INFO: Pod pod-07e3b622-6044-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:34:53.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-92ncz" for this suite.
Apr 16 12:34:59.883: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:34:59.960: INFO: namespace: e2e-tests-emptydir-92ncz, resource: bindings, ignored listing per whitelist
Apr 16 12:34:59.991: INFO: namespace e2e-tests-emptydir-92ncz deletion completed in 6.125524432s

• [SLOW TEST:8.262 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:34:59.993: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Apr 16 12:35:02.610: INFO: Successfully updated pod "pod-update-0cd34c4d-6044-11e9-be7e-0a580ae9423f"
STEP: verifying the updated pod is in kubernetes
Apr 16 12:35:02.621: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:35:02.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-fwgnq" for this suite.
Apr 16 12:35:20.645: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:35:20.671: INFO: namespace: e2e-tests-pods-fwgnq, resource: bindings, ignored listing per whitelist
Apr 16 12:35:20.741: INFO: namespace e2e-tests-pods-fwgnq deletion completed in 18.113800435s

• [SLOW TEST:20.748 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:35:20.742: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 16 12:35:20.807: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-d2dkt'
Apr 16 12:35:20.904: INFO: stderr: ""
Apr 16 12:35:20.904: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Apr 16 12:35:25.954: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-d2dkt -o json'
Apr 16 12:35:26.027: INFO: stderr: ""
Apr 16 12:35:26.027: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-04-16T12:35:20Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-d2dkt\",\n        \"resourceVersion\": \"27379\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-d2dkt/pods/e2e-test-nginx-pod\",\n        \"uid\": \"193b2fb1-6044-11e9-8569-0800277031c6\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-q5df7\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"k8s-1\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-q5df7\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-q5df7\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-04-16T12:35:20Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-04-16T12:35:22Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-04-16T12:35:22Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-04-16T12:35:20Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://c2fbbd604648c5d086277133d36a7391f1640d61830e1a3a906e12afe0b41768\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-04-16T12:35:21Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.17.8.101\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.233.64.144\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-04-16T12:35:20Z\"\n    }\n}\n"
STEP: replace the image in the pod
Apr 16 12:35:26.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 replace -f - --namespace=e2e-tests-kubectl-d2dkt'
Apr 16 12:35:26.189: INFO: stderr: ""
Apr 16 12:35:26.189: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
Apr 16 12:35:26.193: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-d2dkt'
Apr 16 12:35:28.294: INFO: stderr: ""
Apr 16 12:35:28.294: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:35:28.294: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-d2dkt" for this suite.
Apr 16 12:35:34.328: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:35:34.374: INFO: namespace: e2e-tests-kubectl-d2dkt, resource: bindings, ignored listing per whitelist
Apr 16 12:35:34.423: INFO: namespace e2e-tests-kubectl-d2dkt deletion completed in 6.113422031s

• [SLOW TEST:13.681 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:35:34.424: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0416 12:35:40.544751      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr 16 12:35:40.544: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:35:40.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-2fdz5" for this suite.
Apr 16 12:35:46.569: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:35:46.697: INFO: namespace: e2e-tests-gc-2fdz5, resource: bindings, ignored listing per whitelist
Apr 16 12:35:46.714: INFO: namespace e2e-tests-gc-2fdz5 deletion completed in 6.163847929s

• [SLOW TEST:12.290 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:35:46.715: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Apr 16 12:35:46.836: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Apr 16 12:35:46.867: INFO: Number of nodes with available pods: 0
Apr 16 12:35:46.867: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:35:47.875: INFO: Number of nodes with available pods: 0
Apr 16 12:35:47.875: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:35:48.878: INFO: Number of nodes with available pods: 3
Apr 16 12:35:48.879: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Apr 16 12:35:48.912: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:35:48.912: INFO: Wrong image for pod: daemon-set-ml7p2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:35:48.912: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:35:49.927: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:35:49.927: INFO: Wrong image for pod: daemon-set-ml7p2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:35:49.927: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:35:50.921: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:35:50.921: INFO: Wrong image for pod: daemon-set-ml7p2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:35:50.921: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:35:51.924: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:35:51.924: INFO: Wrong image for pod: daemon-set-ml7p2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:35:51.924: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:35:52.924: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:35:52.924: INFO: Wrong image for pod: daemon-set-ml7p2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:35:52.924: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:35:53.921: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:35:53.921: INFO: Wrong image for pod: daemon-set-ml7p2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:35:53.921: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:35:54.921: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:35:54.921: INFO: Wrong image for pod: daemon-set-ml7p2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:35:54.921: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:35:55.921: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:35:55.921: INFO: Wrong image for pod: daemon-set-ml7p2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:35:55.921: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:35:56.920: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:35:56.920: INFO: Wrong image for pod: daemon-set-ml7p2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:35:56.920: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:35:57.921: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:35:57.921: INFO: Wrong image for pod: daemon-set-ml7p2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:35:57.921: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:35:58.921: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:35:58.921: INFO: Wrong image for pod: daemon-set-ml7p2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:35:58.921: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:35:59.922: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:35:59.922: INFO: Wrong image for pod: daemon-set-ml7p2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:35:59.922: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:00.922: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:00.922: INFO: Wrong image for pod: daemon-set-ml7p2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:00.922: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:01.922: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:01.922: INFO: Wrong image for pod: daemon-set-ml7p2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:01.922: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:02.921: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:02.921: INFO: Wrong image for pod: daemon-set-ml7p2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:02.921: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:03.922: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:03.922: INFO: Wrong image for pod: daemon-set-ml7p2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:03.922: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:04.922: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:04.922: INFO: Wrong image for pod: daemon-set-ml7p2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:04.922: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:05.920: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:05.920: INFO: Wrong image for pod: daemon-set-ml7p2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:05.920: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:06.921: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:06.921: INFO: Wrong image for pod: daemon-set-ml7p2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:06.921: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:07.922: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:07.922: INFO: Wrong image for pod: daemon-set-ml7p2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:07.922: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:08.921: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:08.921: INFO: Wrong image for pod: daemon-set-ml7p2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:08.921: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:09.920: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:09.920: INFO: Wrong image for pod: daemon-set-ml7p2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:09.920: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:10.927: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:10.927: INFO: Wrong image for pod: daemon-set-ml7p2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:10.927: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:11.921: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:11.922: INFO: Wrong image for pod: daemon-set-ml7p2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:11.922: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:12.920: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:12.920: INFO: Wrong image for pod: daemon-set-ml7p2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:12.920: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:13.920: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:13.920: INFO: Wrong image for pod: daemon-set-ml7p2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:13.920: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:14.920: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:14.920: INFO: Wrong image for pod: daemon-set-ml7p2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:14.920: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:15.921: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:15.921: INFO: Wrong image for pod: daemon-set-ml7p2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:15.921: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:16.922: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:16.922: INFO: Wrong image for pod: daemon-set-ml7p2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:16.922: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:17.921: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:17.921: INFO: Wrong image for pod: daemon-set-ml7p2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:17.921: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:18.921: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:18.921: INFO: Wrong image for pod: daemon-set-ml7p2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:18.921: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:19.921: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:19.921: INFO: Wrong image for pod: daemon-set-ml7p2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:19.921: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:20.922: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:20.922: INFO: Wrong image for pod: daemon-set-ml7p2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:20.922: INFO: Pod daemon-set-ml7p2 is not available
Apr 16 12:36:20.922: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:21.925: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:21.926: INFO: Wrong image for pod: daemon-set-ml7p2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:21.926: INFO: Pod daemon-set-ml7p2 is not available
Apr 16 12:36:21.926: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:22.921: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:22.921: INFO: Wrong image for pod: daemon-set-ml7p2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:22.921: INFO: Pod daemon-set-ml7p2 is not available
Apr 16 12:36:22.921: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:23.921: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:23.921: INFO: Wrong image for pod: daemon-set-ml7p2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:23.921: INFO: Pod daemon-set-ml7p2 is not available
Apr 16 12:36:23.921: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:24.922: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:24.922: INFO: Wrong image for pod: daemon-set-ml7p2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:24.922: INFO: Pod daemon-set-ml7p2 is not available
Apr 16 12:36:24.922: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:25.922: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:25.922: INFO: Wrong image for pod: daemon-set-ml7p2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:25.922: INFO: Pod daemon-set-ml7p2 is not available
Apr 16 12:36:25.922: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:26.921: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:26.921: INFO: Pod daemon-set-9cb99 is not available
Apr 16 12:36:26.921: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:27.923: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:27.923: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:28.921: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:28.921: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:29.921: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:29.921: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:30.920: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:30.920: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:31.920: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:31.920: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:32.926: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:32.926: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:33.921: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:33.921: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:34.920: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:34.920: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:35.921: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:35.921: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:36.921: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:36.921: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:37.921: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:37.922: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:38.921: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:38.921: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:39.921: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:39.921: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:40.920: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:40.921: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:41.920: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:41.920: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:42.920: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:42.920: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:43.927: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:43.927: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:44.921: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:44.922: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:45.921: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:45.921: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:46.920: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:46.921: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:47.921: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:47.921: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:48.923: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:48.923: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:49.921: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:49.921: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:50.922: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:50.922: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:51.922: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:51.922: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:52.919: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:52.919: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:53.927: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:53.927: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:54.923: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:54.923: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:55.922: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:55.922: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:56.922: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:56.922: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:57.922: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:57.923: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:58.921: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:58.921: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:58.921: INFO: Pod daemon-set-xj9k6 is not available
Apr 16 12:36:59.921: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:59.921: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:36:59.921: INFO: Pod daemon-set-xj9k6 is not available
Apr 16 12:37:00.921: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:00.921: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:00.921: INFO: Pod daemon-set-xj9k6 is not available
Apr 16 12:37:01.923: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:01.923: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:01.923: INFO: Pod daemon-set-xj9k6 is not available
Apr 16 12:37:02.923: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:02.923: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:02.923: INFO: Pod daemon-set-xj9k6 is not available
Apr 16 12:37:03.924: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:03.925: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:03.925: INFO: Pod daemon-set-xj9k6 is not available
Apr 16 12:37:04.927: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:04.927: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:04.927: INFO: Pod daemon-set-xj9k6 is not available
Apr 16 12:37:05.925: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:05.925: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:05.925: INFO: Pod daemon-set-xj9k6 is not available
Apr 16 12:37:06.924: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:06.924: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:06.924: INFO: Pod daemon-set-xj9k6 is not available
Apr 16 12:37:07.921: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:07.921: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:07.921: INFO: Pod daemon-set-xj9k6 is not available
Apr 16 12:37:08.921: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:08.921: INFO: Wrong image for pod: daemon-set-xj9k6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:08.921: INFO: Pod daemon-set-xj9k6 is not available
Apr 16 12:37:09.923: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:09.923: INFO: Pod daemon-set-zklcl is not available
Apr 16 12:37:10.920: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:10.920: INFO: Pod daemon-set-zklcl is not available
Apr 16 12:37:11.923: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:12.921: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:13.921: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:14.920: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:15.926: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:16.920: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:17.921: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:18.920: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:19.920: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:20.920: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:21.923: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:22.921: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:23.921: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:24.921: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:25.921: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:26.927: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:27.922: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:28.923: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:29.921: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:30.923: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:31.920: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:32.920: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:33.922: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:34.921: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:35.921: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:36.928: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:37.922: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:38.922: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:39.922: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:40.922: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:41.921: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:42.921: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:42.921: INFO: Pod daemon-set-6brqh is not available
Apr 16 12:37:43.920: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:43.921: INFO: Pod daemon-set-6brqh is not available
Apr 16 12:37:44.921: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:44.921: INFO: Pod daemon-set-6brqh is not available
Apr 16 12:37:45.921: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:45.921: INFO: Pod daemon-set-6brqh is not available
Apr 16 12:37:46.921: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:46.921: INFO: Pod daemon-set-6brqh is not available
Apr 16 12:37:47.928: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:47.928: INFO: Pod daemon-set-6brqh is not available
Apr 16 12:37:48.921: INFO: Wrong image for pod: daemon-set-6brqh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 16 12:37:48.921: INFO: Pod daemon-set-6brqh is not available
Apr 16 12:37:49.933: INFO: Pod daemon-set-8tzxn is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Apr 16 12:37:49.966: INFO: Number of nodes with available pods: 2
Apr 16 12:37:49.966: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:37:50.975: INFO: Number of nodes with available pods: 2
Apr 16 12:37:50.975: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:37:51.977: INFO: Number of nodes with available pods: 3
Apr 16 12:37:51.977: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-2b82w, will wait for the garbage collector to delete the pods
Apr 16 12:37:52.058: INFO: Deleting DaemonSet.extensions daemon-set took: 11.099199ms
Apr 16 12:37:52.159: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.565003ms
Apr 16 12:37:59.671: INFO: Number of nodes with available pods: 0
Apr 16 12:37:59.671: INFO: Number of running nodes: 0, number of available pods: 0
Apr 16 12:37:59.675: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-2b82w/daemonsets","resourceVersion":"27972"},"items":null}

Apr 16 12:37:59.682: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-2b82w/pods","resourceVersion":"27972"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:37:59.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-2b82w" for this suite.
Apr 16 12:38:05.735: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:38:05.796: INFO: namespace: e2e-tests-daemonsets-2b82w, resource: bindings, ignored listing per whitelist
Apr 16 12:38:05.843: INFO: namespace e2e-tests-daemonsets-2b82w deletion completed in 6.134904199s

• [SLOW TEST:139.128 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:38:05.845: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-7b990ad2-6044-11e9-be7e-0a580ae9423f
STEP: Creating a pod to test consume configMaps
Apr 16 12:38:05.933: INFO: Waiting up to 5m0s for pod "pod-configmaps-7b9a2132-6044-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-configmap-wsvdk" to be "success or failure"
Apr 16 12:38:05.941: INFO: Pod "pod-configmaps-7b9a2132-6044-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.043029ms
Apr 16 12:38:07.947: INFO: Pod "pod-configmaps-7b9a2132-6044-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013773794s
STEP: Saw pod success
Apr 16 12:38:07.947: INFO: Pod "pod-configmaps-7b9a2132-6044-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 12:38:07.952: INFO: Trying to get logs from node k8s-3 pod pod-configmaps-7b9a2132-6044-11e9-be7e-0a580ae9423f container configmap-volume-test: <nil>
STEP: delete the pod
Apr 16 12:38:07.989: INFO: Waiting for pod pod-configmaps-7b9a2132-6044-11e9-be7e-0a580ae9423f to disappear
Apr 16 12:38:07.994: INFO: Pod pod-configmaps-7b9a2132-6044-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:38:07.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-wsvdk" for this suite.
Apr 16 12:38:14.032: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:38:14.186: INFO: namespace: e2e-tests-configmap-wsvdk, resource: bindings, ignored listing per whitelist
Apr 16 12:38:14.194: INFO: namespace e2e-tests-configmap-wsvdk deletion completed in 6.194408666s

• [SLOW TEST:8.349 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:38:14.195: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Apr 16 12:38:14.270: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:38:17.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-dv488" for this suite.
Apr 16 12:38:23.801: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:38:23.869: INFO: namespace: e2e-tests-init-container-dv488, resource: bindings, ignored listing per whitelist
Apr 16 12:38:23.939: INFO: namespace e2e-tests-init-container-dv488 deletion completed in 6.156926863s

• [SLOW TEST:9.744 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:38:23.940: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:38:43.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-runtime-n42gx" for this suite.
Apr 16 12:38:49.409: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:38:49.438: INFO: namespace: e2e-tests-container-runtime-n42gx, resource: bindings, ignored listing per whitelist
Apr 16 12:38:49.523: INFO: namespace e2e-tests-container-runtime-n42gx deletion completed in 6.13940198s

• [SLOW TEST:25.583 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  blackbox test
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:38:49.525: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Apr 16 12:38:49.623: INFO: Waiting up to 5m0s for pod "downward-api-95a42d6f-6044-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-downward-api-2rftl" to be "success or failure"
Apr 16 12:38:49.627: INFO: Pod "downward-api-95a42d6f-6044-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.818977ms
Apr 16 12:38:51.634: INFO: Pod "downward-api-95a42d6f-6044-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011140409s
STEP: Saw pod success
Apr 16 12:38:51.634: INFO: Pod "downward-api-95a42d6f-6044-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 12:38:51.637: INFO: Trying to get logs from node k8s-3 pod downward-api-95a42d6f-6044-11e9-be7e-0a580ae9423f container dapi-container: <nil>
STEP: delete the pod
Apr 16 12:38:51.668: INFO: Waiting for pod downward-api-95a42d6f-6044-11e9-be7e-0a580ae9423f to disappear
Apr 16 12:38:51.672: INFO: Pod downward-api-95a42d6f-6044-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:38:51.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-2rftl" for this suite.
Apr 16 12:38:57.695: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:38:57.740: INFO: namespace: e2e-tests-downward-api-2rftl, resource: bindings, ignored listing per whitelist
Apr 16 12:38:57.791: INFO: namespace e2e-tests-downward-api-2rftl deletion completed in 6.116336345s

• [SLOW TEST:8.266 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:38:57.792: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-9a8dfd58-6044-11e9-be7e-0a580ae9423f
STEP: Creating a pod to test consume secrets
Apr 16 12:38:57.871: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-9a8ef962-6044-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-projected-tpdt4" to be "success or failure"
Apr 16 12:38:57.884: INFO: Pod "pod-projected-secrets-9a8ef962-6044-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 13.179237ms
Apr 16 12:38:59.889: INFO: Pod "pod-projected-secrets-9a8ef962-6044-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018087259s
STEP: Saw pod success
Apr 16 12:38:59.889: INFO: Pod "pod-projected-secrets-9a8ef962-6044-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 12:38:59.894: INFO: Trying to get logs from node k8s-2 pod pod-projected-secrets-9a8ef962-6044-11e9-be7e-0a580ae9423f container secret-volume-test: <nil>
STEP: delete the pod
Apr 16 12:38:59.936: INFO: Waiting for pod pod-projected-secrets-9a8ef962-6044-11e9-be7e-0a580ae9423f to disappear
Apr 16 12:38:59.940: INFO: Pod pod-projected-secrets-9a8ef962-6044-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:38:59.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-tpdt4" for this suite.
Apr 16 12:39:05.970: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:39:06.019: INFO: namespace: e2e-tests-projected-tpdt4, resource: bindings, ignored listing per whitelist
Apr 16 12:39:06.092: INFO: namespace e2e-tests-projected-tpdt4 deletion completed in 6.147729043s

• [SLOW TEST:8.300 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:39:06.095: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:39:06.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-mtlrw" for this suite.
Apr 16 12:39:28.279: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:39:28.292: INFO: namespace: e2e-tests-pods-mtlrw, resource: bindings, ignored listing per whitelist
Apr 16 12:39:28.386: INFO: namespace e2e-tests-pods-mtlrw deletion completed in 22.14642471s

• [SLOW TEST:22.291 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:39:28.387: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Apr 16 12:39:28.463: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:39:30.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-g57kv" for this suite.
Apr 16 12:40:08.674: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:40:08.716: INFO: namespace: e2e-tests-pods-g57kv, resource: bindings, ignored listing per whitelist
Apr 16 12:40:08.801: INFO: namespace e2e-tests-pods-g57kv deletion completed in 38.160068467s

• [SLOW TEST:40.414 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:40:08.803: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Apr 16 12:40:08.922: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Apr 16 12:40:13.935: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr 16 12:40:13.935: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr 16 12:40:13.972: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-jgkdk,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-jgkdk/deployments/test-cleanup-deployment,UID:c7e7c250-6044-11e9-8569-0800277031c6,ResourceVersion:28479,Generation:1,CreationTimestamp:2019-04-16 12:40:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Apr 16 12:40:13.976: INFO: New ReplicaSet "test-cleanup-deployment-7dbbfcf846" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-7dbbfcf846,GenerateName:,Namespace:e2e-tests-deployment-jgkdk,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-jgkdk/replicasets/test-cleanup-deployment-7dbbfcf846,UID:c7eb5b92-6044-11e9-8978-0800277031c6,ResourceVersion:28481,Generation:1,CreationTimestamp:2019-04-16 12:40:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment c7e7c250-6044-11e9-8569-0800277031c6 0xc0019f1b97 0xc0019f1b98}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr 16 12:40:13.976: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Apr 16 12:40:13.976: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:e2e-tests-deployment-jgkdk,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-jgkdk/replicasets/test-cleanup-controller,UID:c4e7e96c-6044-11e9-8569-0800277031c6,ResourceVersion:28480,Generation:1,CreationTimestamp:2019-04-16 12:40:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment c7e7c250-6044-11e9-8569-0800277031c6 0xc0019f1a37 0xc0019f1a38}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Apr 16 12:40:13.984: INFO: Pod "test-cleanup-controller-7kxtz" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-7kxtz,GenerateName:test-cleanup-controller-,Namespace:e2e-tests-deployment-jgkdk,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jgkdk/pods/test-cleanup-controller-7kxtz,UID:c4eb4f03-6044-11e9-8978-0800277031c6,ResourceVersion:28474,Generation:0,CreationTimestamp:2019-04-16 12:40:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller c4e7e96c-6044-11e9-8569-0800277031c6 0xc002aa0657 0xc002aa0658}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8hljs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8hljs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8hljs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002aa06d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002aa06f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:40:08 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:40:10 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:40:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:40:08 +0000 UTC  }],Message:,Reason:,HostIP:172.17.8.102,PodIP:10.233.65.121,StartTime:2019-04-16 12:40:08 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-16 12:40:09 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://2ca299460cf568c6396ce6bd34de835afb0d4a2cba323835cf3d2b5a016098d6}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 16 12:40:13.984: INFO: Pod "test-cleanup-deployment-7dbbfcf846-zlb2h" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-7dbbfcf846-zlb2h,GenerateName:test-cleanup-deployment-7dbbfcf846-,Namespace:e2e-tests-deployment-jgkdk,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jgkdk/pods/test-cleanup-deployment-7dbbfcf846-zlb2h,UID:c7ec3ab0-6044-11e9-8978-0800277031c6,ResourceVersion:28482,Generation:0,CreationTimestamp:2019-04-16 12:40:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-7dbbfcf846 c7eb5b92-6044-11e9-8978-0800277031c6 0xc002aa0837 0xc002aa0838}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8hljs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8hljs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-8hljs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002aa08a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002aa08c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:40:13.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-jgkdk" for this suite.
Apr 16 12:40:20.019: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:40:20.050: INFO: namespace: e2e-tests-deployment-jgkdk, resource: bindings, ignored listing per whitelist
Apr 16 12:40:20.122: INFO: namespace e2e-tests-deployment-jgkdk deletion completed in 6.131457562s

• [SLOW TEST:11.320 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:40:20.123: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Apr 16 12:40:20.216: INFO: Pod name rollover-pod: Found 0 pods out of 1
Apr 16 12:40:25.229: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr 16 12:40:25.229: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Apr 16 12:40:27.234: INFO: Creating deployment "test-rollover-deployment"
Apr 16 12:40:27.248: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Apr 16 12:40:29.258: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Apr 16 12:40:29.266: INFO: Ensure that both replica sets have 1 created replica
Apr 16 12:40:29.271: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Apr 16 12:40:29.286: INFO: Updating deployment test-rollover-deployment
Apr 16 12:40:29.286: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Apr 16 12:40:31.315: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Apr 16 12:40:31.325: INFO: Make sure deployment "test-rollover-deployment" is complete
Apr 16 12:40:31.333: INFO: all replica sets need to contain the pod-template-hash label
Apr 16 12:40:31.333: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63691015227, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691015227, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63691015231, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691015227, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 16 12:40:33.342: INFO: all replica sets need to contain the pod-template-hash label
Apr 16 12:40:33.342: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63691015227, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691015227, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63691015231, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691015227, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 16 12:40:35.348: INFO: all replica sets need to contain the pod-template-hash label
Apr 16 12:40:35.348: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63691015227, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691015227, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63691015231, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691015227, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 16 12:40:37.343: INFO: all replica sets need to contain the pod-template-hash label
Apr 16 12:40:37.343: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63691015227, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691015227, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63691015231, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691015227, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 16 12:40:39.342: INFO: all replica sets need to contain the pod-template-hash label
Apr 16 12:40:39.343: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63691015227, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691015227, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63691015231, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691015227, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 16 12:40:41.341: INFO: 
Apr 16 12:40:41.342: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr 16 12:40:41.354: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-rmh8p,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-rmh8p/deployments/test-rollover-deployment,UID:cfd469cf-6044-11e9-8569-0800277031c6,ResourceVersion:28633,Generation:2,CreationTimestamp:2019-04-16 12:40:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-04-16 12:40:27 +0000 UTC 2019-04-16 12:40:27 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-04-16 12:40:41 +0000 UTC 2019-04-16 12:40:27 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-6b7f9d6597" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Apr 16 12:40:41.358: INFO: New ReplicaSet "test-rollover-deployment-6b7f9d6597" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597,GenerateName:,Namespace:e2e-tests-deployment-rmh8p,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-rmh8p/replicasets/test-rollover-deployment-6b7f9d6597,UID:d10c4a0a-6044-11e9-8978-0800277031c6,ResourceVersion:28624,Generation:2,CreationTimestamp:2019-04-16 12:40:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment cfd469cf-6044-11e9-8569-0800277031c6 0xc0014d0127 0xc0014d0128}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Apr 16 12:40:41.358: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Apr 16 12:40:41.358: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-rmh8p,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-rmh8p/replicasets/test-rollover-controller,UID:cba35d1b-6044-11e9-8569-0800277031c6,ResourceVersion:28632,Generation:2,CreationTimestamp:2019-04-16 12:40:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment cfd469cf-6044-11e9-8569-0800277031c6 0xc00225bf97 0xc00225bf98}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr 16 12:40:41.359: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6586df867b,GenerateName:,Namespace:e2e-tests-deployment-rmh8p,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-rmh8p/replicasets/test-rollover-deployment-6586df867b,UID:cfd7aff2-6044-11e9-8978-0800277031c6,ResourceVersion:28593,Generation:2,CreationTimestamp:2019-04-16 12:40:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment cfd469cf-6044-11e9-8569-0800277031c6 0xc0014d0057 0xc0014d0058}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr 16 12:40:41.364: INFO: Pod "test-rollover-deployment-6b7f9d6597-j7kc5" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597-j7kc5,GenerateName:test-rollover-deployment-6b7f9d6597-,Namespace:e2e-tests-deployment-rmh8p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rmh8p/pods/test-rollover-deployment-6b7f9d6597-j7kc5,UID:d1181fb2-6044-11e9-8978-0800277031c6,ResourceVersion:28606,Generation:0,CreationTimestamp:2019-04-16 12:40:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-6b7f9d6597 d10c4a0a-6044-11e9-8978-0800277031c6 0xc0014d0c77 0xc0014d0c78}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-48527 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-48527,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-48527 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0014d0cf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0014d0d10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:40:29 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:40:31 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:40:31 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:40:29 +0000 UTC  }],Message:,Reason:,HostIP:172.17.8.103,PodIP:10.233.66.153,StartTime:2019-04-16 12:40:29 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-04-16 12:40:30 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://0a48cdd9bb64c01c76c050da668c0df1a0f24853a9f7f08921a878dd08944609}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:40:41.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-rmh8p" for this suite.
Apr 16 12:40:47.388: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:40:47.417: INFO: namespace: e2e-tests-deployment-rmh8p, resource: bindings, ignored listing per whitelist
Apr 16 12:40:47.495: INFO: namespace e2e-tests-deployment-rmh8p deletion completed in 6.127092763s

• [SLOW TEST:27.372 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:40:47.496: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Apr 16 12:40:47.593: INFO: Waiting up to 5m0s for pod "pod-dbf52823-6044-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-emptydir-r2nxx" to be "success or failure"
Apr 16 12:40:47.605: INFO: Pod "pod-dbf52823-6044-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 12.126543ms
Apr 16 12:40:49.611: INFO: Pod "pod-dbf52823-6044-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018566765s
STEP: Saw pod success
Apr 16 12:40:49.611: INFO: Pod "pod-dbf52823-6044-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 12:40:49.617: INFO: Trying to get logs from node k8s-1 pod pod-dbf52823-6044-11e9-be7e-0a580ae9423f container test-container: <nil>
STEP: delete the pod
Apr 16 12:40:49.654: INFO: Waiting for pod pod-dbf52823-6044-11e9-be7e-0a580ae9423f to disappear
Apr 16 12:40:49.660: INFO: Pod pod-dbf52823-6044-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:40:49.660: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-r2nxx" for this suite.
Apr 16 12:40:55.702: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:40:55.756: INFO: namespace: e2e-tests-emptydir-r2nxx, resource: bindings, ignored listing per whitelist
Apr 16 12:40:55.805: INFO: namespace e2e-tests-emptydir-r2nxx deletion completed in 6.141744825s

• [SLOW TEST:8.310 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:40:55.807: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-e0e5e524-6044-11e9-be7e-0a580ae9423f
STEP: Creating a pod to test consume secrets
Apr 16 12:40:55.886: INFO: Waiting up to 5m0s for pod "pod-secrets-e0e6e711-6044-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-secrets-kb767" to be "success or failure"
Apr 16 12:40:55.892: INFO: Pod "pod-secrets-e0e6e711-6044-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.289546ms
Apr 16 12:40:57.898: INFO: Pod "pod-secrets-e0e6e711-6044-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011302193s
STEP: Saw pod success
Apr 16 12:40:57.898: INFO: Pod "pod-secrets-e0e6e711-6044-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 12:40:57.901: INFO: Trying to get logs from node k8s-2 pod pod-secrets-e0e6e711-6044-11e9-be7e-0a580ae9423f container secret-volume-test: <nil>
STEP: delete the pod
Apr 16 12:40:57.944: INFO: Waiting for pod pod-secrets-e0e6e711-6044-11e9-be7e-0a580ae9423f to disappear
Apr 16 12:40:57.951: INFO: Pod pod-secrets-e0e6e711-6044-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:40:57.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-kb767" for this suite.
Apr 16 12:41:03.986: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:41:04.074: INFO: namespace: e2e-tests-secrets-kb767, resource: bindings, ignored listing per whitelist
Apr 16 12:41:04.185: INFO: namespace e2e-tests-secrets-kb767 deletion completed in 6.225359471s

• [SLOW TEST:8.379 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:41:04.186: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Apr 16 12:41:04.286: INFO: (0) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 11.528359ms)
Apr 16 12:41:04.292: INFO: (1) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 6.002782ms)
Apr 16 12:41:04.298: INFO: (2) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 6.040414ms)
Apr 16 12:41:04.305: INFO: (3) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.785041ms)
Apr 16 12:41:04.308: INFO: (4) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.256572ms)
Apr 16 12:41:04.315: INFO: (5) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 6.796959ms)
Apr 16 12:41:04.325: INFO: (6) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 10.197052ms)
Apr 16 12:41:04.333: INFO: (7) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 7.226015ms)
Apr 16 12:41:04.338: INFO: (8) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 5.190629ms)
Apr 16 12:41:04.342: INFO: (9) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.242626ms)
Apr 16 12:41:04.347: INFO: (10) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 5.133708ms)
Apr 16 12:41:04.352: INFO: (11) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.571093ms)
Apr 16 12:41:04.362: INFO: (12) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 10.457145ms)
Apr 16 12:41:04.366: INFO: (13) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.889918ms)
Apr 16 12:41:04.370: INFO: (14) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.358903ms)
Apr 16 12:41:04.374: INFO: (15) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.723106ms)
Apr 16 12:41:04.379: INFO: (16) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 5.125446ms)
Apr 16 12:41:04.383: INFO: (17) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.670752ms)
Apr 16 12:41:04.389: INFO: (18) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 5.56738ms)
Apr 16 12:41:04.397: INFO: (19) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 8.127199ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:41:04.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-xdlrw" for this suite.
Apr 16 12:41:10.422: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:41:10.466: INFO: namespace: e2e-tests-proxy-xdlrw, resource: bindings, ignored listing per whitelist
Apr 16 12:41:10.541: INFO: namespace e2e-tests-proxy-xdlrw deletion completed in 6.138495515s

• [SLOW TEST:6.355 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:41:10.543: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-e9b03d15-6044-11e9-be7e-0a580ae9423f
STEP: Creating secret with name secret-projected-all-test-volume-e9b03d09-6044-11e9-be7e-0a580ae9423f
STEP: Creating a pod to test Check all projections for projected volume plugin
Apr 16 12:41:10.646: INFO: Waiting up to 5m0s for pod "projected-volume-e9b03ce5-6044-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-projected-jwqzs" to be "success or failure"
Apr 16 12:41:10.656: INFO: Pod "projected-volume-e9b03ce5-6044-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 9.067229ms
Apr 16 12:41:12.661: INFO: Pod "projected-volume-e9b03ce5-6044-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014309547s
STEP: Saw pod success
Apr 16 12:41:12.661: INFO: Pod "projected-volume-e9b03ce5-6044-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 12:41:12.667: INFO: Trying to get logs from node k8s-3 pod projected-volume-e9b03ce5-6044-11e9-be7e-0a580ae9423f container projected-all-volume-test: <nil>
STEP: delete the pod
Apr 16 12:41:12.696: INFO: Waiting for pod projected-volume-e9b03ce5-6044-11e9-be7e-0a580ae9423f to disappear
Apr 16 12:41:12.701: INFO: Pod projected-volume-e9b03ce5-6044-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:41:12.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jwqzs" for this suite.
Apr 16 12:41:18.725: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:41:18.758: INFO: namespace: e2e-tests-projected-jwqzs, resource: bindings, ignored listing per whitelist
Apr 16 12:41:18.829: INFO: namespace e2e-tests-projected-jwqzs deletion completed in 6.124051373s

• [SLOW TEST:8.286 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:41:18.830: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-j59q4
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-j59q4
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-j59q4
Apr 16 12:41:18.926: INFO: Found 0 stateful pods, waiting for 1
Apr 16 12:41:28.939: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Apr 16 12:41:28.944: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-j59q4 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 16 12:41:29.134: INFO: stderr: ""
Apr 16 12:41:29.134: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 16 12:41:29.134: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 16 12:41:29.139: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Apr 16 12:41:39.162: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 16 12:41:39.162: INFO: Waiting for statefulset status.replicas updated to 0
Apr 16 12:41:39.188: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999502s
Apr 16 12:41:40.193: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.993630853s
Apr 16 12:41:41.198: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.989414664s
Apr 16 12:41:42.204: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.983821133s
Apr 16 12:41:43.211: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.97806896s
Apr 16 12:41:44.220: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.970534251s
Apr 16 12:41:45.227: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.961471298s
Apr 16 12:41:46.233: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.955338089s
Apr 16 12:41:47.238: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.949022588s
Apr 16 12:41:48.245: INFO: Verifying statefulset ss doesn't scale past 1 for another 943.542721ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-j59q4
Apr 16 12:41:49.257: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-j59q4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 16 12:41:49.410: INFO: stderr: ""
Apr 16 12:41:49.410: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 16 12:41:49.410: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 16 12:41:49.415: INFO: Found 1 stateful pods, waiting for 3
Apr 16 12:41:59.426: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 16 12:41:59.426: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 16 12:41:59.426: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Apr 16 12:41:59.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-j59q4 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 16 12:41:59.592: INFO: stderr: ""
Apr 16 12:41:59.592: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 16 12:41:59.592: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 16 12:41:59.592: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-j59q4 ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 16 12:41:59.763: INFO: stderr: ""
Apr 16 12:41:59.763: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 16 12:41:59.763: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 16 12:41:59.763: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-j59q4 ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 16 12:41:59.998: INFO: stderr: ""
Apr 16 12:41:59.998: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 16 12:41:59.998: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 16 12:41:59.998: INFO: Waiting for statefulset status.replicas updated to 0
Apr 16 12:42:00.002: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Apr 16 12:42:10.016: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 16 12:42:10.016: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Apr 16 12:42:10.016: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Apr 16 12:42:10.036: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999581s
Apr 16 12:42:11.042: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.987664541s
Apr 16 12:42:12.048: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.98112094s
Apr 16 12:42:13.054: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.975346822s
Apr 16 12:42:14.060: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.969086765s
Apr 16 12:42:15.067: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.963067616s
Apr 16 12:42:16.076: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.955703967s
Apr 16 12:42:17.082: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.947123241s
Apr 16 12:42:18.089: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.941444599s
Apr 16 12:42:19.094: INFO: Verifying statefulset ss doesn't scale past 3 for another 934.632311ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-j59q4
Apr 16 12:42:20.106: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-j59q4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 16 12:42:20.261: INFO: stderr: ""
Apr 16 12:42:20.261: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 16 12:42:20.261: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 16 12:42:20.261: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-j59q4 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 16 12:42:20.415: INFO: stderr: ""
Apr 16 12:42:20.415: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 16 12:42:20.415: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 16 12:42:20.415: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-j59q4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 16 12:42:20.610: INFO: stderr: ""
Apr 16 12:42:20.610: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 16 12:42:20.610: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 16 12:42:20.610: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr 16 12:42:40.653: INFO: Deleting all statefulset in ns e2e-tests-statefulset-j59q4
Apr 16 12:42:40.656: INFO: Scaling statefulset ss to 0
Apr 16 12:42:40.672: INFO: Waiting for statefulset status.replicas updated to 0
Apr 16 12:42:40.674: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:42:40.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-j59q4" for this suite.
Apr 16 12:42:46.730: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:42:46.955: INFO: namespace: e2e-tests-statefulset-j59q4, resource: bindings, ignored listing per whitelist
Apr 16 12:42:46.960: INFO: namespace e2e-tests-statefulset-j59q4 deletion completed in 6.263661388s

• [SLOW TEST:88.130 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:42:46.963: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Apr 16 12:42:47.091: INFO: Waiting up to 5m0s for pod "downwardapi-volume-232efd12-6045-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-projected-8rvgw" to be "success or failure"
Apr 16 12:42:47.095: INFO: Pod "downwardapi-volume-232efd12-6045-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.532312ms
Apr 16 12:42:49.100: INFO: Pod "downwardapi-volume-232efd12-6045-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009008101s
STEP: Saw pod success
Apr 16 12:42:49.100: INFO: Pod "downwardapi-volume-232efd12-6045-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 12:42:49.104: INFO: Trying to get logs from node k8s-1 pod downwardapi-volume-232efd12-6045-11e9-be7e-0a580ae9423f container client-container: <nil>
STEP: delete the pod
Apr 16 12:42:49.134: INFO: Waiting for pod downwardapi-volume-232efd12-6045-11e9-be7e-0a580ae9423f to disappear
Apr 16 12:42:49.138: INFO: Pod downwardapi-volume-232efd12-6045-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:42:49.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8rvgw" for this suite.
Apr 16 12:42:55.164: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:42:55.231: INFO: namespace: e2e-tests-projected-8rvgw, resource: bindings, ignored listing per whitelist
Apr 16 12:42:55.276: INFO: namespace e2e-tests-projected-8rvgw deletion completed in 6.134441806s

• [SLOW TEST:8.313 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:42:55.277: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-281b4419-6045-11e9-be7e-0a580ae9423f
STEP: Creating a pod to test consume secrets
Apr 16 12:42:55.355: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-281c4162-6045-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-projected-2ghq9" to be "success or failure"
Apr 16 12:42:55.358: INFO: Pod "pod-projected-secrets-281c4162-6045-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.328066ms
Apr 16 12:42:57.366: INFO: Pod "pod-projected-secrets-281c4162-6045-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011468377s
STEP: Saw pod success
Apr 16 12:42:57.366: INFO: Pod "pod-projected-secrets-281c4162-6045-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 12:42:57.370: INFO: Trying to get logs from node k8s-2 pod pod-projected-secrets-281c4162-6045-11e9-be7e-0a580ae9423f container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 16 12:42:57.404: INFO: Waiting for pod pod-projected-secrets-281c4162-6045-11e9-be7e-0a580ae9423f to disappear
Apr 16 12:42:57.408: INFO: Pod pod-projected-secrets-281c4162-6045-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:42:57.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2ghq9" for this suite.
Apr 16 12:43:03.429: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:43:03.476: INFO: namespace: e2e-tests-projected-2ghq9, resource: bindings, ignored listing per whitelist
Apr 16 12:43:03.564: INFO: namespace e2e-tests-projected-2ghq9 deletion completed in 6.152318785s

• [SLOW TEST:8.287 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:43:03.565: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Apr 16 12:43:03.645: INFO: Waiting up to 5m0s for pod "pod-2d0cc43f-6045-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-emptydir-mz5sv" to be "success or failure"
Apr 16 12:43:03.649: INFO: Pod "pod-2d0cc43f-6045-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.051864ms
Apr 16 12:43:05.654: INFO: Pod "pod-2d0cc43f-6045-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009103908s
STEP: Saw pod success
Apr 16 12:43:05.654: INFO: Pod "pod-2d0cc43f-6045-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 12:43:05.658: INFO: Trying to get logs from node k8s-3 pod pod-2d0cc43f-6045-11e9-be7e-0a580ae9423f container test-container: <nil>
STEP: delete the pod
Apr 16 12:43:05.689: INFO: Waiting for pod pod-2d0cc43f-6045-11e9-be7e-0a580ae9423f to disappear
Apr 16 12:43:05.692: INFO: Pod pod-2d0cc43f-6045-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:43:05.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-mz5sv" for this suite.
Apr 16 12:43:11.720: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:43:11.801: INFO: namespace: e2e-tests-emptydir-mz5sv, resource: bindings, ignored listing per whitelist
Apr 16 12:43:11.832: INFO: namespace e2e-tests-emptydir-mz5sv deletion completed in 6.137354246s

• [SLOW TEST:8.268 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:43:11.833: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Apr 16 12:43:11.919: INFO: Waiting up to 5m0s for pod "pod-31fb3b38-6045-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-emptydir-5227z" to be "success or failure"
Apr 16 12:43:11.923: INFO: Pod "pod-31fb3b38-6045-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.205065ms
Apr 16 12:43:13.929: INFO: Pod "pod-31fb3b38-6045-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009532648s
STEP: Saw pod success
Apr 16 12:43:13.929: INFO: Pod "pod-31fb3b38-6045-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 12:43:13.933: INFO: Trying to get logs from node k8s-1 pod pod-31fb3b38-6045-11e9-be7e-0a580ae9423f container test-container: <nil>
STEP: delete the pod
Apr 16 12:43:13.967: INFO: Waiting for pod pod-31fb3b38-6045-11e9-be7e-0a580ae9423f to disappear
Apr 16 12:43:13.972: INFO: Pod pod-31fb3b38-6045-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:43:13.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-5227z" for this suite.
Apr 16 12:43:19.994: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:43:20.018: INFO: namespace: e2e-tests-emptydir-5227z, resource: bindings, ignored listing per whitelist
Apr 16 12:43:20.102: INFO: namespace e2e-tests-emptydir-5227z deletion completed in 6.126816862s

• [SLOW TEST:8.269 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:43:20.103: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Apr 16 12:43:20.233: INFO: Number of nodes with available pods: 0
Apr 16 12:43:20.233: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:43:21.249: INFO: Number of nodes with available pods: 1
Apr 16 12:43:21.249: INFO: Node k8s-1 is running more than one daemon pod
Apr 16 12:43:22.250: INFO: Number of nodes with available pods: 3
Apr 16 12:43:22.250: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Apr 16 12:43:22.288: INFO: Number of nodes with available pods: 2
Apr 16 12:43:22.288: INFO: Node k8s-3 is running more than one daemon pod
Apr 16 12:43:23.298: INFO: Number of nodes with available pods: 2
Apr 16 12:43:23.298: INFO: Node k8s-3 is running more than one daemon pod
Apr 16 12:43:24.309: INFO: Number of nodes with available pods: 3
Apr 16 12:43:24.310: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-mlvnw, will wait for the garbage collector to delete the pods
Apr 16 12:43:24.383: INFO: Deleting DaemonSet.extensions daemon-set took: 10.940476ms
Apr 16 12:43:24.483: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.514424ms
Apr 16 12:44:06.695: INFO: Number of nodes with available pods: 0
Apr 16 12:44:06.695: INFO: Number of running nodes: 0, number of available pods: 0
Apr 16 12:44:06.699: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-mlvnw/daemonsets","resourceVersion":"29434"},"items":null}

Apr 16 12:44:06.702: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-mlvnw/pods","resourceVersion":"29434"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:44:06.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-mlvnw" for this suite.
Apr 16 12:44:12.735: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:44:12.803: INFO: namespace: e2e-tests-daemonsets-mlvnw, resource: bindings, ignored listing per whitelist
Apr 16 12:44:12.837: INFO: namespace e2e-tests-daemonsets-mlvnw deletion completed in 6.119077463s

• [SLOW TEST:52.734 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:44:12.838: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:44:19.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-c894q" for this suite.
Apr 16 12:44:25.048: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:44:25.097: INFO: namespace: e2e-tests-namespaces-c894q, resource: bindings, ignored listing per whitelist
Apr 16 12:44:25.196: INFO: namespace e2e-tests-namespaces-c894q deletion completed in 6.163947129s
STEP: Destroying namespace "e2e-tests-nsdeletetest-472t4" for this suite.
Apr 16 12:44:25.200: INFO: Namespace e2e-tests-nsdeletetest-472t4 was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-cqqzg" for this suite.
Apr 16 12:44:31.217: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:44:31.278: INFO: namespace: e2e-tests-nsdeletetest-cqqzg, resource: bindings, ignored listing per whitelist
Apr 16 12:44:31.335: INFO: namespace e2e-tests-nsdeletetest-cqqzg deletion completed in 6.13456876s

• [SLOW TEST:18.498 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:44:31.339: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1134
STEP: creating an rc
Apr 16 12:44:31.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 create -f - --namespace=e2e-tests-kubectl-2p84d'
Apr 16 12:44:32.022: INFO: stderr: ""
Apr 16 12:44:32.022: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Apr 16 12:44:33.027: INFO: Selector matched 1 pods for map[app:redis]
Apr 16 12:44:33.027: INFO: Found 0 / 1
Apr 16 12:44:34.027: INFO: Selector matched 1 pods for map[app:redis]
Apr 16 12:44:34.027: INFO: Found 1 / 1
Apr 16 12:44:34.027: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr 16 12:44:34.031: INFO: Selector matched 1 pods for map[app:redis]
Apr 16 12:44:34.031: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Apr 16 12:44:34.031: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 logs redis-master-kbhbw redis-master --namespace=e2e-tests-kubectl-2p84d'
Apr 16 12:44:34.143: INFO: stderr: ""
Apr 16 12:44:34.143: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 16 Apr 12:44:32.816 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 16 Apr 12:44:32.816 # Server started, Redis version 3.2.12\n1:M 16 Apr 12:44:32.816 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 16 Apr 12:44:32.816 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Apr 16 12:44:34.144: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 log redis-master-kbhbw redis-master --namespace=e2e-tests-kubectl-2p84d --tail=1'
Apr 16 12:44:34.230: INFO: stderr: ""
Apr 16 12:44:34.230: INFO: stdout: "1:M 16 Apr 12:44:32.816 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Apr 16 12:44:34.230: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 log redis-master-kbhbw redis-master --namespace=e2e-tests-kubectl-2p84d --limit-bytes=1'
Apr 16 12:44:34.318: INFO: stderr: ""
Apr 16 12:44:34.318: INFO: stdout: " "
STEP: exposing timestamps
Apr 16 12:44:34.318: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 log redis-master-kbhbw redis-master --namespace=e2e-tests-kubectl-2p84d --tail=1 --timestamps'
Apr 16 12:44:34.405: INFO: stderr: ""
Apr 16 12:44:34.405: INFO: stdout: "2019-04-16T12:44:32.817174046Z 1:M 16 Apr 12:44:32.816 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Apr 16 12:44:36.905: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 log redis-master-kbhbw redis-master --namespace=e2e-tests-kubectl-2p84d --since=1s'
Apr 16 12:44:36.994: INFO: stderr: ""
Apr 16 12:44:36.994: INFO: stdout: ""
Apr 16 12:44:36.994: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 log redis-master-kbhbw redis-master --namespace=e2e-tests-kubectl-2p84d --since=24h'
Apr 16 12:44:37.077: INFO: stderr: ""
Apr 16 12:44:37.077: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 16 Apr 12:44:32.816 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 16 Apr 12:44:32.816 # Server started, Redis version 3.2.12\n1:M 16 Apr 12:44:32.816 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 16 Apr 12:44:32.816 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1140
STEP: using delete to clean up resources
Apr 16 12:44:37.077: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-2p84d'
Apr 16 12:44:37.193: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 16 12:44:37.193: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Apr 16 12:44:37.193: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-2p84d'
Apr 16 12:44:37.298: INFO: stderr: "No resources found.\n"
Apr 16 12:44:37.298: INFO: stdout: ""
Apr 16 12:44:37.298: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 get pods -l name=nginx --namespace=e2e-tests-kubectl-2p84d -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 16 12:44:37.386: INFO: stderr: ""
Apr 16 12:44:37.386: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:44:37.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2p84d" for this suite.
Apr 16 12:44:59.412: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:44:59.461: INFO: namespace: e2e-tests-kubectl-2p84d, resource: bindings, ignored listing per whitelist
Apr 16 12:44:59.581: INFO: namespace e2e-tests-kubectl-2p84d deletion completed in 22.191476808s

• [SLOW TEST:28.242 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:44:59.581: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Apr 16 12:44:59.672: INFO: (0) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 7.497843ms)
Apr 16 12:44:59.677: INFO: (1) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.703473ms)
Apr 16 12:44:59.682: INFO: (2) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.82413ms)
Apr 16 12:44:59.689: INFO: (3) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 6.794932ms)
Apr 16 12:44:59.692: INFO: (4) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.062808ms)
Apr 16 12:44:59.696: INFO: (5) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.607021ms)
Apr 16 12:44:59.701: INFO: (6) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.060418ms)
Apr 16 12:44:59.708: INFO: (7) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 6.931281ms)
Apr 16 12:44:59.712: INFO: (8) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.75512ms)
Apr 16 12:44:59.716: INFO: (9) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.648522ms)
Apr 16 12:44:59.720: INFO: (10) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.805327ms)
Apr 16 12:44:59.726: INFO: (11) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 5.397786ms)
Apr 16 12:44:59.730: INFO: (12) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.435968ms)
Apr 16 12:44:59.736: INFO: (13) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 5.823481ms)
Apr 16 12:44:59.739: INFO: (14) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.248102ms)
Apr 16 12:44:59.742: INFO: (15) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.953486ms)
Apr 16 12:44:59.746: INFO: (16) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.15158ms)
Apr 16 12:44:59.749: INFO: (17) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.461738ms)
Apr 16 12:44:59.754: INFO: (18) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.575073ms)
Apr 16 12:44:59.759: INFO: (19) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 5.009769ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:44:59.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-jxhhv" for this suite.
Apr 16 12:45:05.780: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:45:05.870: INFO: namespace: e2e-tests-proxy-jxhhv, resource: bindings, ignored listing per whitelist
Apr 16 12:45:05.889: INFO: namespace e2e-tests-proxy-jxhhv deletion completed in 6.126236044s

• [SLOW TEST:6.308 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:45:05.891: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Apr 16 12:45:06.484: INFO: created pod pod-service-account-defaultsa
Apr 16 12:45:06.484: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Apr 16 12:45:06.493: INFO: created pod pod-service-account-mountsa
Apr 16 12:45:06.493: INFO: pod pod-service-account-mountsa service account token volume mount: true
Apr 16 12:45:06.509: INFO: created pod pod-service-account-nomountsa
Apr 16 12:45:06.509: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Apr 16 12:45:06.530: INFO: created pod pod-service-account-defaultsa-mountspec
Apr 16 12:45:06.530: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Apr 16 12:45:06.549: INFO: created pod pod-service-account-mountsa-mountspec
Apr 16 12:45:06.549: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Apr 16 12:45:06.559: INFO: created pod pod-service-account-nomountsa-mountspec
Apr 16 12:45:06.559: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Apr 16 12:45:06.569: INFO: created pod pod-service-account-defaultsa-nomountspec
Apr 16 12:45:06.569: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Apr 16 12:45:06.591: INFO: created pod pod-service-account-mountsa-nomountspec
Apr 16 12:45:06.591: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Apr 16 12:45:06.636: INFO: created pod pod-service-account-nomountsa-nomountspec
Apr 16 12:45:06.636: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:45:06.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-s7bw9" for this suite.
Apr 16 12:45:12.782: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:45:12.858: INFO: namespace: e2e-tests-svcaccounts-s7bw9, resource: bindings, ignored listing per whitelist
Apr 16 12:45:12.887: INFO: namespace e2e-tests-svcaccounts-s7bw9 deletion completed in 6.247086031s

• [SLOW TEST:6.995 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:45:12.888: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Apr 16 12:45:12.980: INFO: Waiting up to 5m0s for pod "pod-7a240a9d-6045-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-emptydir-ls6mh" to be "success or failure"
Apr 16 12:45:12.983: INFO: Pod "pod-7a240a9d-6045-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.254604ms
Apr 16 12:45:14.988: INFO: Pod "pod-7a240a9d-6045-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008188844s
STEP: Saw pod success
Apr 16 12:45:14.988: INFO: Pod "pod-7a240a9d-6045-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 12:45:14.992: INFO: Trying to get logs from node k8s-3 pod pod-7a240a9d-6045-11e9-be7e-0a580ae9423f container test-container: <nil>
STEP: delete the pod
Apr 16 12:45:15.023: INFO: Waiting for pod pod-7a240a9d-6045-11e9-be7e-0a580ae9423f to disappear
Apr 16 12:45:15.028: INFO: Pod pod-7a240a9d-6045-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:45:15.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-ls6mh" for this suite.
Apr 16 12:45:21.055: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:45:21.123: INFO: namespace: e2e-tests-emptydir-ls6mh, resource: bindings, ignored listing per whitelist
Apr 16 12:45:21.156: INFO: namespace e2e-tests-emptydir-ls6mh deletion completed in 6.125466142s

• [SLOW TEST:8.268 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:45:21.159: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-7f0f89e4-6045-11e9-be7e-0a580ae9423f
STEP: Creating a pod to test consume secrets
Apr 16 12:45:21.241: INFO: Waiting up to 5m0s for pod "pod-secrets-7f10896d-6045-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-secrets-pbgk9" to be "success or failure"
Apr 16 12:45:21.245: INFO: Pod "pod-secrets-7f10896d-6045-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.938745ms
Apr 16 12:45:23.250: INFO: Pod "pod-secrets-7f10896d-6045-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009222485s
STEP: Saw pod success
Apr 16 12:45:23.250: INFO: Pod "pod-secrets-7f10896d-6045-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 12:45:23.256: INFO: Trying to get logs from node k8s-1 pod pod-secrets-7f10896d-6045-11e9-be7e-0a580ae9423f container secret-env-test: <nil>
STEP: delete the pod
Apr 16 12:45:23.289: INFO: Waiting for pod pod-secrets-7f10896d-6045-11e9-be7e-0a580ae9423f to disappear
Apr 16 12:45:23.292: INFO: Pod pod-secrets-7f10896d-6045-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:45:23.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-pbgk9" for this suite.
Apr 16 12:45:29.315: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:45:29.369: INFO: namespace: e2e-tests-secrets-pbgk9, resource: bindings, ignored listing per whitelist
Apr 16 12:45:29.424: INFO: namespace e2e-tests-secrets-pbgk9 deletion completed in 6.127250767s

• [SLOW TEST:8.265 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:45:29.425: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-hdsjj
Apr 16 12:45:31.516: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-hdsjj
STEP: checking the pod's current state and verifying that restartCount is present
Apr 16 12:45:31.519: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:49:32.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-hdsjj" for this suite.
Apr 16 12:49:38.440: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:49:38.483: INFO: namespace: e2e-tests-container-probe-hdsjj, resource: bindings, ignored listing per whitelist
Apr 16 12:49:38.535: INFO: namespace e2e-tests-container-probe-hdsjj deletion completed in 6.111891495s

• [SLOW TEST:249.111 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:49:38.536: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Apr 16 12:49:40.630: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-1877d61f-6046-11e9-be7e-0a580ae9423f", GenerateName:"", Namespace:"e2e-tests-pods-6z69h", SelfLink:"/api/v1/namespaces/e2e-tests-pods-6z69h/pods/pod-submit-remove-1877d61f-6046-11e9-be7e-0a580ae9423f", UID:"1878fae2-6046-11e9-8569-0800277031c6", ResourceVersion:"30240", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63691015778, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"599481651"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-krvrs", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc000ac67c0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-krvrs", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc000dd96a8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"k8s-3", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001642a20), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc000dd96f0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc000dd9740)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc000dd9748), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc000dd974c)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691015778, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691015780, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691015780, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691015778, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.17.8.103", PodIP:"10.233.66.163", StartTime:(*v1.Time)(0xc000d3ad80), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc000d3ada0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7", ContainerID:"docker://5a36303e8320e66498e5ee3dc2d0bea8a59df798e1ce09556028a2f7cf87aef9"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:49:46.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-6z69h" for this suite.
Apr 16 12:49:52.638: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:49:52.722: INFO: namespace: e2e-tests-pods-6z69h, resource: bindings, ignored listing per whitelist
Apr 16 12:49:52.734: INFO: namespace e2e-tests-pods-6z69h deletion completed in 6.11958597s

• [SLOW TEST:14.198 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:49:52.735: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-mrd5w
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-mrd5w
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-mrd5w
Apr 16 12:49:52.819: INFO: Found 0 stateful pods, waiting for 1
Apr 16 12:50:02.835: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Apr 16 12:50:02.839: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 16 12:50:02.986: INFO: stderr: ""
Apr 16 12:50:02.986: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 16 12:50:02.986: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 16 12:50:02.991: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Apr 16 12:50:13.002: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 16 12:50:13.002: INFO: Waiting for statefulset status.replicas updated to 0
Apr 16 12:50:13.031: INFO: POD   NODE   PHASE    GRACE  CONDITIONS
Apr 16 12:50:13.031: INFO: ss-0  k8s-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:49:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:49:52 +0000 UTC  }]
Apr 16 12:50:13.031: INFO: 
Apr 16 12:50:13.031: INFO: StatefulSet ss has not reached scale 3, at 1
Apr 16 12:50:14.037: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.987013114s
Apr 16 12:50:15.046: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.980985654s
Apr 16 12:50:16.052: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.972179522s
Apr 16 12:50:17.058: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.965479717s
Apr 16 12:50:18.064: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.960288601s
Apr 16 12:50:19.074: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.954808625s
Apr 16 12:50:20.082: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.943771293s
Apr 16 12:50:21.087: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.93615643s
Apr 16 12:50:22.093: INFO: Verifying statefulset ss doesn't scale past 3 for another 930.717076ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-mrd5w
Apr 16 12:50:23.106: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 16 12:50:23.263: INFO: stderr: ""
Apr 16 12:50:23.263: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 16 12:50:23.263: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 16 12:50:23.263: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 16 12:50:23.509: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Apr 16 12:50:23.509: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 16 12:50:23.509: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 16 12:50:23.509: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 16 12:50:23.653: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Apr 16 12:50:23.653: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 16 12:50:23.654: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 16 12:50:23.659: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 16 12:50:23.659: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 16 12:50:23.659: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Apr 16 12:50:23.663: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 16 12:50:23.892: INFO: stderr: ""
Apr 16 12:50:23.892: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 16 12:50:23.892: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 16 12:50:23.892: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 16 12:50:24.053: INFO: stderr: ""
Apr 16 12:50:24.053: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 16 12:50:24.053: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 16 12:50:24.054: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 16 12:50:24.238: INFO: stderr: ""
Apr 16 12:50:24.238: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 16 12:50:24.238: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 16 12:50:24.238: INFO: Waiting for statefulset status.replicas updated to 0
Apr 16 12:50:24.248: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Apr 16 12:50:34.264: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 16 12:50:34.264: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Apr 16 12:50:34.264: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Apr 16 12:50:34.278: INFO: POD   NODE   PHASE    GRACE  CONDITIONS
Apr 16 12:50:34.278: INFO: ss-0  k8s-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:49:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:49:52 +0000 UTC  }]
Apr 16 12:50:34.278: INFO: ss-1  k8s-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:13 +0000 UTC  }]
Apr 16 12:50:34.278: INFO: ss-2  k8s-3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:13 +0000 UTC  }]
Apr 16 12:50:34.278: INFO: 
Apr 16 12:50:34.278: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 16 12:50:35.286: INFO: POD   NODE   PHASE    GRACE  CONDITIONS
Apr 16 12:50:35.286: INFO: ss-0  k8s-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:49:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:49:52 +0000 UTC  }]
Apr 16 12:50:35.286: INFO: ss-1  k8s-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:13 +0000 UTC  }]
Apr 16 12:50:35.286: INFO: ss-2  k8s-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:13 +0000 UTC  }]
Apr 16 12:50:35.286: INFO: 
Apr 16 12:50:35.286: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 16 12:50:36.292: INFO: POD   NODE   PHASE    GRACE  CONDITIONS
Apr 16 12:50:36.292: INFO: ss-0  k8s-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:49:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:49:52 +0000 UTC  }]
Apr 16 12:50:36.292: INFO: ss-2  k8s-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:13 +0000 UTC  }]
Apr 16 12:50:36.292: INFO: 
Apr 16 12:50:36.292: INFO: StatefulSet ss has not reached scale 0, at 2
Apr 16 12:50:37.297: INFO: POD   NODE   PHASE    GRACE  CONDITIONS
Apr 16 12:50:37.297: INFO: ss-0  k8s-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:49:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:49:52 +0000 UTC  }]
Apr 16 12:50:37.297: INFO: ss-2  k8s-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:13 +0000 UTC  }]
Apr 16 12:50:37.297: INFO: 
Apr 16 12:50:37.297: INFO: StatefulSet ss has not reached scale 0, at 2
Apr 16 12:50:38.303: INFO: POD   NODE   PHASE    GRACE  CONDITIONS
Apr 16 12:50:38.303: INFO: ss-0  k8s-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:49:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:49:52 +0000 UTC  }]
Apr 16 12:50:38.303: INFO: ss-2  k8s-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:13 +0000 UTC  }]
Apr 16 12:50:38.303: INFO: 
Apr 16 12:50:38.303: INFO: StatefulSet ss has not reached scale 0, at 2
Apr 16 12:50:39.310: INFO: POD   NODE   PHASE    GRACE  CONDITIONS
Apr 16 12:50:39.310: INFO: ss-0  k8s-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:49:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:49:52 +0000 UTC  }]
Apr 16 12:50:39.310: INFO: ss-2  k8s-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:13 +0000 UTC  }]
Apr 16 12:50:39.310: INFO: 
Apr 16 12:50:39.310: INFO: StatefulSet ss has not reached scale 0, at 2
Apr 16 12:50:40.318: INFO: POD   NODE   PHASE    GRACE  CONDITIONS
Apr 16 12:50:40.319: INFO: ss-2  k8s-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:13 +0000 UTC  }]
Apr 16 12:50:40.319: INFO: 
Apr 16 12:50:40.319: INFO: StatefulSet ss has not reached scale 0, at 1
Apr 16 12:50:41.324: INFO: POD   NODE   PHASE    GRACE  CONDITIONS
Apr 16 12:50:41.324: INFO: ss-2  k8s-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:13 +0000 UTC  }]
Apr 16 12:50:41.324: INFO: 
Apr 16 12:50:41.324: INFO: StatefulSet ss has not reached scale 0, at 1
Apr 16 12:50:42.330: INFO: POD   NODE   PHASE    GRACE  CONDITIONS
Apr 16 12:50:42.330: INFO: ss-2  k8s-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:13 +0000 UTC  }]
Apr 16 12:50:42.330: INFO: 
Apr 16 12:50:42.330: INFO: StatefulSet ss has not reached scale 0, at 1
Apr 16 12:50:43.339: INFO: POD   NODE   PHASE    GRACE  CONDITIONS
Apr 16 12:50:43.339: INFO: ss-2  k8s-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 12:50:13 +0000 UTC  }]
Apr 16 12:50:43.339: INFO: 
Apr 16 12:50:43.339: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-mrd5w
Apr 16 12:50:44.352: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 16 12:50:44.444: INFO: rc: 1
Apr 16 12:50:44.445: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc000c48a80 exit status 1 <nil> <nil> true [0xc000fac520 0xc000fac578 0xc000fac5a0] [0xc000fac520 0xc000fac578 0xc000fac5a0] [0xc000fac558 0xc000fac598] [0x92f8e0 0x92f8e0] 0xc002953620 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Apr 16 12:50:54.447: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 16 12:50:54.526: INFO: rc: 1
Apr 16 12:50:54.526: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000c48e40 exit status 1 <nil> <nil> true [0xc000fac5a8 0xc000fac5c0 0xc000fac5e0] [0xc000fac5a8 0xc000fac5c0 0xc000fac5e0] [0xc000fac5b8 0xc000fac5d0] [0x92f8e0 0x92f8e0] 0xc002953980 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 16 12:51:04.526: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 16 12:51:04.618: INFO: rc: 1
Apr 16 12:51:04.618: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000c49200 exit status 1 <nil> <nil> true [0xc000fac5e8 0xc000fac600 0xc000fac618] [0xc000fac5e8 0xc000fac600 0xc000fac618] [0xc000fac5f8 0xc000fac610] [0x92f8e0 0x92f8e0] 0xc002953c80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 16 12:51:14.618: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 16 12:51:14.704: INFO: rc: 1
Apr 16 12:51:14.704: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000c49830 exit status 1 <nil> <nil> true [0xc000fac620 0xc000fac638 0xc000fac650] [0xc000fac620 0xc000fac638 0xc000fac650] [0xc000fac630 0xc000fac648] [0x92f8e0 0x92f8e0] 0xc002953f80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 16 12:51:24.704: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 16 12:51:24.776: INFO: rc: 1
Apr 16 12:51:24.776: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000c49f50 exit status 1 <nil> <nil> true [0xc000fac658 0xc000fac670 0xc000fac688] [0xc000fac658 0xc000fac670 0xc000fac688] [0xc000fac668 0xc000fac680] [0x92f8e0 0x92f8e0] 0xc0008ee2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 16 12:51:34.776: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 16 12:51:34.844: INFO: rc: 1
Apr 16 12:51:34.845: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000c9a5a0 exit status 1 <nil> <nil> true [0xc000fac690 0xc000fac6a8 0xc000fac6c0] [0xc000fac690 0xc000fac6a8 0xc000fac6c0] [0xc000fac6a0 0xc000fac6b8] [0x92f8e0 0x92f8e0] 0xc0008ee600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 16 12:51:44.845: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 16 12:51:44.915: INFO: rc: 1
Apr 16 12:51:44.915: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000c9a9c0 exit status 1 <nil> <nil> true [0xc000fac6c8 0xc000fac6f0 0xc000fac708] [0xc000fac6c8 0xc000fac6f0 0xc000fac708] [0xc000fac6e8 0xc000fac700] [0x92f8e0 0x92f8e0] 0xc0008ee960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 16 12:51:54.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 16 12:51:54.982: INFO: rc: 1
Apr 16 12:51:54.982: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000c9ad80 exit status 1 <nil> <nil> true [0xc000fac710 0xc000fac728 0xc000fac740] [0xc000fac710 0xc000fac728 0xc000fac740] [0xc000fac720 0xc000fac738] [0x92f8e0 0x92f8e0] 0xc0008eec60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 16 12:52:04.983: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 16 12:52:05.054: INFO: rc: 1
Apr 16 12:52:05.054: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000c9b4d0 exit status 1 <nil> <nil> true [0xc000fac748 0xc000fac760 0xc000fac778] [0xc000fac748 0xc000fac760 0xc000fac778] [0xc000fac758 0xc000fac770] [0x92f8e0 0x92f8e0] 0xc0008eefc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 16 12:52:15.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 16 12:52:15.135: INFO: rc: 1
Apr 16 12:52:15.135: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000c9bb60 exit status 1 <nil> <nil> true [0xc000fac780 0xc000fac798 0xc000fac7b0] [0xc000fac780 0xc000fac798 0xc000fac7b0] [0xc000fac790 0xc000fac7a8] [0x92f8e0 0x92f8e0] 0xc0008ef2c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 16 12:52:25.135: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 16 12:52:25.203: INFO: rc: 1
Apr 16 12:52:25.203: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000c9bf80 exit status 1 <nil> <nil> true [0xc000fac7b8 0xc000fac7d0 0xc000fac7e8] [0xc000fac7b8 0xc000fac7d0 0xc000fac7e8] [0xc000fac7c8 0xc000fac7e0] [0x92f8e0 0x92f8e0] 0xc0008ef620 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 16 12:52:35.203: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 16 12:52:35.288: INFO: rc: 1
Apr 16 12:52:35.288: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000c9a630 exit status 1 <nil> <nil> true [0xc000fac018 0xc000fac078 0xc000fac0c0] [0xc000fac018 0xc000fac078 0xc000fac0c0] [0xc000fac058 0xc000fac0b0] [0x92f8e0 0x92f8e0] 0xc002952240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 16 12:52:45.288: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 16 12:52:45.360: INFO: rc: 1
Apr 16 12:52:45.360: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000c9aa80 exit status 1 <nil> <nil> true [0xc000fac0d0 0xc000fac120 0xc000fac158] [0xc000fac0d0 0xc000fac120 0xc000fac158] [0xc000fac108 0xc000fac148] [0x92f8e0 0x92f8e0] 0xc002952540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 16 12:52:55.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 16 12:52:55.424: INFO: rc: 1
Apr 16 12:52:55.425: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000c9b0b0 exit status 1 <nil> <nil> true [0xc000fac190 0xc000fac1a8 0xc000fac1c8] [0xc000fac190 0xc000fac1a8 0xc000fac1c8] [0xc000fac1a0 0xc000fac1b8] [0x92f8e0 0x92f8e0] 0xc002952840 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 16 12:53:05.425: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 16 12:53:05.498: INFO: rc: 1
Apr 16 12:53:05.498: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000c9b5f0 exit status 1 <nil> <nil> true [0xc000fac1e0 0xc000fac220 0xc000fac268] [0xc000fac1e0 0xc000fac220 0xc000fac268] [0xc000fac208 0xc000fac240] [0x92f8e0 0x92f8e0] 0xc002952b40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 16 12:53:15.499: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 16 12:53:15.565: INFO: rc: 1
Apr 16 12:53:15.565: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000c9bce0 exit status 1 <nil> <nil> true [0xc000fac278 0xc000fac2b8 0xc000fac310] [0xc000fac278 0xc000fac2b8 0xc000fac310] [0xc000fac2a8 0xc000fac2e8] [0x92f8e0 0x92f8e0] 0xc002952e40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 16 12:53:25.565: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 16 12:53:25.635: INFO: rc: 1
Apr 16 12:53:25.635: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000c48120 exit status 1 <nil> <nil> true [0xc000fac320 0xc000fac380 0xc000fac398] [0xc000fac320 0xc000fac380 0xc000fac398] [0xc000fac378 0xc000fac390] [0x92f8e0 0x92f8e0] 0xc002953140 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 16 12:53:35.636: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 16 12:53:35.704: INFO: rc: 1
Apr 16 12:53:35.704: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000c486c0 exit status 1 <nil> <nil> true [0xc000fac3a0 0xc000fac3b8 0xc000fac3d0] [0xc000fac3a0 0xc000fac3b8 0xc000fac3d0] [0xc000fac3b0 0xc000fac3c8] [0x92f8e0 0x92f8e0] 0xc0029534a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 16 12:53:45.705: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 16 12:53:45.796: INFO: rc: 1
Apr 16 12:53:45.796: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000c48b40 exit status 1 <nil> <nil> true [0xc000fac3d8 0xc000fac3f0 0xc000fac408] [0xc000fac3d8 0xc000fac3f0 0xc000fac408] [0xc000fac3e8 0xc000fac400] [0x92f8e0 0x92f8e0] 0xc002953800 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 16 12:53:55.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 16 12:53:55.864: INFO: rc: 1
Apr 16 12:53:55.864: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000c48f30 exit status 1 <nil> <nil> true [0xc000fac410 0xc000fac430 0xc000fac480] [0xc000fac410 0xc000fac430 0xc000fac480] [0xc000fac420 0xc000fac468] [0x92f8e0 0x92f8e0] 0xc002953b00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 16 12:54:05.864: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 16 12:54:05.933: INFO: rc: 1
Apr 16 12:54:05.933: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000c49320 exit status 1 <nil> <nil> true [0xc000fac498 0xc000fac4c0 0xc000fac4d8] [0xc000fac498 0xc000fac4c0 0xc000fac4d8] [0xc000fac4b8 0xc000fac4d0] [0x92f8e0 0x92f8e0] 0xc002953e00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 16 12:54:15.933: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 16 12:54:15.999: INFO: rc: 1
Apr 16 12:54:16.000: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000c49980 exit status 1 <nil> <nil> true [0xc000fac4e0 0xc000fac500 0xc000fac538] [0xc000fac4e0 0xc000fac500 0xc000fac538] [0xc000fac4f0 0xc000fac520] [0x92f8e0 0x92f8e0] 0xc0008ee120 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 16 12:54:26.000: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 16 12:54:26.074: INFO: rc: 1
Apr 16 12:54:26.074: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0014fe0f0 exit status 1 <nil> <nil> true [0xc000fac558 0xc000fac598 0xc000fac5b0] [0xc000fac558 0xc000fac598 0xc000fac5b0] [0xc000fac590 0xc000fac5a8] [0x92f8e0 0x92f8e0] 0xc0008ee420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 16 12:54:36.075: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 16 12:54:36.163: INFO: rc: 1
Apr 16 12:54:36.163: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0014fe780 exit status 1 <nil> <nil> true [0xc000fac5b8 0xc000fac5d0 0xc000fac5f0] [0xc000fac5b8 0xc000fac5d0 0xc000fac5f0] [0xc000fac5c8 0xc000fac5e8] [0x92f8e0 0x92f8e0] 0xc0008ee780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 16 12:54:46.164: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 16 12:54:46.232: INFO: rc: 1
Apr 16 12:54:46.232: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000c483f0 exit status 1 <nil> <nil> true [0xc000fac018 0xc000fac078 0xc000fac0c0] [0xc000fac018 0xc000fac078 0xc000fac0c0] [0xc000fac058 0xc000fac0b0] [0x92f8e0 0x92f8e0] 0xc002952240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 16 12:54:56.232: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 16 12:54:56.296: INFO: rc: 1
Apr 16 12:54:56.296: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000c48a20 exit status 1 <nil> <nil> true [0xc000fac0d0 0xc000fac120 0xc000fac158] [0xc000fac0d0 0xc000fac120 0xc000fac158] [0xc000fac108 0xc000fac148] [0x92f8e0 0x92f8e0] 0xc002952540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 16 12:55:06.296: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 16 12:55:06.366: INFO: rc: 1
Apr 16 12:55:06.366: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000c48e10 exit status 1 <nil> <nil> true [0xc000fac190 0xc000fac1a8 0xc000fac1c8] [0xc000fac190 0xc000fac1a8 0xc000fac1c8] [0xc000fac1a0 0xc000fac1b8] [0x92f8e0 0x92f8e0] 0xc002952840 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 16 12:55:16.368: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 16 12:55:16.437: INFO: rc: 1
Apr 16 12:55:16.437: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000c49200 exit status 1 <nil> <nil> true [0xc000fac1e0 0xc000fac220 0xc000fac268] [0xc000fac1e0 0xc000fac220 0xc000fac268] [0xc000fac208 0xc000fac240] [0x92f8e0 0x92f8e0] 0xc002952b40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 16 12:55:26.438: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 16 12:55:26.509: INFO: rc: 1
Apr 16 12:55:26.509: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000c49860 exit status 1 <nil> <nil> true [0xc000fac278 0xc000fac2b8 0xc000fac310] [0xc000fac278 0xc000fac2b8 0xc000fac310] [0xc000fac2a8 0xc000fac2e8] [0x92f8e0 0x92f8e0] 0xc002952e40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 16 12:55:36.511: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 16 12:55:36.593: INFO: rc: 1
Apr 16 12:55:36.593: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000c49fb0 exit status 1 <nil> <nil> true [0xc000fac320 0xc000fac380 0xc000fac398] [0xc000fac320 0xc000fac380 0xc000fac398] [0xc000fac378 0xc000fac390] [0x92f8e0 0x92f8e0] 0xc002953140 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr 16 12:55:46.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-mrd5w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 16 12:55:46.678: INFO: rc: 1
Apr 16 12:55:46.678: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: 
Apr 16 12:55:46.678: INFO: Scaling statefulset ss to 0
Apr 16 12:55:46.688: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr 16 12:55:46.691: INFO: Deleting all statefulset in ns e2e-tests-statefulset-mrd5w
Apr 16 12:55:46.693: INFO: Scaling statefulset ss to 0
Apr 16 12:55:46.702: INFO: Waiting for statefulset status.replicas updated to 0
Apr 16 12:55:46.704: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:55:46.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-mrd5w" for this suite.
Apr 16 12:55:52.745: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:55:52.791: INFO: namespace: e2e-tests-statefulset-mrd5w, resource: bindings, ignored listing per whitelist
Apr 16 12:55:52.840: INFO: namespace e2e-tests-statefulset-mrd5w deletion completed in 6.117884721s

• [SLOW TEST:360.105 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:55:52.841: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:55:54.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-xpmv7" for this suite.
Apr 16 12:56:32.983: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:56:33.020: INFO: namespace: e2e-tests-kubelet-test-xpmv7, resource: bindings, ignored listing per whitelist
Apr 16 12:56:33.077: INFO: namespace e2e-tests-kubelet-test-xpmv7 deletion completed in 38.116752693s

• [SLOW TEST:40.236 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:56:33.078: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Apr 16 12:56:33.155: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0f8e4958-6047-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-downward-api-jsf27" to be "success or failure"
Apr 16 12:56:33.161: INFO: Pod "downwardapi-volume-0f8e4958-6047-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.582924ms
Apr 16 12:56:35.166: INFO: Pod "downwardapi-volume-0f8e4958-6047-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011283865s
STEP: Saw pod success
Apr 16 12:56:35.166: INFO: Pod "downwardapi-volume-0f8e4958-6047-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 12:56:35.170: INFO: Trying to get logs from node k8s-2 pod downwardapi-volume-0f8e4958-6047-11e9-be7e-0a580ae9423f container client-container: <nil>
STEP: delete the pod
Apr 16 12:56:35.205: INFO: Waiting for pod downwardapi-volume-0f8e4958-6047-11e9-be7e-0a580ae9423f to disappear
Apr 16 12:56:35.209: INFO: Pod downwardapi-volume-0f8e4958-6047-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:56:35.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-jsf27" for this suite.
Apr 16 12:56:41.230: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:56:41.318: INFO: namespace: e2e-tests-downward-api-jsf27, resource: bindings, ignored listing per whitelist
Apr 16 12:56:41.323: INFO: namespace e2e-tests-downward-api-jsf27 deletion completed in 6.110263944s

• [SLOW TEST:8.245 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:56:41.324: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Apr 16 12:56:41.392: INFO: Waiting up to 5m0s for pod "pod-147765e4-6047-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-emptydir-mmn8b" to be "success or failure"
Apr 16 12:56:41.398: INFO: Pod "pod-147765e4-6047-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.215034ms
Apr 16 12:56:43.411: INFO: Pod "pod-147765e4-6047-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019274868s
STEP: Saw pod success
Apr 16 12:56:43.411: INFO: Pod "pod-147765e4-6047-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 12:56:43.415: INFO: Trying to get logs from node k8s-3 pod pod-147765e4-6047-11e9-be7e-0a580ae9423f container test-container: <nil>
STEP: delete the pod
Apr 16 12:56:43.444: INFO: Waiting for pod pod-147765e4-6047-11e9-be7e-0a580ae9423f to disappear
Apr 16 12:56:43.448: INFO: Pod pod-147765e4-6047-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:56:43.448: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-mmn8b" for this suite.
Apr 16 12:56:49.482: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:56:49.573: INFO: namespace: e2e-tests-emptydir-mmn8b, resource: bindings, ignored listing per whitelist
Apr 16 12:56:49.575: INFO: namespace e2e-tests-emptydir-mmn8b deletion completed in 6.123912747s

• [SLOW TEST:8.251 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:56:49.577: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Apr 16 12:56:49.651: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1963696f-6047-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-downward-api-dsd7h" to be "success or failure"
Apr 16 12:56:49.655: INFO: Pod "downwardapi-volume-1963696f-6047-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.944698ms
Apr 16 12:56:51.661: INFO: Pod "downwardapi-volume-1963696f-6047-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009910424s
STEP: Saw pod success
Apr 16 12:56:51.661: INFO: Pod "downwardapi-volume-1963696f-6047-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 12:56:51.665: INFO: Trying to get logs from node k8s-3 pod downwardapi-volume-1963696f-6047-11e9-be7e-0a580ae9423f container client-container: <nil>
STEP: delete the pod
Apr 16 12:56:51.695: INFO: Waiting for pod downwardapi-volume-1963696f-6047-11e9-be7e-0a580ae9423f to disappear
Apr 16 12:56:51.699: INFO: Pod downwardapi-volume-1963696f-6047-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:56:51.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-dsd7h" for this suite.
Apr 16 12:56:57.718: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:56:57.739: INFO: namespace: e2e-tests-downward-api-dsd7h, resource: bindings, ignored listing per whitelist
Apr 16 12:56:57.821: INFO: namespace e2e-tests-downward-api-dsd7h deletion completed in 6.118457995s

• [SLOW TEST:8.244 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:56:57.822: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-8h4st A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-8h4st;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-8h4st A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-8h4st;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-8h4st.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-8h4st.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-8h4st.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-8h4st.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-8h4st.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-8h4st.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-8h4st.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-8h4st.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-8h4st.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-8h4st.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-8h4st.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-8h4st.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-8h4st.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 55.41.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.41.55_udp@PTR;check="$$(dig +tcp +noall +answer +search 55.41.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.41.55_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-8h4st A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-8h4st;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-8h4st A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-8h4st;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-8h4st.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-8h4st.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-8h4st.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-8h4st.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-8h4st.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-8h4st.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-8h4st.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-8h4st.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-8h4st.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-8h4st.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-8h4st.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-8h4st.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-8h4st.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 55.41.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.41.55_udp@PTR;check="$$(dig +tcp +noall +answer +search 55.41.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.41.55_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 16 12:56:59.967: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-8h4st/dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f: the server could not find the requested resource (get pods dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f)
Apr 16 12:56:59.972: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-8h4st/dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f: the server could not find the requested resource (get pods dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f)
Apr 16 12:56:59.979: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-8h4st from pod e2e-tests-dns-8h4st/dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f: the server could not find the requested resource (get pods dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f)
Apr 16 12:56:59.983: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-8h4st from pod e2e-tests-dns-8h4st/dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f: the server could not find the requested resource (get pods dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f)
Apr 16 12:56:59.988: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-8h4st.svc from pod e2e-tests-dns-8h4st/dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f: the server could not find the requested resource (get pods dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f)
Apr 16 12:56:59.992: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-8h4st.svc from pod e2e-tests-dns-8h4st/dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f: the server could not find the requested resource (get pods dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f)
Apr 16 12:56:59.996: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-8h4st.svc from pod e2e-tests-dns-8h4st/dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f: the server could not find the requested resource (get pods dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f)
Apr 16 12:57:00.000: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-8h4st.svc from pod e2e-tests-dns-8h4st/dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f: the server could not find the requested resource (get pods dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f)
Apr 16 12:57:00.004: INFO: Unable to read wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-8h4st.svc from pod e2e-tests-dns-8h4st/dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f: the server could not find the requested resource (get pods dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f)
Apr 16 12:57:00.008: INFO: Unable to read wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-8h4st.svc from pod e2e-tests-dns-8h4st/dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f: the server could not find the requested resource (get pods dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f)
Apr 16 12:57:00.011: INFO: Unable to read wheezy_udp@PodARecord from pod e2e-tests-dns-8h4st/dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f: the server could not find the requested resource (get pods dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f)
Apr 16 12:57:00.016: INFO: Unable to read wheezy_tcp@PodARecord from pod e2e-tests-dns-8h4st/dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f: the server could not find the requested resource (get pods dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f)
Apr 16 12:57:00.020: INFO: Unable to read 10.233.41.55_udp@PTR from pod e2e-tests-dns-8h4st/dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f: the server could not find the requested resource (get pods dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f)
Apr 16 12:57:00.024: INFO: Unable to read 10.233.41.55_tcp@PTR from pod e2e-tests-dns-8h4st/dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f: the server could not find the requested resource (get pods dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f)
Apr 16 12:57:00.027: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-8h4st/dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f: the server could not find the requested resource (get pods dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f)
Apr 16 12:57:00.031: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-8h4st/dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f: the server could not find the requested resource (get pods dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f)
Apr 16 12:57:00.035: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-8h4st from pod e2e-tests-dns-8h4st/dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f: the server could not find the requested resource (get pods dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f)
Apr 16 12:57:00.039: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-8h4st from pod e2e-tests-dns-8h4st/dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f: the server could not find the requested resource (get pods dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f)
Apr 16 12:57:00.044: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-8h4st.svc from pod e2e-tests-dns-8h4st/dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f: the server could not find the requested resource (get pods dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f)
Apr 16 12:57:00.049: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-8h4st.svc from pod e2e-tests-dns-8h4st/dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f: the server could not find the requested resource (get pods dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f)
Apr 16 12:57:00.053: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-8h4st.svc from pod e2e-tests-dns-8h4st/dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f: the server could not find the requested resource (get pods dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f)
Apr 16 12:57:00.057: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-8h4st.svc from pod e2e-tests-dns-8h4st/dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f: the server could not find the requested resource (get pods dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f)
Apr 16 12:57:00.062: INFO: Unable to read jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-8h4st.svc from pod e2e-tests-dns-8h4st/dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f: the server could not find the requested resource (get pods dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f)
Apr 16 12:57:00.066: INFO: Unable to read jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-8h4st.svc from pod e2e-tests-dns-8h4st/dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f: the server could not find the requested resource (get pods dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f)
Apr 16 12:57:00.072: INFO: Unable to read jessie_udp@PodARecord from pod e2e-tests-dns-8h4st/dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f: the server could not find the requested resource (get pods dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f)
Apr 16 12:57:00.085: INFO: Unable to read jessie_tcp@PodARecord from pod e2e-tests-dns-8h4st/dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f: the server could not find the requested resource (get pods dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f)
Apr 16 12:57:00.089: INFO: Unable to read 10.233.41.55_udp@PTR from pod e2e-tests-dns-8h4st/dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f: the server could not find the requested resource (get pods dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f)
Apr 16 12:57:00.093: INFO: Unable to read 10.233.41.55_tcp@PTR from pod e2e-tests-dns-8h4st/dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f: the server could not find the requested resource (get pods dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f)
Apr 16 12:57:00.093: INFO: Lookups using e2e-tests-dns-8h4st/dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-8h4st wheezy_tcp@dns-test-service.e2e-tests-dns-8h4st wheezy_udp@dns-test-service.e2e-tests-dns-8h4st.svc wheezy_tcp@dns-test-service.e2e-tests-dns-8h4st.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-8h4st.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-8h4st.svc wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-8h4st.svc wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-8h4st.svc wheezy_udp@PodARecord wheezy_tcp@PodARecord 10.233.41.55_udp@PTR 10.233.41.55_tcp@PTR jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-8h4st jessie_tcp@dns-test-service.e2e-tests-dns-8h4st jessie_udp@dns-test-service.e2e-tests-dns-8h4st.svc jessie_tcp@dns-test-service.e2e-tests-dns-8h4st.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-8h4st.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-8h4st.svc jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-8h4st.svc jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-8h4st.svc jessie_udp@PodARecord jessie_tcp@PodARecord 10.233.41.55_udp@PTR 10.233.41.55_tcp@PTR]

Apr 16 12:57:05.106: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-8h4st/dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f: the server could not find the requested resource (get pods dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f)
Apr 16 12:57:05.119: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-8h4st from pod e2e-tests-dns-8h4st/dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f: the server could not find the requested resource (get pods dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f)
Apr 16 12:57:05.128: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-8h4st.svc from pod e2e-tests-dns-8h4st/dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f: the server could not find the requested resource (get pods dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f)
Apr 16 12:57:05.181: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-8h4st/dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f: the server could not find the requested resource (get pods dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f)
Apr 16 12:57:05.186: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-8h4st/dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f: the server could not find the requested resource (get pods dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f)
Apr 16 12:57:05.190: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-8h4st from pod e2e-tests-dns-8h4st/dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f: the server could not find the requested resource (get pods dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f)
Apr 16 12:57:05.199: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-8h4st.svc from pod e2e-tests-dns-8h4st/dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f: the server could not find the requested resource (get pods dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f)
Apr 16 12:57:05.203: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-8h4st.svc from pod e2e-tests-dns-8h4st/dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f: the server could not find the requested resource (get pods dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f)
Apr 16 12:57:05.211: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-8h4st.svc from pod e2e-tests-dns-8h4st/dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f: the server could not find the requested resource (get pods dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f)
Apr 16 12:57:05.215: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-8h4st.svc from pod e2e-tests-dns-8h4st/dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f: the server could not find the requested resource (get pods dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f)
Apr 16 12:57:05.220: INFO: Unable to read jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-8h4st.svc from pod e2e-tests-dns-8h4st/dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f: the server could not find the requested resource (get pods dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f)
Apr 16 12:57:05.224: INFO: Unable to read jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-8h4st.svc from pod e2e-tests-dns-8h4st/dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f: the server could not find the requested resource (get pods dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f)
Apr 16 12:57:05.232: INFO: Unable to read jessie_udp@PodARecord from pod e2e-tests-dns-8h4st/dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f: the server could not find the requested resource (get pods dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f)
Apr 16 12:57:05.240: INFO: Unable to read jessie_tcp@PodARecord from pod e2e-tests-dns-8h4st/dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f: the server could not find the requested resource (get pods dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f)
Apr 16 12:57:05.251: INFO: Lookups using e2e-tests-dns-8h4st/dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f failed for: [wheezy_udp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-8h4st wheezy_udp@dns-test-service.e2e-tests-dns-8h4st.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-8h4st jessie_udp@dns-test-service.e2e-tests-dns-8h4st.svc jessie_tcp@dns-test-service.e2e-tests-dns-8h4st.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-8h4st.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-8h4st.svc jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-8h4st.svc jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-8h4st.svc jessie_udp@PodARecord jessie_tcp@PodARecord]

Apr 16 12:57:10.252: INFO: DNS probes using e2e-tests-dns-8h4st/dns-test-1e50cdae-6047-11e9-be7e-0a580ae9423f succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:57:10.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-8h4st" for this suite.
Apr 16 12:57:16.382: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:57:16.479: INFO: namespace: e2e-tests-dns-8h4st, resource: bindings, ignored listing per whitelist
Apr 16 12:57:16.487: INFO: namespace e2e-tests-dns-8h4st deletion completed in 6.135520497s

• [SLOW TEST:18.666 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:57:16.488: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-vz9cr
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 16 12:57:16.553: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr 16 12:57:38.710: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.233.64.166 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-vz9cr PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 16 12:57:38.710: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
Apr 16 12:57:39.805: INFO: Found all expected endpoints: [netserver-0]
Apr 16 12:57:39.811: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.233.65.134 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-vz9cr PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 16 12:57:39.811: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
Apr 16 12:57:40.888: INFO: Found all expected endpoints: [netserver-1]
Apr 16 12:57:40.893: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.233.66.168 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-vz9cr PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 16 12:57:40.893: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
Apr 16 12:57:41.969: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:57:41.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-vz9cr" for this suite.
Apr 16 12:58:03.995: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:58:04.023: INFO: namespace: e2e-tests-pod-network-test-vz9cr, resource: bindings, ignored listing per whitelist
Apr 16 12:58:04.102: INFO: namespace e2e-tests-pod-network-test-vz9cr deletion completed in 22.128484979s

• [SLOW TEST:47.614 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:58:04.104: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-wn6n
STEP: Creating a pod to test atomic-volume-subpath
Apr 16 12:58:04.217: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-wn6n" in namespace "e2e-tests-subpath-dkzp4" to be "success or failure"
Apr 16 12:58:04.226: INFO: Pod "pod-subpath-test-secret-wn6n": Phase="Pending", Reason="", readiness=false. Elapsed: 8.151447ms
Apr 16 12:58:06.232: INFO: Pod "pod-subpath-test-secret-wn6n": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014046187s
Apr 16 12:58:08.236: INFO: Pod "pod-subpath-test-secret-wn6n": Phase="Running", Reason="", readiness=false. Elapsed: 4.018078893s
Apr 16 12:58:10.246: INFO: Pod "pod-subpath-test-secret-wn6n": Phase="Running", Reason="", readiness=false. Elapsed: 6.028666827s
Apr 16 12:58:12.253: INFO: Pod "pod-subpath-test-secret-wn6n": Phase="Running", Reason="", readiness=false. Elapsed: 8.035379631s
Apr 16 12:58:14.258: INFO: Pod "pod-subpath-test-secret-wn6n": Phase="Running", Reason="", readiness=false. Elapsed: 10.040386118s
Apr 16 12:58:16.264: INFO: Pod "pod-subpath-test-secret-wn6n": Phase="Running", Reason="", readiness=false. Elapsed: 12.046160857s
Apr 16 12:58:18.270: INFO: Pod "pod-subpath-test-secret-wn6n": Phase="Running", Reason="", readiness=false. Elapsed: 14.051987376s
Apr 16 12:58:20.282: INFO: Pod "pod-subpath-test-secret-wn6n": Phase="Running", Reason="", readiness=false. Elapsed: 16.064755015s
Apr 16 12:58:22.290: INFO: Pod "pod-subpath-test-secret-wn6n": Phase="Running", Reason="", readiness=false. Elapsed: 18.072521717s
Apr 16 12:58:24.296: INFO: Pod "pod-subpath-test-secret-wn6n": Phase="Running", Reason="", readiness=false. Elapsed: 20.078059467s
Apr 16 12:58:26.302: INFO: Pod "pod-subpath-test-secret-wn6n": Phase="Running", Reason="", readiness=false. Elapsed: 22.084307543s
Apr 16 12:58:28.307: INFO: Pod "pod-subpath-test-secret-wn6n": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.089805552s
STEP: Saw pod success
Apr 16 12:58:28.307: INFO: Pod "pod-subpath-test-secret-wn6n" satisfied condition "success or failure"
Apr 16 12:58:28.312: INFO: Trying to get logs from node k8s-1 pod pod-subpath-test-secret-wn6n container test-container-subpath-secret-wn6n: <nil>
STEP: delete the pod
Apr 16 12:58:28.344: INFO: Waiting for pod pod-subpath-test-secret-wn6n to disappear
Apr 16 12:58:28.347: INFO: Pod pod-subpath-test-secret-wn6n no longer exists
STEP: Deleting pod pod-subpath-test-secret-wn6n
Apr 16 12:58:28.347: INFO: Deleting pod "pod-subpath-test-secret-wn6n" in namespace "e2e-tests-subpath-dkzp4"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:58:28.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-dkzp4" for this suite.
Apr 16 12:58:34.371: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:58:34.492: INFO: namespace: e2e-tests-subpath-dkzp4, resource: bindings, ignored listing per whitelist
Apr 16 12:58:34.539: INFO: namespace e2e-tests-subpath-dkzp4 deletion completed in 6.184935369s

• [SLOW TEST:30.435 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:58:34.539: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Apr 16 12:58:34.618: INFO: Waiting up to 5m0s for pod "client-containers-57f42f5b-6047-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-containers-nqkkj" to be "success or failure"
Apr 16 12:58:34.621: INFO: Pod "client-containers-57f42f5b-6047-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.592242ms
Apr 16 12:58:36.628: INFO: Pod "client-containers-57f42f5b-6047-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009812971s
Apr 16 12:58:38.633: INFO: Pod "client-containers-57f42f5b-6047-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014723615s
STEP: Saw pod success
Apr 16 12:58:38.633: INFO: Pod "client-containers-57f42f5b-6047-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 12:58:38.637: INFO: Trying to get logs from node k8s-2 pod client-containers-57f42f5b-6047-11e9-be7e-0a580ae9423f container test-container: <nil>
STEP: delete the pod
Apr 16 12:58:38.677: INFO: Waiting for pod client-containers-57f42f5b-6047-11e9-be7e-0a580ae9423f to disappear
Apr 16 12:58:38.686: INFO: Pod client-containers-57f42f5b-6047-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:58:38.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-nqkkj" for this suite.
Apr 16 12:58:44.710: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:58:44.749: INFO: namespace: e2e-tests-containers-nqkkj, resource: bindings, ignored listing per whitelist
Apr 16 12:58:44.811: INFO: namespace e2e-tests-containers-nqkkj deletion completed in 6.118859624s

• [SLOW TEST:10.272 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:58:44.812: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Apr 16 12:58:44.891: INFO: Waiting up to 5m0s for pod "downward-api-5e13d49d-6047-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-downward-api-hmzwf" to be "success or failure"
Apr 16 12:58:44.896: INFO: Pod "downward-api-5e13d49d-6047-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.313518ms
Apr 16 12:58:46.903: INFO: Pod "downward-api-5e13d49d-6047-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012261778s
STEP: Saw pod success
Apr 16 12:58:46.903: INFO: Pod "downward-api-5e13d49d-6047-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 12:58:46.907: INFO: Trying to get logs from node k8s-3 pod downward-api-5e13d49d-6047-11e9-be7e-0a580ae9423f container dapi-container: <nil>
STEP: delete the pod
Apr 16 12:58:46.964: INFO: Waiting for pod downward-api-5e13d49d-6047-11e9-be7e-0a580ae9423f to disappear
Apr 16 12:58:46.970: INFO: Pod downward-api-5e13d49d-6047-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:58:46.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-hmzwf" for this suite.
Apr 16 12:58:52.995: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:58:53.076: INFO: namespace: e2e-tests-downward-api-hmzwf, resource: bindings, ignored listing per whitelist
Apr 16 12:58:53.094: INFO: namespace e2e-tests-downward-api-hmzwf deletion completed in 6.118993653s

• [SLOW TEST:8.283 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:58:53.096: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Apr 16 12:58:53.174: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6302a6b8-6047-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-projected-g25n4" to be "success or failure"
Apr 16 12:58:53.184: INFO: Pod "downwardapi-volume-6302a6b8-6047-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.445137ms
Apr 16 12:58:55.189: INFO: Pod "downwardapi-volume-6302a6b8-6047-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015510557s
STEP: Saw pod success
Apr 16 12:58:55.189: INFO: Pod "downwardapi-volume-6302a6b8-6047-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 12:58:55.198: INFO: Trying to get logs from node k8s-3 pod downwardapi-volume-6302a6b8-6047-11e9-be7e-0a580ae9423f container client-container: <nil>
STEP: delete the pod
Apr 16 12:58:55.225: INFO: Waiting for pod downwardapi-volume-6302a6b8-6047-11e9-be7e-0a580ae9423f to disappear
Apr 16 12:58:55.232: INFO: Pod downwardapi-volume-6302a6b8-6047-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:58:55.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-g25n4" for this suite.
Apr 16 12:59:01.258: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:59:01.346: INFO: namespace: e2e-tests-projected-g25n4, resource: bindings, ignored listing per whitelist
Apr 16 12:59:01.355: INFO: namespace e2e-tests-projected-g25n4 deletion completed in 6.119320539s

• [SLOW TEST:8.260 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:59:01.356: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0416 12:59:11.463173      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr 16 12:59:11.463: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:59:11.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-jq74c" for this suite.
Apr 16 12:59:17.485: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:59:17.507: INFO: namespace: e2e-tests-gc-jq74c, resource: bindings, ignored listing per whitelist
Apr 16 12:59:17.611: INFO: namespace e2e-tests-gc-jq74c deletion completed in 6.144974032s

• [SLOW TEST:16.255 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:59:17.612: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Apr 16 12:59:35.711: INFO: Container started at 2019-04-16 12:59:18 +0000 UTC, pod became ready at 2019-04-16 12:59:35 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 12:59:35.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-5fssf" for this suite.
Apr 16 12:59:57.732: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 12:59:57.789: INFO: namespace: e2e-tests-container-probe-5fssf, resource: bindings, ignored listing per whitelist
Apr 16 12:59:57.853: INFO: namespace e2e-tests-container-probe-5fssf deletion completed in 22.137843016s

• [SLOW TEST:40.241 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 12:59:57.855: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Apr 16 12:59:57.930: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 create -f - --namespace=e2e-tests-kubectl-tf2t7'
Apr 16 12:59:58.524: INFO: stderr: ""
Apr 16 12:59:58.524: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 16 12:59:58.524: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-tf2t7'
Apr 16 12:59:58.652: INFO: stderr: ""
Apr 16 12:59:58.652: INFO: stdout: "update-demo-nautilus-25tkf update-demo-nautilus-pzzz8 "
Apr 16 12:59:58.652: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 get pods update-demo-nautilus-25tkf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tf2t7'
Apr 16 12:59:58.748: INFO: stderr: ""
Apr 16 12:59:58.748: INFO: stdout: ""
Apr 16 12:59:58.748: INFO: update-demo-nautilus-25tkf is created but not running
Apr 16 13:00:03.749: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-tf2t7'
Apr 16 13:00:03.834: INFO: stderr: ""
Apr 16 13:00:03.834: INFO: stdout: "update-demo-nautilus-25tkf update-demo-nautilus-pzzz8 "
Apr 16 13:00:03.834: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 get pods update-demo-nautilus-25tkf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tf2t7'
Apr 16 13:00:03.911: INFO: stderr: ""
Apr 16 13:00:03.911: INFO: stdout: "true"
Apr 16 13:00:03.911: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 get pods update-demo-nautilus-25tkf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tf2t7'
Apr 16 13:00:03.986: INFO: stderr: ""
Apr 16 13:00:03.986: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 16 13:00:03.986: INFO: validating pod update-demo-nautilus-25tkf
Apr 16 13:00:03.997: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 16 13:00:03.997: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 16 13:00:03.997: INFO: update-demo-nautilus-25tkf is verified up and running
Apr 16 13:00:03.997: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 get pods update-demo-nautilus-pzzz8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tf2t7'
Apr 16 13:00:04.082: INFO: stderr: ""
Apr 16 13:00:04.082: INFO: stdout: "true"
Apr 16 13:00:04.082: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 get pods update-demo-nautilus-pzzz8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tf2t7'
Apr 16 13:00:04.183: INFO: stderr: ""
Apr 16 13:00:04.183: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 16 13:00:04.183: INFO: validating pod update-demo-nautilus-pzzz8
Apr 16 13:00:04.197: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 16 13:00:04.197: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 16 13:00:04.197: INFO: update-demo-nautilus-pzzz8 is verified up and running
STEP: scaling down the replication controller
Apr 16 13:00:04.198: INFO: scanned /root for discovery docs: <nil>
Apr 16 13:00:04.199: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-tf2t7'
Apr 16 13:00:05.302: INFO: stderr: ""
Apr 16 13:00:05.302: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 16 13:00:05.302: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-tf2t7'
Apr 16 13:00:05.375: INFO: stderr: ""
Apr 16 13:00:05.375: INFO: stdout: "update-demo-nautilus-25tkf update-demo-nautilus-pzzz8 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Apr 16 13:00:10.375: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-tf2t7'
Apr 16 13:00:10.458: INFO: stderr: ""
Apr 16 13:00:10.458: INFO: stdout: "update-demo-nautilus-pzzz8 "
Apr 16 13:00:10.458: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 get pods update-demo-nautilus-pzzz8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tf2t7'
Apr 16 13:00:10.535: INFO: stderr: ""
Apr 16 13:00:10.535: INFO: stdout: "true"
Apr 16 13:00:10.535: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 get pods update-demo-nautilus-pzzz8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tf2t7'
Apr 16 13:00:10.624: INFO: stderr: ""
Apr 16 13:00:10.624: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 16 13:00:10.624: INFO: validating pod update-demo-nautilus-pzzz8
Apr 16 13:00:10.629: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 16 13:00:10.629: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 16 13:00:10.629: INFO: update-demo-nautilus-pzzz8 is verified up and running
STEP: scaling up the replication controller
Apr 16 13:00:10.630: INFO: scanned /root for discovery docs: <nil>
Apr 16 13:00:10.630: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-tf2t7'
Apr 16 13:00:11.754: INFO: stderr: ""
Apr 16 13:00:11.754: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 16 13:00:11.754: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-tf2t7'
Apr 16 13:00:11.838: INFO: stderr: ""
Apr 16 13:00:11.838: INFO: stdout: "update-demo-nautilus-9k6b7 update-demo-nautilus-pzzz8 "
Apr 16 13:00:11.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 get pods update-demo-nautilus-9k6b7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tf2t7'
Apr 16 13:00:11.916: INFO: stderr: ""
Apr 16 13:00:11.916: INFO: stdout: ""
Apr 16 13:00:11.916: INFO: update-demo-nautilus-9k6b7 is created but not running
Apr 16 13:00:16.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-tf2t7'
Apr 16 13:00:17.005: INFO: stderr: ""
Apr 16 13:00:17.005: INFO: stdout: "update-demo-nautilus-9k6b7 update-demo-nautilus-pzzz8 "
Apr 16 13:00:17.006: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 get pods update-demo-nautilus-9k6b7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tf2t7'
Apr 16 13:00:17.078: INFO: stderr: ""
Apr 16 13:00:17.078: INFO: stdout: "true"
Apr 16 13:00:17.078: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 get pods update-demo-nautilus-9k6b7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tf2t7'
Apr 16 13:00:17.151: INFO: stderr: ""
Apr 16 13:00:17.151: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 16 13:00:17.151: INFO: validating pod update-demo-nautilus-9k6b7
Apr 16 13:00:17.157: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 16 13:00:17.157: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 16 13:00:17.157: INFO: update-demo-nautilus-9k6b7 is verified up and running
Apr 16 13:00:17.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 get pods update-demo-nautilus-pzzz8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tf2t7'
Apr 16 13:00:17.229: INFO: stderr: ""
Apr 16 13:00:17.229: INFO: stdout: "true"
Apr 16 13:00:17.229: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 get pods update-demo-nautilus-pzzz8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tf2t7'
Apr 16 13:00:17.304: INFO: stderr: ""
Apr 16 13:00:17.304: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 16 13:00:17.304: INFO: validating pod update-demo-nautilus-pzzz8
Apr 16 13:00:17.309: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 16 13:00:17.309: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 16 13:00:17.309: INFO: update-demo-nautilus-pzzz8 is verified up and running
STEP: using delete to clean up resources
Apr 16 13:00:17.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-tf2t7'
Apr 16 13:00:17.399: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 16 13:00:17.399: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Apr 16 13:00:17.399: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-tf2t7'
Apr 16 13:00:17.627: INFO: stderr: "No resources found.\n"
Apr 16 13:00:17.627: INFO: stdout: ""
Apr 16 13:00:17.627: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 get pods -l name=update-demo --namespace=e2e-tests-kubectl-tf2t7 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 16 13:00:17.809: INFO: stderr: ""
Apr 16 13:00:17.809: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 13:00:17.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-tf2t7" for this suite.
Apr 16 13:00:39.832: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 13:00:39.878: INFO: namespace: e2e-tests-kubectl-tf2t7, resource: bindings, ignored listing per whitelist
Apr 16 13:00:39.957: INFO: namespace e2e-tests-kubectl-tf2t7 deletion completed in 22.143517072s

• [SLOW TEST:42.103 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 13:00:39.958: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Apr 16 13:00:40.115: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"a2bbef65-6047-11e9-8569-0800277031c6", Controller:(*bool)(0xc000c73d4e), BlockOwnerDeletion:(*bool)(0xc000c73d4f)}}
Apr 16 13:00:40.170: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"a2b75d18-6047-11e9-8569-0800277031c6", Controller:(*bool)(0xc001df807e), BlockOwnerDeletion:(*bool)(0xc001df807f)}}
Apr 16 13:00:40.191: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"a2b9dfc0-6047-11e9-8569-0800277031c6", Controller:(*bool)(0xc001df827e), BlockOwnerDeletion:(*bool)(0xc001df827f)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 13:00:45.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-946wc" for this suite.
Apr 16 13:00:51.249: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 13:00:51.353: INFO: namespace: e2e-tests-gc-946wc, resource: bindings, ignored listing per whitelist
Apr 16 13:00:51.353: INFO: namespace e2e-tests-gc-946wc deletion completed in 6.121882742s

• [SLOW TEST:11.395 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 13:00:51.354: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Apr 16 13:00:51.437: INFO: Waiting up to 5m0s for pod "var-expansion-a9809466-6047-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-var-expansion-fmsk5" to be "success or failure"
Apr 16 13:00:51.442: INFO: Pod "var-expansion-a9809466-6047-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.833214ms
Apr 16 13:00:53.447: INFO: Pod "var-expansion-a9809466-6047-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010025836s
STEP: Saw pod success
Apr 16 13:00:53.447: INFO: Pod "var-expansion-a9809466-6047-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 13:00:53.450: INFO: Trying to get logs from node k8s-3 pod var-expansion-a9809466-6047-11e9-be7e-0a580ae9423f container dapi-container: <nil>
STEP: delete the pod
Apr 16 13:00:53.478: INFO: Waiting for pod var-expansion-a9809466-6047-11e9-be7e-0a580ae9423f to disappear
Apr 16 13:00:53.482: INFO: Pod var-expansion-a9809466-6047-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 13:00:53.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-fmsk5" for this suite.
Apr 16 13:00:59.500: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 13:00:59.564: INFO: namespace: e2e-tests-var-expansion-fmsk5, resource: bindings, ignored listing per whitelist
Apr 16 13:00:59.618: INFO: namespace e2e-tests-var-expansion-fmsk5 deletion completed in 6.132841521s

• [SLOW TEST:8.264 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 13:00:59.619: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Apr 16 13:01:03.766: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 16 13:01:03.772: INFO: Pod pod-with-poststart-http-hook still exists
Apr 16 13:01:05.773: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 16 13:01:05.783: INFO: Pod pod-with-poststart-http-hook still exists
Apr 16 13:01:07.773: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 16 13:01:07.778: INFO: Pod pod-with-poststart-http-hook still exists
Apr 16 13:01:09.772: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 16 13:01:09.777: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 13:01:09.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-xfgbt" for this suite.
Apr 16 13:01:31.798: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 13:01:31.882: INFO: namespace: e2e-tests-container-lifecycle-hook-xfgbt, resource: bindings, ignored listing per whitelist
Apr 16 13:01:31.910: INFO: namespace e2e-tests-container-lifecycle-hook-xfgbt deletion completed in 22.129259845s

• [SLOW TEST:32.292 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 13:01:31.911: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-c1af1108-6047-11e9-be7e-0a580ae9423f
STEP: Creating a pod to test consume secrets
Apr 16 13:01:32.008: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c1b0170b-6047-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-projected-g2g7t" to be "success or failure"
Apr 16 13:01:32.011: INFO: Pod "pod-projected-secrets-c1b0170b-6047-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.987822ms
Apr 16 13:01:34.017: INFO: Pod "pod-projected-secrets-c1b0170b-6047-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00914654s
STEP: Saw pod success
Apr 16 13:01:34.017: INFO: Pod "pod-projected-secrets-c1b0170b-6047-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 13:01:34.021: INFO: Trying to get logs from node k8s-3 pod pod-projected-secrets-c1b0170b-6047-11e9-be7e-0a580ae9423f container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 16 13:01:34.052: INFO: Waiting for pod pod-projected-secrets-c1b0170b-6047-11e9-be7e-0a580ae9423f to disappear
Apr 16 13:01:34.055: INFO: Pod pod-projected-secrets-c1b0170b-6047-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 13:01:34.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-g2g7t" for this suite.
Apr 16 13:01:40.075: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 13:01:40.170: INFO: namespace: e2e-tests-projected-g2g7t, resource: bindings, ignored listing per whitelist
Apr 16 13:01:40.245: INFO: namespace e2e-tests-projected-g2g7t deletion completed in 6.186191838s

• [SLOW TEST:8.334 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 13:01:40.246: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Apr 16 13:01:40.376: INFO: Waiting up to 5m0s for pod "client-containers-c6abbcfd-6047-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-containers-zsb4b" to be "success or failure"
Apr 16 13:01:40.390: INFO: Pod "client-containers-c6abbcfd-6047-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.072648ms
Apr 16 13:01:42.396: INFO: Pod "client-containers-c6abbcfd-6047-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019344091s
STEP: Saw pod success
Apr 16 13:01:42.396: INFO: Pod "client-containers-c6abbcfd-6047-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 13:01:42.400: INFO: Trying to get logs from node k8s-1 pod client-containers-c6abbcfd-6047-11e9-be7e-0a580ae9423f container test-container: <nil>
STEP: delete the pod
Apr 16 13:01:42.430: INFO: Waiting for pod client-containers-c6abbcfd-6047-11e9-be7e-0a580ae9423f to disappear
Apr 16 13:01:42.434: INFO: Pod client-containers-c6abbcfd-6047-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 13:01:42.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-zsb4b" for this suite.
Apr 16 13:01:48.461: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 13:01:48.487: INFO: namespace: e2e-tests-containers-zsb4b, resource: bindings, ignored listing per whitelist
Apr 16 13:01:48.560: INFO: namespace e2e-tests-containers-zsb4b deletion completed in 6.122677289s

• [SLOW TEST:8.314 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 13:01:48.561: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 16 13:01:48.645: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-5vv75'
Apr 16 13:01:48.727: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr 16 13:01:48.727: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1404
Apr 16 13:01:52.740: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-5vv75'
Apr 16 13:01:52.828: INFO: stderr: ""
Apr 16 13:01:52.828: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 13:01:52.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5vv75" for this suite.
Apr 16 13:01:58.862: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 13:01:58.929: INFO: namespace: e2e-tests-kubectl-5vv75, resource: bindings, ignored listing per whitelist
Apr 16 13:01:59.004: INFO: namespace e2e-tests-kubectl-5vv75 deletion completed in 6.172441453s

• [SLOW TEST:10.444 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 13:01:59.006: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-h2j6r
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Apr 16 13:01:59.102: INFO: Found 0 stateful pods, waiting for 3
Apr 16 13:02:09.113: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 16 13:02:09.113: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 16 13:02:09.113: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Apr 16 13:02:09.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-h2j6r ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 16 13:02:09.297: INFO: stderr: ""
Apr 16 13:02:09.297: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 16 13:02:09.297: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Apr 16 13:02:19.340: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Apr 16 13:02:29.369: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-h2j6r ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 16 13:02:29.529: INFO: stderr: ""
Apr 16 13:02:29.529: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 16 13:02:29.529: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 16 13:02:39.561: INFO: Waiting for StatefulSet e2e-tests-statefulset-h2j6r/ss2 to complete update
Apr 16 13:02:39.561: INFO: Waiting for Pod e2e-tests-statefulset-h2j6r/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr 16 13:02:39.561: INFO: Waiting for Pod e2e-tests-statefulset-h2j6r/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr 16 13:02:39.561: INFO: Waiting for Pod e2e-tests-statefulset-h2j6r/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr 16 13:02:49.590: INFO: Waiting for StatefulSet e2e-tests-statefulset-h2j6r/ss2 to complete update
Apr 16 13:02:49.590: INFO: Waiting for Pod e2e-tests-statefulset-h2j6r/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Apr 16 13:02:59.570: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-h2j6r ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 16 13:02:59.726: INFO: stderr: ""
Apr 16 13:02:59.726: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 16 13:02:59.726: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 16 13:03:09.770: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Apr 16 13:03:19.803: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 exec --namespace=e2e-tests-statefulset-h2j6r ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 16 13:03:20.003: INFO: stderr: ""
Apr 16 13:03:20.003: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 16 13:03:20.003: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr 16 13:03:40.031: INFO: Deleting all statefulset in ns e2e-tests-statefulset-h2j6r
Apr 16 13:03:40.034: INFO: Scaling statefulset ss2 to 0
Apr 16 13:04:00.059: INFO: Waiting for statefulset status.replicas updated to 0
Apr 16 13:04:00.072: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 13:04:00.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-h2j6r" for this suite.
Apr 16 13:04:06.123: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 13:04:06.205: INFO: namespace: e2e-tests-statefulset-h2j6r, resource: bindings, ignored listing per whitelist
Apr 16 13:04:06.240: INFO: namespace e2e-tests-statefulset-h2j6r deletion completed in 6.147962503s

• [SLOW TEST:127.233 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 13:04:06.241: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1358
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 16 13:04:06.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-6q4bj'
Apr 16 13:04:06.389: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr 16 13:04:06.389: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Apr 16 13:04:06.394: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Apr 16 13:04:06.408: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Apr 16 13:04:06.419: INFO: scanned /root for discovery docs: <nil>
Apr 16 13:04:06.419: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-6q4bj'
Apr 16 13:04:22.306: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Apr 16 13:04:22.306: INFO: stdout: "Created e2e-test-nginx-rc-7d33f0a3c271bf513b8addf2a3f5ff6e\nScaling up e2e-test-nginx-rc-7d33f0a3c271bf513b8addf2a3f5ff6e from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-7d33f0a3c271bf513b8addf2a3f5ff6e up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-7d33f0a3c271bf513b8addf2a3f5ff6e to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Apr 16 13:04:22.306: INFO: stdout: "Created e2e-test-nginx-rc-7d33f0a3c271bf513b8addf2a3f5ff6e\nScaling up e2e-test-nginx-rc-7d33f0a3c271bf513b8addf2a3f5ff6e from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-7d33f0a3c271bf513b8addf2a3f5ff6e up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-7d33f0a3c271bf513b8addf2a3f5ff6e to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Apr 16 13:04:22.306: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-6q4bj'
Apr 16 13:04:22.389: INFO: stderr: ""
Apr 16 13:04:22.389: INFO: stdout: "e2e-test-nginx-rc-7d33f0a3c271bf513b8addf2a3f5ff6e-pxzcg "
Apr 16 13:04:22.390: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 get pods e2e-test-nginx-rc-7d33f0a3c271bf513b8addf2a3f5ff6e-pxzcg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6q4bj'
Apr 16 13:04:22.460: INFO: stderr: ""
Apr 16 13:04:22.460: INFO: stdout: "true"
Apr 16 13:04:22.461: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 get pods e2e-test-nginx-rc-7d33f0a3c271bf513b8addf2a3f5ff6e-pxzcg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6q4bj'
Apr 16 13:04:22.529: INFO: stderr: ""
Apr 16 13:04:22.529: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Apr 16 13:04:22.529: INFO: e2e-test-nginx-rc-7d33f0a3c271bf513b8addf2a3f5ff6e-pxzcg is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1364
Apr 16 13:04:22.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-6q4bj'
Apr 16 13:04:22.629: INFO: stderr: ""
Apr 16 13:04:22.629: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 13:04:22.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6q4bj" for this suite.
Apr 16 13:04:44.673: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 13:04:44.768: INFO: namespace: e2e-tests-kubectl-6q4bj, resource: bindings, ignored listing per whitelist
Apr 16 13:04:44.821: INFO: namespace e2e-tests-kubectl-6q4bj deletion completed in 22.187737689s

• [SLOW TEST:38.581 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 13:04:44.824: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Apr 16 13:04:48.972: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wnhll PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 16 13:04:48.972: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
Apr 16 13:04:49.063: INFO: Exec stderr: ""
Apr 16 13:04:49.063: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wnhll PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 16 13:04:49.063: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
Apr 16 13:04:49.146: INFO: Exec stderr: ""
Apr 16 13:04:49.146: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wnhll PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 16 13:04:49.146: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
Apr 16 13:04:49.223: INFO: Exec stderr: ""
Apr 16 13:04:49.223: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wnhll PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 16 13:04:49.223: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
Apr 16 13:04:49.309: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Apr 16 13:04:49.309: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wnhll PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 16 13:04:49.309: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
Apr 16 13:04:49.395: INFO: Exec stderr: ""
Apr 16 13:04:49.395: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wnhll PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 16 13:04:49.395: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
Apr 16 13:04:49.479: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Apr 16 13:04:49.479: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wnhll PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 16 13:04:49.480: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
Apr 16 13:04:49.567: INFO: Exec stderr: ""
Apr 16 13:04:49.568: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wnhll PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 16 13:04:49.568: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
Apr 16 13:04:49.650: INFO: Exec stderr: ""
Apr 16 13:04:49.650: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wnhll PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 16 13:04:49.650: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
Apr 16 13:04:49.731: INFO: Exec stderr: ""
Apr 16 13:04:49.731: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wnhll PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 16 13:04:49.731: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
Apr 16 13:04:49.817: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 13:04:49.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-wnhll" for this suite.
Apr 16 13:05:33.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 13:05:33.856: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-wnhll, resource: bindings, ignored listing per whitelist
Apr 16 13:05:34.024: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-wnhll deletion completed in 44.202695078s

• [SLOW TEST:49.200 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 13:05:34.027: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-5202053f-6048-11e9-be7e-0a580ae9423f
STEP: Creating a pod to test consume configMaps
Apr 16 13:05:34.144: INFO: Waiting up to 5m0s for pod "pod-configmaps-52032d1d-6048-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-configmap-qrmz5" to be "success or failure"
Apr 16 13:05:34.148: INFO: Pod "pod-configmaps-52032d1d-6048-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.162677ms
Apr 16 13:05:36.154: INFO: Pod "pod-configmaps-52032d1d-6048-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009981084s
STEP: Saw pod success
Apr 16 13:05:36.154: INFO: Pod "pod-configmaps-52032d1d-6048-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 13:05:36.159: INFO: Trying to get logs from node k8s-1 pod pod-configmaps-52032d1d-6048-11e9-be7e-0a580ae9423f container configmap-volume-test: <nil>
STEP: delete the pod
Apr 16 13:05:36.199: INFO: Waiting for pod pod-configmaps-52032d1d-6048-11e9-be7e-0a580ae9423f to disappear
Apr 16 13:05:36.203: INFO: Pod pod-configmaps-52032d1d-6048-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 13:05:36.203: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-qrmz5" for this suite.
Apr 16 13:05:42.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 13:05:42.323: INFO: namespace: e2e-tests-configmap-qrmz5, resource: bindings, ignored listing per whitelist
Apr 16 13:05:42.367: INFO: namespace e2e-tests-configmap-qrmz5 deletion completed in 6.159681723s

• [SLOW TEST:8.341 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 13:05:42.369: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-56f79fe0-6048-11e9-be7e-0a580ae9423f
STEP: Creating a pod to test consume configMaps
Apr 16 13:05:42.478: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-56f91d3b-6048-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-projected-xprfn" to be "success or failure"
Apr 16 13:05:42.497: INFO: Pod "pod-projected-configmaps-56f91d3b-6048-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 18.641486ms
Apr 16 13:05:44.502: INFO: Pod "pod-projected-configmaps-56f91d3b-6048-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023514136s
STEP: Saw pod success
Apr 16 13:05:44.502: INFO: Pod "pod-projected-configmaps-56f91d3b-6048-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 13:05:44.505: INFO: Trying to get logs from node k8s-2 pod pod-projected-configmaps-56f91d3b-6048-11e9-be7e-0a580ae9423f container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 16 13:05:44.540: INFO: Waiting for pod pod-projected-configmaps-56f91d3b-6048-11e9-be7e-0a580ae9423f to disappear
Apr 16 13:05:44.544: INFO: Pod pod-projected-configmaps-56f91d3b-6048-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 13:05:44.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xprfn" for this suite.
Apr 16 13:05:50.565: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 13:05:50.609: INFO: namespace: e2e-tests-projected-xprfn, resource: bindings, ignored listing per whitelist
Apr 16 13:05:50.678: INFO: namespace e2e-tests-projected-xprfn deletion completed in 6.129575994s

• [SLOW TEST:8.309 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 13:05:50.679: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Apr 16 13:05:50.753: INFO: Waiting up to 5m0s for pod "downward-api-5be926a4-6048-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-downward-api-5mbqr" to be "success or failure"
Apr 16 13:05:50.758: INFO: Pod "downward-api-5be926a4-6048-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.57777ms
Apr 16 13:05:52.770: INFO: Pod "downward-api-5be926a4-6048-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016640774s
STEP: Saw pod success
Apr 16 13:05:52.770: INFO: Pod "downward-api-5be926a4-6048-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 13:05:52.774: INFO: Trying to get logs from node k8s-3 pod downward-api-5be926a4-6048-11e9-be7e-0a580ae9423f container dapi-container: <nil>
STEP: delete the pod
Apr 16 13:05:52.801: INFO: Waiting for pod downward-api-5be926a4-6048-11e9-be7e-0a580ae9423f to disappear
Apr 16 13:05:52.805: INFO: Pod downward-api-5be926a4-6048-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 13:05:52.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-5mbqr" for this suite.
Apr 16 13:05:58.826: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 13:05:58.862: INFO: namespace: e2e-tests-downward-api-5mbqr, resource: bindings, ignored listing per whitelist
Apr 16 13:05:58.954: INFO: namespace e2e-tests-downward-api-5mbqr deletion completed in 6.146196149s

• [SLOW TEST:8.276 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 13:05:58.956: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-60d8b767-6048-11e9-be7e-0a580ae9423f
STEP: Creating configMap with name cm-test-opt-upd-60d8b793-6048-11e9-be7e-0a580ae9423f
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-60d8b767-6048-11e9-be7e-0a580ae9423f
STEP: Updating configmap cm-test-opt-upd-60d8b793-6048-11e9-be7e-0a580ae9423f
STEP: Creating configMap with name cm-test-opt-create-60d8b79e-6048-11e9-be7e-0a580ae9423f
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 13:06:03.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4xbdc" for this suite.
Apr 16 13:06:25.226: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 13:06:25.279: INFO: namespace: e2e-tests-projected-4xbdc, resource: bindings, ignored listing per whitelist
Apr 16 13:06:25.327: INFO: namespace e2e-tests-projected-4xbdc deletion completed in 22.129635782s

• [SLOW TEST:26.371 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 13:06:25.328: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Apr 16 13:06:25.413: INFO: Waiting up to 5m0s for pod "var-expansion-7091696b-6048-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-var-expansion-7kc9s" to be "success or failure"
Apr 16 13:06:25.419: INFO: Pod "var-expansion-7091696b-6048-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.07728ms
Apr 16 13:06:27.426: INFO: Pod "var-expansion-7091696b-6048-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012107149s
STEP: Saw pod success
Apr 16 13:06:27.426: INFO: Pod "var-expansion-7091696b-6048-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 13:06:27.429: INFO: Trying to get logs from node k8s-2 pod var-expansion-7091696b-6048-11e9-be7e-0a580ae9423f container dapi-container: <nil>
STEP: delete the pod
Apr 16 13:06:27.462: INFO: Waiting for pod var-expansion-7091696b-6048-11e9-be7e-0a580ae9423f to disappear
Apr 16 13:06:27.469: INFO: Pod var-expansion-7091696b-6048-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 13:06:27.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-7kc9s" for this suite.
Apr 16 13:06:33.489: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 13:06:33.592: INFO: namespace: e2e-tests-var-expansion-7kc9s, resource: bindings, ignored listing per whitelist
Apr 16 13:06:33.596: INFO: namespace e2e-tests-var-expansion-7kc9s deletion completed in 6.123436405s

• [SLOW TEST:8.268 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 13:06:33.597: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-f6pvg
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-f6pvg to expose endpoints map[]
Apr 16 13:06:33.677: INFO: Get endpoints failed (6.541512ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Apr 16 13:06:34.681: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-f6pvg exposes endpoints map[] (1.010216003s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-f6pvg
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-f6pvg to expose endpoints map[pod1:[80]]
Apr 16 13:06:36.724: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-f6pvg exposes endpoints map[pod1:[80]] (2.030483041s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-f6pvg
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-f6pvg to expose endpoints map[pod1:[80] pod2:[80]]
Apr 16 13:06:38.776: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-f6pvg exposes endpoints map[pod1:[80] pod2:[80]] (2.045608057s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-f6pvg
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-f6pvg to expose endpoints map[pod2:[80]]
Apr 16 13:06:39.815: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-f6pvg exposes endpoints map[pod2:[80]] (1.02729481s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-f6pvg
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-f6pvg to expose endpoints map[]
Apr 16 13:06:39.831: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-f6pvg exposes endpoints map[] (6.594185ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 13:06:39.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-f6pvg" for this suite.
Apr 16 13:07:01.887: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 13:07:01.956: INFO: namespace: e2e-tests-services-f6pvg, resource: bindings, ignored listing per whitelist
Apr 16 13:07:01.985: INFO: namespace e2e-tests-services-f6pvg deletion completed in 22.120707334s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:28.388 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 13:07:01.986: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Apr 16 13:07:02.058: INFO: Waiting up to 5m0s for pod "downwardapi-volume-866977b4-6048-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-downward-api-kshbq" to be "success or failure"
Apr 16 13:07:02.064: INFO: Pod "downwardapi-volume-866977b4-6048-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.261268ms
Apr 16 13:07:04.069: INFO: Pod "downwardapi-volume-866977b4-6048-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010517466s
STEP: Saw pod success
Apr 16 13:07:04.069: INFO: Pod "downwardapi-volume-866977b4-6048-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 13:07:04.075: INFO: Trying to get logs from node k8s-2 pod downwardapi-volume-866977b4-6048-11e9-be7e-0a580ae9423f container client-container: <nil>
STEP: delete the pod
Apr 16 13:07:04.118: INFO: Waiting for pod downwardapi-volume-866977b4-6048-11e9-be7e-0a580ae9423f to disappear
Apr 16 13:07:04.125: INFO: Pod downwardapi-volume-866977b4-6048-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 13:07:04.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-kshbq" for this suite.
Apr 16 13:07:10.151: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 13:07:10.230: INFO: namespace: e2e-tests-downward-api-kshbq, resource: bindings, ignored listing per whitelist
Apr 16 13:07:10.264: INFO: namespace e2e-tests-downward-api-kshbq deletion completed in 6.135429072s

• [SLOW TEST:8.278 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 13:07:10.265: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Apr 16 13:07:12.459: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 13:07:36.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-vp5dc" for this suite.
Apr 16 13:07:42.538: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 13:07:42.632: INFO: namespace: e2e-tests-namespaces-vp5dc, resource: bindings, ignored listing per whitelist
Apr 16 13:07:42.662: INFO: namespace e2e-tests-namespaces-vp5dc deletion completed in 6.150630971s
STEP: Destroying namespace "e2e-tests-nsdeletetest-f6grt" for this suite.
Apr 16 13:07:42.668: INFO: Namespace e2e-tests-nsdeletetest-f6grt was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-gp6q9" for this suite.
Apr 16 13:07:48.684: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 13:07:48.749: INFO: namespace: e2e-tests-nsdeletetest-gp6q9, resource: bindings, ignored listing per whitelist
Apr 16 13:07:48.779: INFO: namespace e2e-tests-nsdeletetest-gp6q9 deletion completed in 6.111287297s

• [SLOW TEST:38.514 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 13:07:48.780: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 13:07:50.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-797x2" for this suite.
Apr 16 13:08:28.901: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 13:08:28.958: INFO: namespace: e2e-tests-kubelet-test-797x2, resource: bindings, ignored listing per whitelist
Apr 16 13:08:28.998: INFO: namespace e2e-tests-kubelet-test-797x2 deletion completed in 38.114025126s

• [SLOW TEST:40.218 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a read only busybox container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:186
    should not write to root filesystem [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 13:08:28.999: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Apr 16 13:08:29.081: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ba483a12-6048-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-projected-5dktp" to be "success or failure"
Apr 16 13:08:29.084: INFO: Pod "downwardapi-volume-ba483a12-6048-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.982346ms
Apr 16 13:08:31.089: INFO: Pod "downwardapi-volume-ba483a12-6048-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008048131s
STEP: Saw pod success
Apr 16 13:08:31.089: INFO: Pod "downwardapi-volume-ba483a12-6048-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 13:08:31.093: INFO: Trying to get logs from node k8s-3 pod downwardapi-volume-ba483a12-6048-11e9-be7e-0a580ae9423f container client-container: <nil>
STEP: delete the pod
Apr 16 13:08:31.126: INFO: Waiting for pod downwardapi-volume-ba483a12-6048-11e9-be7e-0a580ae9423f to disappear
Apr 16 13:08:31.130: INFO: Pod downwardapi-volume-ba483a12-6048-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 13:08:31.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5dktp" for this suite.
Apr 16 13:08:37.150: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 13:08:37.235: INFO: namespace: e2e-tests-projected-5dktp, resource: bindings, ignored listing per whitelist
Apr 16 13:08:37.253: INFO: namespace e2e-tests-projected-5dktp deletion completed in 6.120158986s

• [SLOW TEST:8.254 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 13:08:37.253: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Apr 16 13:08:37.322: INFO: Waiting up to 5m0s for pod "pod-bf3194d2-6048-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-emptydir-tswq9" to be "success or failure"
Apr 16 13:08:37.325: INFO: Pod "pod-bf3194d2-6048-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.966528ms
Apr 16 13:08:39.331: INFO: Pod "pod-bf3194d2-6048-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008789899s
STEP: Saw pod success
Apr 16 13:08:39.331: INFO: Pod "pod-bf3194d2-6048-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 13:08:39.336: INFO: Trying to get logs from node k8s-1 pod pod-bf3194d2-6048-11e9-be7e-0a580ae9423f container test-container: <nil>
STEP: delete the pod
Apr 16 13:08:39.363: INFO: Waiting for pod pod-bf3194d2-6048-11e9-be7e-0a580ae9423f to disappear
Apr 16 13:08:39.368: INFO: Pod pod-bf3194d2-6048-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 13:08:39.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-tswq9" for this suite.
Apr 16 13:08:45.396: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 13:08:45.449: INFO: namespace: e2e-tests-emptydir-tswq9, resource: bindings, ignored listing per whitelist
Apr 16 13:08:45.529: INFO: namespace e2e-tests-emptydir-tswq9 deletion completed in 6.157352107s

• [SLOW TEST:8.276 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 13:08:45.529: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 16 13:08:45.609: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-v7qvg'
Apr 16 13:08:45.734: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr 16 13:08:45.734: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Apr 16 13:08:45.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-v7qvg'
Apr 16 13:08:45.876: INFO: stderr: ""
Apr 16 13:08:45.876: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 13:08:45.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-v7qvg" for this suite.
Apr 16 13:08:51.899: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 13:08:52.032: INFO: namespace: e2e-tests-kubectl-v7qvg, resource: bindings, ignored listing per whitelist
Apr 16 13:08:52.061: INFO: namespace e2e-tests-kubectl-v7qvg deletion completed in 6.180088754s

• [SLOW TEST:6.532 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 13:08:52.062: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Apr 16 13:08:52.134: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 16 13:08:52.146: INFO: Waiting for terminating namespaces to be deleted...
Apr 16 13:08:52.154: INFO: 
Logging pods the kubelet thinks is on node k8s-1 before test
Apr 16 13:08:52.163: INFO: kube-controller-manager-k8s-1 from kube-system started at <nil> (0 container statuses recorded)
Apr 16 13:08:52.163: INFO: kube-scheduler-k8s-1 from kube-system started at <nil> (0 container statuses recorded)
Apr 16 13:08:52.163: INFO: sonobuoy-systemd-logs-daemon-set-bd0902ee46574666-xtxss from heptio-sonobuoy started at 2019-04-16 11:31:01 +0000 UTC (2 container statuses recorded)
Apr 16 13:08:52.163: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Apr 16 13:08:52.163: INFO: 	Container systemd-logs ready: true, restart count 1
Apr 16 13:08:52.163: INFO: kube-flannel-fnd59 from kube-system started at 2019-04-16 09:04:20 +0000 UTC (2 container statuses recorded)
Apr 16 13:08:52.163: INFO: 	Container install-cni ready: true, restart count 0
Apr 16 13:08:52.163: INFO: 	Container kube-flannel ready: true, restart count 0
Apr 16 13:08:52.163: INFO: kube-apiserver-k8s-1 from kube-system started at <nil> (0 container statuses recorded)
Apr 16 13:08:52.164: INFO: kube-proxy-zmk77 from kube-system started at 2019-04-16 09:04:35 +0000 UTC (1 container statuses recorded)
Apr 16 13:08:52.164: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 16 13:08:52.164: INFO: 
Logging pods the kubelet thinks is on node k8s-2 before test
Apr 16 13:08:52.169: INFO: kube-controller-manager-k8s-2 from kube-system started at <nil> (0 container statuses recorded)
Apr 16 13:08:52.170: INFO: kube-apiserver-k8s-2 from kube-system started at <nil> (0 container statuses recorded)
Apr 16 13:08:52.170: INFO: kube-proxy-zbpwt from kube-system started at 2019-04-16 09:04:46 +0000 UTC (1 container statuses recorded)
Apr 16 13:08:52.170: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 16 13:08:52.170: INFO: kube-scheduler-k8s-2 from kube-system started at <nil> (0 container statuses recorded)
Apr 16 13:08:52.170: INFO: coredns-644c686c9-xkwgk from kube-system started at 2019-04-16 09:04:45 +0000 UTC (1 container statuses recorded)
Apr 16 13:08:52.170: INFO: 	Container coredns ready: true, restart count 0
Apr 16 13:08:52.170: INFO: sonobuoy-systemd-logs-daemon-set-bd0902ee46574666-6pmwz from heptio-sonobuoy started at 2019-04-16 11:31:01 +0000 UTC (2 container statuses recorded)
Apr 16 13:08:52.170: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Apr 16 13:08:52.170: INFO: 	Container systemd-logs ready: true, restart count 1
Apr 16 13:08:52.170: INFO: kube-flannel-zhgc5 from kube-system started at 2019-04-16 09:04:20 +0000 UTC (2 container statuses recorded)
Apr 16 13:08:52.170: INFO: 	Container install-cni ready: true, restart count 0
Apr 16 13:08:52.170: INFO: 	Container kube-flannel ready: true, restart count 0
Apr 16 13:08:52.170: INFO: 
Logging pods the kubelet thinks is on node k8s-3 before test
Apr 16 13:08:52.176: INFO: kube-flannel-ct7gl from kube-system started at 2019-04-16 09:04:19 +0000 UTC (2 container statuses recorded)
Apr 16 13:08:52.176: INFO: 	Container install-cni ready: true, restart count 0
Apr 16 13:08:52.176: INFO: 	Container kube-flannel ready: true, restart count 0
Apr 16 13:08:52.176: INFO: dns-autoscaler-586f58b8bf-rhxhm from kube-system started at 2019-04-16 09:04:43 +0000 UTC (1 container statuses recorded)
Apr 16 13:08:52.176: INFO: 	Container autoscaler ready: true, restart count 0
Apr 16 13:08:52.176: INFO: kube-proxy-7rzm9 from kube-system started at 2019-04-16 09:04:23 +0000 UTC (1 container statuses recorded)
Apr 16 13:08:52.176: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 16 13:08:52.176: INFO: sonobuoy from heptio-sonobuoy started at 2019-04-16 11:30:59 +0000 UTC (1 container statuses recorded)
Apr 16 13:08:52.176: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr 16 13:08:52.176: INFO: kubernetes-dashboard-8457c55f89-sqzmm from kube-system started at 2019-04-16 09:04:46 +0000 UTC (1 container statuses recorded)
Apr 16 13:08:52.176: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Apr 16 13:08:52.176: INFO: sonobuoy-e2e-job-112a3508806440e9 from heptio-sonobuoy started at 2019-04-16 11:31:01 +0000 UTC (2 container statuses recorded)
Apr 16 13:08:52.176: INFO: 	Container e2e ready: true, restart count 0
Apr 16 13:08:52.176: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 16 13:08:52.176: INFO: nginx-proxy-k8s-3 from kube-system started at <nil> (0 container statuses recorded)
Apr 16 13:08:52.176: INFO: coredns-644c686c9-bjmcw from kube-system started at 2019-04-16 09:04:41 +0000 UTC (1 container statuses recorded)
Apr 16 13:08:52.176: INFO: 	Container coredns ready: true, restart count 0
Apr 16 13:08:52.177: INFO: sonobuoy-systemd-logs-daemon-set-bd0902ee46574666-rcqwb from heptio-sonobuoy started at 2019-04-16 11:31:01 +0000 UTC (2 container statuses recorded)
Apr 16 13:08:52.177: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Apr 16 13:08:52.177: INFO: 	Container systemd-logs ready: true, restart count 1
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node k8s-1
STEP: verifying the node has the label node k8s-2
STEP: verifying the node has the label node k8s-3
Apr 16 13:08:52.225: INFO: Pod sonobuoy requesting resource cpu=0m on Node k8s-3
Apr 16 13:08:52.225: INFO: Pod sonobuoy-e2e-job-112a3508806440e9 requesting resource cpu=0m on Node k8s-3
Apr 16 13:08:52.225: INFO: Pod sonobuoy-systemd-logs-daemon-set-bd0902ee46574666-6pmwz requesting resource cpu=0m on Node k8s-2
Apr 16 13:08:52.225: INFO: Pod sonobuoy-systemd-logs-daemon-set-bd0902ee46574666-rcqwb requesting resource cpu=0m on Node k8s-3
Apr 16 13:08:52.225: INFO: Pod sonobuoy-systemd-logs-daemon-set-bd0902ee46574666-xtxss requesting resource cpu=0m on Node k8s-1
Apr 16 13:08:52.225: INFO: Pod coredns-644c686c9-bjmcw requesting resource cpu=100m on Node k8s-3
Apr 16 13:08:52.225: INFO: Pod coredns-644c686c9-xkwgk requesting resource cpu=100m on Node k8s-2
Apr 16 13:08:52.225: INFO: Pod dns-autoscaler-586f58b8bf-rhxhm requesting resource cpu=20m on Node k8s-3
Apr 16 13:08:52.225: INFO: Pod kube-apiserver-k8s-1 requesting resource cpu=250m on Node k8s-1
Apr 16 13:08:52.225: INFO: Pod kube-apiserver-k8s-2 requesting resource cpu=250m on Node k8s-2
Apr 16 13:08:52.225: INFO: Pod kube-controller-manager-k8s-1 requesting resource cpu=200m on Node k8s-1
Apr 16 13:08:52.225: INFO: Pod kube-controller-manager-k8s-2 requesting resource cpu=200m on Node k8s-2
Apr 16 13:08:52.225: INFO: Pod kube-flannel-ct7gl requesting resource cpu=150m on Node k8s-3
Apr 16 13:08:52.226: INFO: Pod kube-flannel-fnd59 requesting resource cpu=150m on Node k8s-1
Apr 16 13:08:52.226: INFO: Pod kube-flannel-zhgc5 requesting resource cpu=150m on Node k8s-2
Apr 16 13:08:52.226: INFO: Pod kube-proxy-7rzm9 requesting resource cpu=0m on Node k8s-3
Apr 16 13:08:52.226: INFO: Pod kube-proxy-zbpwt requesting resource cpu=0m on Node k8s-2
Apr 16 13:08:52.226: INFO: Pod kube-proxy-zmk77 requesting resource cpu=0m on Node k8s-1
Apr 16 13:08:52.226: INFO: Pod kube-scheduler-k8s-1 requesting resource cpu=100m on Node k8s-1
Apr 16 13:08:52.226: INFO: Pod kube-scheduler-k8s-2 requesting resource cpu=100m on Node k8s-2
Apr 16 13:08:52.226: INFO: Pod kubernetes-dashboard-8457c55f89-sqzmm requesting resource cpu=50m on Node k8s-3
Apr 16 13:08:52.226: INFO: Pod nginx-proxy-k8s-3 requesting resource cpu=25m on Node k8s-3
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c815584f-6048-11e9-be7e-0a580ae9423f.1595f65e8ac0fc33], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-kgl7n/filler-pod-c815584f-6048-11e9-be7e-0a580ae9423f to k8s-2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c815584f-6048-11e9-be7e-0a580ae9423f.1595f65eabf5326c], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c815584f-6048-11e9-be7e-0a580ae9423f.1595f65eb0d75793], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c815584f-6048-11e9-be7e-0a580ae9423f.1595f65eb91afe66], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c816f39d-6048-11e9-be7e-0a580ae9423f.1595f65e8c3c8453], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-kgl7n/filler-pod-c816f39d-6048-11e9-be7e-0a580ae9423f to k8s-3]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c816f39d-6048-11e9-be7e-0a580ae9423f.1595f65eaf3c473a], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c816f39d-6048-11e9-be7e-0a580ae9423f.1595f65eb33e4a4c], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c816f39d-6048-11e9-be7e-0a580ae9423f.1595f65ebb1feb95], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c818efab-6048-11e9-be7e-0a580ae9423f.1595f65e8cf2bf85], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-kgl7n/filler-pod-c818efab-6048-11e9-be7e-0a580ae9423f to k8s-1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c818efab-6048-11e9-be7e-0a580ae9423f.1595f65eb745c864], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c818efab-6048-11e9-be7e-0a580ae9423f.1595f65ebc68522e], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c818efab-6048-11e9-be7e-0a580ae9423f.1595f65eca642528], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1595f65f7dc0943b], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node k8s-3
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node k8s-1
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node k8s-2
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 13:08:57.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-kgl7n" for this suite.
Apr 16 13:09:03.436: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 13:09:03.498: INFO: namespace: e2e-tests-sched-pred-kgl7n, resource: bindings, ignored listing per whitelist
Apr 16 13:09:03.581: INFO: namespace e2e-tests-sched-pred-kgl7n deletion completed in 6.169244037s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:11.520 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 13:09:03.582: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Apr 16 13:09:03.661: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Apr 16 13:09:03.672: INFO: Pod name sample-pod: Found 0 pods out of 1
Apr 16 13:09:08.684: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr 16 13:09:08.684: INFO: Creating deployment "test-rolling-update-deployment"
Apr 16 13:09:08.693: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Apr 16 13:09:08.701: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Apr 16 13:09:10.712: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Apr 16 13:09:10.716: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr 16 13:09:10.731: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-qhdf5,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-qhdf5/deployments/test-rolling-update-deployment,UID:d1e4e9de-6048-11e9-8569-0800277031c6,ResourceVersion:33917,Generation:1,CreationTimestamp:2019-04-16 13:09:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-04-16 13:09:08 +0000 UTC 2019-04-16 13:09:08 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-04-16 13:09:10 +0000 UTC 2019-04-16 13:09:08 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-68b55d7bc6" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Apr 16 13:09:10.735: INFO: New ReplicaSet "test-rolling-update-deployment-68b55d7bc6" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6,GenerateName:,Namespace:e2e-tests-deployment-qhdf5,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-qhdf5/replicasets/test-rolling-update-deployment-68b55d7bc6,UID:d1e75b3f-6048-11e9-8978-0800277031c6,ResourceVersion:33908,Generation:1,CreationTimestamp:2019-04-16 13:09:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment d1e4e9de-6048-11e9-8569-0800277031c6 0xc0022ca9e7 0xc0022ca9e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Apr 16 13:09:10.735: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Apr 16 13:09:10.735: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-qhdf5,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-qhdf5/replicasets/test-rolling-update-controller,UID:cee683ee-6048-11e9-8569-0800277031c6,ResourceVersion:33916,Generation:2,CreationTimestamp:2019-04-16 13:09:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment d1e4e9de-6048-11e9-8569-0800277031c6 0xc0022ca927 0xc0022ca928}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr 16 13:09:10.740: INFO: Pod "test-rolling-update-deployment-68b55d7bc6-sdvpt" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6-sdvpt,GenerateName:test-rolling-update-deployment-68b55d7bc6-,Namespace:e2e-tests-deployment-qhdf5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhdf5/pods/test-rolling-update-deployment-68b55d7bc6-sdvpt,UID:d1ea18dc-6048-11e9-8978-0800277031c6,ResourceVersion:33907,Generation:0,CreationTimestamp:2019-04-16 13:09:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-68b55d7bc6 d1e75b3f-6048-11e9-8978-0800277031c6 0xc0022cb2c7 0xc0022cb2c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rxvs2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rxvs2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-rxvs2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022cb340} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022cb360}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 13:09:08 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 13:09:10 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 13:09:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-16 13:09:08 +0000 UTC  }],Message:,Reason:,HostIP:172.17.8.101,PodIP:10.233.64.181,StartTime:2019-04-16 13:09:08 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-04-16 13:09:09 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://c1bedd6de7bd8e4b19040c287e460d61efcfcd6c5e70370575f730a94950120d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 13:09:10.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-qhdf5" for this suite.
Apr 16 13:09:16.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 13:09:16.854: INFO: namespace: e2e-tests-deployment-qhdf5, resource: bindings, ignored listing per whitelist
Apr 16 13:09:16.870: INFO: namespace e2e-tests-deployment-qhdf5 deletion completed in 6.126998432s

• [SLOW TEST:13.289 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 13:09:16.872: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Apr 16 13:09:16.939: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 13:09:18.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-4x5jp" for this suite.
Apr 16 13:09:57.005: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 13:09:57.053: INFO: namespace: e2e-tests-pods-4x5jp, resource: bindings, ignored listing per whitelist
Apr 16 13:09:57.099: INFO: namespace e2e-tests-pods-4x5jp deletion completed in 38.112640922s

• [SLOW TEST:40.227 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 13:09:57.100: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Apr 16 13:09:57.239: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-f4vtq,SelfLink:/api/v1/namespaces/e2e-tests-watch-f4vtq/configmaps/e2e-watch-test-label-changed,UID:eecc3159-6048-11e9-8569-0800277031c6,ResourceVersion:34052,Generation:0,CreationTimestamp:2019-04-16 13:09:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr 16 13:09:57.239: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-f4vtq,SelfLink:/api/v1/namespaces/e2e-tests-watch-f4vtq/configmaps/e2e-watch-test-label-changed,UID:eecc3159-6048-11e9-8569-0800277031c6,ResourceVersion:34053,Generation:0,CreationTimestamp:2019-04-16 13:09:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Apr 16 13:09:57.239: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-f4vtq,SelfLink:/api/v1/namespaces/e2e-tests-watch-f4vtq/configmaps/e2e-watch-test-label-changed,UID:eecc3159-6048-11e9-8569-0800277031c6,ResourceVersion:34054,Generation:0,CreationTimestamp:2019-04-16 13:09:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Apr 16 13:10:07.302: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-f4vtq,SelfLink:/api/v1/namespaces/e2e-tests-watch-f4vtq/configmaps/e2e-watch-test-label-changed,UID:eecc3159-6048-11e9-8569-0800277031c6,ResourceVersion:34071,Generation:0,CreationTimestamp:2019-04-16 13:09:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr 16 13:10:07.302: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-f4vtq,SelfLink:/api/v1/namespaces/e2e-tests-watch-f4vtq/configmaps/e2e-watch-test-label-changed,UID:eecc3159-6048-11e9-8569-0800277031c6,ResourceVersion:34072,Generation:0,CreationTimestamp:2019-04-16 13:09:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Apr 16 13:10:07.302: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-f4vtq,SelfLink:/api/v1/namespaces/e2e-tests-watch-f4vtq/configmaps/e2e-watch-test-label-changed,UID:eecc3159-6048-11e9-8569-0800277031c6,ResourceVersion:34073,Generation:0,CreationTimestamp:2019-04-16 13:09:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 13:10:07.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-f4vtq" for this suite.
Apr 16 13:10:13.322: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 13:10:13.430: INFO: namespace: e2e-tests-watch-f4vtq, resource: bindings, ignored listing per whitelist
Apr 16 13:10:13.452: INFO: namespace e2e-tests-watch-f4vtq deletion completed in 6.146551967s

• [SLOW TEST:16.352 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 13:10:13.452: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Apr 16 13:10:17.587: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 16 13:10:17.590: INFO: Pod pod-with-prestop-http-hook still exists
Apr 16 13:10:19.591: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 16 13:10:19.595: INFO: Pod pod-with-prestop-http-hook still exists
Apr 16 13:10:21.591: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 16 13:10:21.596: INFO: Pod pod-with-prestop-http-hook still exists
Apr 16 13:10:23.591: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 16 13:10:23.596: INFO: Pod pod-with-prestop-http-hook still exists
Apr 16 13:10:25.591: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 16 13:10:25.595: INFO: Pod pod-with-prestop-http-hook still exists
Apr 16 13:10:27.591: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 16 13:10:27.600: INFO: Pod pod-with-prestop-http-hook still exists
Apr 16 13:10:29.591: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 16 13:10:29.595: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 13:10:29.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-cbg52" for this suite.
Apr 16 13:10:51.624: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 13:10:51.676: INFO: namespace: e2e-tests-container-lifecycle-hook-cbg52, resource: bindings, ignored listing per whitelist
Apr 16 13:10:51.729: INFO: namespace e2e-tests-container-lifecycle-hook-cbg52 deletion completed in 22.121762539s

• [SLOW TEST:38.277 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 13:10:51.730: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Apr 16 13:10:51.798: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-454217481 version'
Apr 16 13:10:51.860: INFO: stderr: ""
Apr 16 13:10:51.860: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.5\", GitCommit:\"2166946f41b36dea2c4626f90a77706f426cdea2\", GitTreeState:\"clean\", BuildDate:\"2019-03-25T15:19:22Z\", GoVersion:\"go1.11.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 13:10:51.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-876vd" for this suite.
Apr 16 13:10:57.885: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 13:10:57.917: INFO: namespace: e2e-tests-kubectl-876vd, resource: bindings, ignored listing per whitelist
Apr 16 13:10:57.997: INFO: namespace e2e-tests-kubectl-876vd deletion completed in 6.131804717s

• [SLOW TEST:6.267 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 13:10:57.999: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Apr 16 13:10:58.071: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1315c9ae-6049-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-projected-2fjpw" to be "success or failure"
Apr 16 13:10:58.077: INFO: Pod "downwardapi-volume-1315c9ae-6049-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.510939ms
Apr 16 13:11:00.091: INFO: Pod "downwardapi-volume-1315c9ae-6049-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019762139s
STEP: Saw pod success
Apr 16 13:11:00.091: INFO: Pod "downwardapi-volume-1315c9ae-6049-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 13:11:00.095: INFO: Trying to get logs from node k8s-3 pod downwardapi-volume-1315c9ae-6049-11e9-be7e-0a580ae9423f container client-container: <nil>
STEP: delete the pod
Apr 16 13:11:00.124: INFO: Waiting for pod downwardapi-volume-1315c9ae-6049-11e9-be7e-0a580ae9423f to disappear
Apr 16 13:11:00.127: INFO: Pod downwardapi-volume-1315c9ae-6049-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 13:11:00.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2fjpw" for this suite.
Apr 16 13:11:06.150: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 13:11:06.180: INFO: namespace: e2e-tests-projected-2fjpw, resource: bindings, ignored listing per whitelist
Apr 16 13:11:06.251: INFO: namespace e2e-tests-projected-2fjpw deletion completed in 6.119861268s

• [SLOW TEST:8.252 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 13:11:06.252: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Apr 16 13:11:06.327: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 13:11:09.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-cm5ck" for this suite.
Apr 16 13:11:31.637: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 13:11:31.711: INFO: namespace: e2e-tests-init-container-cm5ck, resource: bindings, ignored listing per whitelist
Apr 16 13:11:31.747: INFO: namespace e2e-tests-init-container-cm5ck deletion completed in 22.127699733s

• [SLOW TEST:25.495 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 13:11:31.749: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Apr 16 13:11:31.829: INFO: Waiting up to 5m0s for pod "downwardapi-volume-273540e3-6049-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-downward-api-fmq7k" to be "success or failure"
Apr 16 13:11:31.835: INFO: Pod "downwardapi-volume-273540e3-6049-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.778763ms
Apr 16 13:11:33.848: INFO: Pod "downwardapi-volume-273540e3-6049-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018902818s
STEP: Saw pod success
Apr 16 13:11:33.848: INFO: Pod "downwardapi-volume-273540e3-6049-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 13:11:33.853: INFO: Trying to get logs from node k8s-3 pod downwardapi-volume-273540e3-6049-11e9-be7e-0a580ae9423f container client-container: <nil>
STEP: delete the pod
Apr 16 13:11:33.884: INFO: Waiting for pod downwardapi-volume-273540e3-6049-11e9-be7e-0a580ae9423f to disappear
Apr 16 13:11:33.888: INFO: Pod downwardapi-volume-273540e3-6049-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 13:11:33.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-fmq7k" for this suite.
Apr 16 13:11:39.916: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 13:11:40.008: INFO: namespace: e2e-tests-downward-api-fmq7k, resource: bindings, ignored listing per whitelist
Apr 16 13:11:40.059: INFO: namespace e2e-tests-downward-api-fmq7k deletion completed in 6.166160463s

• [SLOW TEST:8.310 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 16 13:11:40.061: INFO: >>> kubeConfig: /tmp/kubeconfig-454217481
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-2c293dfb-6049-11e9-be7e-0a580ae9423f
STEP: Creating a pod to test consume secrets
Apr 16 13:11:40.175: INFO: Waiting up to 5m0s for pod "pod-secrets-2c2bd69d-6049-11e9-be7e-0a580ae9423f" in namespace "e2e-tests-secrets-65c52" to be "success or failure"
Apr 16 13:11:40.200: INFO: Pod "pod-secrets-2c2bd69d-6049-11e9-be7e-0a580ae9423f": Phase="Pending", Reason="", readiness=false. Elapsed: 24.797473ms
Apr 16 13:11:42.204: INFO: Pod "pod-secrets-2c2bd69d-6049-11e9-be7e-0a580ae9423f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02917795s
STEP: Saw pod success
Apr 16 13:11:42.204: INFO: Pod "pod-secrets-2c2bd69d-6049-11e9-be7e-0a580ae9423f" satisfied condition "success or failure"
Apr 16 13:11:42.210: INFO: Trying to get logs from node k8s-1 pod pod-secrets-2c2bd69d-6049-11e9-be7e-0a580ae9423f container secret-volume-test: <nil>
STEP: delete the pod
Apr 16 13:11:42.254: INFO: Waiting for pod pod-secrets-2c2bd69d-6049-11e9-be7e-0a580ae9423f to disappear
Apr 16 13:11:42.262: INFO: Pod pod-secrets-2c2bd69d-6049-11e9-be7e-0a580ae9423f no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 16 13:11:42.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-65c52" for this suite.
Apr 16 13:11:48.287: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 16 13:11:48.450: INFO: namespace: e2e-tests-secrets-65c52, resource: bindings, ignored listing per whitelist
Apr 16 13:11:48.491: INFO: namespace e2e-tests-secrets-65c52 deletion completed in 6.224930751s

• [SLOW TEST:8.430 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSApr 16 13:11:48.492: INFO: Running AfterSuite actions on all nodes
Apr 16 13:11:48.493: INFO: Running AfterSuite actions on node 1
Apr 16 13:11:48.493: INFO: Skipping dumping logs from cluster

Ran 200 of 1946 Specs in 6015.185 seconds
SUCCESS! -- 200 Passed | 0 Failed | 0 Pending | 1746 Skipped PASS

Ginkgo ran 1 suite in 1h40m16.26174949s
Test Suite Passed
