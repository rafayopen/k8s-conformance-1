I0117 17:15:15.833678      17 test_context.go:358] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-043318780
I0117 17:15:15.834145      17 e2e.go:224] Starting e2e run "74af5e5f-1a7b-11e9-a4b6-0a580af40269" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1547745315 - Will randomize all specs
Will run 201 of 1946 specs

Jan 17 17:15:15.999: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
Jan 17 17:15:16.001: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Jan 17 17:15:16.269: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Jan 17 17:15:16.350: INFO: 12 / 12 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Jan 17 17:15:16.350: INFO: expected 2 pod replicas in namespace 'kube-system', 2 are Running and Ready.
Jan 17 17:15:16.350: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Jan 17 17:15:16.360: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-amd64' (0 seconds elapsed)
Jan 17 17:15:16.360: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-arm' (0 seconds elapsed)
Jan 17 17:15:16.360: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-arm64' (0 seconds elapsed)
Jan 17 17:15:16.360: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-ppc64le' (0 seconds elapsed)
Jan 17 17:15:16.360: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-s390x' (0 seconds elapsed)
Jan 17 17:15:16.360: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Jan 17 17:15:16.360: INFO: e2e test version: v1.13.0
Jan 17 17:15:16.361: INFO: kube-apiserver version: v1.13.2
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:15:16.362: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename replication-controller
Jan 17 17:15:16.435: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:15:23.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-k5scb" for this suite.
Jan 17 17:15:46.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:15:46.141: INFO: namespace: e2e-tests-replication-controller-k5scb, resource: bindings, ignored listing per whitelist
Jan 17 17:15:46.151: INFO: namespace e2e-tests-replication-controller-k5scb deletion completed in 22.13215125s

• [SLOW TEST:29.789 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:15:46.152: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-8730da0e-1a7b-11e9-a4b6-0a580af40269
STEP: Creating a pod to test consume secrets
Jan 17 17:15:46.314: INFO: Waiting up to 5m0s for pod "pod-secrets-87315add-1a7b-11e9-a4b6-0a580af40269" in namespace "e2e-tests-secrets-4js7b" to be "success or failure"
Jan 17 17:15:46.318: INFO: Pod "pod-secrets-87315add-1a7b-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 3.88673ms
Jan 17 17:15:48.330: INFO: Pod "pod-secrets-87315add-1a7b-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015648889s
Jan 17 17:15:50.332: INFO: Pod "pod-secrets-87315add-1a7b-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018001024s
STEP: Saw pod success
Jan 17 17:15:50.332: INFO: Pod "pod-secrets-87315add-1a7b-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 17:15:50.335: INFO: Trying to get logs from node node1 pod pod-secrets-87315add-1a7b-11e9-a4b6-0a580af40269 container secret-env-test: <nil>
STEP: delete the pod
Jan 17 17:15:50.370: INFO: Waiting for pod pod-secrets-87315add-1a7b-11e9-a4b6-0a580af40269 to disappear
Jan 17 17:15:50.379: INFO: Pod pod-secrets-87315add-1a7b-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:15:50.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-4js7b" for this suite.
Jan 17 17:15:56.457: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:15:56.708: INFO: namespace: e2e-tests-secrets-4js7b, resource: bindings, ignored listing per whitelist
Jan 17 17:15:56.766: INFO: namespace e2e-tests-secrets-4js7b deletion completed in 6.331082605s

• [SLOW TEST:10.614 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:15:56.771: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 17 17:15:56.927: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8d845c5d-1a7b-11e9-a4b6-0a580af40269" in namespace "e2e-tests-projected-sjshf" to be "success or failure"
Jan 17 17:15:56.936: INFO: Pod "downwardapi-volume-8d845c5d-1a7b-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 9.133601ms
Jan 17 17:15:58.970: INFO: Pod "downwardapi-volume-8d845c5d-1a7b-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043519493s
Jan 17 17:16:00.980: INFO: Pod "downwardapi-volume-8d845c5d-1a7b-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052663608s
STEP: Saw pod success
Jan 17 17:16:00.980: INFO: Pod "downwardapi-volume-8d845c5d-1a7b-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 17:16:00.990: INFO: Trying to get logs from node node1 pod downwardapi-volume-8d845c5d-1a7b-11e9-a4b6-0a580af40269 container client-container: <nil>
STEP: delete the pod
Jan 17 17:16:01.062: INFO: Waiting for pod downwardapi-volume-8d845c5d-1a7b-11e9-a4b6-0a580af40269 to disappear
Jan 17 17:16:01.067: INFO: Pod downwardapi-volume-8d845c5d-1a7b-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:16:01.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-sjshf" for this suite.
Jan 17 17:16:07.091: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:16:07.160: INFO: namespace: e2e-tests-projected-sjshf, resource: bindings, ignored listing per whitelist
Jan 17 17:16:07.184: INFO: namespace e2e-tests-projected-sjshf deletion completed in 6.111007816s

• [SLOW TEST:10.413 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:16:07.187: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 17 17:16:07.273: INFO: Waiting up to 5m0s for pod "downwardapi-volume-93affddd-1a7b-11e9-a4b6-0a580af40269" in namespace "e2e-tests-projected-2ngzk" to be "success or failure"
Jan 17 17:16:07.282: INFO: Pod "downwardapi-volume-93affddd-1a7b-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 8.500494ms
Jan 17 17:16:09.284: INFO: Pod "downwardapi-volume-93affddd-1a7b-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010905199s
Jan 17 17:16:11.318: INFO: Pod "downwardapi-volume-93affddd-1a7b-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044825101s
STEP: Saw pod success
Jan 17 17:16:11.318: INFO: Pod "downwardapi-volume-93affddd-1a7b-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 17:16:11.322: INFO: Trying to get logs from node node1 pod downwardapi-volume-93affddd-1a7b-11e9-a4b6-0a580af40269 container client-container: <nil>
STEP: delete the pod
Jan 17 17:16:11.374: INFO: Waiting for pod downwardapi-volume-93affddd-1a7b-11e9-a4b6-0a580af40269 to disappear
Jan 17 17:16:11.376: INFO: Pod downwardapi-volume-93affddd-1a7b-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:16:11.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2ngzk" for this suite.
Jan 17 17:16:17.403: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:16:17.452: INFO: namespace: e2e-tests-projected-2ngzk, resource: bindings, ignored listing per whitelist
Jan 17 17:16:17.491: INFO: namespace e2e-tests-projected-2ngzk deletion completed in 6.106392504s

• [SLOW TEST:10.304 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:16:17.491: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0117 17:16:48.178472      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 17 17:16:48.178: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:16:48.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-57hlp" for this suite.
Jan 17 17:16:54.208: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:16:54.271: INFO: namespace: e2e-tests-gc-57hlp, resource: bindings, ignored listing per whitelist
Jan 17 17:16:54.299: INFO: namespace e2e-tests-gc-57hlp deletion completed in 6.108018786s

• [SLOW TEST:36.809 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:16:54.300: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-7ght7 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-7ght7;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-7ght7 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-7ght7;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-7ght7.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-7ght7.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-7ght7.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-7ght7.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-7ght7.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-7ght7.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-7ght7.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-7ght7.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-7ght7.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-7ght7.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-7ght7.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-7ght7.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-7ght7.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 74.16.104.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.104.16.74_udp@PTR;check="$$(dig +tcp +noall +answer +search 74.16.104.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.104.16.74_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-7ght7 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-7ght7;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-7ght7 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-7ght7;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-7ght7.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-7ght7.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-7ght7.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-7ght7.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-7ght7.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-7ght7.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-7ght7.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-7ght7.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-7ght7.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-7ght7.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-7ght7.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-7ght7.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-7ght7.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 74.16.104.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.104.16.74_udp@PTR;check="$$(dig +tcp +noall +answer +search 74.16.104.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.104.16.74_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jan 17 17:16:58.581: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:16:58.596: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-7ght7 from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:16:58.626: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:16:58.632: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:16:58.637: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-7ght7 from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:16:58.640: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-7ght7 from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:16:58.643: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-7ght7.svc from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:16:58.647: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-7ght7.svc from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:16:58.650: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-7ght7.svc from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:16:58.653: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-7ght7.svc from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:16:58.676: INFO: Lookups using e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service.e2e-tests-dns-7ght7 jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-7ght7 jessie_tcp@dns-test-service.e2e-tests-dns-7ght7 jessie_udp@dns-test-service.e2e-tests-dns-7ght7.svc jessie_tcp@dns-test-service.e2e-tests-dns-7ght7.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-7ght7.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-7ght7.svc]

Jan 17 17:17:03.689: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:17:03.720: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-7ght7 from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:17:03.754: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:17:03.760: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:17:03.762: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-7ght7 from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:17:03.766: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-7ght7 from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:17:03.770: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-7ght7.svc from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:17:03.773: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-7ght7.svc from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:17:03.776: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-7ght7.svc from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:17:03.779: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-7ght7.svc from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:17:03.796: INFO: Lookups using e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service.e2e-tests-dns-7ght7 jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-7ght7 jessie_tcp@dns-test-service.e2e-tests-dns-7ght7 jessie_udp@dns-test-service.e2e-tests-dns-7ght7.svc jessie_tcp@dns-test-service.e2e-tests-dns-7ght7.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-7ght7.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-7ght7.svc]

Jan 17 17:17:08.704: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:17:08.726: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-7ght7 from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:17:08.758: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:17:08.763: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:17:08.765: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-7ght7 from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:17:08.768: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-7ght7 from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:17:08.771: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-7ght7.svc from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:17:08.777: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-7ght7.svc from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:17:08.782: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-7ght7.svc from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:17:08.785: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-7ght7.svc from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:17:08.802: INFO: Lookups using e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service.e2e-tests-dns-7ght7 jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-7ght7 jessie_tcp@dns-test-service.e2e-tests-dns-7ght7 jessie_udp@dns-test-service.e2e-tests-dns-7ght7.svc jessie_tcp@dns-test-service.e2e-tests-dns-7ght7.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-7ght7.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-7ght7.svc]

Jan 17 17:17:13.687: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:17:13.724: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-7ght7 from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:17:13.769: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:17:13.773: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:17:13.778: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-7ght7 from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:17:13.782: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-7ght7 from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:17:13.784: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-7ght7.svc from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:17:13.787: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-7ght7.svc from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:17:13.790: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-7ght7.svc from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:17:13.792: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-7ght7.svc from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:17:13.811: INFO: Lookups using e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service.e2e-tests-dns-7ght7 jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-7ght7 jessie_tcp@dns-test-service.e2e-tests-dns-7ght7 jessie_udp@dns-test-service.e2e-tests-dns-7ght7.svc jessie_tcp@dns-test-service.e2e-tests-dns-7ght7.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-7ght7.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-7ght7.svc]

Jan 17 17:17:18.680: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:17:18.691: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-7ght7 from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:17:18.722: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:17:18.725: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:17:18.727: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-7ght7 from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:17:18.731: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-7ght7 from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:17:18.734: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-7ght7.svc from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:17:18.737: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-7ght7.svc from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:17:18.740: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-7ght7.svc from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:17:18.743: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-7ght7.svc from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:17:18.768: INFO: Lookups using e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service.e2e-tests-dns-7ght7 jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-7ght7 jessie_tcp@dns-test-service.e2e-tests-dns-7ght7 jessie_udp@dns-test-service.e2e-tests-dns-7ght7.svc jessie_tcp@dns-test-service.e2e-tests-dns-7ght7.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-7ght7.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-7ght7.svc]

Jan 17 17:17:23.687: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:17:23.722: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-7ght7 from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:17:23.785: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:17:23.789: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:17:23.796: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-7ght7 from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:17:23.800: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-7ght7 from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:17:23.803: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-7ght7.svc from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:17:23.806: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-7ght7.svc from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:17:23.810: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-7ght7.svc from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:17:23.817: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-7ght7.svc from pod e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269: the server could not find the requested resource (get pods dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269)
Jan 17 17:17:23.837: INFO: Lookups using e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service.e2e-tests-dns-7ght7 jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-7ght7 jessie_tcp@dns-test-service.e2e-tests-dns-7ght7 jessie_udp@dns-test-service.e2e-tests-dns-7ght7.svc jessie_tcp@dns-test-service.e2e-tests-dns-7ght7.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-7ght7.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-7ght7.svc]

Jan 17 17:17:28.777: INFO: DNS probes using e2e-tests-dns-7ght7/dns-test-afd2986c-1a7b-11e9-a4b6-0a580af40269 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:17:28.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-7ght7" for this suite.
Jan 17 17:17:34.974: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:17:35.042: INFO: namespace: e2e-tests-dns-7ght7, resource: bindings, ignored listing per whitelist
Jan 17 17:17:35.066: INFO: namespace e2e-tests-dns-7ght7 deletion completed in 6.112585367s

• [SLOW TEST:40.766 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:17:35.066: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 17 17:17:35.245: INFO: Pod name rollover-pod: Found 0 pods out of 1
Jan 17 17:17:40.252: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jan 17 17:17:40.252: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Jan 17 17:17:42.255: INFO: Creating deployment "test-rollover-deployment"
Jan 17 17:17:42.288: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Jan 17 17:17:44.301: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Jan 17 17:17:44.337: INFO: Ensure that both replica sets have 1 created replica
Jan 17 17:17:44.348: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Jan 17 17:17:44.356: INFO: Updating deployment test-rollover-deployment
Jan 17 17:17:44.356: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Jan 17 17:17:46.397: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Jan 17 17:17:46.401: INFO: Make sure deployment "test-rollover-deployment" is complete
Jan 17 17:17:46.404: INFO: all replica sets need to contain the pod-template-hash label
Jan 17 17:17:46.404: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683342262, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683342262, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683342264, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683342262, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 17 17:17:48.461: INFO: all replica sets need to contain the pod-template-hash label
Jan 17 17:17:48.462: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683342262, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683342262, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683342267, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683342262, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 17 17:17:50.426: INFO: all replica sets need to contain the pod-template-hash label
Jan 17 17:17:50.426: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683342262, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683342262, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683342267, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683342262, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 17 17:17:52.409: INFO: all replica sets need to contain the pod-template-hash label
Jan 17 17:17:52.409: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683342262, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683342262, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683342267, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683342262, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 17 17:17:54.413: INFO: all replica sets need to contain the pod-template-hash label
Jan 17 17:17:54.413: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683342262, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683342262, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683342267, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683342262, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 17 17:17:56.463: INFO: all replica sets need to contain the pod-template-hash label
Jan 17 17:17:56.463: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683342262, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683342262, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683342267, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683342262, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 17 17:17:58.423: INFO: 
Jan 17 17:17:58.425: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan 17 17:17:58.434: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-5pg56,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-5pg56/deployments/test-rollover-deployment,UID:cc4efd48-1a7b-11e9-8458-5254003c4592,ResourceVersion:74920,Generation:2,CreationTimestamp:2019-01-17 17:17:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-01-17 17:17:42 +0000 UTC 2019-01-17 17:17:42 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-01-17 17:17:57 +0000 UTC 2019-01-17 17:17:42 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-6b7f9d6597" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Jan 17 17:17:58.437: INFO: New ReplicaSet "test-rollover-deployment-6b7f9d6597" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597,GenerateName:,Namespace:e2e-tests-deployment-5pg56,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-5pg56/replicasets/test-rollover-deployment-6b7f9d6597,UID:cd8f9b88-1a7b-11e9-8458-5254003c4592,ResourceVersion:74910,Generation:2,CreationTimestamp:2019-01-17 17:17:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment cc4efd48-1a7b-11e9-8458-5254003c4592 0xc00188c3b7 0xc00188c3b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jan 17 17:17:58.437: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Jan 17 17:17:58.437: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-5pg56,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-5pg56/replicasets/test-rollover-controller,UID:c81f8472-1a7b-11e9-8458-5254003c4592,ResourceVersion:74919,Generation:2,CreationTimestamp:2019-01-17 17:17:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment cc4efd48-1a7b-11e9-8458-5254003c4592 0xc00188c227 0xc00188c228}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 17 17:17:58.439: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6586df867b,GenerateName:,Namespace:e2e-tests-deployment-5pg56,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-5pg56/replicasets/test-rollover-deployment-6586df867b,UID:cc5514ae-1a7b-11e9-8458-5254003c4592,ResourceVersion:74880,Generation:2,CreationTimestamp:2019-01-17 17:17:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment cc4efd48-1a7b-11e9-8458-5254003c4592 0xc00188c2e7 0xc00188c2e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 17 17:17:58.444: INFO: Pod "test-rollover-deployment-6b7f9d6597-m7sgk" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597-m7sgk,GenerateName:test-rollover-deployment-6b7f9d6597-,Namespace:e2e-tests-deployment-5pg56,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5pg56/pods/test-rollover-deployment-6b7f9d6597-m7sgk,UID:cd9cbcd0-1a7b-11e9-8458-5254003c4592,ResourceVersion:74893,Generation:0,CreationTimestamp:2019-01-17 17:17:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-6b7f9d6597 cd8f9b88-1a7b-11e9-8458-5254003c4592 0xc00188d737 0xc00188d738}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7mvqx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7mvqx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-7mvqx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00188d840} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00188d860}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 17:17:44 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 17:17:46 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 17:17:46 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 17:17:44 +0000 UTC  }],Message:,Reason:,HostIP:192.168.122.53,PodIP:10.244.1.173,StartTime:2019-01-17 17:17:44 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-01-17 17:17:46 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:2238f5a02d2648d41cc94a88f084060fbfa860890220328eb92696bf2ac649c9 cri-o://b3d364be51f32b6aaa01dba31f0cb438b8edb0ec0fd98a42efa91f49f085bce5}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:17:58.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-5pg56" for this suite.
Jan 17 17:18:04.470: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:18:04.947: INFO: namespace: e2e-tests-deployment-5pg56, resource: bindings, ignored listing per whitelist
Jan 17 17:18:05.015: INFO: namespace e2e-tests-deployment-5pg56 deletion completed in 6.567630621s

• [SLOW TEST:29.950 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:18:05.016: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 17 17:18:05.167: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Jan 17 17:18:05.183: INFO: Pod name sample-pod: Found 0 pods out of 1
Jan 17 17:18:10.203: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jan 17 17:18:10.203: INFO: Creating deployment "test-rolling-update-deployment"
Jan 17 17:18:10.209: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Jan 17 17:18:10.231: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Jan 17 17:18:12.265: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Jan 17 17:18:12.270: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683342290, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683342290, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683342290, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683342290, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-68b55d7bc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 17 17:18:14.273: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan 17 17:18:14.309: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-z8dwb,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-z8dwb/deployments/test-rolling-update-deployment,UID:dcf7b41a-1a7b-11e9-8458-5254003c4592,ResourceVersion:75023,Generation:1,CreationTimestamp:2019-01-17 17:18:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-01-17 17:18:10 +0000 UTC 2019-01-17 17:18:10 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-01-17 17:18:13 +0000 UTC 2019-01-17 17:18:10 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-68b55d7bc6" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Jan 17 17:18:14.314: INFO: New ReplicaSet "test-rolling-update-deployment-68b55d7bc6" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6,GenerateName:,Namespace:e2e-tests-deployment-z8dwb,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-z8dwb/replicasets/test-rolling-update-deployment-68b55d7bc6,UID:dcfc9b36-1a7b-11e9-8458-5254003c4592,ResourceVersion:75013,Generation:1,CreationTimestamp:2019-01-17 17:18:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment dcf7b41a-1a7b-11e9-8458-5254003c4592 0xc000a5dcc7 0xc000a5dcc8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jan 17 17:18:14.314: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Jan 17 17:18:14.314: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-z8dwb,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-z8dwb/replicasets/test-rolling-update-controller,UID:d9f729a6-1a7b-11e9-8458-5254003c4592,ResourceVersion:75022,Generation:2,CreationTimestamp:2019-01-17 17:18:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment dcf7b41a-1a7b-11e9-8458-5254003c4592 0xc000a5dc07 0xc000a5dc08}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 17 17:18:14.350: INFO: Pod "test-rolling-update-deployment-68b55d7bc6-2cqbk" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6-2cqbk,GenerateName:test-rolling-update-deployment-68b55d7bc6-,Namespace:e2e-tests-deployment-z8dwb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z8dwb/pods/test-rolling-update-deployment-68b55d7bc6-2cqbk,UID:dcfe8a8e-1a7b-11e9-8458-5254003c4592,ResourceVersion:75012,Generation:0,CreationTimestamp:2019-01-17 17:18:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-68b55d7bc6 dcfc9b36-1a7b-11e9-8458-5254003c4592 0xc00200e587 0xc00200e588}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7wmq5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7wmq5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-7wmq5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00200e600} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00200e620}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 17:18:10 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 17:18:13 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 17:18:13 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 17:18:10 +0000 UTC  }],Message:,Reason:,HostIP:192.168.122.53,PodIP:10.244.1.175,StartTime:2019-01-17 17:18:10 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-01-17 17:18:12 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:2238f5a02d2648d41cc94a88f084060fbfa860890220328eb92696bf2ac649c9 cri-o://907280736ac48e10cf80830ec7587abab7de50616e0c0ecf4b93577698197340}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:18:14.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-z8dwb" for this suite.
Jan 17 17:18:20.404: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:18:20.441: INFO: namespace: e2e-tests-deployment-z8dwb, resource: bindings, ignored listing per whitelist
Jan 17 17:18:20.497: INFO: namespace e2e-tests-deployment-z8dwb deletion completed in 6.139344277s

• [SLOW TEST:15.482 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:18:20.502: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1134
STEP: creating an rc
Jan 17 17:18:20.659: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 create -f - --namespace=e2e-tests-kubectl-cstz5'
Jan 17 17:18:22.046: INFO: stderr: ""
Jan 17 17:18:22.046: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Jan 17 17:18:23.048: INFO: Selector matched 1 pods for map[app:redis]
Jan 17 17:18:23.048: INFO: Found 0 / 1
Jan 17 17:18:24.049: INFO: Selector matched 1 pods for map[app:redis]
Jan 17 17:18:24.049: INFO: Found 0 / 1
Jan 17 17:18:25.083: INFO: Selector matched 1 pods for map[app:redis]
Jan 17 17:18:25.083: INFO: Found 1 / 1
Jan 17 17:18:25.083: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jan 17 17:18:25.093: INFO: Selector matched 1 pods for map[app:redis]
Jan 17 17:18:25.093: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Jan 17 17:18:25.093: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 logs redis-master-lvbqj redis-master --namespace=e2e-tests-kubectl-cstz5'
Jan 17 17:18:25.280: INFO: stderr: ""
Jan 17 17:18:25.280: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 17 Jan 17:18:23.977 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 17 Jan 17:18:23.977 # Server started, Redis version 3.2.12\n1:M 17 Jan 17:18:23.977 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 17 Jan 17:18:23.977 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Jan 17 17:18:25.281: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 log redis-master-lvbqj redis-master --namespace=e2e-tests-kubectl-cstz5 --tail=1'
Jan 17 17:18:25.410: INFO: stderr: ""
Jan 17 17:18:25.410: INFO: stdout: "1:M 17 Jan 17:18:23.977 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Jan 17 17:18:25.410: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 log redis-master-lvbqj redis-master --namespace=e2e-tests-kubectl-cstz5 --limit-bytes=1'
Jan 17 17:18:25.559: INFO: stderr: ""
Jan 17 17:18:25.559: INFO: stdout: " "
STEP: exposing timestamps
Jan 17 17:18:25.559: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 log redis-master-lvbqj redis-master --namespace=e2e-tests-kubectl-cstz5 --tail=1 --timestamps'
Jan 17 17:18:25.703: INFO: stderr: ""
Jan 17 17:18:25.703: INFO: stdout: "2019-01-17T17:18:23.977254659Z 1:M 17 Jan 17:18:23.977 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Jan 17 17:18:28.203: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 log redis-master-lvbqj redis-master --namespace=e2e-tests-kubectl-cstz5 --since=1s'
Jan 17 17:18:28.358: INFO: stderr: ""
Jan 17 17:18:28.358: INFO: stdout: ""
Jan 17 17:18:28.358: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 log redis-master-lvbqj redis-master --namespace=e2e-tests-kubectl-cstz5 --since=24h'
Jan 17 17:18:28.519: INFO: stderr: ""
Jan 17 17:18:28.519: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 17 Jan 17:18:23.977 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 17 Jan 17:18:23.977 # Server started, Redis version 3.2.12\n1:M 17 Jan 17:18:23.977 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 17 Jan 17:18:23.977 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1140
STEP: using delete to clean up resources
Jan 17 17:18:28.519: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-cstz5'
Jan 17 17:18:28.645: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 17 17:18:28.645: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Jan 17 17:18:28.645: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-cstz5'
Jan 17 17:18:28.827: INFO: stderr: "No resources found.\n"
Jan 17 17:18:28.827: INFO: stdout: ""
Jan 17 17:18:28.827: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 get pods -l name=nginx --namespace=e2e-tests-kubectl-cstz5 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan 17 17:18:28.935: INFO: stderr: ""
Jan 17 17:18:28.935: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:18:28.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-cstz5" for this suite.
Jan 17 17:18:34.962: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:18:35.012: INFO: namespace: e2e-tests-kubectl-cstz5, resource: bindings, ignored listing per whitelist
Jan 17 17:18:35.087: INFO: namespace e2e-tests-kubectl-cstz5 deletion completed in 6.148313962s

• [SLOW TEST:14.586 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:18:35.090: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1052
STEP: creating the pod
Jan 17 17:18:35.447: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 create -f - --namespace=e2e-tests-kubectl-hnql4'
Jan 17 17:18:35.661: INFO: stderr: ""
Jan 17 17:18:35.661: INFO: stdout: "pod/pause created\n"
Jan 17 17:18:35.661: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Jan 17 17:18:35.661: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-hnql4" to be "running and ready"
Jan 17 17:18:35.687: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 26.61622ms
Jan 17 17:18:37.694: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032947051s
Jan 17 17:18:39.701: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.040563839s
Jan 17 17:18:39.701: INFO: Pod "pause" satisfied condition "running and ready"
Jan 17 17:18:39.701: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Jan 17 17:18:39.702: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-hnql4'
Jan 17 17:18:39.876: INFO: stderr: ""
Jan 17 17:18:39.876: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Jan 17 17:18:39.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 get pod pause -L testing-label --namespace=e2e-tests-kubectl-hnql4'
Jan 17 17:18:40.164: INFO: stderr: ""
Jan 17 17:18:40.164: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Jan 17 17:18:40.165: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 label pods pause testing-label- --namespace=e2e-tests-kubectl-hnql4'
Jan 17 17:18:40.330: INFO: stderr: ""
Jan 17 17:18:40.330: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Jan 17 17:18:40.330: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 get pod pause -L testing-label --namespace=e2e-tests-kubectl-hnql4'
Jan 17 17:18:40.456: INFO: stderr: ""
Jan 17 17:18:40.456: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1059
STEP: using delete to clean up resources
Jan 17 17:18:40.456: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-hnql4'
Jan 17 17:18:40.600: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 17 17:18:40.600: INFO: stdout: "pod \"pause\" force deleted\n"
Jan 17 17:18:40.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-hnql4'
Jan 17 17:18:40.756: INFO: stderr: "No resources found.\n"
Jan 17 17:18:40.756: INFO: stdout: ""
Jan 17 17:18:40.756: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 get pods -l name=pause --namespace=e2e-tests-kubectl-hnql4 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan 17 17:18:40.844: INFO: stderr: ""
Jan 17 17:18:40.844: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:18:40.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hnql4" for this suite.
Jan 17 17:18:46.869: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:18:46.943: INFO: namespace: e2e-tests-kubectl-hnql4, resource: bindings, ignored listing per whitelist
Jan 17 17:18:46.962: INFO: namespace e2e-tests-kubectl-hnql4 deletion completed in 6.112159093s

• [SLOW TEST:11.872 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:18:46.965: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 17 17:18:47.043: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f2eb5737-1a7b-11e9-a4b6-0a580af40269" in namespace "e2e-tests-downward-api-8dw2z" to be "success or failure"
Jan 17 17:18:47.051: INFO: Pod "downwardapi-volume-f2eb5737-1a7b-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 8.46757ms
Jan 17 17:18:49.057: INFO: Pod "downwardapi-volume-f2eb5737-1a7b-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014040475s
Jan 17 17:18:51.092: INFO: Pod "downwardapi-volume-f2eb5737-1a7b-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048654326s
STEP: Saw pod success
Jan 17 17:18:51.095: INFO: Pod "downwardapi-volume-f2eb5737-1a7b-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 17:18:51.103: INFO: Trying to get logs from node node1 pod downwardapi-volume-f2eb5737-1a7b-11e9-a4b6-0a580af40269 container client-container: <nil>
STEP: delete the pod
Jan 17 17:18:51.167: INFO: Waiting for pod downwardapi-volume-f2eb5737-1a7b-11e9-a4b6-0a580af40269 to disappear
Jan 17 17:18:51.169: INFO: Pod downwardapi-volume-f2eb5737-1a7b-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:18:51.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-8dw2z" for this suite.
Jan 17 17:18:57.197: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:18:57.285: INFO: namespace: e2e-tests-downward-api-8dw2z, resource: bindings, ignored listing per whitelist
Jan 17 17:18:57.289: INFO: namespace e2e-tests-downward-api-8dw2z deletion completed in 6.111335574s

• [SLOW TEST:10.324 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:18:57.295: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Jan 17 17:18:58.008: INFO: Pod name wrapped-volume-race-f967e866-1a7b-11e9-a4b6-0a580af40269: Found 0 pods out of 5
Jan 17 17:19:03.048: INFO: Pod name wrapped-volume-race-f967e866-1a7b-11e9-a4b6-0a580af40269: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-f967e866-1a7b-11e9-a4b6-0a580af40269 in namespace e2e-tests-emptydir-wrapper-ck5tg, will wait for the garbage collector to delete the pods
Jan 17 17:19:15.513: INFO: Deleting ReplicationController wrapped-volume-race-f967e866-1a7b-11e9-a4b6-0a580af40269 took: 4.404ms
Jan 17 17:19:15.613: INFO: Terminating ReplicationController wrapped-volume-race-f967e866-1a7b-11e9-a4b6-0a580af40269 pods took: 100.293919ms
STEP: Creating RC which spawns configmap-volume pods
Jan 17 17:19:50.835: INFO: Pod name wrapped-volume-race-18e083e5-1a7c-11e9-a4b6-0a580af40269: Found 2 pods out of 5
Jan 17 17:19:55.923: INFO: Pod name wrapped-volume-race-18e083e5-1a7c-11e9-a4b6-0a580af40269: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-18e083e5-1a7c-11e9-a4b6-0a580af40269 in namespace e2e-tests-emptydir-wrapper-ck5tg, will wait for the garbage collector to delete the pods
Jan 17 17:20:06.029: INFO: Deleting ReplicationController wrapped-volume-race-18e083e5-1a7c-11e9-a4b6-0a580af40269 took: 12.641527ms
Jan 17 17:20:06.229: INFO: Terminating ReplicationController wrapped-volume-race-18e083e5-1a7c-11e9-a4b6-0a580af40269 pods took: 200.546718ms
STEP: Creating RC which spawns configmap-volume pods
Jan 17 17:20:42.281: INFO: Pod name wrapped-volume-race-37952f08-1a7c-11e9-a4b6-0a580af40269: Found 0 pods out of 5
Jan 17 17:20:47.351: INFO: Pod name wrapped-volume-race-37952f08-1a7c-11e9-a4b6-0a580af40269: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-37952f08-1a7c-11e9-a4b6-0a580af40269 in namespace e2e-tests-emptydir-wrapper-ck5tg, will wait for the garbage collector to delete the pods
Jan 17 17:20:57.453: INFO: Deleting ReplicationController wrapped-volume-race-37952f08-1a7c-11e9-a4b6-0a580af40269 took: 14.570373ms
Jan 17 17:20:57.553: INFO: Terminating ReplicationController wrapped-volume-race-37952f08-1a7c-11e9-a4b6-0a580af40269 pods took: 100.133231ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:21:33.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-ck5tg" for this suite.
Jan 17 17:21:41.842: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:21:41.880: INFO: namespace: e2e-tests-emptydir-wrapper-ck5tg, resource: bindings, ignored listing per whitelist
Jan 17 17:21:41.928: INFO: namespace e2e-tests-emptydir-wrapper-ck5tg deletion completed in 8.098397607s

• [SLOW TEST:164.632 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:21:41.928: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 17 17:21:41.999: INFO: Creating ReplicaSet my-hostname-basic-5b3546fd-1a7c-11e9-a4b6-0a580af40269
Jan 17 17:21:42.022: INFO: Pod name my-hostname-basic-5b3546fd-1a7c-11e9-a4b6-0a580af40269: Found 0 pods out of 1
Jan 17 17:21:47.032: INFO: Pod name my-hostname-basic-5b3546fd-1a7c-11e9-a4b6-0a580af40269: Found 1 pods out of 1
Jan 17 17:21:47.033: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-5b3546fd-1a7c-11e9-a4b6-0a580af40269" is running
Jan 17 17:21:47.072: INFO: Pod "my-hostname-basic-5b3546fd-1a7c-11e9-a4b6-0a580af40269-7jhp2" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-17 17:21:42 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-17 17:21:45 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-17 17:21:45 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-17 17:21:42 +0000 UTC Reason: Message:}])
Jan 17 17:21:47.072: INFO: Trying to dial the pod
Jan 17 17:21:52.101: INFO: Controller my-hostname-basic-5b3546fd-1a7c-11e9-a4b6-0a580af40269: Got expected result from replica 1 [my-hostname-basic-5b3546fd-1a7c-11e9-a4b6-0a580af40269-7jhp2]: "my-hostname-basic-5b3546fd-1a7c-11e9-a4b6-0a580af40269-7jhp2", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:21:52.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-7dz7x" for this suite.
Jan 17 17:21:58.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:21:58.213: INFO: namespace: e2e-tests-replicaset-7dz7x, resource: bindings, ignored listing per whitelist
Jan 17 17:21:58.236: INFO: namespace e2e-tests-replicaset-7dz7x deletion completed in 6.106233538s

• [SLOW TEST:16.308 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:21:58.237: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-64fa242a-1a7c-11e9-a4b6-0a580af40269
STEP: Creating secret with name secret-projected-all-test-volume-64fa241c-1a7c-11e9-a4b6-0a580af40269
STEP: Creating a pod to test Check all projections for projected volume plugin
Jan 17 17:21:58.434: INFO: Waiting up to 5m0s for pod "projected-volume-64fa23ef-1a7c-11e9-a4b6-0a580af40269" in namespace "e2e-tests-projected-5pjtm" to be "success or failure"
Jan 17 17:21:58.440: INFO: Pod "projected-volume-64fa23ef-1a7c-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 5.917214ms
Jan 17 17:22:00.446: INFO: Pod "projected-volume-64fa23ef-1a7c-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011922833s
STEP: Saw pod success
Jan 17 17:22:00.446: INFO: Pod "projected-volume-64fa23ef-1a7c-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 17:22:00.486: INFO: Trying to get logs from node node1 pod projected-volume-64fa23ef-1a7c-11e9-a4b6-0a580af40269 container projected-all-volume-test: <nil>
STEP: delete the pod
Jan 17 17:22:00.509: INFO: Waiting for pod projected-volume-64fa23ef-1a7c-11e9-a4b6-0a580af40269 to disappear
Jan 17 17:22:00.520: INFO: Pod projected-volume-64fa23ef-1a7c-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:22:00.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5pjtm" for this suite.
Jan 17 17:22:06.569: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:22:06.609: INFO: namespace: e2e-tests-projected-5pjtm, resource: bindings, ignored listing per whitelist
Jan 17 17:22:06.661: INFO: namespace e2e-tests-projected-5pjtm deletion completed in 6.112010035s

• [SLOW TEST:8.425 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:22:06.662: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Jan 17 17:22:06.738: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 api-versions'
Jan 17 17:22:06.840: INFO: stderr: ""
Jan 17 17:22:06.840: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:22:06.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-nflt9" for this suite.
Jan 17 17:22:12.867: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:22:12.916: INFO: namespace: e2e-tests-kubectl-nflt9, resource: bindings, ignored listing per whitelist
Jan 17 17:22:12.954: INFO: namespace e2e-tests-kubectl-nflt9 deletion completed in 6.107795355s

• [SLOW TEST:6.292 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:22:12.955: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Jan 17 17:22:17.212: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:22:41.294: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-4sb82" for this suite.
Jan 17 17:22:47.373: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:22:47.427: INFO: namespace: e2e-tests-namespaces-4sb82, resource: bindings, ignored listing per whitelist
Jan 17 17:22:47.445: INFO: namespace e2e-tests-namespaces-4sb82 deletion completed in 6.093389936s
STEP: Destroying namespace "e2e-tests-nsdeletetest-js7cd" for this suite.
Jan 17 17:22:47.447: INFO: Namespace e2e-tests-nsdeletetest-js7cd was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-zwttz" for this suite.
Jan 17 17:22:53.479: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:22:53.520: INFO: namespace: e2e-tests-nsdeletetest-zwttz, resource: bindings, ignored listing per whitelist
Jan 17 17:22:53.564: INFO: namespace e2e-tests-nsdeletetest-zwttz deletion completed in 6.116678562s

• [SLOW TEST:40.608 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:22:53.564: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 17 17:22:53.655: INFO: Waiting up to 5m0s for pod "downwardapi-volume-85e9c223-1a7c-11e9-a4b6-0a580af40269" in namespace "e2e-tests-projected-x5kbl" to be "success or failure"
Jan 17 17:22:53.665: INFO: Pod "downwardapi-volume-85e9c223-1a7c-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 10.348143ms
Jan 17 17:22:55.674: INFO: Pod "downwardapi-volume-85e9c223-1a7c-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019359745s
Jan 17 17:22:57.709: INFO: Pod "downwardapi-volume-85e9c223-1a7c-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053967462s
STEP: Saw pod success
Jan 17 17:22:57.709: INFO: Pod "downwardapi-volume-85e9c223-1a7c-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 17:22:57.718: INFO: Trying to get logs from node node1 pod downwardapi-volume-85e9c223-1a7c-11e9-a4b6-0a580af40269 container client-container: <nil>
STEP: delete the pod
Jan 17 17:22:57.787: INFO: Waiting for pod downwardapi-volume-85e9c223-1a7c-11e9-a4b6-0a580af40269 to disappear
Jan 17 17:22:57.789: INFO: Pod downwardapi-volume-85e9c223-1a7c-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:22:57.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-x5kbl" for this suite.
Jan 17 17:23:03.820: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:23:03.921: INFO: namespace: e2e-tests-projected-x5kbl, resource: bindings, ignored listing per whitelist
Jan 17 17:23:03.930: INFO: namespace e2e-tests-projected-x5kbl deletion completed in 6.136150347s

• [SLOW TEST:10.366 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:23:03.930: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Jan 17 17:23:08.046: INFO: Pod pod-hostip-8c18eddf-1a7c-11e9-a4b6-0a580af40269 has hostIP: 192.168.122.53
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:23:08.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-z7npt" for this suite.
Jan 17 17:23:30.066: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:23:30.131: INFO: namespace: e2e-tests-pods-z7npt, resource: bindings, ignored listing per whitelist
Jan 17 17:23:30.149: INFO: namespace e2e-tests-pods-z7npt deletion completed in 22.099022244s

• [SLOW TEST:26.219 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:23:30.151: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Jan 17 17:23:30.264: INFO: Waiting up to 5m0s for pod "pod-9bba4cb0-1a7c-11e9-a4b6-0a580af40269" in namespace "e2e-tests-emptydir-r5mjh" to be "success or failure"
Jan 17 17:23:30.281: INFO: Pod "pod-9bba4cb0-1a7c-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 16.939199ms
Jan 17 17:23:32.289: INFO: Pod "pod-9bba4cb0-1a7c-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024441795s
Jan 17 17:23:34.331: INFO: Pod "pod-9bba4cb0-1a7c-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.06673941s
STEP: Saw pod success
Jan 17 17:23:34.332: INFO: Pod "pod-9bba4cb0-1a7c-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 17:23:34.347: INFO: Trying to get logs from node node1 pod pod-9bba4cb0-1a7c-11e9-a4b6-0a580af40269 container test-container: <nil>
STEP: delete the pod
Jan 17 17:23:34.415: INFO: Waiting for pod pod-9bba4cb0-1a7c-11e9-a4b6-0a580af40269 to disappear
Jan 17 17:23:34.417: INFO: Pod pod-9bba4cb0-1a7c-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:23:34.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-r5mjh" for this suite.
Jan 17 17:23:40.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:23:40.453: INFO: namespace: e2e-tests-emptydir-r5mjh, resource: bindings, ignored listing per whitelist
Jan 17 17:23:40.508: INFO: namespace e2e-tests-emptydir-r5mjh deletion completed in 6.086370862s

• [SLOW TEST:10.357 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:23:40.509: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Jan 17 17:23:40.724: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 create -f - --namespace=e2e-tests-kubectl-zl6lc'
Jan 17 17:23:40.845: INFO: stderr: ""
Jan 17 17:23:40.845: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 17 17:23:40.845: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-zl6lc'
Jan 17 17:23:41.180: INFO: stderr: ""
Jan 17 17:23:41.180: INFO: stdout: "update-demo-nautilus-vqnwr update-demo-nautilus-zc2g6 "
Jan 17 17:23:41.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 get pods update-demo-nautilus-vqnwr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zl6lc'
Jan 17 17:23:41.360: INFO: stderr: ""
Jan 17 17:23:41.360: INFO: stdout: ""
Jan 17 17:23:41.360: INFO: update-demo-nautilus-vqnwr is created but not running
Jan 17 17:23:46.360: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-zl6lc'
Jan 17 17:23:46.703: INFO: stderr: ""
Jan 17 17:23:46.703: INFO: stdout: "update-demo-nautilus-vqnwr update-demo-nautilus-zc2g6 "
Jan 17 17:23:46.703: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 get pods update-demo-nautilus-vqnwr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zl6lc'
Jan 17 17:23:46.823: INFO: stderr: ""
Jan 17 17:23:46.823: INFO: stdout: "true"
Jan 17 17:23:46.824: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 get pods update-demo-nautilus-vqnwr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zl6lc'
Jan 17 17:23:46.924: INFO: stderr: ""
Jan 17 17:23:46.924: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 17 17:23:46.924: INFO: validating pod update-demo-nautilus-vqnwr
Jan 17 17:23:46.927: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 17 17:23:46.927: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 17 17:23:46.927: INFO: update-demo-nautilus-vqnwr is verified up and running
Jan 17 17:23:46.927: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 get pods update-demo-nautilus-zc2g6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zl6lc'
Jan 17 17:23:47.051: INFO: stderr: ""
Jan 17 17:23:47.051: INFO: stdout: "true"
Jan 17 17:23:47.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 get pods update-demo-nautilus-zc2g6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zl6lc'
Jan 17 17:23:47.144: INFO: stderr: ""
Jan 17 17:23:47.144: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 17 17:23:47.144: INFO: validating pod update-demo-nautilus-zc2g6
Jan 17 17:23:47.147: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 17 17:23:47.147: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 17 17:23:47.147: INFO: update-demo-nautilus-zc2g6 is verified up and running
STEP: rolling-update to new replication controller
Jan 17 17:23:47.148: INFO: scanned /root for discovery docs: <nil>
Jan 17 17:23:47.148: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-zl6lc'
Jan 17 17:24:13.099: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Jan 17 17:24:13.099: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 17 17:24:13.099: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-zl6lc'
Jan 17 17:24:13.409: INFO: stderr: ""
Jan 17 17:24:13.409: INFO: stdout: "update-demo-kitten-29rls update-demo-kitten-lf7gn "
Jan 17 17:24:13.409: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 get pods update-demo-kitten-29rls -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zl6lc'
Jan 17 17:24:13.536: INFO: stderr: ""
Jan 17 17:24:13.536: INFO: stdout: "true"
Jan 17 17:24:13.536: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 get pods update-demo-kitten-29rls -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zl6lc'
Jan 17 17:24:13.635: INFO: stderr: ""
Jan 17 17:24:13.636: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Jan 17 17:24:13.636: INFO: validating pod update-demo-kitten-29rls
Jan 17 17:24:13.640: INFO: got data: {
  "image": "kitten.jpg"
}

Jan 17 17:24:13.640: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Jan 17 17:24:13.640: INFO: update-demo-kitten-29rls is verified up and running
Jan 17 17:24:13.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 get pods update-demo-kitten-lf7gn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zl6lc'
Jan 17 17:24:13.763: INFO: stderr: ""
Jan 17 17:24:13.763: INFO: stdout: "true"
Jan 17 17:24:13.763: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 get pods update-demo-kitten-lf7gn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zl6lc'
Jan 17 17:24:13.881: INFO: stderr: ""
Jan 17 17:24:13.881: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Jan 17 17:24:13.881: INFO: validating pod update-demo-kitten-lf7gn
Jan 17 17:24:13.896: INFO: got data: {
  "image": "kitten.jpg"
}

Jan 17 17:24:13.896: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Jan 17 17:24:13.896: INFO: update-demo-kitten-lf7gn is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:24:13.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-zl6lc" for this suite.
Jan 17 17:24:35.981: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:24:36.048: INFO: namespace: e2e-tests-kubectl-zl6lc, resource: bindings, ignored listing per whitelist
Jan 17 17:24:36.093: INFO: namespace e2e-tests-kubectl-zl6lc deletion completed in 22.17101387s

• [SLOW TEST:55.584 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:24:36.093: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 17 17:24:36.185: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c3051886-1a7c-11e9-a4b6-0a580af40269" in namespace "e2e-tests-projected-cfz29" to be "success or failure"
Jan 17 17:24:36.197: INFO: Pod "downwardapi-volume-c3051886-1a7c-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 11.574616ms
Jan 17 17:24:38.236: INFO: Pod "downwardapi-volume-c3051886-1a7c-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.050114342s
Jan 17 17:24:40.242: INFO: Pod "downwardapi-volume-c3051886-1a7c-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.05620756s
STEP: Saw pod success
Jan 17 17:24:40.242: INFO: Pod "downwardapi-volume-c3051886-1a7c-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 17:24:40.279: INFO: Trying to get logs from node node1 pod downwardapi-volume-c3051886-1a7c-11e9-a4b6-0a580af40269 container client-container: <nil>
STEP: delete the pod
Jan 17 17:24:40.301: INFO: Waiting for pod downwardapi-volume-c3051886-1a7c-11e9-a4b6-0a580af40269 to disappear
Jan 17 17:24:40.311: INFO: Pod downwardapi-volume-c3051886-1a7c-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:24:40.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-cfz29" for this suite.
Jan 17 17:24:46.342: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:24:46.401: INFO: namespace: e2e-tests-projected-cfz29, resource: bindings, ignored listing per whitelist
Jan 17 17:24:46.414: INFO: namespace e2e-tests-projected-cfz29 deletion completed in 6.096521231s

• [SLOW TEST:10.321 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:24:46.415: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-c92cbfd0-1a7c-11e9-a4b6-0a580af40269
STEP: Creating a pod to test consume configMaps
Jan 17 17:24:46.523: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c92e2bf1-1a7c-11e9-a4b6-0a580af40269" in namespace "e2e-tests-projected-m7dv7" to be "success or failure"
Jan 17 17:24:46.527: INFO: Pod "pod-projected-configmaps-c92e2bf1-1a7c-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 3.322182ms
Jan 17 17:24:48.564: INFO: Pod "pod-projected-configmaps-c92e2bf1-1a7c-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040728462s
Jan 17 17:24:50.574: INFO: Pod "pod-projected-configmaps-c92e2bf1-1a7c-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051173245s
STEP: Saw pod success
Jan 17 17:24:50.575: INFO: Pod "pod-projected-configmaps-c92e2bf1-1a7c-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 17:24:50.618: INFO: Trying to get logs from node node1 pod pod-projected-configmaps-c92e2bf1-1a7c-11e9-a4b6-0a580af40269 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 17 17:24:50.643: INFO: Waiting for pod pod-projected-configmaps-c92e2bf1-1a7c-11e9-a4b6-0a580af40269 to disappear
Jan 17 17:24:50.654: INFO: Pod pod-projected-configmaps-c92e2bf1-1a7c-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:24:50.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-m7dv7" for this suite.
Jan 17 17:24:56.673: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:24:56.710: INFO: namespace: e2e-tests-projected-m7dv7, resource: bindings, ignored listing per whitelist
Jan 17 17:24:56.731: INFO: namespace e2e-tests-projected-m7dv7 deletion completed in 6.072733102s

• [SLOW TEST:10.316 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:24:56.734: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Jan 17 17:24:56.887: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jan 17 17:24:56.898: INFO: Waiting for terminating namespaces to be deleted...
Jan 17 17:24:56.901: INFO: 
Logging pods the kubelet thinks is on node node1 before test
Jan 17 17:24:56.909: INFO: kube-flannel-ds-amd64-8fwk6 from kube-system started at 2019-01-17 06:49:56 +0000 UTC (1 container statuses recorded)
Jan 17 17:24:56.909: INFO: 	Container kube-flannel ready: true, restart count 1
Jan 17 17:24:56.909: INFO: sonobuoy-systemd-logs-daemon-set-0dcc53c5f8e1419f-kq5jj from heptio-sonobuoy started at 2019-01-17 17:15:12 +0000 UTC (2 container statuses recorded)
Jan 17 17:24:56.909: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan 17 17:24:56.909: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 17 17:24:56.909: INFO: kube-proxy-7z4x2 from kube-system started at 2019-01-17 06:49:56 +0000 UTC (1 container statuses recorded)
Jan 17 17:24:56.909: INFO: 	Container kube-proxy ready: true, restart count 1
Jan 17 17:24:56.909: INFO: sonobuoy from heptio-sonobuoy started at 2019-01-17 17:15:08 +0000 UTC (1 container statuses recorded)
Jan 17 17:24:56.909: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jan 17 17:24:56.909: INFO: 
Logging pods the kubelet thinks is on node node2 before test
Jan 17 17:24:56.956: INFO: kube-flannel-ds-amd64-pcptp from kube-system started at 2019-01-17 06:52:49 +0000 UTC (1 container statuses recorded)
Jan 17 17:24:56.956: INFO: 	Container kube-flannel ready: true, restart count 1
Jan 17 17:24:56.956: INFO: kube-proxy-qmrgn from kube-system started at 2019-01-17 06:52:49 +0000 UTC (1 container statuses recorded)
Jan 17 17:24:56.959: INFO: 	Container kube-proxy ready: true, restart count 1
Jan 17 17:24:56.961: INFO: sonobuoy-e2e-job-5a5cc172c34e4413 from heptio-sonobuoy started at 2019-01-17 17:15:12 +0000 UTC (2 container statuses recorded)
Jan 17 17:24:56.961: INFO: 	Container e2e ready: true, restart count 0
Jan 17 17:24:56.961: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 17 17:24:56.961: INFO: sonobuoy-systemd-logs-daemon-set-0dcc53c5f8e1419f-q5jtj from heptio-sonobuoy started at 2019-01-17 17:15:12 +0000 UTC (2 container statuses recorded)
Jan 17 17:24:56.961: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan 17 17:24:56.961: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.157ab2b167b8462a], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:24:57.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-fhjjb" for this suite.
Jan 17 17:25:04.028: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:25:04.140: INFO: namespace: e2e-tests-sched-pred-fhjjb, resource: bindings, ignored listing per whitelist
Jan 17 17:25:04.152: INFO: namespace e2e-tests-sched-pred-fhjjb deletion completed in 6.146031289s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.418 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:25:04.152: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan 17 17:25:04.236: INFO: Waiting up to 5m0s for pod "downward-api-d3bec3af-1a7c-11e9-a4b6-0a580af40269" in namespace "e2e-tests-downward-api-kb8mg" to be "success or failure"
Jan 17 17:25:04.247: INFO: Pod "downward-api-d3bec3af-1a7c-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 10.334708ms
Jan 17 17:25:06.254: INFO: Pod "downward-api-d3bec3af-1a7c-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017697667s
Jan 17 17:25:08.290: INFO: Pod "downward-api-d3bec3af-1a7c-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053934085s
STEP: Saw pod success
Jan 17 17:25:08.290: INFO: Pod "downward-api-d3bec3af-1a7c-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 17:25:08.294: INFO: Trying to get logs from node node1 pod downward-api-d3bec3af-1a7c-11e9-a4b6-0a580af40269 container dapi-container: <nil>
STEP: delete the pod
Jan 17 17:25:08.343: INFO: Waiting for pod downward-api-d3bec3af-1a7c-11e9-a4b6-0a580af40269 to disappear
Jan 17 17:25:08.346: INFO: Pod downward-api-d3bec3af-1a7c-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:25:08.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-kb8mg" for this suite.
Jan 17 17:25:14.385: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:25:14.477: INFO: namespace: e2e-tests-downward-api-kb8mg, resource: bindings, ignored listing per whitelist
Jan 17 17:25:14.483: INFO: namespace e2e-tests-downward-api-kb8mg deletion completed in 6.12557027s

• [SLOW TEST:10.332 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:25:14.489: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Jan 17 17:25:22.717: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 17 17:25:22.766: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 17 17:25:24.767: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 17 17:25:24.775: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 17 17:25:26.767: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 17 17:25:26.815: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 17 17:25:28.767: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 17 17:25:28.770: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 17 17:25:30.767: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 17 17:25:30.772: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 17 17:25:32.767: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 17 17:25:32.777: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 17 17:25:34.767: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 17 17:25:34.773: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 17 17:25:36.767: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 17 17:25:36.775: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 17 17:25:38.767: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 17 17:25:38.795: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 17 17:25:40.767: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 17 17:25:40.773: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 17 17:25:42.767: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 17 17:25:42.780: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 17 17:25:44.767: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 17 17:25:44.774: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 17 17:25:46.767: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 17 17:25:46.797: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 17 17:25:48.767: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 17 17:25:48.769: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:25:48.769: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-zd2t7" for this suite.
Jan 17 17:26:10.792: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:26:11.065: INFO: namespace: e2e-tests-container-lifecycle-hook-zd2t7, resource: bindings, ignored listing per whitelist
Jan 17 17:26:11.105: INFO: namespace e2e-tests-container-lifecycle-hook-zd2t7 deletion completed in 22.331055003s

• [SLOW TEST:56.616 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:26:11.105: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-lqfnc
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan 17 17:26:11.189: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan 17 17:26:35.387: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.207:8080/dial?request=hostName&protocol=http&host=10.244.2.112&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-lqfnc PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 17 17:26:35.388: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
Jan 17 17:26:35.474: INFO: Waiting for endpoints: map[]
Jan 17 17:26:35.477: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.207:8080/dial?request=hostName&protocol=http&host=10.244.1.206&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-lqfnc PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 17 17:26:35.477: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
Jan 17 17:26:35.524: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:26:35.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-lqfnc" for this suite.
Jan 17 17:26:57.595: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:26:57.618: INFO: namespace: e2e-tests-pod-network-test-lqfnc, resource: bindings, ignored listing per whitelist
Jan 17 17:26:57.668: INFO: namespace e2e-tests-pod-network-test-lqfnc deletion completed in 22.089082851s

• [SLOW TEST:46.563 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:26:57.669: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Jan 17 17:27:04.892: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:27:05.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-9mj7j" for this suite.
Jan 17 17:27:27.980: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:27:28.028: INFO: namespace: e2e-tests-replicaset-9mj7j, resource: bindings, ignored listing per whitelist
Jan 17 17:27:28.060: INFO: namespace e2e-tests-replicaset-9mj7j deletion completed in 22.100651468s

• [SLOW TEST:30.391 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:27:28.060: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:27:32.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-fw8z4" for this suite.
Jan 17 17:27:38.325: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:27:38.397: INFO: namespace: e2e-tests-emptydir-wrapper-fw8z4, resource: bindings, ignored listing per whitelist
Jan 17 17:27:38.452: INFO: namespace e2e-tests-emptydir-wrapper-fw8z4 deletion completed in 6.146131733s

• [SLOW TEST:10.392 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:27:38.453: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-2z5hs.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-2z5hs.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-2z5hs.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-2z5hs.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-2z5hs.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-2z5hs.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jan 17 17:27:42.650: INFO: DNS probes using e2e-tests-dns-2z5hs/dns-test-2fb6f710-1a7d-11e9-a4b6-0a580af40269 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:27:42.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-2z5hs" for this suite.
Jan 17 17:27:48.698: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:27:48.772: INFO: namespace: e2e-tests-dns-2z5hs, resource: bindings, ignored listing per whitelist
Jan 17 17:27:48.799: INFO: namespace e2e-tests-dns-2z5hs deletion completed in 6.122542156s

• [SLOW TEST:10.346 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:27:48.800: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan 17 17:27:48.984: INFO: Waiting up to 5m0s for pod "downward-api-35f0b060-1a7d-11e9-a4b6-0a580af40269" in namespace "e2e-tests-downward-api-qqnfj" to be "success or failure"
Jan 17 17:27:49.004: INFO: Pod "downward-api-35f0b060-1a7d-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 19.742675ms
Jan 17 17:27:51.012: INFO: Pod "downward-api-35f0b060-1a7d-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02803158s
Jan 17 17:27:53.020: INFO: Pod "downward-api-35f0b060-1a7d-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036123288s
STEP: Saw pod success
Jan 17 17:27:53.020: INFO: Pod "downward-api-35f0b060-1a7d-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 17:27:53.067: INFO: Trying to get logs from node node1 pod downward-api-35f0b060-1a7d-11e9-a4b6-0a580af40269 container dapi-container: <nil>
STEP: delete the pod
Jan 17 17:27:53.102: INFO: Waiting for pod downward-api-35f0b060-1a7d-11e9-a4b6-0a580af40269 to disappear
Jan 17 17:27:53.112: INFO: Pod downward-api-35f0b060-1a7d-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:27:53.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-qqnfj" for this suite.
Jan 17 17:27:59.170: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:27:59.253: INFO: namespace: e2e-tests-downward-api-qqnfj, resource: bindings, ignored listing per whitelist
Jan 17 17:27:59.260: INFO: namespace e2e-tests-downward-api-qqnfj deletion completed in 6.112902847s

• [SLOW TEST:10.460 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:27:59.262: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Jan 17 17:27:59.497: INFO: Waiting up to 5m0s for pod "pod-3c35c991-1a7d-11e9-a4b6-0a580af40269" in namespace "e2e-tests-emptydir-gjd7x" to be "success or failure"
Jan 17 17:27:59.505: INFO: Pod "pod-3c35c991-1a7d-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 7.699205ms
Jan 17 17:28:01.507: INFO: Pod "pod-3c35c991-1a7d-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009966543s
Jan 17 17:28:03.509: INFO: Pod "pod-3c35c991-1a7d-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012100757s
STEP: Saw pod success
Jan 17 17:28:03.510: INFO: Pod "pod-3c35c991-1a7d-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 17:28:03.546: INFO: Trying to get logs from node node1 pod pod-3c35c991-1a7d-11e9-a4b6-0a580af40269 container test-container: <nil>
STEP: delete the pod
Jan 17 17:28:03.570: INFO: Waiting for pod pod-3c35c991-1a7d-11e9-a4b6-0a580af40269 to disappear
Jan 17 17:28:03.579: INFO: Pod pod-3c35c991-1a7d-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:28:03.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-gjd7x" for this suite.
Jan 17 17:28:09.637: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:28:09.695: INFO: namespace: e2e-tests-emptydir-gjd7x, resource: bindings, ignored listing per whitelist
Jan 17 17:28:09.709: INFO: namespace e2e-tests-emptydir-gjd7x deletion completed in 6.093892805s

• [SLOW TEST:10.447 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:28:09.710: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 17 17:28:09.856: INFO: Waiting up to 5m0s for pod "downwardapi-volume-42629a32-1a7d-11e9-a4b6-0a580af40269" in namespace "e2e-tests-downward-api-4fr7v" to be "success or failure"
Jan 17 17:28:09.867: INFO: Pod "downwardapi-volume-42629a32-1a7d-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 10.542246ms
Jan 17 17:28:11.906: INFO: Pod "downwardapi-volume-42629a32-1a7d-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.050139568s
Jan 17 17:28:13.916: INFO: Pod "downwardapi-volume-42629a32-1a7d-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.059846754s
STEP: Saw pod success
Jan 17 17:28:13.916: INFO: Pod "downwardapi-volume-42629a32-1a7d-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 17:28:13.925: INFO: Trying to get logs from node node1 pod downwardapi-volume-42629a32-1a7d-11e9-a4b6-0a580af40269 container client-container: <nil>
STEP: delete the pod
Jan 17 17:28:13.959: INFO: Waiting for pod downwardapi-volume-42629a32-1a7d-11e9-a4b6-0a580af40269 to disappear
Jan 17 17:28:13.966: INFO: Pod downwardapi-volume-42629a32-1a7d-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:28:13.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-4fr7v" for this suite.
Jan 17 17:28:19.985: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:28:20.058: INFO: namespace: e2e-tests-downward-api-4fr7v, resource: bindings, ignored listing per whitelist
Jan 17 17:28:20.065: INFO: namespace e2e-tests-downward-api-4fr7v deletion completed in 6.093693664s

• [SLOW TEST:10.355 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:28:20.066: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-488e5808-1a7d-11e9-a4b6-0a580af40269
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-488e5808-1a7d-11e9-a4b6-0a580af40269
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:29:43.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-jvp77" for this suite.
Jan 17 17:30:05.205: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:30:05.233: INFO: namespace: e2e-tests-configmap-jvp77, resource: bindings, ignored listing per whitelist
Jan 17 17:30:05.263: INFO: namespace e2e-tests-configmap-jvp77 deletion completed in 22.080264248s

• [SLOW TEST:105.200 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:30:05.273: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Jan 17 17:30:05.438: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-b9jlc,SelfLink:/api/v1/namespaces/e2e-tests-watch-b9jlc/configmaps/e2e-watch-test-watch-closed,UID:87436ca6-1a7d-11e9-8458-5254003c4592,ResourceVersion:77732,Generation:0,CreationTimestamp:2019-01-17 17:30:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 17 17:30:05.438: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-b9jlc,SelfLink:/api/v1/namespaces/e2e-tests-watch-b9jlc/configmaps/e2e-watch-test-watch-closed,UID:87436ca6-1a7d-11e9-8458-5254003c4592,ResourceVersion:77733,Generation:0,CreationTimestamp:2019-01-17 17:30:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Jan 17 17:30:05.455: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-b9jlc,SelfLink:/api/v1/namespaces/e2e-tests-watch-b9jlc/configmaps/e2e-watch-test-watch-closed,UID:87436ca6-1a7d-11e9-8458-5254003c4592,ResourceVersion:77734,Generation:0,CreationTimestamp:2019-01-17 17:30:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 17 17:30:05.455: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-b9jlc,SelfLink:/api/v1/namespaces/e2e-tests-watch-b9jlc/configmaps/e2e-watch-test-watch-closed,UID:87436ca6-1a7d-11e9-8458-5254003c4592,ResourceVersion:77735,Generation:0,CreationTimestamp:2019-01-17 17:30:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:30:05.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-b9jlc" for this suite.
Jan 17 17:30:11.518: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:30:11.579: INFO: namespace: e2e-tests-watch-b9jlc, resource: bindings, ignored listing per whitelist
Jan 17 17:30:11.580: INFO: namespace e2e-tests-watch-b9jlc deletion completed in 6.110502626s

• [SLOW TEST:6.307 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:30:11.580: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-8b0318d6-1a7d-11e9-a4b6-0a580af40269
STEP: Creating a pod to test consume secrets
Jan 17 17:30:11.716: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8b04dd9c-1a7d-11e9-a4b6-0a580af40269" in namespace "e2e-tests-projected-q6qls" to be "success or failure"
Jan 17 17:30:11.731: INFO: Pod "pod-projected-secrets-8b04dd9c-1a7d-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 14.065608ms
Jan 17 17:30:13.733: INFO: Pod "pod-projected-secrets-8b04dd9c-1a7d-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01623589s
Jan 17 17:30:15.741: INFO: Pod "pod-projected-secrets-8b04dd9c-1a7d-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024688325s
STEP: Saw pod success
Jan 17 17:30:15.742: INFO: Pod "pod-projected-secrets-8b04dd9c-1a7d-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 17:30:15.774: INFO: Trying to get logs from node node1 pod pod-projected-secrets-8b04dd9c-1a7d-11e9-a4b6-0a580af40269 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan 17 17:30:15.796: INFO: Waiting for pod pod-projected-secrets-8b04dd9c-1a7d-11e9-a4b6-0a580af40269 to disappear
Jan 17 17:30:15.803: INFO: Pod pod-projected-secrets-8b04dd9c-1a7d-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:30:15.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-q6qls" for this suite.
Jan 17 17:30:21.860: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:30:21.934: INFO: namespace: e2e-tests-projected-q6qls, resource: bindings, ignored listing per whitelist
Jan 17 17:30:21.947: INFO: namespace e2e-tests-projected-q6qls deletion completed in 6.108163778s

• [SLOW TEST:10.367 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:30:21.949: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 17 17:30:22.105: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Jan 17 17:30:22.119: INFO: Number of nodes with available pods: 0
Jan 17 17:30:22.119: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Jan 17 17:30:22.192: INFO: Number of nodes with available pods: 0
Jan 17 17:30:22.192: INFO: Node node1 is running more than one daemon pod
Jan 17 17:30:23.196: INFO: Number of nodes with available pods: 0
Jan 17 17:30:23.196: INFO: Node node1 is running more than one daemon pod
Jan 17 17:30:24.194: INFO: Number of nodes with available pods: 0
Jan 17 17:30:24.194: INFO: Node node1 is running more than one daemon pod
Jan 17 17:30:25.195: INFO: Number of nodes with available pods: 1
Jan 17 17:30:25.195: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Jan 17 17:30:25.265: INFO: Number of nodes with available pods: 0
Jan 17 17:30:25.265: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Jan 17 17:30:25.277: INFO: Number of nodes with available pods: 0
Jan 17 17:30:25.279: INFO: Node node1 is running more than one daemon pod
Jan 17 17:30:26.283: INFO: Number of nodes with available pods: 0
Jan 17 17:30:26.283: INFO: Node node1 is running more than one daemon pod
Jan 17 17:30:27.283: INFO: Number of nodes with available pods: 0
Jan 17 17:30:27.283: INFO: Node node1 is running more than one daemon pod
Jan 17 17:30:28.315: INFO: Number of nodes with available pods: 0
Jan 17 17:30:28.315: INFO: Node node1 is running more than one daemon pod
Jan 17 17:30:29.288: INFO: Number of nodes with available pods: 0
Jan 17 17:30:29.288: INFO: Node node1 is running more than one daemon pod
Jan 17 17:30:30.326: INFO: Number of nodes with available pods: 0
Jan 17 17:30:30.326: INFO: Node node1 is running more than one daemon pod
Jan 17 17:30:31.289: INFO: Number of nodes with available pods: 0
Jan 17 17:30:31.289: INFO: Node node1 is running more than one daemon pod
Jan 17 17:30:32.290: INFO: Number of nodes with available pods: 0
Jan 17 17:30:32.290: INFO: Node node1 is running more than one daemon pod
Jan 17 17:30:33.289: INFO: Number of nodes with available pods: 0
Jan 17 17:30:33.289: INFO: Node node1 is running more than one daemon pod
Jan 17 17:30:34.290: INFO: Number of nodes with available pods: 0
Jan 17 17:30:34.290: INFO: Node node1 is running more than one daemon pod
Jan 17 17:30:35.290: INFO: Number of nodes with available pods: 0
Jan 17 17:30:35.290: INFO: Node node1 is running more than one daemon pod
Jan 17 17:30:36.309: INFO: Number of nodes with available pods: 0
Jan 17 17:30:36.309: INFO: Node node1 is running more than one daemon pod
Jan 17 17:30:37.283: INFO: Number of nodes with available pods: 0
Jan 17 17:30:37.283: INFO: Node node1 is running more than one daemon pod
Jan 17 17:30:38.302: INFO: Number of nodes with available pods: 0
Jan 17 17:30:38.303: INFO: Node node1 is running more than one daemon pod
Jan 17 17:30:39.283: INFO: Number of nodes with available pods: 0
Jan 17 17:30:39.283: INFO: Node node1 is running more than one daemon pod
Jan 17 17:30:40.283: INFO: Number of nodes with available pods: 0
Jan 17 17:30:40.283: INFO: Node node1 is running more than one daemon pod
Jan 17 17:30:41.283: INFO: Number of nodes with available pods: 0
Jan 17 17:30:41.283: INFO: Node node1 is running more than one daemon pod
Jan 17 17:30:42.283: INFO: Number of nodes with available pods: 0
Jan 17 17:30:42.283: INFO: Node node1 is running more than one daemon pod
Jan 17 17:30:43.283: INFO: Number of nodes with available pods: 0
Jan 17 17:30:43.283: INFO: Node node1 is running more than one daemon pod
Jan 17 17:30:44.299: INFO: Number of nodes with available pods: 0
Jan 17 17:30:44.299: INFO: Node node1 is running more than one daemon pod
Jan 17 17:30:45.283: INFO: Number of nodes with available pods: 0
Jan 17 17:30:45.283: INFO: Node node1 is running more than one daemon pod
Jan 17 17:30:46.299: INFO: Number of nodes with available pods: 0
Jan 17 17:30:46.300: INFO: Node node1 is running more than one daemon pod
Jan 17 17:30:47.283: INFO: Number of nodes with available pods: 0
Jan 17 17:30:47.283: INFO: Node node1 is running more than one daemon pod
Jan 17 17:30:48.283: INFO: Number of nodes with available pods: 0
Jan 17 17:30:48.283: INFO: Node node1 is running more than one daemon pod
Jan 17 17:30:49.283: INFO: Number of nodes with available pods: 0
Jan 17 17:30:49.283: INFO: Node node1 is running more than one daemon pod
Jan 17 17:30:50.283: INFO: Number of nodes with available pods: 0
Jan 17 17:30:50.283: INFO: Node node1 is running more than one daemon pod
Jan 17 17:30:51.283: INFO: Number of nodes with available pods: 0
Jan 17 17:30:51.283: INFO: Node node1 is running more than one daemon pod
Jan 17 17:30:52.298: INFO: Number of nodes with available pods: 0
Jan 17 17:30:52.299: INFO: Node node1 is running more than one daemon pod
Jan 17 17:30:53.283: INFO: Number of nodes with available pods: 0
Jan 17 17:30:53.283: INFO: Node node1 is running more than one daemon pod
Jan 17 17:30:54.298: INFO: Number of nodes with available pods: 0
Jan 17 17:30:54.299: INFO: Node node1 is running more than one daemon pod
Jan 17 17:30:55.283: INFO: Number of nodes with available pods: 0
Jan 17 17:30:55.283: INFO: Node node1 is running more than one daemon pod
Jan 17 17:30:56.283: INFO: Number of nodes with available pods: 0
Jan 17 17:30:56.283: INFO: Node node1 is running more than one daemon pod
Jan 17 17:30:57.290: INFO: Number of nodes with available pods: 0
Jan 17 17:30:57.290: INFO: Node node1 is running more than one daemon pod
Jan 17 17:30:58.283: INFO: Number of nodes with available pods: 0
Jan 17 17:30:58.283: INFO: Node node1 is running more than one daemon pod
Jan 17 17:30:59.283: INFO: Number of nodes with available pods: 0
Jan 17 17:30:59.283: INFO: Node node1 is running more than one daemon pod
Jan 17 17:31:00.305: INFO: Number of nodes with available pods: 0
Jan 17 17:31:00.305: INFO: Node node1 is running more than one daemon pod
Jan 17 17:31:01.289: INFO: Number of nodes with available pods: 0
Jan 17 17:31:01.289: INFO: Node node1 is running more than one daemon pod
Jan 17 17:31:02.299: INFO: Number of nodes with available pods: 0
Jan 17 17:31:02.299: INFO: Node node1 is running more than one daemon pod
Jan 17 17:31:03.283: INFO: Number of nodes with available pods: 0
Jan 17 17:31:03.283: INFO: Node node1 is running more than one daemon pod
Jan 17 17:31:04.283: INFO: Number of nodes with available pods: 0
Jan 17 17:31:04.283: INFO: Node node1 is running more than one daemon pod
Jan 17 17:31:05.288: INFO: Number of nodes with available pods: 0
Jan 17 17:31:05.288: INFO: Node node1 is running more than one daemon pod
Jan 17 17:31:06.288: INFO: Number of nodes with available pods: 0
Jan 17 17:31:06.289: INFO: Node node1 is running more than one daemon pod
Jan 17 17:31:07.283: INFO: Number of nodes with available pods: 0
Jan 17 17:31:07.283: INFO: Node node1 is running more than one daemon pod
Jan 17 17:31:08.301: INFO: Number of nodes with available pods: 0
Jan 17 17:31:08.301: INFO: Node node1 is running more than one daemon pod
Jan 17 17:31:09.291: INFO: Number of nodes with available pods: 0
Jan 17 17:31:09.292: INFO: Node node1 is running more than one daemon pod
Jan 17 17:31:10.305: INFO: Number of nodes with available pods: 0
Jan 17 17:31:10.305: INFO: Node node1 is running more than one daemon pod
Jan 17 17:31:11.290: INFO: Number of nodes with available pods: 0
Jan 17 17:31:11.291: INFO: Node node1 is running more than one daemon pod
Jan 17 17:31:12.288: INFO: Number of nodes with available pods: 1
Jan 17 17:31:12.289: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-vhh4m, will wait for the garbage collector to delete the pods
Jan 17 17:31:12.372: INFO: Deleting DaemonSet.extensions daemon-set took: 5.09341ms
Jan 17 17:31:12.474: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.57651ms
Jan 17 17:31:45.678: INFO: Number of nodes with available pods: 0
Jan 17 17:31:45.678: INFO: Number of running nodes: 0, number of available pods: 0
Jan 17 17:31:45.683: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-vhh4m/daemonsets","resourceVersion":"77959"},"items":null}

Jan 17 17:31:45.687: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-vhh4m/pods","resourceVersion":"77959"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:31:45.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-vhh4m" for this suite.
Jan 17 17:31:51.791: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:31:52.028: INFO: namespace: e2e-tests-daemonsets-vhh4m, resource: bindings, ignored listing per whitelist
Jan 17 17:31:52.091: INFO: namespace e2e-tests-daemonsets-vhh4m deletion completed in 6.312334135s

• [SLOW TEST:90.142 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:31:52.091: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Jan 17 17:31:52.794: INFO: Waiting up to 5m0s for pod "pod-service-account-c7445779-1a7d-11e9-a4b6-0a580af40269-jtsrn" in namespace "e2e-tests-svcaccounts-5mnkg" to be "success or failure"
Jan 17 17:31:52.807: INFO: Pod "pod-service-account-c7445779-1a7d-11e9-a4b6-0a580af40269-jtsrn": Phase="Pending", Reason="", readiness=false. Elapsed: 12.837361ms
Jan 17 17:31:54.809: INFO: Pod "pod-service-account-c7445779-1a7d-11e9-a4b6-0a580af40269-jtsrn": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014814611s
Jan 17 17:31:56.837: INFO: Pod "pod-service-account-c7445779-1a7d-11e9-a4b6-0a580af40269-jtsrn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042844245s
STEP: Saw pod success
Jan 17 17:31:56.837: INFO: Pod "pod-service-account-c7445779-1a7d-11e9-a4b6-0a580af40269-jtsrn" satisfied condition "success or failure"
Jan 17 17:31:56.848: INFO: Trying to get logs from node node1 pod pod-service-account-c7445779-1a7d-11e9-a4b6-0a580af40269-jtsrn container token-test: <nil>
STEP: delete the pod
Jan 17 17:31:56.888: INFO: Waiting for pod pod-service-account-c7445779-1a7d-11e9-a4b6-0a580af40269-jtsrn to disappear
Jan 17 17:31:56.895: INFO: Pod pod-service-account-c7445779-1a7d-11e9-a4b6-0a580af40269-jtsrn no longer exists
STEP: Creating a pod to test consume service account root CA
Jan 17 17:31:56.898: INFO: Waiting up to 5m0s for pod "pod-service-account-c7445779-1a7d-11e9-a4b6-0a580af40269-9lbj6" in namespace "e2e-tests-svcaccounts-5mnkg" to be "success or failure"
Jan 17 17:31:56.909: INFO: Pod "pod-service-account-c7445779-1a7d-11e9-a4b6-0a580af40269-9lbj6": Phase="Pending", Reason="", readiness=false. Elapsed: 10.494608ms
Jan 17 17:31:58.926: INFO: Pod "pod-service-account-c7445779-1a7d-11e9-a4b6-0a580af40269-9lbj6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027615395s
Jan 17 17:32:00.951: INFO: Pod "pod-service-account-c7445779-1a7d-11e9-a4b6-0a580af40269-9lbj6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052853349s
STEP: Saw pod success
Jan 17 17:32:00.953: INFO: Pod "pod-service-account-c7445779-1a7d-11e9-a4b6-0a580af40269-9lbj6" satisfied condition "success or failure"
Jan 17 17:32:00.956: INFO: Trying to get logs from node node1 pod pod-service-account-c7445779-1a7d-11e9-a4b6-0a580af40269-9lbj6 container root-ca-test: <nil>
STEP: delete the pod
Jan 17 17:32:00.988: INFO: Waiting for pod pod-service-account-c7445779-1a7d-11e9-a4b6-0a580af40269-9lbj6 to disappear
Jan 17 17:32:00.997: INFO: Pod pod-service-account-c7445779-1a7d-11e9-a4b6-0a580af40269-9lbj6 no longer exists
STEP: Creating a pod to test consume service account namespace
Jan 17 17:32:01.001: INFO: Waiting up to 5m0s for pod "pod-service-account-c7445779-1a7d-11e9-a4b6-0a580af40269-jshph" in namespace "e2e-tests-svcaccounts-5mnkg" to be "success or failure"
Jan 17 17:32:01.009: INFO: Pod "pod-service-account-c7445779-1a7d-11e9-a4b6-0a580af40269-jshph": Phase="Pending", Reason="", readiness=false. Elapsed: 7.665872ms
Jan 17 17:32:03.011: INFO: Pod "pod-service-account-c7445779-1a7d-11e9-a4b6-0a580af40269-jshph": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010122072s
Jan 17 17:32:05.035: INFO: Pod "pod-service-account-c7445779-1a7d-11e9-a4b6-0a580af40269-jshph": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033960901s
STEP: Saw pod success
Jan 17 17:32:05.035: INFO: Pod "pod-service-account-c7445779-1a7d-11e9-a4b6-0a580af40269-jshph" satisfied condition "success or failure"
Jan 17 17:32:05.039: INFO: Trying to get logs from node node1 pod pod-service-account-c7445779-1a7d-11e9-a4b6-0a580af40269-jshph container namespace-test: <nil>
STEP: delete the pod
Jan 17 17:32:05.066: INFO: Waiting for pod pod-service-account-c7445779-1a7d-11e9-a4b6-0a580af40269-jshph to disappear
Jan 17 17:32:05.074: INFO: Pod pod-service-account-c7445779-1a7d-11e9-a4b6-0a580af40269-jshph no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:32:05.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-5mnkg" for this suite.
Jan 17 17:32:11.104: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:32:11.170: INFO: namespace: e2e-tests-svcaccounts-5mnkg, resource: bindings, ignored listing per whitelist
Jan 17 17:32:11.182: INFO: namespace e2e-tests-svcaccounts-5mnkg deletion completed in 6.103246836s

• [SLOW TEST:19.091 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:32:11.186: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:33:11.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-z9mlb" for this suite.
Jan 17 17:33:33.405: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:33:33.472: INFO: namespace: e2e-tests-container-probe-z9mlb, resource: bindings, ignored listing per whitelist
Jan 17 17:33:33.482: INFO: namespace e2e-tests-container-probe-z9mlb deletion completed in 22.100627832s

• [SLOW TEST:82.296 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:33:33.484: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-lpjn
STEP: Creating a pod to test atomic-volume-subpath
Jan 17 17:33:33.678: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-lpjn" in namespace "e2e-tests-subpath-kdrn5" to be "success or failure"
Jan 17 17:33:33.690: INFO: Pod "pod-subpath-test-secret-lpjn": Phase="Pending", Reason="", readiness=false. Elapsed: 11.317716ms
Jan 17 17:33:35.692: INFO: Pod "pod-subpath-test-secret-lpjn": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013666925s
Jan 17 17:33:37.700: INFO: Pod "pod-subpath-test-secret-lpjn": Phase="Running", Reason="", readiness=false. Elapsed: 4.022007022s
Jan 17 17:33:39.712: INFO: Pod "pod-subpath-test-secret-lpjn": Phase="Running", Reason="", readiness=false. Elapsed: 6.033860513s
Jan 17 17:33:41.722: INFO: Pod "pod-subpath-test-secret-lpjn": Phase="Running", Reason="", readiness=false. Elapsed: 8.043485654s
Jan 17 17:33:43.749: INFO: Pod "pod-subpath-test-secret-lpjn": Phase="Running", Reason="", readiness=false. Elapsed: 10.07026387s
Jan 17 17:33:45.757: INFO: Pod "pod-subpath-test-secret-lpjn": Phase="Running", Reason="", readiness=false. Elapsed: 12.078531788s
Jan 17 17:33:47.774: INFO: Pod "pod-subpath-test-secret-lpjn": Phase="Running", Reason="", readiness=false. Elapsed: 14.096200576s
Jan 17 17:33:49.778: INFO: Pod "pod-subpath-test-secret-lpjn": Phase="Running", Reason="", readiness=false. Elapsed: 16.099358973s
Jan 17 17:33:51.801: INFO: Pod "pod-subpath-test-secret-lpjn": Phase="Running", Reason="", readiness=false. Elapsed: 18.122275136s
Jan 17 17:33:53.810: INFO: Pod "pod-subpath-test-secret-lpjn": Phase="Running", Reason="", readiness=false. Elapsed: 20.131588954s
Jan 17 17:33:55.832: INFO: Pod "pod-subpath-test-secret-lpjn": Phase="Running", Reason="", readiness=false. Elapsed: 22.153511402s
Jan 17 17:33:57.842: INFO: Pod "pod-subpath-test-secret-lpjn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.163477663s
STEP: Saw pod success
Jan 17 17:33:57.842: INFO: Pod "pod-subpath-test-secret-lpjn" satisfied condition "success or failure"
Jan 17 17:33:57.869: INFO: Trying to get logs from node node1 pod pod-subpath-test-secret-lpjn container test-container-subpath-secret-lpjn: <nil>
STEP: delete the pod
Jan 17 17:33:57.910: INFO: Waiting for pod pod-subpath-test-secret-lpjn to disappear
Jan 17 17:33:57.923: INFO: Pod pod-subpath-test-secret-lpjn no longer exists
STEP: Deleting pod pod-subpath-test-secret-lpjn
Jan 17 17:33:57.923: INFO: Deleting pod "pod-subpath-test-secret-lpjn" in namespace "e2e-tests-subpath-kdrn5"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:33:57.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-kdrn5" for this suite.
Jan 17 17:34:03.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:34:04.277: INFO: namespace: e2e-tests-subpath-kdrn5, resource: bindings, ignored listing per whitelist
Jan 17 17:34:04.310: INFO: namespace e2e-tests-subpath-kdrn5 deletion completed in 6.377740907s

• [SLOW TEST:30.827 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:34:04.312: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 17 17:34:04.403: INFO: Waiting up to 5m0s for pod "downwardapi-volume-15b65b59-1a7e-11e9-a4b6-0a580af40269" in namespace "e2e-tests-downward-api-zvpzk" to be "success or failure"
Jan 17 17:34:04.413: INFO: Pod "downwardapi-volume-15b65b59-1a7e-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 8.137154ms
Jan 17 17:34:06.450: INFO: Pod "downwardapi-volume-15b65b59-1a7e-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.045194759s
Jan 17 17:34:08.458: INFO: Pod "downwardapi-volume-15b65b59-1a7e-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053121031s
STEP: Saw pod success
Jan 17 17:34:08.458: INFO: Pod "downwardapi-volume-15b65b59-1a7e-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 17:34:08.502: INFO: Trying to get logs from node node1 pod downwardapi-volume-15b65b59-1a7e-11e9-a4b6-0a580af40269 container client-container: <nil>
STEP: delete the pod
Jan 17 17:34:08.529: INFO: Waiting for pod downwardapi-volume-15b65b59-1a7e-11e9-a4b6-0a580af40269 to disappear
Jan 17 17:34:08.538: INFO: Pod downwardapi-volume-15b65b59-1a7e-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:34:08.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-zvpzk" for this suite.
Jan 17 17:34:14.569: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:34:14.614: INFO: namespace: e2e-tests-downward-api-zvpzk, resource: bindings, ignored listing per whitelist
Jan 17 17:34:14.657: INFO: namespace e2e-tests-downward-api-zvpzk deletion completed in 6.109171269s

• [SLOW TEST:10.345 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:34:14.657: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1527
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 17 17:34:14.804: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-274dx'
Jan 17 17:34:15.675: INFO: stderr: ""
Jan 17 17:34:15.675: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1532
Jan 17 17:34:15.696: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-274dx'
Jan 17 17:34:19.121: INFO: stderr: ""
Jan 17 17:34:19.121: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:34:19.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-274dx" for this suite.
Jan 17 17:34:25.169: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:34:25.202: INFO: namespace: e2e-tests-kubectl-274dx, resource: bindings, ignored listing per whitelist
Jan 17 17:34:25.228: INFO: namespace e2e-tests-kubectl-274dx deletion completed in 6.073484472s

• [SLOW TEST:10.571 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:34:25.228: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Jan 17 17:34:25.370: INFO: Waiting up to 5m0s for pod "var-expansion-22344afd-1a7e-11e9-a4b6-0a580af40269" in namespace "e2e-tests-var-expansion-w8tpx" to be "success or failure"
Jan 17 17:34:25.380: INFO: Pod "var-expansion-22344afd-1a7e-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 10.128181ms
Jan 17 17:34:27.384: INFO: Pod "var-expansion-22344afd-1a7e-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01460221s
Jan 17 17:34:29.422: INFO: Pod "var-expansion-22344afd-1a7e-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052635284s
STEP: Saw pod success
Jan 17 17:34:29.422: INFO: Pod "var-expansion-22344afd-1a7e-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 17:34:29.425: INFO: Trying to get logs from node node1 pod var-expansion-22344afd-1a7e-11e9-a4b6-0a580af40269 container dapi-container: <nil>
STEP: delete the pod
Jan 17 17:34:29.470: INFO: Waiting for pod var-expansion-22344afd-1a7e-11e9-a4b6-0a580af40269 to disappear
Jan 17 17:34:29.477: INFO: Pod var-expansion-22344afd-1a7e-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:34:29.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-w8tpx" for this suite.
Jan 17 17:34:35.500: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:34:35.556: INFO: namespace: e2e-tests-var-expansion-w8tpx, resource: bindings, ignored listing per whitelist
Jan 17 17:34:35.586: INFO: namespace e2e-tests-var-expansion-w8tpx deletion completed in 6.106156329s

• [SLOW TEST:10.358 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:34:35.588: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-286338c3-1a7e-11e9-a4b6-0a580af40269
STEP: Creating a pod to test consume configMaps
Jan 17 17:34:35.754: INFO: Waiting up to 5m0s for pod "pod-configmaps-286617de-1a7e-11e9-a4b6-0a580af40269" in namespace "e2e-tests-configmap-8rl87" to be "success or failure"
Jan 17 17:34:35.763: INFO: Pod "pod-configmaps-286617de-1a7e-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 9.607988ms
Jan 17 17:34:37.766: INFO: Pod "pod-configmaps-286617de-1a7e-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012126454s
Jan 17 17:34:39.806: INFO: Pod "pod-configmaps-286617de-1a7e-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.05274619s
STEP: Saw pod success
Jan 17 17:34:39.807: INFO: Pod "pod-configmaps-286617de-1a7e-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 17:34:39.810: INFO: Trying to get logs from node node1 pod pod-configmaps-286617de-1a7e-11e9-a4b6-0a580af40269 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 17 17:34:39.854: INFO: Waiting for pod pod-configmaps-286617de-1a7e-11e9-a4b6-0a580af40269 to disappear
Jan 17 17:34:39.857: INFO: Pod pod-configmaps-286617de-1a7e-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:34:39.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-8rl87" for this suite.
Jan 17 17:34:45.890: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:34:45.958: INFO: namespace: e2e-tests-configmap-8rl87, resource: bindings, ignored listing per whitelist
Jan 17 17:34:45.991: INFO: namespace e2e-tests-configmap-8rl87 deletion completed in 6.124276017s

• [SLOW TEST:10.404 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:34:45.994: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 17 17:35:14.122: INFO: Container started at 2019-01-17 17:34:48 +0000 UTC, pod became ready at 2019-01-17 17:35:12 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:35:14.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-dld8w" for this suite.
Jan 17 17:35:36.158: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:35:36.199: INFO: namespace: e2e-tests-container-probe-dld8w, resource: bindings, ignored listing per whitelist
Jan 17 17:35:36.239: INFO: namespace e2e-tests-container-probe-dld8w deletion completed in 22.108884801s

• [SLOW TEST:50.246 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:35:36.239: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-pn759
Jan 17 17:35:40.356: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-pn759
STEP: checking the pod's current state and verifying that restartCount is present
Jan 17 17:35:40.368: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:39:41.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-pn759" for this suite.
Jan 17 17:39:47.262: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:39:47.313: INFO: namespace: e2e-tests-container-probe-pn759, resource: bindings, ignored listing per whitelist
Jan 17 17:39:47.348: INFO: namespace e2e-tests-container-probe-pn759 deletion completed in 6.113089551s

• [SLOW TEST:251.109 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:39:47.348: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:39:53.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-m64mg" for this suite.
Jan 17 17:39:59.734: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:39:59.742: INFO: namespace: e2e-tests-namespaces-m64mg, resource: bindings, ignored listing per whitelist
Jan 17 17:39:59.791: INFO: namespace e2e-tests-namespaces-m64mg deletion completed in 6.071945366s
STEP: Destroying namespace "e2e-tests-nsdeletetest-92zqh" for this suite.
Jan 17 17:39:59.793: INFO: Namespace e2e-tests-nsdeletetest-92zqh was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-nzgth" for this suite.
Jan 17 17:40:05.817: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:40:06.100: INFO: namespace: e2e-tests-nsdeletetest-nzgth, resource: bindings, ignored listing per whitelist
Jan 17 17:40:06.123: INFO: namespace e2e-tests-nsdeletetest-nzgth deletion completed in 6.329907454s

• [SLOW TEST:18.775 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:40:06.124: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 17 17:40:08.269: INFO: Waiting up to 5m0s for pod "client-envvars-ee969d29-1a7e-11e9-a4b6-0a580af40269" in namespace "e2e-tests-pods-gtftm" to be "success or failure"
Jan 17 17:40:08.281: INFO: Pod "client-envvars-ee969d29-1a7e-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 11.861744ms
Jan 17 17:40:10.288: INFO: Pod "client-envvars-ee969d29-1a7e-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019086375s
Jan 17 17:40:12.330: INFO: Pod "client-envvars-ee969d29-1a7e-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.061150181s
STEP: Saw pod success
Jan 17 17:40:12.330: INFO: Pod "client-envvars-ee969d29-1a7e-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 17:40:12.333: INFO: Trying to get logs from node node2 pod client-envvars-ee969d29-1a7e-11e9-a4b6-0a580af40269 container env3cont: <nil>
STEP: delete the pod
Jan 17 17:40:12.383: INFO: Waiting for pod client-envvars-ee969d29-1a7e-11e9-a4b6-0a580af40269 to disappear
Jan 17 17:40:12.385: INFO: Pod client-envvars-ee969d29-1a7e-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:40:12.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-gtftm" for this suite.
Jan 17 17:40:50.411: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:40:50.471: INFO: namespace: e2e-tests-pods-gtftm, resource: bindings, ignored listing per whitelist
Jan 17 17:40:50.493: INFO: namespace e2e-tests-pods-gtftm deletion completed in 38.10264021s

• [SLOW TEST:44.369 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:40:50.493: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-07d02990-1a7f-11e9-a4b6-0a580af40269
STEP: Creating a pod to test consume secrets
Jan 17 17:40:50.602: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-07d24791-1a7f-11e9-a4b6-0a580af40269" in namespace "e2e-tests-projected-62w2f" to be "success or failure"
Jan 17 17:40:50.611: INFO: Pod "pod-projected-secrets-07d24791-1a7f-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 9.313478ms
Jan 17 17:40:52.654: INFO: Pod "pod-projected-secrets-07d24791-1a7f-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.052496683s
Jan 17 17:40:54.657: INFO: Pod "pod-projected-secrets-07d24791-1a7f-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.055633174s
STEP: Saw pod success
Jan 17 17:40:54.658: INFO: Pod "pod-projected-secrets-07d24791-1a7f-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 17:40:54.698: INFO: Trying to get logs from node node1 pod pod-projected-secrets-07d24791-1a7f-11e9-a4b6-0a580af40269 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan 17 17:40:54.730: INFO: Waiting for pod pod-projected-secrets-07d24791-1a7f-11e9-a4b6-0a580af40269 to disappear
Jan 17 17:40:54.736: INFO: Pod pod-projected-secrets-07d24791-1a7f-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:40:54.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-62w2f" for this suite.
Jan 17 17:41:00.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:41:00.851: INFO: namespace: e2e-tests-projected-62w2f, resource: bindings, ignored listing per whitelist
Jan 17 17:41:00.856: INFO: namespace e2e-tests-projected-62w2f deletion completed in 6.115949897s

• [SLOW TEST:10.364 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:41:00.860: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-0dfce245-1a7f-11e9-a4b6-0a580af40269
STEP: Creating a pod to test consume secrets
Jan 17 17:41:00.952: INFO: Waiting up to 5m0s for pod "pod-secrets-0dfe29da-1a7f-11e9-a4b6-0a580af40269" in namespace "e2e-tests-secrets-hj5ss" to be "success or failure"
Jan 17 17:41:00.963: INFO: Pod "pod-secrets-0dfe29da-1a7f-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 10.056096ms
Jan 17 17:41:03.006: INFO: Pod "pod-secrets-0dfe29da-1a7f-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.053197929s
Jan 17 17:41:05.010: INFO: Pod "pod-secrets-0dfe29da-1a7f-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.056582662s
STEP: Saw pod success
Jan 17 17:41:05.010: INFO: Pod "pod-secrets-0dfe29da-1a7f-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 17:41:05.050: INFO: Trying to get logs from node node1 pod pod-secrets-0dfe29da-1a7f-11e9-a4b6-0a580af40269 container secret-volume-test: <nil>
STEP: delete the pod
Jan 17 17:41:05.076: INFO: Waiting for pod pod-secrets-0dfe29da-1a7f-11e9-a4b6-0a580af40269 to disappear
Jan 17 17:41:05.085: INFO: Pod pod-secrets-0dfe29da-1a7f-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:41:05.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-hj5ss" for this suite.
Jan 17 17:41:11.106: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:41:11.144: INFO: namespace: e2e-tests-secrets-hj5ss, resource: bindings, ignored listing per whitelist
Jan 17 17:41:11.208: INFO: namespace e2e-tests-secrets-hj5ss deletion completed in 6.119284564s

• [SLOW TEST:10.348 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:41:11.208: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:41:11.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-c99rw" for this suite.
Jan 17 17:41:33.429: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:41:33.483: INFO: namespace: e2e-tests-kubelet-test-c99rw, resource: bindings, ignored listing per whitelist
Jan 17 17:41:33.510: INFO: namespace e2e-tests-kubelet-test-c99rw deletion completed in 22.106699465s

• [SLOW TEST:22.301 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:41:33.516: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-217e6736-1a7f-11e9-a4b6-0a580af40269
STEP: Creating a pod to test consume secrets
Jan 17 17:41:33.681: INFO: Waiting up to 5m0s for pod "pod-secrets-217f53da-1a7f-11e9-a4b6-0a580af40269" in namespace "e2e-tests-secrets-xgtlw" to be "success or failure"
Jan 17 17:41:33.689: INFO: Pod "pod-secrets-217f53da-1a7f-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 8.389331ms
Jan 17 17:41:35.693: INFO: Pod "pod-secrets-217f53da-1a7f-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012166424s
Jan 17 17:41:37.734: INFO: Pod "pod-secrets-217f53da-1a7f-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053149354s
STEP: Saw pod success
Jan 17 17:41:37.734: INFO: Pod "pod-secrets-217f53da-1a7f-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 17:41:37.737: INFO: Trying to get logs from node node1 pod pod-secrets-217f53da-1a7f-11e9-a4b6-0a580af40269 container secret-volume-test: <nil>
STEP: delete the pod
Jan 17 17:41:37.794: INFO: Waiting for pod pod-secrets-217f53da-1a7f-11e9-a4b6-0a580af40269 to disappear
Jan 17 17:41:37.802: INFO: Pod pod-secrets-217f53da-1a7f-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:41:37.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-xgtlw" for this suite.
Jan 17 17:41:43.828: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:41:43.897: INFO: namespace: e2e-tests-secrets-xgtlw, resource: bindings, ignored listing per whitelist
Jan 17 17:41:43.935: INFO: namespace e2e-tests-secrets-xgtlw deletion completed in 6.127956281s

• [SLOW TEST:10.420 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:41:43.941: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 17 17:41:44.039: INFO: Waiting up to 5m0s for pod "downwardapi-volume-27abc6fc-1a7f-11e9-a4b6-0a580af40269" in namespace "e2e-tests-projected-trksv" to be "success or failure"
Jan 17 17:41:44.044: INFO: Pod "downwardapi-volume-27abc6fc-1a7f-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 4.616506ms
Jan 17 17:41:46.086: INFO: Pod "downwardapi-volume-27abc6fc-1a7f-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.047293374s
Jan 17 17:41:48.090: INFO: Pod "downwardapi-volume-27abc6fc-1a7f-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051104268s
STEP: Saw pod success
Jan 17 17:41:48.090: INFO: Pod "downwardapi-volume-27abc6fc-1a7f-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 17:41:48.130: INFO: Trying to get logs from node node1 pod downwardapi-volume-27abc6fc-1a7f-11e9-a4b6-0a580af40269 container client-container: <nil>
STEP: delete the pod
Jan 17 17:41:48.158: INFO: Waiting for pod downwardapi-volume-27abc6fc-1a7f-11e9-a4b6-0a580af40269 to disappear
Jan 17 17:41:48.167: INFO: Pod downwardapi-volume-27abc6fc-1a7f-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:41:48.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-trksv" for this suite.
Jan 17 17:41:54.186: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:41:54.234: INFO: namespace: e2e-tests-projected-trksv, resource: bindings, ignored listing per whitelist
Jan 17 17:41:54.252: INFO: namespace e2e-tests-projected-trksv deletion completed in 6.079972731s

• [SLOW TEST:10.311 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:41:54.258: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-2dfd1baf-1a7f-11e9-a4b6-0a580af40269
STEP: Creating a pod to test consume configMaps
Jan 17 17:41:54.659: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2e00a787-1a7f-11e9-a4b6-0a580af40269" in namespace "e2e-tests-projected-qcc4z" to be "success or failure"
Jan 17 17:41:54.679: INFO: Pod "pod-projected-configmaps-2e00a787-1a7f-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 20.754065ms
Jan 17 17:41:56.726: INFO: Pod "pod-projected-configmaps-2e00a787-1a7f-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.067673021s
Jan 17 17:41:58.735: INFO: Pod "pod-projected-configmaps-2e00a787-1a7f-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.076647558s
STEP: Saw pod success
Jan 17 17:41:58.736: INFO: Pod "pod-projected-configmaps-2e00a787-1a7f-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 17:41:58.782: INFO: Trying to get logs from node node1 pod pod-projected-configmaps-2e00a787-1a7f-11e9-a4b6-0a580af40269 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 17 17:41:58.805: INFO: Waiting for pod pod-projected-configmaps-2e00a787-1a7f-11e9-a4b6-0a580af40269 to disappear
Jan 17 17:41:58.815: INFO: Pod pod-projected-configmaps-2e00a787-1a7f-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:41:58.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qcc4z" for this suite.
Jan 17 17:42:04.832: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:42:04.864: INFO: namespace: e2e-tests-projected-qcc4z, resource: bindings, ignored listing per whitelist
Jan 17 17:42:04.892: INFO: namespace e2e-tests-projected-qcc4z deletion completed in 6.073771076s

• [SLOW TEST:10.637 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:42:04.893: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Jan 17 17:42:05.061: INFO: Waiting up to 5m0s for pod "pod-343356da-1a7f-11e9-a4b6-0a580af40269" in namespace "e2e-tests-emptydir-7svwg" to be "success or failure"
Jan 17 17:42:05.070: INFO: Pod "pod-343356da-1a7f-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 9.268484ms
Jan 17 17:42:07.078: INFO: Pod "pod-343356da-1a7f-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017499531s
Jan 17 17:42:09.086: INFO: Pod "pod-343356da-1a7f-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025366891s
STEP: Saw pod success
Jan 17 17:42:09.086: INFO: Pod "pod-343356da-1a7f-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 17:42:09.126: INFO: Trying to get logs from node node1 pod pod-343356da-1a7f-11e9-a4b6-0a580af40269 container test-container: <nil>
STEP: delete the pod
Jan 17 17:42:09.153: INFO: Waiting for pod pod-343356da-1a7f-11e9-a4b6-0a580af40269 to disappear
Jan 17 17:42:09.163: INFO: Pod pod-343356da-1a7f-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:42:09.163: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-7svwg" for this suite.
Jan 17 17:42:15.220: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:42:15.251: INFO: namespace: e2e-tests-emptydir-7svwg, resource: bindings, ignored listing per whitelist
Jan 17 17:42:15.291: INFO: namespace e2e-tests-emptydir-7svwg deletion completed in 6.092683258s

• [SLOW TEST:10.398 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:42:15.292: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Jan 17 17:42:15.443: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jan 17 17:42:15.463: INFO: Waiting for terminating namespaces to be deleted...
Jan 17 17:42:15.468: INFO: 
Logging pods the kubelet thinks is on node node1 before test
Jan 17 17:42:15.474: INFO: kube-proxy-7z4x2 from kube-system started at 2019-01-17 06:49:56 +0000 UTC (1 container statuses recorded)
Jan 17 17:42:15.474: INFO: 	Container kube-proxy ready: true, restart count 1
Jan 17 17:42:15.474: INFO: sonobuoy from heptio-sonobuoy started at 2019-01-17 17:15:08 +0000 UTC (1 container statuses recorded)
Jan 17 17:42:15.474: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jan 17 17:42:15.474: INFO: kube-flannel-ds-amd64-8fwk6 from kube-system started at 2019-01-17 06:49:56 +0000 UTC (1 container statuses recorded)
Jan 17 17:42:15.474: INFO: 	Container kube-flannel ready: true, restart count 1
Jan 17 17:42:15.474: INFO: sonobuoy-systemd-logs-daemon-set-0dcc53c5f8e1419f-kq5jj from heptio-sonobuoy started at 2019-01-17 17:15:12 +0000 UTC (2 container statuses recorded)
Jan 17 17:42:15.474: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan 17 17:42:15.474: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 17 17:42:15.474: INFO: 
Logging pods the kubelet thinks is on node node2 before test
Jan 17 17:42:15.483: INFO: kube-flannel-ds-amd64-pcptp from kube-system started at 2019-01-17 06:52:49 +0000 UTC (1 container statuses recorded)
Jan 17 17:42:15.483: INFO: 	Container kube-flannel ready: true, restart count 1
Jan 17 17:42:15.483: INFO: kube-proxy-qmrgn from kube-system started at 2019-01-17 06:52:49 +0000 UTC (1 container statuses recorded)
Jan 17 17:42:15.483: INFO: 	Container kube-proxy ready: true, restart count 1
Jan 17 17:42:15.483: INFO: sonobuoy-e2e-job-5a5cc172c34e4413 from heptio-sonobuoy started at 2019-01-17 17:15:12 +0000 UTC (2 container statuses recorded)
Jan 17 17:42:15.483: INFO: 	Container e2e ready: true, restart count 0
Jan 17 17:42:15.483: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 17 17:42:15.483: INFO: sonobuoy-systemd-logs-daemon-set-0dcc53c5f8e1419f-q5jtj from heptio-sonobuoy started at 2019-01-17 17:15:12 +0000 UTC (2 container statuses recorded)
Jan 17 17:42:15.483: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan 17 17:42:15.483: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-3cdb9a7e-1a7f-11e9-a4b6-0a580af40269 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-3cdb9a7e-1a7f-11e9-a4b6-0a580af40269 off the node node1
STEP: verifying the node doesn't have the label kubernetes.io/e2e-3cdb9a7e-1a7f-11e9-a4b6-0a580af40269
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:42:23.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-lzznz" for this suite.
Jan 17 17:42:41.702: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:42:41.765: INFO: namespace: e2e-tests-sched-pred-lzznz, resource: bindings, ignored listing per whitelist
Jan 17 17:42:41.798: INFO: namespace e2e-tests-sched-pred-lzznz deletion completed in 18.114484705s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:26.507 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:42:41.799: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-28dz9
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Jan 17 17:42:41.974: INFO: Found 0 stateful pods, waiting for 3
Jan 17 17:42:51.980: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 17 17:42:51.980: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 17 17:42:51.980: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Jan 17 17:42:52.032: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Jan 17 17:43:02.088: INFO: Updating stateful set ss2
Jan 17 17:43:02.110: INFO: Waiting for Pod e2e-tests-statefulset-28dz9/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Jan 17 17:43:12.282: INFO: Found 2 stateful pods, waiting for 3
Jan 17 17:43:22.286: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 17 17:43:22.287: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 17 17:43:22.287: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Jan 17 17:43:22.322: INFO: Updating stateful set ss2
Jan 17 17:43:22.335: INFO: Waiting for Pod e2e-tests-statefulset-28dz9/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Jan 17 17:43:32.359: INFO: Updating stateful set ss2
Jan 17 17:43:32.404: INFO: Waiting for StatefulSet e2e-tests-statefulset-28dz9/ss2 to complete update
Jan 17 17:43:32.404: INFO: Waiting for Pod e2e-tests-statefulset-28dz9/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan 17 17:43:42.422: INFO: Deleting all statefulset in ns e2e-tests-statefulset-28dz9
Jan 17 17:43:42.425: INFO: Scaling statefulset ss2 to 0
Jan 17 17:44:02.441: INFO: Waiting for statefulset status.replicas updated to 0
Jan 17 17:44:02.444: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:44:02.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-28dz9" for this suite.
Jan 17 17:44:08.526: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:44:08.572: INFO: namespace: e2e-tests-statefulset-28dz9, resource: bindings, ignored listing per whitelist
Jan 17 17:44:08.612: INFO: namespace e2e-tests-statefulset-28dz9 deletion completed in 6.120111886s

• [SLOW TEST:86.814 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:44:08.615: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 17 17:44:08.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-q5khx'
Jan 17 17:44:08.784: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jan 17 17:44:08.784: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Jan 17 17:44:08.801: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-ftj8l]
Jan 17 17:44:08.801: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-ftj8l" in namespace "e2e-tests-kubectl-q5khx" to be "running and ready"
Jan 17 17:44:08.831: INFO: Pod "e2e-test-nginx-rc-ftj8l": Phase="Pending", Reason="", readiness=false. Elapsed: 29.485705ms
Jan 17 17:44:10.839: INFO: Pod "e2e-test-nginx-rc-ftj8l": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037564471s
Jan 17 17:44:12.842: INFO: Pod "e2e-test-nginx-rc-ftj8l": Phase="Running", Reason="", readiness=true. Elapsed: 4.040678664s
Jan 17 17:44:12.842: INFO: Pod "e2e-test-nginx-rc-ftj8l" satisfied condition "running and ready"
Jan 17 17:44:12.842: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-ftj8l]
Jan 17 17:44:12.842: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-q5khx'
Jan 17 17:44:12.956: INFO: stderr: ""
Jan 17 17:44:12.956: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1303
Jan 17 17:44:12.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-q5khx'
Jan 17 17:44:13.059: INFO: stderr: ""
Jan 17 17:44:13.059: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:44:13.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-q5khx" for this suite.
Jan 17 17:44:35.077: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:44:35.171: INFO: namespace: e2e-tests-kubectl-q5khx, resource: bindings, ignored listing per whitelist
Jan 17 17:44:35.192: INFO: namespace e2e-tests-kubectl-q5khx deletion completed in 22.128820319s

• [SLOW TEST:26.577 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:44:35.193: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Jan 17 17:44:35.281: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Jan 17 17:44:35.281: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 create -f - --namespace=e2e-tests-kubectl-ffcbm'
Jan 17 17:44:36.079: INFO: stderr: ""
Jan 17 17:44:36.079: INFO: stdout: "service/redis-slave created\n"
Jan 17 17:44:36.079: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Jan 17 17:44:36.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 create -f - --namespace=e2e-tests-kubectl-ffcbm'
Jan 17 17:44:36.240: INFO: stderr: ""
Jan 17 17:44:36.240: INFO: stdout: "service/redis-master created\n"
Jan 17 17:44:36.240: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Jan 17 17:44:36.240: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 create -f - --namespace=e2e-tests-kubectl-ffcbm'
Jan 17 17:44:36.413: INFO: stderr: ""
Jan 17 17:44:36.413: INFO: stdout: "service/frontend created\n"
Jan 17 17:44:36.417: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Jan 17 17:44:36.418: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 create -f - --namespace=e2e-tests-kubectl-ffcbm'
Jan 17 17:44:36.579: INFO: stderr: ""
Jan 17 17:44:36.579: INFO: stdout: "deployment.extensions/frontend created\n"
Jan 17 17:44:36.579: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Jan 17 17:44:36.579: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 create -f - --namespace=e2e-tests-kubectl-ffcbm'
Jan 17 17:44:36.845: INFO: stderr: ""
Jan 17 17:44:36.845: INFO: stdout: "deployment.extensions/redis-master created\n"
Jan 17 17:44:36.848: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Jan 17 17:44:36.849: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 create -f - --namespace=e2e-tests-kubectl-ffcbm'
Jan 17 17:44:37.158: INFO: stderr: ""
Jan 17 17:44:37.158: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Jan 17 17:44:37.158: INFO: Waiting for all frontend pods to be Running.
Jan 17 17:44:42.209: INFO: Waiting for frontend to serve content.
Jan 17 17:44:42.231: INFO: Trying to add a new entry to the guestbook.
Jan 17 17:44:42.245: INFO: Verifying that added entry can be retrieved.
Jan 17 17:44:42.261: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Jan 17 17:44:47.298: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Jan 17 17:44:52.333: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Jan 17 17:44:57.345: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Jan 17 17:45:02.393: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Jan 17 17:45:07.411: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Jan 17 17:45:12.420: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Jan 17 17:45:17.432: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Jan 17 17:45:22.451: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Jan 17 17:45:27.462: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Jan 17 17:45:32.485: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Jan 17 17:45:37.508: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
STEP: using delete to clean up resources
Jan 17 17:45:42.550: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-ffcbm'
Jan 17 17:45:42.685: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 17 17:45:42.685: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Jan 17 17:45:42.685: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-ffcbm'
Jan 17 17:45:42.815: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 17 17:45:42.815: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Jan 17 17:45:42.817: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-ffcbm'
Jan 17 17:45:42.970: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 17 17:45:42.970: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Jan 17 17:45:42.970: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-ffcbm'
Jan 17 17:45:43.063: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 17 17:45:43.063: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Jan 17 17:45:43.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-ffcbm'
Jan 17 17:45:43.164: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 17 17:45:43.164: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Jan 17 17:45:43.164: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-ffcbm'
Jan 17 17:45:43.289: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 17 17:45:43.289: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:45:43.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ffcbm" for this suite.
Jan 17 17:46:29.400: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:46:29.494: INFO: namespace: e2e-tests-kubectl-ffcbm, resource: bindings, ignored listing per whitelist
Jan 17 17:46:29.503: INFO: namespace e2e-tests-kubectl-ffcbm deletion completed in 46.150935391s

• [SLOW TEST:114.310 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:46:29.504: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-d1eb86da-1a7f-11e9-a4b6-0a580af40269
STEP: Creating configMap with name cm-test-opt-upd-d1eb87a0-1a7f-11e9-a4b6-0a580af40269
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-d1eb86da-1a7f-11e9-a4b6-0a580af40269
STEP: Updating configmap cm-test-opt-upd-d1eb87a0-1a7f-11e9-a4b6-0a580af40269
STEP: Creating configMap with name cm-test-opt-create-d1eb87b0-1a7f-11e9-a4b6-0a580af40269
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:47:46.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-s4l4v" for this suite.
Jan 17 17:48:08.540: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:48:08.566: INFO: namespace: e2e-tests-projected-s4l4v, resource: bindings, ignored listing per whitelist
Jan 17 17:48:08.612: INFO: namespace e2e-tests-projected-s4l4v deletion completed in 22.093144759s

• [SLOW TEST:99.109 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:48:08.614: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jan 17 17:48:08.762: INFO: Waiting up to 5m0s for pod "pod-0cfc5f7d-1a80-11e9-a4b6-0a580af40269" in namespace "e2e-tests-emptydir-lxvgx" to be "success or failure"
Jan 17 17:48:08.783: INFO: Pod "pod-0cfc5f7d-1a80-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 20.379983ms
Jan 17 17:48:10.792: INFO: Pod "pod-0cfc5f7d-1a80-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029797158s
Jan 17 17:48:12.795: INFO: Pod "pod-0cfc5f7d-1a80-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032391873s
STEP: Saw pod success
Jan 17 17:48:12.795: INFO: Pod "pod-0cfc5f7d-1a80-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 17:48:12.797: INFO: Trying to get logs from node node1 pod pod-0cfc5f7d-1a80-11e9-a4b6-0a580af40269 container test-container: <nil>
STEP: delete the pod
Jan 17 17:48:12.818: INFO: Waiting for pod pod-0cfc5f7d-1a80-11e9-a4b6-0a580af40269 to disappear
Jan 17 17:48:12.829: INFO: Pod pod-0cfc5f7d-1a80-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:48:12.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-lxvgx" for this suite.
Jan 17 17:48:18.852: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:48:19.121: INFO: namespace: e2e-tests-emptydir-lxvgx, resource: bindings, ignored listing per whitelist
Jan 17 17:48:19.163: INFO: namespace e2e-tests-emptydir-lxvgx deletion completed in 6.328152939s

• [SLOW TEST:10.549 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:48:19.168: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jan 17 17:48:23.858: INFO: Successfully updated pod "pod-update-activedeadlineseconds-13483453-1a80-11e9-a4b6-0a580af40269"
Jan 17 17:48:23.858: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-13483453-1a80-11e9-a4b6-0a580af40269" in namespace "e2e-tests-pods-nqbqc" to be "terminated due to deadline exceeded"
Jan 17 17:48:23.869: INFO: Pod "pod-update-activedeadlineseconds-13483453-1a80-11e9-a4b6-0a580af40269": Phase="Running", Reason="", readiness=true. Elapsed: 10.042538ms
Jan 17 17:48:25.871: INFO: Pod "pod-update-activedeadlineseconds-13483453-1a80-11e9-a4b6-0a580af40269": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.012098483s
Jan 17 17:48:25.871: INFO: Pod "pod-update-activedeadlineseconds-13483453-1a80-11e9-a4b6-0a580af40269" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:48:25.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-nqbqc" for this suite.
Jan 17 17:48:31.894: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:48:31.917: INFO: namespace: e2e-tests-pods-nqbqc, resource: bindings, ignored listing per whitelist
Jan 17 17:48:31.960: INFO: namespace e2e-tests-pods-nqbqc deletion completed in 6.084654195s

• [SLOW TEST:12.792 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:48:31.963: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 17 17:48:32.119: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:48:36.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-q7hl5" for this suite.
Jan 17 17:49:20.230: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:49:20.290: INFO: namespace: e2e-tests-pods-q7hl5, resource: bindings, ignored listing per whitelist
Jan 17 17:49:20.305: INFO: namespace e2e-tests-pods-q7hl5 deletion completed in 44.113307586s

• [SLOW TEST:48.343 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:49:20.307: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Jan 17 17:49:20.390: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 cluster-info'
Jan 17 17:49:20.488: INFO: stderr: ""
Jan 17 17:49:20.488: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:49:20.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-w6gxm" for this suite.
Jan 17 17:49:26.519: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:49:26.596: INFO: namespace: e2e-tests-kubectl-w6gxm, resource: bindings, ignored listing per whitelist
Jan 17 17:49:26.623: INFO: namespace e2e-tests-kubectl-w6gxm deletion completed in 6.128538566s

• [SLOW TEST:6.317 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:49:26.625: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-3b780023-1a80-11e9-a4b6-0a580af40269
STEP: Creating a pod to test consume configMaps
Jan 17 17:49:26.765: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-3b7972ef-1a80-11e9-a4b6-0a580af40269" in namespace "e2e-tests-projected-x4p48" to be "success or failure"
Jan 17 17:49:26.781: INFO: Pod "pod-projected-configmaps-3b7972ef-1a80-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 16.796989ms
Jan 17 17:49:28.818: INFO: Pod "pod-projected-configmaps-3b7972ef-1a80-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.053502991s
Jan 17 17:49:30.830: INFO: Pod "pod-projected-configmaps-3b7972ef-1a80-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.064845262s
STEP: Saw pod success
Jan 17 17:49:30.830: INFO: Pod "pod-projected-configmaps-3b7972ef-1a80-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 17:49:30.866: INFO: Trying to get logs from node node1 pod pod-projected-configmaps-3b7972ef-1a80-11e9-a4b6-0a580af40269 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 17 17:49:30.889: INFO: Waiting for pod pod-projected-configmaps-3b7972ef-1a80-11e9-a4b6-0a580af40269 to disappear
Jan 17 17:49:30.908: INFO: Pod pod-projected-configmaps-3b7972ef-1a80-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:49:30.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-x4p48" for this suite.
Jan 17 17:49:36.942: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:49:37.015: INFO: namespace: e2e-tests-projected-x4p48, resource: bindings, ignored listing per whitelist
Jan 17 17:49:37.029: INFO: namespace e2e-tests-projected-x4p48 deletion completed in 6.107994746s

• [SLOW TEST:10.404 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:49:37.032: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-ks2kp
Jan 17 17:49:41.146: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-ks2kp
STEP: checking the pod's current state and verifying that restartCount is present
Jan 17 17:49:41.154: INFO: Initial restart count of pod liveness-exec is 0
Jan 17 17:50:29.260: INFO: Restart count of pod e2e-tests-container-probe-ks2kp/liveness-exec is now 1 (48.10592954s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:50:29.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-ks2kp" for this suite.
Jan 17 17:50:35.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:50:35.397: INFO: namespace: e2e-tests-container-probe-ks2kp, resource: bindings, ignored listing per whitelist
Jan 17 17:50:35.423: INFO: namespace e2e-tests-container-probe-ks2kp deletion completed in 6.072645602s

• [SLOW TEST:58.394 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:50:35.426: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-647e7fbf-1a80-11e9-a4b6-0a580af40269
STEP: Creating a pod to test consume configMaps
Jan 17 17:50:35.587: INFO: Waiting up to 5m0s for pod "pod-configmaps-647fd446-1a80-11e9-a4b6-0a580af40269" in namespace "e2e-tests-configmap-whglz" to be "success or failure"
Jan 17 17:50:35.597: INFO: Pod "pod-configmaps-647fd446-1a80-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 9.98445ms
Jan 17 17:50:37.635: INFO: Pod "pod-configmaps-647fd446-1a80-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.048263629s
Jan 17 17:50:39.644: INFO: Pod "pod-configmaps-647fd446-1a80-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.057098404s
STEP: Saw pod success
Jan 17 17:50:39.644: INFO: Pod "pod-configmaps-647fd446-1a80-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 17:50:39.690: INFO: Trying to get logs from node node1 pod pod-configmaps-647fd446-1a80-11e9-a4b6-0a580af40269 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 17 17:50:39.714: INFO: Waiting for pod pod-configmaps-647fd446-1a80-11e9-a4b6-0a580af40269 to disappear
Jan 17 17:50:39.722: INFO: Pod pod-configmaps-647fd446-1a80-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:50:39.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-whglz" for this suite.
Jan 17 17:50:45.757: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:50:45.814: INFO: namespace: e2e-tests-configmap-whglz, resource: bindings, ignored listing per whitelist
Jan 17 17:50:45.850: INFO: namespace e2e-tests-configmap-whglz deletion completed in 6.122025846s

• [SLOW TEST:10.425 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:50:45.851: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan 17 17:50:45.942: INFO: Waiting up to 5m0s for pod "downward-api-6aac1bc3-1a80-11e9-a4b6-0a580af40269" in namespace "e2e-tests-downward-api-g8fvr" to be "success or failure"
Jan 17 17:50:45.952: INFO: Pod "downward-api-6aac1bc3-1a80-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 10.400119ms
Jan 17 17:50:48.009: INFO: Pod "downward-api-6aac1bc3-1a80-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.067311739s
Jan 17 17:50:50.012: INFO: Pod "downward-api-6aac1bc3-1a80-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.070589192s
STEP: Saw pod success
Jan 17 17:50:50.012: INFO: Pod "downward-api-6aac1bc3-1a80-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 17:50:50.054: INFO: Trying to get logs from node node1 pod downward-api-6aac1bc3-1a80-11e9-a4b6-0a580af40269 container dapi-container: <nil>
STEP: delete the pod
Jan 17 17:50:50.075: INFO: Waiting for pod downward-api-6aac1bc3-1a80-11e9-a4b6-0a580af40269 to disappear
Jan 17 17:50:50.085: INFO: Pod downward-api-6aac1bc3-1a80-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:50:50.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-g8fvr" for this suite.
Jan 17 17:50:56.103: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:50:56.202: INFO: namespace: e2e-tests-downward-api-g8fvr, resource: bindings, ignored listing per whitelist
Jan 17 17:50:56.208: INFO: namespace e2e-tests-downward-api-g8fvr deletion completed in 6.118791875s

• [SLOW TEST:10.358 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:50:56.212: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-70d951e7-1a80-11e9-a4b6-0a580af40269
STEP: Creating a pod to test consume configMaps
Jan 17 17:50:56.321: INFO: Waiting up to 5m0s for pod "pod-configmaps-70db0f11-1a80-11e9-a4b6-0a580af40269" in namespace "e2e-tests-configmap-hw7x8" to be "success or failure"
Jan 17 17:50:56.331: INFO: Pod "pod-configmaps-70db0f11-1a80-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 10.24697ms
Jan 17 17:50:58.366: INFO: Pod "pod-configmaps-70db0f11-1a80-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.045233928s
Jan 17 17:51:00.369: INFO: Pod "pod-configmaps-70db0f11-1a80-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048441589s
STEP: Saw pod success
Jan 17 17:51:00.369: INFO: Pod "pod-configmaps-70db0f11-1a80-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 17:51:00.406: INFO: Trying to get logs from node node1 pod pod-configmaps-70db0f11-1a80-11e9-a4b6-0a580af40269 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 17 17:51:00.441: INFO: Waiting for pod pod-configmaps-70db0f11-1a80-11e9-a4b6-0a580af40269 to disappear
Jan 17 17:51:00.450: INFO: Pod pod-configmaps-70db0f11-1a80-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:51:00.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-hw7x8" for this suite.
Jan 17 17:51:06.481: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:51:06.543: INFO: namespace: e2e-tests-configmap-hw7x8, resource: bindings, ignored listing per whitelist
Jan 17 17:51:06.574: INFO: namespace e2e-tests-configmap-hw7x8 deletion completed in 6.115269176s

• [SLOW TEST:10.362 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:51:06.575: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-77144c27-1a80-11e9-a4b6-0a580af40269
STEP: Creating a pod to test consume configMaps
Jan 17 17:51:06.772: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-77161717-1a80-11e9-a4b6-0a580af40269" in namespace "e2e-tests-projected-684qk" to be "success or failure"
Jan 17 17:51:06.797: INFO: Pod "pod-projected-configmaps-77161717-1a80-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 24.548034ms
Jan 17 17:51:08.799: INFO: Pod "pod-projected-configmaps-77161717-1a80-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.026805614s
STEP: Saw pod success
Jan 17 17:51:08.799: INFO: Pod "pod-projected-configmaps-77161717-1a80-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 17:51:08.834: INFO: Trying to get logs from node node1 pod pod-projected-configmaps-77161717-1a80-11e9-a4b6-0a580af40269 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 17 17:51:08.856: INFO: Waiting for pod pod-projected-configmaps-77161717-1a80-11e9-a4b6-0a580af40269 to disappear
Jan 17 17:51:08.868: INFO: Pod pod-projected-configmaps-77161717-1a80-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:51:08.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-684qk" for this suite.
Jan 17 17:51:14.930: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:51:15.016: INFO: namespace: e2e-tests-projected-684qk, resource: bindings, ignored listing per whitelist
Jan 17 17:51:15.024: INFO: namespace e2e-tests-projected-684qk deletion completed in 6.109648473s

• [SLOW TEST:8.449 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:51:15.026: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-7c0f8c0b-1a80-11e9-a4b6-0a580af40269
STEP: Creating a pod to test consume configMaps
Jan 17 17:51:15.129: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7c10c359-1a80-11e9-a4b6-0a580af40269" in namespace "e2e-tests-projected-cw5tm" to be "success or failure"
Jan 17 17:51:15.140: INFO: Pod "pod-projected-configmaps-7c10c359-1a80-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 10.885112ms
Jan 17 17:51:17.179: INFO: Pod "pod-projected-configmaps-7c10c359-1a80-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.049795911s
Jan 17 17:51:19.182: INFO: Pod "pod-projected-configmaps-7c10c359-1a80-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052412735s
STEP: Saw pod success
Jan 17 17:51:19.182: INFO: Pod "pod-projected-configmaps-7c10c359-1a80-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 17:51:19.218: INFO: Trying to get logs from node node1 pod pod-projected-configmaps-7c10c359-1a80-11e9-a4b6-0a580af40269 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 17 17:51:19.241: INFO: Waiting for pod pod-projected-configmaps-7c10c359-1a80-11e9-a4b6-0a580af40269 to disappear
Jan 17 17:51:19.252: INFO: Pod pod-projected-configmaps-7c10c359-1a80-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:51:19.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-cw5tm" for this suite.
Jan 17 17:51:25.284: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:51:25.361: INFO: namespace: e2e-tests-projected-cw5tm, resource: bindings, ignored listing per whitelist
Jan 17 17:51:25.364: INFO: namespace e2e-tests-projected-cw5tm deletion completed in 6.100371656s

• [SLOW TEST:10.338 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:51:25.365: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-4fqrn
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Jan 17 17:51:25.486: INFO: Found 0 stateful pods, waiting for 3
Jan 17 17:51:35.513: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 17 17:51:35.514: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 17 17:51:35.514: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Jan 17 17:51:45.496: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 17 17:51:45.496: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 17 17:51:45.497: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Jan 17 17:51:45.541: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 exec --namespace=e2e-tests-statefulset-4fqrn ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 17 17:51:45.686: INFO: stderr: ""
Jan 17 17:51:45.686: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 17 17:51:45.686: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Jan 17 17:51:55.729: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Jan 17 17:52:05.765: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 exec --namespace=e2e-tests-statefulset-4fqrn ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 17 17:52:05.920: INFO: stderr: ""
Jan 17 17:52:05.920: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 17 17:52:05.920: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 17 17:52:15.951: INFO: Waiting for StatefulSet e2e-tests-statefulset-4fqrn/ss2 to complete update
Jan 17 17:52:15.951: INFO: Waiting for Pod e2e-tests-statefulset-4fqrn/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Jan 17 17:52:25.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 exec --namespace=e2e-tests-statefulset-4fqrn ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 17 17:52:26.106: INFO: stderr: ""
Jan 17 17:52:26.106: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 17 17:52:26.106: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 17 17:52:36.152: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Jan 17 17:52:46.243: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 exec --namespace=e2e-tests-statefulset-4fqrn ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 17 17:52:46.415: INFO: stderr: ""
Jan 17 17:52:46.416: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 17 17:52:46.416: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 17 17:52:56.533: INFO: Waiting for StatefulSet e2e-tests-statefulset-4fqrn/ss2 to complete update
Jan 17 17:52:56.533: INFO: Waiting for Pod e2e-tests-statefulset-4fqrn/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Jan 17 17:52:56.533: INFO: Waiting for Pod e2e-tests-statefulset-4fqrn/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Jan 17 17:52:56.533: INFO: Waiting for Pod e2e-tests-statefulset-4fqrn/ss2-2 to have revision ss2-787997d666 update revision ss2-c79899b9
Jan 17 17:53:06.560: INFO: Waiting for StatefulSet e2e-tests-statefulset-4fqrn/ss2 to complete update
Jan 17 17:53:06.561: INFO: Waiting for Pod e2e-tests-statefulset-4fqrn/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Jan 17 17:53:06.561: INFO: Waiting for Pod e2e-tests-statefulset-4fqrn/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Jan 17 17:53:16.550: INFO: Waiting for StatefulSet e2e-tests-statefulset-4fqrn/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan 17 17:53:26.538: INFO: Deleting all statefulset in ns e2e-tests-statefulset-4fqrn
Jan 17 17:53:26.541: INFO: Scaling statefulset ss2 to 0
Jan 17 17:53:56.567: INFO: Waiting for statefulset status.replicas updated to 0
Jan 17 17:53:56.575: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:53:56.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-4fqrn" for this suite.
Jan 17 17:54:02.675: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:54:02.740: INFO: namespace: e2e-tests-statefulset-4fqrn, resource: bindings, ignored listing per whitelist
Jan 17 17:54:02.776: INFO: namespace e2e-tests-statefulset-4fqrn deletion completed in 6.120637258s

• [SLOW TEST:157.411 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:54:02.778: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 17 17:54:02.860: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e00b526a-1a80-11e9-a4b6-0a580af40269" in namespace "e2e-tests-downward-api-x44td" to be "success or failure"
Jan 17 17:54:02.870: INFO: Pod "downwardapi-volume-e00b526a-1a80-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 9.078039ms
Jan 17 17:54:04.872: INFO: Pod "downwardapi-volume-e00b526a-1a80-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011423972s
Jan 17 17:54:06.910: INFO: Pod "downwardapi-volume-e00b526a-1a80-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.049751041s
STEP: Saw pod success
Jan 17 17:54:06.910: INFO: Pod "downwardapi-volume-e00b526a-1a80-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 17:54:06.914: INFO: Trying to get logs from node node1 pod downwardapi-volume-e00b526a-1a80-11e9-a4b6-0a580af40269 container client-container: <nil>
STEP: delete the pod
Jan 17 17:54:06.962: INFO: Waiting for pod downwardapi-volume-e00b526a-1a80-11e9-a4b6-0a580af40269 to disappear
Jan 17 17:54:06.965: INFO: Pod downwardapi-volume-e00b526a-1a80-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:54:06.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-x44td" for this suite.
Jan 17 17:54:12.991: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:54:13.074: INFO: namespace: e2e-tests-downward-api-x44td, resource: bindings, ignored listing per whitelist
Jan 17 17:54:13.085: INFO: namespace e2e-tests-downward-api-x44td deletion completed in 6.114887091s

• [SLOW TEST:10.307 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:54:13.085: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-e630f4da-1a80-11e9-a4b6-0a580af40269
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-e630f4da-1a80-11e9-a4b6-0a580af40269
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:55:39.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-27bdk" for this suite.
Jan 17 17:55:58.044: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:55:58.127: INFO: namespace: e2e-tests-projected-27bdk, resource: bindings, ignored listing per whitelist
Jan 17 17:55:58.140: INFO: namespace e2e-tests-projected-27bdk deletion completed in 18.112773242s

• [SLOW TEST:105.055 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:55:58.144: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0117 17:56:38.351177      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 17 17:56:38.351: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:56:38.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-q5t55" for this suite.
Jan 17 17:56:44.396: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:56:44.487: INFO: namespace: e2e-tests-gc-q5t55, resource: bindings, ignored listing per whitelist
Jan 17 17:56:44.530: INFO: namespace e2e-tests-gc-q5t55 deletion completed in 6.154396148s

• [SLOW TEST:46.386 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:56:44.531: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:56:44.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-b6ckz" for this suite.
Jan 17 17:56:50.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:56:50.802: INFO: namespace: e2e-tests-services-b6ckz, resource: bindings, ignored listing per whitelist
Jan 17 17:56:50.829: INFO: namespace e2e-tests-services-b6ckz deletion completed in 6.080232661s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:6.299 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:56:50.836: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-572q5 in namespace e2e-tests-proxy-psbcf
I0117 17:56:50.955162      17 runners.go:184] Created replication controller with name: proxy-service-572q5, namespace: e2e-tests-proxy-psbcf, replica count: 1
I0117 17:56:52.005716      17 runners.go:184] proxy-service-572q5 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0117 17:56:53.006303      17 runners.go:184] proxy-service-572q5 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0117 17:56:54.006675      17 runners.go:184] proxy-service-572q5 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jan 17 17:56:54.011: INFO: setup took 3.09363769s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Jan 17 17:56:54.024: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:162/proxy/: bar (200; 11.809783ms)
Jan 17 17:56:54.026: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:1080/proxy/... (200; 15.153435ms)
Jan 17 17:56:54.027: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/proxy-service-572q5:portname2/proxy/: bar (200; 15.010849ms)
Jan 17 17:56:54.027: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:162/proxy/: bar (200; 14.938975ms)
Jan 17 17:56:54.029: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:1080/proxy/rewri... (200; 17.215717ms)
Jan 17 17:56:54.030: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46/proxy/rewriteme"... (200; 18.666298ms)
Jan 17 17:56:54.036: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/http:proxy-service-572q5:portname2/proxy/: bar (200; 24.294615ms)
Jan 17 17:56:54.036: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/http:proxy-service-572q5:portname1/proxy/: foo (200; 24.168564ms)
Jan 17 17:56:54.038: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:160/proxy/: foo (200; 26.494734ms)
Jan 17 17:56:54.039: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/proxy-service-572q5:portname1/proxy/: foo (200; 27.617983ms)
Jan 17 17:56:54.040: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:160/proxy/: foo (200; 28.490885ms)
Jan 17 17:56:54.041: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:460/proxy/: tls baz (200; 29.765041ms)
Jan 17 17:56:54.046: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/https:proxy-service-572q5:tlsportname2/proxy/: tls qux (200; 34.089595ms)
Jan 17 17:56:54.047: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/https:proxy-service-572q5:tlsportname1/proxy/: tls baz (200; 35.396941ms)
Jan 17 17:56:54.047: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:462/proxy/: tls qux (200; 35.20003ms)
Jan 17 17:56:54.049: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:443/proxy/... (200; 37.33969ms)
Jan 17 17:56:54.061: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:160/proxy/: foo (200; 11.515587ms)
Jan 17 17:56:54.061: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:462/proxy/: tls qux (200; 11.520323ms)
Jan 17 17:56:54.062: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/https:proxy-service-572q5:tlsportname2/proxy/: tls qux (200; 12.738249ms)
Jan 17 17:56:54.062: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:1080/proxy/... (200; 12.523317ms)
Jan 17 17:56:54.062: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:1080/proxy/rewri... (200; 12.06638ms)
Jan 17 17:56:54.062: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:160/proxy/: foo (200; 12.36865ms)
Jan 17 17:56:54.062: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/https:proxy-service-572q5:tlsportname1/proxy/: tls baz (200; 11.857794ms)
Jan 17 17:56:54.062: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:162/proxy/: bar (200; 12.465611ms)
Jan 17 17:56:54.063: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/http:proxy-service-572q5:portname1/proxy/: foo (200; 12.579424ms)
Jan 17 17:56:54.063: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:460/proxy/: tls baz (200; 13.05344ms)
Jan 17 17:56:54.063: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46/proxy/rewriteme"... (200; 13.676704ms)
Jan 17 17:56:54.063: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/http:proxy-service-572q5:portname2/proxy/: bar (200; 13.832451ms)
Jan 17 17:56:54.063: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:443/proxy/... (200; 14.212141ms)
Jan 17 17:56:54.063: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/proxy-service-572q5:portname1/proxy/: foo (200; 13.949627ms)
Jan 17 17:56:54.063: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:162/proxy/: bar (200; 13.44325ms)
Jan 17 17:56:54.063: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/proxy-service-572q5:portname2/proxy/: bar (200; 13.989114ms)
Jan 17 17:56:54.073: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:160/proxy/: foo (200; 8.807006ms)
Jan 17 17:56:54.073: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/http:proxy-service-572q5:portname2/proxy/: bar (200; 8.924799ms)
Jan 17 17:56:54.073: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:160/proxy/: foo (200; 9.476943ms)
Jan 17 17:56:54.073: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:443/proxy/... (200; 8.952908ms)
Jan 17 17:56:54.073: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46/proxy/rewriteme"... (200; 9.108855ms)
Jan 17 17:56:54.073: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:460/proxy/: tls baz (200; 9.580322ms)
Jan 17 17:56:54.073: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:162/proxy/: bar (200; 9.719775ms)
Jan 17 17:56:54.073: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:1080/proxy/rewri... (200; 9.567636ms)
Jan 17 17:56:54.073: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:1080/proxy/... (200; 9.382558ms)
Jan 17 17:56:54.074: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:462/proxy/: tls qux (200; 9.593505ms)
Jan 17 17:56:54.074: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/http:proxy-service-572q5:portname1/proxy/: foo (200; 9.913173ms)
Jan 17 17:56:54.074: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/https:proxy-service-572q5:tlsportname2/proxy/: tls qux (200; 9.901897ms)
Jan 17 17:56:54.074: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:162/proxy/: bar (200; 9.834502ms)
Jan 17 17:56:54.074: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/proxy-service-572q5:portname1/proxy/: foo (200; 9.731156ms)
Jan 17 17:56:54.074: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/https:proxy-service-572q5:tlsportname1/proxy/: tls baz (200; 10.270048ms)
Jan 17 17:56:54.074: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/proxy-service-572q5:portname2/proxy/: bar (200; 10.875979ms)
Jan 17 17:56:54.084: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:460/proxy/: tls baz (200; 9.166787ms)
Jan 17 17:56:54.084: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:160/proxy/: foo (200; 9.389834ms)
Jan 17 17:56:54.084: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:160/proxy/: foo (200; 9.226308ms)
Jan 17 17:56:54.086: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46/proxy/rewriteme"... (200; 11.047191ms)
Jan 17 17:56:54.086: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:1080/proxy/rewri... (200; 11.238904ms)
Jan 17 17:56:54.086: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:162/proxy/: bar (200; 11.834144ms)
Jan 17 17:56:54.089: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/https:proxy-service-572q5:tlsportname1/proxy/: tls baz (200; 14.173652ms)
Jan 17 17:56:54.089: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:1080/proxy/... (200; 14.459443ms)
Jan 17 17:56:54.089: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:462/proxy/: tls qux (200; 14.612448ms)
Jan 17 17:56:54.089: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/proxy-service-572q5:portname1/proxy/: foo (200; 14.621722ms)
Jan 17 17:56:54.089: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:162/proxy/: bar (200; 14.633566ms)
Jan 17 17:56:54.090: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/http:proxy-service-572q5:portname1/proxy/: foo (200; 14.674167ms)
Jan 17 17:56:54.090: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/https:proxy-service-572q5:tlsportname2/proxy/: tls qux (200; 14.841893ms)
Jan 17 17:56:54.090: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/http:proxy-service-572q5:portname2/proxy/: bar (200; 15.571672ms)
Jan 17 17:56:54.090: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:443/proxy/... (200; 15.559738ms)
Jan 17 17:56:54.090: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/proxy-service-572q5:portname2/proxy/: bar (200; 15.59738ms)
Jan 17 17:56:54.097: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:162/proxy/: bar (200; 5.584939ms)
Jan 17 17:56:54.100: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:1080/proxy/rewri... (200; 8.834954ms)
Jan 17 17:56:54.100: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:443/proxy/... (200; 4.551502ms)
Jan 17 17:56:54.100: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:160/proxy/: foo (200; 8.397566ms)
Jan 17 17:56:54.100: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:160/proxy/: foo (200; 8.133801ms)
Jan 17 17:56:54.100: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:462/proxy/: tls qux (200; 9.666672ms)
Jan 17 17:56:54.101: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:1080/proxy/... (200; 8.417168ms)
Jan 17 17:56:54.101: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46/proxy/rewriteme"... (200; 8.620548ms)
Jan 17 17:56:54.107: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:460/proxy/: tls baz (200; 16.469107ms)
Jan 17 17:56:54.108: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/http:proxy-service-572q5:portname1/proxy/: foo (200; 16.665285ms)
Jan 17 17:56:54.108: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/https:proxy-service-572q5:tlsportname1/proxy/: tls baz (200; 16.661804ms)
Jan 17 17:56:54.108: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/https:proxy-service-572q5:tlsportname2/proxy/: tls qux (200; 16.579811ms)
Jan 17 17:56:54.108: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/proxy-service-572q5:portname1/proxy/: foo (200; 16.108479ms)
Jan 17 17:56:54.109: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/proxy-service-572q5:portname2/proxy/: bar (200; 17.709147ms)
Jan 17 17:56:54.110: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/http:proxy-service-572q5:portname2/proxy/: bar (200; 17.689644ms)
Jan 17 17:56:54.110: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:162/proxy/: bar (200; 19.042938ms)
Jan 17 17:56:54.116: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:1080/proxy/... (200; 5.137562ms)
Jan 17 17:56:54.116: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:162/proxy/: bar (200; 6.510235ms)
Jan 17 17:56:54.117: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:460/proxy/: tls baz (200; 6.605553ms)
Jan 17 17:56:54.118: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:1080/proxy/rewri... (200; 7.642344ms)
Jan 17 17:56:54.118: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:162/proxy/: bar (200; 7.673619ms)
Jan 17 17:56:54.119: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:462/proxy/: tls qux (200; 8.138144ms)
Jan 17 17:56:54.119: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46/proxy/rewriteme"... (200; 8.090128ms)
Jan 17 17:56:54.119: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:443/proxy/... (200; 8.29093ms)
Jan 17 17:56:54.119: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:160/proxy/: foo (200; 9.416755ms)
Jan 17 17:56:54.119: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:160/proxy/: foo (200; 8.955334ms)
Jan 17 17:56:54.121: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/proxy-service-572q5:portname1/proxy/: foo (200; 9.752984ms)
Jan 17 17:56:54.121: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/https:proxy-service-572q5:tlsportname1/proxy/: tls baz (200; 10.770675ms)
Jan 17 17:56:54.121: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/http:proxy-service-572q5:portname2/proxy/: bar (200; 10.584947ms)
Jan 17 17:56:54.121: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/https:proxy-service-572q5:tlsportname2/proxy/: tls qux (200; 11.139533ms)
Jan 17 17:56:54.122: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/proxy-service-572q5:portname2/proxy/: bar (200; 11.903443ms)
Jan 17 17:56:54.125: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/http:proxy-service-572q5:portname1/proxy/: foo (200; 14.89422ms)
Jan 17 17:56:54.130: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/https:proxy-service-572q5:tlsportname1/proxy/: tls baz (200; 4.539977ms)
Jan 17 17:56:54.130: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:443/proxy/... (200; 4.242595ms)
Jan 17 17:56:54.130: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:1080/proxy/... (200; 4.58642ms)
Jan 17 17:56:54.132: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46/proxy/rewriteme"... (200; 5.881215ms)
Jan 17 17:56:54.133: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:162/proxy/: bar (200; 6.585478ms)
Jan 17 17:56:54.133: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/http:proxy-service-572q5:portname2/proxy/: bar (200; 7.341031ms)
Jan 17 17:56:54.133: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:462/proxy/: tls qux (200; 6.168169ms)
Jan 17 17:56:54.133: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:160/proxy/: foo (200; 6.41075ms)
Jan 17 17:56:54.133: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:1080/proxy/rewri... (200; 6.913072ms)
Jan 17 17:56:54.134: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/proxy-service-572q5:portname1/proxy/: foo (200; 7.916755ms)
Jan 17 17:56:54.134: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:160/proxy/: foo (200; 7.603651ms)
Jan 17 17:56:54.134: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:162/proxy/: bar (200; 7.679405ms)
Jan 17 17:56:54.139: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/http:proxy-service-572q5:portname1/proxy/: foo (200; 11.673126ms)
Jan 17 17:56:54.139: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:460/proxy/: tls baz (200; 12.607908ms)
Jan 17 17:56:54.139: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/https:proxy-service-572q5:tlsportname2/proxy/: tls qux (200; 12.266695ms)
Jan 17 17:56:54.139: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/proxy-service-572q5:portname2/proxy/: bar (200; 13.107801ms)
Jan 17 17:56:54.145: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:160/proxy/: foo (200; 5.837681ms)
Jan 17 17:56:54.147: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:162/proxy/: bar (200; 7.839895ms)
Jan 17 17:56:54.148: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46/proxy/rewriteme"... (200; 7.297957ms)
Jan 17 17:56:54.148: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:1080/proxy/rewri... (200; 8.549119ms)
Jan 17 17:56:54.148: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:443/proxy/... (200; 7.577738ms)
Jan 17 17:56:54.148: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:462/proxy/: tls qux (200; 8.282257ms)
Jan 17 17:56:54.150: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:460/proxy/: tls baz (200; 9.52246ms)
Jan 17 17:56:54.150: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:160/proxy/: foo (200; 9.605653ms)
Jan 17 17:56:54.150: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:162/proxy/: bar (200; 11.26233ms)
Jan 17 17:56:54.151: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:1080/proxy/... (200; 11.216371ms)
Jan 17 17:56:54.152: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/https:proxy-service-572q5:tlsportname2/proxy/: tls qux (200; 13.024091ms)
Jan 17 17:56:54.153: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/proxy-service-572q5:portname1/proxy/: foo (200; 12.142115ms)
Jan 17 17:56:54.153: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/http:proxy-service-572q5:portname1/proxy/: foo (200; 13.088563ms)
Jan 17 17:56:54.153: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/https:proxy-service-572q5:tlsportname1/proxy/: tls baz (200; 13.079885ms)
Jan 17 17:56:54.153: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/proxy-service-572q5:portname2/proxy/: bar (200; 12.62166ms)
Jan 17 17:56:54.155: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/http:proxy-service-572q5:portname2/proxy/: bar (200; 14.263934ms)
Jan 17 17:56:54.161: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46/proxy/rewriteme"... (200; 5.680192ms)
Jan 17 17:56:54.161: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:1080/proxy/... (200; 5.769255ms)
Jan 17 17:56:54.161: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:1080/proxy/rewri... (200; 5.460315ms)
Jan 17 17:56:54.161: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:462/proxy/: tls qux (200; 5.433627ms)
Jan 17 17:56:54.163: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:162/proxy/: bar (200; 7.753801ms)
Jan 17 17:56:54.164: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:162/proxy/: bar (200; 8.667937ms)
Jan 17 17:56:54.164: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:443/proxy/... (200; 9.340301ms)
Jan 17 17:56:54.165: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/https:proxy-service-572q5:tlsportname2/proxy/: tls qux (200; 9.301449ms)
Jan 17 17:56:54.165: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:460/proxy/: tls baz (200; 9.486464ms)
Jan 17 17:56:54.165: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:160/proxy/: foo (200; 9.551742ms)
Jan 17 17:56:54.166: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/http:proxy-service-572q5:portname2/proxy/: bar (200; 11.068036ms)
Jan 17 17:56:54.166: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/proxy-service-572q5:portname2/proxy/: bar (200; 11.158978ms)
Jan 17 17:56:54.166: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/http:proxy-service-572q5:portname1/proxy/: foo (200; 11.602984ms)
Jan 17 17:56:54.166: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/proxy-service-572q5:portname1/proxy/: foo (200; 11.2366ms)
Jan 17 17:56:54.166: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/https:proxy-service-572q5:tlsportname1/proxy/: tls baz (200; 11.109078ms)
Jan 17 17:56:54.169: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:160/proxy/: foo (200; 13.882697ms)
Jan 17 17:56:54.178: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:162/proxy/: bar (200; 8.095536ms)
Jan 17 17:56:54.181: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:1080/proxy/... (200; 10.934916ms)
Jan 17 17:56:54.181: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:162/proxy/: bar (200; 11.166562ms)
Jan 17 17:56:54.181: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/https:proxy-service-572q5:tlsportname2/proxy/: tls qux (200; 11.287218ms)
Jan 17 17:56:54.181: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46/proxy/rewriteme"... (200; 11.154433ms)
Jan 17 17:56:54.181: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/https:proxy-service-572q5:tlsportname1/proxy/: tls baz (200; 11.353218ms)
Jan 17 17:56:54.181: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:460/proxy/: tls baz (200; 11.271667ms)
Jan 17 17:56:54.181: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:160/proxy/: foo (200; 11.322806ms)
Jan 17 17:56:54.181: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:443/proxy/... (200; 11.716904ms)
Jan 17 17:56:54.181: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:1080/proxy/rewri... (200; 11.36782ms)
Jan 17 17:56:54.181: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:160/proxy/: foo (200; 11.496903ms)
Jan 17 17:56:54.181: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/http:proxy-service-572q5:portname2/proxy/: bar (200; 11.26838ms)
Jan 17 17:56:54.181: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/proxy-service-572q5:portname2/proxy/: bar (200; 11.576637ms)
Jan 17 17:56:54.181: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:462/proxy/: tls qux (200; 11.403757ms)
Jan 17 17:56:54.182: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/proxy-service-572q5:portname1/proxy/: foo (200; 12.290813ms)
Jan 17 17:56:54.182: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/http:proxy-service-572q5:portname1/proxy/: foo (200; 12.441853ms)
Jan 17 17:56:54.190: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46/proxy/rewriteme"... (200; 8.234126ms)
Jan 17 17:56:54.192: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:443/proxy/... (200; 9.560427ms)
Jan 17 17:56:54.192: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:160/proxy/: foo (200; 9.946919ms)
Jan 17 17:56:54.192: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:460/proxy/: tls baz (200; 10.065032ms)
Jan 17 17:56:54.192: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:162/proxy/: bar (200; 10.460543ms)
Jan 17 17:56:54.192: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:1080/proxy/... (200; 10.247329ms)
Jan 17 17:56:54.192: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:162/proxy/: bar (200; 10.330291ms)
Jan 17 17:56:54.192: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:1080/proxy/rewri... (200; 10.284809ms)
Jan 17 17:56:54.192: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:462/proxy/: tls qux (200; 10.247553ms)
Jan 17 17:56:54.192: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:160/proxy/: foo (200; 10.30053ms)
Jan 17 17:56:54.195: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/http:proxy-service-572q5:portname2/proxy/: bar (200; 13.350831ms)
Jan 17 17:56:54.195: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/https:proxy-service-572q5:tlsportname2/proxy/: tls qux (200; 13.506136ms)
Jan 17 17:56:54.196: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/proxy-service-572q5:portname2/proxy/: bar (200; 13.358872ms)
Jan 17 17:56:54.196: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/proxy-service-572q5:portname1/proxy/: foo (200; 13.381482ms)
Jan 17 17:56:54.196: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/http:proxy-service-572q5:portname1/proxy/: foo (200; 13.885566ms)
Jan 17 17:56:54.200: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/https:proxy-service-572q5:tlsportname1/proxy/: tls baz (200; 17.581537ms)
Jan 17 17:56:54.212: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:460/proxy/: tls baz (200; 12.170583ms)
Jan 17 17:56:54.215: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:1080/proxy/rewri... (200; 15.524927ms)
Jan 17 17:56:54.215: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:443/proxy/... (200; 15.595487ms)
Jan 17 17:56:54.215: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/proxy-service-572q5:portname2/proxy/: bar (200; 15.553383ms)
Jan 17 17:56:54.215: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:462/proxy/: tls qux (200; 15.670901ms)
Jan 17 17:56:54.215: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:160/proxy/: foo (200; 15.727491ms)
Jan 17 17:56:54.215: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:160/proxy/: foo (200; 15.584778ms)
Jan 17 17:56:54.215: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:162/proxy/: bar (200; 15.742588ms)
Jan 17 17:56:54.216: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/https:proxy-service-572q5:tlsportname2/proxy/: tls qux (200; 15.803907ms)
Jan 17 17:56:54.216: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46/proxy/rewriteme"... (200; 15.719763ms)
Jan 17 17:56:54.216: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:1080/proxy/... (200; 15.724183ms)
Jan 17 17:56:54.216: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/proxy-service-572q5:portname1/proxy/: foo (200; 15.766304ms)
Jan 17 17:56:54.216: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:162/proxy/: bar (200; 15.816244ms)
Jan 17 17:56:54.216: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/http:proxy-service-572q5:portname2/proxy/: bar (200; 16.664393ms)
Jan 17 17:56:54.219: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/http:proxy-service-572q5:portname1/proxy/: foo (200; 19.365843ms)
Jan 17 17:56:54.223: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/https:proxy-service-572q5:tlsportname1/proxy/: tls baz (200; 23.221676ms)
Jan 17 17:56:54.227: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:460/proxy/: tls baz (200; 3.977061ms)
Jan 17 17:56:54.230: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/http:proxy-service-572q5:portname1/proxy/: foo (200; 6.865932ms)
Jan 17 17:56:54.230: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/http:proxy-service-572q5:portname2/proxy/: bar (200; 7.095676ms)
Jan 17 17:56:54.233: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/proxy-service-572q5:portname2/proxy/: bar (200; 9.900801ms)
Jan 17 17:56:54.233: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/https:proxy-service-572q5:tlsportname2/proxy/: tls qux (200; 10.212526ms)
Jan 17 17:56:54.233: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:1080/proxy/rewri... (200; 10.209103ms)
Jan 17 17:56:54.233: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/proxy-service-572q5:portname1/proxy/: foo (200; 10.163707ms)
Jan 17 17:56:54.233: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:162/proxy/: bar (200; 10.222474ms)
Jan 17 17:56:54.233: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:462/proxy/: tls qux (200; 10.429471ms)
Jan 17 17:56:54.236: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/https:proxy-service-572q5:tlsportname1/proxy/: tls baz (200; 13.315638ms)
Jan 17 17:56:54.239: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:162/proxy/: bar (200; 15.211776ms)
Jan 17 17:56:54.239: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:443/proxy/... (200; 15.596869ms)
Jan 17 17:56:54.239: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:160/proxy/: foo (200; 15.780656ms)
Jan 17 17:56:54.239: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46/proxy/rewriteme"... (200; 15.966951ms)
Jan 17 17:56:54.239: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:1080/proxy/... (200; 16.096476ms)
Jan 17 17:56:54.239: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:160/proxy/: foo (200; 16.15908ms)
Jan 17 17:56:54.244: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:160/proxy/: foo (200; 4.437772ms)
Jan 17 17:56:54.248: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46/proxy/rewriteme"... (200; 7.944272ms)
Jan 17 17:56:54.250: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:460/proxy/: tls baz (200; 10.103218ms)
Jan 17 17:56:54.250: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:443/proxy/... (200; 10.56056ms)
Jan 17 17:56:54.250: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:1080/proxy/rewri... (200; 10.135621ms)
Jan 17 17:56:54.251: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:162/proxy/: bar (200; 10.405979ms)
Jan 17 17:56:54.251: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:162/proxy/: bar (200; 10.615629ms)
Jan 17 17:56:54.251: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/http:proxy-service-572q5:portname2/proxy/: bar (200; 11.054421ms)
Jan 17 17:56:54.251: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:160/proxy/: foo (200; 10.785793ms)
Jan 17 17:56:54.251: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:1080/proxy/... (200; 11.059297ms)
Jan 17 17:56:54.253: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/https:proxy-service-572q5:tlsportname1/proxy/: tls baz (200; 13.219334ms)
Jan 17 17:56:54.254: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/http:proxy-service-572q5:portname1/proxy/: foo (200; 13.463722ms)
Jan 17 17:56:54.253: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:462/proxy/: tls qux (200; 13.096067ms)
Jan 17 17:56:54.256: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/proxy-service-572q5:portname1/proxy/: foo (200; 15.677652ms)
Jan 17 17:56:54.256: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/proxy-service-572q5:portname2/proxy/: bar (200; 15.68555ms)
Jan 17 17:56:54.256: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/https:proxy-service-572q5:tlsportname2/proxy/: tls qux (200; 15.444339ms)
Jan 17 17:56:54.258: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:443/proxy/... (200; 2.575245ms)
Jan 17 17:56:54.265: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:162/proxy/: bar (200; 7.863039ms)
Jan 17 17:56:54.267: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46/proxy/rewriteme"... (200; 10.414155ms)
Jan 17 17:56:54.267: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:1080/proxy/... (200; 10.463492ms)
Jan 17 17:56:54.267: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:160/proxy/: foo (200; 10.782223ms)
Jan 17 17:56:54.268: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:162/proxy/: bar (200; 11.509632ms)
Jan 17 17:56:54.268: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:1080/proxy/rewri... (200; 11.114422ms)
Jan 17 17:56:54.268: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:462/proxy/: tls qux (200; 11.568476ms)
Jan 17 17:56:54.268: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:460/proxy/: tls baz (200; 11.678107ms)
Jan 17 17:56:54.271: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/http:proxy-service-572q5:portname1/proxy/: foo (200; 14.207408ms)
Jan 17 17:56:54.271: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:160/proxy/: foo (200; 14.625013ms)
Jan 17 17:56:54.271: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/http:proxy-service-572q5:portname2/proxy/: bar (200; 13.96299ms)
Jan 17 17:56:54.271: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/https:proxy-service-572q5:tlsportname2/proxy/: tls qux (200; 14.304566ms)
Jan 17 17:56:54.271: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/https:proxy-service-572q5:tlsportname1/proxy/: tls baz (200; 14.432531ms)
Jan 17 17:56:54.271: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/proxy-service-572q5:portname2/proxy/: bar (200; 14.953887ms)
Jan 17 17:56:54.275: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/proxy-service-572q5:portname1/proxy/: foo (200; 19.424455ms)
Jan 17 17:56:54.288: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:460/proxy/: tls baz (200; 12.179684ms)
Jan 17 17:56:54.288: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:443/proxy/... (200; 6.503932ms)
Jan 17 17:56:54.288: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:1080/proxy/rewri... (200; 6.739467ms)
Jan 17 17:56:54.288: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:162/proxy/: bar (200; 6.554047ms)
Jan 17 17:56:54.288: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:162/proxy/: bar (200; 6.746392ms)
Jan 17 17:56:54.288: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:462/proxy/: tls qux (200; 6.73392ms)
Jan 17 17:56:54.292: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:160/proxy/: foo (200; 10.208874ms)
Jan 17 17:56:54.292: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:1080/proxy/... (200; 10.487079ms)
Jan 17 17:56:54.292: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46/proxy/rewriteme"... (200; 10.535409ms)
Jan 17 17:56:54.292: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:160/proxy/: foo (200; 10.705678ms)
Jan 17 17:56:54.292: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/http:proxy-service-572q5:portname1/proxy/: foo (200; 10.814971ms)
Jan 17 17:56:54.292: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/proxy-service-572q5:portname2/proxy/: bar (200; 10.71396ms)
Jan 17 17:56:54.292: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/https:proxy-service-572q5:tlsportname1/proxy/: tls baz (200; 10.90023ms)
Jan 17 17:56:54.292: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/https:proxy-service-572q5:tlsportname2/proxy/: tls qux (200; 10.905636ms)
Jan 17 17:56:54.293: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/http:proxy-service-572q5:portname2/proxy/: bar (200; 11.329989ms)
Jan 17 17:56:54.294: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/proxy-service-572q5:portname1/proxy/: foo (200; 11.97805ms)
Jan 17 17:56:54.306: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:443/proxy/... (200; 11.222018ms)
Jan 17 17:56:54.306: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:460/proxy/: tls baz (200; 12.09218ms)
Jan 17 17:56:54.307: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/https:proxy-service-572q5:tlsportname1/proxy/: tls baz (200; 12.526062ms)
Jan 17 17:56:54.307: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:162/proxy/: bar (200; 13.096165ms)
Jan 17 17:56:54.307: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:1080/proxy/... (200; 12.384388ms)
Jan 17 17:56:54.307: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/http:proxy-service-572q5:portname1/proxy/: foo (200; 12.834091ms)
Jan 17 17:56:54.307: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:162/proxy/: bar (200; 13.141715ms)
Jan 17 17:56:54.307: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:1080/proxy/rewri... (200; 13.356132ms)
Jan 17 17:56:54.308: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/http:proxy-service-572q5:portname2/proxy/: bar (200; 13.128662ms)
Jan 17 17:56:54.308: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:160/proxy/: foo (200; 13.670686ms)
Jan 17 17:56:54.308: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46/proxy/rewriteme"... (200; 13.346562ms)
Jan 17 17:56:54.308: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:160/proxy/: foo (200; 14.226795ms)
Jan 17 17:56:54.308: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/proxy-service-572q5:portname1/proxy/: foo (200; 13.48021ms)
Jan 17 17:56:54.308: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/https:proxy-service-572q5:tlsportname2/proxy/: tls qux (200; 13.880847ms)
Jan 17 17:56:54.308: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:462/proxy/: tls qux (200; 14.139894ms)
Jan 17 17:56:54.308: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/proxy-service-572q5:portname2/proxy/: bar (200; 14.754563ms)
Jan 17 17:56:54.317: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/http:proxy-service-572q5:portname2/proxy/: bar (200; 8.462923ms)
Jan 17 17:56:54.317: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46/proxy/rewriteme"... (200; 8.767595ms)
Jan 17 17:56:54.322: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:160/proxy/: foo (200; 14.009824ms)
Jan 17 17:56:54.323: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:462/proxy/: tls qux (200; 14.217009ms)
Jan 17 17:56:54.323: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:1080/proxy/... (200; 14.079224ms)
Jan 17 17:56:54.326: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/proxy-service-572q5:portname1/proxy/: foo (200; 16.874166ms)
Jan 17 17:56:54.327: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:443/proxy/... (200; 18.431831ms)
Jan 17 17:56:54.333: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:162/proxy/: bar (200; 23.956895ms)
Jan 17 17:56:54.335: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:160/proxy/: foo (200; 26.379513ms)
Jan 17 17:56:54.336: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:1080/proxy/rewri... (200; 26.451646ms)
Jan 17 17:56:54.336: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/http:proxy-service-572q5:portname1/proxy/: foo (200; 26.499409ms)
Jan 17 17:56:54.336: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/https:proxy-service-572q5:tlsportname2/proxy/: tls qux (200; 26.455268ms)
Jan 17 17:56:54.336: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:162/proxy/: bar (200; 26.413698ms)
Jan 17 17:56:54.336: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/https:proxy-service-572q5:tlsportname1/proxy/: tls baz (200; 26.611019ms)
Jan 17 17:56:54.336: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/proxy-service-572q5:portname2/proxy/: bar (200; 26.648072ms)
Jan 17 17:56:54.338: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:460/proxy/: tls baz (200; 29.071593ms)
Jan 17 17:56:54.345: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:160/proxy/: foo (200; 3.770705ms)
Jan 17 17:56:54.348: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:443/proxy/... (200; 6.219888ms)
Jan 17 17:56:54.348: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46/proxy/rewriteme"... (200; 6.011708ms)
Jan 17 17:56:54.348: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:1080/proxy/... (200; 6.467054ms)
Jan 17 17:56:54.352: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/http:proxy-service-572q5:portname2/proxy/: bar (200; 10.566738ms)
Jan 17 17:56:54.352: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:1080/proxy/rewri... (200; 9.446996ms)
Jan 17 17:56:54.354: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/https:proxy-service-572q5:tlsportname1/proxy/: tls baz (200; 10.779918ms)
Jan 17 17:56:54.354: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:162/proxy/: bar (200; 11.59334ms)
Jan 17 17:56:54.354: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:162/proxy/: bar (200; 11.07899ms)
Jan 17 17:56:54.355: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:460/proxy/: tls baz (200; 13.270905ms)
Jan 17 17:56:54.355: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/http:proxy-service-572q5:portname1/proxy/: foo (200; 12.35936ms)
Jan 17 17:56:54.355: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:160/proxy/: foo (200; 13.149172ms)
Jan 17 17:56:54.355: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/proxy-service-572q5:portname2/proxy/: bar (200; 13.434603ms)
Jan 17 17:56:54.357: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/https:proxy-service-572q5:tlsportname2/proxy/: tls qux (200; 14.596421ms)
Jan 17 17:56:54.357: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/proxy-service-572q5:portname1/proxy/: foo (200; 15.341293ms)
Jan 17 17:56:54.357: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:462/proxy/: tls qux (200; 14.380975ms)
Jan 17 17:56:54.368: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:160/proxy/: foo (200; 6.244887ms)
Jan 17 17:56:54.368: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:462/proxy/: tls qux (200; 7.029254ms)
Jan 17 17:56:54.372: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:1080/proxy/rewri... (200; 11.316695ms)
Jan 17 17:56:54.375: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:1080/proxy/... (200; 14.114851ms)
Jan 17 17:56:54.375: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:443/proxy/... (200; 14.131303ms)
Jan 17 17:56:54.375: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:160/proxy/: foo (200; 14.396989ms)
Jan 17 17:56:54.375: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/http:proxy-service-572q5-vkn46:162/proxy/: bar (200; 14.117074ms)
Jan 17 17:56:54.375: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/https:proxy-service-572q5-vkn46:460/proxy/: tls baz (200; 14.138501ms)
Jan 17 17:56:54.375: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46/proxy/rewriteme"... (200; 14.235729ms)
Jan 17 17:56:54.375: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-psbcf/pods/proxy-service-572q5-vkn46:162/proxy/: bar (200; 14.121171ms)
Jan 17 17:56:54.376: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/https:proxy-service-572q5:tlsportname2/proxy/: tls qux (200; 14.622954ms)
Jan 17 17:56:54.376: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/http:proxy-service-572q5:portname2/proxy/: bar (200; 14.737273ms)
Jan 17 17:56:54.376: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/proxy-service-572q5:portname1/proxy/: foo (200; 14.533019ms)
Jan 17 17:56:54.376: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/http:proxy-service-572q5:portname1/proxy/: foo (200; 14.474078ms)
Jan 17 17:56:54.375: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/proxy-service-572q5:portname2/proxy/: bar (200; 17.320915ms)
Jan 17 17:56:54.380: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-psbcf/services/https:proxy-service-572q5:tlsportname1/proxy/: tls baz (200; 20.812147ms)
STEP: deleting ReplicationController proxy-service-572q5 in namespace e2e-tests-proxy-psbcf, will wait for the garbage collector to delete the pods
Jan 17 17:56:54.448: INFO: Deleting ReplicationController proxy-service-572q5 took: 3.752918ms
Jan 17 17:56:54.548: INFO: Terminating ReplicationController proxy-service-572q5 pods took: 100.471172ms
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:56:59.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-psbcf" for this suite.
Jan 17 17:57:05.172: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:57:05.245: INFO: namespace: e2e-tests-proxy-psbcf, resource: bindings, ignored listing per whitelist
Jan 17 17:57:05.259: INFO: namespace e2e-tests-proxy-psbcf deletion completed in 6.105986692s

• [SLOW TEST:14.423 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:57:05.259: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 17 17:57:05.413: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"4cd96f9c-1a81-11e9-8458-5254003c4592", Controller:(*bool)(0xc0008c1d46), BlockOwnerDeletion:(*bool)(0xc0008c1d47)}}
Jan 17 17:57:05.428: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"4cd6ae73-1a81-11e9-8458-5254003c4592", Controller:(*bool)(0xc001a15446), BlockOwnerDeletion:(*bool)(0xc001a15447)}}
Jan 17 17:57:05.442: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"4cd72af4-1a81-11e9-8458-5254003c4592", Controller:(*bool)(0xc0008c1f5e), BlockOwnerDeletion:(*bool)(0xc0008c1f5f)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:57:10.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-5b9q8" for this suite.
Jan 17 17:57:16.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:57:16.564: INFO: namespace: e2e-tests-gc-5b9q8, resource: bindings, ignored listing per whitelist
Jan 17 17:57:16.584: INFO: namespace e2e-tests-gc-5b9q8 deletion completed in 6.085766967s

• [SLOW TEST:11.326 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:57:16.587: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Jan 17 17:57:16.759: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-w4pnw,SelfLink:/api/v1/namespaces/e2e-tests-watch-w4pnw/configmaps/e2e-watch-test-resource-version,UID:5397ee9d-1a81-11e9-8458-5254003c4592,ResourceVersion:82210,Generation:0,CreationTimestamp:2019-01-17 17:57:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 17 17:57:16.759: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-w4pnw,SelfLink:/api/v1/namespaces/e2e-tests-watch-w4pnw/configmaps/e2e-watch-test-resource-version,UID:5397ee9d-1a81-11e9-8458-5254003c4592,ResourceVersion:82211,Generation:0,CreationTimestamp:2019-01-17 17:57:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:57:16.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-w4pnw" for this suite.
Jan 17 17:57:22.829: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:57:22.855: INFO: namespace: e2e-tests-watch-w4pnw, resource: bindings, ignored listing per whitelist
Jan 17 17:57:22.882: INFO: namespace e2e-tests-watch-w4pnw deletion completed in 6.06733864s

• [SLOW TEST:6.296 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:57:22.882: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-575cfb09-1a81-11e9-a4b6-0a580af40269
STEP: Creating a pod to test consume secrets
Jan 17 17:57:23.044: INFO: Waiting up to 5m0s for pod "pod-secrets-575d630e-1a81-11e9-a4b6-0a580af40269" in namespace "e2e-tests-secrets-lsvtp" to be "success or failure"
Jan 17 17:57:23.054: INFO: Pod "pod-secrets-575d630e-1a81-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 9.758275ms
Jan 17 17:57:25.063: INFO: Pod "pod-secrets-575d630e-1a81-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018957602s
Jan 17 17:57:27.095: INFO: Pod "pod-secrets-575d630e-1a81-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051234206s
STEP: Saw pod success
Jan 17 17:57:27.095: INFO: Pod "pod-secrets-575d630e-1a81-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 17:57:27.100: INFO: Trying to get logs from node node1 pod pod-secrets-575d630e-1a81-11e9-a4b6-0a580af40269 container secret-volume-test: <nil>
STEP: delete the pod
Jan 17 17:57:27.146: INFO: Waiting for pod pod-secrets-575d630e-1a81-11e9-a4b6-0a580af40269 to disappear
Jan 17 17:57:27.149: INFO: Pod pod-secrets-575d630e-1a81-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:57:27.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-lsvtp" for this suite.
Jan 17 17:57:33.171: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:57:33.249: INFO: namespace: e2e-tests-secrets-lsvtp, resource: bindings, ignored listing per whitelist
Jan 17 17:57:33.266: INFO: namespace e2e-tests-secrets-lsvtp deletion completed in 6.113518319s

• [SLOW TEST:10.384 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:57:33.266: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:57:37.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-t9s56" for this suite.
Jan 17 17:58:23.439: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:58:23.494: INFO: namespace: e2e-tests-kubelet-test-t9s56, resource: bindings, ignored listing per whitelist
Jan 17 17:58:23.524: INFO: namespace e2e-tests-kubelet-test-t9s56 deletion completed in 46.103734983s

• [SLOW TEST:50.259 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:58:23.542: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-ckq6
STEP: Creating a pod to test atomic-volume-subpath
Jan 17 17:58:23.747: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-ckq6" in namespace "e2e-tests-subpath-v4b4r" to be "success or failure"
Jan 17 17:58:23.753: INFO: Pod "pod-subpath-test-configmap-ckq6": Phase="Pending", Reason="", readiness=false. Elapsed: 5.799561ms
Jan 17 17:58:25.755: INFO: Pod "pod-subpath-test-configmap-ckq6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008035344s
Jan 17 17:58:27.763: INFO: Pod "pod-subpath-test-configmap-ckq6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016382848s
Jan 17 17:58:29.772: INFO: Pod "pod-subpath-test-configmap-ckq6": Phase="Running", Reason="", readiness=false. Elapsed: 6.025252475s
Jan 17 17:58:31.806: INFO: Pod "pod-subpath-test-configmap-ckq6": Phase="Running", Reason="", readiness=false. Elapsed: 8.058692709s
Jan 17 17:58:33.824: INFO: Pod "pod-subpath-test-configmap-ckq6": Phase="Running", Reason="", readiness=false. Elapsed: 10.077445754s
Jan 17 17:58:35.832: INFO: Pod "pod-subpath-test-configmap-ckq6": Phase="Running", Reason="", readiness=false. Elapsed: 12.084697997s
Jan 17 17:58:37.857: INFO: Pod "pod-subpath-test-configmap-ckq6": Phase="Running", Reason="", readiness=false. Elapsed: 14.109700388s
Jan 17 17:58:39.863: INFO: Pod "pod-subpath-test-configmap-ckq6": Phase="Running", Reason="", readiness=false. Elapsed: 16.11608894s
Jan 17 17:58:41.883: INFO: Pod "pod-subpath-test-configmap-ckq6": Phase="Running", Reason="", readiness=false. Elapsed: 18.135630723s
Jan 17 17:58:43.894: INFO: Pod "pod-subpath-test-configmap-ckq6": Phase="Running", Reason="", readiness=false. Elapsed: 20.14679121s
Jan 17 17:58:45.898: INFO: Pod "pod-subpath-test-configmap-ckq6": Phase="Running", Reason="", readiness=false. Elapsed: 22.151345125s
Jan 17 17:58:47.903: INFO: Pod "pod-subpath-test-configmap-ckq6": Phase="Running", Reason="", readiness=false. Elapsed: 24.155719739s
Jan 17 17:58:49.927: INFO: Pod "pod-subpath-test-configmap-ckq6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.180268944s
STEP: Saw pod success
Jan 17 17:58:49.927: INFO: Pod "pod-subpath-test-configmap-ckq6" satisfied condition "success or failure"
Jan 17 17:58:49.931: INFO: Trying to get logs from node node1 pod pod-subpath-test-configmap-ckq6 container test-container-subpath-configmap-ckq6: <nil>
STEP: delete the pod
Jan 17 17:58:49.968: INFO: Waiting for pod pod-subpath-test-configmap-ckq6 to disappear
Jan 17 17:58:49.979: INFO: Pod pod-subpath-test-configmap-ckq6 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-ckq6
Jan 17 17:58:49.979: INFO: Deleting pod "pod-subpath-test-configmap-ckq6" in namespace "e2e-tests-subpath-v4b4r"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:58:49.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-v4b4r" for this suite.
Jan 17 17:58:56.024: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:58:56.050: INFO: namespace: e2e-tests-subpath-v4b4r, resource: bindings, ignored listing per whitelist
Jan 17 17:58:56.125: INFO: namespace e2e-tests-subpath-v4b4r deletion completed in 6.137385156s

• [SLOW TEST:32.583 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:58:56.126: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-l2spm
Jan 17 17:58:58.286: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-l2spm
STEP: checking the pod's current state and verifying that restartCount is present
Jan 17 17:58:58.289: INFO: Initial restart count of pod liveness-http is 0
Jan 17 17:59:22.384: INFO: Restart count of pod e2e-tests-container-probe-l2spm/liveness-http is now 1 (24.094216083s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:59:22.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-l2spm" for this suite.
Jan 17 17:59:28.490: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:59:28.552: INFO: namespace: e2e-tests-container-probe-l2spm, resource: bindings, ignored listing per whitelist
Jan 17 17:59:28.578: INFO: namespace e2e-tests-container-probe-l2spm deletion completed in 6.102965334s

• [SLOW TEST:32.452 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:59:28.579: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-a245b0ff-1a81-11e9-a4b6-0a580af40269
STEP: Creating a pod to test consume secrets
Jan 17 17:59:28.732: INFO: Waiting up to 5m0s for pod "pod-secrets-a24705b2-1a81-11e9-a4b6-0a580af40269" in namespace "e2e-tests-secrets-s25tc" to be "success or failure"
Jan 17 17:59:28.743: INFO: Pod "pod-secrets-a24705b2-1a81-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 11.025339ms
Jan 17 17:59:30.782: INFO: Pod "pod-secrets-a24705b2-1a81-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.049996331s
Jan 17 17:59:32.786: INFO: Pod "pod-secrets-a24705b2-1a81-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.05325063s
STEP: Saw pod success
Jan 17 17:59:32.786: INFO: Pod "pod-secrets-a24705b2-1a81-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 17:59:32.790: INFO: Trying to get logs from node node1 pod pod-secrets-a24705b2-1a81-11e9-a4b6-0a580af40269 container secret-volume-test: <nil>
STEP: delete the pod
Jan 17 17:59:32.824: INFO: Waiting for pod pod-secrets-a24705b2-1a81-11e9-a4b6-0a580af40269 to disappear
Jan 17 17:59:32.832: INFO: Pod pod-secrets-a24705b2-1a81-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:59:32.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-s25tc" for this suite.
Jan 17 17:59:38.854: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 17:59:38.937: INFO: namespace: e2e-tests-secrets-s25tc, resource: bindings, ignored listing per whitelist
Jan 17 17:59:38.942: INFO: namespace e2e-tests-secrets-s25tc deletion completed in 6.103632013s

• [SLOW TEST:10.363 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 17:59:38.944: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-a86b98da-1a81-11e9-a4b6-0a580af40269
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 17:59:43.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-9ph4r" for this suite.
Jan 17 18:00:05.125: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:00:05.204: INFO: namespace: e2e-tests-configmap-9ph4r, resource: bindings, ignored listing per whitelist
Jan 17 18:00:05.225: INFO: namespace e2e-tests-configmap-9ph4r deletion completed in 22.119365971s

• [SLOW TEST:26.282 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:00:05.226: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Jan 17 18:00:05.337: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jan 17 18:00:05.398: INFO: Waiting for terminating namespaces to be deleted...
Jan 17 18:00:05.401: INFO: 
Logging pods the kubelet thinks is on node node1 before test
Jan 17 18:00:05.407: INFO: kube-proxy-7z4x2 from kube-system started at 2019-01-17 06:49:56 +0000 UTC (1 container statuses recorded)
Jan 17 18:00:05.407: INFO: 	Container kube-proxy ready: true, restart count 1
Jan 17 18:00:05.407: INFO: sonobuoy from heptio-sonobuoy started at 2019-01-17 17:15:08 +0000 UTC (1 container statuses recorded)
Jan 17 18:00:05.407: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jan 17 18:00:05.407: INFO: kube-flannel-ds-amd64-8fwk6 from kube-system started at 2019-01-17 06:49:56 +0000 UTC (1 container statuses recorded)
Jan 17 18:00:05.407: INFO: 	Container kube-flannel ready: true, restart count 1
Jan 17 18:00:05.407: INFO: sonobuoy-systemd-logs-daemon-set-0dcc53c5f8e1419f-kq5jj from heptio-sonobuoy started at 2019-01-17 17:15:12 +0000 UTC (2 container statuses recorded)
Jan 17 18:00:05.407: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan 17 18:00:05.407: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 17 18:00:05.407: INFO: 
Logging pods the kubelet thinks is on node node2 before test
Jan 17 18:00:05.418: INFO: kube-flannel-ds-amd64-pcptp from kube-system started at 2019-01-17 06:52:49 +0000 UTC (1 container statuses recorded)
Jan 17 18:00:05.418: INFO: 	Container kube-flannel ready: true, restart count 1
Jan 17 18:00:05.418: INFO: kube-proxy-qmrgn from kube-system started at 2019-01-17 06:52:49 +0000 UTC (1 container statuses recorded)
Jan 17 18:00:05.418: INFO: 	Container kube-proxy ready: true, restart count 1
Jan 17 18:00:05.418: INFO: sonobuoy-e2e-job-5a5cc172c34e4413 from heptio-sonobuoy started at 2019-01-17 17:15:12 +0000 UTC (2 container statuses recorded)
Jan 17 18:00:05.418: INFO: 	Container e2e ready: true, restart count 0
Jan 17 18:00:05.418: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 17 18:00:05.418: INFO: sonobuoy-systemd-logs-daemon-set-0dcc53c5f8e1419f-q5jtj from heptio-sonobuoy started at 2019-01-17 17:15:12 +0000 UTC (2 container statuses recorded)
Jan 17 18:00:05.418: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan 17 18:00:05.418: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node node1
STEP: verifying the node has the label node node2
Jan 17 18:00:05.540: INFO: Pod sonobuoy requesting resource cpu=0m on Node node1
Jan 17 18:00:05.540: INFO: Pod sonobuoy-e2e-job-5a5cc172c34e4413 requesting resource cpu=0m on Node node2
Jan 17 18:00:05.540: INFO: Pod sonobuoy-systemd-logs-daemon-set-0dcc53c5f8e1419f-kq5jj requesting resource cpu=0m on Node node1
Jan 17 18:00:05.540: INFO: Pod sonobuoy-systemd-logs-daemon-set-0dcc53c5f8e1419f-q5jtj requesting resource cpu=0m on Node node2
Jan 17 18:00:05.540: INFO: Pod kube-flannel-ds-amd64-8fwk6 requesting resource cpu=100m on Node node1
Jan 17 18:00:05.540: INFO: Pod kube-flannel-ds-amd64-pcptp requesting resource cpu=100m on Node node2
Jan 17 18:00:05.540: INFO: Pod kube-proxy-7z4x2 requesting resource cpu=0m on Node node1
Jan 17 18:00:05.540: INFO: Pod kube-proxy-qmrgn requesting resource cpu=0m on Node node2
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b839c235-1a81-11e9-a4b6-0a580af40269.157ab49c59026c22], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-qwqk5/filler-pod-b839c235-1a81-11e9-a4b6-0a580af40269 to node1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b839c235-1a81-11e9-a4b6-0a580af40269.157ab49cc7a748c5], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b839c235-1a81-11e9-a4b6-0a580af40269.157ab49ccd0dbc8d], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b839c235-1a81-11e9-a4b6-0a580af40269.157ab49cce4a84e5], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b83b35d6-1a81-11e9-a4b6-0a580af40269.157ab49c5971c241], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-qwqk5/filler-pod-b83b35d6-1a81-11e9-a4b6-0a580af40269 to node2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b83b35d6-1a81-11e9-a4b6-0a580af40269.157ab49cbf90712f], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b83b35d6-1a81-11e9-a4b6-0a580af40269.157ab49cc574340c], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b83b35d6-1a81-11e9-a4b6-0a580af40269.157ab49cc6b3595f], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.157ab49d48ac3cd2], Reason = [FailedScheduling], Message = [0/3 nodes are available: 1 node(s) had taints that the pod didn't tolerate, 2 Insufficient cpu.]
STEP: removing the label node off the node node2
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node node1
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:00:10.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-qwqk5" for this suite.
Jan 17 18:00:16.726: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:00:16.782: INFO: namespace: e2e-tests-sched-pred-qwqk5, resource: bindings, ignored listing per whitelist
Jan 17 18:00:16.806: INFO: namespace e2e-tests-sched-pred-qwqk5 deletion completed in 6.095106597s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:11.580 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:00:16.812: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 17 18:00:16.974: INFO: (0) /api/v1/nodes/node1:10250/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 4.150044ms)
Jan 17 18:00:16.978: INFO: (1) /api/v1/nodes/node1:10250/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 3.273587ms)
Jan 17 18:00:16.982: INFO: (2) /api/v1/nodes/node1:10250/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 4.478506ms)
Jan 17 18:00:16.986: INFO: (3) /api/v1/nodes/node1:10250/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 3.561732ms)
Jan 17 18:00:16.989: INFO: (4) /api/v1/nodes/node1:10250/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 3.188621ms)
Jan 17 18:00:16.993: INFO: (5) /api/v1/nodes/node1:10250/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 3.614634ms)
Jan 17 18:00:16.997: INFO: (6) /api/v1/nodes/node1:10250/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 3.948178ms)
Jan 17 18:00:17.000: INFO: (7) /api/v1/nodes/node1:10250/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 3.155494ms)
Jan 17 18:00:17.004: INFO: (8) /api/v1/nodes/node1:10250/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 3.626765ms)
Jan 17 18:00:17.008: INFO: (9) /api/v1/nodes/node1:10250/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 4.743205ms)
Jan 17 18:00:17.013: INFO: (10) /api/v1/nodes/node1:10250/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 3.956772ms)
Jan 17 18:00:17.020: INFO: (11) /api/v1/nodes/node1:10250/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 7.341167ms)
Jan 17 18:00:17.023: INFO: (12) /api/v1/nodes/node1:10250/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 3.211874ms)
Jan 17 18:00:17.027: INFO: (13) /api/v1/nodes/node1:10250/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 3.396652ms)
Jan 17 18:00:17.031: INFO: (14) /api/v1/nodes/node1:10250/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 4.297423ms)
Jan 17 18:00:17.034: INFO: (15) /api/v1/nodes/node1:10250/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 3.067422ms)
Jan 17 18:00:17.038: INFO: (16) /api/v1/nodes/node1:10250/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 3.350839ms)
Jan 17 18:00:17.042: INFO: (17) /api/v1/nodes/node1:10250/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 3.888895ms)
Jan 17 18:00:17.046: INFO: (18) /api/v1/nodes/node1:10250/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 3.984376ms)
Jan 17 18:00:17.051: INFO: (19) /api/v1/nodes/node1:10250/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 4.822417ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:00:17.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-2vchk" for this suite.
Jan 17 18:00:23.092: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:00:23.411: INFO: namespace: e2e-tests-proxy-2vchk, resource: bindings, ignored listing per whitelist
Jan 17 18:00:23.424: INFO: namespace e2e-tests-proxy-2vchk deletion completed in 6.352184697s

• [SLOW TEST:6.612 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:00:23.424: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-c2edbe89-1a81-11e9-a4b6-0a580af40269
STEP: Creating a pod to test consume secrets
Jan 17 18:00:23.518: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c2ef4f49-1a81-11e9-a4b6-0a580af40269" in namespace "e2e-tests-projected-jxbt5" to be "success or failure"
Jan 17 18:00:23.528: INFO: Pod "pod-projected-secrets-c2ef4f49-1a81-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 9.580565ms
Jan 17 18:00:25.571: INFO: Pod "pod-projected-secrets-c2ef4f49-1a81-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.052525652s
Jan 17 18:00:27.574: INFO: Pod "pod-projected-secrets-c2ef4f49-1a81-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.055159577s
STEP: Saw pod success
Jan 17 18:00:27.574: INFO: Pod "pod-projected-secrets-c2ef4f49-1a81-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 18:00:27.577: INFO: Trying to get logs from node node1 pod pod-projected-secrets-c2ef4f49-1a81-11e9-a4b6-0a580af40269 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan 17 18:00:27.642: INFO: Waiting for pod pod-projected-secrets-c2ef4f49-1a81-11e9-a4b6-0a580af40269 to disappear
Jan 17 18:00:27.644: INFO: Pod pod-projected-secrets-c2ef4f49-1a81-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:00:27.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jxbt5" for this suite.
Jan 17 18:00:33.660: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:00:33.725: INFO: namespace: e2e-tests-projected-jxbt5, resource: bindings, ignored listing per whitelist
Jan 17 18:00:33.729: INFO: namespace e2e-tests-projected-jxbt5 deletion completed in 6.081294774s

• [SLOW TEST:10.304 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:00:33.729: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jan 17 18:00:33.862: INFO: Waiting up to 5m0s for pod "pod-c919180e-1a81-11e9-a4b6-0a580af40269" in namespace "e2e-tests-emptydir-mw4bh" to be "success or failure"
Jan 17 18:00:33.869: INFO: Pod "pod-c919180e-1a81-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 6.71239ms
Jan 17 18:00:35.873: INFO: Pod "pod-c919180e-1a81-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011352319s
Jan 17 18:00:37.910: INFO: Pod "pod-c919180e-1a81-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048075444s
STEP: Saw pod success
Jan 17 18:00:37.910: INFO: Pod "pod-c919180e-1a81-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 18:00:37.912: INFO: Trying to get logs from node node1 pod pod-c919180e-1a81-11e9-a4b6-0a580af40269 container test-container: <nil>
STEP: delete the pod
Jan 17 18:00:37.954: INFO: Waiting for pod pod-c919180e-1a81-11e9-a4b6-0a580af40269 to disappear
Jan 17 18:00:37.956: INFO: Pod pod-c919180e-1a81-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:00:37.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-mw4bh" for this suite.
Jan 17 18:00:43.983: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:00:44.058: INFO: namespace: e2e-tests-emptydir-mw4bh, resource: bindings, ignored listing per whitelist
Jan 17 18:00:44.064: INFO: namespace e2e-tests-emptydir-mw4bh deletion completed in 6.099264957s

• [SLOW TEST:10.337 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:00:44.069: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-cf3c9b0f-1a81-11e9-a4b6-0a580af40269
STEP: Creating a pod to test consume configMaps
Jan 17 18:00:44.162: INFO: Waiting up to 5m0s for pod "pod-configmaps-cf3d926f-1a81-11e9-a4b6-0a580af40269" in namespace "e2e-tests-configmap-tmc2r" to be "success or failure"
Jan 17 18:00:44.173: INFO: Pod "pod-configmaps-cf3d926f-1a81-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 10.680119ms
Jan 17 18:00:46.220: INFO: Pod "pod-configmaps-cf3d926f-1a81-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.056940962s
Jan 17 18:00:48.229: INFO: Pod "pod-configmaps-cf3d926f-1a81-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.066534764s
STEP: Saw pod success
Jan 17 18:00:48.229: INFO: Pod "pod-configmaps-cf3d926f-1a81-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 18:00:48.274: INFO: Trying to get logs from node node1 pod pod-configmaps-cf3d926f-1a81-11e9-a4b6-0a580af40269 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 17 18:00:48.299: INFO: Waiting for pod pod-configmaps-cf3d926f-1a81-11e9-a4b6-0a580af40269 to disappear
Jan 17 18:00:48.315: INFO: Pod pod-configmaps-cf3d926f-1a81-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:00:48.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-tmc2r" for this suite.
Jan 17 18:00:54.345: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:00:54.412: INFO: namespace: e2e-tests-configmap-tmc2r, resource: bindings, ignored listing per whitelist
Jan 17 18:00:54.440: INFO: namespace e2e-tests-configmap-tmc2r deletion completed in 6.11970016s

• [SLOW TEST:10.370 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:00:54.440: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Jan 17 18:00:54.543: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 --namespace=e2e-tests-kubectl-hdcjr run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Jan 17 18:00:57.949: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Jan 17 18:00:57.949: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:00:59.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hdcjr" for this suite.
Jan 17 18:01:05.977: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:01:06.051: INFO: namespace: e2e-tests-kubectl-hdcjr, resource: bindings, ignored listing per whitelist
Jan 17 18:01:06.061: INFO: namespace e2e-tests-kubectl-hdcjr deletion completed in 6.098310874s

• [SLOW TEST:11.622 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:01:06.066: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Jan 17 18:01:06.213: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-043318780 proxy --unix-socket=/tmp/kubectl-proxy-unix503753003/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:01:06.294: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-nxszv" for this suite.
Jan 17 18:01:12.313: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:01:12.347: INFO: namespace: e2e-tests-kubectl-nxszv, resource: bindings, ignored listing per whitelist
Jan 17 18:01:12.378: INFO: namespace e2e-tests-kubectl-nxszv deletion completed in 6.078703306s

• [SLOW TEST:6.314 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:01:12.384: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 17 18:01:12.539: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e02775c8-1a81-11e9-a4b6-0a580af40269" in namespace "e2e-tests-projected-skgml" to be "success or failure"
Jan 17 18:01:12.548: INFO: Pod "downwardapi-volume-e02775c8-1a81-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 9.882236ms
Jan 17 18:01:14.551: INFO: Pod "downwardapi-volume-e02775c8-1a81-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01247353s
Jan 17 18:01:16.558: INFO: Pod "downwardapi-volume-e02775c8-1a81-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019458906s
STEP: Saw pod success
Jan 17 18:01:16.559: INFO: Pod "downwardapi-volume-e02775c8-1a81-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 18:01:16.599: INFO: Trying to get logs from node node1 pod downwardapi-volume-e02775c8-1a81-11e9-a4b6-0a580af40269 container client-container: <nil>
STEP: delete the pod
Jan 17 18:01:16.629: INFO: Waiting for pod downwardapi-volume-e02775c8-1a81-11e9-a4b6-0a580af40269 to disappear
Jan 17 18:01:16.638: INFO: Pod downwardapi-volume-e02775c8-1a81-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:01:16.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-skgml" for this suite.
Jan 17 18:01:22.688: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:01:22.780: INFO: namespace: e2e-tests-projected-skgml, resource: bindings, ignored listing per whitelist
Jan 17 18:01:22.780: INFO: namespace e2e-tests-projected-skgml deletion completed in 6.108616529s

• [SLOW TEST:10.398 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:01:22.780: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Jan 17 18:01:22.852: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 create -f - --namespace=e2e-tests-kubectl-cmcgr'
Jan 17 18:01:22.975: INFO: stderr: ""
Jan 17 18:01:22.975: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Jan 17 18:01:23.980: INFO: Selector matched 1 pods for map[app:redis]
Jan 17 18:01:23.980: INFO: Found 0 / 1
Jan 17 18:01:24.977: INFO: Selector matched 1 pods for map[app:redis]
Jan 17 18:01:24.977: INFO: Found 0 / 1
Jan 17 18:01:25.993: INFO: Selector matched 1 pods for map[app:redis]
Jan 17 18:01:25.993: INFO: Found 1 / 1
Jan 17 18:01:25.993: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Jan 17 18:01:26.042: INFO: Selector matched 1 pods for map[app:redis]
Jan 17 18:01:26.042: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jan 17 18:01:26.042: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 patch pod redis-master-nftjv --namespace=e2e-tests-kubectl-cmcgr -p {"metadata":{"annotations":{"x":"y"}}}'
Jan 17 18:01:26.147: INFO: stderr: ""
Jan 17 18:01:26.147: INFO: stdout: "pod/redis-master-nftjv patched\n"
STEP: checking annotations
Jan 17 18:01:26.151: INFO: Selector matched 1 pods for map[app:redis]
Jan 17 18:01:26.151: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:01:26.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-cmcgr" for this suite.
Jan 17 18:01:48.205: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:01:48.290: INFO: namespace: e2e-tests-kubectl-cmcgr, resource: bindings, ignored listing per whitelist
Jan 17 18:01:48.295: INFO: namespace e2e-tests-kubectl-cmcgr deletion completed in 22.108251504s

• [SLOW TEST:25.516 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:01:48.301: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1358
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 17 18:01:48.404: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-r8bfp'
Jan 17 18:01:48.503: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jan 17 18:01:48.503: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Jan 17 18:01:48.519: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Jan 17 18:01:48.521: INFO: scanned /root for discovery docs: <nil>
Jan 17 18:01:48.521: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-r8bfp'
Jan 17 18:02:04.472: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Jan 17 18:02:04.472: INFO: stdout: "Created e2e-test-nginx-rc-07d26aeeb7151178d7ad0aba45f431ee\nScaling up e2e-test-nginx-rc-07d26aeeb7151178d7ad0aba45f431ee from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-07d26aeeb7151178d7ad0aba45f431ee up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-07d26aeeb7151178d7ad0aba45f431ee to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Jan 17 18:02:04.472: INFO: stdout: "Created e2e-test-nginx-rc-07d26aeeb7151178d7ad0aba45f431ee\nScaling up e2e-test-nginx-rc-07d26aeeb7151178d7ad0aba45f431ee from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-07d26aeeb7151178d7ad0aba45f431ee up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-07d26aeeb7151178d7ad0aba45f431ee to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Jan 17 18:02:04.472: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-r8bfp'
Jan 17 18:02:04.585: INFO: stderr: ""
Jan 17 18:02:04.585: INFO: stdout: "e2e-test-nginx-rc-07d26aeeb7151178d7ad0aba45f431ee-zgrr6 "
Jan 17 18:02:04.585: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 get pods e2e-test-nginx-rc-07d26aeeb7151178d7ad0aba45f431ee-zgrr6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-r8bfp'
Jan 17 18:02:04.688: INFO: stderr: ""
Jan 17 18:02:04.688: INFO: stdout: "true"
Jan 17 18:02:04.688: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 get pods e2e-test-nginx-rc-07d26aeeb7151178d7ad0aba45f431ee-zgrr6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-r8bfp'
Jan 17 18:02:04.800: INFO: stderr: ""
Jan 17 18:02:04.800: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Jan 17 18:02:04.800: INFO: e2e-test-nginx-rc-07d26aeeb7151178d7ad0aba45f431ee-zgrr6 is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1364
Jan 17 18:02:04.800: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-r8bfp'
Jan 17 18:02:04.883: INFO: stderr: ""
Jan 17 18:02:04.883: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:02:04.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-r8bfp" for this suite.
Jan 17 18:02:10.916: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:02:10.969: INFO: namespace: e2e-tests-kubectl-r8bfp, resource: bindings, ignored listing per whitelist
Jan 17 18:02:11.019: INFO: namespace e2e-tests-kubectl-r8bfp deletion completed in 6.121154593s

• [SLOW TEST:22.718 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:02:11.020: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Jan 17 18:02:11.191: INFO: Waiting up to 5m0s for pod "client-containers-0319fb77-1a82-11e9-a4b6-0a580af40269" in namespace "e2e-tests-containers-5cx77" to be "success or failure"
Jan 17 18:02:11.206: INFO: Pod "client-containers-0319fb77-1a82-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 14.478184ms
Jan 17 18:02:13.210: INFO: Pod "client-containers-0319fb77-1a82-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018946497s
STEP: Saw pod success
Jan 17 18:02:13.211: INFO: Pod "client-containers-0319fb77-1a82-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 18:02:13.215: INFO: Trying to get logs from node node1 pod client-containers-0319fb77-1a82-11e9-a4b6-0a580af40269 container test-container: <nil>
STEP: delete the pod
Jan 17 18:02:13.242: INFO: Waiting for pod client-containers-0319fb77-1a82-11e9-a4b6-0a580af40269 to disappear
Jan 17 18:02:13.261: INFO: Pod client-containers-0319fb77-1a82-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:02:13.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-5cx77" for this suite.
Jan 17 18:02:19.350: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:02:19.423: INFO: namespace: e2e-tests-containers-5cx77, resource: bindings, ignored listing per whitelist
Jan 17 18:02:19.424: INFO: namespace e2e-tests-containers-5cx77 deletion completed in 6.092613768s

• [SLOW TEST:8.404 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:02:19.428: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-vtdqx/configmap-test-081afae1-1a82-11e9-a4b6-0a580af40269
STEP: Creating a pod to test consume configMaps
Jan 17 18:02:19.576: INFO: Waiting up to 5m0s for pod "pod-configmaps-081c5458-1a82-11e9-a4b6-0a580af40269" in namespace "e2e-tests-configmap-vtdqx" to be "success or failure"
Jan 17 18:02:19.606: INFO: Pod "pod-configmaps-081c5458-1a82-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 28.811001ms
Jan 17 18:02:21.608: INFO: Pod "pod-configmaps-081c5458-1a82-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031175158s
Jan 17 18:02:23.642: INFO: Pod "pod-configmaps-081c5458-1a82-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.065720765s
STEP: Saw pod success
Jan 17 18:02:23.643: INFO: Pod "pod-configmaps-081c5458-1a82-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 18:02:23.650: INFO: Trying to get logs from node node1 pod pod-configmaps-081c5458-1a82-11e9-a4b6-0a580af40269 container env-test: <nil>
STEP: delete the pod
Jan 17 18:02:23.683: INFO: Waiting for pod pod-configmaps-081c5458-1a82-11e9-a4b6-0a580af40269 to disappear
Jan 17 18:02:23.698: INFO: Pod pod-configmaps-081c5458-1a82-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:02:23.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-vtdqx" for this suite.
Jan 17 18:02:29.723: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:02:29.769: INFO: namespace: e2e-tests-configmap-vtdqx, resource: bindings, ignored listing per whitelist
Jan 17 18:02:29.820: INFO: namespace e2e-tests-configmap-vtdqx deletion completed in 6.118258754s

• [SLOW TEST:10.393 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:02:29.822: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jan 17 18:02:30.083: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:02:35.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-dgq66" for this suite.
Jan 17 18:02:41.246: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:02:41.315: INFO: namespace: e2e-tests-init-container-dgq66, resource: bindings, ignored listing per whitelist
Jan 17 18:02:41.336: INFO: namespace e2e-tests-init-container-dgq66 deletion completed in 6.108111774s

• [SLOW TEST:11.515 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:02:41.336: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 17 18:02:41.406: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-7b6pq'
Jan 17 18:02:41.509: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jan 17 18:02:41.509: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Jan 17 18:02:41.512: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-7b6pq'
Jan 17 18:02:41.604: INFO: stderr: ""
Jan 17 18:02:41.604: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:02:41.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-7b6pq" for this suite.
Jan 17 18:03:03.660: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:03:03.714: INFO: namespace: e2e-tests-kubectl-7b6pq, resource: bindings, ignored listing per whitelist
Jan 17 18:03:03.761: INFO: namespace e2e-tests-kubectl-7b6pq deletion completed in 22.121817541s

• [SLOW TEST:22.425 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:03:03.763: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:03:07.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-wsmln" for this suite.
Jan 17 18:03:46.030: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:03:46.070: INFO: namespace: e2e-tests-kubelet-test-wsmln, resource: bindings, ignored listing per whitelist
Jan 17 18:03:46.103: INFO: namespace e2e-tests-kubelet-test-wsmln deletion completed in 38.099763748s

• [SLOW TEST:42.340 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a read only busybox container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:186
    should not write to root filesystem [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:03:46.105: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-5mmj4
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan 17 18:03:46.231: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan 17 18:04:12.408: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.244.2.128 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-5mmj4 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 17 18:04:12.408: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
Jan 17 18:04:13.455: INFO: Found all expected endpoints: [netserver-0]
Jan 17 18:04:13.458: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.244.1.39 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-5mmj4 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 17 18:04:13.459: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
Jan 17 18:04:14.523: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:04:14.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-5mmj4" for this suite.
Jan 17 18:04:36.556: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:04:36.601: INFO: namespace: e2e-tests-pod-network-test-5mmj4, resource: bindings, ignored listing per whitelist
Jan 17 18:04:36.625: INFO: namespace e2e-tests-pod-network-test-5mmj4 deletion completed in 22.093441914s

• [SLOW TEST:50.520 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:04:36.625: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 17 18:04:36.738: INFO: Waiting up to 5m0s for pod "downwardapi-volume-59de5780-1a82-11e9-a4b6-0a580af40269" in namespace "e2e-tests-downward-api-t9hbv" to be "success or failure"
Jan 17 18:04:36.748: INFO: Pod "downwardapi-volume-59de5780-1a82-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 7.494758ms
Jan 17 18:04:38.756: INFO: Pod "downwardapi-volume-59de5780-1a82-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015280611s
Jan 17 18:04:40.765: INFO: Pod "downwardapi-volume-59de5780-1a82-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024225968s
STEP: Saw pod success
Jan 17 18:04:40.765: INFO: Pod "downwardapi-volume-59de5780-1a82-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 18:04:40.803: INFO: Trying to get logs from node node1 pod downwardapi-volume-59de5780-1a82-11e9-a4b6-0a580af40269 container client-container: <nil>
STEP: delete the pod
Jan 17 18:04:40.848: INFO: Waiting for pod downwardapi-volume-59de5780-1a82-11e9-a4b6-0a580af40269 to disappear
Jan 17 18:04:40.858: INFO: Pod downwardapi-volume-59de5780-1a82-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:04:40.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-t9hbv" for this suite.
Jan 17 18:04:46.911: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:04:46.972: INFO: namespace: e2e-tests-downward-api-t9hbv, resource: bindings, ignored listing per whitelist
Jan 17 18:04:46.979: INFO: namespace e2e-tests-downward-api-t9hbv deletion completed in 6.088304318s

• [SLOW TEST:10.354 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:04:46.983: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jan 17 18:04:51.677: INFO: Successfully updated pod "labelsupdate60067c64-1a82-11e9-a4b6-0a580af40269"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:04:53.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-pmgxp" for this suite.
Jan 17 18:05:15.780: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:05:15.861: INFO: namespace: e2e-tests-downward-api-pmgxp, resource: bindings, ignored listing per whitelist
Jan 17 18:05:15.875: INFO: namespace e2e-tests-downward-api-pmgxp deletion completed in 22.128758367s

• [SLOW TEST:28.892 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:05:15.875: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Jan 17 18:05:15.976: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-v99z7" to be "success or failure"
Jan 17 18:05:15.988: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 11.450874ms
Jan 17 18:05:18.026: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.049704487s
Jan 17 18:05:20.033: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.056666204s
STEP: Saw pod success
Jan 17 18:05:20.033: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Jan 17 18:05:20.079: INFO: Trying to get logs from node node1 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Jan 17 18:05:20.120: INFO: Waiting for pod pod-host-path-test to disappear
Jan 17 18:05:20.132: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:05:20.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-v99z7" for this suite.
Jan 17 18:05:26.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:05:26.219: INFO: namespace: e2e-tests-hostpath-v99z7, resource: bindings, ignored listing per whitelist
Jan 17 18:05:26.243: INFO: namespace e2e-tests-hostpath-v99z7 deletion completed in 6.102406406s

• [SLOW TEST:10.369 seconds]
[sig-storage] HostPath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:05:26.245: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Jan 17 18:05:26.404: INFO: Waiting up to 5m0s for pod "pod-7777f6ed-1a82-11e9-a4b6-0a580af40269" in namespace "e2e-tests-emptydir-npwsw" to be "success or failure"
Jan 17 18:05:26.415: INFO: Pod "pod-7777f6ed-1a82-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 10.672782ms
Jan 17 18:05:28.420: INFO: Pod "pod-7777f6ed-1a82-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015917348s
Jan 17 18:05:30.428: INFO: Pod "pod-7777f6ed-1a82-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023277838s
STEP: Saw pod success
Jan 17 18:05:30.431: INFO: Pod "pod-7777f6ed-1a82-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 18:05:30.442: INFO: Trying to get logs from node node1 pod pod-7777f6ed-1a82-11e9-a4b6-0a580af40269 container test-container: <nil>
STEP: delete the pod
Jan 17 18:05:30.482: INFO: Waiting for pod pod-7777f6ed-1a82-11e9-a4b6-0a580af40269 to disappear
Jan 17 18:05:30.506: INFO: Pod pod-7777f6ed-1a82-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:05:30.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-npwsw" for this suite.
Jan 17 18:05:36.592: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:05:36.645: INFO: namespace: e2e-tests-emptydir-npwsw, resource: bindings, ignored listing per whitelist
Jan 17 18:05:36.674: INFO: namespace e2e-tests-emptydir-npwsw deletion completed in 6.110481542s

• [SLOW TEST:10.429 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:05:36.674: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-7dd32d8a-1a82-11e9-a4b6-0a580af40269
STEP: Creating a pod to test consume secrets
Jan 17 18:05:37.076: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7dd45ab0-1a82-11e9-a4b6-0a580af40269" in namespace "e2e-tests-projected-dm5v2" to be "success or failure"
Jan 17 18:05:37.085: INFO: Pod "pod-projected-secrets-7dd45ab0-1a82-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 9.263686ms
Jan 17 18:05:39.087: INFO: Pod "pod-projected-secrets-7dd45ab0-1a82-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011281996s
STEP: Saw pod success
Jan 17 18:05:39.087: INFO: Pod "pod-projected-secrets-7dd45ab0-1a82-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 18:05:39.089: INFO: Trying to get logs from node node1 pod pod-projected-secrets-7dd45ab0-1a82-11e9-a4b6-0a580af40269 container secret-volume-test: <nil>
STEP: delete the pod
Jan 17 18:05:39.115: INFO: Waiting for pod pod-projected-secrets-7dd45ab0-1a82-11e9-a4b6-0a580af40269 to disappear
Jan 17 18:05:39.125: INFO: Pod pod-projected-secrets-7dd45ab0-1a82-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:05:39.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dm5v2" for this suite.
Jan 17 18:05:45.163: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:05:45.265: INFO: namespace: e2e-tests-projected-dm5v2, resource: bindings, ignored listing per whitelist
Jan 17 18:05:45.305: INFO: namespace e2e-tests-projected-dm5v2 deletion completed in 6.16126284s

• [SLOW TEST:8.631 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:05:45.305: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jan 17 18:05:50.182: INFO: Successfully updated pod "labelsupdate82e1fd50-1a82-11e9-a4b6-0a580af40269"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:05:52.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bk6s4" for this suite.
Jan 17 18:06:14.264: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:06:14.310: INFO: namespace: e2e-tests-projected-bk6s4, resource: bindings, ignored listing per whitelist
Jan 17 18:06:14.378: INFO: namespace e2e-tests-projected-bk6s4 deletion completed in 22.147278844s

• [SLOW TEST:29.074 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:06:14.379: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:06:18.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-rqdv8" for this suite.
Jan 17 18:06:24.598: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:06:24.651: INFO: namespace: e2e-tests-kubelet-test-rqdv8, resource: bindings, ignored listing per whitelist
Jan 17 18:06:24.684: INFO: namespace e2e-tests-kubelet-test-rqdv8 deletion completed in 6.127194643s

• [SLOW TEST:10.306 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:06:24.693: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Jan 17 18:06:32.985: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan 17 18:06:33.034: INFO: Pod pod-with-poststart-http-hook still exists
Jan 17 18:06:35.035: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan 17 18:06:35.049: INFO: Pod pod-with-poststart-http-hook still exists
Jan 17 18:06:37.035: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan 17 18:06:37.060: INFO: Pod pod-with-poststart-http-hook still exists
Jan 17 18:06:39.036: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan 17 18:06:39.043: INFO: Pod pod-with-poststart-http-hook still exists
Jan 17 18:06:41.035: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan 17 18:06:41.046: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:06:41.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-lrl9c" for this suite.
Jan 17 18:07:03.093: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:07:03.162: INFO: namespace: e2e-tests-container-lifecycle-hook-lrl9c, resource: bindings, ignored listing per whitelist
Jan 17 18:07:03.177: INFO: namespace e2e-tests-container-lifecycle-hook-lrl9c deletion completed in 22.11258251s

• [SLOW TEST:38.484 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:07:03.178: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-fnb52
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan 17 18:07:03.390: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan 17 18:07:25.635: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.2.129:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-fnb52 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 17 18:07:25.635: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
Jan 17 18:07:25.711: INFO: Found all expected endpoints: [netserver-0]
Jan 17 18:07:25.713: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.1.50:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-fnb52 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 17 18:07:25.713: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
Jan 17 18:07:25.756: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:07:25.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-fnb52" for this suite.
Jan 17 18:07:47.782: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:07:47.881: INFO: namespace: e2e-tests-pod-network-test-fnb52, resource: bindings, ignored listing per whitelist
Jan 17 18:07:47.901: INFO: namespace e2e-tests-pod-network-test-fnb52 deletion completed in 22.141485454s

• [SLOW TEST:44.723 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:07:47.901: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 17 18:07:47.977: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cbdab52d-1a82-11e9-a4b6-0a580af40269" in namespace "e2e-tests-projected-qk8nm" to be "success or failure"
Jan 17 18:07:47.987: INFO: Pod "downwardapi-volume-cbdab52d-1a82-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 10.284634ms
Jan 17 18:07:49.995: INFO: Pod "downwardapi-volume-cbdab52d-1a82-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018438485s
Jan 17 18:07:52.027: INFO: Pod "downwardapi-volume-cbdab52d-1a82-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.04956004s
STEP: Saw pod success
Jan 17 18:07:52.027: INFO: Pod "downwardapi-volume-cbdab52d-1a82-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 18:07:52.032: INFO: Trying to get logs from node node1 pod downwardapi-volume-cbdab52d-1a82-11e9-a4b6-0a580af40269 container client-container: <nil>
STEP: delete the pod
Jan 17 18:07:52.110: INFO: Waiting for pod downwardapi-volume-cbdab52d-1a82-11e9-a4b6-0a580af40269 to disappear
Jan 17 18:07:52.113: INFO: Pod downwardapi-volume-cbdab52d-1a82-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:07:52.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qk8nm" for this suite.
Jan 17 18:07:58.150: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:07:58.227: INFO: namespace: e2e-tests-projected-qk8nm, resource: bindings, ignored listing per whitelist
Jan 17 18:07:58.302: INFO: namespace e2e-tests-projected-qk8nm deletion completed in 6.184678165s

• [SLOW TEST:10.401 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:07:58.303: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Jan 17 18:08:06.569: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan 17 18:08:06.615: INFO: Pod pod-with-prestop-http-hook still exists
Jan 17 18:08:08.616: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan 17 18:08:08.625: INFO: Pod pod-with-prestop-http-hook still exists
Jan 17 18:08:10.616: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan 17 18:08:10.640: INFO: Pod pod-with-prestop-http-hook still exists
Jan 17 18:08:12.616: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan 17 18:08:12.621: INFO: Pod pod-with-prestop-http-hook still exists
Jan 17 18:08:14.617: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan 17 18:08:14.626: INFO: Pod pod-with-prestop-http-hook still exists
Jan 17 18:08:16.615: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan 17 18:08:16.619: INFO: Pod pod-with-prestop-http-hook still exists
Jan 17 18:08:18.616: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan 17 18:08:18.620: INFO: Pod pod-with-prestop-http-hook still exists
Jan 17 18:08:20.616: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan 17 18:08:20.619: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:08:20.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-nk2jl" for this suite.
Jan 17 18:08:42.703: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:08:42.715: INFO: namespace: e2e-tests-container-lifecycle-hook-nk2jl, resource: bindings, ignored listing per whitelist
Jan 17 18:08:42.758: INFO: namespace e2e-tests-container-lifecycle-hook-nk2jl deletion completed in 22.078781946s

• [SLOW TEST:44.455 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:08:42.761: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-eca327c5-1a82-11e9-a4b6-0a580af40269
STEP: Creating a pod to test consume configMaps
Jan 17 18:08:42.989: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-eca47d4a-1a82-11e9-a4b6-0a580af40269" in namespace "e2e-tests-projected-5wzfl" to be "success or failure"
Jan 17 18:08:43.003: INFO: Pod "pod-projected-configmaps-eca47d4a-1a82-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 13.941862ms
Jan 17 18:08:45.043: INFO: Pod "pod-projected-configmaps-eca47d4a-1a82-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.053567869s
Jan 17 18:08:47.052: INFO: Pod "pod-projected-configmaps-eca47d4a-1a82-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.062748205s
STEP: Saw pod success
Jan 17 18:08:47.053: INFO: Pod "pod-projected-configmaps-eca47d4a-1a82-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 18:08:47.106: INFO: Trying to get logs from node node1 pod pod-projected-configmaps-eca47d4a-1a82-11e9-a4b6-0a580af40269 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 17 18:08:47.140: INFO: Waiting for pod pod-projected-configmaps-eca47d4a-1a82-11e9-a4b6-0a580af40269 to disappear
Jan 17 18:08:47.151: INFO: Pod pod-projected-configmaps-eca47d4a-1a82-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:08:47.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5wzfl" for this suite.
Jan 17 18:08:53.184: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:08:53.227: INFO: namespace: e2e-tests-projected-5wzfl, resource: bindings, ignored listing per whitelist
Jan 17 18:08:53.242: INFO: namespace e2e-tests-projected-5wzfl deletion completed in 6.085865344s

• [SLOW TEST:10.481 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:08:53.243: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 17 18:08:53.318: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f2cce797-1a82-11e9-a4b6-0a580af40269" in namespace "e2e-tests-projected-wqxvz" to be "success or failure"
Jan 17 18:08:53.328: INFO: Pod "downwardapi-volume-f2cce797-1a82-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 10.041667ms
Jan 17 18:08:55.337: INFO: Pod "downwardapi-volume-f2cce797-1a82-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018216696s
Jan 17 18:08:57.375: INFO: Pod "downwardapi-volume-f2cce797-1a82-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.056761939s
STEP: Saw pod success
Jan 17 18:08:57.375: INFO: Pod "downwardapi-volume-f2cce797-1a82-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 18:08:57.381: INFO: Trying to get logs from node node1 pod downwardapi-volume-f2cce797-1a82-11e9-a4b6-0a580af40269 container client-container: <nil>
STEP: delete the pod
Jan 17 18:08:57.430: INFO: Waiting for pod downwardapi-volume-f2cce797-1a82-11e9-a4b6-0a580af40269 to disappear
Jan 17 18:08:57.432: INFO: Pod downwardapi-volume-f2cce797-1a82-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:08:57.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wqxvz" for this suite.
Jan 17 18:09:03.458: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:09:03.544: INFO: namespace: e2e-tests-projected-wqxvz, resource: bindings, ignored listing per whitelist
Jan 17 18:09:03.562: INFO: namespace e2e-tests-projected-wqxvz deletion completed in 6.124938877s

• [SLOW TEST:10.319 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:09:03.562: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 17 18:09:03.739: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Jan 17 18:09:03.764: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:03.767: INFO: Number of nodes with available pods: 0
Jan 17 18:09:03.767: INFO: Node node1 is running more than one daemon pod
Jan 17 18:09:04.774: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:04.795: INFO: Number of nodes with available pods: 0
Jan 17 18:09:04.795: INFO: Node node1 is running more than one daemon pod
Jan 17 18:09:05.799: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:05.822: INFO: Number of nodes with available pods: 0
Jan 17 18:09:05.822: INFO: Node node1 is running more than one daemon pod
Jan 17 18:09:06.774: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:06.777: INFO: Number of nodes with available pods: 0
Jan 17 18:09:06.777: INFO: Node node1 is running more than one daemon pod
Jan 17 18:09:07.784: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:07.808: INFO: Number of nodes with available pods: 2
Jan 17 18:09:07.808: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Jan 17 18:09:07.854: INFO: Wrong image for pod: daemon-set-7jn9g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:07.854: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:07.870: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:08.881: INFO: Wrong image for pod: daemon-set-7jn9g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:08.882: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:08.947: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:09.883: INFO: Wrong image for pod: daemon-set-7jn9g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:09.883: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:09.901: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:10.881: INFO: Wrong image for pod: daemon-set-7jn9g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:10.881: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:10.946: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:11.878: INFO: Wrong image for pod: daemon-set-7jn9g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:11.878: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:11.889: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:12.883: INFO: Wrong image for pod: daemon-set-7jn9g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:12.883: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:12.956: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:13.892: INFO: Wrong image for pod: daemon-set-7jn9g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:13.892: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:13.910: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:14.880: INFO: Wrong image for pod: daemon-set-7jn9g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:14.880: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:14.950: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:15.896: INFO: Wrong image for pod: daemon-set-7jn9g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:15.897: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:15.903: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:16.882: INFO: Wrong image for pod: daemon-set-7jn9g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:16.882: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:16.940: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:17.880: INFO: Wrong image for pod: daemon-set-7jn9g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:17.881: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:17.905: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:18.882: INFO: Wrong image for pod: daemon-set-7jn9g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:18.882: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:18.943: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:19.880: INFO: Wrong image for pod: daemon-set-7jn9g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:19.880: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:19.895: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:20.877: INFO: Wrong image for pod: daemon-set-7jn9g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:20.877: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:20.928: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:21.874: INFO: Wrong image for pod: daemon-set-7jn9g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:21.874: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:21.880: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:22.881: INFO: Wrong image for pod: daemon-set-7jn9g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:22.883: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:22.946: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:23.882: INFO: Wrong image for pod: daemon-set-7jn9g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:23.882: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:23.907: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:24.878: INFO: Wrong image for pod: daemon-set-7jn9g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:24.878: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:24.931: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:25.882: INFO: Wrong image for pod: daemon-set-7jn9g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:25.882: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:25.900: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:26.878: INFO: Wrong image for pod: daemon-set-7jn9g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:26.878: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:26.948: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:27.880: INFO: Wrong image for pod: daemon-set-7jn9g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:27.881: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:27.903: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:28.881: INFO: Wrong image for pod: daemon-set-7jn9g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:28.881: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:29.138: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:29.881: INFO: Wrong image for pod: daemon-set-7jn9g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:29.882: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:29.898: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:30.882: INFO: Wrong image for pod: daemon-set-7jn9g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:30.882: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:30.937: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:31.880: INFO: Wrong image for pod: daemon-set-7jn9g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:31.880: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:31.896: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:32.881: INFO: Wrong image for pod: daemon-set-7jn9g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:32.881: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:32.945: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:33.883: INFO: Wrong image for pod: daemon-set-7jn9g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:33.883: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:33.900: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:34.880: INFO: Wrong image for pod: daemon-set-7jn9g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:34.881: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:34.956: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:35.882: INFO: Wrong image for pod: daemon-set-7jn9g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:35.882: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:35.899: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:36.874: INFO: Wrong image for pod: daemon-set-7jn9g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:36.874: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:36.923: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:37.884: INFO: Wrong image for pod: daemon-set-7jn9g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:37.885: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:37.893: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:38.883: INFO: Wrong image for pod: daemon-set-7jn9g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:38.883: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:38.946: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:39.881: INFO: Wrong image for pod: daemon-set-7jn9g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:39.881: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:39.900: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:40.880: INFO: Wrong image for pod: daemon-set-7jn9g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:40.881: INFO: Pod daemon-set-7jn9g is not available
Jan 17 18:09:40.881: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:40.945: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:41.882: INFO: Pod daemon-set-857gv is not available
Jan 17 18:09:41.883: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:41.901: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:42.881: INFO: Pod daemon-set-857gv is not available
Jan 17 18:09:42.881: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:42.943: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:43.882: INFO: Pod daemon-set-857gv is not available
Jan 17 18:09:43.882: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:43.903: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:44.880: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:44.945: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:45.880: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:45.897: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:46.883: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:46.939: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:47.880: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:47.898: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:48.881: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:48.943: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:49.879: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:49.895: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:50.880: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:50.945: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:51.878: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:51.890: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:52.881: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:52.946: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:53.881: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:53.897: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:54.880: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:54.941: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:55.881: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:55.899: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:56.881: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:56.943: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:57.881: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:57.898: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:58.880: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:58.947: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:09:59.881: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:09:59.898: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:10:00.879: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:10:00.946: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:10:01.881: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:10:01.898: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:10:02.881: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:10:03.147: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:10:03.881: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:10:03.897: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:10:04.880: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:10:04.949: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:10:05.882: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:10:05.899: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:10:06.880: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:10:06.945: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:10:07.881: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:10:07.899: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:10:08.881: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:10:08.947: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:10:09.881: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:10:09.897: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:10:10.878: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:10:10.936: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:10:11.881: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:10:11.898: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:10:12.880: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:10:12.946: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:10:13.881: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:10:13.897: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:10:14.878: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:10:14.941: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:10:15.880: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:10:15.880: INFO: Pod daemon-set-zbb99 is not available
Jan 17 18:10:15.915: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:10:16.881: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:10:16.882: INFO: Pod daemon-set-zbb99 is not available
Jan 17 18:10:16.944: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:10:17.880: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:10:17.880: INFO: Pod daemon-set-zbb99 is not available
Jan 17 18:10:17.897: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:10:18.893: INFO: Wrong image for pod: daemon-set-zbb99. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 17 18:10:18.893: INFO: Pod daemon-set-zbb99 is not available
Jan 17 18:10:18.955: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:10:19.876: INFO: Pod daemon-set-s5fx5 is not available
Jan 17 18:10:19.885: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Jan 17 18:10:19.893: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:10:19.898: INFO: Number of nodes with available pods: 1
Jan 17 18:10:19.898: INFO: Node node1 is running more than one daemon pod
Jan 17 18:10:20.912: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:10:20.931: INFO: Number of nodes with available pods: 1
Jan 17 18:10:20.931: INFO: Node node1 is running more than one daemon pod
Jan 17 18:10:21.923: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:10:21.937: INFO: Number of nodes with available pods: 2
Jan 17 18:10:21.937: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-b4psf, will wait for the garbage collector to delete the pods
Jan 17 18:10:22.040: INFO: Deleting DaemonSet.extensions daemon-set took: 17.98371ms
Jan 17 18:10:22.141: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.321642ms
Jan 17 18:10:29.148: INFO: Number of nodes with available pods: 0
Jan 17 18:10:29.149: INFO: Number of running nodes: 0, number of available pods: 0
Jan 17 18:10:29.159: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-b4psf/daemonsets","resourceVersion":"84515"},"items":null}

Jan 17 18:10:29.167: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-b4psf/pods","resourceVersion":"84515"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:10:29.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-b4psf" for this suite.
Jan 17 18:10:35.244: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:10:35.306: INFO: namespace: e2e-tests-daemonsets-b4psf, resource: bindings, ignored listing per whitelist
Jan 17 18:10:35.326: INFO: namespace e2e-tests-daemonsets-b4psf deletion completed in 6.109638733s

• [SLOW TEST:91.763 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:10:35.327: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-2fa6f705-1a83-11e9-a4b6-0a580af40269
STEP: Creating secret with name s-test-opt-upd-2fa6f735-1a83-11e9-a4b6-0a580af40269
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-2fa6f705-1a83-11e9-a4b6-0a580af40269
STEP: Updating secret s-test-opt-upd-2fa6f735-1a83-11e9-a4b6-0a580af40269
STEP: Creating secret with name s-test-opt-create-2fa6f747-1a83-11e9-a4b6-0a580af40269
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:11:50.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qnrbb" for this suite.
Jan 17 18:12:12.622: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:12:12.687: INFO: namespace: e2e-tests-projected-qnrbb, resource: bindings, ignored listing per whitelist
Jan 17 18:12:12.725: INFO: namespace e2e-tests-projected-qnrbb deletion completed in 22.122169696s

• [SLOW TEST:97.398 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:12:12.725: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-69c4faf0-1a83-11e9-a4b6-0a580af40269
STEP: Creating a pod to test consume secrets
Jan 17 18:12:12.940: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-69c979a4-1a83-11e9-a4b6-0a580af40269" in namespace "e2e-tests-projected-zljdf" to be "success or failure"
Jan 17 18:12:12.952: INFO: Pod "pod-projected-secrets-69c979a4-1a83-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 11.780983ms
Jan 17 18:12:14.960: INFO: Pod "pod-projected-secrets-69c979a4-1a83-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020036771s
Jan 17 18:12:16.964: INFO: Pod "pod-projected-secrets-69c979a4-1a83-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023798651s
STEP: Saw pod success
Jan 17 18:12:16.964: INFO: Pod "pod-projected-secrets-69c979a4-1a83-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 18:12:16.999: INFO: Trying to get logs from node node1 pod pod-projected-secrets-69c979a4-1a83-11e9-a4b6-0a580af40269 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan 17 18:12:17.073: INFO: Waiting for pod pod-projected-secrets-69c979a4-1a83-11e9-a4b6-0a580af40269 to disappear
Jan 17 18:12:17.083: INFO: Pod pod-projected-secrets-69c979a4-1a83-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:12:17.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zljdf" for this suite.
Jan 17 18:12:23.157: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:12:23.227: INFO: namespace: e2e-tests-projected-zljdf, resource: bindings, ignored listing per whitelist
Jan 17 18:12:23.241: INFO: namespace e2e-tests-projected-zljdf deletion completed in 6.12478838s

• [SLOW TEST:10.516 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:12:23.241: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Jan 17 18:12:23.450: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-8xz5l,SelfLink:/api/v1/namespaces/e2e-tests-watch-8xz5l/configmaps/e2e-watch-test-configmap-a,UID:700ba674-1a83-11e9-8458-5254003c4592,ResourceVersion:84780,Generation:0,CreationTimestamp:2019-01-17 18:12:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 17 18:12:23.450: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-8xz5l,SelfLink:/api/v1/namespaces/e2e-tests-watch-8xz5l/configmaps/e2e-watch-test-configmap-a,UID:700ba674-1a83-11e9-8458-5254003c4592,ResourceVersion:84780,Generation:0,CreationTimestamp:2019-01-17 18:12:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Jan 17 18:12:33.462: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-8xz5l,SelfLink:/api/v1/namespaces/e2e-tests-watch-8xz5l/configmaps/e2e-watch-test-configmap-a,UID:700ba674-1a83-11e9-8458-5254003c4592,ResourceVersion:84795,Generation:0,CreationTimestamp:2019-01-17 18:12:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Jan 17 18:12:33.463: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-8xz5l,SelfLink:/api/v1/namespaces/e2e-tests-watch-8xz5l/configmaps/e2e-watch-test-configmap-a,UID:700ba674-1a83-11e9-8458-5254003c4592,ResourceVersion:84795,Generation:0,CreationTimestamp:2019-01-17 18:12:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Jan 17 18:12:43.491: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-8xz5l,SelfLink:/api/v1/namespaces/e2e-tests-watch-8xz5l/configmaps/e2e-watch-test-configmap-a,UID:700ba674-1a83-11e9-8458-5254003c4592,ResourceVersion:84810,Generation:0,CreationTimestamp:2019-01-17 18:12:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 17 18:12:43.492: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-8xz5l,SelfLink:/api/v1/namespaces/e2e-tests-watch-8xz5l/configmaps/e2e-watch-test-configmap-a,UID:700ba674-1a83-11e9-8458-5254003c4592,ResourceVersion:84810,Generation:0,CreationTimestamp:2019-01-17 18:12:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Jan 17 18:12:53.509: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-8xz5l,SelfLink:/api/v1/namespaces/e2e-tests-watch-8xz5l/configmaps/e2e-watch-test-configmap-a,UID:700ba674-1a83-11e9-8458-5254003c4592,ResourceVersion:84825,Generation:0,CreationTimestamp:2019-01-17 18:12:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 17 18:12:53.509: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-8xz5l,SelfLink:/api/v1/namespaces/e2e-tests-watch-8xz5l/configmaps/e2e-watch-test-configmap-a,UID:700ba674-1a83-11e9-8458-5254003c4592,ResourceVersion:84825,Generation:0,CreationTimestamp:2019-01-17 18:12:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Jan 17 18:13:03.517: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-8xz5l,SelfLink:/api/v1/namespaces/e2e-tests-watch-8xz5l/configmaps/e2e-watch-test-configmap-b,UID:87eebec1-1a83-11e9-8458-5254003c4592,ResourceVersion:84840,Generation:0,CreationTimestamp:2019-01-17 18:13:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 17 18:13:03.518: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-8xz5l,SelfLink:/api/v1/namespaces/e2e-tests-watch-8xz5l/configmaps/e2e-watch-test-configmap-b,UID:87eebec1-1a83-11e9-8458-5254003c4592,ResourceVersion:84840,Generation:0,CreationTimestamp:2019-01-17 18:13:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Jan 17 18:13:13.523: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-8xz5l,SelfLink:/api/v1/namespaces/e2e-tests-watch-8xz5l/configmaps/e2e-watch-test-configmap-b,UID:87eebec1-1a83-11e9-8458-5254003c4592,ResourceVersion:84855,Generation:0,CreationTimestamp:2019-01-17 18:13:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 17 18:13:13.523: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-8xz5l,SelfLink:/api/v1/namespaces/e2e-tests-watch-8xz5l/configmaps/e2e-watch-test-configmap-b,UID:87eebec1-1a83-11e9-8458-5254003c4592,ResourceVersion:84855,Generation:0,CreationTimestamp:2019-01-17 18:13:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:13:23.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-8xz5l" for this suite.
Jan 17 18:13:29.643: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:13:29.688: INFO: namespace: e2e-tests-watch-8xz5l, resource: bindings, ignored listing per whitelist
Jan 17 18:13:29.718: INFO: namespace e2e-tests-watch-8xz5l deletion completed in 6.132412855s

• [SLOW TEST:66.479 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:13:29.725: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 17 18:13:29.933: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Jan 17 18:13:34.942: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jan 17 18:13:34.942: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan 17 18:13:34.973: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-7br5x,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-7br5x/deployments/test-cleanup-deployment,UID:9aac6a7d-1a83-11e9-8458-5254003c4592,ResourceVersion:84909,Generation:1,CreationTimestamp:2019-01-17 18:13:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Jan 17 18:13:34.976: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:13:34.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-7br5x" for this suite.
Jan 17 18:13:41.105: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:13:41.161: INFO: namespace: e2e-tests-deployment-7br5x, resource: bindings, ignored listing per whitelist
Jan 17 18:13:41.168: INFO: namespace e2e-tests-deployment-7br5x deletion completed in 6.1366844s

• [SLOW TEST:11.443 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:13:41.171: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-75v7d
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan 17 18:13:41.345: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan 17 18:14:07.541: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.62:8080/dial?request=hostName&protocol=udp&host=10.244.1.61&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-75v7d PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 17 18:14:07.541: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
Jan 17 18:14:07.589: INFO: Waiting for endpoints: map[]
Jan 17 18:14:07.593: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.62:8080/dial?request=hostName&protocol=udp&host=10.244.2.134&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-75v7d PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 17 18:14:07.594: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
Jan 17 18:14:07.640: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:14:07.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-75v7d" for this suite.
Jan 17 18:14:29.670: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:14:29.788: INFO: namespace: e2e-tests-pod-network-test-75v7d, resource: bindings, ignored listing per whitelist
Jan 17 18:14:29.797: INFO: namespace e2e-tests-pod-network-test-75v7d deletion completed in 22.149951808s

• [SLOW TEST:48.627 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:14:29.798: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 17 18:14:29.969: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 version --client'
Jan 17 18:14:30.022: INFO: stderr: ""
Jan 17 18:14:30.022: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Jan 17 18:14:30.025: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 create -f - --namespace=e2e-tests-kubectl-79rsj'
Jan 17 18:14:30.994: INFO: stderr: ""
Jan 17 18:14:30.995: INFO: stdout: "replicationcontroller/redis-master created\n"
Jan 17 18:14:30.995: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 create -f - --namespace=e2e-tests-kubectl-79rsj'
Jan 17 18:14:31.165: INFO: stderr: ""
Jan 17 18:14:31.165: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Jan 17 18:14:32.173: INFO: Selector matched 1 pods for map[app:redis]
Jan 17 18:14:32.173: INFO: Found 0 / 1
Jan 17 18:14:33.184: INFO: Selector matched 1 pods for map[app:redis]
Jan 17 18:14:33.184: INFO: Found 0 / 1
Jan 17 18:14:34.174: INFO: Selector matched 1 pods for map[app:redis]
Jan 17 18:14:34.174: INFO: Found 1 / 1
Jan 17 18:14:34.174: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jan 17 18:14:34.215: INFO: Selector matched 1 pods for map[app:redis]
Jan 17 18:14:34.215: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jan 17 18:14:34.215: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 describe pod redis-master-sdk92 --namespace=e2e-tests-kubectl-79rsj'
Jan 17 18:14:34.414: INFO: stderr: ""
Jan 17 18:14:34.414: INFO: stdout: "Name:               redis-master-sdk92\nNamespace:          e2e-tests-kubectl-79rsj\nPriority:           0\nPriorityClassName:  <none>\nNode:               node1/192.168.122.53\nStart Time:         Thu, 17 Jan 2019 18:14:31 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.244.1.63\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   cri-o://4792a24cbbea55aad69d42c70d599a7e78e75270f838f2640d5518ebecf683cd\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       gcr.io/kubernetes-e2e-test-images/redis@sha256:2238f5a02d2648d41cc94a88f084060fbfa860890220328eb92696bf2ac649c9\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Thu, 17 Jan 2019 18:14:33 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-tnllk (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-tnllk:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-tnllk\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  3s    default-scheduler  Successfully assigned e2e-tests-kubectl-79rsj/redis-master-sdk92 to node1\n  Normal  Pulled     1s    kubelet, node1     Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, node1     Created container\n  Normal  Started    1s    kubelet, node1     Started container\n"
Jan 17 18:14:34.416: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 describe rc redis-master --namespace=e2e-tests-kubectl-79rsj'
Jan 17 18:14:34.550: INFO: stderr: ""
Jan 17 18:14:34.550: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-79rsj\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-sdk92\n"
Jan 17 18:14:34.550: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 describe service redis-master --namespace=e2e-tests-kubectl-79rsj'
Jan 17 18:14:34.632: INFO: stderr: ""
Jan 17 18:14:34.632: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-79rsj\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.107.226.72\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.244.1.63:6379\nSession Affinity:  None\nEvents:            <none>\n"
Jan 17 18:14:34.656: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 describe node masteru'
Jan 17 18:14:35.064: INFO: stderr: ""
Jan 17 18:14:35.064: INFO: stdout: "Name:               masteru\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/hostname=masteru\n                    node-role.kubernetes.io/master=\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"b6:51:f8:18:c9:e9\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 192.168.122.16\n                    kubeadm.alpha.kubernetes.io/cri-socket: /var/run/crio/crio.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Thu, 17 Jan 2019 06:29:26 +0000\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Thu, 17 Jan 2019 18:14:33 +0000   Thu, 17 Jan 2019 06:29:17 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Thu, 17 Jan 2019 18:14:33 +0000   Thu, 17 Jan 2019 06:29:17 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Thu, 17 Jan 2019 18:14:33 +0000   Thu, 17 Jan 2019 06:29:17 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Thu, 17 Jan 2019 18:14:33 +0000   Thu, 17 Jan 2019 06:47:15 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  192.168.122.16\n  Hostname:    masteru\nCapacity:\n cpu:                3\n ephemeral-storage:  34596844Ki\n hugepages-2Mi:      0\n memory:             4037220Ki\n pods:               110\nAllocatable:\n cpu:                3\n ephemeral-storage:  31884451378\n hugepages-2Mi:      0\n memory:             3934820Ki\n pods:               110\nSystem Info:\n Machine ID:                 452a22ec9f204600a383265fc0c343e2\n System UUID:                aad97a82-d636-44ac-a3bf-3848cdece643\n Boot ID:                    37235ae1-f6eb-45f0-b374-9127486d4c90\n Kernel Version:             4.19.12-1-default\n OS Image:                   openSUSE Tumbleweed Kubic\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  cri-o://1.13.0\n Kubelet Version:            v1.13.0\n Kube-Proxy Version:         v1.13.0\nPodCIDR:                     10.244.0.0/24\nNon-terminated Pods:         (9 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-0dcc53c5f8e1419f-d8cmr    0 (0%)        0 (0%)      0 (0%)           0 (0%)         59m\n  kube-system                coredns-86c58d9df4-8xm2w                                   100m (3%)     0 (0%)      70Mi (1%)        170Mi (4%)     11h\n  kube-system                coredns-86c58d9df4-lx6qb                                   100m (3%)     0 (0%)      70Mi (1%)        170Mi (4%)     11h\n  kube-system                etcd-masteru                                               0 (0%)        0 (0%)      0 (0%)           0 (0%)         11h\n  kube-system                kube-apiserver-masteru                                     250m (8%)     0 (0%)      0 (0%)           0 (0%)         11h\n  kube-system                kube-controller-manager-masteru                            200m (6%)     0 (0%)      0 (0%)           0 (0%)         11h\n  kube-system                kube-flannel-ds-amd64-tjpxr                                100m (3%)     100m (3%)   50Mi (1%)        50Mi (1%)      11h\n  kube-system                kube-proxy-zg8dl                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         11h\n  kube-system                kube-scheduler-masteru                                     100m (3%)     0 (0%)      0 (0%)           0 (0%)         11h\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                850m (28%)  100m (3%)\n  memory             190Mi (4%)  390Mi (10%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:\n  Type     Reason         Age                   From              Message\n  ----     ------         ----                  ----              -------\n  Warning  ImageGCFailed  4m28s (x119 over 9h)  kubelet, masteru  failed to get imageFs info: no imagefs label for configured runtime\n"
Jan 17 18:14:35.064: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 describe namespace e2e-tests-kubectl-79rsj'
Jan 17 18:14:35.138: INFO: stderr: ""
Jan 17 18:14:35.138: INFO: stdout: "Name:         e2e-tests-kubectl-79rsj\nLabels:       e2e-framework=kubectl\n              e2e-run=74af5e5f-1a7b-11e9-a4b6-0a580af40269\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:14:35.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-79rsj" for this suite.
Jan 17 18:14:57.164: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:14:57.242: INFO: namespace: e2e-tests-kubectl-79rsj, resource: bindings, ignored listing per whitelist
Jan 17 18:14:57.244: INFO: namespace e2e-tests-kubectl-79rsj deletion completed in 22.101379055s

• [SLOW TEST:27.446 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:14:57.244: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Jan 17 18:15:01.326: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-cbc1d8a3-1a83-11e9-a4b6-0a580af40269,GenerateName:,Namespace:e2e-tests-events-szmvn,SelfLink:/api/v1/namespaces/e2e-tests-events-szmvn/pods/send-events-cbc1d8a3-1a83-11e9-a4b6-0a580af40269,UID:cbc2673f-1a83-11e9-8458-5254003c4592,ResourceVersion:85192,Generation:0,CreationTimestamp:2019-01-17 18:14:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 302752244,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l9wds {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l9wds,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-l9wds true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0011feeb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0011fefb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:14:57 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:15:00 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:15:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:14:57 +0000 UTC  }],Message:,Reason:,HostIP:192.168.122.53,PodIP:10.244.1.64,StartTime:2019-01-17 18:14:57 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-01-17 18:14:59 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:53c28beabd3509fb5b1d1185b2962e8204384cef7562982d8b216b71292aabf9 cri-o://ad0ed7f5e56fdca66d0c9ea0353c79a2a71b515e34429d41620151195b83f920}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Jan 17 18:15:03.336: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Jan 17 18:15:05.375: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:15:05.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-szmvn" for this suite.
Jan 17 18:15:43.500: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:15:43.578: INFO: namespace: e2e-tests-events-szmvn, resource: bindings, ignored listing per whitelist
Jan 17 18:15:43.582: INFO: namespace e2e-tests-events-szmvn deletion completed in 38.131778121s

• [SLOW TEST:46.338 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:15:43.584: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jan 17 18:15:43.800: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:15:51.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-wsnx9" for this suite.
Jan 17 18:16:13.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:16:13.472: INFO: namespace: e2e-tests-init-container-wsnx9, resource: bindings, ignored listing per whitelist
Jan 17 18:16:13.485: INFO: namespace e2e-tests-init-container-wsnx9 deletion completed in 22.141042038s

• [SLOW TEST:29.901 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:16:13.488: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 17 18:16:13.552: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 version'
Jan 17 18:16:13.643: INFO: stderr: ""
Jan 17 18:16:13.643: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.2\", GitCommit:\"cff46ab41ff0bb44d8584413b598ad8360ec1def\", GitTreeState:\"clean\", BuildDate:\"2019-01-10T23:28:14Z\", GoVersion:\"go1.11.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:16:13.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hhsxd" for this suite.
Jan 17 18:16:19.663: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:16:19.786: INFO: namespace: e2e-tests-kubectl-hhsxd, resource: bindings, ignored listing per whitelist
Jan 17 18:16:19.826: INFO: namespace e2e-tests-kubectl-hhsxd deletion completed in 6.175714705s

• [SLOW TEST:6.338 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:16:19.826: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 17 18:16:20.067: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:16:21.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-nnxmc" for this suite.
Jan 17 18:16:27.271: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:16:27.316: INFO: namespace: e2e-tests-custom-resource-definition-nnxmc, resource: bindings, ignored listing per whitelist
Jan 17 18:16:27.353: INFO: namespace e2e-tests-custom-resource-definition-nnxmc deletion completed in 6.115042582s

• [SLOW TEST:7.528 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:16:27.356: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Jan 17 18:16:28.107: INFO: created pod pod-service-account-defaultsa
Jan 17 18:16:28.107: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Jan 17 18:16:28.128: INFO: created pod pod-service-account-mountsa
Jan 17 18:16:28.129: INFO: pod pod-service-account-mountsa service account token volume mount: true
Jan 17 18:16:28.145: INFO: created pod pod-service-account-nomountsa
Jan 17 18:16:28.145: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Jan 17 18:16:28.161: INFO: created pod pod-service-account-defaultsa-mountspec
Jan 17 18:16:28.161: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Jan 17 18:16:28.190: INFO: created pod pod-service-account-mountsa-mountspec
Jan 17 18:16:28.190: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Jan 17 18:16:28.207: INFO: created pod pod-service-account-nomountsa-mountspec
Jan 17 18:16:28.208: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Jan 17 18:16:28.220: INFO: created pod pod-service-account-defaultsa-nomountspec
Jan 17 18:16:28.220: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Jan 17 18:16:28.231: INFO: created pod pod-service-account-mountsa-nomountspec
Jan 17 18:16:28.231: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Jan 17 18:16:28.242: INFO: created pod pod-service-account-nomountsa-nomountspec
Jan 17 18:16:28.242: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:16:28.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-9br4z" for this suite.
Jan 17 18:16:34.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:16:34.392: INFO: namespace: e2e-tests-svcaccounts-9br4z, resource: bindings, ignored listing per whitelist
Jan 17 18:16:34.424: INFO: namespace e2e-tests-svcaccounts-9br4z deletion completed in 6.097471567s

• [SLOW TEST:7.068 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:16:34.425: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-2lrzb
Jan 17 18:16:38.842: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-2lrzb
STEP: checking the pod's current state and verifying that restartCount is present
Jan 17 18:16:38.855: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:20:39.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-2lrzb" for this suite.
Jan 17 18:20:46.022: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:20:46.064: INFO: namespace: e2e-tests-container-probe-2lrzb, resource: bindings, ignored listing per whitelist
Jan 17 18:20:46.110: INFO: namespace e2e-tests-container-probe-2lrzb deletion completed in 6.100124487s

• [SLOW TEST:251.685 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:20:46.110: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 17 18:20:46.176: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:20:50.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-6v85s" for this suite.
Jan 17 18:21:28.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:21:28.405: INFO: namespace: e2e-tests-pods-6v85s, resource: bindings, ignored listing per whitelist
Jan 17 18:21:28.414: INFO: namespace e2e-tests-pods-6v85s deletion completed in 38.142745947s

• [SLOW TEST:42.304 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:21:28.414: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0117 18:21:29.794528      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 17 18:21:29.795: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:21:29.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-v6lsj" for this suite.
Jan 17 18:21:35.847: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:21:35.930: INFO: namespace: e2e-tests-gc-v6lsj, resource: bindings, ignored listing per whitelist
Jan 17 18:21:35.964: INFO: namespace e2e-tests-gc-v6lsj deletion completed in 6.146398557s

• [SLOW TEST:7.550 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:21:35.964: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 17 18:21:36.118: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
Jan 17 18:21:36.124: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-lxjg6/daemonsets","resourceVersion":"86066"},"items":null}

Jan 17 18:21:36.129: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-lxjg6/pods","resourceVersion":"86066"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:21:36.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-lxjg6" for this suite.
Jan 17 18:21:42.172: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:21:42.239: INFO: namespace: e2e-tests-daemonsets-lxjg6, resource: bindings, ignored listing per whitelist
Jan 17 18:21:42.243: INFO: namespace e2e-tests-daemonsets-lxjg6 deletion completed in 6.094516772s

S [SKIPPING] [6.279 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Jan 17 18:21:36.118: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:21:42.243: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-bd31cdcf-1a84-11e9-a4b6-0a580af40269
STEP: Creating a pod to test consume configMaps
Jan 17 18:21:42.393: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-bd34d74d-1a84-11e9-a4b6-0a580af40269" in namespace "e2e-tests-projected-s77pw" to be "success or failure"
Jan 17 18:21:42.403: INFO: Pod "pod-projected-configmaps-bd34d74d-1a84-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 10.461552ms
Jan 17 18:21:44.443: INFO: Pod "pod-projected-configmaps-bd34d74d-1a84-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.050274425s
Jan 17 18:21:46.452: INFO: Pod "pod-projected-configmaps-bd34d74d-1a84-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.059327953s
STEP: Saw pod success
Jan 17 18:21:46.452: INFO: Pod "pod-projected-configmaps-bd34d74d-1a84-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 18:21:46.463: INFO: Trying to get logs from node node1 pod pod-projected-configmaps-bd34d74d-1a84-11e9-a4b6-0a580af40269 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 17 18:21:46.510: INFO: Waiting for pod pod-projected-configmaps-bd34d74d-1a84-11e9-a4b6-0a580af40269 to disappear
Jan 17 18:21:46.516: INFO: Pod pod-projected-configmaps-bd34d74d-1a84-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:21:46.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-s77pw" for this suite.
Jan 17 18:21:52.543: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:21:52.623: INFO: namespace: e2e-tests-projected-s77pw, resource: bindings, ignored listing per whitelist
Jan 17 18:21:52.642: INFO: namespace e2e-tests-projected-s77pw deletion completed in 6.118955161s

• [SLOW TEST:10.399 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:21:52.643: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-c35ce7f4-1a84-11e9-a4b6-0a580af40269
STEP: Creating configMap with name cm-test-opt-upd-c35ce821-1a84-11e9-a4b6-0a580af40269
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-c35ce7f4-1a84-11e9-a4b6-0a580af40269
STEP: Updating configmap cm-test-opt-upd-c35ce821-1a84-11e9-a4b6-0a580af40269
STEP: Creating configMap with name cm-test-opt-create-c35ce832-1a84-11e9-a4b6-0a580af40269
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:23:11.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-cgvcm" for this suite.
Jan 17 18:23:34.025: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:23:34.217: INFO: namespace: e2e-tests-configmap-cgvcm, resource: bindings, ignored listing per whitelist
Jan 17 18:23:34.232: INFO: namespace e2e-tests-configmap-cgvcm deletion completed in 22.234471513s

• [SLOW TEST:101.590 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:23:34.233: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-v2qsh
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-v2qsh
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-v2qsh
Jan 17 18:23:34.375: INFO: Found 0 stateful pods, waiting for 1
Jan 17 18:23:44.385: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Jan 17 18:23:44.435: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 exec --namespace=e2e-tests-statefulset-v2qsh ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 17 18:23:44.607: INFO: stderr: ""
Jan 17 18:23:44.607: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 17 18:23:44.607: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 17 18:23:44.610: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jan 17 18:23:54.630: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan 17 18:23:54.630: INFO: Waiting for statefulset status.replicas updated to 0
Jan 17 18:23:54.662: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999536s
Jan 17 18:23:55.671: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.989215346s
Jan 17 18:23:56.681: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.978963923s
Jan 17 18:23:57.712: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.969872255s
Jan 17 18:23:58.721: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.938587448s
Jan 17 18:23:59.748: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.930209888s
Jan 17 18:24:00.758: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.90262329s
Jan 17 18:24:01.766: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.893401305s
Jan 17 18:24:02.776: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.884798774s
Jan 17 18:24:03.785: INFO: Verifying statefulset ss doesn't scale past 1 for another 874.73834ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-v2qsh
Jan 17 18:24:04.790: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 exec --namespace=e2e-tests-statefulset-v2qsh ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 17 18:24:04.978: INFO: stderr: ""
Jan 17 18:24:04.978: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 17 18:24:04.978: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 17 18:24:04.998: INFO: Found 1 stateful pods, waiting for 3
Jan 17 18:24:15.008: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 17 18:24:15.009: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 17 18:24:15.009: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Jan 17 18:24:15.036: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 exec --namespace=e2e-tests-statefulset-v2qsh ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 17 18:24:15.196: INFO: stderr: ""
Jan 17 18:24:15.196: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 17 18:24:15.196: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 17 18:24:15.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 exec --namespace=e2e-tests-statefulset-v2qsh ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 17 18:24:15.334: INFO: stderr: ""
Jan 17 18:24:15.334: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 17 18:24:15.334: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 17 18:24:15.334: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 exec --namespace=e2e-tests-statefulset-v2qsh ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 17 18:24:15.702: INFO: stderr: ""
Jan 17 18:24:15.702: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 17 18:24:15.702: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 17 18:24:15.702: INFO: Waiting for statefulset status.replicas updated to 0
Jan 17 18:24:15.712: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Jan 17 18:24:25.763: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan 17 18:24:25.763: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jan 17 18:24:25.763: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jan 17 18:24:25.787: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999504s
Jan 17 18:24:26.813: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.986837671s
Jan 17 18:24:27.840: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.961122863s
Jan 17 18:24:28.844: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.933509885s
Jan 17 18:24:29.858: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.930361629s
Jan 17 18:24:30.901: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.91609146s
Jan 17 18:24:31.915: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.872446784s
Jan 17 18:24:32.945: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.858569857s
Jan 17 18:24:33.959: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.828886822s
Jan 17 18:24:34.971: INFO: Verifying statefulset ss doesn't scale past 3 for another 815.038798ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-v2qsh
Jan 17 18:24:35.995: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 exec --namespace=e2e-tests-statefulset-v2qsh ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 17 18:24:36.121: INFO: stderr: ""
Jan 17 18:24:36.121: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 17 18:24:36.121: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 17 18:24:36.121: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 exec --namespace=e2e-tests-statefulset-v2qsh ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 17 18:24:36.262: INFO: stderr: ""
Jan 17 18:24:36.262: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 17 18:24:36.262: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 17 18:24:36.262: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 exec --namespace=e2e-tests-statefulset-v2qsh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 17 18:24:36.418: INFO: stderr: ""
Jan 17 18:24:36.418: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 17 18:24:36.418: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 17 18:24:36.418: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan 17 18:25:06.458: INFO: Deleting all statefulset in ns e2e-tests-statefulset-v2qsh
Jan 17 18:25:06.467: INFO: Scaling statefulset ss to 0
Jan 17 18:25:06.479: INFO: Waiting for statefulset status.replicas updated to 0
Jan 17 18:25:06.482: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:25:06.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-v2qsh" for this suite.
Jan 17 18:25:12.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:25:12.634: INFO: namespace: e2e-tests-statefulset-v2qsh, resource: bindings, ignored listing per whitelist
Jan 17 18:25:12.667: INFO: namespace e2e-tests-statefulset-v2qsh deletion completed in 6.110392911s

• [SLOW TEST:98.434 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:25:12.669: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-vqrmx
Jan 17 18:25:16.816: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-vqrmx
STEP: checking the pod's current state and verifying that restartCount is present
Jan 17 18:25:16.819: INFO: Initial restart count of pod liveness-http is 0
Jan 17 18:25:34.884: INFO: Restart count of pod e2e-tests-container-probe-vqrmx/liveness-http is now 1 (18.064767328s elapsed)
Jan 17 18:25:54.922: INFO: Restart count of pod e2e-tests-container-probe-vqrmx/liveness-http is now 2 (38.102987349s elapsed)
Jan 17 18:26:14.956: INFO: Restart count of pod e2e-tests-container-probe-vqrmx/liveness-http is now 3 (58.137408735s elapsed)
Jan 17 18:26:34.997: INFO: Restart count of pod e2e-tests-container-probe-vqrmx/liveness-http is now 4 (1m18.178008024s elapsed)
Jan 17 18:27:47.376: INFO: Restart count of pod e2e-tests-container-probe-vqrmx/liveness-http is now 5 (2m30.55678727s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:27:47.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-vqrmx" for this suite.
Jan 17 18:27:53.449: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:27:53.510: INFO: namespace: e2e-tests-container-probe-vqrmx, resource: bindings, ignored listing per whitelist
Jan 17 18:27:53.517: INFO: namespace e2e-tests-container-probe-vqrmx deletion completed in 6.088964655s

• [SLOW TEST:160.848 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:27:53.519: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-bs6p
STEP: Creating a pod to test atomic-volume-subpath
Jan 17 18:27:53.658: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-bs6p" in namespace "e2e-tests-subpath-sfj8x" to be "success or failure"
Jan 17 18:27:53.678: INFO: Pod "pod-subpath-test-configmap-bs6p": Phase="Pending", Reason="", readiness=false. Elapsed: 19.4738ms
Jan 17 18:27:55.718: INFO: Pod "pod-subpath-test-configmap-bs6p": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05998867s
Jan 17 18:27:57.722: INFO: Pod "pod-subpath-test-configmap-bs6p": Phase="Running", Reason="", readiness=false. Elapsed: 4.063634612s
Jan 17 18:27:59.725: INFO: Pod "pod-subpath-test-configmap-bs6p": Phase="Running", Reason="", readiness=false. Elapsed: 6.06699142s
Jan 17 18:28:01.729: INFO: Pod "pod-subpath-test-configmap-bs6p": Phase="Running", Reason="", readiness=false. Elapsed: 8.071136641s
Jan 17 18:28:03.732: INFO: Pod "pod-subpath-test-configmap-bs6p": Phase="Running", Reason="", readiness=false. Elapsed: 10.073975294s
Jan 17 18:28:05.736: INFO: Pod "pod-subpath-test-configmap-bs6p": Phase="Running", Reason="", readiness=false. Elapsed: 12.078276275s
Jan 17 18:28:07.744: INFO: Pod "pod-subpath-test-configmap-bs6p": Phase="Running", Reason="", readiness=false. Elapsed: 14.085777038s
Jan 17 18:28:09.747: INFO: Pod "pod-subpath-test-configmap-bs6p": Phase="Running", Reason="", readiness=false. Elapsed: 16.089248192s
Jan 17 18:28:11.758: INFO: Pod "pod-subpath-test-configmap-bs6p": Phase="Running", Reason="", readiness=false. Elapsed: 18.099891979s
Jan 17 18:28:13.769: INFO: Pod "pod-subpath-test-configmap-bs6p": Phase="Running", Reason="", readiness=false. Elapsed: 20.110779057s
Jan 17 18:28:15.795: INFO: Pod "pod-subpath-test-configmap-bs6p": Phase="Running", Reason="", readiness=false. Elapsed: 22.137106898s
Jan 17 18:28:17.802: INFO: Pod "pod-subpath-test-configmap-bs6p": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.144107945s
STEP: Saw pod success
Jan 17 18:28:17.803: INFO: Pod "pod-subpath-test-configmap-bs6p" satisfied condition "success or failure"
Jan 17 18:28:17.808: INFO: Trying to get logs from node node1 pod pod-subpath-test-configmap-bs6p container test-container-subpath-configmap-bs6p: <nil>
STEP: delete the pod
Jan 17 18:28:17.874: INFO: Waiting for pod pod-subpath-test-configmap-bs6p to disappear
Jan 17 18:28:17.877: INFO: Pod pod-subpath-test-configmap-bs6p no longer exists
STEP: Deleting pod pod-subpath-test-configmap-bs6p
Jan 17 18:28:17.877: INFO: Deleting pod "pod-subpath-test-configmap-bs6p" in namespace "e2e-tests-subpath-sfj8x"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:28:17.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-sfj8x" for this suite.
Jan 17 18:28:23.928: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:28:24.007: INFO: namespace: e2e-tests-subpath-sfj8x, resource: bindings, ignored listing per whitelist
Jan 17 18:28:24.009: INFO: namespace e2e-tests-subpath-sfj8x deletion completed in 6.104787001s

• [SLOW TEST:30.490 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:28:24.009: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 17 18:28:24.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-p8trg'
Jan 17 18:28:25.048: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jan 17 18:28:25.048: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1404
Jan 17 18:28:29.069: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-p8trg'
Jan 17 18:28:29.158: INFO: stderr: ""
Jan 17 18:28:29.158: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:28:29.159: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-p8trg" for this suite.
Jan 17 18:28:35.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:28:35.305: INFO: namespace: e2e-tests-kubectl-p8trg, resource: bindings, ignored listing per whitelist
Jan 17 18:28:35.342: INFO: namespace e2e-tests-kubectl-p8trg deletion completed in 6.119614061s

• [SLOW TEST:11.333 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:28:35.347: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jan 17 18:28:35.535: INFO: Waiting up to 5m0s for pod "pod-b373edfc-1a85-11e9-a4b6-0a580af40269" in namespace "e2e-tests-emptydir-k4clc" to be "success or failure"
Jan 17 18:28:35.547: INFO: Pod "pod-b373edfc-1a85-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 11.97958ms
Jan 17 18:28:37.555: INFO: Pod "pod-b373edfc-1a85-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020128783s
Jan 17 18:28:39.566: INFO: Pod "pod-b373edfc-1a85-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031122097s
STEP: Saw pod success
Jan 17 18:28:39.566: INFO: Pod "pod-b373edfc-1a85-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 18:28:39.578: INFO: Trying to get logs from node node1 pod pod-b373edfc-1a85-11e9-a4b6-0a580af40269 container test-container: <nil>
STEP: delete the pod
Jan 17 18:28:39.625: INFO: Waiting for pod pod-b373edfc-1a85-11e9-a4b6-0a580af40269 to disappear
Jan 17 18:28:39.636: INFO: Pod pod-b373edfc-1a85-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:28:39.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-k4clc" for this suite.
Jan 17 18:28:45.701: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:28:45.741: INFO: namespace: e2e-tests-emptydir-k4clc, resource: bindings, ignored listing per whitelist
Jan 17 18:28:45.759: INFO: namespace e2e-tests-emptydir-k4clc deletion completed in 6.072652702s

• [SLOW TEST:10.415 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:28:45.761: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-6k4t
STEP: Creating a pod to test atomic-volume-subpath
Jan 17 18:28:45.941: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-6k4t" in namespace "e2e-tests-subpath-tj4s9" to be "success or failure"
Jan 17 18:28:45.951: INFO: Pod "pod-subpath-test-projected-6k4t": Phase="Pending", Reason="", readiness=false. Elapsed: 10.072533ms
Jan 17 18:28:48.010: INFO: Pod "pod-subpath-test-projected-6k4t": Phase="Pending", Reason="", readiness=false. Elapsed: 2.069074474s
Jan 17 18:28:50.014: INFO: Pod "pod-subpath-test-projected-6k4t": Phase="Running", Reason="", readiness=false. Elapsed: 4.072737178s
Jan 17 18:28:52.019: INFO: Pod "pod-subpath-test-projected-6k4t": Phase="Running", Reason="", readiness=false. Elapsed: 6.078402046s
Jan 17 18:28:54.027: INFO: Pod "pod-subpath-test-projected-6k4t": Phase="Running", Reason="", readiness=false. Elapsed: 8.085891047s
Jan 17 18:28:56.036: INFO: Pod "pod-subpath-test-projected-6k4t": Phase="Running", Reason="", readiness=false. Elapsed: 10.095218592s
Jan 17 18:28:58.046: INFO: Pod "pod-subpath-test-projected-6k4t": Phase="Running", Reason="", readiness=false. Elapsed: 12.105472558s
Jan 17 18:29:00.053: INFO: Pod "pod-subpath-test-projected-6k4t": Phase="Running", Reason="", readiness=false. Elapsed: 14.112492606s
Jan 17 18:29:02.070: INFO: Pod "pod-subpath-test-projected-6k4t": Phase="Running", Reason="", readiness=false. Elapsed: 16.129471009s
Jan 17 18:29:04.079: INFO: Pod "pod-subpath-test-projected-6k4t": Phase="Running", Reason="", readiness=false. Elapsed: 18.13814884s
Jan 17 18:29:06.101: INFO: Pod "pod-subpath-test-projected-6k4t": Phase="Running", Reason="", readiness=false. Elapsed: 20.159660621s
Jan 17 18:29:08.103: INFO: Pod "pod-subpath-test-projected-6k4t": Phase="Running", Reason="", readiness=false. Elapsed: 22.162218544s
Jan 17 18:29:10.128: INFO: Pod "pod-subpath-test-projected-6k4t": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.187329938s
STEP: Saw pod success
Jan 17 18:29:10.128: INFO: Pod "pod-subpath-test-projected-6k4t" satisfied condition "success or failure"
Jan 17 18:29:10.138: INFO: Trying to get logs from node node1 pod pod-subpath-test-projected-6k4t container test-container-subpath-projected-6k4t: <nil>
STEP: delete the pod
Jan 17 18:29:10.171: INFO: Waiting for pod pod-subpath-test-projected-6k4t to disappear
Jan 17 18:29:10.180: INFO: Pod pod-subpath-test-projected-6k4t no longer exists
STEP: Deleting pod pod-subpath-test-projected-6k4t
Jan 17 18:29:10.181: INFO: Deleting pod "pod-subpath-test-projected-6k4t" in namespace "e2e-tests-subpath-tj4s9"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:29:10.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-tj4s9" for this suite.
Jan 17 18:29:16.213: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:29:16.296: INFO: namespace: e2e-tests-subpath-tj4s9, resource: bindings, ignored listing per whitelist
Jan 17 18:29:16.306: INFO: namespace e2e-tests-subpath-tj4s9 deletion completed in 6.117356626s

• [SLOW TEST:30.545 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:29:16.306: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-t79q
STEP: Creating a pod to test atomic-volume-subpath
Jan 17 18:29:16.463: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-t79q" in namespace "e2e-tests-subpath-fmkzj" to be "success or failure"
Jan 17 18:29:16.472: INFO: Pod "pod-subpath-test-downwardapi-t79q": Phase="Pending", Reason="", readiness=false. Elapsed: 9.679479ms
Jan 17 18:29:18.476: INFO: Pod "pod-subpath-test-downwardapi-t79q": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013610024s
Jan 17 18:29:20.511: INFO: Pod "pod-subpath-test-downwardapi-t79q": Phase="Pending", Reason="", readiness=false. Elapsed: 4.047986256s
Jan 17 18:29:22.514: INFO: Pod "pod-subpath-test-downwardapi-t79q": Phase="Running", Reason="", readiness=false. Elapsed: 6.05151218s
Jan 17 18:29:24.535: INFO: Pod "pod-subpath-test-downwardapi-t79q": Phase="Running", Reason="", readiness=false. Elapsed: 8.0721542s
Jan 17 18:29:26.543: INFO: Pod "pod-subpath-test-downwardapi-t79q": Phase="Running", Reason="", readiness=false. Elapsed: 10.080285257s
Jan 17 18:29:28.548: INFO: Pod "pod-subpath-test-downwardapi-t79q": Phase="Running", Reason="", readiness=false. Elapsed: 12.085649998s
Jan 17 18:29:30.552: INFO: Pod "pod-subpath-test-downwardapi-t79q": Phase="Running", Reason="", readiness=false. Elapsed: 14.089737721s
Jan 17 18:29:32.562: INFO: Pod "pod-subpath-test-downwardapi-t79q": Phase="Running", Reason="", readiness=false. Elapsed: 16.099862563s
Jan 17 18:29:34.571: INFO: Pod "pod-subpath-test-downwardapi-t79q": Phase="Running", Reason="", readiness=false. Elapsed: 18.10870826s
Jan 17 18:29:36.591: INFO: Pod "pod-subpath-test-downwardapi-t79q": Phase="Running", Reason="", readiness=false. Elapsed: 20.128008274s
Jan 17 18:29:38.595: INFO: Pod "pod-subpath-test-downwardapi-t79q": Phase="Running", Reason="", readiness=false. Elapsed: 22.131906356s
Jan 17 18:29:40.619: INFO: Pod "pod-subpath-test-downwardapi-t79q": Phase="Running", Reason="", readiness=false. Elapsed: 24.156217646s
Jan 17 18:29:42.625: INFO: Pod "pod-subpath-test-downwardapi-t79q": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.162604638s
STEP: Saw pod success
Jan 17 18:29:42.625: INFO: Pod "pod-subpath-test-downwardapi-t79q" satisfied condition "success or failure"
Jan 17 18:29:42.647: INFO: Trying to get logs from node node1 pod pod-subpath-test-downwardapi-t79q container test-container-subpath-downwardapi-t79q: <nil>
STEP: delete the pod
Jan 17 18:29:42.674: INFO: Waiting for pod pod-subpath-test-downwardapi-t79q to disappear
Jan 17 18:29:42.682: INFO: Pod pod-subpath-test-downwardapi-t79q no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-t79q
Jan 17 18:29:42.682: INFO: Deleting pod "pod-subpath-test-downwardapi-t79q" in namespace "e2e-tests-subpath-fmkzj"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:29:42.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-fmkzj" for this suite.
Jan 17 18:29:48.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:29:48.759: INFO: namespace: e2e-tests-subpath-fmkzj, resource: bindings, ignored listing per whitelist
Jan 17 18:29:48.782: INFO: namespace e2e-tests-subpath-fmkzj deletion completed in 6.085408523s

• [SLOW TEST:32.476 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:29:48.785: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 17 18:29:48.876: INFO: Waiting up to 5m0s for pod "downwardapi-volume-df2bb0c3-1a85-11e9-a4b6-0a580af40269" in namespace "e2e-tests-downward-api-smgm6" to be "success or failure"
Jan 17 18:29:48.886: INFO: Pod "downwardapi-volume-df2bb0c3-1a85-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 10.047526ms
Jan 17 18:29:50.890: INFO: Pod "downwardapi-volume-df2bb0c3-1a85-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014862267s
Jan 17 18:29:52.926: INFO: Pod "downwardapi-volume-df2bb0c3-1a85-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050524854s
STEP: Saw pod success
Jan 17 18:29:52.926: INFO: Pod "downwardapi-volume-df2bb0c3-1a85-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 18:29:52.930: INFO: Trying to get logs from node node1 pod downwardapi-volume-df2bb0c3-1a85-11e9-a4b6-0a580af40269 container client-container: <nil>
STEP: delete the pod
Jan 17 18:29:52.990: INFO: Waiting for pod downwardapi-volume-df2bb0c3-1a85-11e9-a4b6-0a580af40269 to disappear
Jan 17 18:29:52.993: INFO: Pod downwardapi-volume-df2bb0c3-1a85-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:29:52.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-smgm6" for this suite.
Jan 17 18:29:59.014: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:29:59.037: INFO: namespace: e2e-tests-downward-api-smgm6, resource: bindings, ignored listing per whitelist
Jan 17 18:29:59.089: INFO: namespace e2e-tests-downward-api-smgm6 deletion completed in 6.09130686s

• [SLOW TEST:10.305 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:29:59.094: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0117 18:30:09.343059      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 17 18:30:09.343: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:30:09.343: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-htsxx" for this suite.
Jan 17 18:30:15.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:30:15.421: INFO: namespace: e2e-tests-gc-htsxx, resource: bindings, ignored listing per whitelist
Jan 17 18:30:15.473: INFO: namespace e2e-tests-gc-htsxx deletion completed in 6.122276161s

• [SLOW TEST:16.379 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:30:15.479: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:30:15.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-qldfx" for this suite.
Jan 17 18:30:37.654: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:30:37.730: INFO: namespace: e2e-tests-pods-qldfx, resource: bindings, ignored listing per whitelist
Jan 17 18:30:37.736: INFO: namespace e2e-tests-pods-qldfx deletion completed in 22.101194989s

• [SLOW TEST:22.257 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:30:37.737: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jan 17 18:30:37.983: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:30:37.989: INFO: Number of nodes with available pods: 0
Jan 17 18:30:37.989: INFO: Node node1 is running more than one daemon pod
Jan 17 18:30:39.059: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:30:39.075: INFO: Number of nodes with available pods: 0
Jan 17 18:30:39.076: INFO: Node node1 is running more than one daemon pod
Jan 17 18:30:40.005: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:30:40.017: INFO: Number of nodes with available pods: 0
Jan 17 18:30:40.017: INFO: Node node1 is running more than one daemon pod
Jan 17 18:30:41.007: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:30:41.031: INFO: Number of nodes with available pods: 1
Jan 17 18:30:41.031: INFO: Node node1 is running more than one daemon pod
Jan 17 18:30:42.027: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:30:42.042: INFO: Number of nodes with available pods: 2
Jan 17 18:30:42.042: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Jan 17 18:30:42.079: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:30:42.094: INFO: Number of nodes with available pods: 1
Jan 17 18:30:42.095: INFO: Node node2 is running more than one daemon pod
Jan 17 18:30:43.125: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:30:43.133: INFO: Number of nodes with available pods: 1
Jan 17 18:30:43.134: INFO: Node node2 is running more than one daemon pod
Jan 17 18:30:44.113: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:30:44.124: INFO: Number of nodes with available pods: 1
Jan 17 18:30:44.124: INFO: Node node2 is running more than one daemon pod
Jan 17 18:30:45.112: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:30:45.136: INFO: Number of nodes with available pods: 1
Jan 17 18:30:45.137: INFO: Node node2 is running more than one daemon pod
Jan 17 18:30:46.131: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:30:46.148: INFO: Number of nodes with available pods: 1
Jan 17 18:30:46.149: INFO: Node node2 is running more than one daemon pod
Jan 17 18:30:47.106: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:30:47.112: INFO: Number of nodes with available pods: 1
Jan 17 18:30:47.112: INFO: Node node2 is running more than one daemon pod
Jan 17 18:30:48.113: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:30:48.140: INFO: Number of nodes with available pods: 1
Jan 17 18:30:48.141: INFO: Node node2 is running more than one daemon pod
Jan 17 18:30:49.130: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:30:49.141: INFO: Number of nodes with available pods: 1
Jan 17 18:30:49.141: INFO: Node node2 is running more than one daemon pod
Jan 17 18:30:50.111: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:30:50.130: INFO: Number of nodes with available pods: 1
Jan 17 18:30:50.130: INFO: Node node2 is running more than one daemon pod
Jan 17 18:30:51.111: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:30:51.135: INFO: Number of nodes with available pods: 1
Jan 17 18:30:51.135: INFO: Node node2 is running more than one daemon pod
Jan 17 18:30:52.122: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:30:52.128: INFO: Number of nodes with available pods: 1
Jan 17 18:30:52.128: INFO: Node node2 is running more than one daemon pod
Jan 17 18:30:53.110: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:30:53.122: INFO: Number of nodes with available pods: 1
Jan 17 18:30:53.122: INFO: Node node2 is running more than one daemon pod
Jan 17 18:30:54.112: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:30:54.136: INFO: Number of nodes with available pods: 1
Jan 17 18:30:54.136: INFO: Node node2 is running more than one daemon pod
Jan 17 18:30:55.131: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:30:55.143: INFO: Number of nodes with available pods: 1
Jan 17 18:30:55.143: INFO: Node node2 is running more than one daemon pod
Jan 17 18:30:56.111: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:30:56.124: INFO: Number of nodes with available pods: 1
Jan 17 18:30:56.124: INFO: Node node2 is running more than one daemon pod
Jan 17 18:30:57.103: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:30:57.123: INFO: Number of nodes with available pods: 1
Jan 17 18:30:57.123: INFO: Node node2 is running more than one daemon pod
Jan 17 18:30:58.131: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:30:58.140: INFO: Number of nodes with available pods: 1
Jan 17 18:30:58.141: INFO: Node node2 is running more than one daemon pod
Jan 17 18:30:59.098: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:30:59.101: INFO: Number of nodes with available pods: 1
Jan 17 18:30:59.101: INFO: Node node2 is running more than one daemon pod
Jan 17 18:31:00.112: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:31:00.136: INFO: Number of nodes with available pods: 1
Jan 17 18:31:00.136: INFO: Node node2 is running more than one daemon pod
Jan 17 18:31:01.126: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:31:01.131: INFO: Number of nodes with available pods: 1
Jan 17 18:31:01.131: INFO: Node node2 is running more than one daemon pod
Jan 17 18:31:02.110: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:31:02.126: INFO: Number of nodes with available pods: 1
Jan 17 18:31:02.126: INFO: Node node2 is running more than one daemon pod
Jan 17 18:31:03.134: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:31:03.150: INFO: Number of nodes with available pods: 1
Jan 17 18:31:03.150: INFO: Node node2 is running more than one daemon pod
Jan 17 18:31:04.127: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:31:04.137: INFO: Number of nodes with available pods: 1
Jan 17 18:31:04.138: INFO: Node node2 is running more than one daemon pod
Jan 17 18:31:05.109: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:31:05.144: INFO: Number of nodes with available pods: 1
Jan 17 18:31:05.144: INFO: Node node2 is running more than one daemon pod
Jan 17 18:31:06.129: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:31:06.140: INFO: Number of nodes with available pods: 1
Jan 17 18:31:06.141: INFO: Node node2 is running more than one daemon pod
Jan 17 18:31:07.115: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:31:07.124: INFO: Number of nodes with available pods: 1
Jan 17 18:31:07.124: INFO: Node node2 is running more than one daemon pod
Jan 17 18:31:08.114: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:31:08.147: INFO: Number of nodes with available pods: 1
Jan 17 18:31:08.147: INFO: Node node2 is running more than one daemon pod
Jan 17 18:31:09.124: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:31:09.135: INFO: Number of nodes with available pods: 1
Jan 17 18:31:09.135: INFO: Node node2 is running more than one daemon pod
Jan 17 18:31:10.106: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:31:10.113: INFO: Number of nodes with available pods: 1
Jan 17 18:31:10.113: INFO: Node node2 is running more than one daemon pod
Jan 17 18:31:11.113: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:31:11.139: INFO: Number of nodes with available pods: 1
Jan 17 18:31:11.139: INFO: Node node2 is running more than one daemon pod
Jan 17 18:31:12.117: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:31:12.120: INFO: Number of nodes with available pods: 1
Jan 17 18:31:12.120: INFO: Node node2 is running more than one daemon pod
Jan 17 18:31:13.110: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:31:13.123: INFO: Number of nodes with available pods: 1
Jan 17 18:31:13.123: INFO: Node node2 is running more than one daemon pod
Jan 17 18:31:14.112: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:31:14.139: INFO: Number of nodes with available pods: 1
Jan 17 18:31:14.139: INFO: Node node2 is running more than one daemon pod
Jan 17 18:31:15.121: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:31:15.123: INFO: Number of nodes with available pods: 1
Jan 17 18:31:15.123: INFO: Node node2 is running more than one daemon pod
Jan 17 18:31:16.115: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:31:16.119: INFO: Number of nodes with available pods: 1
Jan 17 18:31:16.119: INFO: Node node2 is running more than one daemon pod
Jan 17 18:31:17.112: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:31:17.125: INFO: Number of nodes with available pods: 1
Jan 17 18:31:17.126: INFO: Node node2 is running more than one daemon pod
Jan 17 18:31:18.108: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:31:18.123: INFO: Number of nodes with available pods: 2
Jan 17 18:31:18.124: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-qswqv, will wait for the garbage collector to delete the pods
Jan 17 18:31:18.194: INFO: Deleting DaemonSet.extensions daemon-set took: 15.615558ms
Jan 17 18:31:18.295: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.362972ms
Jan 17 18:31:59.198: INFO: Number of nodes with available pods: 0
Jan 17 18:31:59.198: INFO: Number of running nodes: 0, number of available pods: 0
Jan 17 18:31:59.201: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-qswqv/daemonsets","resourceVersion":"87602"},"items":null}

Jan 17 18:31:59.203: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-qswqv/pods","resourceVersion":"87602"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:31:59.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-qswqv" for this suite.
Jan 17 18:32:05.256: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:32:05.322: INFO: namespace: e2e-tests-daemonsets-qswqv, resource: bindings, ignored listing per whitelist
Jan 17 18:32:05.338: INFO: namespace e2e-tests-daemonsets-qswqv deletion completed in 6.106048566s

• [SLOW TEST:87.601 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:32:05.338: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0117 18:32:11.548597      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 17 18:32:11.549: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:32:11.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-9rtk9" for this suite.
Jan 17 18:32:17.687: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:32:17.743: INFO: namespace: e2e-tests-gc-9rtk9, resource: bindings, ignored listing per whitelist
Jan 17 18:32:17.763: INFO: namespace e2e-tests-gc-9rtk9 deletion completed in 6.184671917s

• [SLOW TEST:12.425 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:32:17.763: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Jan 17 18:32:17.843: INFO: Waiting up to 5m0s for pod "client-containers-37f721f5-1a86-11e9-a4b6-0a580af40269" in namespace "e2e-tests-containers-klh5w" to be "success or failure"
Jan 17 18:32:17.854: INFO: Pod "client-containers-37f721f5-1a86-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 10.713233ms
Jan 17 18:32:19.867: INFO: Pod "client-containers-37f721f5-1a86-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024057524s
Jan 17 18:32:21.907: INFO: Pod "client-containers-37f721f5-1a86-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.063515915s
STEP: Saw pod success
Jan 17 18:32:21.907: INFO: Pod "client-containers-37f721f5-1a86-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 18:32:21.920: INFO: Trying to get logs from node node1 pod client-containers-37f721f5-1a86-11e9-a4b6-0a580af40269 container test-container: <nil>
STEP: delete the pod
Jan 17 18:32:22.010: INFO: Waiting for pod client-containers-37f721f5-1a86-11e9-a4b6-0a580af40269 to disappear
Jan 17 18:32:22.013: INFO: Pod client-containers-37f721f5-1a86-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:32:22.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-klh5w" for this suite.
Jan 17 18:32:28.045: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:32:28.125: INFO: namespace: e2e-tests-containers-klh5w, resource: bindings, ignored listing per whitelist
Jan 17 18:32:28.125: INFO: namespace e2e-tests-containers-klh5w deletion completed in 6.106932532s

• [SLOW TEST:10.362 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:32:28.127: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 17 18:32:28.325: INFO: (0) /api/v1/nodes/node1/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 3.77477ms)
Jan 17 18:32:28.329: INFO: (1) /api/v1/nodes/node1/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 4.015424ms)
Jan 17 18:32:28.332: INFO: (2) /api/v1/nodes/node1/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 3.081508ms)
Jan 17 18:32:28.335: INFO: (3) /api/v1/nodes/node1/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 2.637657ms)
Jan 17 18:32:28.338: INFO: (4) /api/v1/nodes/node1/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 2.648951ms)
Jan 17 18:32:28.341: INFO: (5) /api/v1/nodes/node1/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 2.958836ms)
Jan 17 18:32:28.344: INFO: (6) /api/v1/nodes/node1/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 3.375023ms)
Jan 17 18:32:28.348: INFO: (7) /api/v1/nodes/node1/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 3.347702ms)
Jan 17 18:32:28.351: INFO: (8) /api/v1/nodes/node1/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 3.219854ms)
Jan 17 18:32:28.354: INFO: (9) /api/v1/nodes/node1/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 3.137725ms)
Jan 17 18:32:28.357: INFO: (10) /api/v1/nodes/node1/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 2.775333ms)
Jan 17 18:32:28.360: INFO: (11) /api/v1/nodes/node1/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 2.746422ms)
Jan 17 18:32:28.363: INFO: (12) /api/v1/nodes/node1/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 2.899177ms)
Jan 17 18:32:28.366: INFO: (13) /api/v1/nodes/node1/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 2.901145ms)
Jan 17 18:32:28.369: INFO: (14) /api/v1/nodes/node1/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 2.856308ms)
Jan 17 18:32:28.372: INFO: (15) /api/v1/nodes/node1/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 2.610586ms)
Jan 17 18:32:28.375: INFO: (16) /api/v1/nodes/node1/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 3.129965ms)
Jan 17 18:32:28.381: INFO: (17) /api/v1/nodes/node1/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 6.423988ms)
Jan 17 18:32:28.384: INFO: (18) /api/v1/nodes/node1/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 2.864102ms)
Jan 17 18:32:28.387: INFO: (19) /api/v1/nodes/node1/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 2.737713ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:32:28.387: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-pwd52" for this suite.
Jan 17 18:32:34.428: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:32:34.516: INFO: namespace: e2e-tests-proxy-pwd52, resource: bindings, ignored listing per whitelist
Jan 17 18:32:34.545: INFO: namespace e2e-tests-proxy-pwd52 deletion completed in 6.137901033s

• [SLOW TEST:6.419 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:32:34.546: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 17 18:32:34.739: INFO: Creating deployment "test-recreate-deployment"
Jan 17 18:32:34.752: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Jan 17 18:32:34.761: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Jan 17 18:32:36.785: INFO: Waiting deployment "test-recreate-deployment" to complete
Jan 17 18:32:36.790: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683346754, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683346754, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683346754, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683346754, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-5dfdcc846d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 17 18:32:38.812: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Jan 17 18:32:38.821: INFO: Updating deployment test-recreate-deployment
Jan 17 18:32:38.821: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan 17 18:32:38.977: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-kbnrh,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-kbnrh/deployments/test-recreate-deployment,UID:4209fc5d-1a86-11e9-8458-5254003c4592,ResourceVersion:87976,Generation:2,CreationTimestamp:2019-01-17 18:32:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-01-17 18:32:38 +0000 UTC 2019-01-17 18:32:38 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-01-17 18:32:38 +0000 UTC 2019-01-17 18:32:34 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-697fbf54bf" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Jan 17 18:32:38.981: INFO: New ReplicaSet "test-recreate-deployment-697fbf54bf" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf,GenerateName:,Namespace:e2e-tests-deployment-kbnrh,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-kbnrh/replicasets/test-recreate-deployment-697fbf54bf,UID:4481ab42-1a86-11e9-8458-5254003c4592,ResourceVersion:87973,Generation:1,CreationTimestamp:2019-01-17 18:32:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 4209fc5d-1a86-11e9-8458-5254003c4592 0xc0022b6757 0xc0022b6758}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 17 18:32:38.981: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Jan 17 18:32:38.981: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5dfdcc846d,GenerateName:,Namespace:e2e-tests-deployment-kbnrh,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-kbnrh/replicasets/test-recreate-deployment-5dfdcc846d,UID:420ce5b1-1a86-11e9-8458-5254003c4592,ResourceVersion:87965,Generation:2,CreationTimestamp:2019-01-17 18:32:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 4209fc5d-1a86-11e9-8458-5254003c4592 0xc0022b6697 0xc0022b6698}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 17 18:32:38.990: INFO: Pod "test-recreate-deployment-697fbf54bf-4td66" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf-4td66,GenerateName:test-recreate-deployment-697fbf54bf-,Namespace:e2e-tests-deployment-kbnrh,SelfLink:/api/v1/namespaces/e2e-tests-deployment-kbnrh/pods/test-recreate-deployment-697fbf54bf-4td66,UID:4482ebd9-1a86-11e9-8458-5254003c4592,ResourceVersion:87977,Generation:0,CreationTimestamp:2019-01-17 18:32:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-697fbf54bf 4481ab42-1a86-11e9-8458-5254003c4592 0xc0022b70d7 0xc0022b70d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8btz9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8btz9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8btz9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022b7150} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022b7170}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:32:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:32:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:32:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:32:38 +0000 UTC  }],Message:,Reason:,HostIP:192.168.122.53,PodIP:,StartTime:2019-01-17 18:32:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:32:38.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-kbnrh" for this suite.
Jan 17 18:32:45.075: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:32:45.112: INFO: namespace: e2e-tests-deployment-kbnrh, resource: bindings, ignored listing per whitelist
Jan 17 18:32:45.148: INFO: namespace e2e-tests-deployment-kbnrh deletion completed in 6.097115932s

• [SLOW TEST:10.602 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:32:45.150: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Jan 17 18:32:45.369: INFO: Waiting up to 5m0s for pod "pod-485c47b0-1a86-11e9-a4b6-0a580af40269" in namespace "e2e-tests-emptydir-hhcbt" to be "success or failure"
Jan 17 18:32:45.372: INFO: Pod "pod-485c47b0-1a86-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.705279ms
Jan 17 18:32:47.380: INFO: Pod "pod-485c47b0-1a86-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01075085s
Jan 17 18:32:49.388: INFO: Pod "pod-485c47b0-1a86-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019258376s
STEP: Saw pod success
Jan 17 18:32:49.389: INFO: Pod "pod-485c47b0-1a86-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 18:32:49.431: INFO: Trying to get logs from node node1 pod pod-485c47b0-1a86-11e9-a4b6-0a580af40269 container test-container: <nil>
STEP: delete the pod
Jan 17 18:32:49.489: INFO: Waiting for pod pod-485c47b0-1a86-11e9-a4b6-0a580af40269 to disappear
Jan 17 18:32:49.498: INFO: Pod pod-485c47b0-1a86-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:32:49.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-hhcbt" for this suite.
Jan 17 18:32:55.596: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:32:55.664: INFO: namespace: e2e-tests-emptydir-hhcbt, resource: bindings, ignored listing per whitelist
Jan 17 18:32:55.676: INFO: namespace e2e-tests-emptydir-hhcbt deletion completed in 6.139429265s

• [SLOW TEST:10.527 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:32:55.679: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-4e9cd35e-1a86-11e9-a4b6-0a580af40269
STEP: Creating a pod to test consume secrets
Jan 17 18:32:55.851: INFO: Waiting up to 5m0s for pod "pod-secrets-4e9dbab5-1a86-11e9-a4b6-0a580af40269" in namespace "e2e-tests-secrets-g7p4p" to be "success or failure"
Jan 17 18:32:55.858: INFO: Pod "pod-secrets-4e9dbab5-1a86-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 7.888602ms
Jan 17 18:32:57.861: INFO: Pod "pod-secrets-4e9dbab5-1a86-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010102024s
STEP: Saw pod success
Jan 17 18:32:57.861: INFO: Pod "pod-secrets-4e9dbab5-1a86-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 18:32:57.899: INFO: Trying to get logs from node node1 pod pod-secrets-4e9dbab5-1a86-11e9-a4b6-0a580af40269 container secret-volume-test: <nil>
STEP: delete the pod
Jan 17 18:32:57.958: INFO: Waiting for pod pod-secrets-4e9dbab5-1a86-11e9-a4b6-0a580af40269 to disappear
Jan 17 18:32:57.968: INFO: Pod pod-secrets-4e9dbab5-1a86-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:32:57.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-g7p4p" for this suite.
Jan 17 18:33:04.023: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:33:04.087: INFO: namespace: e2e-tests-secrets-g7p4p, resource: bindings, ignored listing per whitelist
Jan 17 18:33:04.108: INFO: namespace e2e-tests-secrets-g7p4p deletion completed in 6.104969686s

• [SLOW TEST:8.429 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:33:04.109: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:33:30.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-runtime-62r47" for this suite.
Jan 17 18:33:37.023: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:33:37.062: INFO: namespace: e2e-tests-container-runtime-62r47, resource: bindings, ignored listing per whitelist
Jan 17 18:33:37.107: INFO: namespace e2e-tests-container-runtime-62r47 deletion completed in 6.128384496s

• [SLOW TEST:32.998 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  blackbox test
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:33:37.107: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-kbhx4/secret-test-674f4008-1a86-11e9-a4b6-0a580af40269
STEP: Creating a pod to test consume secrets
Jan 17 18:33:37.286: INFO: Waiting up to 5m0s for pod "pod-configmaps-67505a4a-1a86-11e9-a4b6-0a580af40269" in namespace "e2e-tests-secrets-kbhx4" to be "success or failure"
Jan 17 18:33:37.294: INFO: Pod "pod-configmaps-67505a4a-1a86-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 8.440994ms
Jan 17 18:33:39.302: INFO: Pod "pod-configmaps-67505a4a-1a86-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016266808s
Jan 17 18:33:41.304: INFO: Pod "pod-configmaps-67505a4a-1a86-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018573977s
STEP: Saw pod success
Jan 17 18:33:41.304: INFO: Pod "pod-configmaps-67505a4a-1a86-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 18:33:41.343: INFO: Trying to get logs from node node1 pod pod-configmaps-67505a4a-1a86-11e9-a4b6-0a580af40269 container env-test: <nil>
STEP: delete the pod
Jan 17 18:33:41.419: INFO: Waiting for pod pod-configmaps-67505a4a-1a86-11e9-a4b6-0a580af40269 to disappear
Jan 17 18:33:41.439: INFO: Pod pod-configmaps-67505a4a-1a86-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:33:41.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-kbhx4" for this suite.
Jan 17 18:33:47.538: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:33:47.587: INFO: namespace: e2e-tests-secrets-kbhx4, resource: bindings, ignored listing per whitelist
Jan 17 18:33:47.608: INFO: namespace e2e-tests-secrets-kbhx4 deletion completed in 6.125135219s

• [SLOW TEST:10.501 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:33:47.609: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Jan 17 18:33:47.778: INFO: Pod name pod-release: Found 0 pods out of 1
Jan 17 18:33:52.788: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:33:53.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-6hc4t" for this suite.
Jan 17 18:33:59.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:34:00.137: INFO: namespace: e2e-tests-replication-controller-6hc4t, resource: bindings, ignored listing per whitelist
Jan 17 18:34:00.165: INFO: namespace e2e-tests-replication-controller-6hc4t deletion completed in 6.307853254s

• [SLOW TEST:12.557 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:34:00.169: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-pzjkf
I0117 18:34:00.323164      17 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-pzjkf, replica count: 1
I0117 18:34:01.374659      17 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0117 18:34:02.375443      17 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0117 18:34:03.375927      17 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jan 17 18:34:03.515: INFO: Created: latency-svc-g4nrp
Jan 17 18:34:03.548: INFO: Got endpoints: latency-svc-g4nrp [71.785858ms]
Jan 17 18:34:03.587: INFO: Created: latency-svc-7jk8m
Jan 17 18:34:03.592: INFO: Got endpoints: latency-svc-7jk8m [41.653071ms]
Jan 17 18:34:03.608: INFO: Created: latency-svc-w6t99
Jan 17 18:34:03.619: INFO: Got endpoints: latency-svc-w6t99 [70.91912ms]
Jan 17 18:34:03.633: INFO: Created: latency-svc-l9x7j
Jan 17 18:34:03.666: INFO: Got endpoints: latency-svc-l9x7j [114.916485ms]
Jan 17 18:34:03.677: INFO: Created: latency-svc-fdmks
Jan 17 18:34:03.691: INFO: Got endpoints: latency-svc-fdmks [139.918916ms]
Jan 17 18:34:03.706: INFO: Created: latency-svc-45ptz
Jan 17 18:34:03.719: INFO: Got endpoints: latency-svc-45ptz [167.921303ms]
Jan 17 18:34:03.735: INFO: Created: latency-svc-mmbnh
Jan 17 18:34:03.750: INFO: Got endpoints: latency-svc-mmbnh [198.27239ms]
Jan 17 18:34:03.766: INFO: Created: latency-svc-7tk4j
Jan 17 18:34:03.792: INFO: Got endpoints: latency-svc-7tk4j [240.840806ms]
Jan 17 18:34:03.799: INFO: Created: latency-svc-j6dk8
Jan 17 18:34:03.809: INFO: Got endpoints: latency-svc-j6dk8 [256.794687ms]
Jan 17 18:34:03.843: INFO: Created: latency-svc-kp84f
Jan 17 18:34:03.855: INFO: Got endpoints: latency-svc-kp84f [303.695285ms]
Jan 17 18:34:03.870: INFO: Created: latency-svc-n7h7b
Jan 17 18:34:03.886: INFO: Got endpoints: latency-svc-n7h7b [334.601841ms]
Jan 17 18:34:03.917: INFO: Created: latency-svc-sb5nc
Jan 17 18:34:03.925: INFO: Got endpoints: latency-svc-sb5nc [373.289597ms]
Jan 17 18:34:03.958: INFO: Created: latency-svc-nwfcj
Jan 17 18:34:03.973: INFO: Got endpoints: latency-svc-nwfcj [421.248203ms]
Jan 17 18:34:03.978: INFO: Created: latency-svc-r6nr9
Jan 17 18:34:03.990: INFO: Got endpoints: latency-svc-r6nr9 [438.908975ms]
Jan 17 18:34:04.003: INFO: Created: latency-svc-rq8d2
Jan 17 18:34:04.041: INFO: Got endpoints: latency-svc-rq8d2 [489.015919ms]
Jan 17 18:34:04.050: INFO: Created: latency-svc-jqb22
Jan 17 18:34:04.063: INFO: Got endpoints: latency-svc-jqb22 [511.415878ms]
Jan 17 18:34:04.078: INFO: Created: latency-svc-7fjvq
Jan 17 18:34:04.088: INFO: Got endpoints: latency-svc-7fjvq [495.56018ms]
Jan 17 18:34:04.103: INFO: Created: latency-svc-4xkkv
Jan 17 18:34:04.116: INFO: Got endpoints: latency-svc-4xkkv [496.685893ms]
Jan 17 18:34:04.135: INFO: Created: latency-svc-45nv8
Jan 17 18:34:04.165: INFO: Got endpoints: latency-svc-45nv8 [498.407009ms]
Jan 17 18:34:04.167: INFO: Created: latency-svc-hv6vm
Jan 17 18:34:04.182: INFO: Got endpoints: latency-svc-hv6vm [490.711211ms]
Jan 17 18:34:04.197: INFO: Created: latency-svc-6n944
Jan 17 18:34:04.209: INFO: Got endpoints: latency-svc-6n944 [489.330289ms]
Jan 17 18:34:04.221: INFO: Created: latency-svc-n4kft
Jan 17 18:34:04.231: INFO: Got endpoints: latency-svc-n4kft [481.324456ms]
Jan 17 18:34:04.247: INFO: Created: latency-svc-nvf6b
Jan 17 18:34:04.258: INFO: Got endpoints: latency-svc-nvf6b [466.291205ms]
Jan 17 18:34:04.300: INFO: Created: latency-svc-db4zg
Jan 17 18:34:04.309: INFO: Got endpoints: latency-svc-db4zg [500.019666ms]
Jan 17 18:34:04.321: INFO: Created: latency-svc-5xsjj
Jan 17 18:34:04.334: INFO: Got endpoints: latency-svc-5xsjj [478.262814ms]
Jan 17 18:34:04.348: INFO: Created: latency-svc-8hm4g
Jan 17 18:34:04.360: INFO: Got endpoints: latency-svc-8hm4g [473.458986ms]
Jan 17 18:34:04.375: INFO: Created: latency-svc-hjwtn
Jan 17 18:34:04.388: INFO: Got endpoints: latency-svc-hjwtn [463.319545ms]
Jan 17 18:34:04.415: INFO: Created: latency-svc-mw7cb
Jan 17 18:34:04.425: INFO: Got endpoints: latency-svc-mw7cb [452.454038ms]
Jan 17 18:34:04.441: INFO: Created: latency-svc-pzhxr
Jan 17 18:34:04.456: INFO: Got endpoints: latency-svc-pzhxr [465.569083ms]
Jan 17 18:34:04.474: INFO: Created: latency-svc-8k6kk
Jan 17 18:34:04.484: INFO: Got endpoints: latency-svc-8k6kk [443.313865ms]
Jan 17 18:34:04.503: INFO: Created: latency-svc-j644m
Jan 17 18:34:04.512: INFO: Got endpoints: latency-svc-j644m [448.854879ms]
Jan 17 18:34:04.539: INFO: Created: latency-svc-mfd5m
Jan 17 18:34:04.554: INFO: Got endpoints: latency-svc-mfd5m [465.976601ms]
Jan 17 18:34:04.571: INFO: Created: latency-svc-mk7fv
Jan 17 18:34:04.578: INFO: Got endpoints: latency-svc-mk7fv [461.879464ms]
Jan 17 18:34:04.595: INFO: Created: latency-svc-mtgct
Jan 17 18:34:04.609: INFO: Got endpoints: latency-svc-mtgct [443.909255ms]
Jan 17 18:34:04.641: INFO: Created: latency-svc-ktgxm
Jan 17 18:34:04.669: INFO: Got endpoints: latency-svc-ktgxm [486.717907ms]
Jan 17 18:34:04.686: INFO: Created: latency-svc-h95qr
Jan 17 18:34:04.700: INFO: Got endpoints: latency-svc-h95qr [491.511502ms]
Jan 17 18:34:04.721: INFO: Created: latency-svc-wz4gt
Jan 17 18:34:04.789: INFO: Got endpoints: latency-svc-wz4gt [557.863957ms]
Jan 17 18:34:04.791: INFO: Created: latency-svc-b9cn5
Jan 17 18:34:04.805: INFO: Got endpoints: latency-svc-b9cn5 [104.63619ms]
Jan 17 18:34:04.837: INFO: Created: latency-svc-ckch5
Jan 17 18:34:04.847: INFO: Got endpoints: latency-svc-ckch5 [588.259281ms]
Jan 17 18:34:04.856: INFO: Created: latency-svc-rvnn6
Jan 17 18:34:04.867: INFO: Got endpoints: latency-svc-rvnn6 [557.921684ms]
Jan 17 18:34:04.881: INFO: Created: latency-svc-lnm6z
Jan 17 18:34:04.910: INFO: Got endpoints: latency-svc-lnm6z [576.29513ms]
Jan 17 18:34:04.924: INFO: Created: latency-svc-vfgxk
Jan 17 18:34:04.934: INFO: Got endpoints: latency-svc-vfgxk [573.912309ms]
Jan 17 18:34:04.948: INFO: Created: latency-svc-8km6s
Jan 17 18:34:04.961: INFO: Got endpoints: latency-svc-8km6s [572.64879ms]
Jan 17 18:34:04.978: INFO: Created: latency-svc-rfqvn
Jan 17 18:34:04.991: INFO: Got endpoints: latency-svc-rfqvn [565.361808ms]
Jan 17 18:34:05.001: INFO: Created: latency-svc-lrt5l
Jan 17 18:34:05.035: INFO: Got endpoints: latency-svc-lrt5l [579.212935ms]
Jan 17 18:34:05.048: INFO: Created: latency-svc-vpfkk
Jan 17 18:34:05.051: INFO: Got endpoints: latency-svc-vpfkk [567.213767ms]
Jan 17 18:34:05.067: INFO: Created: latency-svc-ssnjv
Jan 17 18:34:05.083: INFO: Got endpoints: latency-svc-ssnjv [570.982419ms]
Jan 17 18:34:05.096: INFO: Created: latency-svc-mwglg
Jan 17 18:34:05.105: INFO: Got endpoints: latency-svc-mwglg [550.982703ms]
Jan 17 18:34:05.122: INFO: Created: latency-svc-vfxf4
Jan 17 18:34:05.135: INFO: Got endpoints: latency-svc-vfxf4 [557.031153ms]
Jan 17 18:34:05.193: INFO: Created: latency-svc-m8mk2
Jan 17 18:34:05.197: INFO: Got endpoints: latency-svc-m8mk2 [588.044428ms]
Jan 17 18:34:05.215: INFO: Created: latency-svc-7cb5s
Jan 17 18:34:05.229: INFO: Got endpoints: latency-svc-7cb5s [560.661765ms]
Jan 17 18:34:05.241: INFO: Created: latency-svc-cg7c8
Jan 17 18:34:05.255: INFO: Got endpoints: latency-svc-cg7c8 [465.380671ms]
Jan 17 18:34:05.276: INFO: Created: latency-svc-hndrq
Jan 17 18:34:05.304: INFO: Got endpoints: latency-svc-hndrq [498.738196ms]
Jan 17 18:34:05.310: INFO: Created: latency-svc-zgwbx
Jan 17 18:34:05.321: INFO: Got endpoints: latency-svc-zgwbx [473.991117ms]
Jan 17 18:34:05.348: INFO: Created: latency-svc-47spl
Jan 17 18:34:05.367: INFO: Got endpoints: latency-svc-47spl [500.012341ms]
Jan 17 18:34:05.385: INFO: Created: latency-svc-m7k5m
Jan 17 18:34:05.395: INFO: Got endpoints: latency-svc-m7k5m [485.140094ms]
Jan 17 18:34:05.431: INFO: Created: latency-svc-vdd9d
Jan 17 18:34:05.433: INFO: Got endpoints: latency-svc-vdd9d [499.120561ms]
Jan 17 18:34:05.478: INFO: Created: latency-svc-xmzsv
Jan 17 18:34:05.491: INFO: Got endpoints: latency-svc-xmzsv [529.877051ms]
Jan 17 18:34:05.506: INFO: Created: latency-svc-dw9m6
Jan 17 18:34:05.520: INFO: Got endpoints: latency-svc-dw9m6 [528.56567ms]
Jan 17 18:34:05.550: INFO: Created: latency-svc-bpz8r
Jan 17 18:34:05.563: INFO: Got endpoints: latency-svc-bpz8r [527.939077ms]
Jan 17 18:34:05.580: INFO: Created: latency-svc-j2hcp
Jan 17 18:34:05.591: INFO: Got endpoints: latency-svc-j2hcp [539.5516ms]
Jan 17 18:34:05.609: INFO: Created: latency-svc-sg7bh
Jan 17 18:34:05.621: INFO: Got endpoints: latency-svc-sg7bh [537.547439ms]
Jan 17 18:34:05.638: INFO: Created: latency-svc-b6dxr
Jan 17 18:34:05.673: INFO: Got endpoints: latency-svc-b6dxr [567.844046ms]
Jan 17 18:34:05.677: INFO: Created: latency-svc-96lkt
Jan 17 18:34:05.689: INFO: Got endpoints: latency-svc-96lkt [553.879449ms]
Jan 17 18:34:05.707: INFO: Created: latency-svc-bf2wt
Jan 17 18:34:05.719: INFO: Got endpoints: latency-svc-bf2wt [522.24845ms]
Jan 17 18:34:05.734: INFO: Created: latency-svc-rdkcq
Jan 17 18:34:05.744: INFO: Got endpoints: latency-svc-rdkcq [514.06827ms]
Jan 17 18:34:05.760: INFO: Created: latency-svc-jjpg7
Jan 17 18:34:05.770: INFO: Got endpoints: latency-svc-jjpg7 [514.974974ms]
Jan 17 18:34:05.799: INFO: Created: latency-svc-hjmbl
Jan 17 18:34:05.809: INFO: Got endpoints: latency-svc-hjmbl [505.427953ms]
Jan 17 18:34:05.828: INFO: Created: latency-svc-44wb8
Jan 17 18:34:05.837: INFO: Got endpoints: latency-svc-44wb8 [516.112422ms]
Jan 17 18:34:05.855: INFO: Created: latency-svc-4m48z
Jan 17 18:34:05.871: INFO: Got endpoints: latency-svc-4m48z [504.603323ms]
Jan 17 18:34:05.882: INFO: Created: latency-svc-97hcn
Jan 17 18:34:05.893: INFO: Got endpoints: latency-svc-97hcn [498.249885ms]
Jan 17 18:34:05.932: INFO: Created: latency-svc-l5qtd
Jan 17 18:34:05.945: INFO: Got endpoints: latency-svc-l5qtd [511.628867ms]
Jan 17 18:34:05.964: INFO: Created: latency-svc-m4g9x
Jan 17 18:34:05.975: INFO: Got endpoints: latency-svc-m4g9x [483.392892ms]
Jan 17 18:34:05.992: INFO: Created: latency-svc-snssx
Jan 17 18:34:06.006: INFO: Got endpoints: latency-svc-snssx [486.059794ms]
Jan 17 18:34:06.023: INFO: Created: latency-svc-nxhdn
Jan 17 18:34:06.074: INFO: Got endpoints: latency-svc-nxhdn [510.237856ms]
Jan 17 18:34:06.088: INFO: Created: latency-svc-jqkxp
Jan 17 18:34:06.100: INFO: Got endpoints: latency-svc-jqkxp [508.689433ms]
Jan 17 18:34:06.139: INFO: Created: latency-svc-pgsdk
Jan 17 18:34:06.149: INFO: Got endpoints: latency-svc-pgsdk [527.760596ms]
Jan 17 18:34:06.165: INFO: Created: latency-svc-r8smc
Jan 17 18:34:06.186: INFO: Got endpoints: latency-svc-r8smc [512.561053ms]
Jan 17 18:34:06.201: INFO: Created: latency-svc-ll7hl
Jan 17 18:34:06.213: INFO: Got endpoints: latency-svc-ll7hl [521.908829ms]
Jan 17 18:34:06.226: INFO: Created: latency-svc-xhtnc
Jan 17 18:34:06.241: INFO: Got endpoints: latency-svc-xhtnc [522.292613ms]
Jan 17 18:34:06.260: INFO: Created: latency-svc-p7t27
Jan 17 18:34:06.273: INFO: Got endpoints: latency-svc-p7t27 [529.165749ms]
Jan 17 18:34:06.307: INFO: Created: latency-svc-hrldb
Jan 17 18:34:06.317: INFO: Got endpoints: latency-svc-hrldb [547.502796ms]
Jan 17 18:34:06.331: INFO: Created: latency-svc-lc2z9
Jan 17 18:34:06.344: INFO: Got endpoints: latency-svc-lc2z9 [534.610901ms]
Jan 17 18:34:06.361: INFO: Created: latency-svc-hcmnl
Jan 17 18:34:06.373: INFO: Got endpoints: latency-svc-hcmnl [535.330623ms]
Jan 17 18:34:06.390: INFO: Created: latency-svc-slkvv
Jan 17 18:34:06.402: INFO: Got endpoints: latency-svc-slkvv [530.763386ms]
Jan 17 18:34:06.433: INFO: Created: latency-svc-6rbkl
Jan 17 18:34:06.444: INFO: Got endpoints: latency-svc-6rbkl [550.074279ms]
Jan 17 18:34:06.462: INFO: Created: latency-svc-2cd2v
Jan 17 18:34:06.473: INFO: Got endpoints: latency-svc-2cd2v [528.678338ms]
Jan 17 18:34:06.490: INFO: Created: latency-svc-v4wmz
Jan 17 18:34:06.502: INFO: Got endpoints: latency-svc-v4wmz [527.190059ms]
Jan 17 18:34:06.515: INFO: Created: latency-svc-rbgh9
Jan 17 18:34:06.527: INFO: Got endpoints: latency-svc-rbgh9 [520.444586ms]
Jan 17 18:34:06.558: INFO: Created: latency-svc-46875
Jan 17 18:34:06.559: INFO: Got endpoints: latency-svc-46875 [484.879167ms]
Jan 17 18:34:06.584: INFO: Created: latency-svc-jj4rd
Jan 17 18:34:06.597: INFO: Got endpoints: latency-svc-jj4rd [497.028507ms]
Jan 17 18:34:06.609: INFO: Created: latency-svc-46bdz
Jan 17 18:34:06.635: INFO: Got endpoints: latency-svc-46bdz [486.377146ms]
Jan 17 18:34:06.638: INFO: Created: latency-svc-g8b9d
Jan 17 18:34:06.682: INFO: Created: latency-svc-gdxpt
Jan 17 18:34:06.694: INFO: Got endpoints: latency-svc-g8b9d [508.289963ms]
Jan 17 18:34:06.730: INFO: Created: latency-svc-z4qnn
Jan 17 18:34:06.738: INFO: Got endpoints: latency-svc-gdxpt [525.602003ms]
Jan 17 18:34:06.742: INFO: Created: latency-svc-697z7
Jan 17 18:34:06.773: INFO: Created: latency-svc-4hzxg
Jan 17 18:34:06.799: INFO: Got endpoints: latency-svc-z4qnn [557.952692ms]
Jan 17 18:34:06.808: INFO: Created: latency-svc-tcrp6
Jan 17 18:34:06.843: INFO: Got endpoints: latency-svc-697z7 [570.540345ms]
Jan 17 18:34:06.847: INFO: Created: latency-svc-jcvp2
Jan 17 18:34:06.872: INFO: Created: latency-svc-jwch9
Jan 17 18:34:06.889: INFO: Got endpoints: latency-svc-4hzxg [571.24338ms]
Jan 17 18:34:06.920: INFO: Created: latency-svc-qwsjp
Jan 17 18:34:06.950: INFO: Got endpoints: latency-svc-tcrp6 [606.286123ms]
Jan 17 18:34:06.977: INFO: Created: latency-svc-zkhpx
Jan 17 18:34:06.988: INFO: Got endpoints: latency-svc-jcvp2 [614.681468ms]
Jan 17 18:34:07.001: INFO: Created: latency-svc-2j8n6
Jan 17 18:34:07.040: INFO: Got endpoints: latency-svc-jwch9 [637.30527ms]
Jan 17 18:34:07.046: INFO: Created: latency-svc-bmx49
Jan 17 18:34:07.067: INFO: Created: latency-svc-l97xp
Jan 17 18:34:07.086: INFO: Got endpoints: latency-svc-qwsjp [642.078855ms]
Jan 17 18:34:07.090: INFO: Created: latency-svc-dwm82
Jan 17 18:34:07.115: INFO: Created: latency-svc-56867
Jan 17 18:34:07.144: INFO: Got endpoints: latency-svc-zkhpx [670.138469ms]
Jan 17 18:34:07.180: INFO: Created: latency-svc-wfxdt
Jan 17 18:34:07.189: INFO: Got endpoints: latency-svc-2j8n6 [686.545318ms]
Jan 17 18:34:07.211: INFO: Created: latency-svc-62fn6
Jan 17 18:34:07.248: INFO: Got endpoints: latency-svc-bmx49 [721.69339ms]
Jan 17 18:34:07.251: INFO: Created: latency-svc-4bgsn
Jan 17 18:34:07.294: INFO: Got endpoints: latency-svc-l97xp [735.709679ms]
Jan 17 18:34:07.296: INFO: Created: latency-svc-p9klr
Jan 17 18:34:07.335: INFO: Got endpoints: latency-svc-dwm82 [737.572715ms]
Jan 17 18:34:07.350: INFO: Created: latency-svc-lhvp9
Jan 17 18:34:07.384: INFO: Created: latency-svc-6fsz4
Jan 17 18:34:07.389: INFO: Got endpoints: latency-svc-56867 [753.533021ms]
Jan 17 18:34:07.434: INFO: Created: latency-svc-9tq6z
Jan 17 18:34:07.447: INFO: Got endpoints: latency-svc-wfxdt [753.030255ms]
Jan 17 18:34:07.460: INFO: Created: latency-svc-kvwtk
Jan 17 18:34:07.488: INFO: Got endpoints: latency-svc-62fn6 [749.759074ms]
Jan 17 18:34:07.507: INFO: Created: latency-svc-2fdmc
Jan 17 18:34:07.546: INFO: Got endpoints: latency-svc-4bgsn [746.380455ms]
Jan 17 18:34:07.550: INFO: Created: latency-svc-5lg4p
Jan 17 18:34:07.596: INFO: Created: latency-svc-xmgtl
Jan 17 18:34:07.606: INFO: Got endpoints: latency-svc-p9klr [762.345334ms]
Jan 17 18:34:07.634: INFO: Created: latency-svc-2k496
Jan 17 18:34:07.655: INFO: Got endpoints: latency-svc-lhvp9 [765.741636ms]
Jan 17 18:34:07.663: INFO: Created: latency-svc-zs2dj
Jan 17 18:34:07.686: INFO: Got endpoints: latency-svc-6fsz4 [735.072962ms]
Jan 17 18:34:07.689: INFO: Created: latency-svc-qmhk4
Jan 17 18:34:07.709: INFO: Created: latency-svc-8q7ml
Jan 17 18:34:07.730: INFO: Created: latency-svc-5l2hp
Jan 17 18:34:07.739: INFO: Got endpoints: latency-svc-9tq6z [751.622847ms]
Jan 17 18:34:07.751: INFO: Created: latency-svc-9vvsb
Jan 17 18:34:07.796: INFO: Created: latency-svc-fflnx
Jan 17 18:34:07.796: INFO: Got endpoints: latency-svc-kvwtk [755.981809ms]
Jan 17 18:34:07.822: INFO: Created: latency-svc-hnwdl
Jan 17 18:34:07.845: INFO: Got endpoints: latency-svc-2fdmc [758.916448ms]
Jan 17 18:34:07.849: INFO: Created: latency-svc-m5wgp
Jan 17 18:34:07.869: INFO: Created: latency-svc-5nxtj
Jan 17 18:34:07.907: INFO: Got endpoints: latency-svc-5lg4p [762.734732ms]
Jan 17 18:34:07.919: INFO: Created: latency-svc-lpbjh
Jan 17 18:34:07.937: INFO: Got endpoints: latency-svc-xmgtl [748.613194ms]
Jan 17 18:34:07.940: INFO: Created: latency-svc-sn22q
Jan 17 18:34:07.963: INFO: Created: latency-svc-cr86w
Jan 17 18:34:07.983: INFO: Created: latency-svc-sdhcx
Jan 17 18:34:07.992: INFO: Got endpoints: latency-svc-2k496 [743.152659ms]
Jan 17 18:34:08.004: INFO: Created: latency-svc-hgqhn
Jan 17 18:34:08.032: INFO: Created: latency-svc-bn7qq
Jan 17 18:34:08.043: INFO: Got endpoints: latency-svc-zs2dj [748.266706ms]
Jan 17 18:34:08.067: INFO: Created: latency-svc-665wv
Jan 17 18:34:08.084: INFO: Got endpoints: latency-svc-qmhk4 [749.601032ms]
Jan 17 18:34:08.107: INFO: Created: latency-svc-jzqhv
Jan 17 18:34:08.149: INFO: Got endpoints: latency-svc-8q7ml [759.983837ms]
Jan 17 18:34:08.178: INFO: Created: latency-svc-gxqhq
Jan 17 18:34:08.188: INFO: Got endpoints: latency-svc-5l2hp [740.347631ms]
Jan 17 18:34:08.214: INFO: Created: latency-svc-8hpzx
Jan 17 18:34:08.234: INFO: Got endpoints: latency-svc-9vvsb [745.745131ms]
Jan 17 18:34:08.281: INFO: Created: latency-svc-mmpc5
Jan 17 18:34:08.290: INFO: Got endpoints: latency-svc-fflnx [744.345188ms]
Jan 17 18:34:08.316: INFO: Created: latency-svc-gt6l2
Jan 17 18:34:08.337: INFO: Got endpoints: latency-svc-hnwdl [729.124995ms]
Jan 17 18:34:08.354: INFO: Created: latency-svc-5n5h2
Jan 17 18:34:08.384: INFO: Got endpoints: latency-svc-m5wgp [729.017868ms]
Jan 17 18:34:08.411: INFO: Created: latency-svc-nvqcm
Jan 17 18:34:08.434: INFO: Got endpoints: latency-svc-5nxtj [748.104552ms]
Jan 17 18:34:08.465: INFO: Created: latency-svc-54fbz
Jan 17 18:34:08.484: INFO: Got endpoints: latency-svc-lpbjh [744.204355ms]
Jan 17 18:34:08.512: INFO: Created: latency-svc-7gzgd
Jan 17 18:34:08.539: INFO: Got endpoints: latency-svc-sn22q [742.501609ms]
Jan 17 18:34:08.562: INFO: Created: latency-svc-2n85v
Jan 17 18:34:08.584: INFO: Got endpoints: latency-svc-cr86w [738.536505ms]
Jan 17 18:34:08.637: INFO: Got endpoints: latency-svc-sdhcx [729.892928ms]
Jan 17 18:34:08.651: INFO: Created: latency-svc-kfkwl
Jan 17 18:34:08.671: INFO: Created: latency-svc-t52x4
Jan 17 18:34:08.684: INFO: Got endpoints: latency-svc-hgqhn [746.554961ms]
Jan 17 18:34:08.711: INFO: Created: latency-svc-7mxbs
Jan 17 18:34:08.734: INFO: Got endpoints: latency-svc-bn7qq [742.600159ms]
Jan 17 18:34:08.779: INFO: Created: latency-svc-pphdt
Jan 17 18:34:08.786: INFO: Got endpoints: latency-svc-665wv [742.876364ms]
Jan 17 18:34:08.811: INFO: Created: latency-svc-8f6h4
Jan 17 18:34:08.835: INFO: Got endpoints: latency-svc-jzqhv [750.805595ms]
Jan 17 18:34:08.875: INFO: Created: latency-svc-dz567
Jan 17 18:34:08.887: INFO: Got endpoints: latency-svc-gxqhq [738.138798ms]
Jan 17 18:34:08.919: INFO: Created: latency-svc-r9jms
Jan 17 18:34:08.934: INFO: Got endpoints: latency-svc-8hpzx [746.147551ms]
Jan 17 18:34:08.963: INFO: Created: latency-svc-mfpvn
Jan 17 18:34:08.985: INFO: Got endpoints: latency-svc-mmpc5 [750.39935ms]
Jan 17 18:34:09.019: INFO: Created: latency-svc-9xrnw
Jan 17 18:34:09.035: INFO: Got endpoints: latency-svc-gt6l2 [744.38655ms]
Jan 17 18:34:09.061: INFO: Created: latency-svc-cl76x
Jan 17 18:34:09.098: INFO: Got endpoints: latency-svc-5n5h2 [760.444343ms]
Jan 17 18:34:09.132: INFO: Created: latency-svc-5j5j8
Jan 17 18:34:09.143: INFO: Got endpoints: latency-svc-nvqcm [759.120829ms]
Jan 17 18:34:09.165: INFO: Created: latency-svc-z4dtx
Jan 17 18:34:09.184: INFO: Got endpoints: latency-svc-54fbz [749.722035ms]
Jan 17 18:34:09.228: INFO: Created: latency-svc-5v7w6
Jan 17 18:34:09.234: INFO: Got endpoints: latency-svc-7gzgd [750.604985ms]
Jan 17 18:34:09.260: INFO: Created: latency-svc-2krtb
Jan 17 18:34:09.284: INFO: Got endpoints: latency-svc-2n85v [745.721879ms]
Jan 17 18:34:09.310: INFO: Created: latency-svc-nxt5b
Jan 17 18:34:09.339: INFO: Got endpoints: latency-svc-kfkwl [755.317837ms]
Jan 17 18:34:09.359: INFO: Created: latency-svc-g4pxk
Jan 17 18:34:09.384: INFO: Got endpoints: latency-svc-t52x4 [747.513549ms]
Jan 17 18:34:09.410: INFO: Created: latency-svc-hslds
Jan 17 18:34:09.437: INFO: Got endpoints: latency-svc-7mxbs [752.795491ms]
Jan 17 18:34:09.461: INFO: Created: latency-svc-lcmh4
Jan 17 18:34:09.490: INFO: Got endpoints: latency-svc-pphdt [755.231535ms]
Jan 17 18:34:09.513: INFO: Created: latency-svc-d85tp
Jan 17 18:34:09.540: INFO: Got endpoints: latency-svc-8f6h4 [754.114305ms]
Jan 17 18:34:09.570: INFO: Created: latency-svc-zlzlz
Jan 17 18:34:09.584: INFO: Got endpoints: latency-svc-dz567 [748.94426ms]
Jan 17 18:34:09.613: INFO: Created: latency-svc-ltkxd
Jan 17 18:34:09.638: INFO: Got endpoints: latency-svc-r9jms [750.235697ms]
Jan 17 18:34:09.660: INFO: Created: latency-svc-qkrpj
Jan 17 18:34:09.684: INFO: Got endpoints: latency-svc-mfpvn [750.053058ms]
Jan 17 18:34:09.715: INFO: Created: latency-svc-bkk6w
Jan 17 18:34:09.734: INFO: Got endpoints: latency-svc-9xrnw [749.53361ms]
Jan 17 18:34:09.763: INFO: Created: latency-svc-hd8gh
Jan 17 18:34:09.785: INFO: Got endpoints: latency-svc-cl76x [749.566277ms]
Jan 17 18:34:09.812: INFO: Created: latency-svc-cm8kh
Jan 17 18:34:09.834: INFO: Got endpoints: latency-svc-5j5j8 [736.192392ms]
Jan 17 18:34:09.864: INFO: Created: latency-svc-8g29p
Jan 17 18:34:09.908: INFO: Got endpoints: latency-svc-z4dtx [762.357063ms]
Jan 17 18:34:09.936: INFO: Created: latency-svc-h9vlh
Jan 17 18:34:09.949: INFO: Got endpoints: latency-svc-5v7w6 [765.021744ms]
Jan 17 18:34:09.981: INFO: Created: latency-svc-fk9r9
Jan 17 18:34:09.991: INFO: Got endpoints: latency-svc-2krtb [755.869278ms]
Jan 17 18:34:10.030: INFO: Created: latency-svc-bl49x
Jan 17 18:34:10.041: INFO: Got endpoints: latency-svc-nxt5b [756.06117ms]
Jan 17 18:34:10.072: INFO: Created: latency-svc-q2ntz
Jan 17 18:34:10.087: INFO: Got endpoints: latency-svc-g4pxk [747.76216ms]
Jan 17 18:34:10.112: INFO: Created: latency-svc-r8prl
Jan 17 18:34:10.161: INFO: Got endpoints: latency-svc-hslds [776.592693ms]
Jan 17 18:34:10.187: INFO: Got endpoints: latency-svc-lcmh4 [749.898319ms]
Jan 17 18:34:10.190: INFO: Created: latency-svc-g54k2
Jan 17 18:34:10.213: INFO: Created: latency-svc-q8hzq
Jan 17 18:34:10.234: INFO: Got endpoints: latency-svc-d85tp [744.095041ms]
Jan 17 18:34:10.282: INFO: Created: latency-svc-kt6vs
Jan 17 18:34:10.289: INFO: Got endpoints: latency-svc-zlzlz [748.997503ms]
Jan 17 18:34:10.323: INFO: Created: latency-svc-xbn9x
Jan 17 18:34:10.335: INFO: Got endpoints: latency-svc-ltkxd [750.428572ms]
Jan 17 18:34:10.362: INFO: Created: latency-svc-hr892
Jan 17 18:34:10.398: INFO: Got endpoints: latency-svc-qkrpj [759.953811ms]
Jan 17 18:34:10.415: INFO: Created: latency-svc-hxsdp
Jan 17 18:34:10.434: INFO: Got endpoints: latency-svc-bkk6w [750.104998ms]
Jan 17 18:34:10.470: INFO: Created: latency-svc-l899x
Jan 17 18:34:10.485: INFO: Got endpoints: latency-svc-hd8gh [750.411937ms]
Jan 17 18:34:10.522: INFO: Created: latency-svc-x6qts
Jan 17 18:34:10.534: INFO: Got endpoints: latency-svc-cm8kh [749.632567ms]
Jan 17 18:34:10.558: INFO: Created: latency-svc-ghs5m
Jan 17 18:34:10.585: INFO: Got endpoints: latency-svc-8g29p [750.232549ms]
Jan 17 18:34:10.610: INFO: Created: latency-svc-89hzk
Jan 17 18:34:10.634: INFO: Got endpoints: latency-svc-h9vlh [726.167658ms]
Jan 17 18:34:10.661: INFO: Created: latency-svc-bfmjj
Jan 17 18:34:10.687: INFO: Got endpoints: latency-svc-fk9r9 [737.518496ms]
Jan 17 18:34:10.715: INFO: Created: latency-svc-mm7bl
Jan 17 18:34:10.735: INFO: Got endpoints: latency-svc-bl49x [744.475976ms]
Jan 17 18:34:10.759: INFO: Created: latency-svc-qgq6l
Jan 17 18:34:10.784: INFO: Got endpoints: latency-svc-q2ntz [743.214637ms]
Jan 17 18:34:10.808: INFO: Created: latency-svc-f4d8s
Jan 17 18:34:10.834: INFO: Got endpoints: latency-svc-r8prl [746.692518ms]
Jan 17 18:34:10.874: INFO: Created: latency-svc-4w482
Jan 17 18:34:10.884: INFO: Got endpoints: latency-svc-g54k2 [723.227921ms]
Jan 17 18:34:10.909: INFO: Created: latency-svc-r7f7z
Jan 17 18:34:10.936: INFO: Got endpoints: latency-svc-q8hzq [748.719908ms]
Jan 17 18:34:10.976: INFO: Created: latency-svc-4hdfj
Jan 17 18:34:10.989: INFO: Got endpoints: latency-svc-kt6vs [755.268739ms]
Jan 17 18:34:11.012: INFO: Created: latency-svc-ctr76
Jan 17 18:34:11.035: INFO: Got endpoints: latency-svc-xbn9x [745.572669ms]
Jan 17 18:34:11.060: INFO: Created: latency-svc-kq2ch
Jan 17 18:34:11.084: INFO: Got endpoints: latency-svc-hr892 [749.181014ms]
Jan 17 18:34:11.114: INFO: Created: latency-svc-gq9gk
Jan 17 18:34:11.134: INFO: Got endpoints: latency-svc-hxsdp [735.719325ms]
Jan 17 18:34:11.156: INFO: Created: latency-svc-xp44g
Jan 17 18:34:11.212: INFO: Got endpoints: latency-svc-l899x [777.108042ms]
Jan 17 18:34:11.229: INFO: Created: latency-svc-547hg
Jan 17 18:34:11.242: INFO: Got endpoints: latency-svc-x6qts [756.50165ms]
Jan 17 18:34:11.310: INFO: Got endpoints: latency-svc-ghs5m [775.654759ms]
Jan 17 18:34:11.354: INFO: Got endpoints: latency-svc-89hzk [769.566015ms]
Jan 17 18:34:11.358: INFO: Created: latency-svc-k92hh
Jan 17 18:34:11.384: INFO: Created: latency-svc-5jpwq
Jan 17 18:34:11.403: INFO: Got endpoints: latency-svc-bfmjj [767.887455ms]
Jan 17 18:34:11.417: INFO: Created: latency-svc-x6rm6
Jan 17 18:34:11.437: INFO: Got endpoints: latency-svc-mm7bl [750.00694ms]
Jan 17 18:34:11.492: INFO: Got endpoints: latency-svc-qgq6l [757.072769ms]
Jan 17 18:34:11.535: INFO: Got endpoints: latency-svc-f4d8s [750.660758ms]
Jan 17 18:34:11.586: INFO: Got endpoints: latency-svc-4w482 [751.44914ms]
Jan 17 18:34:11.635: INFO: Got endpoints: latency-svc-r7f7z [750.092414ms]
Jan 17 18:34:11.684: INFO: Got endpoints: latency-svc-4hdfj [748.057157ms]
Jan 17 18:34:11.739: INFO: Got endpoints: latency-svc-ctr76 [749.429467ms]
Jan 17 18:34:11.788: INFO: Got endpoints: latency-svc-kq2ch [752.774207ms]
Jan 17 18:34:11.837: INFO: Got endpoints: latency-svc-gq9gk [752.375885ms]
Jan 17 18:34:11.895: INFO: Got endpoints: latency-svc-xp44g [761.589804ms]
Jan 17 18:34:11.935: INFO: Got endpoints: latency-svc-547hg [723.06062ms]
Jan 17 18:34:11.984: INFO: Got endpoints: latency-svc-k92hh [742.392731ms]
Jan 17 18:34:12.037: INFO: Got endpoints: latency-svc-5jpwq [726.893021ms]
Jan 17 18:34:12.089: INFO: Got endpoints: latency-svc-x6rm6 [735.012408ms]
Jan 17 18:34:12.090: INFO: Latencies: [41.653071ms 70.91912ms 104.63619ms 114.916485ms 139.918916ms 167.921303ms 198.27239ms 240.840806ms 256.794687ms 303.695285ms 334.601841ms 373.289597ms 421.248203ms 438.908975ms 443.313865ms 443.909255ms 448.854879ms 452.454038ms 461.879464ms 463.319545ms 465.380671ms 465.569083ms 465.976601ms 466.291205ms 473.458986ms 473.991117ms 478.262814ms 481.324456ms 483.392892ms 484.879167ms 485.140094ms 486.059794ms 486.377146ms 486.717907ms 489.015919ms 489.330289ms 490.711211ms 491.511502ms 495.56018ms 496.685893ms 497.028507ms 498.249885ms 498.407009ms 498.738196ms 499.120561ms 500.012341ms 500.019666ms 504.603323ms 505.427953ms 508.289963ms 508.689433ms 510.237856ms 511.415878ms 511.628867ms 512.561053ms 514.06827ms 514.974974ms 516.112422ms 520.444586ms 521.908829ms 522.24845ms 522.292613ms 525.602003ms 527.190059ms 527.760596ms 527.939077ms 528.56567ms 528.678338ms 529.165749ms 529.877051ms 530.763386ms 534.610901ms 535.330623ms 537.547439ms 539.5516ms 547.502796ms 550.074279ms 550.982703ms 553.879449ms 557.031153ms 557.863957ms 557.921684ms 557.952692ms 560.661765ms 565.361808ms 567.213767ms 567.844046ms 570.540345ms 570.982419ms 571.24338ms 572.64879ms 573.912309ms 576.29513ms 579.212935ms 588.044428ms 588.259281ms 606.286123ms 614.681468ms 637.30527ms 642.078855ms 670.138469ms 686.545318ms 721.69339ms 723.06062ms 723.227921ms 726.167658ms 726.893021ms 729.017868ms 729.124995ms 729.892928ms 735.012408ms 735.072962ms 735.709679ms 735.719325ms 736.192392ms 737.518496ms 737.572715ms 738.138798ms 738.536505ms 740.347631ms 742.392731ms 742.501609ms 742.600159ms 742.876364ms 743.152659ms 743.214637ms 744.095041ms 744.204355ms 744.345188ms 744.38655ms 744.475976ms 745.572669ms 745.721879ms 745.745131ms 746.147551ms 746.380455ms 746.554961ms 746.692518ms 747.513549ms 747.76216ms 748.057157ms 748.104552ms 748.266706ms 748.613194ms 748.719908ms 748.94426ms 748.997503ms 749.181014ms 749.429467ms 749.53361ms 749.566277ms 749.601032ms 749.632567ms 749.722035ms 749.759074ms 749.898319ms 750.00694ms 750.053058ms 750.092414ms 750.104998ms 750.232549ms 750.235697ms 750.39935ms 750.411937ms 750.428572ms 750.604985ms 750.660758ms 750.805595ms 751.44914ms 751.622847ms 752.375885ms 752.774207ms 752.795491ms 753.030255ms 753.533021ms 754.114305ms 755.231535ms 755.268739ms 755.317837ms 755.869278ms 755.981809ms 756.06117ms 756.50165ms 757.072769ms 758.916448ms 759.120829ms 759.953811ms 759.983837ms 760.444343ms 761.589804ms 762.345334ms 762.357063ms 762.734732ms 765.021744ms 765.741636ms 767.887455ms 769.566015ms 775.654759ms 776.592693ms 777.108042ms]
Jan 17 18:34:12.090: INFO: 50 %ile: 670.138469ms
Jan 17 18:34:12.090: INFO: 90 %ile: 755.981809ms
Jan 17 18:34:12.090: INFO: 99 %ile: 776.592693ms
Jan 17 18:34:12.090: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:34:12.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-pzjkf" for this suite.
Jan 17 18:34:30.177: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:34:30.236: INFO: namespace: e2e-tests-svc-latency-pzjkf, resource: bindings, ignored listing per whitelist
Jan 17 18:34:30.241: INFO: namespace e2e-tests-svc-latency-pzjkf deletion completed in 18.082234107s

• [SLOW TEST:30.073 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:34:30.242: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-jjdfq
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-jjdfq to expose endpoints map[]
Jan 17 18:34:30.658: INFO: Get endpoints failed (7.566213ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Jan 17 18:34:31.668: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-jjdfq exposes endpoints map[] (1.017004588s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-jjdfq
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-jjdfq to expose endpoints map[pod1:[100]]
Jan 17 18:34:34.713: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-jjdfq exposes endpoints map[pod1:[100]] (3.039677864s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-jjdfq
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-jjdfq to expose endpoints map[pod2:[101] pod1:[100]]
Jan 17 18:34:37.815: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-jjdfq exposes endpoints map[pod1:[100] pod2:[101]] (3.094921542s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-jjdfq
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-jjdfq to expose endpoints map[pod2:[101]]
Jan 17 18:34:38.862: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-jjdfq exposes endpoints map[pod2:[101]] (1.037900777s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-jjdfq
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-jjdfq to expose endpoints map[]
Jan 17 18:34:38.907: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-jjdfq exposes endpoints map[] (21.763093ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:34:38.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-jjdfq" for this suite.
Jan 17 18:34:45.054: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:34:45.096: INFO: namespace: e2e-tests-services-jjdfq, resource: bindings, ignored listing per whitelist
Jan 17 18:34:45.101: INFO: namespace e2e-tests-services-jjdfq deletion completed in 6.066605993s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:14.860 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:34:45.102: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-9wdhf
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-9wdhf
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-9wdhf
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-9wdhf
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-9wdhf
Jan 17 18:34:49.357: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-9wdhf, name: ss-0, uid: 922fa79b-1a86-11e9-8458-5254003c4592, status phase: Pending. Waiting for statefulset controller to delete.
Jan 17 18:34:59.052: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-9wdhf, name: ss-0, uid: 922fa79b-1a86-11e9-8458-5254003c4592, status phase: Failed. Waiting for statefulset controller to delete.
Jan 17 18:34:59.065: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-9wdhf, name: ss-0, uid: 922fa79b-1a86-11e9-8458-5254003c4592, status phase: Failed. Waiting for statefulset controller to delete.
Jan 17 18:34:59.076: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-9wdhf
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-9wdhf
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-9wdhf and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan 17 18:35:03.181: INFO: Deleting all statefulset in ns e2e-tests-statefulset-9wdhf
Jan 17 18:35:03.201: INFO: Scaling statefulset ss to 0
Jan 17 18:35:13.286: INFO: Waiting for statefulset status.replicas updated to 0
Jan 17 18:35:13.290: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:35:13.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-9wdhf" for this suite.
Jan 17 18:35:19.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:35:19.407: INFO: namespace: e2e-tests-statefulset-9wdhf, resource: bindings, ignored listing per whitelist
Jan 17 18:35:19.467: INFO: namespace e2e-tests-statefulset-9wdhf deletion completed in 6.120224518s

• [SLOW TEST:34.364 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:35:19.467: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:35:23.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-v7llm" for this suite.
Jan 17 18:36:19.716: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:36:19.750: INFO: namespace: e2e-tests-kubelet-test-v7llm, resource: bindings, ignored listing per whitelist
Jan 17 18:36:19.779: INFO: namespace e2e-tests-kubelet-test-v7llm deletion completed in 56.084303909s

• [SLOW TEST:60.314 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:36:19.789: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-c8419dc2-1a86-11e9-a4b6-0a580af40269
STEP: Creating a pod to test consume configMaps
Jan 17 18:36:19.935: INFO: Waiting up to 5m0s for pod "pod-configmaps-c842aa37-1a86-11e9-a4b6-0a580af40269" in namespace "e2e-tests-configmap-6f5zj" to be "success or failure"
Jan 17 18:36:19.942: INFO: Pod "pod-configmaps-c842aa37-1a86-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 7.667359ms
Jan 17 18:36:21.945: INFO: Pod "pod-configmaps-c842aa37-1a86-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010489682s
Jan 17 18:36:23.953: INFO: Pod "pod-configmaps-c842aa37-1a86-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018720085s
STEP: Saw pod success
Jan 17 18:36:23.954: INFO: Pod "pod-configmaps-c842aa37-1a86-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 18:36:23.995: INFO: Trying to get logs from node node1 pod pod-configmaps-c842aa37-1a86-11e9-a4b6-0a580af40269 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 17 18:36:24.026: INFO: Waiting for pod pod-configmaps-c842aa37-1a86-11e9-a4b6-0a580af40269 to disappear
Jan 17 18:36:24.036: INFO: Pod pod-configmaps-c842aa37-1a86-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:36:24.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-6f5zj" for this suite.
Jan 17 18:36:30.089: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:36:30.152: INFO: namespace: e2e-tests-configmap-6f5zj, resource: bindings, ignored listing per whitelist
Jan 17 18:36:30.173: INFO: namespace e2e-tests-configmap-6f5zj deletion completed in 6.102354002s

• [SLOW TEST:10.384 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:36:30.175: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-ce6a25c7-1a86-11e9-a4b6-0a580af40269
Jan 17 18:36:30.272: INFO: Pod name my-hostname-basic-ce6a25c7-1a86-11e9-a4b6-0a580af40269: Found 0 pods out of 1
Jan 17 18:36:35.311: INFO: Pod name my-hostname-basic-ce6a25c7-1a86-11e9-a4b6-0a580af40269: Found 1 pods out of 1
Jan 17 18:36:35.311: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-ce6a25c7-1a86-11e9-a4b6-0a580af40269" are running
Jan 17 18:36:35.319: INFO: Pod "my-hostname-basic-ce6a25c7-1a86-11e9-a4b6-0a580af40269-67gpp" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-17 18:36:30 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-17 18:36:32 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-17 18:36:32 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-17 18:36:30 +0000 UTC Reason: Message:}])
Jan 17 18:36:35.319: INFO: Trying to dial the pod
Jan 17 18:36:40.372: INFO: Controller my-hostname-basic-ce6a25c7-1a86-11e9-a4b6-0a580af40269: Got expected result from replica 1 [my-hostname-basic-ce6a25c7-1a86-11e9-a4b6-0a580af40269-67gpp]: "my-hostname-basic-ce6a25c7-1a86-11e9-a4b6-0a580af40269-67gpp", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:36:40.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-j5vr7" for this suite.
Jan 17 18:36:46.421: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:36:46.484: INFO: namespace: e2e-tests-replication-controller-j5vr7, resource: bindings, ignored listing per whitelist
Jan 17 18:36:46.500: INFO: namespace e2e-tests-replication-controller-j5vr7 deletion completed in 6.112325773s

• [SLOW TEST:16.326 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:36:46.500: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Jan 17 18:36:46.616: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-4fp45,SelfLink:/api/v1/namespaces/e2e-tests-watch-4fp45/configmaps/e2e-watch-test-label-changed,UID:d82616c7-1a86-11e9-8458-5254003c4592,ResourceVersion:90034,Generation:0,CreationTimestamp:2019-01-17 18:36:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 17 18:36:46.616: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-4fp45,SelfLink:/api/v1/namespaces/e2e-tests-watch-4fp45/configmaps/e2e-watch-test-label-changed,UID:d82616c7-1a86-11e9-8458-5254003c4592,ResourceVersion:90035,Generation:0,CreationTimestamp:2019-01-17 18:36:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Jan 17 18:36:46.617: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-4fp45,SelfLink:/api/v1/namespaces/e2e-tests-watch-4fp45/configmaps/e2e-watch-test-label-changed,UID:d82616c7-1a86-11e9-8458-5254003c4592,ResourceVersion:90036,Generation:0,CreationTimestamp:2019-01-17 18:36:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Jan 17 18:36:56.673: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-4fp45,SelfLink:/api/v1/namespaces/e2e-tests-watch-4fp45/configmaps/e2e-watch-test-label-changed,UID:d82616c7-1a86-11e9-8458-5254003c4592,ResourceVersion:90052,Generation:0,CreationTimestamp:2019-01-17 18:36:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 17 18:36:56.673: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-4fp45,SelfLink:/api/v1/namespaces/e2e-tests-watch-4fp45/configmaps/e2e-watch-test-label-changed,UID:d82616c7-1a86-11e9-8458-5254003c4592,ResourceVersion:90053,Generation:0,CreationTimestamp:2019-01-17 18:36:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Jan 17 18:36:56.675: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-4fp45,SelfLink:/api/v1/namespaces/e2e-tests-watch-4fp45/configmaps/e2e-watch-test-label-changed,UID:d82616c7-1a86-11e9-8458-5254003c4592,ResourceVersion:90054,Generation:0,CreationTimestamp:2019-01-17 18:36:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:36:56.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-4fp45" for this suite.
Jan 17 18:37:02.747: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:37:02.784: INFO: namespace: e2e-tests-watch-4fp45, resource: bindings, ignored listing per whitelist
Jan 17 18:37:02.833: INFO: namespace e2e-tests-watch-4fp45 deletion completed in 6.110872543s

• [SLOW TEST:16.333 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:37:02.834: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-frfjf
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-frfjf
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-frfjf
Jan 17 18:37:03.018: INFO: Found 0 stateful pods, waiting for 1
Jan 17 18:37:13.059: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Jan 17 18:37:13.069: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 exec --namespace=e2e-tests-statefulset-frfjf ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 17 18:37:13.217: INFO: stderr: ""
Jan 17 18:37:13.217: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 17 18:37:13.217: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 17 18:37:13.220: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jan 17 18:37:23.229: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan 17 18:37:23.229: INFO: Waiting for statefulset status.replicas updated to 0
Jan 17 18:37:23.295: INFO: POD   NODE   PHASE    GRACE  CONDITIONS
Jan 17 18:37:23.295: INFO: ss-0  node1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:03 +0000 UTC  }]
Jan 17 18:37:23.295: INFO: ss-1         Pending         []
Jan 17 18:37:23.295: INFO: 
Jan 17 18:37:23.295: INFO: StatefulSet ss has not reached scale 3, at 2
Jan 17 18:37:24.316: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.96768206s
Jan 17 18:37:25.321: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.945943326s
Jan 17 18:37:26.326: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.941088396s
Jan 17 18:37:27.329: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.936896358s
Jan 17 18:37:28.356: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.932957866s
Jan 17 18:37:29.363: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.906225821s
Jan 17 18:37:30.385: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.899912902s
Jan 17 18:37:31.396: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.876979548s
Jan 17 18:37:32.425: INFO: Verifying statefulset ss doesn't scale past 3 for another 866.207655ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-frfjf
Jan 17 18:37:33.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 exec --namespace=e2e-tests-statefulset-frfjf ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 17 18:37:33.648: INFO: stderr: ""
Jan 17 18:37:33.648: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 17 18:37:33.648: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 17 18:37:33.648: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 exec --namespace=e2e-tests-statefulset-frfjf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 17 18:37:33.779: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Jan 17 18:37:33.779: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 17 18:37:33.779: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 17 18:37:33.782: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 exec --namespace=e2e-tests-statefulset-frfjf ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 17 18:37:34.060: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Jan 17 18:37:34.060: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 17 18:37:34.061: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 17 18:37:34.083: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Jan 17 18:37:44.090: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 17 18:37:44.090: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 17 18:37:44.090: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Jan 17 18:37:44.115: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 exec --namespace=e2e-tests-statefulset-frfjf ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 17 18:37:44.473: INFO: stderr: ""
Jan 17 18:37:44.473: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 17 18:37:44.473: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 17 18:37:44.473: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 exec --namespace=e2e-tests-statefulset-frfjf ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 17 18:37:44.610: INFO: stderr: ""
Jan 17 18:37:44.610: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 17 18:37:44.610: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 17 18:37:44.610: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 exec --namespace=e2e-tests-statefulset-frfjf ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 17 18:37:44.743: INFO: stderr: ""
Jan 17 18:37:44.743: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 17 18:37:44.743: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 17 18:37:44.743: INFO: Waiting for statefulset status.replicas updated to 0
Jan 17 18:37:44.745: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Jan 17 18:37:54.763: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan 17 18:37:54.763: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jan 17 18:37:54.763: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jan 17 18:37:54.790: INFO: POD   NODE   PHASE    GRACE  CONDITIONS
Jan 17 18:37:54.790: INFO: ss-0  node1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:03 +0000 UTC  }]
Jan 17 18:37:54.790: INFO: ss-1  node2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:23 +0000 UTC  }]
Jan 17 18:37:54.790: INFO: ss-2  node1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:23 +0000 UTC  }]
Jan 17 18:37:54.790: INFO: 
Jan 17 18:37:54.790: INFO: StatefulSet ss has not reached scale 0, at 3
Jan 17 18:37:55.815: INFO: POD   NODE   PHASE    GRACE  CONDITIONS
Jan 17 18:37:55.815: INFO: ss-0  node1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:03 +0000 UTC  }]
Jan 17 18:37:55.815: INFO: ss-1  node2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:23 +0000 UTC  }]
Jan 17 18:37:55.815: INFO: ss-2  node1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:23 +0000 UTC  }]
Jan 17 18:37:55.815: INFO: 
Jan 17 18:37:55.815: INFO: StatefulSet ss has not reached scale 0, at 3
Jan 17 18:37:56.818: INFO: POD   NODE   PHASE    GRACE  CONDITIONS
Jan 17 18:37:56.818: INFO: ss-0  node1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:03 +0000 UTC  }]
Jan 17 18:37:56.818: INFO: ss-1  node2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:23 +0000 UTC  }]
Jan 17 18:37:56.818: INFO: ss-2  node1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:23 +0000 UTC  }]
Jan 17 18:37:56.818: INFO: 
Jan 17 18:37:56.818: INFO: StatefulSet ss has not reached scale 0, at 3
Jan 17 18:37:57.823: INFO: POD   NODE   PHASE    GRACE  CONDITIONS
Jan 17 18:37:57.823: INFO: ss-0  node1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:03 +0000 UTC  }]
Jan 17 18:37:57.823: INFO: ss-1  node2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:23 +0000 UTC  }]
Jan 17 18:37:57.823: INFO: ss-2  node1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:23 +0000 UTC  }]
Jan 17 18:37:57.823: INFO: 
Jan 17 18:37:57.823: INFO: StatefulSet ss has not reached scale 0, at 3
Jan 17 18:37:58.827: INFO: POD   NODE   PHASE    GRACE  CONDITIONS
Jan 17 18:37:58.827: INFO: ss-0  node1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:03 +0000 UTC  }]
Jan 17 18:37:58.827: INFO: ss-2  node1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:37:23 +0000 UTC  }]
Jan 17 18:37:58.827: INFO: 
Jan 17 18:37:58.827: INFO: StatefulSet ss has not reached scale 0, at 2
Jan 17 18:37:59.830: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.952492268s
Jan 17 18:38:00.833: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.949661201s
Jan 17 18:38:01.836: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.946575777s
Jan 17 18:38:02.840: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.942858495s
Jan 17 18:38:03.844: INFO: Verifying statefulset ss doesn't scale past 0 for another 939.434792ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-frfjf
Jan 17 18:38:04.852: INFO: Scaling statefulset ss to 0
Jan 17 18:38:04.879: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan 17 18:38:04.883: INFO: Deleting all statefulset in ns e2e-tests-statefulset-frfjf
Jan 17 18:38:04.886: INFO: Scaling statefulset ss to 0
Jan 17 18:38:04.898: INFO: Waiting for statefulset status.replicas updated to 0
Jan 17 18:38:04.908: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:38:04.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-frfjf" for this suite.
Jan 17 18:38:10.982: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:38:11.034: INFO: namespace: e2e-tests-statefulset-frfjf, resource: bindings, ignored listing per whitelist
Jan 17 18:38:11.062: INFO: namespace e2e-tests-statefulset-frfjf deletion completed in 6.100524634s

• [SLOW TEST:68.229 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:38:11.064: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Jan 17 18:38:11.158: INFO: Waiting up to 5m0s for pod "pod-0a8cf023-1a87-11e9-a4b6-0a580af40269" in namespace "e2e-tests-emptydir-qwh7p" to be "success or failure"
Jan 17 18:38:11.169: INFO: Pod "pod-0a8cf023-1a87-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 10.722723ms
Jan 17 18:38:13.177: INFO: Pod "pod-0a8cf023-1a87-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018327598s
Jan 17 18:38:15.218: INFO: Pod "pod-0a8cf023-1a87-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.059737148s
STEP: Saw pod success
Jan 17 18:38:15.218: INFO: Pod "pod-0a8cf023-1a87-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 18:38:15.221: INFO: Trying to get logs from node node1 pod pod-0a8cf023-1a87-11e9-a4b6-0a580af40269 container test-container: <nil>
STEP: delete the pod
Jan 17 18:38:15.274: INFO: Waiting for pod pod-0a8cf023-1a87-11e9-a4b6-0a580af40269 to disappear
Jan 17 18:38:15.276: INFO: Pod pod-0a8cf023-1a87-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:38:15.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-qwh7p" for this suite.
Jan 17 18:38:21.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:38:21.379: INFO: namespace: e2e-tests-emptydir-qwh7p, resource: bindings, ignored listing per whitelist
Jan 17 18:38:21.428: INFO: namespace e2e-tests-emptydir-qwh7p deletion completed in 6.146593269s

• [SLOW TEST:10.365 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:38:21.429: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jan 17 18:38:26.141: INFO: Successfully updated pod "annotationupdate10bcf050-1a87-11e9-a4b6-0a580af40269"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:38:28.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-m8v6n" for this suite.
Jan 17 18:38:50.249: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:38:50.366: INFO: namespace: e2e-tests-downward-api-m8v6n, resource: bindings, ignored listing per whitelist
Jan 17 18:38:50.370: INFO: namespace e2e-tests-downward-api-m8v6n deletion completed in 22.133873583s

• [SLOW TEST:28.941 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:38:50.372: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-2203cb50-1a87-11e9-a4b6-0a580af40269
STEP: Creating a pod to test consume configMaps
Jan 17 18:38:50.539: INFO: Waiting up to 5m0s for pod "pod-configmaps-22074321-1a87-11e9-a4b6-0a580af40269" in namespace "e2e-tests-configmap-2w5hq" to be "success or failure"
Jan 17 18:38:50.552: INFO: Pod "pod-configmaps-22074321-1a87-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 12.862713ms
Jan 17 18:38:52.555: INFO: Pod "pod-configmaps-22074321-1a87-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016006736s
Jan 17 18:38:54.594: INFO: Pod "pod-configmaps-22074321-1a87-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054899769s
STEP: Saw pod success
Jan 17 18:38:54.594: INFO: Pod "pod-configmaps-22074321-1a87-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 18:38:54.598: INFO: Trying to get logs from node node1 pod pod-configmaps-22074321-1a87-11e9-a4b6-0a580af40269 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 17 18:38:54.668: INFO: Waiting for pod pod-configmaps-22074321-1a87-11e9-a4b6-0a580af40269 to disappear
Jan 17 18:38:54.670: INFO: Pod pod-configmaps-22074321-1a87-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:38:54.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-2w5hq" for this suite.
Jan 17 18:39:00.689: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:39:00.725: INFO: namespace: e2e-tests-configmap-2w5hq, resource: bindings, ignored listing per whitelist
Jan 17 18:39:00.770: INFO: namespace e2e-tests-configmap-2w5hq deletion completed in 6.096313666s

• [SLOW TEST:10.398 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:39:00.772: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Jan 17 18:39:00.859: INFO: Waiting up to 5m0s for pod "var-expansion-282d3d9e-1a87-11e9-a4b6-0a580af40269" in namespace "e2e-tests-var-expansion-xq9l8" to be "success or failure"
Jan 17 18:39:00.867: INFO: Pod "var-expansion-282d3d9e-1a87-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 7.820045ms
Jan 17 18:39:02.875: INFO: Pod "var-expansion-282d3d9e-1a87-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015512927s
Jan 17 18:39:04.914: INFO: Pod "var-expansion-282d3d9e-1a87-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054883175s
STEP: Saw pod success
Jan 17 18:39:04.914: INFO: Pod "var-expansion-282d3d9e-1a87-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 18:39:04.920: INFO: Trying to get logs from node node1 pod var-expansion-282d3d9e-1a87-11e9-a4b6-0a580af40269 container dapi-container: <nil>
STEP: delete the pod
Jan 17 18:39:04.982: INFO: Waiting for pod var-expansion-282d3d9e-1a87-11e9-a4b6-0a580af40269 to disappear
Jan 17 18:39:04.985: INFO: Pod var-expansion-282d3d9e-1a87-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:39:04.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-xq9l8" for this suite.
Jan 17 18:39:11.010: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:39:11.062: INFO: namespace: e2e-tests-var-expansion-xq9l8, resource: bindings, ignored listing per whitelist
Jan 17 18:39:11.092: INFO: namespace e2e-tests-var-expansion-xq9l8 deletion completed in 6.103221048s

• [SLOW TEST:10.321 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:39:11.094: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 17 18:39:11.189: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2e55ece6-1a87-11e9-a4b6-0a580af40269" in namespace "e2e-tests-downward-api-sfwvm" to be "success or failure"
Jan 17 18:39:11.199: INFO: Pod "downwardapi-volume-2e55ece6-1a87-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 9.744582ms
Jan 17 18:39:13.202: INFO: Pod "downwardapi-volume-2e55ece6-1a87-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01256749s
Jan 17 18:39:15.243: INFO: Pod "downwardapi-volume-2e55ece6-1a87-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054231142s
STEP: Saw pod success
Jan 17 18:39:15.244: INFO: Pod "downwardapi-volume-2e55ece6-1a87-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 18:39:15.253: INFO: Trying to get logs from node node1 pod downwardapi-volume-2e55ece6-1a87-11e9-a4b6-0a580af40269 container client-container: <nil>
STEP: delete the pod
Jan 17 18:39:15.342: INFO: Waiting for pod downwardapi-volume-2e55ece6-1a87-11e9-a4b6-0a580af40269 to disappear
Jan 17 18:39:15.345: INFO: Pod downwardapi-volume-2e55ece6-1a87-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:39:15.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-sfwvm" for this suite.
Jan 17 18:39:21.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:39:21.866: INFO: namespace: e2e-tests-downward-api-sfwvm, resource: bindings, ignored listing per whitelist
Jan 17 18:39:21.879: INFO: namespace e2e-tests-downward-api-sfwvm deletion completed in 6.528105744s

• [SLOW TEST:10.786 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:39:21.893: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-34ce52d1-1a87-11e9-a4b6-0a580af40269
STEP: Creating a pod to test consume secrets
Jan 17 18:39:22.053: INFO: Waiting up to 5m0s for pod "pod-secrets-34cee4c2-1a87-11e9-a4b6-0a580af40269" in namespace "e2e-tests-secrets-rk8p9" to be "success or failure"
Jan 17 18:39:22.063: INFO: Pod "pod-secrets-34cee4c2-1a87-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 10.058713ms
Jan 17 18:39:24.069: INFO: Pod "pod-secrets-34cee4c2-1a87-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015687949s
Jan 17 18:39:26.104: INFO: Pod "pod-secrets-34cee4c2-1a87-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050941177s
STEP: Saw pod success
Jan 17 18:39:26.105: INFO: Pod "pod-secrets-34cee4c2-1a87-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 18:39:26.116: INFO: Trying to get logs from node node1 pod pod-secrets-34cee4c2-1a87-11e9-a4b6-0a580af40269 container secret-volume-test: <nil>
STEP: delete the pod
Jan 17 18:39:26.174: INFO: Waiting for pod pod-secrets-34cee4c2-1a87-11e9-a4b6-0a580af40269 to disappear
Jan 17 18:39:26.177: INFO: Pod pod-secrets-34cee4c2-1a87-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:39:26.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-rk8p9" for this suite.
Jan 17 18:39:32.196: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:39:32.214: INFO: namespace: e2e-tests-secrets-rk8p9, resource: bindings, ignored listing per whitelist
Jan 17 18:39:32.256: INFO: namespace e2e-tests-secrets-rk8p9 deletion completed in 6.074585648s

• [SLOW TEST:10.364 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:39:32.263: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 17 18:39:32.359: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-p8t4h'
Jan 17 18:39:33.124: INFO: stderr: ""
Jan 17 18:39:33.124: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Jan 17 18:39:38.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-p8t4h -o json'
Jan 17 18:39:38.303: INFO: stderr: ""
Jan 17 18:39:38.303: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-01-17T18:39:33Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-p8t4h\",\n        \"resourceVersion\": \"90606\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-p8t4h/pods/e2e-test-nginx-pod\",\n        \"uid\": \"3b68b16c-1a87-11e9-8458-5254003c4592\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-j7dkp\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"node1\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-j7dkp\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-j7dkp\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-01-17T18:39:33Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-01-17T18:39:36Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-01-17T18:39:36Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-01-17T18:39:33Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"cri-o://5d8adfc3c59ad045a631e53b52cffd144ebfce48e98a273871790fadbd250f05\",\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imageID\": \"docker.io/library/nginx@sha256:507234ea54dc6a9c7dd6a4b5d8649802bf711bcc7a7b2381ce404982f0f6966e\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-01-17T18:39:35Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.122.53\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.244.1.119\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-01-17T18:39:33Z\"\n    }\n}\n"
STEP: replace the image in the pod
Jan 17 18:39:38.304: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 replace -f - --namespace=e2e-tests-kubectl-p8t4h'
Jan 17 18:39:38.456: INFO: stderr: ""
Jan 17 18:39:38.456: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
Jan 17 18:39:38.460: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-p8t4h'
Jan 17 18:39:49.105: INFO: stderr: ""
Jan 17 18:39:49.105: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:39:49.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-p8t4h" for this suite.
Jan 17 18:39:55.127: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:39:55.238: INFO: namespace: e2e-tests-kubectl-p8t4h, resource: bindings, ignored listing per whitelist
Jan 17 18:39:55.244: INFO: namespace e2e-tests-kubectl-p8t4h deletion completed in 6.129741838s

• [SLOW TEST:22.981 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:39:55.251: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jan 17 18:39:55.318: INFO: PodSpec: initContainers in spec.initContainers
Jan 17 18:40:39.341: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-48a4df82-1a87-11e9-a4b6-0a580af40269", GenerateName:"", Namespace:"e2e-tests-init-container-pcvlt", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-pcvlt/pods/pod-init-48a4df82-1a87-11e9-a4b6-0a580af40269", UID:"48a63ce5-1a87-11e9-8458-5254003c4592", ResourceVersion:"90748", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63683347195, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"318262839"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-hphx7", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc00229c000), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-hphx7", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-hphx7", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-hphx7", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0021da0e8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"node1", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0022b2000), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0021da190)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0021da1b0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0021da1b8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0021da1bc)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683347195, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683347195, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683347195, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683347195, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.122.53", PodIP:"10.244.1.120", StartTime:(*v1.Time)(0xc001f36040), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001eb2070)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001eb20e0)}, Ready:false, RestartCount:3, Image:"docker.io/library/busybox:1.29", ImageID:"docker.io/library/busybox@sha256:e004c2cc521c95383aebb1fb5893719aa7a8eae2e7a71f316a4410784edb00a9", ContainerID:"cri-o://cdd537ed055c8db2838698773dbf048c3ee72d423d127229af84e2c15b751463"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001f36080), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001f36060), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:40:39.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-pcvlt" for this suite.
Jan 17 18:40:57.409: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:40:57.480: INFO: namespace: e2e-tests-init-container-pcvlt, resource: bindings, ignored listing per whitelist
Jan 17 18:40:57.500: INFO: namespace e2e-tests-init-container-pcvlt deletion completed in 18.107727807s

• [SLOW TEST:62.249 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:40:57.509: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jan 17 18:41:02.208: INFO: Successfully updated pod "pod-update-6dca5432-1a87-11e9-a4b6-0a580af40269"
STEP: verifying the updated pod is in kubernetes
Jan 17 18:41:02.237: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:41:02.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-b4t8j" for this suite.
Jan 17 18:41:24.264: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:41:24.367: INFO: namespace: e2e-tests-pods-b4t8j, resource: bindings, ignored listing per whitelist
Jan 17 18:41:24.373: INFO: namespace e2e-tests-pods-b4t8j deletion completed in 22.129322393s

• [SLOW TEST:26.864 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:41:24.373: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jan 17 18:41:24.577: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:41:24.591: INFO: Number of nodes with available pods: 0
Jan 17 18:41:24.591: INFO: Node node1 is running more than one daemon pod
Jan 17 18:41:25.641: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:41:25.653: INFO: Number of nodes with available pods: 0
Jan 17 18:41:25.660: INFO: Node node1 is running more than one daemon pod
Jan 17 18:41:26.595: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:41:26.599: INFO: Number of nodes with available pods: 0
Jan 17 18:41:26.599: INFO: Node node1 is running more than one daemon pod
Jan 17 18:41:27.602: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:41:27.623: INFO: Number of nodes with available pods: 2
Jan 17 18:41:27.623: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Jan 17 18:41:27.700: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:41:27.718: INFO: Number of nodes with available pods: 1
Jan 17 18:41:27.718: INFO: Node node2 is running more than one daemon pod
Jan 17 18:41:28.733: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:41:28.742: INFO: Number of nodes with available pods: 1
Jan 17 18:41:28.742: INFO: Node node2 is running more than one daemon pod
Jan 17 18:41:29.725: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:41:29.743: INFO: Number of nodes with available pods: 1
Jan 17 18:41:29.743: INFO: Node node2 is running more than one daemon pod
Jan 17 18:41:30.751: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:41:30.761: INFO: Number of nodes with available pods: 1
Jan 17 18:41:30.761: INFO: Node node2 is running more than one daemon pod
Jan 17 18:41:31.733: INFO: DaemonSet pods can't tolerate node masteru with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 17 18:41:31.748: INFO: Number of nodes with available pods: 2
Jan 17 18:41:31.748: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-zzw8d, will wait for the garbage collector to delete the pods
Jan 17 18:41:31.839: INFO: Deleting DaemonSet.extensions daemon-set took: 8.572515ms
Jan 17 18:41:31.939: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.403144ms
Jan 17 18:42:09.161: INFO: Number of nodes with available pods: 0
Jan 17 18:42:09.161: INFO: Number of running nodes: 0, number of available pods: 0
Jan 17 18:42:09.171: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-zzw8d/daemonsets","resourceVersion":"90972"},"items":null}

Jan 17 18:42:09.181: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-zzw8d/pods","resourceVersion":"90972"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:42:09.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-zzw8d" for this suite.
Jan 17 18:42:15.246: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:42:15.279: INFO: namespace: e2e-tests-daemonsets-zzw8d, resource: bindings, ignored listing per whitelist
Jan 17 18:42:15.302: INFO: namespace e2e-tests-daemonsets-zzw8d deletion completed in 6.081219633s

• [SLOW TEST:50.929 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:42:15.307: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-9c27f8ee-1a87-11e9-a4b6-0a580af40269
STEP: Creating a pod to test consume secrets
Jan 17 18:42:15.490: INFO: Waiting up to 5m0s for pod "pod-secrets-9c302a14-1a87-11e9-a4b6-0a580af40269" in namespace "e2e-tests-secrets-wr8lz" to be "success or failure"
Jan 17 18:42:15.510: INFO: Pod "pod-secrets-9c302a14-1a87-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 20.617565ms
Jan 17 18:42:17.555: INFO: Pod "pod-secrets-9c302a14-1a87-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.065382368s
Jan 17 18:42:19.563: INFO: Pod "pod-secrets-9c302a14-1a87-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.073560588s
STEP: Saw pod success
Jan 17 18:42:19.564: INFO: Pod "pod-secrets-9c302a14-1a87-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 18:42:19.611: INFO: Trying to get logs from node node1 pod pod-secrets-9c302a14-1a87-11e9-a4b6-0a580af40269 container secret-volume-test: <nil>
STEP: delete the pod
Jan 17 18:42:19.667: INFO: Waiting for pod pod-secrets-9c302a14-1a87-11e9-a4b6-0a580af40269 to disappear
Jan 17 18:42:19.686: INFO: Pod pod-secrets-9c302a14-1a87-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:42:19.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-wr8lz" for this suite.
Jan 17 18:42:25.709: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:42:25.754: INFO: namespace: e2e-tests-secrets-wr8lz, resource: bindings, ignored listing per whitelist
Jan 17 18:42:25.770: INFO: namespace e2e-tests-secrets-wr8lz deletion completed in 6.078999026s
STEP: Destroying namespace "e2e-tests-secret-namespace-jn5fj" for this suite.
Jan 17 18:42:31.797: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:42:31.836: INFO: namespace: e2e-tests-secret-namespace-jn5fj, resource: bindings, ignored listing per whitelist
Jan 17 18:42:31.880: INFO: namespace e2e-tests-secret-namespace-jn5fj deletion completed in 6.110256859s

• [SLOW TEST:16.573 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:42:31.881: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 17 18:42:32.325: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a634dc85-1a87-11e9-a4b6-0a580af40269" in namespace "e2e-tests-downward-api-lbwjl" to be "success or failure"
Jan 17 18:42:32.336: INFO: Pod "downwardapi-volume-a634dc85-1a87-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 11.022492ms
Jan 17 18:42:34.344: INFO: Pod "downwardapi-volume-a634dc85-1a87-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018782457s
Jan 17 18:42:36.349: INFO: Pod "downwardapi-volume-a634dc85-1a87-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0244807s
STEP: Saw pod success
Jan 17 18:42:36.349: INFO: Pod "downwardapi-volume-a634dc85-1a87-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 18:42:36.391: INFO: Trying to get logs from node node1 pod downwardapi-volume-a634dc85-1a87-11e9-a4b6-0a580af40269 container client-container: <nil>
STEP: delete the pod
Jan 17 18:42:36.444: INFO: Waiting for pod downwardapi-volume-a634dc85-1a87-11e9-a4b6-0a580af40269 to disappear
Jan 17 18:42:36.452: INFO: Pod downwardapi-volume-a634dc85-1a87-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:42:36.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-lbwjl" for this suite.
Jan 17 18:42:42.539: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:42:42.583: INFO: namespace: e2e-tests-downward-api-lbwjl, resource: bindings, ignored listing per whitelist
Jan 17 18:42:42.622: INFO: namespace e2e-tests-downward-api-lbwjl deletion completed in 6.131769557s

• [SLOW TEST:10.740 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:42:42.622: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Jan 17 18:42:42.764: INFO: Waiting up to 5m0s for pod "pod-ac7209d6-1a87-11e9-a4b6-0a580af40269" in namespace "e2e-tests-emptydir-78jcn" to be "success or failure"
Jan 17 18:42:42.772: INFO: Pod "pod-ac7209d6-1a87-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 7.716308ms
Jan 17 18:42:44.774: INFO: Pod "pod-ac7209d6-1a87-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009875659s
Jan 17 18:42:46.777: INFO: Pod "pod-ac7209d6-1a87-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012181546s
STEP: Saw pod success
Jan 17 18:42:46.777: INFO: Pod "pod-ac7209d6-1a87-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 18:42:46.810: INFO: Trying to get logs from node node1 pod pod-ac7209d6-1a87-11e9-a4b6-0a580af40269 container test-container: <nil>
STEP: delete the pod
Jan 17 18:42:46.830: INFO: Waiting for pod pod-ac7209d6-1a87-11e9-a4b6-0a580af40269 to disappear
Jan 17 18:42:46.840: INFO: Pod pod-ac7209d6-1a87-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:42:46.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-78jcn" for this suite.
Jan 17 18:42:52.889: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:42:52.955: INFO: namespace: e2e-tests-emptydir-78jcn, resource: bindings, ignored listing per whitelist
Jan 17 18:42:52.965: INFO: namespace e2e-tests-emptydir-78jcn deletion completed in 6.090637514s

• [SLOW TEST:10.343 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:42:52.967: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Jan 17 18:42:53.087: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 create -f - --namespace=e2e-tests-kubectl-4gsgl'
Jan 17 18:42:53.216: INFO: stderr: ""
Jan 17 18:42:53.216: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 17 18:42:53.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-4gsgl'
Jan 17 18:42:53.555: INFO: stderr: ""
Jan 17 18:42:53.555: INFO: stdout: "update-demo-nautilus-j7cqw update-demo-nautilus-xt6hl "
Jan 17 18:42:53.555: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 get pods update-demo-nautilus-j7cqw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-4gsgl'
Jan 17 18:42:53.697: INFO: stderr: ""
Jan 17 18:42:53.697: INFO: stdout: ""
Jan 17 18:42:53.697: INFO: update-demo-nautilus-j7cqw is created but not running
Jan 17 18:42:58.698: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-4gsgl'
Jan 17 18:42:59.029: INFO: stderr: ""
Jan 17 18:42:59.029: INFO: stdout: "update-demo-nautilus-j7cqw update-demo-nautilus-xt6hl "
Jan 17 18:42:59.029: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 get pods update-demo-nautilus-j7cqw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-4gsgl'
Jan 17 18:42:59.176: INFO: stderr: ""
Jan 17 18:42:59.176: INFO: stdout: "true"
Jan 17 18:42:59.176: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 get pods update-demo-nautilus-j7cqw -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-4gsgl'
Jan 17 18:42:59.307: INFO: stderr: ""
Jan 17 18:42:59.307: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 17 18:42:59.307: INFO: validating pod update-demo-nautilus-j7cqw
Jan 17 18:42:59.312: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 17 18:42:59.312: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 17 18:42:59.312: INFO: update-demo-nautilus-j7cqw is verified up and running
Jan 17 18:42:59.312: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 get pods update-demo-nautilus-xt6hl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-4gsgl'
Jan 17 18:42:59.400: INFO: stderr: ""
Jan 17 18:42:59.400: INFO: stdout: "true"
Jan 17 18:42:59.400: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 get pods update-demo-nautilus-xt6hl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-4gsgl'
Jan 17 18:42:59.484: INFO: stderr: ""
Jan 17 18:42:59.484: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 17 18:42:59.484: INFO: validating pod update-demo-nautilus-xt6hl
Jan 17 18:42:59.487: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 17 18:42:59.487: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 17 18:42:59.487: INFO: update-demo-nautilus-xt6hl is verified up and running
STEP: using delete to clean up resources
Jan 17 18:42:59.487: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-4gsgl'
Jan 17 18:42:59.593: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 17 18:42:59.593: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jan 17 18:42:59.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-4gsgl'
Jan 17 18:42:59.752: INFO: stderr: "No resources found.\n"
Jan 17 18:42:59.752: INFO: stdout: ""
Jan 17 18:42:59.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 get pods -l name=update-demo --namespace=e2e-tests-kubectl-4gsgl -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan 17 18:43:00.089: INFO: stderr: ""
Jan 17 18:43:00.089: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:43:00.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-4gsgl" for this suite.
Jan 17 18:43:06.156: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:43:06.211: INFO: namespace: e2e-tests-kubectl-4gsgl, resource: bindings, ignored listing per whitelist
Jan 17 18:43:06.255: INFO: namespace e2e-tests-kubectl-4gsgl deletion completed in 6.132076604s

• [SLOW TEST:13.288 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:43:06.256: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Jan 17 18:43:14.438: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 17 18:43:14.486: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 17 18:43:16.486: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 17 18:43:16.491: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 17 18:43:18.486: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 17 18:43:18.531: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 17 18:43:20.486: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 17 18:43:20.494: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 17 18:43:22.487: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 17 18:43:22.495: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 17 18:43:24.486: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 17 18:43:24.494: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 17 18:43:26.486: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 17 18:43:26.497: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 17 18:43:28.487: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 17 18:43:28.497: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 17 18:43:30.487: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 17 18:43:30.516: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 17 18:43:32.486: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 17 18:43:32.489: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 17 18:43:34.486: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 17 18:43:34.490: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 17 18:43:36.486: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 17 18:43:36.491: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 17 18:43:38.486: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 17 18:43:38.489: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 17 18:43:40.486: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 17 18:43:40.493: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:43:40.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-6k955" for this suite.
Jan 17 18:44:02.578: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:44:02.689: INFO: namespace: e2e-tests-container-lifecycle-hook-6k955, resource: bindings, ignored listing per whitelist
Jan 17 18:44:02.730: INFO: namespace e2e-tests-container-lifecycle-hook-6k955 deletion completed in 22.171182349s

• [SLOW TEST:56.475 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:44:02.732: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 17 18:44:02.843: INFO: Creating deployment "nginx-deployment"
Jan 17 18:44:02.851: INFO: Waiting for observed generation 1
Jan 17 18:44:04.865: INFO: Waiting for all required pods to come up
Jan 17 18:44:04.912: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Jan 17 18:44:06.953: INFO: Waiting for deployment "nginx-deployment" to complete
Jan 17 18:44:06.962: INFO: Updating deployment "nginx-deployment" with a non-existent image
Jan 17 18:44:06.971: INFO: Updating deployment nginx-deployment
Jan 17 18:44:06.973: INFO: Waiting for observed generation 2
Jan 17 18:44:08.995: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Jan 17 18:44:09.004: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Jan 17 18:44:09.012: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Jan 17 18:44:09.029: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Jan 17 18:44:09.029: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Jan 17 18:44:09.037: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Jan 17 18:44:09.042: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Jan 17 18:44:09.042: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Jan 17 18:44:09.049: INFO: Updating deployment nginx-deployment
Jan 17 18:44:09.049: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Jan 17 18:44:09.094: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Jan 17 18:44:11.139: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan 17 18:44:11.148: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-svs44,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-svs44/deployments/nginx-deployment,UID:dc2e09f8-1a87-11e9-8458-5254003c4592,ResourceVersion:91590,Generation:3,CreationTimestamp:2019-01-17 18:44:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-01-17 18:44:09 +0000 UTC 2019-01-17 18:44:09 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-01-17 18:44:09 +0000 UTC 2019-01-17 18:44:02 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-65bbdb5f8" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Jan 17 18:44:11.194: INFO: New ReplicaSet "nginx-deployment-65bbdb5f8" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8,GenerateName:,Namespace:e2e-tests-deployment-svs44,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-svs44/replicasets/nginx-deployment-65bbdb5f8,UID:dea3d912-1a87-11e9-8458-5254003c4592,ResourceVersion:91587,Generation:3,CreationTimestamp:2019-01-17 18:44:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment dc2e09f8-1a87-11e9-8458-5254003c4592 0xc00261c1f7 0xc00261c1f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 17 18:44:11.194: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Jan 17 18:44:11.198: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965,GenerateName:,Namespace:e2e-tests-deployment-svs44,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-svs44/replicasets/nginx-deployment-555b55d965,UID:dc313074-1a87-11e9-8458-5254003c4592,ResourceVersion:91581,Generation:3,CreationTimestamp:2019-01-17 18:44:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment dc2e09f8-1a87-11e9-8458-5254003c4592 0xc00261c137 0xc00261c138}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Jan 17 18:44:11.256: INFO: Pod "nginx-deployment-555b55d965-56nlg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-56nlg,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-svs44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-svs44/pods/nginx-deployment-555b55d965-56nlg,UID:dfeee68b-1a87-11e9-8458-5254003c4592,ResourceVersion:91576,Generation:0,CreationTimestamp:2019-01-17 18:44:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 dc313074-1a87-11e9-8458-5254003c4592 0xc002559107 0xc002559108}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fz7h7 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fz7h7,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fz7h7 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002559180} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025591a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 17 18:44:11.257: INFO: Pod "nginx-deployment-555b55d965-574bb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-574bb,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-svs44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-svs44/pods/nginx-deployment-555b55d965-574bb,UID:dfeef53d-1a87-11e9-8458-5254003c4592,ResourceVersion:91656,Generation:0,CreationTimestamp:2019-01-17 18:44:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 dc313074-1a87-11e9-8458-5254003c4592 0xc002559210 0xc002559211}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fz7h7 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fz7h7,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fz7h7 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002559280} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025592a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC  }],Message:,Reason:,HostIP:192.168.122.54,PodIP:,StartTime:2019-01-17 18:44:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 17 18:44:11.257: INFO: Pod "nginx-deployment-555b55d965-5vhrj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-5vhrj,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-svs44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-svs44/pods/nginx-deployment-555b55d965-5vhrj,UID:dfe8604f-1a87-11e9-8458-5254003c4592,ResourceVersion:91630,Generation:0,CreationTimestamp:2019-01-17 18:44:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 dc313074-1a87-11e9-8458-5254003c4592 0xc002559357 0xc002559358}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fz7h7 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fz7h7,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fz7h7 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025593d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025593f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC  }],Message:,Reason:,HostIP:192.168.122.53,PodIP:,StartTime:2019-01-17 18:44:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 17 18:44:11.257: INFO: Pod "nginx-deployment-555b55d965-6w452" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-6w452,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-svs44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-svs44/pods/nginx-deployment-555b55d965-6w452,UID:dfe86027-1a87-11e9-8458-5254003c4592,ResourceVersion:91593,Generation:0,CreationTimestamp:2019-01-17 18:44:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 dc313074-1a87-11e9-8458-5254003c4592 0xc0025594a7 0xc0025594a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fz7h7 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fz7h7,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fz7h7 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002559520} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002559540}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC  }],Message:,Reason:,HostIP:192.168.122.54,PodIP:,StartTime:2019-01-17 18:44:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 17 18:44:11.257: INFO: Pod "nginx-deployment-555b55d965-7lnbq" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-7lnbq,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-svs44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-svs44/pods/nginx-deployment-555b55d965-7lnbq,UID:dc3ab8cc-1a87-11e9-8458-5254003c4592,ResourceVersion:91439,Generation:0,CreationTimestamp:2019-01-17 18:44:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 dc313074-1a87-11e9-8458-5254003c4592 0xc0025595f7 0xc0025595f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fz7h7 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fz7h7,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fz7h7 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002559670} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002559690}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:02 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:05 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:05 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:02 +0000 UTC  }],Message:,Reason:,HostIP:192.168.122.54,PodIP:10.244.2.155,StartTime:2019-01-17 18:44:02 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-17 18:44:05 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:507234ea54dc6a9c7dd6a4b5d8649802bf711bcc7a7b2381ce404982f0f6966e cri-o://ff490589f58b71f0c5f06be4f9c627d26659eb1d2325ffc529dd1df9dc2372e8}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 17 18:44:11.257: INFO: Pod "nginx-deployment-555b55d965-94sj8" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-94sj8,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-svs44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-svs44/pods/nginx-deployment-555b55d965-94sj8,UID:dc3ae4b5-1a87-11e9-8458-5254003c4592,ResourceVersion:91436,Generation:0,CreationTimestamp:2019-01-17 18:44:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 dc313074-1a87-11e9-8458-5254003c4592 0xc002559757 0xc002559758}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fz7h7 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fz7h7,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fz7h7 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025597d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025597f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:02 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:05 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:05 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:02 +0000 UTC  }],Message:,Reason:,HostIP:192.168.122.53,PodIP:10.244.1.132,StartTime:2019-01-17 18:44:02 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-17 18:44:05 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:507234ea54dc6a9c7dd6a4b5d8649802bf711bcc7a7b2381ce404982f0f6966e cri-o://020f63f9521e66750fdd36ab840fe900cc26056013da61aa719a52991fdb6ab0}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 17 18:44:11.257: INFO: Pod "nginx-deployment-555b55d965-bzxzn" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-bzxzn,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-svs44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-svs44/pods/nginx-deployment-555b55d965-bzxzn,UID:dc36b8b4-1a87-11e9-8458-5254003c4592,ResourceVersion:91463,Generation:0,CreationTimestamp:2019-01-17 18:44:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 dc313074-1a87-11e9-8458-5254003c4592 0xc0025598b7 0xc0025598b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fz7h7 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fz7h7,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fz7h7 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002559930} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002559950}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:02 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:06 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:06 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:02 +0000 UTC  }],Message:,Reason:,HostIP:192.168.122.54,PodIP:10.244.2.154,StartTime:2019-01-17 18:44:02 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-17 18:44:05 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:507234ea54dc6a9c7dd6a4b5d8649802bf711bcc7a7b2381ce404982f0f6966e cri-o://b8eddb9d8755402762af02524d7f24a9e5d5b174070b306a74cfb1f6c08954e5}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 17 18:44:11.258: INFO: Pod "nginx-deployment-555b55d965-fnxn5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-fnxn5,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-svs44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-svs44/pods/nginx-deployment-555b55d965-fnxn5,UID:dfe2e813-1a87-11e9-8458-5254003c4592,ResourceVersion:91564,Generation:0,CreationTimestamp:2019-01-17 18:44:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 dc313074-1a87-11e9-8458-5254003c4592 0xc002559a17 0xc002559a18}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fz7h7 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fz7h7,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fz7h7 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002559a90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002559ab0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC  }],Message:,Reason:,HostIP:192.168.122.53,PodIP:,StartTime:2019-01-17 18:44:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 17 18:44:11.258: INFO: Pod "nginx-deployment-555b55d965-fqb9m" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-fqb9m,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-svs44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-svs44/pods/nginx-deployment-555b55d965-fqb9m,UID:dc382fbc-1a87-11e9-8458-5254003c4592,ResourceVersion:91459,Generation:0,CreationTimestamp:2019-01-17 18:44:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 dc313074-1a87-11e9-8458-5254003c4592 0xc002559b67 0xc002559b68}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fz7h7 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fz7h7,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fz7h7 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002559be0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002559c00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:02 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:06 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:06 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:02 +0000 UTC  }],Message:,Reason:,HostIP:192.168.122.54,PodIP:10.244.2.157,StartTime:2019-01-17 18:44:02 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-17 18:44:05 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:507234ea54dc6a9c7dd6a4b5d8649802bf711bcc7a7b2381ce404982f0f6966e cri-o://9395f486685b13eca707baf6eebca14f89f3e36e86df9eda904cb41d0397c384}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 17 18:44:11.258: INFO: Pod "nginx-deployment-555b55d965-g7fxg" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-g7fxg,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-svs44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-svs44/pods/nginx-deployment-555b55d965-g7fxg,UID:dc3adc03-1a87-11e9-8458-5254003c4592,ResourceVersion:91432,Generation:0,CreationTimestamp:2019-01-17 18:44:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 dc313074-1a87-11e9-8458-5254003c4592 0xc002559cc7 0xc002559cc8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fz7h7 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fz7h7,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fz7h7 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002559d40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002559d60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:02 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:05 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:05 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:02 +0000 UTC  }],Message:,Reason:,HostIP:192.168.122.54,PodIP:10.244.2.158,StartTime:2019-01-17 18:44:02 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-17 18:44:05 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:507234ea54dc6a9c7dd6a4b5d8649802bf711bcc7a7b2381ce404982f0f6966e cri-o://307f6b741ae1dbb787384f7a91830d867add79c988c54dc96e4fb00e285fdab5}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 17 18:44:11.258: INFO: Pod "nginx-deployment-555b55d965-hzbjj" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-hzbjj,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-svs44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-svs44/pods/nginx-deployment-555b55d965-hzbjj,UID:dc3836a2-1a87-11e9-8458-5254003c4592,ResourceVersion:91427,Generation:0,CreationTimestamp:2019-01-17 18:44:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 dc313074-1a87-11e9-8458-5254003c4592 0xc002559e27 0xc002559e28}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fz7h7 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fz7h7,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fz7h7 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002559ea0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002559ec0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:02 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:05 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:05 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:02 +0000 UTC  }],Message:,Reason:,HostIP:192.168.122.54,PodIP:10.244.2.156,StartTime:2019-01-17 18:44:02 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-17 18:44:05 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:507234ea54dc6a9c7dd6a4b5d8649802bf711bcc7a7b2381ce404982f0f6966e cri-o://feb64c9acf011ac057796d60d715d7ac85ecf14a116830c20babe95450c75767}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 17 18:44:11.258: INFO: Pod "nginx-deployment-555b55d965-lss5t" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-lss5t,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-svs44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-svs44/pods/nginx-deployment-555b55d965-lss5t,UID:dfeeef45-1a87-11e9-8458-5254003c4592,ResourceVersion:91652,Generation:0,CreationTimestamp:2019-01-17 18:44:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 dc313074-1a87-11e9-8458-5254003c4592 0xc002559f87 0xc002559f88}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fz7h7 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fz7h7,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fz7h7 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002532050} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002532070}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC  }],Message:,Reason:,HostIP:192.168.122.54,PodIP:,StartTime:2019-01-17 18:44:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 17 18:44:11.258: INFO: Pod "nginx-deployment-555b55d965-mk8sw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-mk8sw,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-svs44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-svs44/pods/nginx-deployment-555b55d965-mk8sw,UID:dfe56a91-1a87-11e9-8458-5254003c4592,ResourceVersion:91588,Generation:0,CreationTimestamp:2019-01-17 18:44:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 dc313074-1a87-11e9-8458-5254003c4592 0xc002532137 0xc002532138}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fz7h7 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fz7h7,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fz7h7 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025321b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025321d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC  }],Message:,Reason:,HostIP:192.168.122.53,PodIP:,StartTime:2019-01-17 18:44:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 17 18:44:11.258: INFO: Pod "nginx-deployment-555b55d965-q7msj" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-q7msj,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-svs44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-svs44/pods/nginx-deployment-555b55d965-q7msj,UID:dc382f22-1a87-11e9-8458-5254003c4592,ResourceVersion:91440,Generation:0,CreationTimestamp:2019-01-17 18:44:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 dc313074-1a87-11e9-8458-5254003c4592 0xc002532287 0xc002532288}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fz7h7 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fz7h7,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fz7h7 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002532300} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025323a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:02 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:05 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:05 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:02 +0000 UTC  }],Message:,Reason:,HostIP:192.168.122.53,PodIP:10.244.1.130,StartTime:2019-01-17 18:44:02 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-17 18:44:05 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:507234ea54dc6a9c7dd6a4b5d8649802bf711bcc7a7b2381ce404982f0f6966e cri-o://1d0a661a273c7034d59ed94e509a2d7fdfb801025419c36d58c5dfdfc721d2cc}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 17 18:44:11.260: INFO: Pod "nginx-deployment-555b55d965-q8qwg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-q8qwg,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-svs44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-svs44/pods/nginx-deployment-555b55d965-q8qwg,UID:dfeefdcb-1a87-11e9-8458-5254003c4592,ResourceVersion:91653,Generation:0,CreationTimestamp:2019-01-17 18:44:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 dc313074-1a87-11e9-8458-5254003c4592 0xc002532467 0xc002532468}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fz7h7 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fz7h7,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fz7h7 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025324e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002532500}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC  }],Message:,Reason:,HostIP:192.168.122.53,PodIP:,StartTime:2019-01-17 18:44:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 17 18:44:11.260: INFO: Pod "nginx-deployment-555b55d965-tpdpj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-tpdpj,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-svs44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-svs44/pods/nginx-deployment-555b55d965-tpdpj,UID:dfe8673c-1a87-11e9-8458-5254003c4592,ResourceVersion:91599,Generation:0,CreationTimestamp:2019-01-17 18:44:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 dc313074-1a87-11e9-8458-5254003c4592 0xc0025325b7 0xc0025325b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fz7h7 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fz7h7,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fz7h7 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002532630} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002532650}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC  }],Message:,Reason:,HostIP:192.168.122.54,PodIP:,StartTime:2019-01-17 18:44:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 17 18:44:11.260: INFO: Pod "nginx-deployment-555b55d965-vkgcs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-vkgcs,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-svs44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-svs44/pods/nginx-deployment-555b55d965-vkgcs,UID:dfe8691b-1a87-11e9-8458-5254003c4592,ResourceVersion:91639,Generation:0,CreationTimestamp:2019-01-17 18:44:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 dc313074-1a87-11e9-8458-5254003c4592 0xc0025327f7 0xc0025327f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fz7h7 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fz7h7,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fz7h7 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002532a00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002532a20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC  }],Message:,Reason:,HostIP:192.168.122.53,PodIP:,StartTime:2019-01-17 18:44:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 17 18:44:11.260: INFO: Pod "nginx-deployment-555b55d965-wq8km" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-wq8km,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-svs44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-svs44/pods/nginx-deployment-555b55d965-wq8km,UID:dc366f78-1a87-11e9-8458-5254003c4592,ResourceVersion:91429,Generation:0,CreationTimestamp:2019-01-17 18:44:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 dc313074-1a87-11e9-8458-5254003c4592 0xc002532b07 0xc002532b08}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fz7h7 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fz7h7,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fz7h7 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002532b80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002532ba0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:02 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:05 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:05 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:02 +0000 UTC  }],Message:,Reason:,HostIP:192.168.122.53,PodIP:10.244.1.129,StartTime:2019-01-17 18:44:02 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-17 18:44:05 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:507234ea54dc6a9c7dd6a4b5d8649802bf711bcc7a7b2381ce404982f0f6966e cri-o://d6e6b3f2877b64ccce76403936072391b11ec950c42340338dfa1a32f20f19d8}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 17 18:44:11.260: INFO: Pod "nginx-deployment-555b55d965-xssvm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-xssvm,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-svs44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-svs44/pods/nginx-deployment-555b55d965-xssvm,UID:dfeee19c-1a87-11e9-8458-5254003c4592,ResourceVersion:91608,Generation:0,CreationTimestamp:2019-01-17 18:44:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 dc313074-1a87-11e9-8458-5254003c4592 0xc002532c67 0xc002532c68}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fz7h7 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fz7h7,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fz7h7 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002532d20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002532d40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC  }],Message:,Reason:,HostIP:192.168.122.54,PodIP:,StartTime:2019-01-17 18:44:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 17 18:44:11.260: INFO: Pod "nginx-deployment-555b55d965-z5w4v" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-z5w4v,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-svs44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-svs44/pods/nginx-deployment-555b55d965-z5w4v,UID:dfe591a1-1a87-11e9-8458-5254003c4592,ResourceVersion:91607,Generation:0,CreationTimestamp:2019-01-17 18:44:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 dc313074-1a87-11e9-8458-5254003c4592 0xc002532df7 0xc002532df8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fz7h7 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fz7h7,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fz7h7 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002532ea0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002532ec0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC  }],Message:,Reason:,HostIP:192.168.122.53,PodIP:,StartTime:2019-01-17 18:44:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 17 18:44:11.260: INFO: Pod "nginx-deployment-65bbdb5f8-2r5xb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-2r5xb,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-svs44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-svs44/pods/nginx-deployment-65bbdb5f8-2r5xb,UID:dff28d88-1a87-11e9-8458-5254003c4592,ResourceVersion:91644,Generation:0,CreationTimestamp:2019-01-17 18:44:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 dea3d912-1a87-11e9-8458-5254003c4592 0xc002532f77 0xc002532f78}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fz7h7 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fz7h7,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-fz7h7 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002532ff0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002533010}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC  }],Message:,Reason:,HostIP:192.168.122.53,PodIP:,StartTime:2019-01-17 18:44:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 17 18:44:11.261: INFO: Pod "nginx-deployment-65bbdb5f8-82wqh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-82wqh,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-svs44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-svs44/pods/nginx-deployment-65bbdb5f8-82wqh,UID:dea60f51-1a87-11e9-8458-5254003c4592,ResourceVersion:91490,Generation:0,CreationTimestamp:2019-01-17 18:44:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 dea3d912-1a87-11e9-8458-5254003c4592 0xc002533140 0xc002533141}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fz7h7 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fz7h7,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-fz7h7 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025331c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025331e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:06 +0000 UTC  }],Message:,Reason:,HostIP:192.168.122.53,PodIP:,StartTime:2019-01-17 18:44:07 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 17 18:44:11.261: INFO: Pod "nginx-deployment-65bbdb5f8-9kh6n" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-9kh6n,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-svs44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-svs44/pods/nginx-deployment-65bbdb5f8-9kh6n,UID:dfe8477e-1a87-11e9-8458-5254003c4592,ResourceVersion:91613,Generation:0,CreationTimestamp:2019-01-17 18:44:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 dea3d912-1a87-11e9-8458-5254003c4592 0xc002533310 0xc002533311}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fz7h7 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fz7h7,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-fz7h7 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002533390} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025333b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC  }],Message:,Reason:,HostIP:192.168.122.53,PodIP:,StartTime:2019-01-17 18:44:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 17 18:44:11.261: INFO: Pod "nginx-deployment-65bbdb5f8-ffb6b" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-ffb6b,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-svs44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-svs44/pods/nginx-deployment-65bbdb5f8-ffb6b,UID:dfeeb982-1a87-11e9-8458-5254003c4592,ResourceVersion:91657,Generation:0,CreationTimestamp:2019-01-17 18:44:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 dea3d912-1a87-11e9-8458-5254003c4592 0xc002533470 0xc002533471}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fz7h7 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fz7h7,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-fz7h7 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002533580} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025335a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC  }],Message:,Reason:,HostIP:192.168.122.53,PodIP:,StartTime:2019-01-17 18:44:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 17 18:44:11.261: INFO: Pod "nginx-deployment-65bbdb5f8-hnbnl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-hnbnl,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-svs44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-svs44/pods/nginx-deployment-65bbdb5f8-hnbnl,UID:dfeec658-1a87-11e9-8458-5254003c4592,ResourceVersion:91628,Generation:0,CreationTimestamp:2019-01-17 18:44:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 dea3d912-1a87-11e9-8458-5254003c4592 0xc002533660 0xc002533661}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fz7h7 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fz7h7,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-fz7h7 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002533790} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025337b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC  }],Message:,Reason:,HostIP:192.168.122.54,PodIP:,StartTime:2019-01-17 18:44:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 17 18:44:11.261: INFO: Pod "nginx-deployment-65bbdb5f8-k65bv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-k65bv,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-svs44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-svs44/pods/nginx-deployment-65bbdb5f8-k65bv,UID:dea82848-1a87-11e9-8458-5254003c4592,ResourceVersion:91502,Generation:0,CreationTimestamp:2019-01-17 18:44:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 dea3d912-1a87-11e9-8458-5254003c4592 0xc002533870 0xc002533871}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fz7h7 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fz7h7,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-fz7h7 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025339a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025339c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:07 +0000 UTC  }],Message:,Reason:,HostIP:192.168.122.53,PodIP:,StartTime:2019-01-17 18:44:07 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 17 18:44:11.261: INFO: Pod "nginx-deployment-65bbdb5f8-lzw7n" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-lzw7n,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-svs44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-svs44/pods/nginx-deployment-65bbdb5f8-lzw7n,UID:deb3717e-1a87-11e9-8458-5254003c4592,ResourceVersion:91508,Generation:0,CreationTimestamp:2019-01-17 18:44:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 dea3d912-1a87-11e9-8458-5254003c4592 0xc002533a80 0xc002533a81}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fz7h7 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fz7h7,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-fz7h7 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002533b00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002533b20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:07 +0000 UTC  }],Message:,Reason:,HostIP:192.168.122.54,PodIP:,StartTime:2019-01-17 18:44:07 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 17 18:44:11.261: INFO: Pod "nginx-deployment-65bbdb5f8-n2v7l" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-n2v7l,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-svs44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-svs44/pods/nginx-deployment-65bbdb5f8-n2v7l,UID:dfe86c81-1a87-11e9-8458-5254003c4592,ResourceVersion:91603,Generation:0,CreationTimestamp:2019-01-17 18:44:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 dea3d912-1a87-11e9-8458-5254003c4592 0xc002533cc0 0xc002533cc1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fz7h7 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fz7h7,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-fz7h7 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002533d40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002533d60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC  }],Message:,Reason:,HostIP:192.168.122.54,PodIP:,StartTime:2019-01-17 18:44:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 17 18:44:11.261: INFO: Pod "nginx-deployment-65bbdb5f8-tw745" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-tw745,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-svs44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-svs44/pods/nginx-deployment-65bbdb5f8-tw745,UID:dfeece73-1a87-11e9-8458-5254003c4592,ResourceVersion:91638,Generation:0,CreationTimestamp:2019-01-17 18:44:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 dea3d912-1a87-11e9-8458-5254003c4592 0xc002533ee0 0xc002533ee1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fz7h7 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fz7h7,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-fz7h7 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002533f60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002533f80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC  }],Message:,Reason:,HostIP:192.168.122.54,PodIP:,StartTime:2019-01-17 18:44:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 17 18:44:11.262: INFO: Pod "nginx-deployment-65bbdb5f8-v8wbg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-v8wbg,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-svs44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-svs44/pods/nginx-deployment-65bbdb5f8-v8wbg,UID:deb50beb-1a87-11e9-8458-5254003c4592,ResourceVersion:91513,Generation:0,CreationTimestamp:2019-01-17 18:44:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 dea3d912-1a87-11e9-8458-5254003c4592 0xc0025860e0 0xc0025860e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fz7h7 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fz7h7,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-fz7h7 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002586160} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002586180}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:07 +0000 UTC  }],Message:,Reason:,HostIP:192.168.122.53,PodIP:,StartTime:2019-01-17 18:44:07 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 17 18:44:11.265: INFO: Pod "nginx-deployment-65bbdb5f8-vp2w4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-vp2w4,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-svs44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-svs44/pods/nginx-deployment-65bbdb5f8-vp2w4,UID:dfe57ed9-1a87-11e9-8458-5254003c4592,ResourceVersion:91578,Generation:0,CreationTimestamp:2019-01-17 18:44:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 dea3d912-1a87-11e9-8458-5254003c4592 0xc0025863f0 0xc0025863f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fz7h7 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fz7h7,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-fz7h7 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002586470} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002586490}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC  }],Message:,Reason:,HostIP:192.168.122.54,PodIP:,StartTime:2019-01-17 18:44:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 17 18:44:11.265: INFO: Pod "nginx-deployment-65bbdb5f8-wmgwq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-wmgwq,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-svs44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-svs44/pods/nginx-deployment-65bbdb5f8-wmgwq,UID:dea7ed25-1a87-11e9-8458-5254003c4592,ResourceVersion:91491,Generation:0,CreationTimestamp:2019-01-17 18:44:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 dea3d912-1a87-11e9-8458-5254003c4592 0xc002586550 0xc002586551}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fz7h7 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fz7h7,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-fz7h7 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002586630} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002586650}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:07 +0000 UTC  }],Message:,Reason:,HostIP:192.168.122.54,PodIP:,StartTime:2019-01-17 18:44:07 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 17 18:44:11.266: INFO: Pod "nginx-deployment-65bbdb5f8-xjvss" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-xjvss,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-svs44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-svs44/pods/nginx-deployment-65bbdb5f8-xjvss,UID:dfeed28c-1a87-11e9-8458-5254003c4592,ResourceVersion:91642,Generation:0,CreationTimestamp:2019-01-17 18:44:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 dea3d912-1a87-11e9-8458-5254003c4592 0xc002586710 0xc002586711}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fz7h7 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fz7h7,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-fz7h7 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025867d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025867f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-17 18:44:09 +0000 UTC  }],Message:,Reason:,HostIP:192.168.122.54,PodIP:,StartTime:2019-01-17 18:44:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:44:11.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-svs44" for this suite.
Jan 17 18:44:19.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:44:19.387: INFO: namespace: e2e-tests-deployment-svs44, resource: bindings, ignored listing per whitelist
Jan 17 18:44:19.441: INFO: namespace e2e-tests-deployment-svs44 deletion completed in 8.122364389s

• [SLOW TEST:16.709 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:44:19.448: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-e62aecd4-1a87-11e9-a4b6-0a580af40269
STEP: Creating a pod to test consume secrets
Jan 17 18:44:19.618: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e62c1979-1a87-11e9-a4b6-0a580af40269" in namespace "e2e-tests-projected-g2nlk" to be "success or failure"
Jan 17 18:44:19.634: INFO: Pod "pod-projected-secrets-e62c1979-1a87-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 16.383604ms
Jan 17 18:44:21.638: INFO: Pod "pod-projected-secrets-e62c1979-1a87-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019676346s
Jan 17 18:44:23.670: INFO: Pod "pod-projected-secrets-e62c1979-1a87-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052175641s
STEP: Saw pod success
Jan 17 18:44:23.670: INFO: Pod "pod-projected-secrets-e62c1979-1a87-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 18:44:23.672: INFO: Trying to get logs from node node1 pod pod-projected-secrets-e62c1979-1a87-11e9-a4b6-0a580af40269 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan 17 18:44:23.730: INFO: Waiting for pod pod-projected-secrets-e62c1979-1a87-11e9-a4b6-0a580af40269 to disappear
Jan 17 18:44:23.732: INFO: Pod pod-projected-secrets-e62c1979-1a87-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:44:23.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-g2nlk" for this suite.
Jan 17 18:44:29.761: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:44:29.822: INFO: namespace: e2e-tests-projected-g2nlk, resource: bindings, ignored listing per whitelist
Jan 17 18:44:29.863: INFO: namespace e2e-tests-projected-g2nlk deletion completed in 6.124174758s

• [SLOW TEST:10.415 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:44:29.867: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Jan 17 18:44:29.977: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-043318780 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:44:30.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hfc7p" for this suite.
Jan 17 18:44:36.079: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:44:36.170: INFO: namespace: e2e-tests-kubectl-hfc7p, resource: bindings, ignored listing per whitelist
Jan 17 18:44:36.173: INFO: namespace e2e-tests-kubectl-hfc7p deletion completed in 6.116220571s

• [SLOW TEST:6.307 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:44:36.173: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-tp5pk
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-tp5pk to expose endpoints map[]
Jan 17 18:44:36.312: INFO: Get endpoints failed (14.158349ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Jan 17 18:44:37.316: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-tp5pk exposes endpoints map[] (1.018147639s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-tp5pk
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-tp5pk to expose endpoints map[pod1:[80]]
Jan 17 18:44:40.367: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-tp5pk exposes endpoints map[pod1:[80]] (3.039157441s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-tp5pk
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-tp5pk to expose endpoints map[pod2:[80] pod1:[80]]
Jan 17 18:44:43.480: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-tp5pk exposes endpoints map[pod1:[80] pod2:[80]] (3.107654129s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-tp5pk
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-tp5pk to expose endpoints map[pod2:[80]]
Jan 17 18:44:43.521: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-tp5pk exposes endpoints map[pod2:[80]] (36.039015ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-tp5pk
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-tp5pk to expose endpoints map[]
Jan 17 18:44:43.543: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-tp5pk exposes endpoints map[] (10.426666ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:44:43.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-tp5pk" for this suite.
Jan 17 18:44:49.765: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:44:49.809: INFO: namespace: e2e-tests-services-tp5pk, resource: bindings, ignored listing per whitelist
Jan 17 18:44:49.853: INFO: namespace e2e-tests-services-tp5pk deletion completed in 6.160709937s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:13.680 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:44:49.853: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Jan 17 18:44:54.047: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-f847f1a9-1a87-11e9-a4b6-0a580af40269", GenerateName:"", Namespace:"e2e-tests-pods-8xv5x", SelfLink:"/api/v1/namespaces/e2e-tests-pods-8xv5x/pods/pod-submit-remove-f847f1a9-1a87-11e9-a4b6-0a580af40269", UID:"f8490423-1a87-11e9-8458-5254003c4592", ResourceVersion:"92057", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63683347489, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"988244408"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-z7s6d", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc000dcf6c0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-z7s6d", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc00078f3f8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"node1", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0018e9380), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00078f440)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00078f460)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc00078f468), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00078f46c)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683347490, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683347492, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683347492, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683347489, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.122.53", PodIP:"10.244.1.150", StartTime:(*v1.Time)(0xc0013929a0), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc0013929c0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"docker.io/library/nginx:1.14-alpine", ImageID:"docker.io/library/nginx@sha256:507234ea54dc6a9c7dd6a4b5d8649802bf711bcc7a7b2381ce404982f0f6966e", ContainerID:"cri-o://bc321e2e35ca3a27f7af66eeee6adb659cdafd5c4f119abf4816517b67871354"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:44:59.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-8xv5x" for this suite.
Jan 17 18:45:05.104: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:45:05.176: INFO: namespace: e2e-tests-pods-8xv5x, resource: bindings, ignored listing per whitelist
Jan 17 18:45:05.186: INFO: namespace e2e-tests-pods-8xv5x deletion completed in 6.104067806s

• [SLOW TEST:15.333 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:45:05.186: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 17 18:45:05.282: INFO: Waiting up to 5m0s for pod "downwardapi-volume-01642ee0-1a88-11e9-a4b6-0a580af40269" in namespace "e2e-tests-projected-gxnzz" to be "success or failure"
Jan 17 18:45:05.296: INFO: Pod "downwardapi-volume-01642ee0-1a88-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 13.596046ms
Jan 17 18:45:07.300: INFO: Pod "downwardapi-volume-01642ee0-1a88-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017837499s
Jan 17 18:45:09.335: INFO: Pod "downwardapi-volume-01642ee0-1a88-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053133862s
STEP: Saw pod success
Jan 17 18:45:09.336: INFO: Pod "downwardapi-volume-01642ee0-1a88-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 18:45:09.346: INFO: Trying to get logs from node node1 pod downwardapi-volume-01642ee0-1a88-11e9-a4b6-0a580af40269 container client-container: <nil>
STEP: delete the pod
Jan 17 18:45:09.422: INFO: Waiting for pod downwardapi-volume-01642ee0-1a88-11e9-a4b6-0a580af40269 to disappear
Jan 17 18:45:09.425: INFO: Pod downwardapi-volume-01642ee0-1a88-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:45:09.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gxnzz" for this suite.
Jan 17 18:45:15.449: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:45:15.498: INFO: namespace: e2e-tests-projected-gxnzz, resource: bindings, ignored listing per whitelist
Jan 17 18:45:15.528: INFO: namespace e2e-tests-projected-gxnzz deletion completed in 6.098577412s

• [SLOW TEST:10.342 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:45:15.529: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-jpmbv/configmap-test-078c0e43-1a88-11e9-a4b6-0a580af40269
STEP: Creating a pod to test consume configMaps
Jan 17 18:45:15.620: INFO: Waiting up to 5m0s for pod "pod-configmaps-078d9a0c-1a88-11e9-a4b6-0a580af40269" in namespace "e2e-tests-configmap-jpmbv" to be "success or failure"
Jan 17 18:45:15.630: INFO: Pod "pod-configmaps-078d9a0c-1a88-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 9.485043ms
Jan 17 18:45:17.635: INFO: Pod "pod-configmaps-078d9a0c-1a88-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014492201s
Jan 17 18:45:19.675: INFO: Pod "pod-configmaps-078d9a0c-1a88-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054594987s
STEP: Saw pod success
Jan 17 18:45:19.675: INFO: Pod "pod-configmaps-078d9a0c-1a88-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 18:45:19.684: INFO: Trying to get logs from node node1 pod pod-configmaps-078d9a0c-1a88-11e9-a4b6-0a580af40269 container env-test: <nil>
STEP: delete the pod
Jan 17 18:45:19.750: INFO: Waiting for pod pod-configmaps-078d9a0c-1a88-11e9-a4b6-0a580af40269 to disappear
Jan 17 18:45:19.753: INFO: Pod pod-configmaps-078d9a0c-1a88-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:45:19.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-jpmbv" for this suite.
Jan 17 18:45:25.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:45:25.848: INFO: namespace: e2e-tests-configmap-jpmbv, resource: bindings, ignored listing per whitelist
Jan 17 18:45:25.856: INFO: namespace e2e-tests-configmap-jpmbv deletion completed in 6.098130372s

• [SLOW TEST:10.328 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:45:25.857: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Jan 17 18:45:32.170: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wzzrc PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 17 18:45:32.170: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
Jan 17 18:45:32.227: INFO: Exec stderr: ""
Jan 17 18:45:32.227: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wzzrc PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 17 18:45:32.227: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
Jan 17 18:45:32.275: INFO: Exec stderr: ""
Jan 17 18:45:32.275: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wzzrc PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 17 18:45:32.275: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
Jan 17 18:45:32.324: INFO: Exec stderr: ""
Jan 17 18:45:32.324: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wzzrc PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 17 18:45:32.324: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
Jan 17 18:45:32.375: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Jan 17 18:45:32.375: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wzzrc PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 17 18:45:32.375: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
Jan 17 18:45:32.430: INFO: Exec stderr: ""
Jan 17 18:45:32.430: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wzzrc PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 17 18:45:32.430: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
Jan 17 18:45:32.478: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Jan 17 18:45:32.479: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wzzrc PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 17 18:45:32.479: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
Jan 17 18:45:32.520: INFO: Exec stderr: ""
Jan 17 18:45:32.520: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wzzrc PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 17 18:45:32.520: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
Jan 17 18:45:32.567: INFO: Exec stderr: ""
Jan 17 18:45:32.567: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wzzrc PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 17 18:45:32.570: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
Jan 17 18:45:32.618: INFO: Exec stderr: ""
Jan 17 18:45:32.618: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wzzrc PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 17 18:45:32.618: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
Jan 17 18:45:32.662: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:45:32.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-wzzrc" for this suite.
Jan 17 18:46:22.702: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:46:22.734: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-wzzrc, resource: bindings, ignored listing per whitelist
Jan 17 18:46:22.790: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-wzzrc deletion completed in 50.108540167s

• [SLOW TEST:56.934 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:46:22.791: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan 17 18:46:22.891: INFO: Waiting up to 5m0s for pod "downward-api-2fa5a116-1a88-11e9-a4b6-0a580af40269" in namespace "e2e-tests-downward-api-w6mw2" to be "success or failure"
Jan 17 18:46:22.917: INFO: Pod "downward-api-2fa5a116-1a88-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 25.776939ms
Jan 17 18:46:24.954: INFO: Pod "downward-api-2fa5a116-1a88-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.062490039s
STEP: Saw pod success
Jan 17 18:46:24.954: INFO: Pod "downward-api-2fa5a116-1a88-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 18:46:24.957: INFO: Trying to get logs from node node1 pod downward-api-2fa5a116-1a88-11e9-a4b6-0a580af40269 container dapi-container: <nil>
STEP: delete the pod
Jan 17 18:46:24.998: INFO: Waiting for pod downward-api-2fa5a116-1a88-11e9-a4b6-0a580af40269 to disappear
Jan 17 18:46:25.001: INFO: Pod downward-api-2fa5a116-1a88-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:46:25.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-w6mw2" for this suite.
Jan 17 18:46:31.021: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:46:31.056: INFO: namespace: e2e-tests-downward-api-w6mw2, resource: bindings, ignored listing per whitelist
Jan 17 18:46:31.102: INFO: namespace e2e-tests-downward-api-w6mw2 deletion completed in 6.098163277s

• [SLOW TEST:8.312 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:46:31.103: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 17 18:46:31.198: INFO: Waiting up to 5m0s for pod "downwardapi-volume-349a1c2e-1a88-11e9-a4b6-0a580af40269" in namespace "e2e-tests-downward-api-xxcnm" to be "success or failure"
Jan 17 18:46:31.207: INFO: Pod "downwardapi-volume-349a1c2e-1a88-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 9.189337ms
Jan 17 18:46:33.216: INFO: Pod "downwardapi-volume-349a1c2e-1a88-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017711863s
Jan 17 18:46:35.258: INFO: Pod "downwardapi-volume-349a1c2e-1a88-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.060340814s
STEP: Saw pod success
Jan 17 18:46:35.258: INFO: Pod "downwardapi-volume-349a1c2e-1a88-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 18:46:35.261: INFO: Trying to get logs from node node1 pod downwardapi-volume-349a1c2e-1a88-11e9-a4b6-0a580af40269 container client-container: <nil>
STEP: delete the pod
Jan 17 18:46:35.302: INFO: Waiting for pod downwardapi-volume-349a1c2e-1a88-11e9-a4b6-0a580af40269 to disappear
Jan 17 18:46:35.306: INFO: Pod downwardapi-volume-349a1c2e-1a88-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:46:35.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-xxcnm" for this suite.
Jan 17 18:46:41.349: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:46:41.427: INFO: namespace: e2e-tests-downward-api-xxcnm, resource: bindings, ignored listing per whitelist
Jan 17 18:46:41.439: INFO: namespace e2e-tests-downward-api-xxcnm deletion completed in 6.127581225s

• [SLOW TEST:10.337 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:46:41.440: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Jan 17 18:46:41.532: INFO: Waiting up to 5m0s for pod "client-containers-3ac29627-1a88-11e9-a4b6-0a580af40269" in namespace "e2e-tests-containers-gn4mh" to be "success or failure"
Jan 17 18:46:41.541: INFO: Pod "client-containers-3ac29627-1a88-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 8.160094ms
Jan 17 18:46:43.548: INFO: Pod "client-containers-3ac29627-1a88-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015655437s
Jan 17 18:46:45.587: INFO: Pod "client-containers-3ac29627-1a88-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054513206s
STEP: Saw pod success
Jan 17 18:46:45.587: INFO: Pod "client-containers-3ac29627-1a88-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 18:46:45.598: INFO: Trying to get logs from node node1 pod client-containers-3ac29627-1a88-11e9-a4b6-0a580af40269 container test-container: <nil>
STEP: delete the pod
Jan 17 18:46:45.654: INFO: Waiting for pod client-containers-3ac29627-1a88-11e9-a4b6-0a580af40269 to disappear
Jan 17 18:46:45.657: INFO: Pod client-containers-3ac29627-1a88-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:46:45.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-gn4mh" for this suite.
Jan 17 18:46:51.678: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:46:51.753: INFO: namespace: e2e-tests-containers-gn4mh, resource: bindings, ignored listing per whitelist
Jan 17 18:46:51.771: INFO: namespace e2e-tests-containers-gn4mh deletion completed in 6.110974458s

• [SLOW TEST:10.331 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:46:51.777: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jan 17 18:46:51.863: INFO: Waiting up to 5m0s for pod "pod-40eb28a9-1a88-11e9-a4b6-0a580af40269" in namespace "e2e-tests-emptydir-7qklg" to be "success or failure"
Jan 17 18:46:51.873: INFO: Pod "pod-40eb28a9-1a88-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 9.813881ms
Jan 17 18:46:53.875: INFO: Pod "pod-40eb28a9-1a88-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011938649s
Jan 17 18:46:55.914: INFO: Pod "pod-40eb28a9-1a88-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050639881s
STEP: Saw pod success
Jan 17 18:46:55.914: INFO: Pod "pod-40eb28a9-1a88-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 18:46:55.918: INFO: Trying to get logs from node node1 pod pod-40eb28a9-1a88-11e9-a4b6-0a580af40269 container test-container: <nil>
STEP: delete the pod
Jan 17 18:46:55.986: INFO: Waiting for pod pod-40eb28a9-1a88-11e9-a4b6-0a580af40269 to disappear
Jan 17 18:46:55.989: INFO: Pod pod-40eb28a9-1a88-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:46:55.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-7qklg" for this suite.
Jan 17 18:47:02.017: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:47:02.053: INFO: namespace: e2e-tests-emptydir-7qklg, resource: bindings, ignored listing per whitelist
Jan 17 18:47:02.083: INFO: namespace e2e-tests-emptydir-7qklg deletion completed in 6.083505923s

• [SLOW TEST:10.306 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:47:02.093: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jan 17 18:47:02.190: INFO: Waiting up to 5m0s for pod "pod-471234e0-1a88-11e9-a4b6-0a580af40269" in namespace "e2e-tests-emptydir-nqpm4" to be "success or failure"
Jan 17 18:47:02.198: INFO: Pod "pod-471234e0-1a88-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 7.339859ms
Jan 17 18:47:04.203: INFO: Pod "pod-471234e0-1a88-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012592713s
Jan 17 18:47:06.239: INFO: Pod "pod-471234e0-1a88-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048962641s
STEP: Saw pod success
Jan 17 18:47:06.240: INFO: Pod "pod-471234e0-1a88-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 18:47:06.249: INFO: Trying to get logs from node node1 pod pod-471234e0-1a88-11e9-a4b6-0a580af40269 container test-container: <nil>
STEP: delete the pod
Jan 17 18:47:06.322: INFO: Waiting for pod pod-471234e0-1a88-11e9-a4b6-0a580af40269 to disappear
Jan 17 18:47:06.325: INFO: Pod pod-471234e0-1a88-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:47:06.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-nqpm4" for this suite.
Jan 17 18:47:12.349: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:47:12.405: INFO: namespace: e2e-tests-emptydir-nqpm4, resource: bindings, ignored listing per whitelist
Jan 17 18:47:12.448: INFO: namespace e2e-tests-emptydir-nqpm4 deletion completed in 6.117535368s

• [SLOW TEST:10.356 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:47:12.452: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-rvc55
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-rvc55
STEP: Deleting pre-stop pod
Jan 17 18:47:25.609: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:47:25.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-rvc55" for this suite.
Jan 17 18:48:03.702: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:48:03.717: INFO: namespace: e2e-tests-prestop-rvc55, resource: bindings, ignored listing per whitelist
Jan 17 18:48:03.765: INFO: namespace e2e-tests-prestop-rvc55 deletion completed in 38.086484279s

• [SLOW TEST:51.313 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:48:03.765: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Jan 17 18:48:03.921: INFO: namespace e2e-tests-kubectl-h5q5n
Jan 17 18:48:03.921: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 create -f - --namespace=e2e-tests-kubectl-h5q5n'
Jan 17 18:48:04.051: INFO: stderr: ""
Jan 17 18:48:04.051: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Jan 17 18:48:05.059: INFO: Selector matched 1 pods for map[app:redis]
Jan 17 18:48:05.059: INFO: Found 0 / 1
Jan 17 18:48:06.061: INFO: Selector matched 1 pods for map[app:redis]
Jan 17 18:48:06.062: INFO: Found 0 / 1
Jan 17 18:48:07.095: INFO: Selector matched 1 pods for map[app:redis]
Jan 17 18:48:07.095: INFO: Found 1 / 1
Jan 17 18:48:07.095: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jan 17 18:48:07.106: INFO: Selector matched 1 pods for map[app:redis]
Jan 17 18:48:07.106: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jan 17 18:48:07.106: INFO: wait on redis-master startup in e2e-tests-kubectl-h5q5n 
Jan 17 18:48:07.107: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 logs redis-master-tpcgs redis-master --namespace=e2e-tests-kubectl-h5q5n'
Jan 17 18:48:07.279: INFO: stderr: ""
Jan 17 18:48:07.279: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 17 Jan 18:48:05.941 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 17 Jan 18:48:05.941 # Server started, Redis version 3.2.12\n1:M 17 Jan 18:48:05.941 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 17 Jan 18:48:05.941 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Jan 17 18:48:07.280: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-h5q5n'
Jan 17 18:48:07.402: INFO: stderr: ""
Jan 17 18:48:07.402: INFO: stdout: "service/rm2 exposed\n"
Jan 17 18:48:07.409: INFO: Service rm2 in namespace e2e-tests-kubectl-h5q5n found.
STEP: exposing service
Jan 17 18:48:09.422: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-h5q5n'
Jan 17 18:48:09.569: INFO: stderr: ""
Jan 17 18:48:09.569: INFO: stdout: "service/rm3 exposed\n"
Jan 17 18:48:09.581: INFO: Service rm3 in namespace e2e-tests-kubectl-h5q5n found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:48:11.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-h5q5n" for this suite.
Jan 17 18:48:33.648: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:48:33.702: INFO: namespace: e2e-tests-kubectl-h5q5n, resource: bindings, ignored listing per whitelist
Jan 17 18:48:33.746: INFO: namespace e2e-tests-kubectl-h5q5n deletion completed in 22.13788661s

• [SLOW TEST:29.981 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:48:33.747: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Jan 17 18:48:33.932: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 create -f - --namespace=e2e-tests-kubectl-wlkvs'
Jan 17 18:48:34.087: INFO: stderr: ""
Jan 17 18:48:34.087: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 17 18:48:34.087: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-wlkvs'
Jan 17 18:48:34.430: INFO: stderr: ""
Jan 17 18:48:34.430: INFO: stdout: "update-demo-nautilus-p76nb update-demo-nautilus-rw9ns "
Jan 17 18:48:34.430: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 get pods update-demo-nautilus-p76nb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wlkvs'
Jan 17 18:48:34.555: INFO: stderr: ""
Jan 17 18:48:34.555: INFO: stdout: ""
Jan 17 18:48:34.555: INFO: update-demo-nautilus-p76nb is created but not running
Jan 17 18:48:39.556: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-wlkvs'
Jan 17 18:48:39.899: INFO: stderr: ""
Jan 17 18:48:39.900: INFO: stdout: "update-demo-nautilus-p76nb update-demo-nautilus-rw9ns "
Jan 17 18:48:39.900: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 get pods update-demo-nautilus-p76nb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wlkvs'
Jan 17 18:48:40.032: INFO: stderr: ""
Jan 17 18:48:40.032: INFO: stdout: "true"
Jan 17 18:48:40.032: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 get pods update-demo-nautilus-p76nb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wlkvs'
Jan 17 18:48:40.151: INFO: stderr: ""
Jan 17 18:48:40.151: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 17 18:48:40.151: INFO: validating pod update-demo-nautilus-p76nb
Jan 17 18:48:40.170: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 17 18:48:40.171: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 17 18:48:40.171: INFO: update-demo-nautilus-p76nb is verified up and running
Jan 17 18:48:40.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 get pods update-demo-nautilus-rw9ns -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wlkvs'
Jan 17 18:48:40.292: INFO: stderr: ""
Jan 17 18:48:40.292: INFO: stdout: "true"
Jan 17 18:48:40.292: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 get pods update-demo-nautilus-rw9ns -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wlkvs'
Jan 17 18:48:40.391: INFO: stderr: ""
Jan 17 18:48:40.391: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 17 18:48:40.391: INFO: validating pod update-demo-nautilus-rw9ns
Jan 17 18:48:40.405: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 17 18:48:40.405: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 17 18:48:40.405: INFO: update-demo-nautilus-rw9ns is verified up and running
STEP: scaling down the replication controller
Jan 17 18:48:40.408: INFO: scanned /root for discovery docs: <nil>
Jan 17 18:48:40.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-wlkvs'
Jan 17 18:48:41.534: INFO: stderr: ""
Jan 17 18:48:41.534: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 17 18:48:41.534: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-wlkvs'
Jan 17 18:48:41.868: INFO: stderr: ""
Jan 17 18:48:41.868: INFO: stdout: "update-demo-nautilus-p76nb update-demo-nautilus-rw9ns "
STEP: Replicas for name=update-demo: expected=1 actual=2
Jan 17 18:48:46.869: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-wlkvs'
Jan 17 18:48:47.196: INFO: stderr: ""
Jan 17 18:48:47.196: INFO: stdout: "update-demo-nautilus-p76nb update-demo-nautilus-rw9ns "
STEP: Replicas for name=update-demo: expected=1 actual=2
Jan 17 18:48:52.197: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-wlkvs'
Jan 17 18:48:52.313: INFO: stderr: ""
Jan 17 18:48:52.313: INFO: stdout: "update-demo-nautilus-p76nb "
Jan 17 18:48:52.313: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 get pods update-demo-nautilus-p76nb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wlkvs'
Jan 17 18:48:52.411: INFO: stderr: ""
Jan 17 18:48:52.411: INFO: stdout: "true"
Jan 17 18:48:52.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 get pods update-demo-nautilus-p76nb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wlkvs'
Jan 17 18:48:52.531: INFO: stderr: ""
Jan 17 18:48:52.531: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 17 18:48:52.531: INFO: validating pod update-demo-nautilus-p76nb
Jan 17 18:48:52.534: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 17 18:48:52.534: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 17 18:48:52.534: INFO: update-demo-nautilus-p76nb is verified up and running
STEP: scaling up the replication controller
Jan 17 18:48:52.535: INFO: scanned /root for discovery docs: <nil>
Jan 17 18:48:52.535: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-wlkvs'
Jan 17 18:48:53.641: INFO: stderr: ""
Jan 17 18:48:53.641: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 17 18:48:53.641: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-wlkvs'
Jan 17 18:48:53.989: INFO: stderr: ""
Jan 17 18:48:53.989: INFO: stdout: "update-demo-nautilus-hhrgj update-demo-nautilus-p76nb "
Jan 17 18:48:53.989: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 get pods update-demo-nautilus-hhrgj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wlkvs'
Jan 17 18:48:54.108: INFO: stderr: ""
Jan 17 18:48:54.108: INFO: stdout: ""
Jan 17 18:48:54.109: INFO: update-demo-nautilus-hhrgj is created but not running
Jan 17 18:48:59.109: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-wlkvs'
Jan 17 18:48:59.455: INFO: stderr: ""
Jan 17 18:48:59.455: INFO: stdout: "update-demo-nautilus-hhrgj update-demo-nautilus-p76nb "
Jan 17 18:48:59.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 get pods update-demo-nautilus-hhrgj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wlkvs'
Jan 17 18:48:59.573: INFO: stderr: ""
Jan 17 18:48:59.573: INFO: stdout: "true"
Jan 17 18:48:59.573: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 get pods update-demo-nautilus-hhrgj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wlkvs'
Jan 17 18:48:59.692: INFO: stderr: ""
Jan 17 18:48:59.692: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 17 18:48:59.692: INFO: validating pod update-demo-nautilus-hhrgj
Jan 17 18:48:59.696: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 17 18:48:59.696: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 17 18:48:59.696: INFO: update-demo-nautilus-hhrgj is verified up and running
Jan 17 18:48:59.696: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 get pods update-demo-nautilus-p76nb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wlkvs'
Jan 17 18:48:59.795: INFO: stderr: ""
Jan 17 18:48:59.795: INFO: stdout: "true"
Jan 17 18:48:59.795: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 get pods update-demo-nautilus-p76nb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wlkvs'
Jan 17 18:48:59.915: INFO: stderr: ""
Jan 17 18:48:59.915: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 17 18:48:59.915: INFO: validating pod update-demo-nautilus-p76nb
Jan 17 18:48:59.919: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 17 18:48:59.920: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 17 18:48:59.920: INFO: update-demo-nautilus-p76nb is verified up and running
STEP: using delete to clean up resources
Jan 17 18:48:59.921: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-wlkvs'
Jan 17 18:49:00.017: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 17 18:49:00.017: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jan 17 18:49:00.019: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-wlkvs'
Jan 17 18:49:00.173: INFO: stderr: "No resources found.\n"
Jan 17 18:49:00.173: INFO: stdout: ""
Jan 17 18:49:00.173: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 get pods -l name=update-demo --namespace=e2e-tests-kubectl-wlkvs -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan 17 18:49:00.487: INFO: stderr: ""
Jan 17 18:49:00.487: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:49:00.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wlkvs" for this suite.
Jan 17 18:49:22.544: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:49:22.617: INFO: namespace: e2e-tests-kubectl-wlkvs, resource: bindings, ignored listing per whitelist
Jan 17 18:49:22.635: INFO: namespace e2e-tests-kubectl-wlkvs deletion completed in 22.112618831s

• [SLOW TEST:48.888 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:49:22.637: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-9adbdeb9-1a88-11e9-a4b6-0a580af40269
STEP: Creating secret with name s-test-opt-upd-9adbdee5-1a88-11e9-a4b6-0a580af40269
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-9adbdeb9-1a88-11e9-a4b6-0a580af40269
STEP: Updating secret s-test-opt-upd-9adbdee5-1a88-11e9-a4b6-0a580af40269
STEP: Creating secret with name s-test-opt-create-9adbdef8-1a88-11e9-a4b6-0a580af40269
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:49:28.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-sdd2h" for this suite.
Jan 17 18:49:51.040: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:49:51.112: INFO: namespace: e2e-tests-secrets-sdd2h, resource: bindings, ignored listing per whitelist
Jan 17 18:49:51.126: INFO: namespace e2e-tests-secrets-sdd2h deletion completed in 22.110878914s

• [SLOW TEST:28.489 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:49:51.126: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jan 17 18:49:55.883: INFO: Successfully updated pod "annotationupdateabdab0ab-1a88-11e9-a4b6-0a580af40269"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:49:57.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xprlh" for this suite.
Jan 17 18:50:19.973: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:50:20.019: INFO: namespace: e2e-tests-projected-xprlh, resource: bindings, ignored listing per whitelist
Jan 17 18:50:20.057: INFO: namespace e2e-tests-projected-xprlh deletion completed in 22.121672029s

• [SLOW TEST:28.931 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:50:20.058: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 17 18:50:20.224: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-fph4b'
Jan 17 18:50:20.914: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jan 17 18:50:20.914: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1268
Jan 17 18:50:22.931: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043318780 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-fph4b'
Jan 17 18:50:23.042: INFO: stderr: ""
Jan 17 18:50:23.042: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:50:23.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-fph4b" for this suite.
Jan 17 18:50:45.080: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:50:45.150: INFO: namespace: e2e-tests-kubectl-fph4b, resource: bindings, ignored listing per whitelist
Jan 17 18:50:45.176: INFO: namespace e2e-tests-kubectl-fph4b deletion completed in 22.121430026s

• [SLOW TEST:25.118 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:50:45.176: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan 17 18:50:45.383: INFO: Waiting up to 5m0s for pod "downward-api-cc1bd4db-1a88-11e9-a4b6-0a580af40269" in namespace "e2e-tests-downward-api-hcc65" to be "success or failure"
Jan 17 18:50:45.392: INFO: Pod "downward-api-cc1bd4db-1a88-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 6.821253ms
Jan 17 18:50:47.436: INFO: Pod "downward-api-cc1bd4db-1a88-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.050880921s
Jan 17 18:50:49.444: INFO: Pod "downward-api-cc1bd4db-1a88-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.059522543s
STEP: Saw pod success
Jan 17 18:50:49.445: INFO: Pod "downward-api-cc1bd4db-1a88-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 18:50:49.498: INFO: Trying to get logs from node node1 pod downward-api-cc1bd4db-1a88-11e9-a4b6-0a580af40269 container dapi-container: <nil>
STEP: delete the pod
Jan 17 18:50:49.530: INFO: Waiting for pod downward-api-cc1bd4db-1a88-11e9-a4b6-0a580af40269 to disappear
Jan 17 18:50:49.541: INFO: Pod downward-api-cc1bd4db-1a88-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:50:49.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-hcc65" for this suite.
Jan 17 18:50:55.564: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:50:55.630: INFO: namespace: e2e-tests-downward-api-hcc65, resource: bindings, ignored listing per whitelist
Jan 17 18:50:55.650: INFO: namespace e2e-tests-downward-api-hcc65 deletion completed in 6.103465552s

• [SLOW TEST:10.474 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:50:55.657: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Jan 17 18:50:55.767: INFO: Waiting up to 5m0s for pod "client-containers-d24c7377-1a88-11e9-a4b6-0a580af40269" in namespace "e2e-tests-containers-2x5mc" to be "success or failure"
Jan 17 18:50:55.776: INFO: Pod "client-containers-d24c7377-1a88-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 9.139139ms
Jan 17 18:50:57.784: INFO: Pod "client-containers-d24c7377-1a88-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017089874s
Jan 17 18:50:59.791: INFO: Pod "client-containers-d24c7377-1a88-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023617585s
STEP: Saw pod success
Jan 17 18:50:59.791: INFO: Pod "client-containers-d24c7377-1a88-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 18:50:59.796: INFO: Trying to get logs from node node1 pod client-containers-d24c7377-1a88-11e9-a4b6-0a580af40269 container test-container: <nil>
STEP: delete the pod
Jan 17 18:50:59.824: INFO: Waiting for pod client-containers-d24c7377-1a88-11e9-a4b6-0a580af40269 to disappear
Jan 17 18:50:59.832: INFO: Pod client-containers-d24c7377-1a88-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:50:59.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-2x5mc" for this suite.
Jan 17 18:51:05.913: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:51:05.972: INFO: namespace: e2e-tests-containers-2x5mc, resource: bindings, ignored listing per whitelist
Jan 17 18:51:06.001: INFO: namespace e2e-tests-containers-2x5mc deletion completed in 6.114252017s

• [SLOW TEST:10.344 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:51:06.001: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-d87e3fb2-1a88-11e9-a4b6-0a580af40269
STEP: Creating a pod to test consume configMaps
Jan 17 18:51:06.171: INFO: Waiting up to 5m0s for pod "pod-configmaps-d87f4ae0-1a88-11e9-a4b6-0a580af40269" in namespace "e2e-tests-configmap-5kmxp" to be "success or failure"
Jan 17 18:51:06.180: INFO: Pod "pod-configmaps-d87f4ae0-1a88-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 8.292997ms
Jan 17 18:51:08.189: INFO: Pod "pod-configmaps-d87f4ae0-1a88-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017107891s
Jan 17 18:51:10.231: INFO: Pod "pod-configmaps-d87f4ae0-1a88-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.059563695s
STEP: Saw pod success
Jan 17 18:51:10.231: INFO: Pod "pod-configmaps-d87f4ae0-1a88-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 18:51:10.241: INFO: Trying to get logs from node node1 pod pod-configmaps-d87f4ae0-1a88-11e9-a4b6-0a580af40269 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 17 18:51:10.326: INFO: Waiting for pod pod-configmaps-d87f4ae0-1a88-11e9-a4b6-0a580af40269 to disappear
Jan 17 18:51:10.329: INFO: Pod pod-configmaps-d87f4ae0-1a88-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:51:10.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-5kmxp" for this suite.
Jan 17 18:51:16.354: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:51:16.418: INFO: namespace: e2e-tests-configmap-5kmxp, resource: bindings, ignored listing per whitelist
Jan 17 18:51:16.453: INFO: namespace e2e-tests-configmap-5kmxp deletion completed in 6.118081863s

• [SLOW TEST:10.452 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:51:16.454: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jan 17 18:51:16.521: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:51:23.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-r2jhr" for this suite.
Jan 17 18:51:29.088: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:51:29.127: INFO: namespace: e2e-tests-init-container-r2jhr, resource: bindings, ignored listing per whitelist
Jan 17 18:51:29.177: INFO: namespace e2e-tests-init-container-r2jhr deletion completed in 6.112731625s

• [SLOW TEST:12.723 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:51:29.177: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0117 18:51:39.536665      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 17 18:51:39.536: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:51:39.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-rhqkb" for this suite.
Jan 17 18:51:45.562: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:51:45.581: INFO: namespace: e2e-tests-gc-rhqkb, resource: bindings, ignored listing per whitelist
Jan 17 18:51:45.638: INFO: namespace e2e-tests-gc-rhqkb deletion completed in 6.096404215s

• [SLOW TEST:16.462 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:51:45.639: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jan 17 18:51:45.804: INFO: Waiting up to 5m0s for pod "pod-f01dcda8-1a88-11e9-a4b6-0a580af40269" in namespace "e2e-tests-emptydir-ljmfd" to be "success or failure"
Jan 17 18:51:45.814: INFO: Pod "pod-f01dcda8-1a88-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 10.038142ms
Jan 17 18:51:47.822: INFO: Pod "pod-f01dcda8-1a88-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01781918s
Jan 17 18:51:49.831: INFO: Pod "pod-f01dcda8-1a88-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026881155s
STEP: Saw pod success
Jan 17 18:51:49.831: INFO: Pod "pod-f01dcda8-1a88-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 18:51:49.838: INFO: Trying to get logs from node node1 pod pod-f01dcda8-1a88-11e9-a4b6-0a580af40269 container test-container: <nil>
STEP: delete the pod
Jan 17 18:51:49.865: INFO: Waiting for pod pod-f01dcda8-1a88-11e9-a4b6-0a580af40269 to disappear
Jan 17 18:51:49.869: INFO: Pod pod-f01dcda8-1a88-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:51:49.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-ljmfd" for this suite.
Jan 17 18:51:55.973: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:51:56.024: INFO: namespace: e2e-tests-emptydir-ljmfd, resource: bindings, ignored listing per whitelist
Jan 17 18:51:56.042: INFO: namespace e2e-tests-emptydir-ljmfd deletion completed in 6.116911666s

• [SLOW TEST:10.403 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:51:56.043: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Jan 17 18:51:56.259: INFO: Waiting up to 5m0s for pod "var-expansion-f65a4388-1a88-11e9-a4b6-0a580af40269" in namespace "e2e-tests-var-expansion-v4d94" to be "success or failure"
Jan 17 18:51:56.266: INFO: Pod "var-expansion-f65a4388-1a88-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 6.454759ms
Jan 17 18:51:58.276: INFO: Pod "var-expansion-f65a4388-1a88-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016243354s
Jan 17 18:52:00.319: INFO: Pod "var-expansion-f65a4388-1a88-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.059426663s
STEP: Saw pod success
Jan 17 18:52:00.319: INFO: Pod "var-expansion-f65a4388-1a88-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 18:52:00.331: INFO: Trying to get logs from node node1 pod var-expansion-f65a4388-1a88-11e9-a4b6-0a580af40269 container dapi-container: <nil>
STEP: delete the pod
Jan 17 18:52:00.406: INFO: Waiting for pod var-expansion-f65a4388-1a88-11e9-a4b6-0a580af40269 to disappear
Jan 17 18:52:00.408: INFO: Pod var-expansion-f65a4388-1a88-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:52:00.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-v4d94" for this suite.
Jan 17 18:52:06.429: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:52:06.484: INFO: namespace: e2e-tests-var-expansion-v4d94, resource: bindings, ignored listing per whitelist
Jan 17 18:52:06.520: INFO: namespace e2e-tests-var-expansion-v4d94 deletion completed in 6.108695768s

• [SLOW TEST:10.477 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 17 18:52:06.520: INFO: >>> kubeConfig: /tmp/kubeconfig-043318780
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Jan 17 18:52:06.741: INFO: Waiting up to 5m0s for pod "pod-fc99d59e-1a88-11e9-a4b6-0a580af40269" in namespace "e2e-tests-emptydir-bzzrg" to be "success or failure"
Jan 17 18:52:06.750: INFO: Pod "pod-fc99d59e-1a88-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 9.011117ms
Jan 17 18:52:08.754: INFO: Pod "pod-fc99d59e-1a88-11e9-a4b6-0a580af40269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012094653s
Jan 17 18:52:10.763: INFO: Pod "pod-fc99d59e-1a88-11e9-a4b6-0a580af40269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021428866s
STEP: Saw pod success
Jan 17 18:52:10.763: INFO: Pod "pod-fc99d59e-1a88-11e9-a4b6-0a580af40269" satisfied condition "success or failure"
Jan 17 18:52:10.781: INFO: Trying to get logs from node node1 pod pod-fc99d59e-1a88-11e9-a4b6-0a580af40269 container test-container: <nil>
STEP: delete the pod
Jan 17 18:52:10.835: INFO: Waiting for pod pod-fc99d59e-1a88-11e9-a4b6-0a580af40269 to disappear
Jan 17 18:52:10.846: INFO: Pod pod-fc99d59e-1a88-11e9-a4b6-0a580af40269 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 17 18:52:10.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-bzzrg" for this suite.
Jan 17 18:52:16.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 17 18:52:17.021: INFO: namespace: e2e-tests-emptydir-bzzrg, resource: bindings, ignored listing per whitelist
Jan 17 18:52:17.031: INFO: namespace e2e-tests-emptydir-bzzrg deletion completed in 6.127649913s

• [SLOW TEST:10.510 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSJan 17 18:52:17.031: INFO: Running AfterSuite actions on all nodes
Jan 17 18:52:17.031: INFO: Running AfterSuite actions on node 1
Jan 17 18:52:17.031: INFO: Skipping dumping logs from cluster

Ran 200 of 1946 Specs in 5821.033 seconds
SUCCESS! -- 200 Passed | 0 Failed | 0 Pending | 1746 Skipped PASS

Ginkgo ran 1 suite in 1h37m1.906835394s
Test Suite Passed
