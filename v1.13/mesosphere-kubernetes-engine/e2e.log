I0207 02:33:52.061588      17 test_context.go:358] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-221081943
I0207 02:33:52.061716      17 e2e.go:224] Starting e2e run "ce3d182c-2a80-11e9-87fe-baa4eca941e3" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1549506831 - Will randomize all specs
Will run 201 of 1946 specs

Feb  7 02:33:52.204: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
Feb  7 02:33:52.206: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Feb  7 02:33:52.219: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Feb  7 02:33:52.257: INFO: 31 / 31 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Feb  7 02:33:52.257: INFO: expected 4 pod replicas in namespace 'kube-system', 4 are Running and Ready.
Feb  7 02:33:52.257: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Feb  7 02:33:52.265: INFO: 6 / 6 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Feb  7 02:33:52.265: INFO: e2e test version: v1.13.0
Feb  7 02:33:52.267: INFO: kube-apiserver version: v1.13.3
SSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 02:33:52.267: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename configmap
Feb  7 02:33:52.376: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-ceb724b9-2a80-11e9-87fe-baa4eca941e3
STEP: Creating configMap with name cm-test-opt-upd-ceb724f4-2a80-11e9-87fe-baa4eca941e3
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-ceb724b9-2a80-11e9-87fe-baa4eca941e3
STEP: Updating configmap cm-test-opt-upd-ceb724f4-2a80-11e9-87fe-baa4eca941e3
STEP: Creating configMap with name cm-test-opt-create-ceb72515-2a80-11e9-87fe-baa4eca941e3
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 02:35:20.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-dkzts" for this suite.
Feb  7 02:35:42.650: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 02:35:42.863: INFO: namespace: e2e-tests-configmap-dkzts, resource: bindings, ignored listing per whitelist
Feb  7 02:35:42.866: INFO: namespace e2e-tests-configmap-dkzts deletion completed in 22.226349961s

• [SLOW TEST:110.599 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 02:35:42.866: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  7 02:35:43.394: INFO: Waiting up to 5m0s for pod "downwardapi-volume-109a0c4d-2a81-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-projected-mnndf" to be "success or failure"
Feb  7 02:35:43.397: INFO: Pod "downwardapi-volume-109a0c4d-2a81-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.159754ms
Feb  7 02:35:45.428: INFO: Pod "downwardapi-volume-109a0c4d-2a81-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.033427979s
STEP: Saw pod success
Feb  7 02:35:45.428: INFO: Pod "downwardapi-volume-109a0c4d-2a81-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 02:35:45.430: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod downwardapi-volume-109a0c4d-2a81-11e9-87fe-baa4eca941e3 container client-container: <nil>
STEP: delete the pod
Feb  7 02:35:45.449: INFO: Waiting for pod downwardapi-volume-109a0c4d-2a81-11e9-87fe-baa4eca941e3 to disappear
Feb  7 02:35:45.451: INFO: Pod downwardapi-volume-109a0c4d-2a81-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 02:35:45.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mnndf" for this suite.
Feb  7 02:35:51.465: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 02:35:51.593: INFO: namespace: e2e-tests-projected-mnndf, resource: bindings, ignored listing per whitelist
Feb  7 02:35:51.626: INFO: namespace e2e-tests-projected-mnndf deletion completed in 6.171067554s

• [SLOW TEST:8.760 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 02:35:51.626: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Feb  7 02:35:51.676: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-221081943 proxy --unix-socket=/tmp/kubectl-proxy-unix011188938/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 02:35:51.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bf48v" for this suite.
Feb  7 02:35:57.890: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 02:35:57.906: INFO: namespace: e2e-tests-kubectl-bf48v, resource: bindings, ignored listing per whitelist
Feb  7 02:35:58.266: INFO: namespace e2e-tests-kubectl-bf48v deletion completed in 6.540106118s

• [SLOW TEST:6.640 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 02:35:58.266: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  7 02:35:59.051: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Feb  7 02:35:59.060: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:35:59.061: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:35:59.061: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:35:59.062: INFO: Number of nodes with available pods: 0
Feb  7 02:35:59.062: INFO: Node kube-node-0-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 02:36:00.066: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:00.066: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:00.066: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:00.129: INFO: Number of nodes with available pods: 0
Feb  7 02:36:00.129: INFO: Node kube-node-0-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 02:36:01.067: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:01.067: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:01.067: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:01.070: INFO: Number of nodes with available pods: 1
Feb  7 02:36:01.070: INFO: Node kube-node-0-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 02:36:02.066: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:02.066: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:02.066: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:02.069: INFO: Number of nodes with available pods: 2
Feb  7 02:36:02.069: INFO: Node kube-node-1-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 02:36:03.130: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:03.130: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:03.130: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:03.133: INFO: Number of nodes with available pods: 3
Feb  7 02:36:03.133: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Feb  7 02:36:03.230: INFO: Wrong image for pod: daemon-set-7nljk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:03.230: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:03.230: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:03.233: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:03.233: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:03.233: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:04.237: INFO: Wrong image for pod: daemon-set-7nljk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:04.237: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:04.237: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:04.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:04.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:04.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:05.236: INFO: Wrong image for pod: daemon-set-7nljk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:05.236: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:05.236: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:05.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:05.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:05.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:06.236: INFO: Wrong image for pod: daemon-set-7nljk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:06.236: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:06.236: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:06.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:06.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:06.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:07.236: INFO: Wrong image for pod: daemon-set-7nljk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:07.236: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:07.236: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:07.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:07.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:07.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:08.244: INFO: Wrong image for pod: daemon-set-7nljk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:08.244: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:08.244: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:08.247: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:08.247: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:08.247: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:09.236: INFO: Wrong image for pod: daemon-set-7nljk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:09.237: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:09.237: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:09.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:09.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:09.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:10.236: INFO: Wrong image for pod: daemon-set-7nljk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:10.236: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:10.236: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:10.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:10.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:10.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:11.236: INFO: Wrong image for pod: daemon-set-7nljk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:11.236: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:11.236: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:11.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:11.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:11.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:12.236: INFO: Wrong image for pod: daemon-set-7nljk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:12.236: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:12.236: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:12.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:12.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:12.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:13.236: INFO: Wrong image for pod: daemon-set-7nljk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:13.236: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:13.236: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:13.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:13.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:13.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:14.236: INFO: Wrong image for pod: daemon-set-7nljk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:14.236: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:14.236: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:14.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:14.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:14.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:15.237: INFO: Wrong image for pod: daemon-set-7nljk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:15.237: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:15.237: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:15.330: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:15.330: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:15.330: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:16.236: INFO: Wrong image for pod: daemon-set-7nljk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:16.236: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:16.236: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:16.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:16.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:16.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:17.237: INFO: Wrong image for pod: daemon-set-7nljk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:17.237: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:17.237: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:17.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:17.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:17.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:18.237: INFO: Wrong image for pod: daemon-set-7nljk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:18.237: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:18.237: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:18.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:18.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:18.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:19.246: INFO: Wrong image for pod: daemon-set-7nljk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:19.246: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:19.246: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:19.249: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:19.249: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:19.249: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:20.237: INFO: Wrong image for pod: daemon-set-7nljk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:20.237: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:20.237: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:20.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:20.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:20.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:21.241: INFO: Wrong image for pod: daemon-set-7nljk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:21.241: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:21.241: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:21.244: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:21.244: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:21.244: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:22.236: INFO: Wrong image for pod: daemon-set-7nljk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:22.237: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:22.237: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:22.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:22.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:22.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:23.236: INFO: Wrong image for pod: daemon-set-7nljk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:23.236: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:23.236: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:23.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:23.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:23.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:24.237: INFO: Wrong image for pod: daemon-set-7nljk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:24.237: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:24.237: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:24.330: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:24.330: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:24.330: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:25.237: INFO: Wrong image for pod: daemon-set-7nljk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:25.237: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:25.237: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:25.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:25.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:25.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:26.236: INFO: Wrong image for pod: daemon-set-7nljk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:26.237: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:26.237: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:26.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:26.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:26.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:27.236: INFO: Wrong image for pod: daemon-set-7nljk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:27.236: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:27.236: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:27.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:27.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:27.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:28.237: INFO: Wrong image for pod: daemon-set-7nljk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:28.237: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:28.237: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:28.330: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:28.330: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:28.330: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:29.237: INFO: Wrong image for pod: daemon-set-7nljk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:29.237: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:29.237: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:29.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:29.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:29.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:30.241: INFO: Wrong image for pod: daemon-set-7nljk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:30.241: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:30.241: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:30.244: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:30.244: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:30.244: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:31.237: INFO: Wrong image for pod: daemon-set-7nljk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:31.237: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:31.237: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:31.330: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:31.330: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:31.330: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:32.237: INFO: Wrong image for pod: daemon-set-7nljk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:32.237: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:32.237: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:32.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:32.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:32.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:33.237: INFO: Wrong image for pod: daemon-set-7nljk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:33.237: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:33.237: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:33.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:33.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:33.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:34.237: INFO: Wrong image for pod: daemon-set-7nljk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:34.237: INFO: Pod daemon-set-7nljk is not available
Feb  7 02:36:34.237: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:34.237: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:34.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:34.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:34.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:35.237: INFO: Wrong image for pod: daemon-set-7nljk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:35.237: INFO: Pod daemon-set-7nljk is not available
Feb  7 02:36:35.237: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:35.237: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:35.242: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:35.242: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:35.242: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:36.237: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:36.237: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:36.237: INFO: Pod daemon-set-g8z98 is not available
Feb  7 02:36:36.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:36.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:36.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:37.236: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:37.236: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:37.236: INFO: Pod daemon-set-g8z98 is not available
Feb  7 02:36:37.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:37.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:37.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:38.237: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:38.237: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:38.237: INFO: Pod daemon-set-g8z98 is not available
Feb  7 02:36:38.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:38.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:38.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:39.236: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:39.237: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:39.330: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:39.330: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:39.330: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:40.236: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:40.236: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:40.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:40.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:40.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:41.242: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:41.242: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:41.245: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:41.245: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:41.245: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:42.236: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:42.237: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:42.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:42.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:42.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:43.237: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:43.237: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:43.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:43.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:43.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:44.237: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:44.237: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:44.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:44.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:44.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:45.237: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:45.237: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:45.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:45.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:45.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:46.236: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:46.236: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:46.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:46.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:46.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:47.236: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:47.237: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:47.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:47.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:47.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:48.237: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:48.237: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:48.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:48.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:48.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:49.237: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:49.237: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:49.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:49.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:49.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:50.236: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:50.237: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:50.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:50.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:50.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:51.237: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:51.237: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:51.331: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:51.331: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:51.331: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:52.332: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:52.332: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:52.335: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:52.335: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:52.335: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:53.330: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:53.330: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:53.333: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:53.333: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:53.333: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:54.236: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:54.236: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:54.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:54.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:54.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:55.236: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:55.236: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:55.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:55.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:55.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:56.236: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:56.236: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:56.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:56.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:56.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:57.237: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:57.237: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:57.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:57.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:57.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:58.237: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:58.237: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:58.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:58.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:58.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:59.236: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:59.236: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:36:59.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:59.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:36:59.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:00.236: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:00.236: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:00.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:00.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:00.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:01.237: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:01.237: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:01.330: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:01.330: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:01.330: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:02.236: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:02.236: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:02.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:02.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:02.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:03.331: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:03.331: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:03.334: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:03.334: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:03.334: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:04.236: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:04.236: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:04.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:04.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:04.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:05.236: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:05.236: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:05.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:05.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:05.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:06.236: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:06.236: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:06.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:06.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:06.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:07.236: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:07.236: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:07.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:07.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:07.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:08.237: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:08.237: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:08.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:08.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:08.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:09.242: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:09.242: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:09.330: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:09.330: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:09.330: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:10.236: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:10.236: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:10.236: INFO: Pod daemon-set-bhkqp is not available
Feb  7 02:37:10.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:10.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:10.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:11.237: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:11.237: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:11.237: INFO: Pod daemon-set-bhkqp is not available
Feb  7 02:37:11.330: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:11.330: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:11.330: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:12.236: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:12.236: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:12.236: INFO: Pod daemon-set-bhkqp is not available
Feb  7 02:37:12.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:12.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:12.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:13.236: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:13.236: INFO: Wrong image for pod: daemon-set-bhkqp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:13.236: INFO: Pod daemon-set-bhkqp is not available
Feb  7 02:37:13.330: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:13.330: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:13.330: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:14.243: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:14.243: INFO: Pod daemon-set-gwx2l is not available
Feb  7 02:37:14.246: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:14.246: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:14.246: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:15.236: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:15.236: INFO: Pod daemon-set-gwx2l is not available
Feb  7 02:37:15.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:15.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:15.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:16.237: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:16.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:16.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:16.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:17.236: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:17.331: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:17.331: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:17.331: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:18.236: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:18.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:18.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:18.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:19.237: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:19.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:19.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:19.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:20.237: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:20.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:20.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:20.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:21.237: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:21.332: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:21.332: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:21.332: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:22.237: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:22.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:22.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:22.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:23.236: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:23.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:23.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:23.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:24.237: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:24.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:24.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:24.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:25.241: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:25.243: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:25.243: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:25.243: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:26.236: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:26.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:26.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:26.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:27.237: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:27.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:27.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:27.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:28.236: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:28.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:28.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:28.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:29.236: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:29.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:29.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:29.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:30.236: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:30.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:30.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:30.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:31.237: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:31.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:31.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:31.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:32.236: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:32.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:32.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:32.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:33.237: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:33.241: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:33.241: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:33.241: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:34.236: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:34.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:34.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:34.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:35.239: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:35.246: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:35.246: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:35.246: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:36.236: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:36.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:36.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:36.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:37.236: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:37.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:37.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:37.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:38.236: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:38.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:38.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:38.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:39.236: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:39.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:39.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:39.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:40.236: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:40.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:40.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:40.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:41.236: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:41.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:41.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:41.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:42.237: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:42.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:42.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:42.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:43.237: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:43.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:43.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:43.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:44.236: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:44.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:44.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:44.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:45.236: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:45.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:45.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:45.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:46.240: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:46.243: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:46.243: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:46.243: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:47.236: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:47.236: INFO: Pod daemon-set-bcd52 is not available
Feb  7 02:37:47.239: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:47.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:47.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:48.236: INFO: Wrong image for pod: daemon-set-bcd52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 02:37:48.236: INFO: Pod daemon-set-bcd52 is not available
Feb  7 02:37:48.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:48.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:48.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:49.236: INFO: Pod daemon-set-5wfzc is not available
Feb  7 02:37:49.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:49.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:49.240: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Feb  7 02:37:49.242: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:49.242: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:49.242: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:49.245: INFO: Number of nodes with available pods: 2
Feb  7 02:37:49.245: INFO: Node kube-node-1-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 02:37:50.249: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:50.249: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:50.249: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:50.252: INFO: Number of nodes with available pods: 2
Feb  7 02:37:50.252: INFO: Node kube-node-1-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 02:37:51.340: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:51.340: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:51.340: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:37:51.343: INFO: Number of nodes with available pods: 3
Feb  7 02:37:51.343: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-vpxhr, will wait for the garbage collector to delete the pods
Feb  7 02:37:51.413: INFO: Deleting DaemonSet.extensions daemon-set took: 5.328375ms
Feb  7 02:37:51.513: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.225301ms
Feb  7 02:38:03.520: INFO: Number of nodes with available pods: 0
Feb  7 02:38:03.520: INFO: Number of running nodes: 0, number of available pods: 0
Feb  7 02:38:03.523: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-vpxhr/daemonsets","resourceVersion":"2976"},"items":null}

Feb  7 02:38:03.525: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-vpxhr/pods","resourceVersion":"2976"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 02:38:03.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-vpxhr" for this suite.
Feb  7 02:38:09.548: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 02:38:09.618: INFO: namespace: e2e-tests-daemonsets-vpxhr, resource: bindings, ignored listing per whitelist
Feb  7 02:38:09.640: INFO: namespace e2e-tests-daemonsets-vpxhr deletion completed in 6.102179756s

• [SLOW TEST:131.374 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 02:38:09.640: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-6815e8a6-2a81-11e9-87fe-baa4eca941e3
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-6815e8a6-2a81-11e9-87fe-baa4eca941e3
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 02:38:13.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-4t26p" for this suite.
Feb  7 02:38:35.964: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 02:38:35.976: INFO: namespace: e2e-tests-configmap-4t26p, resource: bindings, ignored listing per whitelist
Feb  7 02:38:36.077: INFO: namespace e2e-tests-configmap-4t26p deletion completed in 22.128375564s

• [SLOW TEST:26.438 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 02:38:36.077: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Feb  7 02:38:36.132: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 --namespace=e2e-tests-kubectl-wcwxj run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Feb  7 02:38:40.946: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Feb  7 02:38:40.946: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 02:38:42.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wcwxj" for this suite.
Feb  7 02:38:57.441: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 02:38:57.547: INFO: namespace: e2e-tests-kubectl-wcwxj, resource: bindings, ignored listing per whitelist
Feb  7 02:38:57.575: INFO: namespace e2e-tests-kubectl-wcwxj deletion completed in 14.620854633s

• [SLOW TEST:21.498 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 02:38:57.575: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Feb  7 02:38:57.634: INFO: Waiting up to 5m0s for pod "var-expansion-84a82ec8-2a81-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-var-expansion-khb7t" to be "success or failure"
Feb  7 02:38:57.636: INFO: Pod "var-expansion-84a82ec8-2a81-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.100014ms
Feb  7 02:38:59.639: INFO: Pod "var-expansion-84a82ec8-2a81-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005126833s
STEP: Saw pod success
Feb  7 02:38:59.639: INFO: Pod "var-expansion-84a82ec8-2a81-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 02:38:59.642: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod var-expansion-84a82ec8-2a81-11e9-87fe-baa4eca941e3 container dapi-container: <nil>
STEP: delete the pod
Feb  7 02:38:59.658: INFO: Waiting for pod var-expansion-84a82ec8-2a81-11e9-87fe-baa4eca941e3 to disappear
Feb  7 02:38:59.659: INFO: Pod var-expansion-84a82ec8-2a81-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 02:38:59.660: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-khb7t" for this suite.
Feb  7 02:39:06.233: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 02:39:06.299: INFO: namespace: e2e-tests-var-expansion-khb7t, resource: bindings, ignored listing per whitelist
Feb  7 02:39:06.327: INFO: namespace e2e-tests-var-expansion-khb7t deletion completed in 6.663549147s

• [SLOW TEST:8.751 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 02:39:06.327: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Feb  7 02:39:06.893: INFO: created pod pod-service-account-defaultsa
Feb  7 02:39:06.893: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Feb  7 02:39:06.897: INFO: created pod pod-service-account-mountsa
Feb  7 02:39:06.897: INFO: pod pod-service-account-mountsa service account token volume mount: true
Feb  7 02:39:06.900: INFO: created pod pod-service-account-nomountsa
Feb  7 02:39:06.900: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Feb  7 02:39:06.904: INFO: created pod pod-service-account-defaultsa-mountspec
Feb  7 02:39:06.904: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Feb  7 02:39:06.912: INFO: created pod pod-service-account-mountsa-mountspec
Feb  7 02:39:06.912: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Feb  7 02:39:06.917: INFO: created pod pod-service-account-nomountsa-mountspec
Feb  7 02:39:06.917: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Feb  7 02:39:06.921: INFO: created pod pod-service-account-defaultsa-nomountspec
Feb  7 02:39:06.921: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Feb  7 02:39:06.925: INFO: created pod pod-service-account-mountsa-nomountspec
Feb  7 02:39:06.925: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Feb  7 02:39:06.929: INFO: created pod pod-service-account-nomountsa-nomountspec
Feb  7 02:39:06.929: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 02:39:06.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-k4rzt" for this suite.
Feb  7 02:39:12.949: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 02:39:12.986: INFO: namespace: e2e-tests-svcaccounts-k4rzt, resource: bindings, ignored listing per whitelist
Feb  7 02:39:13.042: INFO: namespace e2e-tests-svcaccounts-k4rzt deletion completed in 6.104647278s

• [SLOW TEST:6.715 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 02:39:13.042: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 02:39:13.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-2hq6g" for this suite.
Feb  7 02:39:19.132: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 02:39:19.171: INFO: namespace: e2e-tests-services-2hq6g, resource: bindings, ignored listing per whitelist
Feb  7 02:39:19.231: INFO: namespace e2e-tests-services-2hq6g deletion completed in 6.130152578s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:6.189 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 02:39:19.231: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  7 02:39:19.287: INFO: (0) /api/v1/nodes/kube-node-0-kubelet.devkubernetes01.mesos/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 4.156341ms)
Feb  7 02:39:19.290: INFO: (1) /api/v1/nodes/kube-node-0-kubelet.devkubernetes01.mesos/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 2.51877ms)
Feb  7 02:39:19.292: INFO: (2) /api/v1/nodes/kube-node-0-kubelet.devkubernetes01.mesos/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 2.340268ms)
Feb  7 02:39:19.295: INFO: (3) /api/v1/nodes/kube-node-0-kubelet.devkubernetes01.mesos/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 3.205188ms)
Feb  7 02:39:19.300: INFO: (4) /api/v1/nodes/kube-node-0-kubelet.devkubernetes01.mesos/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 4.46992ms)
Feb  7 02:39:19.303: INFO: (5) /api/v1/nodes/kube-node-0-kubelet.devkubernetes01.mesos/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 2.883199ms)
Feb  7 02:39:19.306: INFO: (6) /api/v1/nodes/kube-node-0-kubelet.devkubernetes01.mesos/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 2.943706ms)
Feb  7 02:39:19.312: INFO: (7) /api/v1/nodes/kube-node-0-kubelet.devkubernetes01.mesos/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 6.723685ms)
Feb  7 02:39:19.315: INFO: (8) /api/v1/nodes/kube-node-0-kubelet.devkubernetes01.mesos/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 2.965963ms)
Feb  7 02:39:19.335: INFO: (9) /api/v1/nodes/kube-node-0-kubelet.devkubernetes01.mesos/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 19.249408ms)
Feb  7 02:39:19.337: INFO: (10) /api/v1/nodes/kube-node-0-kubelet.devkubernetes01.mesos/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 2.705121ms)
Feb  7 02:39:19.340: INFO: (11) /api/v1/nodes/kube-node-0-kubelet.devkubernetes01.mesos/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 2.778747ms)
Feb  7 02:39:19.343: INFO: (12) /api/v1/nodes/kube-node-0-kubelet.devkubernetes01.mesos/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 2.384464ms)
Feb  7 02:39:19.345: INFO: (13) /api/v1/nodes/kube-node-0-kubelet.devkubernetes01.mesos/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 2.440538ms)
Feb  7 02:39:19.348: INFO: (14) /api/v1/nodes/kube-node-0-kubelet.devkubernetes01.mesos/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 2.530922ms)
Feb  7 02:39:19.350: INFO: (15) /api/v1/nodes/kube-node-0-kubelet.devkubernetes01.mesos/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 2.546606ms)
Feb  7 02:39:19.353: INFO: (16) /api/v1/nodes/kube-node-0-kubelet.devkubernetes01.mesos/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 2.284156ms)
Feb  7 02:39:19.355: INFO: (17) /api/v1/nodes/kube-node-0-kubelet.devkubernetes01.mesos/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 2.400918ms)
Feb  7 02:39:19.357: INFO: (18) /api/v1/nodes/kube-node-0-kubelet.devkubernetes01.mesos/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 2.479955ms)
Feb  7 02:39:19.360: INFO: (19) /api/v1/nodes/kube-node-0-kubelet.devkubernetes01.mesos/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 2.286587ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 02:39:19.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-pqtq8" for this suite.
Feb  7 02:39:25.373: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 02:39:25.466: INFO: namespace: e2e-tests-proxy-pqtq8, resource: bindings, ignored listing per whitelist
Feb  7 02:39:25.471: INFO: namespace e2e-tests-proxy-pqtq8 deletion completed in 6.108154845s

• [SLOW TEST:6.239 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 02:39:25.471: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  7 02:39:25.528: INFO: Waiting up to 5m0s for pod "downwardapi-volume-95487015-2a81-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-downward-api-fdp4b" to be "success or failure"
Feb  7 02:39:25.530: INFO: Pod "downwardapi-volume-95487015-2a81-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.7859ms
Feb  7 02:39:27.532: INFO: Pod "downwardapi-volume-95487015-2a81-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004503334s
STEP: Saw pod success
Feb  7 02:39:27.532: INFO: Pod "downwardapi-volume-95487015-2a81-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 02:39:27.534: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod downwardapi-volume-95487015-2a81-11e9-87fe-baa4eca941e3 container client-container: <nil>
STEP: delete the pod
Feb  7 02:39:27.549: INFO: Waiting for pod downwardapi-volume-95487015-2a81-11e9-87fe-baa4eca941e3 to disappear
Feb  7 02:39:27.551: INFO: Pod downwardapi-volume-95487015-2a81-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 02:39:27.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-fdp4b" for this suite.
Feb  7 02:39:33.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 02:39:33.964: INFO: namespace: e2e-tests-downward-api-fdp4b, resource: bindings, ignored listing per whitelist
Feb  7 02:39:34.016: INFO: namespace e2e-tests-downward-api-fdp4b deletion completed in 6.46256257s

• [SLOW TEST:8.545 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 02:39:34.017: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-9a60b97e-2a81-11e9-87fe-baa4eca941e3
STEP: Creating a pod to test consume secrets
Feb  7 02:39:34.105: INFO: Waiting up to 5m0s for pod "pod-secrets-9a6578a2-2a81-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-secrets-7l7lr" to be "success or failure"
Feb  7 02:39:34.107: INFO: Pod "pod-secrets-9a6578a2-2a81-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.118292ms
Feb  7 02:39:36.110: INFO: Pod "pod-secrets-9a6578a2-2a81-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005121176s
STEP: Saw pod success
Feb  7 02:39:36.110: INFO: Pod "pod-secrets-9a6578a2-2a81-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 02:39:36.112: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod pod-secrets-9a6578a2-2a81-11e9-87fe-baa4eca941e3 container secret-volume-test: <nil>
STEP: delete the pod
Feb  7 02:39:36.192: INFO: Waiting for pod pod-secrets-9a6578a2-2a81-11e9-87fe-baa4eca941e3 to disappear
Feb  7 02:39:36.195: INFO: Pod pod-secrets-9a6578a2-2a81-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 02:39:36.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-7l7lr" for this suite.
Feb  7 02:39:42.443: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 02:39:42.508: INFO: namespace: e2e-tests-secrets-7l7lr, resource: bindings, ignored listing per whitelist
Feb  7 02:39:42.541: INFO: namespace e2e-tests-secrets-7l7lr deletion completed in 6.343199776s
STEP: Destroying namespace "e2e-tests-secret-namespace-8bk5k" for this suite.
Feb  7 02:39:48.634: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 02:39:48.737: INFO: namespace: e2e-tests-secret-namespace-8bk5k, resource: bindings, ignored listing per whitelist
Feb  7 02:39:48.766: INFO: namespace e2e-tests-secret-namespace-8bk5k deletion completed in 6.22535147s

• [SLOW TEST:14.750 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 02:39:48.766: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-phc4s A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-phc4s;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-phc4s A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-phc4s;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-phc4s.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-phc4s.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-phc4s.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-phc4s.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-phc4s.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-phc4s.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-phc4s.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-phc4s.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-phc4s.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-phc4s.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-phc4s.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-phc4s.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-phc4s.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 16.73.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.73.16_udp@PTR;check="$$(dig +tcp +noall +answer +search 16.73.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.73.16_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-phc4s A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-phc4s;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-phc4s A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-phc4s;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-phc4s.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-phc4s.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-phc4s.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-phc4s.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-phc4s.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-phc4s.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-phc4s.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-phc4s.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-phc4s.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-phc4s.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-phc4s.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-phc4s.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-phc4s.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 16.73.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.73.16_udp@PTR;check="$$(dig +tcp +noall +answer +search 16.73.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.73.16_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb  7 02:39:58.848: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-phc4s/dns-test-a32cb486-2a81-11e9-87fe-baa4eca941e3: the server could not find the requested resource (get pods dns-test-a32cb486-2a81-11e9-87fe-baa4eca941e3)
Feb  7 02:39:58.850: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-phc4s/dns-test-a32cb486-2a81-11e9-87fe-baa4eca941e3: the server could not find the requested resource (get pods dns-test-a32cb486-2a81-11e9-87fe-baa4eca941e3)
Feb  7 02:39:58.852: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-phc4s from pod e2e-tests-dns-phc4s/dns-test-a32cb486-2a81-11e9-87fe-baa4eca941e3: the server could not find the requested resource (get pods dns-test-a32cb486-2a81-11e9-87fe-baa4eca941e3)
Feb  7 02:39:58.855: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-phc4s from pod e2e-tests-dns-phc4s/dns-test-a32cb486-2a81-11e9-87fe-baa4eca941e3: the server could not find the requested resource (get pods dns-test-a32cb486-2a81-11e9-87fe-baa4eca941e3)
Feb  7 02:39:58.857: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-phc4s.svc from pod e2e-tests-dns-phc4s/dns-test-a32cb486-2a81-11e9-87fe-baa4eca941e3: the server could not find the requested resource (get pods dns-test-a32cb486-2a81-11e9-87fe-baa4eca941e3)
Feb  7 02:39:58.860: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-phc4s.svc from pod e2e-tests-dns-phc4s/dns-test-a32cb486-2a81-11e9-87fe-baa4eca941e3: the server could not find the requested resource (get pods dns-test-a32cb486-2a81-11e9-87fe-baa4eca941e3)
Feb  7 02:39:58.862: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-phc4s.svc from pod e2e-tests-dns-phc4s/dns-test-a32cb486-2a81-11e9-87fe-baa4eca941e3: the server could not find the requested resource (get pods dns-test-a32cb486-2a81-11e9-87fe-baa4eca941e3)
Feb  7 02:39:58.865: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-phc4s.svc from pod e2e-tests-dns-phc4s/dns-test-a32cb486-2a81-11e9-87fe-baa4eca941e3: the server could not find the requested resource (get pods dns-test-a32cb486-2a81-11e9-87fe-baa4eca941e3)
Feb  7 02:39:58.882: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-phc4s/dns-test-a32cb486-2a81-11e9-87fe-baa4eca941e3: the server could not find the requested resource (get pods dns-test-a32cb486-2a81-11e9-87fe-baa4eca941e3)
Feb  7 02:39:58.884: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-phc4s/dns-test-a32cb486-2a81-11e9-87fe-baa4eca941e3: the server could not find the requested resource (get pods dns-test-a32cb486-2a81-11e9-87fe-baa4eca941e3)
Feb  7 02:39:58.887: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-phc4s from pod e2e-tests-dns-phc4s/dns-test-a32cb486-2a81-11e9-87fe-baa4eca941e3: the server could not find the requested resource (get pods dns-test-a32cb486-2a81-11e9-87fe-baa4eca941e3)
Feb  7 02:39:58.889: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-phc4s from pod e2e-tests-dns-phc4s/dns-test-a32cb486-2a81-11e9-87fe-baa4eca941e3: the server could not find the requested resource (get pods dns-test-a32cb486-2a81-11e9-87fe-baa4eca941e3)
Feb  7 02:39:58.892: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-phc4s.svc from pod e2e-tests-dns-phc4s/dns-test-a32cb486-2a81-11e9-87fe-baa4eca941e3: the server could not find the requested resource (get pods dns-test-a32cb486-2a81-11e9-87fe-baa4eca941e3)
Feb  7 02:39:58.895: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-phc4s.svc from pod e2e-tests-dns-phc4s/dns-test-a32cb486-2a81-11e9-87fe-baa4eca941e3: the server could not find the requested resource (get pods dns-test-a32cb486-2a81-11e9-87fe-baa4eca941e3)
Feb  7 02:39:58.897: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-phc4s.svc from pod e2e-tests-dns-phc4s/dns-test-a32cb486-2a81-11e9-87fe-baa4eca941e3: the server could not find the requested resource (get pods dns-test-a32cb486-2a81-11e9-87fe-baa4eca941e3)
Feb  7 02:39:58.900: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-phc4s.svc from pod e2e-tests-dns-phc4s/dns-test-a32cb486-2a81-11e9-87fe-baa4eca941e3: the server could not find the requested resource (get pods dns-test-a32cb486-2a81-11e9-87fe-baa4eca941e3)
Feb  7 02:39:58.914: INFO: Lookups using e2e-tests-dns-phc4s/dns-test-a32cb486-2a81-11e9-87fe-baa4eca941e3 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-phc4s wheezy_tcp@dns-test-service.e2e-tests-dns-phc4s wheezy_udp@dns-test-service.e2e-tests-dns-phc4s.svc wheezy_tcp@dns-test-service.e2e-tests-dns-phc4s.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-phc4s.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-phc4s.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-phc4s jessie_tcp@dns-test-service.e2e-tests-dns-phc4s jessie_udp@dns-test-service.e2e-tests-dns-phc4s.svc jessie_tcp@dns-test-service.e2e-tests-dns-phc4s.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-phc4s.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-phc4s.svc]

Feb  7 02:40:03.936: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-phc4s.svc from pod e2e-tests-dns-phc4s/dns-test-a32cb486-2a81-11e9-87fe-baa4eca941e3: the server could not find the requested resource (get pods dns-test-a32cb486-2a81-11e9-87fe-baa4eca941e3)
Feb  7 02:40:03.985: INFO: Lookups using e2e-tests-dns-phc4s/dns-test-a32cb486-2a81-11e9-87fe-baa4eca941e3 failed for: [wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-phc4s.svc]

Feb  7 02:40:08.989: INFO: DNS probes using e2e-tests-dns-phc4s/dns-test-a32cb486-2a81-11e9-87fe-baa4eca941e3 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 02:40:09.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-phc4s" for this suite.
Feb  7 02:40:15.052: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 02:40:15.256: INFO: namespace: e2e-tests-dns-phc4s, resource: bindings, ignored listing per whitelist
Feb  7 02:40:15.265: INFO: namespace e2e-tests-dns-phc4s deletion completed in 6.227821363s

• [SLOW TEST:26.498 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 02:40:15.265: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-b2f69
Feb  7 02:40:19.328: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-b2f69
STEP: checking the pod's current state and verifying that restartCount is present
Feb  7 02:40:19.333: INFO: Initial restart count of pod liveness-http is 0
Feb  7 02:40:39.374: INFO: Restart count of pod e2e-tests-container-probe-b2f69/liveness-http is now 1 (20.040711727s elapsed)
Feb  7 02:40:59.829: INFO: Restart count of pod e2e-tests-container-probe-b2f69/liveness-http is now 2 (40.496254775s elapsed)
Feb  7 02:41:19.865: INFO: Restart count of pod e2e-tests-container-probe-b2f69/liveness-http is now 3 (1m0.532489548s elapsed)
Feb  7 02:41:38.542: INFO: Restart count of pod e2e-tests-container-probe-b2f69/liveness-http is now 4 (1m19.208785962s elapsed)
Feb  7 02:42:41.679: INFO: Restart count of pod e2e-tests-container-probe-b2f69/liveness-http is now 5 (2m22.346002606s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 02:42:41.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-b2f69" for this suite.
Feb  7 02:42:47.729: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 02:42:47.789: INFO: namespace: e2e-tests-container-probe-b2f69, resource: bindings, ignored listing per whitelist
Feb  7 02:42:47.827: INFO: namespace e2e-tests-container-probe-b2f69 deletion completed in 6.133113279s

• [SLOW TEST:152.562 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 02:42:47.827: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb  7 02:42:47.892: INFO: PodSpec: initContainers in spec.initContainers
Feb  7 02:43:34.644: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-0de7c9eb-2a82-11e9-87fe-baa4eca941e3", GenerateName:"", Namespace:"e2e-tests-init-container-tljpz", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-tljpz/pods/pod-init-0de7c9eb-2a82-11e9-87fe-baa4eca941e3", UID:"0e04c4ed-2a82-11e9-809d-e6a419c8531a", ResourceVersion:"4072", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63685104168, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"892021933"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"192.168.5.18/32"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-tl96z", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0007ee140), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-tl96z", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-tl96z", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-tl96z", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0007ec938), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"kube-node-0-kubelet.devkubernetes01.mesos", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001892300), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0007ec9b0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0007ec9d0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0007ec9d8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0007ec9dc)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685104168, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685104168, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685104168, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685104168, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"9.0.1.4", PodIP:"192.168.5.18", StartTime:(*v1.Time)(0xc0011e2860), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000d04e70)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000d04ee0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://07a259aa7a766bc25c7808b18473033c20c2516747312e29bb6987081b8cd901"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0011e28a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0011e2880), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 02:43:34.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-tljpz" for this suite.
Feb  7 02:43:57.661: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 02:43:57.784: INFO: namespace: e2e-tests-init-container-tljpz, resource: bindings, ignored listing per whitelist
Feb  7 02:43:57.817: INFO: namespace e2e-tests-init-container-tljpz deletion completed in 22.676436363s

• [SLOW TEST:69.990 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 02:43:57.817: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0207 02:44:07.946021      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb  7 02:44:07.946: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 02:44:07.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-w66qr" for this suite.
Feb  7 02:44:16.035: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 02:44:16.178: INFO: namespace: e2e-tests-gc-w66qr, resource: bindings, ignored listing per whitelist
Feb  7 02:44:16.207: INFO: namespace e2e-tests-gc-w66qr deletion completed in 8.258656541s

• [SLOW TEST:18.390 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 02:44:16.207: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb  7 02:44:16.260: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 02:44:20.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-hpv6r" for this suite.
Feb  7 02:44:42.141: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 02:44:42.237: INFO: namespace: e2e-tests-init-container-hpv6r, resource: bindings, ignored listing per whitelist
Feb  7 02:44:42.286: INFO: namespace e2e-tests-init-container-hpv6r deletion completed in 22.210026094s

• [SLOW TEST:26.079 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 02:44:42.286: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb  7 02:44:42.343: INFO: Waiting up to 5m0s for pod "pod-521e8d0d-2a82-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-emptydir-hdhzq" to be "success or failure"
Feb  7 02:44:42.345: INFO: Pod "pod-521e8d0d-2a82-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.151709ms
Feb  7 02:44:44.348: INFO: Pod "pod-521e8d0d-2a82-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004870617s
STEP: Saw pod success
Feb  7 02:44:44.348: INFO: Pod "pod-521e8d0d-2a82-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 02:44:44.350: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod pod-521e8d0d-2a82-11e9-87fe-baa4eca941e3 container test-container: <nil>
STEP: delete the pod
Feb  7 02:44:44.367: INFO: Waiting for pod pod-521e8d0d-2a82-11e9-87fe-baa4eca941e3 to disappear
Feb  7 02:44:44.369: INFO: Pod pod-521e8d0d-2a82-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 02:44:44.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-hdhzq" for this suite.
Feb  7 02:44:50.382: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 02:44:50.476: INFO: namespace: e2e-tests-emptydir-hdhzq, resource: bindings, ignored listing per whitelist
Feb  7 02:44:50.510: INFO: namespace e2e-tests-emptydir-hdhzq deletion completed in 6.138205192s

• [SLOW TEST:8.225 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 02:44:50.510: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1052
STEP: creating the pod
Feb  7 02:44:50.563: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 create -f - --namespace=e2e-tests-kubectl-j8s6q'
Feb  7 02:44:50.750: INFO: stderr: ""
Feb  7 02:44:50.750: INFO: stdout: "pod/pause created\n"
Feb  7 02:44:50.750: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Feb  7 02:44:50.750: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-j8s6q" to be "running and ready"
Feb  7 02:44:50.752: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.526142ms
Feb  7 02:44:52.759: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.009788364s
Feb  7 02:44:52.760: INFO: Pod "pause" satisfied condition "running and ready"
Feb  7 02:44:52.760: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Feb  7 02:44:52.760: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-j8s6q'
Feb  7 02:44:52.837: INFO: stderr: ""
Feb  7 02:44:52.837: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Feb  7 02:44:52.837: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 get pod pause -L testing-label --namespace=e2e-tests-kubectl-j8s6q'
Feb  7 02:44:52.905: INFO: stderr: ""
Feb  7 02:44:52.905: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Feb  7 02:44:52.905: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 label pods pause testing-label- --namespace=e2e-tests-kubectl-j8s6q'
Feb  7 02:44:52.978: INFO: stderr: ""
Feb  7 02:44:52.978: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Feb  7 02:44:52.978: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 get pod pause -L testing-label --namespace=e2e-tests-kubectl-j8s6q'
Feb  7 02:44:53.046: INFO: stderr: ""
Feb  7 02:44:53.046: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1059
STEP: using delete to clean up resources
Feb  7 02:44:53.046: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-j8s6q'
Feb  7 02:44:53.122: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  7 02:44:53.122: INFO: stdout: "pod \"pause\" force deleted\n"
Feb  7 02:44:53.122: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-j8s6q'
Feb  7 02:44:53.203: INFO: stderr: "No resources found.\n"
Feb  7 02:44:53.203: INFO: stdout: ""
Feb  7 02:44:53.203: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 get pods -l name=pause --namespace=e2e-tests-kubectl-j8s6q -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb  7 02:44:53.276: INFO: stderr: ""
Feb  7 02:44:53.276: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 02:44:53.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-j8s6q" for this suite.
Feb  7 02:44:59.325: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 02:44:59.469: INFO: namespace: e2e-tests-kubectl-j8s6q, resource: bindings, ignored listing per whitelist
Feb  7 02:44:59.489: INFO: namespace e2e-tests-kubectl-j8s6q deletion completed in 6.209144052s

• [SLOW TEST:8.978 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 02:44:59.489: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  7 02:44:59.541: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 02:45:01.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-9bx98" for this suite.
Feb  7 02:45:43.582: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 02:45:43.661: INFO: namespace: e2e-tests-pods-9bx98, resource: bindings, ignored listing per whitelist
Feb  7 02:45:43.679: INFO: namespace e2e-tests-pods-9bx98 deletion completed in 42.10817183s

• [SLOW TEST:44.190 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 02:45:43.679: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-76b69a8f-2a82-11e9-87fe-baa4eca941e3
STEP: Creating a pod to test consume configMaps
Feb  7 02:45:44.328: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-76b74500-2a82-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-projected-vckqm" to be "success or failure"
Feb  7 02:45:44.330: INFO: Pod "pod-projected-configmaps-76b74500-2a82-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.057275ms
Feb  7 02:45:46.333: INFO: Pod "pod-projected-configmaps-76b74500-2a82-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00489363s
STEP: Saw pod success
Feb  7 02:45:46.333: INFO: Pod "pod-projected-configmaps-76b74500-2a82-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 02:45:46.335: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod pod-projected-configmaps-76b74500-2a82-11e9-87fe-baa4eca941e3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  7 02:45:46.349: INFO: Waiting for pod pod-projected-configmaps-76b74500-2a82-11e9-87fe-baa4eca941e3 to disappear
Feb  7 02:45:46.351: INFO: Pod pod-projected-configmaps-76b74500-2a82-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 02:45:46.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vckqm" for this suite.
Feb  7 02:45:52.500: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 02:45:52.664: INFO: namespace: e2e-tests-projected-vckqm, resource: bindings, ignored listing per whitelist
Feb  7 02:45:52.681: INFO: namespace e2e-tests-projected-vckqm deletion completed in 6.326469864s

• [SLOW TEST:9.002 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 02:45:52.681: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-4lfd4
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb  7 02:45:52.731: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb  7 02:46:16.796: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.4.11:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-4lfd4 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  7 02:46:16.796: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
Feb  7 02:46:16.898: INFO: Found all expected endpoints: [netserver-0]
Feb  7 02:46:16.901: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.5.27:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-4lfd4 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  7 02:46:16.901: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
Feb  7 02:46:16.988: INFO: Found all expected endpoints: [netserver-1]
Feb  7 02:46:16.991: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.3.14:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-4lfd4 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  7 02:46:16.991: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
Feb  7 02:46:17.076: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 02:46:17.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-4lfd4" for this suite.
Feb  7 02:46:41.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 02:46:41.388: INFO: namespace: e2e-tests-pod-network-test-4lfd4, resource: bindings, ignored listing per whitelist
Feb  7 02:46:41.780: INFO: namespace e2e-tests-pod-network-test-4lfd4 deletion completed in 24.701041926s

• [SLOW TEST:49.099 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 02:46:41.780: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb  7 02:46:41.857: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:46:41.857: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:46:41.857: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:46:41.859: INFO: Number of nodes with available pods: 0
Feb  7 02:46:41.859: INFO: Node kube-node-0-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 02:46:42.862: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:46:42.862: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:46:42.862: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:46:42.865: INFO: Number of nodes with available pods: 0
Feb  7 02:46:42.865: INFO: Node kube-node-0-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 02:46:43.867: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:46:43.867: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:46:43.867: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:46:43.869: INFO: Number of nodes with available pods: 3
Feb  7 02:46:43.869: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Feb  7 02:46:43.881: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:46:43.881: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:46:43.881: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 02:46:43.883: INFO: Number of nodes with available pods: 3
Feb  7 02:46:43.883: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-lmwj6, will wait for the garbage collector to delete the pods
Feb  7 02:46:44.950: INFO: Deleting DaemonSet.extensions daemon-set took: 5.863416ms
Feb  7 02:46:45.050: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.218473ms
Feb  7 02:48:26.756: INFO: Number of nodes with available pods: 0
Feb  7 02:48:26.756: INFO: Number of running nodes: 0, number of available pods: 0
Feb  7 02:48:26.759: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-lmwj6/daemonsets","resourceVersion":"5218"},"items":null}

Feb  7 02:48:26.761: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-lmwj6/pods","resourceVersion":"5218"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 02:48:26.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-lmwj6" for this suite.
Feb  7 02:48:34.782: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 02:48:34.823: INFO: namespace: e2e-tests-daemonsets-lmwj6, resource: bindings, ignored listing per whitelist
Feb  7 02:48:34.876: INFO: namespace e2e-tests-daemonsets-lmwj6 deletion completed in 8.103460917s

• [SLOW TEST:113.095 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 02:48:34.876: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  7 02:48:34.933: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dcc105bf-2a82-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-projected-k9jvf" to be "success or failure"
Feb  7 02:48:34.935: INFO: Pod "downwardapi-volume-dcc105bf-2a82-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003738ms
Feb  7 02:48:36.942: INFO: Pod "downwardapi-volume-dcc105bf-2a82-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009159374s
STEP: Saw pod success
Feb  7 02:48:36.942: INFO: Pod "downwardapi-volume-dcc105bf-2a82-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 02:48:36.944: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod downwardapi-volume-dcc105bf-2a82-11e9-87fe-baa4eca941e3 container client-container: <nil>
STEP: delete the pod
Feb  7 02:48:36.960: INFO: Waiting for pod downwardapi-volume-dcc105bf-2a82-11e9-87fe-baa4eca941e3 to disappear
Feb  7 02:48:36.962: INFO: Pod downwardapi-volume-dcc105bf-2a82-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 02:48:36.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-k9jvf" for this suite.
Feb  7 02:48:43.039: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 02:48:43.105: INFO: namespace: e2e-tests-projected-k9jvf, resource: bindings, ignored listing per whitelist
Feb  7 02:48:43.140: INFO: namespace e2e-tests-projected-k9jvf deletion completed in 6.174895923s

• [SLOW TEST:8.264 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 02:48:43.140: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 02:49:43.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-csxjg" for this suite.
Feb  7 02:50:07.266: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 02:50:07.340: INFO: namespace: e2e-tests-container-probe-csxjg, resource: bindings, ignored listing per whitelist
Feb  7 02:50:07.360: INFO: namespace e2e-tests-container-probe-csxjg deletion completed in 24.103676584s

• [SLOW TEST:84.220 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 02:50:07.360: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb  7 02:50:09.933: INFO: Successfully updated pod "pod-update-13e106b1-2a83-11e9-87fe-baa4eca941e3"
STEP: verifying the updated pod is in kubernetes
Feb  7 02:50:09.938: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 02:50:09.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-vrwlr" for this suite.
Feb  7 02:50:33.951: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 02:50:34.024: INFO: namespace: e2e-tests-pods-vrwlr, resource: bindings, ignored listing per whitelist
Feb  7 02:50:34.058: INFO: namespace e2e-tests-pods-vrwlr deletion completed in 24.116690421s

• [SLOW TEST:26.698 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 02:50:34.058: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  7 02:50:34.114: INFO: Waiting up to 5m0s for pod "downwardapi-volume-23caae77-2a83-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-downward-api-f5s8c" to be "success or failure"
Feb  7 02:50:34.116: INFO: Pod "downwardapi-volume-23caae77-2a83-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.054903ms
Feb  7 02:50:36.119: INFO: Pod "downwardapi-volume-23caae77-2a83-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005044488s
STEP: Saw pod success
Feb  7 02:50:36.119: INFO: Pod "downwardapi-volume-23caae77-2a83-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 02:50:36.122: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod downwardapi-volume-23caae77-2a83-11e9-87fe-baa4eca941e3 container client-container: <nil>
STEP: delete the pod
Feb  7 02:50:36.137: INFO: Waiting for pod downwardapi-volume-23caae77-2a83-11e9-87fe-baa4eca941e3 to disappear
Feb  7 02:50:36.139: INFO: Pod downwardapi-volume-23caae77-2a83-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 02:50:36.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-f5s8c" for this suite.
Feb  7 02:50:42.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 02:50:42.160: INFO: namespace: e2e-tests-downward-api-f5s8c, resource: bindings, ignored listing per whitelist
Feb  7 02:50:42.340: INFO: namespace e2e-tests-downward-api-f5s8c deletion completed in 6.197330518s

• [SLOW TEST:8.282 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 02:50:42.340: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Feb  7 02:50:42.389: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 create -f - --namespace=e2e-tests-kubectl-rlgnm'
Feb  7 02:50:42.753: INFO: stderr: ""
Feb  7 02:50:42.753: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb  7 02:50:42.753: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-rlgnm'
Feb  7 02:50:42.837: INFO: stderr: ""
Feb  7 02:50:42.837: INFO: stdout: "update-demo-nautilus-h26jz update-demo-nautilus-r45gz "
Feb  7 02:50:42.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 get pods update-demo-nautilus-h26jz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rlgnm'
Feb  7 02:50:42.906: INFO: stderr: ""
Feb  7 02:50:42.906: INFO: stdout: ""
Feb  7 02:50:42.906: INFO: update-demo-nautilus-h26jz is created but not running
Feb  7 02:50:47.906: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-rlgnm'
Feb  7 02:50:48.314: INFO: stderr: ""
Feb  7 02:50:48.314: INFO: stdout: "update-demo-nautilus-h26jz update-demo-nautilus-r45gz "
Feb  7 02:50:48.314: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 get pods update-demo-nautilus-h26jz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rlgnm'
Feb  7 02:50:48.382: INFO: stderr: ""
Feb  7 02:50:48.382: INFO: stdout: "true"
Feb  7 02:50:48.382: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 get pods update-demo-nautilus-h26jz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rlgnm'
Feb  7 02:50:48.455: INFO: stderr: ""
Feb  7 02:50:48.455: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  7 02:50:48.455: INFO: validating pod update-demo-nautilus-h26jz
Feb  7 02:50:48.460: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  7 02:50:48.460: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  7 02:50:48.460: INFO: update-demo-nautilus-h26jz is verified up and running
Feb  7 02:50:48.460: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 get pods update-demo-nautilus-r45gz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rlgnm'
Feb  7 02:50:48.528: INFO: stderr: ""
Feb  7 02:50:48.528: INFO: stdout: "true"
Feb  7 02:50:48.528: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 get pods update-demo-nautilus-r45gz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rlgnm'
Feb  7 02:50:48.595: INFO: stderr: ""
Feb  7 02:50:48.595: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  7 02:50:48.595: INFO: validating pod update-demo-nautilus-r45gz
Feb  7 02:50:48.599: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  7 02:50:48.599: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  7 02:50:48.599: INFO: update-demo-nautilus-r45gz is verified up and running
STEP: using delete to clean up resources
Feb  7 02:50:48.599: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-rlgnm'
Feb  7 02:50:48.669: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  7 02:50:48.669: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb  7 02:50:48.669: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-rlgnm'
Feb  7 02:50:48.759: INFO: stderr: "No resources found.\n"
Feb  7 02:50:48.759: INFO: stdout: ""
Feb  7 02:50:48.759: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 get pods -l name=update-demo --namespace=e2e-tests-kubectl-rlgnm -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb  7 02:50:48.836: INFO: stderr: ""
Feb  7 02:50:48.836: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 02:50:48.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-rlgnm" for this suite.
Feb  7 02:50:54.852: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 02:50:54.979: INFO: namespace: e2e-tests-kubectl-rlgnm, resource: bindings, ignored listing per whitelist
Feb  7 02:50:55.032: INFO: namespace e2e-tests-kubectl-rlgnm deletion completed in 6.192709966s

• [SLOW TEST:12.692 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 02:50:55.033: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb  7 02:51:01.162: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  7 02:51:01.164: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  7 02:51:03.165: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  7 02:51:03.168: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  7 02:51:05.165: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  7 02:51:05.168: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  7 02:51:07.165: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  7 02:51:07.168: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  7 02:51:09.165: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  7 02:51:09.167: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  7 02:51:11.165: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  7 02:51:11.249: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  7 02:51:13.165: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  7 02:51:13.168: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  7 02:51:15.165: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  7 02:51:15.168: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  7 02:51:17.165: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  7 02:51:17.168: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  7 02:51:19.165: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  7 02:51:19.168: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  7 02:51:21.165: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  7 02:51:21.168: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  7 02:51:23.165: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  7 02:51:23.248: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  7 02:51:25.165: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  7 02:51:25.168: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  7 02:51:27.165: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  7 02:51:27.167: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 02:51:27.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-2w85l" for this suite.
Feb  7 02:51:51.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 02:51:51.360: INFO: namespace: e2e-tests-container-lifecycle-hook-2w85l, resource: bindings, ignored listing per whitelist
Feb  7 02:51:51.390: INFO: namespace e2e-tests-container-lifecycle-hook-2w85l deletion completed in 24.219033623s

• [SLOW TEST:56.357 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 02:51:51.390: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  7 02:51:51.462: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"51e8ad5a-2a83-11e9-809d-e6a419c8531a", Controller:(*bool)(0xc0023728de), BlockOwnerDeletion:(*bool)(0xc0023728df)}}
Feb  7 02:51:51.467: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"51e76ddc-2a83-11e9-809d-e6a419c8531a", Controller:(*bool)(0xc0022854a6), BlockOwnerDeletion:(*bool)(0xc0022854a7)}}
Feb  7 02:51:51.471: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"51e82222-2a83-11e9-809d-e6a419c8531a", Controller:(*bool)(0xc00237c6ea), BlockOwnerDeletion:(*bool)(0xc00237c6eb)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 02:51:56.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-lhrnl" for this suite.
Feb  7 02:52:02.497: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 02:52:02.579: INFO: namespace: e2e-tests-gc-lhrnl, resource: bindings, ignored listing per whitelist
Feb  7 02:52:02.595: INFO: namespace e2e-tests-gc-lhrnl deletion completed in 6.109863359s

• [SLOW TEST:11.206 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 02:52:02.596: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Feb  7 02:52:02.653: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-6pw7v" to be "success or failure"
Feb  7 02:52:02.655: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 1.873007ms
Feb  7 02:52:04.658: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004593279s
STEP: Saw pod success
Feb  7 02:52:04.658: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Feb  7 02:52:04.660: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Feb  7 02:52:04.673: INFO: Waiting for pod pod-host-path-test to disappear
Feb  7 02:52:04.675: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 02:52:04.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-6pw7v" for this suite.
Feb  7 02:52:13.008: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 02:52:13.083: INFO: namespace: e2e-tests-hostpath-6pw7v, resource: bindings, ignored listing per whitelist
Feb  7 02:52:13.106: INFO: namespace e2e-tests-hostpath-6pw7v deletion completed in 8.427664884s

• [SLOW TEST:10.511 seconds]
[sig-storage] HostPath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 02:52:13.107: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-5ed42dea-2a83-11e9-87fe-baa4eca941e3
STEP: Creating a pod to test consume configMaps
Feb  7 02:52:13.167: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5ed4ee59-2a83-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-projected-8hpkb" to be "success or failure"
Feb  7 02:52:13.169: INFO: Pod "pod-projected-configmaps-5ed4ee59-2a83-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021186ms
Feb  7 02:52:15.428: INFO: Pod "pod-projected-configmaps-5ed4ee59-2a83-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.261251356s
STEP: Saw pod success
Feb  7 02:52:15.429: INFO: Pod "pod-projected-configmaps-5ed4ee59-2a83-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 02:52:15.431: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod pod-projected-configmaps-5ed4ee59-2a83-11e9-87fe-baa4eca941e3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  7 02:52:15.647: INFO: Waiting for pod pod-projected-configmaps-5ed4ee59-2a83-11e9-87fe-baa4eca941e3 to disappear
Feb  7 02:52:15.649: INFO: Pod pod-projected-configmaps-5ed4ee59-2a83-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 02:52:15.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8hpkb" for this suite.
Feb  7 02:52:23.663: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 02:52:23.705: INFO: namespace: e2e-tests-projected-8hpkb, resource: bindings, ignored listing per whitelist
Feb  7 02:52:23.768: INFO: namespace e2e-tests-projected-8hpkb deletion completed in 8.116000803s

• [SLOW TEST:10.662 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 02:52:23.768: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  7 02:52:23.829: INFO: Waiting up to 5m0s for pod "downwardapi-volume-652f9ca4-2a83-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-downward-api-mhf7n" to be "success or failure"
Feb  7 02:52:23.832: INFO: Pod "downwardapi-volume-652f9ca4-2a83-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.197061ms
Feb  7 02:52:26.322: INFO: Pod "downwardapi-volume-652f9ca4-2a83-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.492178771s
Feb  7 02:52:28.328: INFO: Pod "downwardapi-volume-652f9ca4-2a83-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.498763384s
STEP: Saw pod success
Feb  7 02:52:28.328: INFO: Pod "downwardapi-volume-652f9ca4-2a83-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 02:52:28.330: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod downwardapi-volume-652f9ca4-2a83-11e9-87fe-baa4eca941e3 container client-container: <nil>
STEP: delete the pod
Feb  7 02:52:28.358: INFO: Waiting for pod downwardapi-volume-652f9ca4-2a83-11e9-87fe-baa4eca941e3 to disappear
Feb  7 02:52:28.360: INFO: Pod downwardapi-volume-652f9ca4-2a83-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 02:52:28.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-mhf7n" for this suite.
Feb  7 02:52:34.373: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 02:52:34.531: INFO: namespace: e2e-tests-downward-api-mhf7n, resource: bindings, ignored listing per whitelist
Feb  7 02:52:34.537: INFO: namespace e2e-tests-downward-api-mhf7n deletion completed in 6.17429103s

• [SLOW TEST:10.769 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 02:52:34.538: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  7 02:52:35.769: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 02:52:38.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-299lg" for this suite.
Feb  7 02:53:26.050: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 02:53:26.102: INFO: namespace: e2e-tests-pods-299lg, resource: bindings, ignored listing per whitelist
Feb  7 02:53:26.146: INFO: namespace e2e-tests-pods-299lg deletion completed in 48.105793263s

• [SLOW TEST:51.608 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 02:53:26.146: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  7 02:53:26.199: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 02:53:27.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-5zfpd" for this suite.
Feb  7 02:53:33.403: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 02:53:33.484: INFO: namespace: e2e-tests-custom-resource-definition-5zfpd, resource: bindings, ignored listing per whitelist
Feb  7 02:53:33.534: INFO: namespace e2e-tests-custom-resource-definition-5zfpd deletion completed in 6.168036771s

• [SLOW TEST:7.388 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 02:53:33.534: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-d9v2p
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-d9v2p to expose endpoints map[]
Feb  7 02:53:33.595: INFO: Get endpoints failed (2.67996ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Feb  7 02:53:34.598: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-d9v2p exposes endpoints map[] (1.005593865s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-d9v2p
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-d9v2p to expose endpoints map[pod1:[80]]
Feb  7 02:53:36.668: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-d9v2p exposes endpoints map[pod1:[80]] (2.062425888s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-d9v2p
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-d9v2p to expose endpoints map[pod1:[80] pod2:[80]]
Feb  7 02:53:39.755: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-d9v2p exposes endpoints map[pod1:[80] pod2:[80]] (3.08235682s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-d9v2p
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-d9v2p to expose endpoints map[pod2:[80]]
Feb  7 02:53:40.156: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-d9v2p exposes endpoints map[pod2:[80]] (60.862346ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-d9v2p
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-d9v2p to expose endpoints map[]
Feb  7 02:53:41.166: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-d9v2p exposes endpoints map[] (1.005643743s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 02:53:41.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-d9v2p" for this suite.
Feb  7 02:54:03.200: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 02:54:03.393: INFO: namespace: e2e-tests-services-d9v2p, resource: bindings, ignored listing per whitelist
Feb  7 02:54:03.393: INFO: namespace e2e-tests-services-d9v2p deletion completed in 22.206911923s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:29.858 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 02:54:03.393: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-a09b5868-2a83-11e9-87fe-baa4eca941e3
STEP: Creating secret with name s-test-opt-upd-a09b58b0-2a83-11e9-87fe-baa4eca941e3
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-a09b5868-2a83-11e9-87fe-baa4eca941e3
STEP: Updating secret s-test-opt-upd-a09b58b0-2a83-11e9-87fe-baa4eca941e3
STEP: Creating secret with name s-test-opt-create-a09b58cf-2a83-11e9-87fe-baa4eca941e3
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 02:54:08.294: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-nts7w" for this suite.
Feb  7 02:54:30.307: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 02:54:30.418: INFO: namespace: e2e-tests-secrets-nts7w, resource: bindings, ignored listing per whitelist
Feb  7 02:54:30.490: INFO: namespace e2e-tests-secrets-nts7w deletion completed in 22.192717858s

• [SLOW TEST:27.097 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 02:54:30.490: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Feb  7 02:54:30.543: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 cluster-info'
Feb  7 02:54:30.606: INFO: stderr: ""
Feb  7 02:54:30.606: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.100.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://10.100.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 02:54:30.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hfgrk" for this suite.
Feb  7 02:54:36.621: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 02:54:36.719: INFO: namespace: e2e-tests-kubectl-hfgrk, resource: bindings, ignored listing per whitelist
Feb  7 02:54:36.784: INFO: namespace e2e-tests-kubectl-hfgrk deletion completed in 6.173286096s

• [SLOW TEST:6.294 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 02:54:36.784: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Feb  7 02:54:39.083: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 02:55:04.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-kvt5h" for this suite.
Feb  7 02:55:11.071: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 02:55:11.077: INFO: namespace: e2e-tests-namespaces-kvt5h, resource: bindings, ignored listing per whitelist
Feb  7 02:55:11.164: INFO: namespace e2e-tests-namespaces-kvt5h deletion completed in 6.345530494s
STEP: Destroying namespace "e2e-tests-nsdeletetest-mdrzs" for this suite.
Feb  7 02:55:11.166: INFO: Namespace e2e-tests-nsdeletetest-mdrzs was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-z9kvf" for this suite.
Feb  7 02:55:17.176: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 02:55:17.665: INFO: namespace: e2e-tests-nsdeletetest-z9kvf, resource: bindings, ignored listing per whitelist
Feb  7 02:55:17.711: INFO: namespace e2e-tests-nsdeletetest-z9kvf deletion completed in 6.544364365s

• [SLOW TEST:40.926 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 02:55:17.711: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Feb  7 02:55:17.776: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-frg7c,SelfLink:/api/v1/namespaces/e2e-tests-watch-frg7c/configmaps/e2e-watch-test-watch-closed,UID:ccdee836-2a83-11e9-809d-e6a419c8531a,ResourceVersion:6617,Generation:0,CreationTimestamp:2019-02-07 02:55:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb  7 02:55:17.776: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-frg7c,SelfLink:/api/v1/namespaces/e2e-tests-watch-frg7c/configmaps/e2e-watch-test-watch-closed,UID:ccdee836-2a83-11e9-809d-e6a419c8531a,ResourceVersion:6618,Generation:0,CreationTimestamp:2019-02-07 02:55:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Feb  7 02:55:17.787: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-frg7c,SelfLink:/api/v1/namespaces/e2e-tests-watch-frg7c/configmaps/e2e-watch-test-watch-closed,UID:ccdee836-2a83-11e9-809d-e6a419c8531a,ResourceVersion:6619,Generation:0,CreationTimestamp:2019-02-07 02:55:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb  7 02:55:17.787: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-frg7c,SelfLink:/api/v1/namespaces/e2e-tests-watch-frg7c/configmaps/e2e-watch-test-watch-closed,UID:ccdee836-2a83-11e9-809d-e6a419c8531a,ResourceVersion:6620,Generation:0,CreationTimestamp:2019-02-07 02:55:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 02:55:17.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-frg7c" for this suite.
Feb  7 02:55:23.800: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 02:55:23.874: INFO: namespace: e2e-tests-watch-frg7c, resource: bindings, ignored listing per whitelist
Feb  7 02:55:23.950: INFO: namespace e2e-tests-watch-frg7c deletion completed in 6.159468237s

• [SLOW TEST:6.239 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 02:55:23.950: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-r2s9z
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb  7 02:55:24.000: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb  7 02:55:46.308: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.5.44:8080/dial?request=hostName&protocol=udp&host=192.168.5.43&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-r2s9z PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  7 02:55:46.308: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
Feb  7 02:55:46.418: INFO: Waiting for endpoints: map[]
Feb  7 02:55:46.420: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.5.44:8080/dial?request=hostName&protocol=udp&host=192.168.4.14&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-r2s9z PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  7 02:55:46.420: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
Feb  7 02:55:46.504: INFO: Waiting for endpoints: map[]
Feb  7 02:55:46.507: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.5.44:8080/dial?request=hostName&protocol=udp&host=192.168.3.20&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-r2s9z PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  7 02:55:46.507: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
Feb  7 02:55:46.589: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 02:55:46.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-r2s9z" for this suite.
Feb  7 02:56:08.655: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 02:56:08.829: INFO: namespace: e2e-tests-pod-network-test-r2s9z, resource: bindings, ignored listing per whitelist
Feb  7 02:56:08.885: INFO: namespace e2e-tests-pod-network-test-r2s9z deletion completed in 22.292070986s

• [SLOW TEST:44.935 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 02:56:08.885: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Feb  7 02:56:08.942: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 create -f - --namespace=e2e-tests-kubectl-sbv2r'
Feb  7 02:56:09.119: INFO: stderr: ""
Feb  7 02:56:09.119: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb  7 02:56:09.119: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-sbv2r'
Feb  7 02:56:09.186: INFO: stderr: ""
Feb  7 02:56:09.186: INFO: stdout: "update-demo-nautilus-cqw9v update-demo-nautilus-x24mp "
Feb  7 02:56:09.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 get pods update-demo-nautilus-cqw9v -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sbv2r'
Feb  7 02:56:09.245: INFO: stderr: ""
Feb  7 02:56:09.245: INFO: stdout: ""
Feb  7 02:56:09.245: INFO: update-demo-nautilus-cqw9v is created but not running
Feb  7 02:56:14.245: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-sbv2r'
Feb  7 02:56:14.309: INFO: stderr: ""
Feb  7 02:56:14.309: INFO: stdout: "update-demo-nautilus-cqw9v update-demo-nautilus-x24mp "
Feb  7 02:56:14.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 get pods update-demo-nautilus-cqw9v -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sbv2r'
Feb  7 02:56:14.368: INFO: stderr: ""
Feb  7 02:56:14.368: INFO: stdout: "true"
Feb  7 02:56:14.368: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 get pods update-demo-nautilus-cqw9v -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sbv2r'
Feb  7 02:56:14.426: INFO: stderr: ""
Feb  7 02:56:14.426: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  7 02:56:14.426: INFO: validating pod update-demo-nautilus-cqw9v
Feb  7 02:56:14.456: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  7 02:56:14.456: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  7 02:56:14.456: INFO: update-demo-nautilus-cqw9v is verified up and running
Feb  7 02:56:14.456: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 get pods update-demo-nautilus-x24mp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sbv2r'
Feb  7 02:56:14.519: INFO: stderr: ""
Feb  7 02:56:14.519: INFO: stdout: "true"
Feb  7 02:56:14.519: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 get pods update-demo-nautilus-x24mp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sbv2r'
Feb  7 02:56:14.576: INFO: stderr: ""
Feb  7 02:56:14.576: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  7 02:56:14.576: INFO: validating pod update-demo-nautilus-x24mp
Feb  7 02:56:14.581: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  7 02:56:14.581: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  7 02:56:14.581: INFO: update-demo-nautilus-x24mp is verified up and running
STEP: rolling-update to new replication controller
Feb  7 02:56:14.582: INFO: scanned /root for discovery docs: <nil>
Feb  7 02:56:14.582: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-sbv2r'
Feb  7 02:56:39.062: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb  7 02:56:39.062: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb  7 02:56:39.062: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-sbv2r'
Feb  7 02:56:39.136: INFO: stderr: ""
Feb  7 02:56:39.136: INFO: stdout: "update-demo-kitten-4wbnl update-demo-kitten-bqlq9 "
Feb  7 02:56:39.136: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 get pods update-demo-kitten-4wbnl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sbv2r'
Feb  7 02:56:39.196: INFO: stderr: ""
Feb  7 02:56:39.196: INFO: stdout: "true"
Feb  7 02:56:39.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 get pods update-demo-kitten-4wbnl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sbv2r'
Feb  7 02:56:39.258: INFO: stderr: ""
Feb  7 02:56:39.258: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb  7 02:56:39.258: INFO: validating pod update-demo-kitten-4wbnl
Feb  7 02:56:39.262: INFO: got data: {
  "image": "kitten.jpg"
}

Feb  7 02:56:39.262: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb  7 02:56:39.262: INFO: update-demo-kitten-4wbnl is verified up and running
Feb  7 02:56:39.262: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 get pods update-demo-kitten-bqlq9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sbv2r'
Feb  7 02:56:39.319: INFO: stderr: ""
Feb  7 02:56:39.319: INFO: stdout: "true"
Feb  7 02:56:39.319: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 get pods update-demo-kitten-bqlq9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sbv2r'
Feb  7 02:56:39.377: INFO: stderr: ""
Feb  7 02:56:39.377: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb  7 02:56:39.377: INFO: validating pod update-demo-kitten-bqlq9
Feb  7 02:56:39.381: INFO: got data: {
  "image": "kitten.jpg"
}

Feb  7 02:56:39.381: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb  7 02:56:39.381: INFO: update-demo-kitten-bqlq9 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 02:56:39.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-sbv2r" for this suite.
Feb  7 02:57:01.395: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 02:57:01.467: INFO: namespace: e2e-tests-kubectl-sbv2r, resource: bindings, ignored listing per whitelist
Feb  7 02:57:01.487: INFO: namespace e2e-tests-kubectl-sbv2r deletion completed in 22.102087106s

• [SLOW TEST:52.602 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 02:57:01.487: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  7 02:57:01.545: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0ab7e969-2a84-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-downward-api-sf8qm" to be "success or failure"
Feb  7 02:57:01.547: INFO: Pod "downwardapi-volume-0ab7e969-2a84-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.803597ms
Feb  7 02:57:03.672: INFO: Pod "downwardapi-volume-0ab7e969-2a84-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.127301197s
STEP: Saw pod success
Feb  7 02:57:03.672: INFO: Pod "downwardapi-volume-0ab7e969-2a84-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 02:57:03.675: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod downwardapi-volume-0ab7e969-2a84-11e9-87fe-baa4eca941e3 container client-container: <nil>
STEP: delete the pod
Feb  7 02:57:03.692: INFO: Waiting for pod downwardapi-volume-0ab7e969-2a84-11e9-87fe-baa4eca941e3 to disappear
Feb  7 02:57:03.756: INFO: Pod downwardapi-volume-0ab7e969-2a84-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 02:57:03.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-sf8qm" for this suite.
Feb  7 02:57:11.769: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 02:57:11.842: INFO: namespace: e2e-tests-downward-api-sf8qm, resource: bindings, ignored listing per whitelist
Feb  7 02:57:11.906: INFO: namespace e2e-tests-downward-api-sf8qm deletion completed in 8.146749495s

• [SLOW TEST:10.419 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 02:57:11.906: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 02:57:21.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-j6vsx" for this suite.
Feb  7 02:57:45.350: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 02:57:45.562: INFO: namespace: e2e-tests-replication-controller-j6vsx, resource: bindings, ignored listing per whitelist
Feb  7 02:57:45.575: INFO: namespace e2e-tests-replication-controller-j6vsx deletion completed in 24.240393857s

• [SLOW TEST:33.670 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 02:57:45.576: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-24ffadf1-2a84-11e9-87fe-baa4eca941e3
STEP: Creating a pod to test consume secrets
Feb  7 02:57:45.642: INFO: Waiting up to 5m0s for pod "pod-secrets-2500941b-2a84-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-secrets-ftkfk" to be "success or failure"
Feb  7 02:57:45.643: INFO: Pod "pod-secrets-2500941b-2a84-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.855196ms
Feb  7 02:57:47.815: INFO: Pod "pod-secrets-2500941b-2a84-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.173307771s
STEP: Saw pod success
Feb  7 02:57:47.815: INFO: Pod "pod-secrets-2500941b-2a84-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 02:57:47.817: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod pod-secrets-2500941b-2a84-11e9-87fe-baa4eca941e3 container secret-volume-test: <nil>
STEP: delete the pod
Feb  7 02:57:47.876: INFO: Waiting for pod pod-secrets-2500941b-2a84-11e9-87fe-baa4eca941e3 to disappear
Feb  7 02:57:47.878: INFO: Pod pod-secrets-2500941b-2a84-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 02:57:47.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-ftkfk" for this suite.
Feb  7 02:57:53.902: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 02:57:54.033: INFO: namespace: e2e-tests-secrets-ftkfk, resource: bindings, ignored listing per whitelist
Feb  7 02:57:54.094: INFO: namespace e2e-tests-secrets-ftkfk deletion completed in 6.212260065s

• [SLOW TEST:8.518 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 02:57:54.094: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  7 02:57:54.150: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2a129d20-2a84-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-downward-api-f6wbr" to be "success or failure"
Feb  7 02:57:54.152: INFO: Pod "downwardapi-volume-2a129d20-2a84-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.842548ms
Feb  7 02:57:56.155: INFO: Pod "downwardapi-volume-2a129d20-2a84-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004954417s
STEP: Saw pod success
Feb  7 02:57:56.155: INFO: Pod "downwardapi-volume-2a129d20-2a84-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 02:57:56.157: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod downwardapi-volume-2a129d20-2a84-11e9-87fe-baa4eca941e3 container client-container: <nil>
STEP: delete the pod
Feb  7 02:57:56.173: INFO: Waiting for pod downwardapi-volume-2a129d20-2a84-11e9-87fe-baa4eca941e3 to disappear
Feb  7 02:57:56.175: INFO: Pod downwardapi-volume-2a129d20-2a84-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 02:57:56.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-f6wbr" for this suite.
Feb  7 02:58:02.189: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 02:58:02.265: INFO: namespace: e2e-tests-downward-api-f6wbr, resource: bindings, ignored listing per whitelist
Feb  7 02:58:02.284: INFO: namespace e2e-tests-downward-api-f6wbr deletion completed in 6.105545377s

• [SLOW TEST:8.190 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 02:58:02.285: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 02:58:02.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-xzmml" for this suite.
Feb  7 02:58:10.373: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 02:58:10.460: INFO: namespace: e2e-tests-kubelet-test-xzmml, resource: bindings, ignored listing per whitelist
Feb  7 02:58:10.473: INFO: namespace e2e-tests-kubelet-test-xzmml deletion completed in 8.111286955s

• [SLOW TEST:8.188 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 02:58:10.473: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Feb  7 02:58:11.035: INFO: Waiting up to 5m0s for pod "pod-service-account-342307ee-2a84-11e9-87fe-baa4eca941e3-n5d29" in namespace "e2e-tests-svcaccounts-v7gmx" to be "success or failure"
Feb  7 02:58:11.037: INFO: Pod "pod-service-account-342307ee-2a84-11e9-87fe-baa4eca941e3-n5d29": Phase="Pending", Reason="", readiness=false. Elapsed: 1.94732ms
Feb  7 02:58:13.040: INFO: Pod "pod-service-account-342307ee-2a84-11e9-87fe-baa4eca941e3-n5d29": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005175179s
STEP: Saw pod success
Feb  7 02:58:13.041: INFO: Pod "pod-service-account-342307ee-2a84-11e9-87fe-baa4eca941e3-n5d29" satisfied condition "success or failure"
Feb  7 02:58:13.043: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod pod-service-account-342307ee-2a84-11e9-87fe-baa4eca941e3-n5d29 container token-test: <nil>
STEP: delete the pod
Feb  7 02:58:13.058: INFO: Waiting for pod pod-service-account-342307ee-2a84-11e9-87fe-baa4eca941e3-n5d29 to disappear
Feb  7 02:58:13.059: INFO: Pod pod-service-account-342307ee-2a84-11e9-87fe-baa4eca941e3-n5d29 no longer exists
STEP: Creating a pod to test consume service account root CA
Feb  7 02:58:13.064: INFO: Waiting up to 5m0s for pod "pod-service-account-342307ee-2a84-11e9-87fe-baa4eca941e3-rwjhd" in namespace "e2e-tests-svcaccounts-v7gmx" to be "success or failure"
Feb  7 02:58:13.066: INFO: Pod "pod-service-account-342307ee-2a84-11e9-87fe-baa4eca941e3-rwjhd": Phase="Pending", Reason="", readiness=false. Elapsed: 1.851335ms
Feb  7 02:58:15.068: INFO: Pod "pod-service-account-342307ee-2a84-11e9-87fe-baa4eca941e3-rwjhd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004519792s
STEP: Saw pod success
Feb  7 02:58:15.068: INFO: Pod "pod-service-account-342307ee-2a84-11e9-87fe-baa4eca941e3-rwjhd" satisfied condition "success or failure"
Feb  7 02:58:15.070: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod pod-service-account-342307ee-2a84-11e9-87fe-baa4eca941e3-rwjhd container root-ca-test: <nil>
STEP: delete the pod
Feb  7 02:58:15.085: INFO: Waiting for pod pod-service-account-342307ee-2a84-11e9-87fe-baa4eca941e3-rwjhd to disappear
Feb  7 02:58:15.087: INFO: Pod pod-service-account-342307ee-2a84-11e9-87fe-baa4eca941e3-rwjhd no longer exists
STEP: Creating a pod to test consume service account namespace
Feb  7 02:58:15.091: INFO: Waiting up to 5m0s for pod "pod-service-account-342307ee-2a84-11e9-87fe-baa4eca941e3-zph92" in namespace "e2e-tests-svcaccounts-v7gmx" to be "success or failure"
Feb  7 02:58:15.093: INFO: Pod "pod-service-account-342307ee-2a84-11e9-87fe-baa4eca941e3-zph92": Phase="Pending", Reason="", readiness=false. Elapsed: 1.904553ms
Feb  7 02:58:17.597: INFO: Pod "pod-service-account-342307ee-2a84-11e9-87fe-baa4eca941e3-zph92": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.506703359s
STEP: Saw pod success
Feb  7 02:58:17.598: INFO: Pod "pod-service-account-342307ee-2a84-11e9-87fe-baa4eca941e3-zph92" satisfied condition "success or failure"
Feb  7 02:58:17.600: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod pod-service-account-342307ee-2a84-11e9-87fe-baa4eca941e3-zph92 container namespace-test: <nil>
STEP: delete the pod
Feb  7 02:58:17.615: INFO: Waiting for pod pod-service-account-342307ee-2a84-11e9-87fe-baa4eca941e3-zph92 to disappear
Feb  7 02:58:17.617: INFO: Pod pod-service-account-342307ee-2a84-11e9-87fe-baa4eca941e3-zph92 no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 02:58:17.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-v7gmx" for this suite.
Feb  7 02:58:23.632: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 02:58:23.700: INFO: namespace: e2e-tests-svcaccounts-v7gmx, resource: bindings, ignored listing per whitelist
Feb  7 02:58:23.756: INFO: namespace e2e-tests-svcaccounts-v7gmx deletion completed in 6.135326952s

• [SLOW TEST:13.284 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 02:58:23.757: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-3c0912ce-2a84-11e9-87fe-baa4eca941e3
STEP: Creating a pod to test consume configMaps
Feb  7 02:58:24.290: INFO: Waiting up to 5m0s for pod "pod-configmaps-3c09ce88-2a84-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-configmap-xqj7v" to be "success or failure"
Feb  7 02:58:24.292: INFO: Pod "pod-configmaps-3c09ce88-2a84-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.949786ms
Feb  7 02:58:26.294: INFO: Pod "pod-configmaps-3c09ce88-2a84-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004362808s
STEP: Saw pod success
Feb  7 02:58:26.294: INFO: Pod "pod-configmaps-3c09ce88-2a84-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 02:58:26.296: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod pod-configmaps-3c09ce88-2a84-11e9-87fe-baa4eca941e3 container configmap-volume-test: <nil>
STEP: delete the pod
Feb  7 02:58:26.309: INFO: Waiting for pod pod-configmaps-3c09ce88-2a84-11e9-87fe-baa4eca941e3 to disappear
Feb  7 02:58:26.312: INFO: Pod pod-configmaps-3c09ce88-2a84-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 02:58:26.312: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-xqj7v" for this suite.
Feb  7 02:58:32.325: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 02:58:32.586: INFO: namespace: e2e-tests-configmap-xqj7v, resource: bindings, ignored listing per whitelist
Feb  7 02:58:32.701: INFO: namespace e2e-tests-configmap-xqj7v deletion completed in 6.385838643s

• [SLOW TEST:8.944 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 02:58:32.701: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Feb  7 02:58:33.185: INFO: Waiting up to 5m0s for pod "var-expansion-4115ffc3-2a84-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-var-expansion-c2jcr" to be "success or failure"
Feb  7 02:58:33.212: INFO: Pod "var-expansion-4115ffc3-2a84-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 27.259305ms
Feb  7 02:58:35.216: INFO: Pod "var-expansion-4115ffc3-2a84-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030825224s
STEP: Saw pod success
Feb  7 02:58:35.216: INFO: Pod "var-expansion-4115ffc3-2a84-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 02:58:35.218: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod var-expansion-4115ffc3-2a84-11e9-87fe-baa4eca941e3 container dapi-container: <nil>
STEP: delete the pod
Feb  7 02:58:35.232: INFO: Waiting for pod var-expansion-4115ffc3-2a84-11e9-87fe-baa4eca941e3 to disappear
Feb  7 02:58:35.234: INFO: Pod var-expansion-4115ffc3-2a84-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 02:58:35.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-c2jcr" for this suite.
Feb  7 02:58:41.253: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 02:58:41.359: INFO: namespace: e2e-tests-var-expansion-c2jcr, resource: bindings, ignored listing per whitelist
Feb  7 02:58:41.390: INFO: namespace e2e-tests-var-expansion-c2jcr deletion completed in 6.153313084s

• [SLOW TEST:8.690 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 02:58:41.390: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1358
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb  7 02:58:42.111: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-ghqc5'
Feb  7 02:58:42.583: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb  7 02:58:42.583: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Feb  7 02:58:42.644: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Feb  7 02:58:42.647: INFO: scanned /root for discovery docs: <nil>
Feb  7 02:58:42.647: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-ghqc5'
Feb  7 02:58:59.092: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb  7 02:58:59.092: INFO: stdout: "Created e2e-test-nginx-rc-a64f9c742a6fd06de65312c19e53fc61\nScaling up e2e-test-nginx-rc-a64f9c742a6fd06de65312c19e53fc61 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-a64f9c742a6fd06de65312c19e53fc61 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-a64f9c742a6fd06de65312c19e53fc61 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Feb  7 02:58:59.092: INFO: stdout: "Created e2e-test-nginx-rc-a64f9c742a6fd06de65312c19e53fc61\nScaling up e2e-test-nginx-rc-a64f9c742a6fd06de65312c19e53fc61 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-a64f9c742a6fd06de65312c19e53fc61 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-a64f9c742a6fd06de65312c19e53fc61 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Feb  7 02:58:59.092: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-ghqc5'
Feb  7 02:58:59.635: INFO: stderr: ""
Feb  7 02:58:59.635: INFO: stdout: "e2e-test-nginx-rc-a64f9c742a6fd06de65312c19e53fc61-7vrhk "
Feb  7 02:58:59.635: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 get pods e2e-test-nginx-rc-a64f9c742a6fd06de65312c19e53fc61-7vrhk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ghqc5'
Feb  7 02:59:00.230: INFO: stderr: ""
Feb  7 02:59:00.231: INFO: stdout: "true"
Feb  7 02:59:00.231: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 get pods e2e-test-nginx-rc-a64f9c742a6fd06de65312c19e53fc61-7vrhk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ghqc5'
Feb  7 02:59:00.290: INFO: stderr: ""
Feb  7 02:59:00.290: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Feb  7 02:59:00.290: INFO: e2e-test-nginx-rc-a64f9c742a6fd06de65312c19e53fc61-7vrhk is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1364
Feb  7 02:59:00.290: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-ghqc5'
Feb  7 02:59:00.360: INFO: stderr: ""
Feb  7 02:59:00.360: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 02:59:00.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ghqc5" for this suite.
Feb  7 02:59:24.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 02:59:24.579: INFO: namespace: e2e-tests-kubectl-ghqc5, resource: bindings, ignored listing per whitelist
Feb  7 02:59:24.597: INFO: namespace e2e-tests-kubectl-ghqc5 deletion completed in 24.233088944s

• [SLOW TEST:43.207 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 02:59:24.597: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-6005dd21-2a84-11e9-87fe-baa4eca941e3
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-6005dd21-2a84-11e9-87fe-baa4eca941e3
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 02:59:28.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-28g6f" for this suite.
Feb  7 02:59:50.981: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 02:59:51.065: INFO: namespace: e2e-tests-projected-28g6f, resource: bindings, ignored listing per whitelist
Feb  7 02:59:51.079: INFO: namespace e2e-tests-projected-28g6f deletion completed in 22.143067011s

• [SLOW TEST:26.482 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 02:59:51.079: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  7 02:59:51.139: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6fcdcb1b-2a84-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-projected-tq8dh" to be "success or failure"
Feb  7 02:59:51.141: INFO: Pod "downwardapi-volume-6fcdcb1b-2a84-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.15118ms
Feb  7 02:59:53.144: INFO: Pod "downwardapi-volume-6fcdcb1b-2a84-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005402483s
STEP: Saw pod success
Feb  7 02:59:53.144: INFO: Pod "downwardapi-volume-6fcdcb1b-2a84-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 02:59:53.146: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod downwardapi-volume-6fcdcb1b-2a84-11e9-87fe-baa4eca941e3 container client-container: <nil>
STEP: delete the pod
Feb  7 02:59:53.160: INFO: Waiting for pod downwardapi-volume-6fcdcb1b-2a84-11e9-87fe-baa4eca941e3 to disappear
Feb  7 02:59:53.162: INFO: Pod downwardapi-volume-6fcdcb1b-2a84-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 02:59:53.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-tq8dh" for this suite.
Feb  7 02:59:59.275: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 02:59:59.425: INFO: namespace: e2e-tests-projected-tq8dh, resource: bindings, ignored listing per whitelist
Feb  7 02:59:59.450: INFO: namespace e2e-tests-projected-tq8dh deletion completed in 6.283986133s

• [SLOW TEST:8.370 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 02:59:59.450: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Feb  7 02:59:59.507: INFO: Waiting up to 5m0s for pod "client-containers-74caaa1c-2a84-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-containers-rjv6v" to be "success or failure"
Feb  7 02:59:59.509: INFO: Pod "client-containers-74caaa1c-2a84-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.002179ms
Feb  7 03:00:01.512: INFO: Pod "client-containers-74caaa1c-2a84-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004672881s
Feb  7 03:00:03.515: INFO: Pod "client-containers-74caaa1c-2a84-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007949324s
STEP: Saw pod success
Feb  7 03:00:03.515: INFO: Pod "client-containers-74caaa1c-2a84-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:00:03.517: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod client-containers-74caaa1c-2a84-11e9-87fe-baa4eca941e3 container test-container: <nil>
STEP: delete the pod
Feb  7 03:00:03.574: INFO: Waiting for pod client-containers-74caaa1c-2a84-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:00:03.576: INFO: Pod client-containers-74caaa1c-2a84-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:00:03.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-rjv6v" for this suite.
Feb  7 03:00:09.590: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:00:09.615: INFO: namespace: e2e-tests-containers-rjv6v, resource: bindings, ignored listing per whitelist
Feb  7 03:00:09.691: INFO: namespace e2e-tests-containers-rjv6v deletion completed in 6.110604853s

• [SLOW TEST:10.241 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:00:09.691: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb  7 03:00:09.753: INFO: Waiting up to 5m0s for pod "pod-7ae5be4f-2a84-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-emptydir-sfq8r" to be "success or failure"
Feb  7 03:00:09.754: INFO: Pod "pod-7ae5be4f-2a84-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.825614ms
Feb  7 03:00:11.757: INFO: Pod "pod-7ae5be4f-2a84-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004724128s
Feb  7 03:00:13.761: INFO: Pod "pod-7ae5be4f-2a84-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007904128s
STEP: Saw pod success
Feb  7 03:00:13.761: INFO: Pod "pod-7ae5be4f-2a84-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:00:13.763: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod pod-7ae5be4f-2a84-11e9-87fe-baa4eca941e3 container test-container: <nil>
STEP: delete the pod
Feb  7 03:00:13.779: INFO: Waiting for pod pod-7ae5be4f-2a84-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:00:13.781: INFO: Pod pod-7ae5be4f-2a84-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:00:13.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-sfq8r" for this suite.
Feb  7 03:00:21.795: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:00:21.803: INFO: namespace: e2e-tests-emptydir-sfq8r, resource: bindings, ignored listing per whitelist
Feb  7 03:00:21.902: INFO: namespace e2e-tests-emptydir-sfq8r deletion completed in 8.117993745s

• [SLOW TEST:12.211 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:00:21.902: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  7 03:00:21.964: INFO: Waiting up to 5m0s for pod "downwardapi-volume-822d7133-2a84-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-projected-9frsn" to be "success or failure"
Feb  7 03:00:21.967: INFO: Pod "downwardapi-volume-822d7133-2a84-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.081096ms
Feb  7 03:00:23.970: INFO: Pod "downwardapi-volume-822d7133-2a84-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005226651s
STEP: Saw pod success
Feb  7 03:00:23.970: INFO: Pod "downwardapi-volume-822d7133-2a84-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:00:23.972: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod downwardapi-volume-822d7133-2a84-11e9-87fe-baa4eca941e3 container client-container: <nil>
STEP: delete the pod
Feb  7 03:00:23.987: INFO: Waiting for pod downwardapi-volume-822d7133-2a84-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:00:23.989: INFO: Pod downwardapi-volume-822d7133-2a84-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:00:23.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9frsn" for this suite.
Feb  7 03:00:30.002: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:00:30.015: INFO: namespace: e2e-tests-projected-9frsn, resource: bindings, ignored listing per whitelist
Feb  7 03:00:30.100: INFO: namespace e2e-tests-projected-9frsn deletion completed in 6.107837748s

• [SLOW TEST:8.198 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:00:30.100: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  7 03:00:30.572: INFO: Creating deployment "test-recreate-deployment"
Feb  7 03:00:30.579: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Feb  7 03:00:30.584: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Feb  7 03:00:33.766: INFO: Waiting deployment "test-recreate-deployment" to complete
Feb  7 03:00:34.285: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Feb  7 03:00:34.379: INFO: Updating deployment test-recreate-deployment
Feb  7 03:00:34.379: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb  7 03:00:34.428: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-kw6wr,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-kw6wr/deployments/test-recreate-deployment,UID:874faf7b-2a84-11e9-809d-e6a419c8531a,ResourceVersion:7968,Generation:2,CreationTimestamp:2019-02-07 03:00:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-02-07 03:00:34 +0000 UTC 2019-02-07 03:00:34 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-02-07 03:00:34 +0000 UTC 2019-02-07 03:00:30 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-697fbf54bf" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Feb  7 03:00:34.433: INFO: New ReplicaSet "test-recreate-deployment-697fbf54bf" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf,GenerateName:,Namespace:e2e-tests-deployment-kw6wr,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-kw6wr/replicasets/test-recreate-deployment-697fbf54bf,UID:898f48c3-2a84-11e9-927c-4a513db42ba3,ResourceVersion:7967,Generation:1,CreationTimestamp:2019-02-07 03:00:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 874faf7b-2a84-11e9-809d-e6a419c8531a 0xc001e41477 0xc001e41478}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb  7 03:00:34.433: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Feb  7 03:00:34.433: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5dfdcc846d,GenerateName:,Namespace:e2e-tests-deployment-kw6wr,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-kw6wr/replicasets/test-recreate-deployment-5dfdcc846d,UID:8748b42d-2a84-11e9-927c-4a513db42ba3,ResourceVersion:7960,Generation:2,CreationTimestamp:2019-02-07 03:00:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 874faf7b-2a84-11e9-809d-e6a419c8531a 0xc001e413c7 0xc001e413c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb  7 03:00:34.436: INFO: Pod "test-recreate-deployment-697fbf54bf-6mhqk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf-6mhqk,GenerateName:test-recreate-deployment-697fbf54bf-,Namespace:e2e-tests-deployment-kw6wr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-kw6wr/pods/test-recreate-deployment-697fbf54bf-6mhqk,UID:898ff32e-2a84-11e9-927c-4a513db42ba3,ResourceVersion:7965,Generation:0,CreationTimestamp:2019-02-07 03:00:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-697fbf54bf 898f48c3-2a84-11e9-927c-4a513db42ba3 0xc00156c607 0xc00156c608}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sjdht {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sjdht,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sjdht true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-node-0-kubelet.devkubernetes01.mesos,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00156c980} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00156c9a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:00:34 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:00:34.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-kw6wr" for this suite.
Feb  7 03:00:42.449: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:00:42.790: INFO: namespace: e2e-tests-deployment-kw6wr, resource: bindings, ignored listing per whitelist
Feb  7 03:00:42.835: INFO: namespace e2e-tests-deployment-kw6wr deletion completed in 8.396702922s

• [SLOW TEST:12.735 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:00:42.836: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb  7 03:00:45.480: INFO: Successfully updated pod "annotationupdate8ea7785f-2a84-11e9-87fe-baa4eca941e3"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:00:49.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pbh84" for this suite.
Feb  7 03:01:13.519: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:01:13.566: INFO: namespace: e2e-tests-projected-pbh84, resource: bindings, ignored listing per whitelist
Feb  7 03:01:13.612: INFO: namespace e2e-tests-projected-pbh84 deletion completed in 24.104877341s

• [SLOW TEST:30.777 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:01:13.613: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0207 03:01:19.776013      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb  7 03:01:19.776: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:01:19.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-8c92g" for this suite.
Feb  7 03:01:25.789: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:01:25.839: INFO: namespace: e2e-tests-gc-8c92g, resource: bindings, ignored listing per whitelist
Feb  7 03:01:25.890: INFO: namespace e2e-tests-gc-8c92g deletion completed in 6.111917705s

• [SLOW TEST:12.278 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:01:25.890: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-a850a9d0-2a84-11e9-87fe-baa4eca941e3
STEP: Creating a pod to test consume secrets
Feb  7 03:01:26.150: INFO: Waiting up to 5m0s for pod "pod-secrets-a8516746-2a84-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-secrets-7gknq" to be "success or failure"
Feb  7 03:01:26.154: INFO: Pod "pod-secrets-a8516746-2a84-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.981037ms
Feb  7 03:01:28.157: INFO: Pod "pod-secrets-a8516746-2a84-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006774142s
STEP: Saw pod success
Feb  7 03:01:28.157: INFO: Pod "pod-secrets-a8516746-2a84-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:01:28.159: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod pod-secrets-a8516746-2a84-11e9-87fe-baa4eca941e3 container secret-volume-test: <nil>
STEP: delete the pod
Feb  7 03:01:28.843: INFO: Waiting for pod pod-secrets-a8516746-2a84-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:01:28.845: INFO: Pod pod-secrets-a8516746-2a84-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:01:28.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-7gknq" for this suite.
Feb  7 03:01:34.886: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:01:35.298: INFO: namespace: e2e-tests-secrets-7gknq, resource: bindings, ignored listing per whitelist
Feb  7 03:01:35.306: INFO: namespace e2e-tests-secrets-7gknq deletion completed in 6.457458712s

• [SLOW TEST:9.416 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:01:35.306: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-pcxpr/secret-test-aded25e1-2a84-11e9-87fe-baa4eca941e3
STEP: Creating a pod to test consume secrets
Feb  7 03:01:35.366: INFO: Waiting up to 5m0s for pod "pod-configmaps-adee0376-2a84-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-secrets-pcxpr" to be "success or failure"
Feb  7 03:01:35.368: INFO: Pod "pod-configmaps-adee0376-2a84-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.833608ms
Feb  7 03:01:37.371: INFO: Pod "pod-configmaps-adee0376-2a84-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004844723s
Feb  7 03:01:39.374: INFO: Pod "pod-configmaps-adee0376-2a84-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007713961s
STEP: Saw pod success
Feb  7 03:01:39.374: INFO: Pod "pod-configmaps-adee0376-2a84-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:01:39.376: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod pod-configmaps-adee0376-2a84-11e9-87fe-baa4eca941e3 container env-test: <nil>
STEP: delete the pod
Feb  7 03:01:39.478: INFO: Waiting for pod pod-configmaps-adee0376-2a84-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:01:39.480: INFO: Pod pod-configmaps-adee0376-2a84-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:01:39.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-pcxpr" for this suite.
Feb  7 03:01:45.578: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:01:45.649: INFO: namespace: e2e-tests-secrets-pcxpr, resource: bindings, ignored listing per whitelist
Feb  7 03:01:45.677: INFO: namespace e2e-tests-secrets-pcxpr deletion completed in 6.193473334s

• [SLOW TEST:10.370 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:01:45.677: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0207 03:01:46.970044      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb  7 03:01:46.970: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:01:46.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-4mb8d" for this suite.
Feb  7 03:01:53.269: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:01:53.278: INFO: namespace: e2e-tests-gc-4mb8d, resource: bindings, ignored listing per whitelist
Feb  7 03:01:53.384: INFO: namespace e2e-tests-gc-4mb8d deletion completed in 6.411218543s

• [SLOW TEST:7.707 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:01:53.384: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-rl8tg
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-rl8tg
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-rl8tg
Feb  7 03:01:53.445: INFO: Found 0 stateful pods, waiting for 1
Feb  7 03:02:03.563: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Feb  7 03:02:03.565: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 exec --namespace=e2e-tests-statefulset-rl8tg ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  7 03:02:03.793: INFO: stderr: ""
Feb  7 03:02:03.793: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  7 03:02:03.793: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  7 03:02:03.864: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb  7 03:02:13.872: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb  7 03:02:13.872: INFO: Waiting for statefulset status.replicas updated to 0
Feb  7 03:02:13.881: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Feb  7 03:02:13.882: INFO: ss-0  kube-node-0-kubelet.devkubernetes01.mesos  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:01:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:02:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:02:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:01:53 +0000 UTC  }]
Feb  7 03:02:13.882: INFO: 
Feb  7 03:02:13.882: INFO: StatefulSet ss has not reached scale 3, at 1
Feb  7 03:02:14.885: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997599582s
Feb  7 03:02:15.888: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.994459828s
Feb  7 03:02:16.891: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.991158617s
Feb  7 03:02:17.895: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.987743965s
Feb  7 03:02:18.899: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.984145691s
Feb  7 03:02:19.902: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.980389237s
Feb  7 03:02:20.905: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.976749315s
Feb  7 03:02:21.909: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.973681743s
Feb  7 03:02:22.912: INFO: Verifying statefulset ss doesn't scale past 3 for another 970.460977ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-rl8tg
Feb  7 03:02:23.920: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 exec --namespace=e2e-tests-statefulset-rl8tg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  7 03:02:24.073: INFO: stderr: ""
Feb  7 03:02:24.073: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  7 03:02:24.073: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  7 03:02:24.073: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 exec --namespace=e2e-tests-statefulset-rl8tg ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  7 03:02:24.219: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Feb  7 03:02:24.219: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  7 03:02:24.219: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  7 03:02:24.219: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 exec --namespace=e2e-tests-statefulset-rl8tg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  7 03:02:24.442: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Feb  7 03:02:24.442: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  7 03:02:24.442: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  7 03:02:24.446: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Feb  7 03:02:34.463: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb  7 03:02:34.463: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb  7 03:02:34.463: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Feb  7 03:02:34.466: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 exec --namespace=e2e-tests-statefulset-rl8tg ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  7 03:02:34.611: INFO: stderr: ""
Feb  7 03:02:34.611: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  7 03:02:34.611: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  7 03:02:34.612: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 exec --namespace=e2e-tests-statefulset-rl8tg ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  7 03:02:34.756: INFO: stderr: ""
Feb  7 03:02:34.756: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  7 03:02:34.756: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  7 03:02:34.756: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 exec --namespace=e2e-tests-statefulset-rl8tg ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  7 03:02:34.902: INFO: stderr: ""
Feb  7 03:02:34.902: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  7 03:02:34.902: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  7 03:02:34.902: INFO: Waiting for statefulset status.replicas updated to 0
Feb  7 03:02:34.905: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Feb  7 03:02:45.069: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb  7 03:02:45.069: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb  7 03:02:45.069: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb  7 03:02:45.076: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Feb  7 03:02:45.076: INFO: ss-0  kube-node-0-kubelet.devkubernetes01.mesos  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:01:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:02:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:02:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:01:53 +0000 UTC  }]
Feb  7 03:02:45.077: INFO: ss-1  kube-node-1-kubelet.devkubernetes01.mesos  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:02:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:02:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:02:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:02:13 +0000 UTC  }]
Feb  7 03:02:45.077: INFO: ss-2  kube-node-2-kubelet.devkubernetes01.mesos  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:02:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:02:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:02:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:02:13 +0000 UTC  }]
Feb  7 03:02:45.077: INFO: 
Feb  7 03:02:45.077: INFO: StatefulSet ss has not reached scale 0, at 3
Feb  7 03:02:46.080: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Feb  7 03:02:46.080: INFO: ss-0  kube-node-0-kubelet.devkubernetes01.mesos  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:01:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:02:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:02:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:01:53 +0000 UTC  }]
Feb  7 03:02:46.080: INFO: ss-1  kube-node-1-kubelet.devkubernetes01.mesos  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:02:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:02:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:02:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:02:13 +0000 UTC  }]
Feb  7 03:02:46.080: INFO: ss-2  kube-node-2-kubelet.devkubernetes01.mesos  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:02:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:02:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:02:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:02:13 +0000 UTC  }]
Feb  7 03:02:46.080: INFO: 
Feb  7 03:02:46.080: INFO: StatefulSet ss has not reached scale 0, at 3
Feb  7 03:02:47.083: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Feb  7 03:02:47.083: INFO: ss-0  kube-node-0-kubelet.devkubernetes01.mesos  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:01:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:02:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:02:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:01:53 +0000 UTC  }]
Feb  7 03:02:47.083: INFO: ss-1  kube-node-1-kubelet.devkubernetes01.mesos  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:02:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:02:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:02:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:02:13 +0000 UTC  }]
Feb  7 03:02:47.083: INFO: 
Feb  7 03:02:47.083: INFO: StatefulSet ss has not reached scale 0, at 2
Feb  7 03:02:48.489: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Feb  7 03:02:48.489: INFO: ss-1  kube-node-1-kubelet.devkubernetes01.mesos  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:02:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:02:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:02:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:02:13 +0000 UTC  }]
Feb  7 03:02:48.489: INFO: 
Feb  7 03:02:48.489: INFO: StatefulSet ss has not reached scale 0, at 1
Feb  7 03:02:49.493: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Feb  7 03:02:49.493: INFO: ss-1  kube-node-1-kubelet.devkubernetes01.mesos  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:02:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:02:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:02:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:02:13 +0000 UTC  }]
Feb  7 03:02:49.493: INFO: 
Feb  7 03:02:49.493: INFO: StatefulSet ss has not reached scale 0, at 1
Feb  7 03:02:50.496: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Feb  7 03:02:50.496: INFO: ss-1  kube-node-1-kubelet.devkubernetes01.mesos  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:02:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:02:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:02:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:02:13 +0000 UTC  }]
Feb  7 03:02:50.496: INFO: 
Feb  7 03:02:50.496: INFO: StatefulSet ss has not reached scale 0, at 1
Feb  7 03:02:51.499: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Feb  7 03:02:51.499: INFO: ss-1  kube-node-1-kubelet.devkubernetes01.mesos  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:02:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:02:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:02:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:02:13 +0000 UTC  }]
Feb  7 03:02:51.499: INFO: 
Feb  7 03:02:51.499: INFO: StatefulSet ss has not reached scale 0, at 1
Feb  7 03:02:52.502: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Feb  7 03:02:52.502: INFO: ss-1  kube-node-1-kubelet.devkubernetes01.mesos  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:02:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:02:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:02:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:02:13 +0000 UTC  }]
Feb  7 03:02:52.502: INFO: 
Feb  7 03:02:52.502: INFO: StatefulSet ss has not reached scale 0, at 1
Feb  7 03:02:53.505: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.571571642s
Feb  7 03:02:54.508: INFO: Verifying statefulset ss doesn't scale past 0 for another 569.196335ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-rl8tg
Feb  7 03:02:55.515: INFO: Scaling statefulset ss to 0
Feb  7 03:02:55.569: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb  7 03:02:55.571: INFO: Deleting all statefulset in ns e2e-tests-statefulset-rl8tg
Feb  7 03:02:55.573: INFO: Scaling statefulset ss to 0
Feb  7 03:02:55.579: INFO: Waiting for statefulset status.replicas updated to 0
Feb  7 03:02:55.581: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:02:55.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-rl8tg" for this suite.
Feb  7 03:03:01.607: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:03:01.689: INFO: namespace: e2e-tests-statefulset-rl8tg, resource: bindings, ignored listing per whitelist
Feb  7 03:03:01.768: INFO: namespace e2e-tests-statefulset-rl8tg deletion completed in 6.173116461s

• [SLOW TEST:68.384 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:03:01.768: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-z4hj
STEP: Creating a pod to test atomic-volume-subpath
Feb  7 03:03:01.834: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-z4hj" in namespace "e2e-tests-subpath-tnkks" to be "success or failure"
Feb  7 03:03:01.836: INFO: Pod "pod-subpath-test-configmap-z4hj": Phase="Pending", Reason="", readiness=false. Elapsed: 1.90782ms
Feb  7 03:03:03.839: INFO: Pod "pod-subpath-test-configmap-z4hj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004707441s
Feb  7 03:03:05.846: INFO: Pod "pod-subpath-test-configmap-z4hj": Phase="Running", Reason="", readiness=false. Elapsed: 4.011400747s
Feb  7 03:03:08.185: INFO: Pod "pod-subpath-test-configmap-z4hj": Phase="Running", Reason="", readiness=false. Elapsed: 6.350595226s
Feb  7 03:03:10.265: INFO: Pod "pod-subpath-test-configmap-z4hj": Phase="Running", Reason="", readiness=false. Elapsed: 8.430698217s
Feb  7 03:03:12.268: INFO: Pod "pod-subpath-test-configmap-z4hj": Phase="Running", Reason="", readiness=false. Elapsed: 10.433739595s
Feb  7 03:03:14.271: INFO: Pod "pod-subpath-test-configmap-z4hj": Phase="Running", Reason="", readiness=false. Elapsed: 12.436771793s
Feb  7 03:03:16.365: INFO: Pod "pod-subpath-test-configmap-z4hj": Phase="Running", Reason="", readiness=false. Elapsed: 14.5304679s
Feb  7 03:03:18.368: INFO: Pod "pod-subpath-test-configmap-z4hj": Phase="Running", Reason="", readiness=false. Elapsed: 16.533247837s
Feb  7 03:03:20.371: INFO: Pod "pod-subpath-test-configmap-z4hj": Phase="Running", Reason="", readiness=false. Elapsed: 18.536190605s
Feb  7 03:03:22.374: INFO: Pod "pod-subpath-test-configmap-z4hj": Phase="Running", Reason="", readiness=false. Elapsed: 20.539420314s
Feb  7 03:03:24.377: INFO: Pod "pod-subpath-test-configmap-z4hj": Phase="Running", Reason="", readiness=false. Elapsed: 22.542529714s
Feb  7 03:03:26.384: INFO: Pod "pod-subpath-test-configmap-z4hj": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.549961521s
STEP: Saw pod success
Feb  7 03:03:26.385: INFO: Pod "pod-subpath-test-configmap-z4hj" satisfied condition "success or failure"
Feb  7 03:03:26.386: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod pod-subpath-test-configmap-z4hj container test-container-subpath-configmap-z4hj: <nil>
STEP: delete the pod
Feb  7 03:03:26.402: INFO: Waiting for pod pod-subpath-test-configmap-z4hj to disappear
Feb  7 03:03:26.404: INFO: Pod pod-subpath-test-configmap-z4hj no longer exists
STEP: Deleting pod pod-subpath-test-configmap-z4hj
Feb  7 03:03:26.404: INFO: Deleting pod "pod-subpath-test-configmap-z4hj" in namespace "e2e-tests-subpath-tnkks"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:03:26.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-tnkks" for this suite.
Feb  7 03:03:32.430: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:03:32.613: INFO: namespace: e2e-tests-subpath-tnkks, resource: bindings, ignored listing per whitelist
Feb  7 03:03:32.636: INFO: namespace e2e-tests-subpath-tnkks deletion completed in 6.226821914s

• [SLOW TEST:30.868 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:03:32.636: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb  7 03:03:32.696: INFO: Waiting up to 5m0s for pod "pod-f3dcd0e3-2a84-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-emptydir-frxns" to be "success or failure"
Feb  7 03:03:32.698: INFO: Pod "pod-f3dcd0e3-2a84-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.795749ms
Feb  7 03:03:34.700: INFO: Pod "pod-f3dcd0e3-2a84-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004545049s
STEP: Saw pod success
Feb  7 03:03:34.700: INFO: Pod "pod-f3dcd0e3-2a84-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:03:34.702: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod pod-f3dcd0e3-2a84-11e9-87fe-baa4eca941e3 container test-container: <nil>
STEP: delete the pod
Feb  7 03:03:34.718: INFO: Waiting for pod pod-f3dcd0e3-2a84-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:03:34.720: INFO: Pod pod-f3dcd0e3-2a84-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:03:34.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-frxns" for this suite.
Feb  7 03:03:40.733: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:03:40.943: INFO: namespace: e2e-tests-emptydir-frxns, resource: bindings, ignored listing per whitelist
Feb  7 03:03:40.970: INFO: namespace e2e-tests-emptydir-frxns deletion completed in 6.246696114s

• [SLOW TEST:8.334 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:03:40.970: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb  7 03:03:41.025: INFO: Waiting up to 5m0s for pod "pod-f8d3c1fb-2a84-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-emptydir-cmnwm" to be "success or failure"
Feb  7 03:03:41.027: INFO: Pod "pod-f8d3c1fb-2a84-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016939ms
Feb  7 03:03:43.065: INFO: Pod "pod-f8d3c1fb-2a84-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.039673805s
STEP: Saw pod success
Feb  7 03:03:43.065: INFO: Pod "pod-f8d3c1fb-2a84-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:03:43.067: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod pod-f8d3c1fb-2a84-11e9-87fe-baa4eca941e3 container test-container: <nil>
STEP: delete the pod
Feb  7 03:03:43.081: INFO: Waiting for pod pod-f8d3c1fb-2a84-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:03:43.083: INFO: Pod pod-f8d3c1fb-2a84-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:03:43.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-cmnwm" for this suite.
Feb  7 03:03:49.188: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:03:49.198: INFO: namespace: e2e-tests-emptydir-cmnwm, resource: bindings, ignored listing per whitelist
Feb  7 03:03:49.301: INFO: namespace e2e-tests-emptydir-cmnwm deletion completed in 6.180355379s

• [SLOW TEST:8.331 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:03:49.301: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-fdcc06f8-2a84-11e9-87fe-baa4eca941e3
STEP: Creating secret with name s-test-opt-upd-fdcc0736-2a84-11e9-87fe-baa4eca941e3
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-fdcc06f8-2a84-11e9-87fe-baa4eca941e3
STEP: Updating secret s-test-opt-upd-fdcc0736-2a84-11e9-87fe-baa4eca941e3
STEP: Creating secret with name s-test-opt-create-fdcc0752-2a84-11e9-87fe-baa4eca941e3
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:03:55.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jzl84" for this suite.
Feb  7 03:04:17.589: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:04:17.670: INFO: namespace: e2e-tests-projected-jzl84, resource: bindings, ignored listing per whitelist
Feb  7 03:04:17.684: INFO: namespace e2e-tests-projected-jzl84 deletion completed in 22.105068454s

• [SLOW TEST:28.382 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:04:17.684: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb  7 03:04:22.398: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  7 03:04:22.400: INFO: Pod pod-with-poststart-http-hook still exists
Feb  7 03:04:24.400: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  7 03:04:24.403: INFO: Pod pod-with-poststart-http-hook still exists
Feb  7 03:04:26.400: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  7 03:04:26.403: INFO: Pod pod-with-poststart-http-hook still exists
Feb  7 03:04:28.400: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  7 03:04:28.403: INFO: Pod pod-with-poststart-http-hook still exists
Feb  7 03:04:30.400: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  7 03:04:30.468: INFO: Pod pod-with-poststart-http-hook still exists
Feb  7 03:04:32.400: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  7 03:04:32.403: INFO: Pod pod-with-poststart-http-hook still exists
Feb  7 03:04:34.400: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  7 03:04:34.403: INFO: Pod pod-with-poststart-http-hook still exists
Feb  7 03:04:36.400: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  7 03:04:36.403: INFO: Pod pod-with-poststart-http-hook still exists
Feb  7 03:04:38.400: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  7 03:04:38.403: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:04:38.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-xw2fq" for this suite.
Feb  7 03:05:00.482: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:05:00.525: INFO: namespace: e2e-tests-container-lifecycle-hook-xw2fq, resource: bindings, ignored listing per whitelist
Feb  7 03:05:00.586: INFO: namespace e2e-tests-container-lifecycle-hook-xw2fq deletion completed in 22.179690893s

• [SLOW TEST:42.902 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:05:00.586: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-txw4
STEP: Creating a pod to test atomic-volume-subpath
Feb  7 03:05:01.313: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-txw4" in namespace "e2e-tests-subpath-mdmkm" to be "success or failure"
Feb  7 03:05:01.316: INFO: Pod "pod-subpath-test-secret-txw4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.523705ms
Feb  7 03:05:03.322: INFO: Pod "pod-subpath-test-secret-txw4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008961748s
Feb  7 03:05:05.430: INFO: Pod "pod-subpath-test-secret-txw4": Phase="Running", Reason="", readiness=false. Elapsed: 4.117098587s
Feb  7 03:05:07.433: INFO: Pod "pod-subpath-test-secret-txw4": Phase="Running", Reason="", readiness=false. Elapsed: 6.120418136s
Feb  7 03:05:09.436: INFO: Pod "pod-subpath-test-secret-txw4": Phase="Running", Reason="", readiness=false. Elapsed: 8.12348641s
Feb  7 03:05:12.090: INFO: Pod "pod-subpath-test-secret-txw4": Phase="Running", Reason="", readiness=false. Elapsed: 10.776594705s
Feb  7 03:05:14.097: INFO: Pod "pod-subpath-test-secret-txw4": Phase="Running", Reason="", readiness=false. Elapsed: 12.784046752s
Feb  7 03:05:16.100: INFO: Pod "pod-subpath-test-secret-txw4": Phase="Running", Reason="", readiness=false. Elapsed: 14.786949452s
Feb  7 03:05:18.103: INFO: Pod "pod-subpath-test-secret-txw4": Phase="Running", Reason="", readiness=false. Elapsed: 16.789875755s
Feb  7 03:05:20.106: INFO: Pod "pod-subpath-test-secret-txw4": Phase="Running", Reason="", readiness=false. Elapsed: 18.792675592s
Feb  7 03:05:22.108: INFO: Pod "pod-subpath-test-secret-txw4": Phase="Running", Reason="", readiness=false. Elapsed: 20.795336161s
Feb  7 03:05:24.115: INFO: Pod "pod-subpath-test-secret-txw4": Phase="Running", Reason="", readiness=false. Elapsed: 22.802294526s
Feb  7 03:05:26.118: INFO: Pod "pod-subpath-test-secret-txw4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.805224111s
STEP: Saw pod success
Feb  7 03:05:26.118: INFO: Pod "pod-subpath-test-secret-txw4" satisfied condition "success or failure"
Feb  7 03:05:26.121: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod pod-subpath-test-secret-txw4 container test-container-subpath-secret-txw4: <nil>
STEP: delete the pod
Feb  7 03:05:26.137: INFO: Waiting for pod pod-subpath-test-secret-txw4 to disappear
Feb  7 03:05:26.139: INFO: Pod pod-subpath-test-secret-txw4 no longer exists
STEP: Deleting pod pod-subpath-test-secret-txw4
Feb  7 03:05:26.139: INFO: Deleting pod "pod-subpath-test-secret-txw4" in namespace "e2e-tests-subpath-mdmkm"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:05:26.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-mdmkm" for this suite.
Feb  7 03:05:32.180: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:05:32.268: INFO: namespace: e2e-tests-subpath-mdmkm, resource: bindings, ignored listing per whitelist
Feb  7 03:05:32.276: INFO: namespace e2e-tests-subpath-mdmkm deletion completed in 6.107363723s

• [SLOW TEST:31.690 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:05:32.276: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  7 03:05:32.336: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3b2c3c6b-2a85-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-downward-api-9tpph" to be "success or failure"
Feb  7 03:05:32.338: INFO: Pod "downwardapi-volume-3b2c3c6b-2a85-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.301986ms
Feb  7 03:05:34.670: INFO: Pod "downwardapi-volume-3b2c3c6b-2a85-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.334052078s
STEP: Saw pod success
Feb  7 03:05:34.670: INFO: Pod "downwardapi-volume-3b2c3c6b-2a85-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:05:34.672: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod downwardapi-volume-3b2c3c6b-2a85-11e9-87fe-baa4eca941e3 container client-container: <nil>
STEP: delete the pod
Feb  7 03:05:34.723: INFO: Waiting for pod downwardapi-volume-3b2c3c6b-2a85-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:05:34.725: INFO: Pod downwardapi-volume-3b2c3c6b-2a85-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:05:34.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-9tpph" for this suite.
Feb  7 03:05:40.780: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:05:41.285: INFO: namespace: e2e-tests-downward-api-9tpph, resource: bindings, ignored listing per whitelist
Feb  7 03:05:41.290: INFO: namespace e2e-tests-downward-api-9tpph deletion completed in 6.562087874s

• [SLOW TEST:9.014 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:05:41.290: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-s8ts
STEP: Creating a pod to test atomic-volume-subpath
Feb  7 03:05:41.359: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-s8ts" in namespace "e2e-tests-subpath-h987q" to be "success or failure"
Feb  7 03:05:41.363: INFO: Pod "pod-subpath-test-downwardapi-s8ts": Phase="Pending", Reason="", readiness=false. Elapsed: 4.758195ms
Feb  7 03:05:43.701: INFO: Pod "pod-subpath-test-downwardapi-s8ts": Phase="Running", Reason="", readiness=false. Elapsed: 2.34279451s
Feb  7 03:05:45.769: INFO: Pod "pod-subpath-test-downwardapi-s8ts": Phase="Running", Reason="", readiness=false. Elapsed: 4.410215494s
Feb  7 03:05:47.772: INFO: Pod "pod-subpath-test-downwardapi-s8ts": Phase="Running", Reason="", readiness=false. Elapsed: 6.413465392s
Feb  7 03:05:50.182: INFO: Pod "pod-subpath-test-downwardapi-s8ts": Phase="Running", Reason="", readiness=false. Elapsed: 8.823245914s
Feb  7 03:05:52.185: INFO: Pod "pod-subpath-test-downwardapi-s8ts": Phase="Running", Reason="", readiness=false. Elapsed: 10.826336901s
Feb  7 03:05:54.188: INFO: Pod "pod-subpath-test-downwardapi-s8ts": Phase="Running", Reason="", readiness=false. Elapsed: 12.829295578s
Feb  7 03:05:56.195: INFO: Pod "pod-subpath-test-downwardapi-s8ts": Phase="Running", Reason="", readiness=false. Elapsed: 14.836710137s
Feb  7 03:05:58.198: INFO: Pod "pod-subpath-test-downwardapi-s8ts": Phase="Running", Reason="", readiness=false. Elapsed: 16.839327093s
Feb  7 03:06:00.269: INFO: Pod "pod-subpath-test-downwardapi-s8ts": Phase="Running", Reason="", readiness=false. Elapsed: 18.910083949s
Feb  7 03:06:02.272: INFO: Pod "pod-subpath-test-downwardapi-s8ts": Phase="Running", Reason="", readiness=false. Elapsed: 20.912956278s
Feb  7 03:06:04.283: INFO: Pod "pod-subpath-test-downwardapi-s8ts": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.924215073s
STEP: Saw pod success
Feb  7 03:06:04.283: INFO: Pod "pod-subpath-test-downwardapi-s8ts" satisfied condition "success or failure"
Feb  7 03:06:04.285: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod pod-subpath-test-downwardapi-s8ts container test-container-subpath-downwardapi-s8ts: <nil>
STEP: delete the pod
Feb  7 03:06:04.385: INFO: Waiting for pod pod-subpath-test-downwardapi-s8ts to disappear
Feb  7 03:06:04.388: INFO: Pod pod-subpath-test-downwardapi-s8ts no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-s8ts
Feb  7 03:06:04.388: INFO: Deleting pod "pod-subpath-test-downwardapi-s8ts" in namespace "e2e-tests-subpath-h987q"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:06:04.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-h987q" for this suite.
Feb  7 03:06:10.482: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:06:10.657: INFO: namespace: e2e-tests-subpath-h987q, resource: bindings, ignored listing per whitelist
Feb  7 03:06:10.661: INFO: namespace e2e-tests-subpath-h987q deletion completed in 6.265238486s

• [SLOW TEST:29.371 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:06:10.661: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-52eec7bd-2a85-11e9-87fe-baa4eca941e3
STEP: Creating a pod to test consume secrets
Feb  7 03:06:12.488: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-531b3288-2a85-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-projected-trxrl" to be "success or failure"
Feb  7 03:06:12.490: INFO: Pod "pod-projected-secrets-531b3288-2a85-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.964094ms
Feb  7 03:06:14.493: INFO: Pod "pod-projected-secrets-531b3288-2a85-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004909769s
STEP: Saw pod success
Feb  7 03:06:14.493: INFO: Pod "pod-projected-secrets-531b3288-2a85-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:06:14.495: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod pod-projected-secrets-531b3288-2a85-11e9-87fe-baa4eca941e3 container secret-volume-test: <nil>
STEP: delete the pod
Feb  7 03:06:14.510: INFO: Waiting for pod pod-projected-secrets-531b3288-2a85-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:06:14.512: INFO: Pod pod-projected-secrets-531b3288-2a85-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:06:14.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-trxrl" for this suite.
Feb  7 03:06:22.526: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:06:22.894: INFO: namespace: e2e-tests-projected-trxrl, resource: bindings, ignored listing per whitelist
Feb  7 03:06:22.920: INFO: namespace e2e-tests-projected-trxrl deletion completed in 8.404804555s

• [SLOW TEST:12.259 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:06:22.920: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-595baed4-2a85-11e9-87fe-baa4eca941e3
STEP: Creating a pod to test consume secrets
Feb  7 03:06:22.980: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-595c6a3d-2a85-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-projected-vzd9c" to be "success or failure"
Feb  7 03:06:22.982: INFO: Pod "pod-projected-secrets-595c6a3d-2a85-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.835729ms
Feb  7 03:06:24.985: INFO: Pod "pod-projected-secrets-595c6a3d-2a85-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004824702s
STEP: Saw pod success
Feb  7 03:06:24.985: INFO: Pod "pod-projected-secrets-595c6a3d-2a85-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:06:24.987: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod pod-projected-secrets-595c6a3d-2a85-11e9-87fe-baa4eca941e3 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb  7 03:06:25.005: INFO: Waiting for pod pod-projected-secrets-595c6a3d-2a85-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:06:25.007: INFO: Pod pod-projected-secrets-595c6a3d-2a85-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:06:25.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vzd9c" for this suite.
Feb  7 03:06:31.020: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:06:31.111: INFO: namespace: e2e-tests-projected-vzd9c, resource: bindings, ignored listing per whitelist
Feb  7 03:06:31.116: INFO: namespace e2e-tests-projected-vzd9c deletion completed in 6.106138679s

• [SLOW TEST:8.195 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:06:31.116: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb  7 03:06:31.171: INFO: Waiting up to 5m0s for pod "pod-5e3dcb9b-2a85-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-emptydir-954ld" to be "success or failure"
Feb  7 03:06:31.173: INFO: Pod "pod-5e3dcb9b-2a85-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.089766ms
Feb  7 03:06:33.176: INFO: Pod "pod-5e3dcb9b-2a85-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005190124s
STEP: Saw pod success
Feb  7 03:06:33.176: INFO: Pod "pod-5e3dcb9b-2a85-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:06:33.178: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod pod-5e3dcb9b-2a85-11e9-87fe-baa4eca941e3 container test-container: <nil>
STEP: delete the pod
Feb  7 03:06:33.191: INFO: Waiting for pod pod-5e3dcb9b-2a85-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:06:33.193: INFO: Pod pod-5e3dcb9b-2a85-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:06:33.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-954ld" for this suite.
Feb  7 03:06:39.207: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:06:39.223: INFO: namespace: e2e-tests-emptydir-954ld, resource: bindings, ignored listing per whitelist
Feb  7 03:06:39.304: INFO: namespace e2e-tests-emptydir-954ld deletion completed in 6.107721132s

• [SLOW TEST:8.189 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:06:39.305: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-63200af4-2a85-11e9-87fe-baa4eca941e3
STEP: Creating a pod to test consume secrets
Feb  7 03:06:39.368: INFO: Waiting up to 5m0s for pod "pod-secrets-6320cab5-2a85-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-secrets-2twdw" to be "success or failure"
Feb  7 03:06:39.370: INFO: Pod "pod-secrets-6320cab5-2a85-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.091766ms
Feb  7 03:06:41.372: INFO: Pod "pod-secrets-6320cab5-2a85-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0049049s
STEP: Saw pod success
Feb  7 03:06:41.372: INFO: Pod "pod-secrets-6320cab5-2a85-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:06:41.375: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod pod-secrets-6320cab5-2a85-11e9-87fe-baa4eca941e3 container secret-volume-test: <nil>
STEP: delete the pod
Feb  7 03:06:41.482: INFO: Waiting for pod pod-secrets-6320cab5-2a85-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:06:41.483: INFO: Pod pod-secrets-6320cab5-2a85-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:06:41.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-2twdw" for this suite.
Feb  7 03:06:47.579: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:06:47.646: INFO: namespace: e2e-tests-secrets-2twdw, resource: bindings, ignored listing per whitelist
Feb  7 03:06:47.673: INFO: namespace e2e-tests-secrets-2twdw deletion completed in 6.186835231s

• [SLOW TEST:8.369 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:06:47.674: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Feb  7 03:06:51.770: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-spbc7 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  7 03:06:51.770: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
Feb  7 03:06:51.856: INFO: Exec stderr: ""
Feb  7 03:06:51.856: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-spbc7 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  7 03:06:51.856: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
Feb  7 03:06:51.936: INFO: Exec stderr: ""
Feb  7 03:06:51.936: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-spbc7 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  7 03:06:51.936: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
Feb  7 03:06:52.019: INFO: Exec stderr: ""
Feb  7 03:06:52.019: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-spbc7 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  7 03:06:52.019: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
Feb  7 03:06:52.099: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Feb  7 03:06:52.099: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-spbc7 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  7 03:06:52.099: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
Feb  7 03:06:52.191: INFO: Exec stderr: ""
Feb  7 03:06:52.191: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-spbc7 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  7 03:06:52.191: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
Feb  7 03:06:52.276: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Feb  7 03:06:52.276: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-spbc7 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  7 03:06:52.276: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
Feb  7 03:06:52.357: INFO: Exec stderr: ""
Feb  7 03:06:52.357: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-spbc7 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  7 03:06:52.357: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
Feb  7 03:06:52.439: INFO: Exec stderr: ""
Feb  7 03:06:52.439: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-spbc7 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  7 03:06:52.439: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
Feb  7 03:06:52.527: INFO: Exec stderr: ""
Feb  7 03:06:52.527: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-spbc7 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  7 03:06:52.527: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
Feb  7 03:06:52.611: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:06:52.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-spbc7" for this suite.
Feb  7 03:07:34.630: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:07:34.689: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-spbc7, resource: bindings, ignored listing per whitelist
Feb  7 03:07:34.733: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-spbc7 deletion completed in 42.117972789s

• [SLOW TEST:47.059 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:07:34.733: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0207 03:08:14.994006      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb  7 03:08:14.994: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:08:14.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-fqnj4" for this suite.
Feb  7 03:08:23.007: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:08:23.088: INFO: namespace: e2e-tests-gc-fqnj4, resource: bindings, ignored listing per whitelist
Feb  7 03:08:23.171: INFO: namespace e2e-tests-gc-fqnj4 deletion completed in 8.174228105s

• [SLOW TEST:48.438 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:08:23.171: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-fqjjh
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-fqjjh
STEP: Deleting pre-stop pod
Feb  7 03:08:36.284: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:08:36.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-fqjjh" for this suite.
Feb  7 03:09:16.390: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:09:16.506: INFO: namespace: e2e-tests-prestop-fqjjh, resource: bindings, ignored listing per whitelist
Feb  7 03:09:16.596: INFO: namespace e2e-tests-prestop-fqjjh deletion completed in 40.216870408s

• [SLOW TEST:53.425 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:09:16.597: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-c0e0b1d2-2a85-11e9-87fe-baa4eca941e3
STEP: Creating a pod to test consume secrets
Feb  7 03:09:16.673: INFO: Waiting up to 5m0s for pod "pod-secrets-c0e17c14-2a85-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-secrets-dsp6x" to be "success or failure"
Feb  7 03:09:16.675: INFO: Pod "pod-secrets-c0e17c14-2a85-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.807162ms
Feb  7 03:09:18.678: INFO: Pod "pod-secrets-c0e17c14-2a85-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004719656s
STEP: Saw pod success
Feb  7 03:09:18.678: INFO: Pod "pod-secrets-c0e17c14-2a85-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:09:18.680: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod pod-secrets-c0e17c14-2a85-11e9-87fe-baa4eca941e3 container secret-volume-test: <nil>
STEP: delete the pod
Feb  7 03:09:18.694: INFO: Waiting for pod pod-secrets-c0e17c14-2a85-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:09:18.696: INFO: Pod pod-secrets-c0e17c14-2a85-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:09:18.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-dsp6x" for this suite.
Feb  7 03:09:24.709: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:09:24.802: INFO: namespace: e2e-tests-secrets-dsp6x, resource: bindings, ignored listing per whitelist
Feb  7 03:09:24.817: INFO: namespace e2e-tests-secrets-dsp6x deletion completed in 6.117748976s

• [SLOW TEST:8.220 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:09:24.817: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  7 03:09:24.874: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c5c6c446-2a85-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-projected-nrwq2" to be "success or failure"
Feb  7 03:09:24.876: INFO: Pod "downwardapi-volume-c5c6c446-2a85-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.921136ms
Feb  7 03:09:26.879: INFO: Pod "downwardapi-volume-c5c6c446-2a85-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005063765s
STEP: Saw pod success
Feb  7 03:09:26.879: INFO: Pod "downwardapi-volume-c5c6c446-2a85-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:09:26.881: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod downwardapi-volume-c5c6c446-2a85-11e9-87fe-baa4eca941e3 container client-container: <nil>
STEP: delete the pod
Feb  7 03:09:26.896: INFO: Waiting for pod downwardapi-volume-c5c6c446-2a85-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:09:26.898: INFO: Pod downwardapi-volume-c5c6c446-2a85-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:09:26.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-nrwq2" for this suite.
Feb  7 03:09:33.132: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:09:33.252: INFO: namespace: e2e-tests-projected-nrwq2, resource: bindings, ignored listing per whitelist
Feb  7 03:09:33.305: INFO: namespace e2e-tests-projected-nrwq2 deletion completed in 6.403686245s

• [SLOW TEST:8.488 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:09:33.305: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb  7 03:09:35.891: INFO: Successfully updated pod "annotationupdatecad62064-2a85-11e9-87fe-baa4eca941e3"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:09:39.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-vtlts" for this suite.
Feb  7 03:10:03.925: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:10:04.026: INFO: namespace: e2e-tests-downward-api-vtlts, resource: bindings, ignored listing per whitelist
Feb  7 03:10:04.031: INFO: namespace e2e-tests-downward-api-vtlts deletion completed in 24.116109736s

• [SLOW TEST:30.726 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:10:04.031: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Feb  7 03:10:04.081: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 create -f - --namespace=e2e-tests-kubectl-hvmvf'
Feb  7 03:10:04.457: INFO: stderr: ""
Feb  7 03:10:04.457: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb  7 03:10:04.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-hvmvf'
Feb  7 03:10:04.519: INFO: stderr: ""
Feb  7 03:10:04.519: INFO: stdout: "update-demo-nautilus-62wzv update-demo-nautilus-fdnd2 "
Feb  7 03:10:04.519: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 get pods update-demo-nautilus-62wzv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hvmvf'
Feb  7 03:10:04.742: INFO: stderr: ""
Feb  7 03:10:04.742: INFO: stdout: ""
Feb  7 03:10:04.742: INFO: update-demo-nautilus-62wzv is created but not running
Feb  7 03:10:09.742: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-hvmvf'
Feb  7 03:10:09.807: INFO: stderr: ""
Feb  7 03:10:09.807: INFO: stdout: "update-demo-nautilus-62wzv update-demo-nautilus-fdnd2 "
Feb  7 03:10:09.807: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 get pods update-demo-nautilus-62wzv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hvmvf'
Feb  7 03:10:09.866: INFO: stderr: ""
Feb  7 03:10:09.866: INFO: stdout: "true"
Feb  7 03:10:09.866: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 get pods update-demo-nautilus-62wzv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hvmvf'
Feb  7 03:10:09.925: INFO: stderr: ""
Feb  7 03:10:09.925: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  7 03:10:09.925: INFO: validating pod update-demo-nautilus-62wzv
Feb  7 03:10:09.929: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  7 03:10:09.929: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  7 03:10:09.929: INFO: update-demo-nautilus-62wzv is verified up and running
Feb  7 03:10:09.929: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 get pods update-demo-nautilus-fdnd2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hvmvf'
Feb  7 03:10:09.988: INFO: stderr: ""
Feb  7 03:10:09.988: INFO: stdout: "true"
Feb  7 03:10:09.989: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 get pods update-demo-nautilus-fdnd2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hvmvf'
Feb  7 03:10:10.053: INFO: stderr: ""
Feb  7 03:10:10.053: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  7 03:10:10.053: INFO: validating pod update-demo-nautilus-fdnd2
Feb  7 03:10:10.057: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  7 03:10:10.057: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  7 03:10:10.057: INFO: update-demo-nautilus-fdnd2 is verified up and running
STEP: scaling down the replication controller
Feb  7 03:10:10.058: INFO: scanned /root for discovery docs: <nil>
Feb  7 03:10:10.058: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-hvmvf'
Feb  7 03:10:11.363: INFO: stderr: ""
Feb  7 03:10:11.363: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb  7 03:10:11.363: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-hvmvf'
Feb  7 03:10:11.434: INFO: stderr: ""
Feb  7 03:10:11.434: INFO: stdout: "update-demo-nautilus-62wzv update-demo-nautilus-fdnd2 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb  7 03:10:16.434: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-hvmvf'
Feb  7 03:10:16.631: INFO: stderr: ""
Feb  7 03:10:16.631: INFO: stdout: "update-demo-nautilus-62wzv "
Feb  7 03:10:16.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 get pods update-demo-nautilus-62wzv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hvmvf'
Feb  7 03:10:16.694: INFO: stderr: ""
Feb  7 03:10:16.694: INFO: stdout: "true"
Feb  7 03:10:16.694: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 get pods update-demo-nautilus-62wzv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hvmvf'
Feb  7 03:10:16.755: INFO: stderr: ""
Feb  7 03:10:16.755: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  7 03:10:16.755: INFO: validating pod update-demo-nautilus-62wzv
Feb  7 03:10:16.762: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  7 03:10:16.763: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  7 03:10:16.763: INFO: update-demo-nautilus-62wzv is verified up and running
STEP: scaling up the replication controller
Feb  7 03:10:16.764: INFO: scanned /root for discovery docs: <nil>
Feb  7 03:10:16.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-hvmvf'
Feb  7 03:10:17.849: INFO: stderr: ""
Feb  7 03:10:17.849: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb  7 03:10:17.849: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-hvmvf'
Feb  7 03:10:17.916: INFO: stderr: ""
Feb  7 03:10:17.916: INFO: stdout: "update-demo-nautilus-62wzv update-demo-nautilus-xdc7d "
Feb  7 03:10:17.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 get pods update-demo-nautilus-62wzv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hvmvf'
Feb  7 03:10:17.977: INFO: stderr: ""
Feb  7 03:10:17.977: INFO: stdout: "true"
Feb  7 03:10:17.977: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 get pods update-demo-nautilus-62wzv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hvmvf'
Feb  7 03:10:18.035: INFO: stderr: ""
Feb  7 03:10:18.035: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  7 03:10:18.035: INFO: validating pod update-demo-nautilus-62wzv
Feb  7 03:10:18.039: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  7 03:10:18.039: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  7 03:10:18.039: INFO: update-demo-nautilus-62wzv is verified up and running
Feb  7 03:10:18.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 get pods update-demo-nautilus-xdc7d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hvmvf'
Feb  7 03:10:18.098: INFO: stderr: ""
Feb  7 03:10:18.098: INFO: stdout: "true"
Feb  7 03:10:18.098: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 get pods update-demo-nautilus-xdc7d -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hvmvf'
Feb  7 03:10:18.156: INFO: stderr: ""
Feb  7 03:10:18.156: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  7 03:10:18.156: INFO: validating pod update-demo-nautilus-xdc7d
Feb  7 03:10:18.160: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  7 03:10:18.160: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  7 03:10:18.160: INFO: update-demo-nautilus-xdc7d is verified up and running
STEP: using delete to clean up resources
Feb  7 03:10:18.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-hvmvf'
Feb  7 03:10:18.225: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  7 03:10:18.225: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb  7 03:10:18.225: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-hvmvf'
Feb  7 03:10:18.301: INFO: stderr: "No resources found.\n"
Feb  7 03:10:18.301: INFO: stdout: ""
Feb  7 03:10:18.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 get pods -l name=update-demo --namespace=e2e-tests-kubectl-hvmvf -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb  7 03:10:18.469: INFO: stderr: ""
Feb  7 03:10:18.469: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:10:18.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hvmvf" for this suite.
Feb  7 03:10:24.487: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:10:24.509: INFO: namespace: e2e-tests-kubectl-hvmvf, resource: bindings, ignored listing per whitelist
Feb  7 03:10:24.590: INFO: namespace e2e-tests-kubectl-hvmvf deletion completed in 6.112816367s

• [SLOW TEST:20.559 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:10:24.590: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  7 03:10:24.649: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e967bf64-2a85-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-downward-api-vt7ls" to be "success or failure"
Feb  7 03:10:24.651: INFO: Pod "downwardapi-volume-e967bf64-2a85-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.90318ms
Feb  7 03:10:26.654: INFO: Pod "downwardapi-volume-e967bf64-2a85-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0050988s
STEP: Saw pod success
Feb  7 03:10:26.654: INFO: Pod "downwardapi-volume-e967bf64-2a85-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:10:26.675: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod downwardapi-volume-e967bf64-2a85-11e9-87fe-baa4eca941e3 container client-container: <nil>
STEP: delete the pod
Feb  7 03:10:26.732: INFO: Waiting for pod downwardapi-volume-e967bf64-2a85-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:10:26.735: INFO: Pod downwardapi-volume-e967bf64-2a85-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:10:26.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-vt7ls" for this suite.
Feb  7 03:10:33.292: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:10:33.390: INFO: namespace: e2e-tests-downward-api-vt7ls, resource: bindings, ignored listing per whitelist
Feb  7 03:10:33.390: INFO: namespace e2e-tests-downward-api-vt7ls deletion completed in 6.65105226s

• [SLOW TEST:8.800 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:10:33.390: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb  7 03:10:36.381: INFO: Successfully updated pod "pod-update-activedeadlineseconds-eed4337b-2a85-11e9-87fe-baa4eca941e3"
Feb  7 03:10:36.381: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-eed4337b-2a85-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-pods-6gdpc" to be "terminated due to deadline exceeded"
Feb  7 03:10:36.383: INFO: Pod "pod-update-activedeadlineseconds-eed4337b-2a85-11e9-87fe-baa4eca941e3": Phase="Running", Reason="", readiness=true. Elapsed: 1.93957ms
Feb  7 03:10:38.390: INFO: Pod "pod-update-activedeadlineseconds-eed4337b-2a85-11e9-87fe-baa4eca941e3": Phase="Running", Reason="", readiness=true. Elapsed: 2.008565599s
Feb  7 03:10:40.393: INFO: Pod "pod-update-activedeadlineseconds-eed4337b-2a85-11e9-87fe-baa4eca941e3": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.011969368s
Feb  7 03:10:40.393: INFO: Pod "pod-update-activedeadlineseconds-eed4337b-2a85-11e9-87fe-baa4eca941e3" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:10:40.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-6gdpc" for this suite.
Feb  7 03:10:47.247: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:10:47.269: INFO: namespace: e2e-tests-pods-6gdpc, resource: bindings, ignored listing per whitelist
Feb  7 03:10:47.609: INFO: namespace e2e-tests-pods-6gdpc deletion completed in 7.213297033s

• [SLOW TEST:14.220 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:10:47.610: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-f72034d5-2a85-11e9-87fe-baa4eca941e3
STEP: Creating a pod to test consume secrets
Feb  7 03:10:47.671: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f720f76f-2a85-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-projected-p4lrz" to be "success or failure"
Feb  7 03:10:47.673: INFO: Pod "pod-projected-secrets-f720f76f-2a85-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.888588ms
Feb  7 03:10:49.778: INFO: Pod "pod-projected-secrets-f720f76f-2a85-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.107426561s
STEP: Saw pod success
Feb  7 03:10:49.778: INFO: Pod "pod-projected-secrets-f720f76f-2a85-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:10:49.781: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod pod-projected-secrets-f720f76f-2a85-11e9-87fe-baa4eca941e3 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb  7 03:10:49.796: INFO: Waiting for pod pod-projected-secrets-f720f76f-2a85-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:10:49.800: INFO: Pod pod-projected-secrets-f720f76f-2a85-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:10:49.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-p4lrz" for this suite.
Feb  7 03:10:55.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:10:55.970: INFO: namespace: e2e-tests-projected-p4lrz, resource: bindings, ignored listing per whitelist
Feb  7 03:10:55.982: INFO: namespace e2e-tests-projected-p4lrz deletion completed in 6.177801757s

• [SLOW TEST:8.372 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:10:55.982: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-fc1d27f8-2a85-11e9-87fe-baa4eca941e3
STEP: Creating a pod to test consume secrets
Feb  7 03:10:56.039: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-fc1de078-2a85-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-projected-x8crd" to be "success or failure"
Feb  7 03:10:56.041: INFO: Pod "pod-projected-secrets-fc1de078-2a85-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.10142ms
Feb  7 03:10:58.044: INFO: Pod "pod-projected-secrets-fc1de078-2a85-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00525291s
STEP: Saw pod success
Feb  7 03:10:58.044: INFO: Pod "pod-projected-secrets-fc1de078-2a85-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:10:58.046: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod pod-projected-secrets-fc1de078-2a85-11e9-87fe-baa4eca941e3 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb  7 03:10:58.061: INFO: Waiting for pod pod-projected-secrets-fc1de078-2a85-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:10:58.063: INFO: Pod pod-projected-secrets-fc1de078-2a85-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:10:58.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-x8crd" for this suite.
Feb  7 03:11:06.080: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:11:06.207: INFO: namespace: e2e-tests-projected-x8crd, resource: bindings, ignored listing per whitelist
Feb  7 03:11:06.240: INFO: namespace e2e-tests-projected-x8crd deletion completed in 8.173369558s

• [SLOW TEST:10.258 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:11:06.240: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb  7 03:11:10.878: INFO: Successfully updated pod "labelsupdate023b722d-2a86-11e9-87fe-baa4eca941e3"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:11:12.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-xkt95" for this suite.
Feb  7 03:11:35.330: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:11:35.336: INFO: namespace: e2e-tests-downward-api-xkt95, resource: bindings, ignored listing per whitelist
Feb  7 03:11:35.482: INFO: namespace e2e-tests-downward-api-xkt95 deletion completed in 22.587630514s

• [SLOW TEST:29.242 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:11:35.482: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:11:39.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-ssv4g" for this suite.
Feb  7 03:11:45.671: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:11:45.744: INFO: namespace: e2e-tests-emptydir-wrapper-ssv4g, resource: bindings, ignored listing per whitelist
Feb  7 03:11:45.902: INFO: namespace e2e-tests-emptydir-wrapper-ssv4g deletion completed in 6.242519784s

• [SLOW TEST:10.420 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:11:45.902: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  7 03:11:46.580: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1a1423c0-2a86-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-downward-api-2j6t8" to be "success or failure"
Feb  7 03:11:46.583: INFO: Pod "downwardapi-volume-1a1423c0-2a86-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.613668ms
Feb  7 03:11:48.586: INFO: Pod "downwardapi-volume-1a1423c0-2a86-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005761098s
STEP: Saw pod success
Feb  7 03:11:48.586: INFO: Pod "downwardapi-volume-1a1423c0-2a86-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:11:48.588: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod downwardapi-volume-1a1423c0-2a86-11e9-87fe-baa4eca941e3 container client-container: <nil>
STEP: delete the pod
Feb  7 03:11:48.602: INFO: Waiting for pod downwardapi-volume-1a1423c0-2a86-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:11:48.604: INFO: Pod downwardapi-volume-1a1423c0-2a86-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:11:48.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-2j6t8" for this suite.
Feb  7 03:11:54.682: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:11:54.820: INFO: namespace: e2e-tests-downward-api-2j6t8, resource: bindings, ignored listing per whitelist
Feb  7 03:11:54.864: INFO: namespace e2e-tests-downward-api-2j6t8 deletion completed in 6.25629778s

• [SLOW TEST:8.961 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:11:54.864: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Feb  7 03:11:54.921: INFO: Pod name pod-release: Found 0 pods out of 1
Feb  7 03:11:59.924: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:12:00.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-hkv84" for this suite.
Feb  7 03:12:06.950: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:12:06.957: INFO: namespace: e2e-tests-replication-controller-hkv84, resource: bindings, ignored listing per whitelist
Feb  7 03:12:07.055: INFO: namespace e2e-tests-replication-controller-hkv84 deletion completed in 6.114723069s

• [SLOW TEST:12.191 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:12:07.055: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:12:09.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-rrxml" for this suite.
Feb  7 03:12:49.147: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:12:49.202: INFO: namespace: e2e-tests-kubelet-test-rrxml, resource: bindings, ignored listing per whitelist
Feb  7 03:12:49.305: INFO: namespace e2e-tests-kubelet-test-rrxml deletion completed in 40.168828712s

• [SLOW TEST:42.250 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a read only busybox container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:186
    should not write to root filesystem [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:12:49.305: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-3fa9d56c-2a86-11e9-87fe-baa4eca941e3
STEP: Creating a pod to test consume configMaps
Feb  7 03:12:49.369: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-3faa93bc-2a86-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-projected-mfcvw" to be "success or failure"
Feb  7 03:12:49.371: INFO: Pod "pod-projected-configmaps-3faa93bc-2a86-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.08468ms
Feb  7 03:12:51.373: INFO: Pod "pod-projected-configmaps-3faa93bc-2a86-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004615959s
STEP: Saw pod success
Feb  7 03:12:51.373: INFO: Pod "pod-projected-configmaps-3faa93bc-2a86-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:12:51.375: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod pod-projected-configmaps-3faa93bc-2a86-11e9-87fe-baa4eca941e3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  7 03:12:51.390: INFO: Waiting for pod pod-projected-configmaps-3faa93bc-2a86-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:12:51.393: INFO: Pod pod-projected-configmaps-3faa93bc-2a86-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:12:51.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mfcvw" for this suite.
Feb  7 03:12:57.408: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:12:57.533: INFO: namespace: e2e-tests-projected-mfcvw, resource: bindings, ignored listing per whitelist
Feb  7 03:12:57.571: INFO: namespace e2e-tests-projected-mfcvw deletion completed in 6.173998928s

• [SLOW TEST:8.266 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:12:57.571: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Feb  7 03:12:57.662: INFO: Waiting up to 5m0s for pod "client-containers-449bc3d3-2a86-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-containers-c8q7f" to be "success or failure"
Feb  7 03:12:57.664: INFO: Pod "client-containers-449bc3d3-2a86-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.911007ms
Feb  7 03:12:59.869: INFO: Pod "client-containers-449bc3d3-2a86-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.206929336s
STEP: Saw pod success
Feb  7 03:12:59.869: INFO: Pod "client-containers-449bc3d3-2a86-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:12:59.871: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod client-containers-449bc3d3-2a86-11e9-87fe-baa4eca941e3 container test-container: <nil>
STEP: delete the pod
Feb  7 03:12:59.885: INFO: Waiting for pod client-containers-449bc3d3-2a86-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:12:59.887: INFO: Pod client-containers-449bc3d3-2a86-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:12:59.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-c8q7f" for this suite.
Feb  7 03:13:05.901: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:13:06.413: INFO: namespace: e2e-tests-containers-c8q7f, resource: bindings, ignored listing per whitelist
Feb  7 03:13:06.441: INFO: namespace e2e-tests-containers-c8q7f deletion completed in 6.550766352s

• [SLOW TEST:8.870 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:13:06.441: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  7 03:13:06.492: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 version --client'
Feb  7 03:13:06.537: INFO: stderr: ""
Feb  7 03:13:06.537: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Feb  7 03:13:06.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 create -f - --namespace=e2e-tests-kubectl-mf97m'
Feb  7 03:13:06.681: INFO: stderr: ""
Feb  7 03:13:06.681: INFO: stdout: "replicationcontroller/redis-master created\n"
Feb  7 03:13:06.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 create -f - --namespace=e2e-tests-kubectl-mf97m'
Feb  7 03:13:06.862: INFO: stderr: ""
Feb  7 03:13:06.862: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb  7 03:13:07.866: INFO: Selector matched 1 pods for map[app:redis]
Feb  7 03:13:07.866: INFO: Found 0 / 1
Feb  7 03:13:08.866: INFO: Selector matched 1 pods for map[app:redis]
Feb  7 03:13:08.866: INFO: Found 1 / 1
Feb  7 03:13:08.866: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb  7 03:13:08.868: INFO: Selector matched 1 pods for map[app:redis]
Feb  7 03:13:08.868: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb  7 03:13:08.868: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 describe pod redis-master-rgh8p --namespace=e2e-tests-kubectl-mf97m'
Feb  7 03:13:08.980: INFO: stderr: ""
Feb  7 03:13:08.980: INFO: stdout: "Name:               redis-master-rgh8p\nNamespace:          e2e-tests-kubectl-mf97m\nPriority:           0\nPriorityClassName:  <none>\nNode:               kube-node-0-kubelet.devkubernetes01.mesos/9.0.1.4\nStart Time:         Thu, 07 Feb 2019 03:13:06 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        cni.projectcalico.org/podIP: 192.168.5.104/32\nStatus:             Running\nIP:                 192.168.5.104\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://81018a7165f87260f6f395f3280b0d3d83cfcfc1d404b1874bc2c7d2d50f7438\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Thu, 07 Feb 2019 03:13:07 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-fgz5j (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-fgz5j:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-fgz5j\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                                Message\n  ----    ------     ----  ----                                                -------\n  Normal  Scheduled  2s    default-scheduler                                   Successfully assigned e2e-tests-kubectl-mf97m/redis-master-rgh8p to kube-node-0-kubelet.devkubernetes01.mesos\n  Normal  Pulled     1s    kubelet, kube-node-0-kubelet.devkubernetes01.mesos  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, kube-node-0-kubelet.devkubernetes01.mesos  Created container\n  Normal  Started    1s    kubelet, kube-node-0-kubelet.devkubernetes01.mesos  Started container\n"
Feb  7 03:13:08.980: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 describe rc redis-master --namespace=e2e-tests-kubectl-mf97m'
Feb  7 03:13:09.059: INFO: stderr: ""
Feb  7 03:13:09.059: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-mf97m\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-rgh8p\n"
Feb  7 03:13:09.059: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 describe service redis-master --namespace=e2e-tests-kubectl-mf97m'
Feb  7 03:13:09.130: INFO: stderr: ""
Feb  7 03:13:09.130: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-mf97m\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.100.108.40\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         192.168.5.104:6379\nSession Affinity:  None\nEvents:            <none>\n"
Feb  7 03:13:09.134: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 describe node kube-control-plane-0-instance.devkubernetes01.mesos'
Feb  7 03:13:09.217: INFO: stderr: ""
Feb  7 03:13:09.217: INFO: stdout: "Name:               kube-control-plane-0-instance.devkubernetes01.mesos\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/hostname=kube-control-plane-0-instance.devkubernetes01.mesos\n                    name=kube-control-plane-0-instance.devkubernetes01.mesos\n                    node-role.kubernetes.io/master=\n                    tier=kube-control-plane\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 9.0.6.3/25\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Thu, 07 Feb 2019 02:24:10 +0000\nTaints:             node-role.kubernetes.io/master:NoExecute\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Thu, 07 Feb 2019 03:13:03 +0000   Thu, 07 Feb 2019 02:24:10 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Thu, 07 Feb 2019 03:13:03 +0000   Thu, 07 Feb 2019 02:24:10 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Thu, 07 Feb 2019 03:13:03 +0000   Thu, 07 Feb 2019 02:24:10 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Thu, 07 Feb 2019 03:13:03 +0000   Thu, 07 Feb 2019 02:26:21 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  9.0.6.3\n  Hostname:    kube-control-plane-0-instance.devkubernetes01.mesos\nCapacity:\n cpu:                8\n ephemeral-storage:  58534856Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             32950908Ki\n pods:               10\nAllocatable:\n cpu:                6\n ephemeral-storage:  58432456Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             30853756Ki\n pods:               10\nSystem Info:\n Machine ID:                 3d6ff2f75c7d3ae927580249a28e7e05\n System UUID:                EC249F5C-386E-3833-F20D-92478CC8BA1B\n Boot ID:                    5b6b8110-7ec0-4694-a60f-786867195a17\n Kernel Version:             4.7.3-coreos-r2\n OS Image:                   Debian GNU/Linux 9 (stretch)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.9.1\n Kubelet Version:            v1.13.3\n Kube-Proxy Version:         v1.13.3\nPodCIDR:                     192.168.1.0/24\nNon-terminated Pods:         (7 in total)\n  Namespace                  Name                                                                           CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                                           ------------  ----------  ---------------  -------------  ---\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-3418c9e540594be1-6pmk4                        0 (0%)        0 (0%)      0 (0%)           0 (0%)         39m\n  kube-system                calico-node-nq6xd                                                              250m (4%)     0 (0%)      0 (0%)           0 (0%)         47m\n  kube-system                kube-apiserver-kube-control-plane-0-instance.devkubernetes01.mesos             0 (0%)        0 (0%)      0 (0%)           0 (0%)         48m\n  kube-system                kube-controller-manager-kube-control-plane-0-instance.devkubernetes01.mesos    0 (0%)        0 (0%)      0 (0%)           0 (0%)         48m\n  kube-system                kube-proxy-kube-control-plane-0-instance.devkubernetes01.mesos                 0 (0%)        0 (0%)      0 (0%)           0 (0%)         47m\n  kube-system                kube-scheduler-kube-control-plane-0-instance.devkubernetes01.mesos             0 (0%)        0 (0%)      0 (0%)           0 (0%)         47m\n  kube-system                local-dns-dispatcher-kube-control-plane-0-instance.devkubernetes01.mesos       100m (1%)     100m (1%)   32Mi (0%)        32Mi (0%)      48m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests   Limits\n  --------           --------   ------\n  cpu                350m (5%)  100m (1%)\n  memory             32Mi (0%)  32Mi (0%)\n  ephemeral-storage  0 (0%)     0 (0%)\nEvents:\n  Type    Reason                   Age                From                                                          Message\n  ----    ------                   ----               ----                                                          -------\n  Normal  Starting                 49m                kubelet, kube-control-plane-0-instance.devkubernetes01.mesos  Starting kubelet.\n  Normal  NodeHasSufficientMemory  49m (x8 over 49m)  kubelet, kube-control-plane-0-instance.devkubernetes01.mesos  Node kube-control-plane-0-instance.devkubernetes01.mesos status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    49m (x8 over 49m)  kubelet, kube-control-plane-0-instance.devkubernetes01.mesos  Node kube-control-plane-0-instance.devkubernetes01.mesos status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     49m (x7 over 49m)  kubelet, kube-control-plane-0-instance.devkubernetes01.mesos  Node kube-control-plane-0-instance.devkubernetes01.mesos status is now: NodeHasSufficientPID\n  Normal  NodeAllocatableEnforced  49m                kubelet, kube-control-plane-0-instance.devkubernetes01.mesos  Updated Node Allocatable limit across pods\n"
Feb  7 03:13:09.217: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 describe namespace e2e-tests-kubectl-mf97m'
Feb  7 03:13:09.287: INFO: stderr: ""
Feb  7 03:13:09.287: INFO: stdout: "Name:         e2e-tests-kubectl-mf97m\nLabels:       e2e-framework=kubectl\n              e2e-run=ce3d182c-2a80-11e9-87fe-baa4eca941e3\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:13:09.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-mf97m" for this suite.
Feb  7 03:13:33.693: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:13:33.872: INFO: namespace: e2e-tests-kubectl-mf97m, resource: bindings, ignored listing per whitelist
Feb  7 03:13:33.877: INFO: namespace e2e-tests-kubectl-mf97m deletion completed in 24.586657201s

• [SLOW TEST:27.436 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:13:33.877: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-5a3a647d-2a86-11e9-87fe-baa4eca941e3
STEP: Creating a pod to test consume configMaps
Feb  7 03:13:33.936: INFO: Waiting up to 5m0s for pod "pod-configmaps-5a3b14a6-2a86-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-configmap-nxhw7" to be "success or failure"
Feb  7 03:13:33.939: INFO: Pod "pod-configmaps-5a3b14a6-2a86-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.248246ms
Feb  7 03:13:35.941: INFO: Pod "pod-configmaps-5a3b14a6-2a86-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004919475s
STEP: Saw pod success
Feb  7 03:13:35.941: INFO: Pod "pod-configmaps-5a3b14a6-2a86-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:13:35.944: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod pod-configmaps-5a3b14a6-2a86-11e9-87fe-baa4eca941e3 container configmap-volume-test: <nil>
STEP: delete the pod
Feb  7 03:13:35.960: INFO: Waiting for pod pod-configmaps-5a3b14a6-2a86-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:13:35.962: INFO: Pod pod-configmaps-5a3b14a6-2a86-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:13:35.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-nxhw7" for this suite.
Feb  7 03:13:42.439: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:13:42.561: INFO: namespace: e2e-tests-configmap-nxhw7, resource: bindings, ignored listing per whitelist
Feb  7 03:13:42.622: INFO: namespace e2e-tests-configmap-nxhw7 deletion completed in 6.657356694s

• [SLOW TEST:8.745 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:13:42.622: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  7 03:13:42.680: INFO: Creating ReplicaSet my-hostname-basic-5f721c42-2a86-11e9-87fe-baa4eca941e3
Feb  7 03:13:42.689: INFO: Pod name my-hostname-basic-5f721c42-2a86-11e9-87fe-baa4eca941e3: Found 0 pods out of 1
Feb  7 03:13:47.696: INFO: Pod name my-hostname-basic-5f721c42-2a86-11e9-87fe-baa4eca941e3: Found 1 pods out of 1
Feb  7 03:13:47.696: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-5f721c42-2a86-11e9-87fe-baa4eca941e3" is running
Feb  7 03:13:47.698: INFO: Pod "my-hostname-basic-5f721c42-2a86-11e9-87fe-baa4eca941e3-5qfhx" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-07 03:13:42 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-07 03:13:44 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-07 03:13:44 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-07 03:13:42 +0000 UTC Reason: Message:}])
Feb  7 03:13:47.698: INFO: Trying to dial the pod
Feb  7 03:13:52.708: INFO: Controller my-hostname-basic-5f721c42-2a86-11e9-87fe-baa4eca941e3: Got expected result from replica 1 [my-hostname-basic-5f721c42-2a86-11e9-87fe-baa4eca941e3-5qfhx]: "my-hostname-basic-5f721c42-2a86-11e9-87fe-baa4eca941e3-5qfhx", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:13:52.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-d5lm7" for this suite.
Feb  7 03:14:00.780: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:14:00.787: INFO: namespace: e2e-tests-replicaset-d5lm7, resource: bindings, ignored listing per whitelist
Feb  7 03:14:00.903: INFO: namespace e2e-tests-replicaset-d5lm7 deletion completed in 8.192251957s

• [SLOW TEST:18.281 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:14:00.903: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb  7 03:14:01.192: INFO: Waiting up to 5m0s for pod "downward-api-6a568f43-2a86-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-downward-api-tcbmp" to be "success or failure"
Feb  7 03:14:01.282: INFO: Pod "downward-api-6a568f43-2a86-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 89.668337ms
Feb  7 03:14:03.285: INFO: Pod "downward-api-6a568f43-2a86-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.092918455s
STEP: Saw pod success
Feb  7 03:14:03.285: INFO: Pod "downward-api-6a568f43-2a86-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:14:03.287: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod downward-api-6a568f43-2a86-11e9-87fe-baa4eca941e3 container dapi-container: <nil>
STEP: delete the pod
Feb  7 03:14:03.397: INFO: Waiting for pod downward-api-6a568f43-2a86-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:14:03.399: INFO: Pod downward-api-6a568f43-2a86-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:14:03.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-tcbmp" for this suite.
Feb  7 03:14:09.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:14:09.460: INFO: namespace: e2e-tests-downward-api-tcbmp, resource: bindings, ignored listing per whitelist
Feb  7 03:14:09.557: INFO: namespace e2e-tests-downward-api-tcbmp deletion completed in 6.15444532s

• [SLOW TEST:8.654 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:14:09.557: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb  7 03:14:09.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-jqtqc'
Feb  7 03:14:09.676: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb  7 03:14:09.676: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1404
Feb  7 03:14:13.684: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-jqtqc'
Feb  7 03:14:13.752: INFO: stderr: ""
Feb  7 03:14:13.752: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:14:13.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-jqtqc" for this suite.
Feb  7 03:14:19.772: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:14:20.367: INFO: namespace: e2e-tests-kubectl-jqtqc, resource: bindings, ignored listing per whitelist
Feb  7 03:14:20.367: INFO: namespace e2e-tests-kubectl-jqtqc deletion completed in 6.611588408s

• [SLOW TEST:10.810 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:14:20.367: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Feb  7 03:14:20.431: INFO: Waiting up to 5m0s for pod "client-containers-75f12dfb-2a86-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-containers-sl77w" to be "success or failure"
Feb  7 03:14:20.433: INFO: Pod "client-containers-75f12dfb-2a86-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.086098ms
Feb  7 03:14:22.436: INFO: Pod "client-containers-75f12dfb-2a86-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005164349s
Feb  7 03:14:24.439: INFO: Pod "client-containers-75f12dfb-2a86-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008145039s
STEP: Saw pod success
Feb  7 03:14:24.439: INFO: Pod "client-containers-75f12dfb-2a86-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:14:24.481: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod client-containers-75f12dfb-2a86-11e9-87fe-baa4eca941e3 container test-container: <nil>
STEP: delete the pod
Feb  7 03:14:24.496: INFO: Waiting for pod client-containers-75f12dfb-2a86-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:14:24.498: INFO: Pod client-containers-75f12dfb-2a86-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:14:24.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-sl77w" for this suite.
Feb  7 03:14:30.583: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:14:30.721: INFO: namespace: e2e-tests-containers-sl77w, resource: bindings, ignored listing per whitelist
Feb  7 03:14:30.726: INFO: namespace e2e-tests-containers-sl77w deletion completed in 6.224835429s

• [SLOW TEST:10.358 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:14:30.726: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb  7 03:14:30.787: INFO: Waiting up to 5m0s for pod "pod-7c1d74e7-2a86-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-emptydir-rpjhh" to be "success or failure"
Feb  7 03:14:30.789: INFO: Pod "pod-7c1d74e7-2a86-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.170834ms
Feb  7 03:14:33.013: INFO: Pod "pod-7c1d74e7-2a86-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.226114862s
STEP: Saw pod success
Feb  7 03:14:33.013: INFO: Pod "pod-7c1d74e7-2a86-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:14:33.016: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod pod-7c1d74e7-2a86-11e9-87fe-baa4eca941e3 container test-container: <nil>
STEP: delete the pod
Feb  7 03:14:33.046: INFO: Waiting for pod pod-7c1d74e7-2a86-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:14:33.047: INFO: Pod pod-7c1d74e7-2a86-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:14:33.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-rpjhh" for this suite.
Feb  7 03:14:39.484: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:14:39.489: INFO: namespace: e2e-tests-emptydir-rpjhh, resource: bindings, ignored listing per whitelist
Feb  7 03:14:39.586: INFO: namespace e2e-tests-emptydir-rpjhh deletion completed in 6.535248998s

• [SLOW TEST:8.860 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:14:39.586: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-ts4kt
I0207 03:14:39.639035      17 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-ts4kt, replica count: 1
I0207 03:14:40.689571      17 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb  7 03:14:40.798: INFO: Created: latency-svc-fzh7f
Feb  7 03:14:41.388: INFO: Got endpoints: latency-svc-fzh7f [598.343688ms]
Feb  7 03:14:41.397: INFO: Created: latency-svc-vw5vw
Feb  7 03:14:41.402: INFO: Got endpoints: latency-svc-vw5vw [14.656409ms]
Feb  7 03:14:41.403: INFO: Created: latency-svc-hldr4
Feb  7 03:14:41.408: INFO: Created: latency-svc-kh75c
Feb  7 03:14:41.408: INFO: Got endpoints: latency-svc-hldr4 [20.215059ms]
Feb  7 03:14:41.412: INFO: Got endpoints: latency-svc-kh75c [23.90844ms]
Feb  7 03:14:41.414: INFO: Created: latency-svc-lrqbp
Feb  7 03:14:41.420: INFO: Got endpoints: latency-svc-lrqbp [32.211244ms]
Feb  7 03:14:41.424: INFO: Created: latency-svc-rwq4x
Feb  7 03:14:41.430: INFO: Got endpoints: latency-svc-rwq4x [41.753301ms]
Feb  7 03:14:41.431: INFO: Created: latency-svc-2nc2m
Feb  7 03:14:41.436: INFO: Created: latency-svc-hhg75
Feb  7 03:14:41.440: INFO: Got endpoints: latency-svc-2nc2m [51.752877ms]
Feb  7 03:14:41.441: INFO: Created: latency-svc-jlp99
Feb  7 03:14:41.441: INFO: Got endpoints: latency-svc-hhg75 [53.394691ms]
Feb  7 03:14:41.446: INFO: Got endpoints: latency-svc-jlp99 [57.559202ms]
Feb  7 03:14:41.447: INFO: Created: latency-svc-wtdjg
Feb  7 03:14:41.452: INFO: Got endpoints: latency-svc-wtdjg [63.489471ms]
Feb  7 03:14:41.453: INFO: Created: latency-svc-rtxsh
Feb  7 03:14:41.458: INFO: Got endpoints: latency-svc-rtxsh [70.166844ms]
Feb  7 03:14:41.460: INFO: Created: latency-svc-hv8gw
Feb  7 03:14:41.465: INFO: Created: latency-svc-qt8hs
Feb  7 03:14:41.466: INFO: Got endpoints: latency-svc-hv8gw [77.919991ms]
Feb  7 03:14:41.476: INFO: Got endpoints: latency-svc-qt8hs [88.138286ms]
Feb  7 03:14:41.477: INFO: Created: latency-svc-rjgt4
Feb  7 03:14:41.477: INFO: Got endpoints: latency-svc-rjgt4 [88.88939ms]
Feb  7 03:14:41.484: INFO: Created: latency-svc-k2hvm
Feb  7 03:14:41.489: INFO: Created: latency-svc-fclk6
Feb  7 03:14:41.490: INFO: Got endpoints: latency-svc-k2hvm [101.846416ms]
Feb  7 03:14:41.494: INFO: Got endpoints: latency-svc-fclk6 [106.40814ms]
Feb  7 03:14:41.495: INFO: Created: latency-svc-ncgtf
Feb  7 03:14:41.499: INFO: Got endpoints: latency-svc-ncgtf [96.007102ms]
Feb  7 03:14:41.501: INFO: Created: latency-svc-tvcd6
Feb  7 03:14:41.507: INFO: Created: latency-svc-nl4tw
Feb  7 03:14:41.507: INFO: Got endpoints: latency-svc-tvcd6 [98.975592ms]
Feb  7 03:14:41.510: INFO: Got endpoints: latency-svc-nl4tw [98.179215ms]
Feb  7 03:14:41.512: INFO: Created: latency-svc-7xvrz
Feb  7 03:14:41.518: INFO: Got endpoints: latency-svc-7xvrz [98.201206ms]
Feb  7 03:14:41.519: INFO: Created: latency-svc-tzcl2
Feb  7 03:14:41.525: INFO: Created: latency-svc-xjqfm
Feb  7 03:14:41.529: INFO: Got endpoints: latency-svc-tzcl2 [98.992526ms]
Feb  7 03:14:41.529: INFO: Created: latency-svc-mmwkz
Feb  7 03:14:41.530: INFO: Got endpoints: latency-svc-xjqfm [90.324799ms]
Feb  7 03:14:41.535: INFO: Created: latency-svc-p97gz
Feb  7 03:14:41.540: INFO: Created: latency-svc-lbmv9
Feb  7 03:14:41.545: INFO: Got endpoints: latency-svc-lbmv9 [93.422533ms]
Feb  7 03:14:41.545: INFO: Got endpoints: latency-svc-p97gz [99.659057ms]
Feb  7 03:14:41.546: INFO: Got endpoints: latency-svc-mmwkz [104.847085ms]
Feb  7 03:14:41.546: INFO: Created: latency-svc-wr4v5
Feb  7 03:14:42.038: INFO: Created: latency-svc-lwtgp
Feb  7 03:14:42.043: INFO: Created: latency-svc-rh27n
Feb  7 03:14:42.051: INFO: Created: latency-svc-w6cg6
Feb  7 03:14:42.056: INFO: Created: latency-svc-ww56b
Feb  7 03:14:42.064: INFO: Created: latency-svc-5x8g5
Feb  7 03:14:42.069: INFO: Created: latency-svc-z9dnc
Feb  7 03:14:42.074: INFO: Created: latency-svc-wqtcb
Feb  7 03:14:42.080: INFO: Created: latency-svc-58f75
Feb  7 03:14:42.085: INFO: Created: latency-svc-jh957
Feb  7 03:14:42.090: INFO: Created: latency-svc-7fgbt
Feb  7 03:14:42.097: INFO: Created: latency-svc-pg7f7
Feb  7 03:14:42.103: INFO: Created: latency-svc-92mk9
Feb  7 03:14:42.110: INFO: Created: latency-svc-mmf9m
Feb  7 03:14:42.110: INFO: Got endpoints: latency-svc-wr4v5 [652.135938ms]
Feb  7 03:14:42.115: INFO: Created: latency-svc-s4pzk
Feb  7 03:14:42.116: INFO: Got endpoints: latency-svc-w6cg6 [639.436253ms]
Feb  7 03:14:42.116: INFO: Got endpoints: latency-svc-lwtgp [650.365581ms]
Feb  7 03:14:42.116: INFO: Got endpoints: latency-svc-rh27n [640.176097ms]
Feb  7 03:14:42.117: INFO: Got endpoints: latency-svc-ww56b [626.651038ms]
Feb  7 03:14:42.118: INFO: Got endpoints: latency-svc-5x8g5 [623.837022ms]
Feb  7 03:14:42.123: INFO: Got endpoints: latency-svc-wqtcb [616.383372ms]
Feb  7 03:14:42.124: INFO: Got endpoints: latency-svc-z9dnc [624.922756ms]
Feb  7 03:14:42.127: INFO: Got endpoints: latency-svc-58f75 [617.196439ms]
Feb  7 03:14:42.128: INFO: Created: latency-svc-zvjn9
Feb  7 03:14:42.128: INFO: Got endpoints: latency-svc-7fgbt [598.709892ms]
Feb  7 03:14:42.128: INFO: Got endpoints: latency-svc-jh957 [609.164861ms]
Feb  7 03:14:42.128: INFO: Got endpoints: latency-svc-pg7f7 [597.999523ms]
Feb  7 03:14:42.130: INFO: Got endpoints: latency-svc-92mk9 [584.457908ms]
Feb  7 03:14:42.131: INFO: Got endpoints: latency-svc-mmf9m [586.228137ms]
Feb  7 03:14:42.133: INFO: Got endpoints: latency-svc-s4pzk [587.128108ms]
Feb  7 03:14:42.134: INFO: Created: latency-svc-jw4c7
Feb  7 03:14:42.134: INFO: Got endpoints: latency-svc-zvjn9 [23.511644ms]
Feb  7 03:14:42.138: INFO: Got endpoints: latency-svc-jw4c7 [22.01799ms]
Feb  7 03:14:42.141: INFO: Created: latency-svc-k5gl5
Feb  7 03:14:42.146: INFO: Got endpoints: latency-svc-k5gl5 [28.836464ms]
Feb  7 03:14:42.147: INFO: Created: latency-svc-2ntkn
Feb  7 03:14:42.151: INFO: Got endpoints: latency-svc-2ntkn [34.754504ms]
Feb  7 03:14:42.152: INFO: Created: latency-svc-pxcgh
Feb  7 03:14:42.157: INFO: Got endpoints: latency-svc-pxcgh [40.691017ms]
Feb  7 03:14:42.158: INFO: Created: latency-svc-g27d2
Feb  7 03:14:42.163: INFO: Created: latency-svc-wzflg
Feb  7 03:14:42.180: INFO: Created: latency-svc-cmhff
Feb  7 03:14:42.185: INFO: Got endpoints: latency-svc-g27d2 [66.721257ms]
Feb  7 03:14:42.187: INFO: Created: latency-svc-86h48
Feb  7 03:14:42.192: INFO: Created: latency-svc-4brb9
Feb  7 03:14:42.201: INFO: Created: latency-svc-sckj6
Feb  7 03:14:42.206: INFO: Created: latency-svc-4xbj2
Feb  7 03:14:42.212: INFO: Created: latency-svc-6qh27
Feb  7 03:14:42.217: INFO: Created: latency-svc-wmmmt
Feb  7 03:14:42.222: INFO: Created: latency-svc-mv4bh
Feb  7 03:14:42.227: INFO: Created: latency-svc-5dmhh
Feb  7 03:14:42.233: INFO: Created: latency-svc-2hc56
Feb  7 03:14:42.239: INFO: Created: latency-svc-sqxvs
Feb  7 03:14:42.243: INFO: Got endpoints: latency-svc-wzflg [119.848619ms]
Feb  7 03:14:42.245: INFO: Created: latency-svc-ht8pq
Feb  7 03:14:42.250: INFO: Created: latency-svc-gqkkz
Feb  7 03:14:42.254: INFO: Created: latency-svc-d2h58
Feb  7 03:14:42.261: INFO: Created: latency-svc-bq5mw
Feb  7 03:14:42.285: INFO: Got endpoints: latency-svc-cmhff [161.659398ms]
Feb  7 03:14:42.294: INFO: Created: latency-svc-scjrk
Feb  7 03:14:42.334: INFO: Got endpoints: latency-svc-86h48 [206.220881ms]
Feb  7 03:14:42.343: INFO: Created: latency-svc-jjrgl
Feb  7 03:14:42.385: INFO: Got endpoints: latency-svc-4brb9 [257.151378ms]
Feb  7 03:14:42.393: INFO: Created: latency-svc-mlf6c
Feb  7 03:14:42.434: INFO: Got endpoints: latency-svc-sckj6 [306.135318ms]
Feb  7 03:14:42.443: INFO: Created: latency-svc-742ph
Feb  7 03:14:42.483: INFO: Got endpoints: latency-svc-4xbj2 [355.368087ms]
Feb  7 03:14:42.491: INFO: Created: latency-svc-n5vh7
Feb  7 03:14:42.534: INFO: Got endpoints: latency-svc-6qh27 [404.404696ms]
Feb  7 03:14:42.544: INFO: Created: latency-svc-xwtgc
Feb  7 03:14:42.590: INFO: Got endpoints: latency-svc-wmmmt [458.433969ms]
Feb  7 03:14:42.598: INFO: Created: latency-svc-26jgd
Feb  7 03:14:42.635: INFO: Got endpoints: latency-svc-mv4bh [501.214565ms]
Feb  7 03:14:42.643: INFO: Created: latency-svc-v5pwd
Feb  7 03:14:42.684: INFO: Got endpoints: latency-svc-5dmhh [550.37655ms]
Feb  7 03:14:42.692: INFO: Created: latency-svc-vt67p
Feb  7 03:14:42.735: INFO: Got endpoints: latency-svc-2hc56 [596.582836ms]
Feb  7 03:14:42.745: INFO: Created: latency-svc-xb9r4
Feb  7 03:14:42.784: INFO: Got endpoints: latency-svc-sqxvs [638.528242ms]
Feb  7 03:14:42.793: INFO: Created: latency-svc-w2mlj
Feb  7 03:14:42.834: INFO: Got endpoints: latency-svc-ht8pq [682.826392ms]
Feb  7 03:14:42.842: INFO: Created: latency-svc-zrw2z
Feb  7 03:14:42.885: INFO: Got endpoints: latency-svc-gqkkz [727.327523ms]
Feb  7 03:14:42.893: INFO: Created: latency-svc-flvtx
Feb  7 03:14:42.935: INFO: Got endpoints: latency-svc-d2h58 [749.521362ms]
Feb  7 03:14:42.943: INFO: Created: latency-svc-lsbx9
Feb  7 03:14:42.991: INFO: Got endpoints: latency-svc-bq5mw [747.880747ms]
Feb  7 03:14:42.999: INFO: Created: latency-svc-b8jt9
Feb  7 03:14:43.034: INFO: Got endpoints: latency-svc-scjrk [748.87994ms]
Feb  7 03:14:43.042: INFO: Created: latency-svc-h58jq
Feb  7 03:14:43.085: INFO: Got endpoints: latency-svc-jjrgl [750.647989ms]
Feb  7 03:14:43.093: INFO: Created: latency-svc-pqhc4
Feb  7 03:14:43.135: INFO: Got endpoints: latency-svc-mlf6c [749.742321ms]
Feb  7 03:14:43.143: INFO: Created: latency-svc-4lt6p
Feb  7 03:14:43.184: INFO: Got endpoints: latency-svc-742ph [750.819753ms]
Feb  7 03:14:43.193: INFO: Created: latency-svc-tnkkp
Feb  7 03:14:43.235: INFO: Got endpoints: latency-svc-n5vh7 [751.237786ms]
Feb  7 03:14:43.243: INFO: Created: latency-svc-664mf
Feb  7 03:14:43.285: INFO: Got endpoints: latency-svc-xwtgc [750.224999ms]
Feb  7 03:14:43.293: INFO: Created: latency-svc-v25sv
Feb  7 03:14:43.804: INFO: Got endpoints: latency-svc-26jgd [1.214170701s]
Feb  7 03:14:43.808: INFO: Got endpoints: latency-svc-v5pwd [1.173730882s]
Feb  7 03:14:43.809: INFO: Got endpoints: latency-svc-vt67p [1.124455901s]
Feb  7 03:14:43.809: INFO: Got endpoints: latency-svc-w2mlj [1.025299759s]
Feb  7 03:14:43.810: INFO: Got endpoints: latency-svc-xb9r4 [1.074372566s]
Feb  7 03:14:43.810: INFO: Got endpoints: latency-svc-zrw2z [975.645266ms]
Feb  7 03:14:43.817: INFO: Got endpoints: latency-svc-flvtx [931.881395ms]
Feb  7 03:14:43.817: INFO: Got endpoints: latency-svc-h58jq [782.705288ms]
Feb  7 03:14:43.817: INFO: Got endpoints: latency-svc-lsbx9 [882.483875ms]
Feb  7 03:14:43.817: INFO: Got endpoints: latency-svc-b8jt9 [826.05332ms]
Feb  7 03:14:43.818: INFO: Created: latency-svc-t7nbv
Feb  7 03:14:43.823: INFO: Created: latency-svc-zv292
Feb  7 03:14:43.828: INFO: Created: latency-svc-w7vtc
Feb  7 03:14:43.833: INFO: Created: latency-svc-ct4sx
Feb  7 03:14:43.834: INFO: Got endpoints: latency-svc-pqhc4 [749.653891ms]
Feb  7 03:14:43.839: INFO: Created: latency-svc-k9pbd
Feb  7 03:14:43.844: INFO: Created: latency-svc-m8bp4
Feb  7 03:14:43.849: INFO: Created: latency-svc-c2s76
Feb  7 03:14:43.854: INFO: Created: latency-svc-5gwdg
Feb  7 03:14:43.861: INFO: Created: latency-svc-2d2zs
Feb  7 03:14:43.866: INFO: Created: latency-svc-p9sbf
Feb  7 03:14:43.872: INFO: Created: latency-svc-mnrhc
Feb  7 03:14:43.884: INFO: Got endpoints: latency-svc-4lt6p [749.447366ms]
Feb  7 03:14:43.892: INFO: Created: latency-svc-s4qkm
Feb  7 03:14:43.934: INFO: Got endpoints: latency-svc-tnkkp [749.846264ms]
Feb  7 03:14:43.942: INFO: Created: latency-svc-ptw8c
Feb  7 03:14:43.984: INFO: Got endpoints: latency-svc-664mf [749.47705ms]
Feb  7 03:14:43.993: INFO: Created: latency-svc-7xcvv
Feb  7 03:14:44.034: INFO: Got endpoints: latency-svc-v25sv [749.202508ms]
Feb  7 03:14:44.042: INFO: Created: latency-svc-trsvc
Feb  7 03:14:44.084: INFO: Got endpoints: latency-svc-t7nbv [280.112084ms]
Feb  7 03:14:44.092: INFO: Created: latency-svc-hcghr
Feb  7 03:14:44.135: INFO: Got endpoints: latency-svc-zv292 [326.327284ms]
Feb  7 03:14:44.143: INFO: Created: latency-svc-r48fs
Feb  7 03:14:44.184: INFO: Got endpoints: latency-svc-w7vtc [375.247956ms]
Feb  7 03:14:44.192: INFO: Created: latency-svc-pwspr
Feb  7 03:14:44.234: INFO: Got endpoints: latency-svc-ct4sx [424.425452ms]
Feb  7 03:14:44.242: INFO: Created: latency-svc-zv5n7
Feb  7 03:14:44.289: INFO: Got endpoints: latency-svc-k9pbd [479.39113ms]
Feb  7 03:14:44.297: INFO: Created: latency-svc-4f4km
Feb  7 03:14:44.802: INFO: Got endpoints: latency-svc-m8bp4 [992.360248ms]
Feb  7 03:14:44.806: INFO: Got endpoints: latency-svc-p9sbf [988.184114ms]
Feb  7 03:14:44.806: INFO: Got endpoints: latency-svc-5gwdg [988.740919ms]
Feb  7 03:14:44.806: INFO: Got endpoints: latency-svc-2d2zs [988.611264ms]
Feb  7 03:14:44.806: INFO: Got endpoints: latency-svc-c2s76 [989.09633ms]
Feb  7 03:14:44.808: INFO: Got endpoints: latency-svc-mnrhc [974.102096ms]
Feb  7 03:14:44.812: INFO: Got endpoints: latency-svc-7xcvv [828.176809ms]
Feb  7 03:14:44.813: INFO: Got endpoints: latency-svc-ptw8c [878.241117ms]
Feb  7 03:14:44.813: INFO: Got endpoints: latency-svc-s4qkm [928.533042ms]
Feb  7 03:14:44.813: INFO: Got endpoints: latency-svc-trsvc [778.922241ms]
Feb  7 03:14:44.814: INFO: Created: latency-svc-6ns9r
Feb  7 03:14:44.816: INFO: Created: latency-svc-2k9hs
Feb  7 03:14:44.822: INFO: Created: latency-svc-gs7qj
Feb  7 03:14:44.827: INFO: Created: latency-svc-g9rtt
Feb  7 03:14:44.832: INFO: Created: latency-svc-qldmz
Feb  7 03:14:44.835: INFO: Got endpoints: latency-svc-hcghr [750.830968ms]
Feb  7 03:14:44.838: INFO: Created: latency-svc-krh8d
Feb  7 03:14:44.844: INFO: Created: latency-svc-jn8x5
Feb  7 03:14:44.849: INFO: Created: latency-svc-lvzx6
Feb  7 03:14:44.854: INFO: Created: latency-svc-kbl6b
Feb  7 03:14:44.859: INFO: Created: latency-svc-mr2tg
Feb  7 03:14:44.865: INFO: Created: latency-svc-grzdn
Feb  7 03:14:44.884: INFO: Got endpoints: latency-svc-r48fs [749.254612ms]
Feb  7 03:14:44.892: INFO: Created: latency-svc-qvf25
Feb  7 03:14:44.934: INFO: Got endpoints: latency-svc-zv5n7 [700.219099ms]
Feb  7 03:14:44.942: INFO: Created: latency-svc-6zrcz
Feb  7 03:14:44.984: INFO: Got endpoints: latency-svc-pwspr [799.988579ms]
Feb  7 03:14:44.993: INFO: Created: latency-svc-smp2q
Feb  7 03:14:45.035: INFO: Got endpoints: latency-svc-4f4km [745.29821ms]
Feb  7 03:14:45.043: INFO: Created: latency-svc-4wsrk
Feb  7 03:14:45.357: INFO: Got endpoints: latency-svc-6ns9r [554.399133ms]
Feb  7 03:14:45.386: INFO: Got endpoints: latency-svc-2k9hs [577.307175ms]
Feb  7 03:14:45.386: INFO: Got endpoints: latency-svc-krh8d [580.383897ms]
Feb  7 03:14:45.386: INFO: Got endpoints: latency-svc-g9rtt [580.41154ms]
Feb  7 03:14:45.386: INFO: Got endpoints: latency-svc-gs7qj [580.747409ms]
Feb  7 03:14:45.386: INFO: Got endpoints: latency-svc-qldmz [580.521211ms]
Feb  7 03:14:45.391: INFO: Created: latency-svc-mwchx
Feb  7 03:14:45.397: INFO: Created: latency-svc-vt7vr
Feb  7 03:14:45.398: INFO: Got endpoints: latency-svc-lvzx6 [585.581629ms]
Feb  7 03:14:45.403: INFO: Created: latency-svc-4kqjc
Feb  7 03:14:45.409: INFO: Created: latency-svc-xnsgb
Feb  7 03:14:45.415: INFO: Created: latency-svc-vvp86
Feb  7 03:14:45.420: INFO: Created: latency-svc-kzbs6
Feb  7 03:14:45.425: INFO: Created: latency-svc-hlqsf
Feb  7 03:14:45.480: INFO: Got endpoints: latency-svc-jn8x5 [667.937529ms]
Feb  7 03:14:45.484: INFO: Got endpoints: latency-svc-kbl6b [671.335622ms]
Feb  7 03:14:45.490: INFO: Created: latency-svc-v9wqd
Feb  7 03:14:45.495: INFO: Created: latency-svc-6zw2b
Feb  7 03:14:45.534: INFO: Got endpoints: latency-svc-mr2tg [721.16722ms]
Feb  7 03:14:45.542: INFO: Created: latency-svc-677nk
Feb  7 03:14:45.584: INFO: Got endpoints: latency-svc-grzdn [748.712061ms]
Feb  7 03:14:45.593: INFO: Created: latency-svc-mcqjw
Feb  7 03:14:45.633: INFO: Got endpoints: latency-svc-qvf25 [749.265896ms]
Feb  7 03:14:45.642: INFO: Created: latency-svc-wxbhg
Feb  7 03:14:45.684: INFO: Got endpoints: latency-svc-6zrcz [750.008758ms]
Feb  7 03:14:45.693: INFO: Created: latency-svc-dqgzg
Feb  7 03:14:45.734: INFO: Got endpoints: latency-svc-smp2q [749.606398ms]
Feb  7 03:14:45.743: INFO: Created: latency-svc-whh7l
Feb  7 03:14:45.784: INFO: Got endpoints: latency-svc-4wsrk [749.246403ms]
Feb  7 03:14:45.792: INFO: Created: latency-svc-5dlrg
Feb  7 03:14:45.833: INFO: Got endpoints: latency-svc-mwchx [476.761085ms]
Feb  7 03:14:45.843: INFO: Created: latency-svc-28fvl
Feb  7 03:14:45.885: INFO: Got endpoints: latency-svc-vt7vr [499.726174ms]
Feb  7 03:14:45.893: INFO: Created: latency-svc-qdqqn
Feb  7 03:14:45.934: INFO: Got endpoints: latency-svc-4kqjc [547.857507ms]
Feb  7 03:14:45.942: INFO: Created: latency-svc-8gkp4
Feb  7 03:14:45.984: INFO: Got endpoints: latency-svc-xnsgb [597.971166ms]
Feb  7 03:14:45.995: INFO: Created: latency-svc-4jmlb
Feb  7 03:14:46.034: INFO: Got endpoints: latency-svc-vvp86 [647.602941ms]
Feb  7 03:14:46.042: INFO: Created: latency-svc-qq62g
Feb  7 03:14:46.649: INFO: Got endpoints: latency-svc-kzbs6 [1.262672352s]
Feb  7 03:14:46.652: INFO: Got endpoints: latency-svc-677nk [1.118275642s]
Feb  7 03:14:46.652: INFO: Got endpoints: latency-svc-hlqsf [1.254174283s]
Feb  7 03:14:46.653: INFO: Got endpoints: latency-svc-v9wqd [1.172239313s]
Feb  7 03:14:46.653: INFO: Got endpoints: latency-svc-6zw2b [1.16885813s]
Feb  7 03:14:46.654: INFO: Got endpoints: latency-svc-mcqjw [1.07028329s]
Feb  7 03:14:46.662: INFO: Got endpoints: latency-svc-wxbhg [1.028857746s]
Feb  7 03:14:46.664: INFO: Created: latency-svc-zlmm9
Feb  7 03:14:46.664: INFO: Got endpoints: latency-svc-whh7l [929.742266ms]
Feb  7 03:14:46.664: INFO: Got endpoints: latency-svc-dqgzg [979.408044ms]
Feb  7 03:14:46.664: INFO: Got endpoints: latency-svc-5dlrg [879.847444ms]
Feb  7 03:14:46.665: INFO: Got endpoints: latency-svc-28fvl [831.105769ms]
Feb  7 03:14:46.668: INFO: Got endpoints: latency-svc-qdqqn [782.967803ms]
Feb  7 03:14:46.671: INFO: Created: latency-svc-sv5s4
Feb  7 03:14:46.678: INFO: Created: latency-svc-tlxsq
Feb  7 03:14:46.684: INFO: Created: latency-svc-dwsjt
Feb  7 03:14:46.684: INFO: Got endpoints: latency-svc-8gkp4 [749.526386ms]
Feb  7 03:14:46.690: INFO: Created: latency-svc-9568p
Feb  7 03:14:46.695: INFO: Created: latency-svc-jsjhz
Feb  7 03:14:46.701: INFO: Created: latency-svc-jmdgz
Feb  7 03:14:46.709: INFO: Created: latency-svc-xq7qm
Feb  7 03:14:46.713: INFO: Created: latency-svc-m249b
Feb  7 03:14:46.718: INFO: Created: latency-svc-rl7sm
Feb  7 03:14:46.724: INFO: Created: latency-svc-cbf8p
Feb  7 03:14:46.729: INFO: Created: latency-svc-7d7x5
Feb  7 03:14:46.736: INFO: Got endpoints: latency-svc-4jmlb [751.834545ms]
Feb  7 03:14:46.737: INFO: Created: latency-svc-fdg2v
Feb  7 03:14:46.745: INFO: Created: latency-svc-x7jkj
Feb  7 03:14:46.784: INFO: Got endpoints: latency-svc-zlmm9 [135.016949ms]
Feb  7 03:14:46.792: INFO: Created: latency-svc-cxqjz
Feb  7 03:14:46.835: INFO: Got endpoints: latency-svc-qq62g [800.506163ms]
Feb  7 03:14:47.284: INFO: Created: latency-svc-gjkcp
Feb  7 03:14:47.286: INFO: Got endpoints: latency-svc-jsjhz [631.974852ms]
Feb  7 03:14:47.286: INFO: Got endpoints: latency-svc-tlxsq [633.259962ms]
Feb  7 03:14:47.286: INFO: Got endpoints: latency-svc-sv5s4 [633.681953ms]
Feb  7 03:14:47.286: INFO: Got endpoints: latency-svc-dwsjt [633.4868ms]
Feb  7 03:14:47.286: INFO: Got endpoints: latency-svc-9568p [633.935756ms]
Feb  7 03:14:47.292: INFO: Got endpoints: latency-svc-jmdgz [629.983627ms]
Feb  7 03:14:47.300: INFO: Created: latency-svc-6hn9r
Feb  7 03:14:47.306: INFO: Created: latency-svc-x6hgx
Feb  7 03:14:47.311: INFO: Created: latency-svc-n79x6
Feb  7 03:14:47.317: INFO: Created: latency-svc-vvctr
Feb  7 03:14:47.325: INFO: Created: latency-svc-jvmcm
Feb  7 03:14:47.329: INFO: Created: latency-svc-dt6hd
Feb  7 03:14:47.421: INFO: Got endpoints: latency-svc-xq7qm [757.43846ms]
Feb  7 03:14:47.422: INFO: Got endpoints: latency-svc-m249b [757.756613ms]
Feb  7 03:14:47.422: INFO: Got endpoints: latency-svc-rl7sm [758.171329ms]
Feb  7 03:14:47.424: INFO: Got endpoints: latency-svc-cbf8p [759.698475ms]
Feb  7 03:14:47.425: INFO: Got endpoints: latency-svc-7d7x5 [756.382406ms]
Feb  7 03:14:47.434: INFO: Created: latency-svc-hwfw8
Feb  7 03:14:47.436: INFO: Got endpoints: latency-svc-fdg2v [751.717427ms]
Feb  7 03:14:47.440: INFO: Created: latency-svc-mh699
Feb  7 03:14:47.445: INFO: Created: latency-svc-kqh4t
Feb  7 03:14:47.450: INFO: Created: latency-svc-tl4w8
Feb  7 03:14:47.455: INFO: Created: latency-svc-vs97m
Feb  7 03:14:47.483: INFO: Created: latency-svc-9vbf4
Feb  7 03:14:47.485: INFO: Got endpoints: latency-svc-x7jkj [748.788924ms]
Feb  7 03:14:47.497: INFO: Created: latency-svc-d9lgk
Feb  7 03:14:47.534: INFO: Got endpoints: latency-svc-cxqjz [749.863134ms]
Feb  7 03:14:47.544: INFO: Created: latency-svc-d6qrf
Feb  7 03:14:47.584: INFO: Got endpoints: latency-svc-gjkcp [749.143437ms]
Feb  7 03:14:47.594: INFO: Created: latency-svc-rw5x6
Feb  7 03:14:47.635: INFO: Got endpoints: latency-svc-6hn9r [349.048574ms]
Feb  7 03:14:47.643: INFO: Created: latency-svc-w5x6p
Feb  7 03:14:47.684: INFO: Got endpoints: latency-svc-x6hgx [397.659581ms]
Feb  7 03:14:47.693: INFO: Created: latency-svc-j2j4n
Feb  7 03:14:47.734: INFO: Got endpoints: latency-svc-n79x6 [446.890798ms]
Feb  7 03:14:47.904: INFO: Got endpoints: latency-svc-vvctr [617.278234ms]
Feb  7 03:14:47.905: INFO: Created: latency-svc-9bqqw
Feb  7 03:14:47.906: INFO: Got endpoints: latency-svc-jvmcm [619.330463ms]
Feb  7 03:14:47.906: INFO: Got endpoints: latency-svc-dt6hd [613.607156ms]
Feb  7 03:14:47.916: INFO: Created: latency-svc-djlsc
Feb  7 03:14:47.921: INFO: Created: latency-svc-sm48h
Feb  7 03:14:47.926: INFO: Created: latency-svc-qmlfm
Feb  7 03:14:47.944: INFO: Got endpoints: latency-svc-hwfw8 [522.269829ms]
Feb  7 03:14:47.982: INFO: Created: latency-svc-q94vx
Feb  7 03:14:47.985: INFO: Got endpoints: latency-svc-mh699 [562.77935ms]
Feb  7 03:14:47.994: INFO: Created: latency-svc-pk5nf
Feb  7 03:14:48.034: INFO: Got endpoints: latency-svc-kqh4t [612.324792ms]
Feb  7 03:14:48.043: INFO: Created: latency-svc-bmrrw
Feb  7 03:14:48.085: INFO: Got endpoints: latency-svc-vs97m [659.806684ms]
Feb  7 03:14:48.093: INFO: Created: latency-svc-bntc9
Feb  7 03:14:48.134: INFO: Got endpoints: latency-svc-tl4w8 [709.563507ms]
Feb  7 03:14:48.142: INFO: Created: latency-svc-94769
Feb  7 03:14:48.184: INFO: Got endpoints: latency-svc-9vbf4 [748.536622ms]
Feb  7 03:14:48.193: INFO: Created: latency-svc-zgksf
Feb  7 03:14:48.235: INFO: Got endpoints: latency-svc-d9lgk [749.521823ms]
Feb  7 03:14:48.243: INFO: Created: latency-svc-kh8g2
Feb  7 03:14:49.777: INFO: Got endpoints: latency-svc-d6qrf [2.243082285s]
Feb  7 03:14:49.778: INFO: Got endpoints: latency-svc-rw5x6 [2.193834002s]
Feb  7 03:14:49.778: INFO: Got endpoints: latency-svc-w5x6p [2.142481897s]
Feb  7 03:14:49.778: INFO: Got endpoints: latency-svc-9bqqw [2.044414427s]
Feb  7 03:14:49.778: INFO: Got endpoints: latency-svc-j2j4n [2.09381764s]
Feb  7 03:14:50.099: INFO: Got endpoints: latency-svc-qmlfm [2.192844248s]
Feb  7 03:14:50.099: INFO: Got endpoints: latency-svc-djlsc [2.19514038s]
Feb  7 03:14:50.099: INFO: Got endpoints: latency-svc-sm48h [2.193403498s]
Feb  7 03:14:50.100: INFO: Got endpoints: latency-svc-pk5nf [2.115477222s]
Feb  7 03:14:50.100: INFO: Got endpoints: latency-svc-q94vx [2.156702349s]
Feb  7 03:14:50.105: INFO: Got endpoints: latency-svc-94769 [1.970958988s]
Feb  7 03:14:50.105: INFO: Got endpoints: latency-svc-bmrrw [2.071069331s]
Feb  7 03:14:50.108: INFO: Got endpoints: latency-svc-bntc9 [2.023637254s]
Feb  7 03:14:50.110: INFO: Got endpoints: latency-svc-zgksf [1.925513038s]
Feb  7 03:14:50.110: INFO: Got endpoints: latency-svc-kh8g2 [1.875417131s]
Feb  7 03:14:50.112: INFO: Created: latency-svc-dx8vj
Feb  7 03:14:50.116: INFO: Got endpoints: latency-svc-dx8vj [339.070277ms]
Feb  7 03:14:50.117: INFO: Created: latency-svc-v5vfz
Feb  7 03:14:50.121: INFO: Got endpoints: latency-svc-v5vfz [343.65317ms]
Feb  7 03:14:50.122: INFO: Created: latency-svc-7hwmb
Feb  7 03:14:50.128: INFO: Got endpoints: latency-svc-7hwmb [349.97773ms]
Feb  7 03:14:50.129: INFO: Created: latency-svc-82n95
Feb  7 03:14:50.135: INFO: Created: latency-svc-lrqh9
Feb  7 03:14:50.136: INFO: Got endpoints: latency-svc-82n95 [357.695946ms]
Feb  7 03:14:50.139: INFO: Got endpoints: latency-svc-lrqh9 [360.649311ms]
Feb  7 03:14:50.140: INFO: Created: latency-svc-nmsbw
Feb  7 03:14:50.145: INFO: Got endpoints: latency-svc-nmsbw [45.543206ms]
Feb  7 03:14:50.147: INFO: Created: latency-svc-7858h
Feb  7 03:14:50.152: INFO: Created: latency-svc-rsp95
Feb  7 03:14:50.153: INFO: Got endpoints: latency-svc-7858h [54.225397ms]
Feb  7 03:14:50.157: INFO: Got endpoints: latency-svc-rsp95 [57.876455ms]
Feb  7 03:14:50.159: INFO: Created: latency-svc-dzdxv
Feb  7 03:14:50.164: INFO: Got endpoints: latency-svc-dzdxv [63.555778ms]
Feb  7 03:14:50.164: INFO: Created: latency-svc-7lcld
Feb  7 03:14:50.171: INFO: Got endpoints: latency-svc-7lcld [70.824247ms]
Feb  7 03:14:50.172: INFO: Created: latency-svc-m8qqn
Feb  7 03:14:50.178: INFO: Created: latency-svc-7tfwg
Feb  7 03:14:50.179: INFO: Got endpoints: latency-svc-m8qqn [74.161975ms]
Feb  7 03:14:50.183: INFO: Got endpoints: latency-svc-7tfwg [77.714428ms]
Feb  7 03:14:50.184: INFO: Created: latency-svc-24rs8
Feb  7 03:14:50.190: INFO: Got endpoints: latency-svc-24rs8 [81.070072ms]
Feb  7 03:14:50.191: INFO: Created: latency-svc-z9n8w
Feb  7 03:14:50.199: INFO: Got endpoints: latency-svc-z9n8w [89.600155ms]
Feb  7 03:14:50.206: INFO: Created: latency-svc-twjbn
Feb  7 03:14:50.206: INFO: Got endpoints: latency-svc-twjbn [95.565045ms]
Feb  7 03:14:50.279: INFO: Created: latency-svc-lxjlx
Feb  7 03:14:50.285: INFO: Created: latency-svc-k7hpn
Feb  7 03:14:50.290: INFO: Got endpoints: latency-svc-lxjlx [173.490275ms]
Feb  7 03:14:50.291: INFO: Got endpoints: latency-svc-k7hpn [169.494042ms]
Feb  7 03:14:50.298: INFO: Created: latency-svc-ckht6
Feb  7 03:14:50.303: INFO: Got endpoints: latency-svc-ckht6 [174.694347ms]
Feb  7 03:14:50.311: INFO: Created: latency-svc-9rdw7
Feb  7 03:14:50.315: INFO: Got endpoints: latency-svc-9rdw7 [178.845139ms]
Feb  7 03:14:50.315: INFO: Latencies: [14.656409ms 20.215059ms 22.01799ms 23.511644ms 23.90844ms 28.836464ms 32.211244ms 34.754504ms 40.691017ms 41.753301ms 45.543206ms 51.752877ms 53.394691ms 54.225397ms 57.559202ms 57.876455ms 63.489471ms 63.555778ms 66.721257ms 70.166844ms 70.824247ms 74.161975ms 77.714428ms 77.919991ms 81.070072ms 88.138286ms 88.88939ms 89.600155ms 90.324799ms 93.422533ms 95.565045ms 96.007102ms 98.179215ms 98.201206ms 98.975592ms 98.992526ms 99.659057ms 101.846416ms 104.847085ms 106.40814ms 119.848619ms 135.016949ms 161.659398ms 169.494042ms 173.490275ms 174.694347ms 178.845139ms 206.220881ms 257.151378ms 280.112084ms 306.135318ms 326.327284ms 339.070277ms 343.65317ms 349.048574ms 349.97773ms 355.368087ms 357.695946ms 360.649311ms 375.247956ms 397.659581ms 404.404696ms 424.425452ms 446.890798ms 458.433969ms 476.761085ms 479.39113ms 499.726174ms 501.214565ms 522.269829ms 547.857507ms 550.37655ms 554.399133ms 562.77935ms 577.307175ms 580.383897ms 580.41154ms 580.521211ms 580.747409ms 584.457908ms 585.581629ms 586.228137ms 587.128108ms 596.582836ms 597.971166ms 597.999523ms 598.709892ms 609.164861ms 612.324792ms 613.607156ms 616.383372ms 617.196439ms 617.278234ms 619.330463ms 623.837022ms 624.922756ms 626.651038ms 629.983627ms 631.974852ms 633.259962ms 633.4868ms 633.681953ms 633.935756ms 638.528242ms 639.436253ms 640.176097ms 647.602941ms 650.365581ms 652.135938ms 659.806684ms 667.937529ms 671.335622ms 682.826392ms 700.219099ms 709.563507ms 721.16722ms 727.327523ms 745.29821ms 747.880747ms 748.536622ms 748.712061ms 748.788924ms 748.87994ms 749.143437ms 749.202508ms 749.246403ms 749.254612ms 749.265896ms 749.447366ms 749.47705ms 749.521362ms 749.521823ms 749.526386ms 749.606398ms 749.653891ms 749.742321ms 749.846264ms 749.863134ms 750.008758ms 750.224999ms 750.647989ms 750.819753ms 750.830968ms 751.237786ms 751.717427ms 751.834545ms 756.382406ms 757.43846ms 757.756613ms 758.171329ms 759.698475ms 778.922241ms 782.705288ms 782.967803ms 799.988579ms 800.506163ms 826.05332ms 828.176809ms 831.105769ms 878.241117ms 879.847444ms 882.483875ms 928.533042ms 929.742266ms 931.881395ms 974.102096ms 975.645266ms 979.408044ms 988.184114ms 988.611264ms 988.740919ms 989.09633ms 992.360248ms 1.025299759s 1.028857746s 1.07028329s 1.074372566s 1.118275642s 1.124455901s 1.16885813s 1.172239313s 1.173730882s 1.214170701s 1.254174283s 1.262672352s 1.875417131s 1.925513038s 1.970958988s 2.023637254s 2.044414427s 2.071069331s 2.09381764s 2.115477222s 2.142481897s 2.156702349s 2.192844248s 2.193403498s 2.193834002s 2.19514038s 2.243082285s]
Feb  7 03:14:50.315: INFO: 50 %ile: 633.4868ms
Feb  7 03:14:50.315: INFO: 90 %ile: 1.172239313s
Feb  7 03:14:50.315: INFO: 99 %ile: 2.19514038s
Feb  7 03:14:50.315: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:14:50.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-ts4kt" for this suite.
Feb  7 03:15:08.395: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:15:08.459: INFO: namespace: e2e-tests-svc-latency-ts4kt, resource: bindings, ignored listing per whitelist
Feb  7 03:15:08.492: INFO: namespace e2e-tests-svc-latency-ts4kt deletion completed in 18.112677026s

• [SLOW TEST:28.906 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:15:08.492: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Feb  7 03:15:08.552: INFO: Waiting up to 5m0s for pod "pod-92a002c0-2a86-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-emptydir-qz8sj" to be "success or failure"
Feb  7 03:15:08.554: INFO: Pod "pod-92a002c0-2a86-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.828941ms
Feb  7 03:15:10.557: INFO: Pod "pod-92a002c0-2a86-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004590194s
STEP: Saw pod success
Feb  7 03:15:10.557: INFO: Pod "pod-92a002c0-2a86-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:15:10.559: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod pod-92a002c0-2a86-11e9-87fe-baa4eca941e3 container test-container: <nil>
STEP: delete the pod
Feb  7 03:15:11.194: INFO: Waiting for pod pod-92a002c0-2a86-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:15:11.196: INFO: Pod pod-92a002c0-2a86-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:15:11.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-qz8sj" for this suite.
Feb  7 03:15:17.295: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:15:17.322: INFO: namespace: e2e-tests-emptydir-qz8sj, resource: bindings, ignored listing per whitelist
Feb  7 03:15:17.392: INFO: namespace e2e-tests-emptydir-qz8sj deletion completed in 6.108915192s

• [SLOW TEST:8.901 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:15:17.392: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-xfsl2
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-xfsl2
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-xfsl2
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-xfsl2
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-xfsl2
Feb  7 03:15:21.467: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-xfsl2, name: ss-0, uid: 9a299c47-2a86-11e9-927c-4a513db42ba3, status phase: Failed. Waiting for statefulset controller to delete.
Feb  7 03:15:21.483: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-xfsl2, name: ss-0, uid: 9a299c47-2a86-11e9-927c-4a513db42ba3, status phase: Failed. Waiting for statefulset controller to delete.
Feb  7 03:15:21.488: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-xfsl2
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-xfsl2
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-xfsl2 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb  7 03:15:23.665: INFO: Deleting all statefulset in ns e2e-tests-statefulset-xfsl2
Feb  7 03:15:23.667: INFO: Scaling statefulset ss to 0
Feb  7 03:15:33.682: INFO: Waiting for statefulset status.replicas updated to 0
Feb  7 03:15:33.685: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:15:33.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-xfsl2" for this suite.
Feb  7 03:15:39.797: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:15:39.806: INFO: namespace: e2e-tests-statefulset-xfsl2, resource: bindings, ignored listing per whitelist
Feb  7 03:15:39.889: INFO: namespace e2e-tests-statefulset-xfsl2 deletion completed in 6.102089792s

• [SLOW TEST:22.497 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:15:39.889: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-a556b755-2a86-11e9-87fe-baa4eca941e3
STEP: Creating a pod to test consume configMaps
Feb  7 03:15:40.510: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a5578765-2a86-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-projected-fkx29" to be "success or failure"
Feb  7 03:15:40.585: INFO: Pod "pod-projected-configmaps-a5578765-2a86-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 75.391324ms
Feb  7 03:15:42.588: INFO: Pod "pod-projected-configmaps-a5578765-2a86-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.078051154s
Feb  7 03:15:44.595: INFO: Pod "pod-projected-configmaps-a5578765-2a86-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.085045307s
STEP: Saw pod success
Feb  7 03:15:44.595: INFO: Pod "pod-projected-configmaps-a5578765-2a86-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:15:44.597: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod pod-projected-configmaps-a5578765-2a86-11e9-87fe-baa4eca941e3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  7 03:15:44.638: INFO: Waiting for pod pod-projected-configmaps-a5578765-2a86-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:15:44.640: INFO: Pod pod-projected-configmaps-a5578765-2a86-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:15:44.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fkx29" for this suite.
Feb  7 03:15:50.686: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:15:50.724: INFO: namespace: e2e-tests-projected-fkx29, resource: bindings, ignored listing per whitelist
Feb  7 03:15:51.085: INFO: namespace e2e-tests-projected-fkx29 deletion completed in 6.442085481s

• [SLOW TEST:11.196 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:15:51.085: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1527
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb  7 03:15:51.847: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-n5t8g'
Feb  7 03:15:51.925: INFO: stderr: ""
Feb  7 03:15:51.925: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1532
Feb  7 03:15:51.927: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-n5t8g'
Feb  7 03:15:54.233: INFO: stderr: ""
Feb  7 03:15:54.233: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:15:54.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-n5t8g" for this suite.
Feb  7 03:16:00.383: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:16:00.447: INFO: namespace: e2e-tests-kubectl-n5t8g, resource: bindings, ignored listing per whitelist
Feb  7 03:16:00.479: INFO: namespace e2e-tests-kubectl-n5t8g deletion completed in 6.242756335s

• [SLOW TEST:9.394 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:16:00.479: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Feb  7 03:16:00.525: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb  7 03:16:00.531: INFO: Waiting for terminating namespaces to be deleted...
Feb  7 03:16:00.533: INFO: 
Logging pods the kubelet thinks is on node kube-node-0-kubelet.devkubernetes01.mesos before test
Feb  7 03:16:00.538: INFO: calico-node-n2c9f from kube-system started at 2019-02-07 02:26:23 +0000 UTC (2 container statuses recorded)
Feb  7 03:16:00.538: INFO: 	Container calico-node ready: true, restart count 0
Feb  7 03:16:00.538: INFO: 	Container install-cni ready: true, restart count 0
Feb  7 03:16:00.538: INFO: sonobuoy-systemd-logs-daemon-set-3418c9e540594be1-n22q8 from heptio-sonobuoy started at 2019-02-07 02:33:29 +0000 UTC (2 container statuses recorded)
Feb  7 03:16:00.538: INFO: 	Container sonobuoy-systemd-logs-config ready: false, restart count 13
Feb  7 03:16:00.538: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  7 03:16:00.538: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-07 02:33:25 +0000 UTC (1 container statuses recorded)
Feb  7 03:16:00.538: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb  7 03:16:00.538: INFO: kube-proxy-kube-node-0-kubelet.devkubernetes01.mesos from kube-system started at <nil> (0 container statuses recorded)
Feb  7 03:16:00.538: INFO: local-dns-dispatcher-kube-node-0-kubelet.devkubernetes01.mesos from kube-system started at <nil> (0 container statuses recorded)
Feb  7 03:16:00.538: INFO: 
Logging pods the kubelet thinks is on node kube-node-1-kubelet.devkubernetes01.mesos before test
Feb  7 03:16:00.543: INFO: coredns-fb6c4f575-rzxqz from kube-system started at 2019-02-07 02:26:43 +0000 UTC (1 container statuses recorded)
Feb  7 03:16:00.543: INFO: 	Container coredns ready: true, restart count 0
Feb  7 03:16:00.543: INFO: sonobuoy-systemd-logs-daemon-set-3418c9e540594be1-cx7gt from heptio-sonobuoy started at 2019-02-07 02:33:29 +0000 UTC (2 container statuses recorded)
Feb  7 03:16:00.543: INFO: 	Container sonobuoy-systemd-logs-config ready: false, restart count 13
Feb  7 03:16:00.543: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  7 03:16:00.543: INFO: calico-node-5snr5 from kube-system started at 2019-02-07 02:26:23 +0000 UTC (2 container statuses recorded)
Feb  7 03:16:00.543: INFO: 	Container calico-node ready: true, restart count 0
Feb  7 03:16:00.543: INFO: 	Container install-cni ready: true, restart count 0
Feb  7 03:16:00.543: INFO: sonobuoy-e2e-job-0cc94a58d02847bf from heptio-sonobuoy started at 2019-02-07 02:33:29 +0000 UTC (2 container statuses recorded)
Feb  7 03:16:00.543: INFO: 	Container e2e ready: true, restart count 0
Feb  7 03:16:00.543: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  7 03:16:00.543: INFO: kube-proxy-kube-node-1-kubelet.devkubernetes01.mesos from kube-system started at <nil> (0 container statuses recorded)
Feb  7 03:16:00.543: INFO: local-dns-dispatcher-kube-node-1-kubelet.devkubernetes01.mesos from kube-system started at <nil> (0 container statuses recorded)
Feb  7 03:16:00.543: INFO: 
Logging pods the kubelet thinks is on node kube-node-2-kubelet.devkubernetes01.mesos before test
Feb  7 03:16:00.547: INFO: kube-proxy-kube-node-2-kubelet.devkubernetes01.mesos from kube-system started at <nil> (0 container statuses recorded)
Feb  7 03:16:00.547: INFO: local-dns-dispatcher-kube-node-2-kubelet.devkubernetes01.mesos from kube-system started at <nil> (0 container statuses recorded)
Feb  7 03:16:00.547: INFO: calico-node-gmcd4 from kube-system started at 2019-02-07 02:26:17 +0000 UTC (2 container statuses recorded)
Feb  7 03:16:00.547: INFO: 	Container calico-node ready: true, restart count 0
Feb  7 03:16:00.547: INFO: 	Container install-cni ready: true, restart count 0
Feb  7 03:16:00.547: INFO: metrics-server-7ddfc7695-b8l5f from kube-system started at 2019-02-07 02:26:36 +0000 UTC (1 container statuses recorded)
Feb  7 03:16:00.547: INFO: 	Container metrics-server ready: true, restart count 0
Feb  7 03:16:00.547: INFO: coredns-fb6c4f575-8xlfk from kube-system started at 2019-02-07 02:26:36 +0000 UTC (1 container statuses recorded)
Feb  7 03:16:00.547: INFO: 	Container coredns ready: true, restart count 0
Feb  7 03:16:00.547: INFO: kubernetes-dashboard-6d87d489d4-d8zr7 from kube-system started at 2019-02-07 02:26:36 +0000 UTC (1 container statuses recorded)
Feb  7 03:16:00.547: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Feb  7 03:16:00.547: INFO: sonobuoy-systemd-logs-daemon-set-3418c9e540594be1-dd7p4 from heptio-sonobuoy started at 2019-02-07 02:33:29 +0000 UTC (2 container statuses recorded)
Feb  7 03:16:00.547: INFO: 	Container sonobuoy-systemd-logs-config ready: false, restart count 13
Feb  7 03:16:00.547: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-b2d7a552-2a86-11e9-87fe-baa4eca941e3 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-b2d7a552-2a86-11e9-87fe-baa4eca941e3 off the node kube-node-0-kubelet.devkubernetes01.mesos
STEP: verifying the node doesn't have the label kubernetes.io/e2e-b2d7a552-2a86-11e9-87fe-baa4eca941e3
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:16:04.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-rfdx4" for this suite.
Feb  7 03:16:24.663: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:16:24.673: INFO: namespace: e2e-tests-sched-pred-rfdx4, resource: bindings, ignored listing per whitelist
Feb  7 03:16:25.086: INFO: namespace e2e-tests-sched-pred-rfdx4 deletion completed in 20.433686585s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:24.607 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:16:25.086: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:16:31.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-gnx6v" for this suite.
Feb  7 03:16:37.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:16:37.600: INFO: namespace: e2e-tests-namespaces-gnx6v, resource: bindings, ignored listing per whitelist
Feb  7 03:16:37.685: INFO: namespace e2e-tests-namespaces-gnx6v deletion completed in 6.382314192s
STEP: Destroying namespace "e2e-tests-nsdeletetest-2mp75" for this suite.
Feb  7 03:16:37.687: INFO: Namespace e2e-tests-nsdeletetest-2mp75 was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-zlp57" for this suite.
Feb  7 03:16:43.868: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:16:43.892: INFO: namespace: e2e-tests-nsdeletetest-zlp57, resource: bindings, ignored listing per whitelist
Feb  7 03:16:43.977: INFO: namespace e2e-tests-nsdeletetest-zlp57 deletion completed in 6.29005636s

• [SLOW TEST:18.891 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:16:43.977: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Feb  7 03:16:46.048: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-cb8a118c-2a86-11e9-87fe-baa4eca941e3,GenerateName:,Namespace:e2e-tests-events-4x5rx,SelfLink:/api/v1/namespaces/e2e-tests-events-4x5rx/pods/send-events-cb8a118c-2a86-11e9-87fe-baa4eca941e3,UID:cb89fa42-2a86-11e9-809d-e6a419c8531a,ResourceVersion:13556,Generation:0,CreationTimestamp:2019-02-07 03:16:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 31840945,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.5.119/32,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4mqbn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4mqbn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-4mqbn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-node-0-kubelet.devkubernetes01.mesos,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001973540} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001973560}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:16:44 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:16:45 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:16:45 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:16:43 +0000 UTC  }],Message:,Reason:,HostIP:9.0.1.4,PodIP:192.168.5.119,StartTime:2019-02-07 03:16:44 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-02-07 03:16:44 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://6c384cd5a9abfb27f6522194cde7a9f061f6fd1f08b53995f9b0fb232e857041}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Feb  7 03:16:48.052: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Feb  7 03:16:50.059: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:16:50.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-4x5rx" for this suite.
Feb  7 03:17:28.693: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:17:28.824: INFO: namespace: e2e-tests-events-4x5rx, resource: bindings, ignored listing per whitelist
Feb  7 03:17:28.877: INFO: namespace e2e-tests-events-4x5rx deletion completed in 38.808802853s

• [SLOW TEST:44.899 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:17:28.877: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb  7 03:17:28.930: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-cjvwb'
Feb  7 03:17:29.014: INFO: stderr: ""
Feb  7 03:17:29.014: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Feb  7 03:17:34.064: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-cjvwb -o json'
Feb  7 03:17:34.125: INFO: stderr: ""
Feb  7 03:17:34.125: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"192.168.5.120/32\"\n        },\n        \"creationTimestamp\": \"2019-02-07T03:17:28Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-cjvwb\",\n        \"resourceVersion\": \"13669\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-cjvwb/pods/e2e-test-nginx-pod\",\n        \"uid\": \"e64d49bd-2a86-11e9-8201-3a104fa10389\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-62z8k\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"kube-node-0-kubelet.devkubernetes01.mesos\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-62z8k\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-62z8k\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-07T03:17:29Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-07T03:17:29Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-07T03:17:29Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-07T03:17:28Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://9f768e0101a38bbcbc7cb2d612d6ba97a6fa6c19e4b3456cf002df9f28069c7f\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-02-07T03:17:29Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"9.0.1.4\",\n        \"phase\": \"Running\",\n        \"podIP\": \"192.168.5.120\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-02-07T03:17:29Z\"\n    }\n}\n"
STEP: replace the image in the pod
Feb  7 03:17:34.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 replace -f - --namespace=e2e-tests-kubectl-cjvwb'
Feb  7 03:17:34.255: INFO: stderr: ""
Feb  7 03:17:34.255: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
Feb  7 03:17:34.257: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-cjvwb'
Feb  7 03:17:35.916: INFO: stderr: ""
Feb  7 03:17:35.916: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:17:35.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-cjvwb" for this suite.
Feb  7 03:17:43.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:17:43.888: INFO: namespace: e2e-tests-kubectl-cjvwb, resource: bindings, ignored listing per whitelist
Feb  7 03:17:43.924: INFO: namespace e2e-tests-kubectl-cjvwb deletion completed in 6.422217588s

• [SLOW TEST:15.047 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:17:43.924: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-ef44c6b7-2a86-11e9-87fe-baa4eca941e3
STEP: Creating a pod to test consume configMaps
Feb  7 03:17:43.986: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ef45867d-2a86-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-projected-knq5j" to be "success or failure"
Feb  7 03:17:43.988: INFO: Pod "pod-projected-configmaps-ef45867d-2a86-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.174544ms
Feb  7 03:17:45.991: INFO: Pod "pod-projected-configmaps-ef45867d-2a86-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004941646s
STEP: Saw pod success
Feb  7 03:17:45.991: INFO: Pod "pod-projected-configmaps-ef45867d-2a86-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:17:45.993: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod pod-projected-configmaps-ef45867d-2a86-11e9-87fe-baa4eca941e3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  7 03:17:46.008: INFO: Waiting for pod pod-projected-configmaps-ef45867d-2a86-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:17:46.010: INFO: Pod pod-projected-configmaps-ef45867d-2a86-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:17:46.010: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-knq5j" for this suite.
Feb  7 03:17:53.494: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:17:53.615: INFO: namespace: e2e-tests-projected-knq5j, resource: bindings, ignored listing per whitelist
Feb  7 03:17:53.622: INFO: namespace e2e-tests-projected-knq5j deletion completed in 7.606876987s

• [SLOW TEST:9.698 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:17:53.622: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Feb  7 03:17:55.907: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-f50c6364-2a86-11e9-87fe-baa4eca941e3", GenerateName:"", Namespace:"e2e-tests-pods-qrc5w", SelfLink:"/api/v1/namespaces/e2e-tests-pods-qrc5w/pods/pod-submit-remove-f50c6364-2a86-11e9-87fe-baa4eca941e3", UID:"f52da814-2a86-11e9-809d-e6a419c8531a", ResourceVersion:"13773", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63685106273, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"672489791"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"192.168.5.122/32"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-kdf7t", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001907040), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-kdf7t", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc002747b18), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"kube-node-0-kubelet.devkubernetes01.mesos", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0027e1800), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002747b50)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002747b70)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc002747b78), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc002747b7c)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685106273, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685106275, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685106275, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685106273, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"9.0.1.4", PodIP:"192.168.5.122", StartTime:(*v1.Time)(0xc0027aad80), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc0027aada0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632", ContainerID:"docker://c1c117c24eac577b063bfbc0d0bd57a84e79d7f45f9e2087f565cb702b32d650"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:18:03.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-qrc5w" for this suite.
Feb  7 03:18:09.470: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:18:09.490: INFO: namespace: e2e-tests-pods-qrc5w, resource: bindings, ignored listing per whitelist
Feb  7 03:18:09.598: INFO: namespace e2e-tests-pods-qrc5w deletion completed in 6.138050514s

• [SLOW TEST:15.976 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:18:09.598: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Feb  7 03:18:09.658: INFO: Waiting up to 5m0s for pod "client-containers-fe926554-2a86-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-containers-c9ssg" to be "success or failure"
Feb  7 03:18:09.660: INFO: Pod "client-containers-fe926554-2a86-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.708802ms
Feb  7 03:18:11.667: INFO: Pod "client-containers-fe926554-2a86-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008919584s
STEP: Saw pod success
Feb  7 03:18:11.667: INFO: Pod "client-containers-fe926554-2a86-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:18:11.669: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod client-containers-fe926554-2a86-11e9-87fe-baa4eca941e3 container test-container: <nil>
STEP: delete the pod
Feb  7 03:18:11.683: INFO: Waiting for pod client-containers-fe926554-2a86-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:18:11.685: INFO: Pod client-containers-fe926554-2a86-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:18:11.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-c9ssg" for this suite.
Feb  7 03:18:18.045: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:18:18.067: INFO: namespace: e2e-tests-containers-c9ssg, resource: bindings, ignored listing per whitelist
Feb  7 03:18:18.141: INFO: namespace e2e-tests-containers-c9ssg deletion completed in 6.453044223s

• [SLOW TEST:8.544 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:18:18.141: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  7 03:18:18.206: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Feb  7 03:18:18.214: INFO: Number of nodes with available pods: 0
Feb  7 03:18:18.214: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Feb  7 03:18:18.227: INFO: Number of nodes with available pods: 0
Feb  7 03:18:18.227: INFO: Node kube-node-0-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:18:19.229: INFO: Number of nodes with available pods: 0
Feb  7 03:18:19.229: INFO: Node kube-node-0-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:18:20.230: INFO: Number of nodes with available pods: 1
Feb  7 03:18:20.230: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Feb  7 03:18:20.243: INFO: Number of nodes with available pods: 1
Feb  7 03:18:20.243: INFO: Number of running nodes: 0, number of available pods: 1
Feb  7 03:18:21.246: INFO: Number of nodes with available pods: 0
Feb  7 03:18:21.246: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Feb  7 03:18:21.253: INFO: Number of nodes with available pods: 0
Feb  7 03:18:21.254: INFO: Node kube-node-0-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:18:22.278: INFO: Number of nodes with available pods: 0
Feb  7 03:18:22.278: INFO: Node kube-node-0-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:18:23.256: INFO: Number of nodes with available pods: 0
Feb  7 03:18:23.256: INFO: Node kube-node-0-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:18:24.256: INFO: Number of nodes with available pods: 0
Feb  7 03:18:24.256: INFO: Node kube-node-0-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:18:25.256: INFO: Number of nodes with available pods: 0
Feb  7 03:18:25.256: INFO: Node kube-node-0-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:18:26.280: INFO: Number of nodes with available pods: 0
Feb  7 03:18:26.280: INFO: Node kube-node-0-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:18:27.256: INFO: Number of nodes with available pods: 0
Feb  7 03:18:27.256: INFO: Node kube-node-0-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:18:28.256: INFO: Number of nodes with available pods: 0
Feb  7 03:18:28.256: INFO: Node kube-node-0-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:18:29.256: INFO: Number of nodes with available pods: 0
Feb  7 03:18:29.256: INFO: Node kube-node-0-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:18:30.257: INFO: Number of nodes with available pods: 0
Feb  7 03:18:30.257: INFO: Node kube-node-0-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:18:31.257: INFO: Number of nodes with available pods: 0
Feb  7 03:18:31.257: INFO: Node kube-node-0-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:18:32.256: INFO: Number of nodes with available pods: 0
Feb  7 03:18:32.256: INFO: Node kube-node-0-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:18:33.261: INFO: Number of nodes with available pods: 0
Feb  7 03:18:33.261: INFO: Node kube-node-0-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:18:34.257: INFO: Number of nodes with available pods: 0
Feb  7 03:18:34.257: INFO: Node kube-node-0-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:18:35.256: INFO: Number of nodes with available pods: 0
Feb  7 03:18:35.256: INFO: Node kube-node-0-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:18:36.256: INFO: Number of nodes with available pods: 0
Feb  7 03:18:36.257: INFO: Node kube-node-0-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:18:37.256: INFO: Number of nodes with available pods: 0
Feb  7 03:18:37.256: INFO: Node kube-node-0-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:18:38.340: INFO: Number of nodes with available pods: 0
Feb  7 03:18:38.340: INFO: Node kube-node-0-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:18:39.257: INFO: Number of nodes with available pods: 0
Feb  7 03:18:39.257: INFO: Node kube-node-0-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:18:40.257: INFO: Number of nodes with available pods: 0
Feb  7 03:18:40.257: INFO: Node kube-node-0-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:18:41.278: INFO: Number of nodes with available pods: 0
Feb  7 03:18:41.278: INFO: Node kube-node-0-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:18:42.278: INFO: Number of nodes with available pods: 0
Feb  7 03:18:42.278: INFO: Node kube-node-0-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:18:43.256: INFO: Number of nodes with available pods: 0
Feb  7 03:18:43.256: INFO: Node kube-node-0-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:18:44.277: INFO: Number of nodes with available pods: 0
Feb  7 03:18:44.277: INFO: Node kube-node-0-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:18:45.257: INFO: Number of nodes with available pods: 0
Feb  7 03:18:45.257: INFO: Node kube-node-0-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:18:46.256: INFO: Number of nodes with available pods: 0
Feb  7 03:18:46.256: INFO: Node kube-node-0-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:18:47.256: INFO: Number of nodes with available pods: 0
Feb  7 03:18:47.256: INFO: Node kube-node-0-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:18:48.257: INFO: Number of nodes with available pods: 0
Feb  7 03:18:48.257: INFO: Node kube-node-0-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:18:49.277: INFO: Number of nodes with available pods: 0
Feb  7 03:18:49.277: INFO: Node kube-node-0-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:18:50.277: INFO: Number of nodes with available pods: 0
Feb  7 03:18:50.277: INFO: Node kube-node-0-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:18:51.257: INFO: Number of nodes with available pods: 0
Feb  7 03:18:51.257: INFO: Node kube-node-0-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:18:52.257: INFO: Number of nodes with available pods: 0
Feb  7 03:18:52.257: INFO: Node kube-node-0-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:18:53.256: INFO: Number of nodes with available pods: 0
Feb  7 03:18:53.256: INFO: Node kube-node-0-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:18:54.280: INFO: Number of nodes with available pods: 0
Feb  7 03:18:54.280: INFO: Node kube-node-0-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:18:55.492: INFO: Number of nodes with available pods: 0
Feb  7 03:18:55.492: INFO: Node kube-node-0-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:18:56.256: INFO: Number of nodes with available pods: 1
Feb  7 03:18:56.257: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-jpg7w, will wait for the garbage collector to delete the pods
Feb  7 03:18:56.320: INFO: Deleting DaemonSet.extensions daemon-set took: 5.847412ms
Feb  7 03:18:56.420: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.256334ms
Feb  7 03:19:29.827: INFO: Number of nodes with available pods: 0
Feb  7 03:19:29.827: INFO: Number of running nodes: 0, number of available pods: 0
Feb  7 03:19:29.830: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-jpg7w/daemonsets","resourceVersion":"14052"},"items":null}

Feb  7 03:19:29.831: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-jpg7w/pods","resourceVersion":"14052"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:19:29.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-jpg7w" for this suite.
Feb  7 03:19:36.114: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:19:36.933: INFO: namespace: e2e-tests-daemonsets-jpg7w, resource: bindings, ignored listing per whitelist
Feb  7 03:19:36.940: INFO: namespace e2e-tests-daemonsets-jpg7w deletion completed in 7.052811053s

• [SLOW TEST:78.798 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:19:36.940: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Feb  7 03:19:36.991: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Feb  7 03:19:36.991: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 create -f - --namespace=e2e-tests-kubectl-scdks'
Feb  7 03:19:37.175: INFO: stderr: ""
Feb  7 03:19:37.175: INFO: stdout: "service/redis-slave created\n"
Feb  7 03:19:37.175: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Feb  7 03:19:37.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 create -f - --namespace=e2e-tests-kubectl-scdks'
Feb  7 03:19:38.228: INFO: stderr: ""
Feb  7 03:19:38.228: INFO: stdout: "service/redis-master created\n"
Feb  7 03:19:38.228: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Feb  7 03:19:38.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 create -f - --namespace=e2e-tests-kubectl-scdks'
Feb  7 03:19:38.366: INFO: stderr: ""
Feb  7 03:19:38.366: INFO: stdout: "service/frontend created\n"
Feb  7 03:19:38.366: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Feb  7 03:19:38.366: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 create -f - --namespace=e2e-tests-kubectl-scdks'
Feb  7 03:19:38.500: INFO: stderr: ""
Feb  7 03:19:38.500: INFO: stdout: "deployment.extensions/frontend created\n"
Feb  7 03:19:38.500: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Feb  7 03:19:38.500: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 create -f - --namespace=e2e-tests-kubectl-scdks'
Feb  7 03:19:38.633: INFO: stderr: ""
Feb  7 03:19:38.633: INFO: stdout: "deployment.extensions/redis-master created\n"
Feb  7 03:19:38.634: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Feb  7 03:19:38.634: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 create -f - --namespace=e2e-tests-kubectl-scdks'
Feb  7 03:19:38.767: INFO: stderr: ""
Feb  7 03:19:38.768: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Feb  7 03:19:38.768: INFO: Waiting for all frontend pods to be Running.
Feb  7 03:19:53.818: INFO: Waiting for frontend to serve content.
Feb  7 03:19:58.842: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Feb  7 03:20:03.857: INFO: Trying to add a new entry to the guestbook.
Feb  7 03:20:03.866: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Feb  7 03:20:03.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-scdks'
Feb  7 03:20:04.307: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  7 03:20:04.307: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Feb  7 03:20:04.307: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-scdks'
Feb  7 03:20:04.587: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  7 03:20:04.587: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb  7 03:20:04.587: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-scdks'
Feb  7 03:20:04.666: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  7 03:20:04.666: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb  7 03:20:04.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-scdks'
Feb  7 03:20:04.734: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  7 03:20:04.734: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb  7 03:20:04.735: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-scdks'
Feb  7 03:20:04.809: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  7 03:20:04.809: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb  7 03:20:04.810: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-scdks'
Feb  7 03:20:04.884: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  7 03:20:04.884: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:20:04.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-scdks" for this suite.
Feb  7 03:20:49.451: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:20:49.520: INFO: namespace: e2e-tests-kubectl-scdks, resource: bindings, ignored listing per whitelist
Feb  7 03:20:50.058: INFO: namespace e2e-tests-kubectl-scdks deletion completed in 45.170328361s

• [SLOW TEST:73.118 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:20:50.058: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Feb  7 03:20:50.220: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-221081943 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:20:50.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ks4gr" for this suite.
Feb  7 03:20:56.285: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:20:56.317: INFO: namespace: e2e-tests-kubectl-ks4gr, resource: bindings, ignored listing per whitelist
Feb  7 03:20:56.427: INFO: namespace e2e-tests-kubectl-ks4gr deletion completed in 6.151737968s

• [SLOW TEST:6.369 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:20:56.427: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb  7 03:20:59.306: INFO: Successfully updated pod "labelsupdate622ff4ce-2a87-11e9-87fe-baa4eca941e3"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:21:03.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2j4ql" for this suite.
Feb  7 03:21:27.399: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:21:27.420: INFO: namespace: e2e-tests-projected-2j4ql, resource: bindings, ignored listing per whitelist
Feb  7 03:21:27.495: INFO: namespace e2e-tests-projected-2j4ql deletion completed in 24.106971193s

• [SLOW TEST:31.068 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:21:27.495: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb  7 03:21:31.586: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb  7 03:21:31.588: INFO: Pod pod-with-prestop-http-hook still exists
Feb  7 03:21:33.588: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb  7 03:21:33.595: INFO: Pod pod-with-prestop-http-hook still exists
Feb  7 03:21:35.588: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb  7 03:21:35.591: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:21:35.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-65nlh" for this suite.
Feb  7 03:21:59.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:21:59.669: INFO: namespace: e2e-tests-container-lifecycle-hook-65nlh, resource: bindings, ignored listing per whitelist
Feb  7 03:21:59.705: INFO: namespace e2e-tests-container-lifecycle-hook-65nlh deletion completed in 24.104585529s

• [SLOW TEST:32.210 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:21:59.705: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-87b9aee6-2a87-11e9-87fe-baa4eca941e3
STEP: Creating a pod to test consume configMaps
Feb  7 03:21:59.766: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-87ba6649-2a87-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-projected-xf4qv" to be "success or failure"
Feb  7 03:21:59.768: INFO: Pod "pod-projected-configmaps-87ba6649-2a87-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.959868ms
Feb  7 03:22:01.771: INFO: Pod "pod-projected-configmaps-87ba6649-2a87-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004862688s
STEP: Saw pod success
Feb  7 03:22:01.771: INFO: Pod "pod-projected-configmaps-87ba6649-2a87-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:22:01.773: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod pod-projected-configmaps-87ba6649-2a87-11e9-87fe-baa4eca941e3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  7 03:22:01.788: INFO: Waiting for pod pod-projected-configmaps-87ba6649-2a87-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:22:01.790: INFO: Pod pod-projected-configmaps-87ba6649-2a87-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:22:01.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xf4qv" for this suite.
Feb  7 03:22:07.804: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:22:07.972: INFO: namespace: e2e-tests-projected-xf4qv, resource: bindings, ignored listing per whitelist
Feb  7 03:22:07.981: INFO: namespace e2e-tests-projected-xf4qv deletion completed in 6.186965968s

• [SLOW TEST:8.275 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:22:07.981: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb  7 03:22:08.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-4dlz6'
Feb  7 03:22:08.095: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb  7 03:22:08.095: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Feb  7 03:22:08.100: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-b6cjx]
Feb  7 03:22:08.100: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-b6cjx" in namespace "e2e-tests-kubectl-4dlz6" to be "running and ready"
Feb  7 03:22:08.104: INFO: Pod "e2e-test-nginx-rc-b6cjx": Phase="Pending", Reason="", readiness=false. Elapsed: 3.58186ms
Feb  7 03:22:10.106: INFO: Pod "e2e-test-nginx-rc-b6cjx": Phase="Running", Reason="", readiness=true. Elapsed: 2.0062652s
Feb  7 03:22:10.106: INFO: Pod "e2e-test-nginx-rc-b6cjx" satisfied condition "running and ready"
Feb  7 03:22:10.106: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-b6cjx]
Feb  7 03:22:10.106: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-4dlz6'
Feb  7 03:22:10.279: INFO: stderr: ""
Feb  7 03:22:10.279: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1303
Feb  7 03:22:10.279: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-4dlz6'
Feb  7 03:22:10.350: INFO: stderr: ""
Feb  7 03:22:10.350: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:22:10.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-4dlz6" for this suite.
Feb  7 03:22:32.365: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:22:33.034: INFO: namespace: e2e-tests-kubectl-4dlz6, resource: bindings, ignored listing per whitelist
Feb  7 03:22:33.041: INFO: namespace e2e-tests-kubectl-4dlz6 deletion completed in 22.684647757s

• [SLOW TEST:25.060 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:22:33.041: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb  7 03:22:33.371: INFO: Waiting up to 5m0s for pod "pod-9b98e1df-2a87-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-emptydir-6szgv" to be "success or failure"
Feb  7 03:22:33.373: INFO: Pod "pod-9b98e1df-2a87-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.064987ms
Feb  7 03:22:35.376: INFO: Pod "pod-9b98e1df-2a87-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004983441s
STEP: Saw pod success
Feb  7 03:22:35.376: INFO: Pod "pod-9b98e1df-2a87-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:22:35.378: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod pod-9b98e1df-2a87-11e9-87fe-baa4eca941e3 container test-container: <nil>
STEP: delete the pod
Feb  7 03:22:35.391: INFO: Waiting for pod pod-9b98e1df-2a87-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:22:35.393: INFO: Pod pod-9b98e1df-2a87-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:22:35.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-6szgv" for this suite.
Feb  7 03:22:41.406: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:22:41.568: INFO: namespace: e2e-tests-emptydir-6szgv, resource: bindings, ignored listing per whitelist
Feb  7 03:22:41.580: INFO: namespace e2e-tests-emptydir-6szgv deletion completed in 6.184520947s

• [SLOW TEST:8.540 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:22:41.581: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb  7 03:22:41.642: INFO: Waiting up to 5m0s for pod "pod-a0afed34-2a87-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-emptydir-6mtp4" to be "success or failure"
Feb  7 03:22:41.644: INFO: Pod "pod-a0afed34-2a87-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.905187ms
Feb  7 03:22:43.647: INFO: Pod "pod-a0afed34-2a87-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005368052s
STEP: Saw pod success
Feb  7 03:22:43.647: INFO: Pod "pod-a0afed34-2a87-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:22:43.650: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod pod-a0afed34-2a87-11e9-87fe-baa4eca941e3 container test-container: <nil>
STEP: delete the pod
Feb  7 03:22:43.698: INFO: Waiting for pod pod-a0afed34-2a87-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:22:43.700: INFO: Pod pod-a0afed34-2a87-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:22:43.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-6mtp4" for this suite.
Feb  7 03:22:49.791: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:22:49.852: INFO: namespace: e2e-tests-emptydir-6mtp4, resource: bindings, ignored listing per whitelist
Feb  7 03:22:49.931: INFO: namespace e2e-tests-emptydir-6mtp4 deletion completed in 6.227948933s

• [SLOW TEST:8.351 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:22:49.931: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-8tbvc
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Feb  7 03:22:50.706: INFO: Found 0 stateful pods, waiting for 3
Feb  7 03:23:00.714: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb  7 03:23:00.714: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb  7 03:23:00.714: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Feb  7 03:23:00.721: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 exec --namespace=e2e-tests-statefulset-8tbvc ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  7 03:23:00.936: INFO: stderr: ""
Feb  7 03:23:00.937: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  7 03:23:00.937: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Feb  7 03:23:11.487: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Feb  7 03:23:21.503: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 exec --namespace=e2e-tests-statefulset-8tbvc ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  7 03:23:21.649: INFO: stderr: ""
Feb  7 03:23:21.649: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  7 03:23:21.649: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  7 03:23:32.559: INFO: Waiting for StatefulSet e2e-tests-statefulset-8tbvc/ss2 to complete update
Feb  7 03:23:32.559: INFO: Waiting for Pod e2e-tests-statefulset-8tbvc/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb  7 03:23:32.559: INFO: Waiting for Pod e2e-tests-statefulset-8tbvc/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb  7 03:23:42.649: INFO: Waiting for StatefulSet e2e-tests-statefulset-8tbvc/ss2 to complete update
Feb  7 03:23:42.649: INFO: Waiting for Pod e2e-tests-statefulset-8tbvc/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb  7 03:23:52.565: INFO: Waiting for StatefulSet e2e-tests-statefulset-8tbvc/ss2 to complete update
Feb  7 03:23:52.565: INFO: Waiting for Pod e2e-tests-statefulset-8tbvc/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Feb  7 03:24:02.569: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 exec --namespace=e2e-tests-statefulset-8tbvc ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  7 03:24:02.718: INFO: stderr: ""
Feb  7 03:24:02.719: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  7 03:24:02.719: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  7 03:24:12.772: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Feb  7 03:24:22.789: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 exec --namespace=e2e-tests-statefulset-8tbvc ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  7 03:24:22.938: INFO: stderr: ""
Feb  7 03:24:22.938: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  7 03:24:22.938: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  7 03:24:32.958: INFO: Waiting for StatefulSet e2e-tests-statefulset-8tbvc/ss2 to complete update
Feb  7 03:24:32.958: INFO: Waiting for Pod e2e-tests-statefulset-8tbvc/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Feb  7 03:24:32.958: INFO: Waiting for Pod e2e-tests-statefulset-8tbvc/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Feb  7 03:24:32.958: INFO: Waiting for Pod e2e-tests-statefulset-8tbvc/ss2-2 to have revision ss2-787997d666 update revision ss2-c79899b9
Feb  7 03:24:43.402: INFO: Waiting for StatefulSet e2e-tests-statefulset-8tbvc/ss2 to complete update
Feb  7 03:24:43.402: INFO: Waiting for Pod e2e-tests-statefulset-8tbvc/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Feb  7 03:24:43.402: INFO: Waiting for Pod e2e-tests-statefulset-8tbvc/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Feb  7 03:24:52.964: INFO: Waiting for StatefulSet e2e-tests-statefulset-8tbvc/ss2 to complete update
Feb  7 03:24:52.964: INFO: Waiting for Pod e2e-tests-statefulset-8tbvc/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb  7 03:25:03.348: INFO: Deleting all statefulset in ns e2e-tests-statefulset-8tbvc
Feb  7 03:25:03.350: INFO: Scaling statefulset ss2 to 0
Feb  7 03:25:33.366: INFO: Waiting for statefulset status.replicas updated to 0
Feb  7 03:25:33.368: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:25:33.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-8tbvc" for this suite.
Feb  7 03:25:41.391: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:25:41.694: INFO: namespace: e2e-tests-statefulset-8tbvc, resource: bindings, ignored listing per whitelist
Feb  7 03:25:41.728: INFO: namespace e2e-tests-statefulset-8tbvc deletion completed in 8.346549296s

• [SLOW TEST:171.797 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:25:41.728: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:25:41.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-xhbxt" for this suite.
Feb  7 03:26:03.859: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:26:03.901: INFO: namespace: e2e-tests-pods-xhbxt, resource: bindings, ignored listing per whitelist
Feb  7 03:26:03.957: INFO: namespace e2e-tests-pods-xhbxt deletion completed in 22.162809169s

• [SLOW TEST:22.228 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:26:03.957: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-w8ms
STEP: Creating a pod to test atomic-volume-subpath
Feb  7 03:26:04.024: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-w8ms" in namespace "e2e-tests-subpath-9wn4v" to be "success or failure"
Feb  7 03:26:04.026: INFO: Pod "pod-subpath-test-configmap-w8ms": Phase="Pending", Reason="", readiness=false. Elapsed: 1.973243ms
Feb  7 03:26:06.030: INFO: Pod "pod-subpath-test-configmap-w8ms": Phase="Running", Reason="", readiness=false. Elapsed: 2.005112408s
Feb  7 03:26:08.037: INFO: Pod "pod-subpath-test-configmap-w8ms": Phase="Running", Reason="", readiness=false. Elapsed: 4.012405426s
Feb  7 03:26:10.040: INFO: Pod "pod-subpath-test-configmap-w8ms": Phase="Running", Reason="", readiness=false. Elapsed: 6.015496806s
Feb  7 03:26:12.043: INFO: Pod "pod-subpath-test-configmap-w8ms": Phase="Running", Reason="", readiness=false. Elapsed: 8.01854216s
Feb  7 03:26:14.046: INFO: Pod "pod-subpath-test-configmap-w8ms": Phase="Running", Reason="", readiness=false. Elapsed: 10.021580979s
Feb  7 03:26:16.049: INFO: Pod "pod-subpath-test-configmap-w8ms": Phase="Running", Reason="", readiness=false. Elapsed: 12.024557285s
Feb  7 03:26:18.056: INFO: Pod "pod-subpath-test-configmap-w8ms": Phase="Running", Reason="", readiness=false. Elapsed: 14.031684801s
Feb  7 03:26:20.059: INFO: Pod "pod-subpath-test-configmap-w8ms": Phase="Running", Reason="", readiness=false. Elapsed: 16.034846606s
Feb  7 03:26:22.062: INFO: Pod "pod-subpath-test-configmap-w8ms": Phase="Running", Reason="", readiness=false. Elapsed: 18.037964323s
Feb  7 03:26:24.065: INFO: Pod "pod-subpath-test-configmap-w8ms": Phase="Running", Reason="", readiness=false. Elapsed: 20.040968978s
Feb  7 03:26:26.068: INFO: Pod "pod-subpath-test-configmap-w8ms": Phase="Running", Reason="", readiness=false. Elapsed: 22.044087778s
Feb  7 03:26:28.076: INFO: Pod "pod-subpath-test-configmap-w8ms": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.051274762s
STEP: Saw pod success
Feb  7 03:26:28.076: INFO: Pod "pod-subpath-test-configmap-w8ms" satisfied condition "success or failure"
Feb  7 03:26:28.078: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod pod-subpath-test-configmap-w8ms container test-container-subpath-configmap-w8ms: <nil>
STEP: delete the pod
Feb  7 03:26:28.165: INFO: Waiting for pod pod-subpath-test-configmap-w8ms to disappear
Feb  7 03:26:28.167: INFO: Pod pod-subpath-test-configmap-w8ms no longer exists
STEP: Deleting pod pod-subpath-test-configmap-w8ms
Feb  7 03:26:28.167: INFO: Deleting pod "pod-subpath-test-configmap-w8ms" in namespace "e2e-tests-subpath-9wn4v"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:26:28.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-9wn4v" for this suite.
Feb  7 03:26:34.183: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:26:34.204: INFO: namespace: e2e-tests-subpath-9wn4v, resource: bindings, ignored listing per whitelist
Feb  7 03:26:34.281: INFO: namespace e2e-tests-subpath-9wn4v deletion completed in 6.108648137s

• [SLOW TEST:30.324 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:26:34.281: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-tjvfb
Feb  7 03:26:36.346: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-tjvfb
STEP: checking the pod's current state and verifying that restartCount is present
Feb  7 03:26:36.348: INFO: Initial restart count of pod liveness-exec is 0
Feb  7 03:27:29.034: INFO: Restart count of pod e2e-tests-container-probe-tjvfb/liveness-exec is now 1 (52.685809584s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:27:29.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-tjvfb" for this suite.
Feb  7 03:27:37.548: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:27:37.661: INFO: namespace: e2e-tests-container-probe-tjvfb, resource: bindings, ignored listing per whitelist
Feb  7 03:27:37.726: INFO: namespace e2e-tests-container-probe-tjvfb deletion completed in 8.188040009s

• [SLOW TEST:63.444 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:27:37.726: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  7 03:27:37.777: INFO: Creating deployment "nginx-deployment"
Feb  7 03:27:37.782: INFO: Waiting for observed generation 1
Feb  7 03:27:39.856: INFO: Waiting for all required pods to come up
Feb  7 03:27:39.859: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Feb  7 03:27:41.865: INFO: Waiting for deployment "nginx-deployment" to complete
Feb  7 03:27:41.870: INFO: Updating deployment "nginx-deployment" with a non-existent image
Feb  7 03:27:41.877: INFO: Updating deployment nginx-deployment
Feb  7 03:27:41.877: INFO: Waiting for observed generation 2
Feb  7 03:27:43.883: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Feb  7 03:27:43.886: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Feb  7 03:27:43.888: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Feb  7 03:27:43.894: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Feb  7 03:27:43.894: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Feb  7 03:27:43.897: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Feb  7 03:27:43.901: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Feb  7 03:27:43.901: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Feb  7 03:27:43.907: INFO: Updating deployment nginx-deployment
Feb  7 03:27:43.907: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Feb  7 03:27:43.913: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Feb  7 03:27:43.915: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb  7 03:27:43.927: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-4f99c,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-4f99c/deployments/nginx-deployment,UID:51364d0e-2a88-11e9-809d-e6a419c8531a,ResourceVersion:16075,Generation:3,CreationTimestamp:2019-02-07 03:27:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[{Available True 2019-02-07 03:27:40 +0000 UTC 2019-02-07 03:27:40 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-02-07 03:27:41 +0000 UTC 2019-02-07 03:27:37 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-65bbdb5f8" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Feb  7 03:27:43.933: INFO: New ReplicaSet "nginx-deployment-65bbdb5f8" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8,GenerateName:,Namespace:e2e-tests-deployment-4f99c,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-4f99c/replicasets/nginx-deployment-65bbdb5f8,UID:53a165cd-2a88-11e9-927c-4a513db42ba3,ResourceVersion:16078,Generation:3,CreationTimestamp:2019-02-07 03:27:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 51364d0e-2a88-11e9-809d-e6a419c8531a 0xc002218cd7 0xc002218cd8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb  7 03:27:43.933: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Feb  7 03:27:43.933: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965,GenerateName:,Namespace:e2e-tests-deployment-4f99c,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-4f99c/replicasets/nginx-deployment-555b55d965,UID:513122f6-2a88-11e9-927c-4a513db42ba3,ResourceVersion:16076,Generation:3,CreationTimestamp:2019-02-07 03:27:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 51364d0e-2a88-11e9-809d-e6a419c8531a 0xc002218c17 0xc002218c18}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Feb  7 03:27:43.943: INFO: Pod "nginx-deployment-555b55d965-72qkx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-72qkx,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-4f99c,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4f99c/pods/nginx-deployment-555b55d965-72qkx,UID:54da936b-2a88-11e9-927c-4a513db42ba3,ResourceVersion:16094,Generation:0,CreationTimestamp:2019-02-07 03:27:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 513122f6-2a88-11e9-927c-4a513db42ba3 0xc00245a657 0xc00245a658}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mznr6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mznr6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-mznr6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00245a6c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00245a6e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  7 03:27:43.943: INFO: Pod "nginx-deployment-555b55d965-8tr7g" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-8tr7g,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-4f99c,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4f99c/pods/nginx-deployment-555b55d965-8tr7g,UID:54d8fb44-2a88-11e9-927c-4a513db42ba3,ResourceVersion:16091,Generation:0,CreationTimestamp:2019-02-07 03:27:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 513122f6-2a88-11e9-927c-4a513db42ba3 0xc00245a797 0xc00245a798}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mznr6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mznr6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-mznr6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-node-2-kubelet.devkubernetes01.mesos,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00245a800} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00245a820}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:43 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  7 03:27:43.943: INFO: Pod "nginx-deployment-555b55d965-9cdhr" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-9cdhr,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-4f99c,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4f99c/pods/nginx-deployment-555b55d965-9cdhr,UID:5134347b-2a88-11e9-927c-4a513db42ba3,ResourceVersion:15993,Generation:0,CreationTimestamp:2019-02-07 03:27:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.5.144/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 513122f6-2a88-11e9-927c-4a513db42ba3 0xc00245a8a0 0xc00245a8a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mznr6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mznr6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-mznr6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-node-0-kubelet.devkubernetes01.mesos,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00245a930} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00245a950}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:37 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:39 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:39 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:37 +0000 UTC  }],Message:,Reason:,HostIP:9.0.1.4,PodIP:192.168.5.144,StartTime:2019-02-07 03:27:37 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-07 03:27:38 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://67aa8abd3bc59dca43b4806161f42a7f35c1efdd462595bed42316727ad087dd}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  7 03:27:43.943: INFO: Pod "nginx-deployment-555b55d965-c87gb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-c87gb,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-4f99c,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4f99c/pods/nginx-deployment-555b55d965-c87gb,UID:54d800c4-2a88-11e9-927c-4a513db42ba3,ResourceVersion:16083,Generation:0,CreationTimestamp:2019-02-07 03:27:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 513122f6-2a88-11e9-927c-4a513db42ba3 0xc00245aa70 0xc00245aa71}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mznr6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mznr6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-mznr6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-node-2-kubelet.devkubernetes01.mesos,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00245aad0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00245ab60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:43 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  7 03:27:43.943: INFO: Pod "nginx-deployment-555b55d965-dms5q" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-dms5q,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-4f99c,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4f99c/pods/nginx-deployment-555b55d965-dms5q,UID:51344766-2a88-11e9-927c-4a513db42ba3,ResourceVersion:15975,Generation:0,CreationTimestamp:2019-02-07 03:27:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.4.32/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 513122f6-2a88-11e9-927c-4a513db42ba3 0xc00245abe0 0xc00245abe1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mznr6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mznr6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-mznr6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-node-1-kubelet.devkubernetes01.mesos,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00245ac40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00245ac60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:37 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:39 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:39 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:37 +0000 UTC  }],Message:,Reason:,HostIP:9.0.1.3,PodIP:192.168.4.32,StartTime:2019-02-07 03:27:37 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-07 03:27:38 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://44c0babaa002f213453dbcedbf6235334a5ecc197ce6ffd1361837cd87c133e2}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  7 03:27:43.944: INFO: Pod "nginx-deployment-555b55d965-fqwtp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-fqwtp,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-4f99c,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4f99c/pods/nginx-deployment-555b55d965-fqwtp,UID:54da9419-2a88-11e9-927c-4a513db42ba3,ResourceVersion:16093,Generation:0,CreationTimestamp:2019-02-07 03:27:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 513122f6-2a88-11e9-927c-4a513db42ba3 0xc00245b0e0 0xc00245b0e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mznr6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mznr6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-mznr6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00245b140} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00245b160}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  7 03:27:43.944: INFO: Pod "nginx-deployment-555b55d965-gjjdg" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-gjjdg,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-4f99c,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4f99c/pods/nginx-deployment-555b55d965-gjjdg,UID:5135990f-2a88-11e9-927c-4a513db42ba3,ResourceVersion:15980,Generation:0,CreationTimestamp:2019-02-07 03:27:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.5.142/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 513122f6-2a88-11e9-927c-4a513db42ba3 0xc00245b1c7 0xc00245b1c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mznr6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mznr6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-mznr6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-node-0-kubelet.devkubernetes01.mesos,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00245b2b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00245b310}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:37 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:38 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:38 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:37 +0000 UTC  }],Message:,Reason:,HostIP:9.0.1.4,PodIP:192.168.5.142,StartTime:2019-02-07 03:27:37 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-07 03:27:38 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://6b6e76cf5086760efca0c5c07b181720d4e5186a3931cf946362d90f7230cf5f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  7 03:27:43.944: INFO: Pod "nginx-deployment-555b55d965-jb5cd" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-jb5cd,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-4f99c,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4f99c/pods/nginx-deployment-555b55d965-jb5cd,UID:5135925b-2a88-11e9-927c-4a513db42ba3,ResourceVersion:15960,Generation:0,CreationTimestamp:2019-02-07 03:27:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.4.31/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 513122f6-2a88-11e9-927c-4a513db42ba3 0xc00245b3f0 0xc00245b3f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mznr6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mznr6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-mznr6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-node-1-kubelet.devkubernetes01.mesos,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00245b450} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00245b470}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:37 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:38 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:38 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:37 +0000 UTC  }],Message:,Reason:,HostIP:9.0.1.3,PodIP:192.168.4.31,StartTime:2019-02-07 03:27:37 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-07 03:27:38 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://be49a10ebf82089a8da54fb2b0b3817396f0a217d340a346c28d4b76f466a408}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  7 03:27:43.944: INFO: Pod "nginx-deployment-555b55d965-l5vwd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-l5vwd,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-4f99c,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4f99c/pods/nginx-deployment-555b55d965-l5vwd,UID:54da96cf-2a88-11e9-927c-4a513db42ba3,ResourceVersion:16095,Generation:0,CreationTimestamp:2019-02-07 03:27:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 513122f6-2a88-11e9-927c-4a513db42ba3 0xc00245b670 0xc00245b671}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mznr6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mznr6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-mznr6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00245b6d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00245b6f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  7 03:27:43.944: INFO: Pod "nginx-deployment-555b55d965-p2zqg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-p2zqg,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-4f99c,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4f99c/pods/nginx-deployment-555b55d965-p2zqg,UID:54da742e-2a88-11e9-927c-4a513db42ba3,ResourceVersion:16092,Generation:0,CreationTimestamp:2019-02-07 03:27:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 513122f6-2a88-11e9-927c-4a513db42ba3 0xc00245b747 0xc00245b748}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mznr6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mznr6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-mznr6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00245b870} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00245b890}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  7 03:27:43.944: INFO: Pod "nginx-deployment-555b55d965-p729v" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-p729v,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-4f99c,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4f99c/pods/nginx-deployment-555b55d965-p729v,UID:51343fc2-2a88-11e9-927c-4a513db42ba3,ResourceVersion:15972,Generation:0,CreationTimestamp:2019-02-07 03:27:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.3.39/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 513122f6-2a88-11e9-927c-4a513db42ba3 0xc00245b8f7 0xc00245b8f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mznr6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mznr6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-mznr6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-node-2-kubelet.devkubernetes01.mesos,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00245b970} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00245b990}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:37 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:39 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:39 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:37 +0000 UTC  }],Message:,Reason:,HostIP:9.0.2.4,PodIP:192.168.3.39,StartTime:2019-02-07 03:27:37 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-07 03:27:38 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://40e00ac5edc00c93652b1bdec27e4cdfc2bca82e0c5d9fe48b05cad6f5ac232a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  7 03:27:43.944: INFO: Pod "nginx-deployment-555b55d965-phjg7" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-phjg7,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-4f99c,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4f99c/pods/nginx-deployment-555b55d965-phjg7,UID:5134539f-2a88-11e9-927c-4a513db42ba3,ResourceVersion:15990,Generation:0,CreationTimestamp:2019-02-07 03:27:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.5.143/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 513122f6-2a88-11e9-927c-4a513db42ba3 0xc00245bb00 0xc00245bb01}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mznr6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mznr6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-mznr6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-node-0-kubelet.devkubernetes01.mesos,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00245bb60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00245bb80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:37 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:39 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:39 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:37 +0000 UTC  }],Message:,Reason:,HostIP:9.0.1.4,PodIP:192.168.5.143,StartTime:2019-02-07 03:27:37 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-07 03:27:38 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://f3aebd84586c8f0538d08f42d78e00a899aca9811c5d47650aede79168aadacc}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  7 03:27:43.944: INFO: Pod "nginx-deployment-555b55d965-pzzng" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-pzzng,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-4f99c,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4f99c/pods/nginx-deployment-555b55d965-pzzng,UID:54d8ee1f-2a88-11e9-927c-4a513db42ba3,ResourceVersion:16087,Generation:0,CreationTimestamp:2019-02-07 03:27:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 513122f6-2a88-11e9-927c-4a513db42ba3 0xc00245bce0 0xc00245bce1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mznr6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mznr6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-mznr6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-node-2-kubelet.devkubernetes01.mesos,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00245bd70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00245bd90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:43 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  7 03:27:43.945: INFO: Pod "nginx-deployment-555b55d965-rjssf" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-rjssf,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-4f99c,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4f99c/pods/nginx-deployment-555b55d965-rjssf,UID:51332dba-2a88-11e9-927c-4a513db42ba3,ResourceVersion:15966,Generation:0,CreationTimestamp:2019-02-07 03:27:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.4.30/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 513122f6-2a88-11e9-927c-4a513db42ba3 0xc00245be10 0xc00245be11}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mznr6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mznr6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-mznr6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-node-1-kubelet.devkubernetes01.mesos,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00245be70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00245be90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:37 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:38 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:38 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:37 +0000 UTC  }],Message:,Reason:,HostIP:9.0.1.3,PodIP:192.168.4.30,StartTime:2019-02-07 03:27:37 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-07 03:27:38 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://6215133620db28394f10980d4a1e123b66d4f825bfef1e0aa7605e21a1a79c9c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  7 03:27:43.945: INFO: Pod "nginx-deployment-555b55d965-s6zl6" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-s6zl6,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-4f99c,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4f99c/pods/nginx-deployment-555b55d965-s6zl6,UID:5132a71e-2a88-11e9-927c-4a513db42ba3,ResourceVersion:15987,Generation:0,CreationTimestamp:2019-02-07 03:27:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.5.141/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 513122f6-2a88-11e9-927c-4a513db42ba3 0xc002520730 0xc002520731}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mznr6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mznr6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-mznr6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-node-0-kubelet.devkubernetes01.mesos,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002520790} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025207b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:37 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:39 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:39 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:37 +0000 UTC  }],Message:,Reason:,HostIP:9.0.1.4,PodIP:192.168.5.141,StartTime:2019-02-07 03:27:37 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-07 03:27:38 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://ec1a0e82fafd5c4acf9d6842b9c4836e59a6cba5664e7a48e48cdb5ee0a00c52}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  7 03:27:43.945: INFO: Pod "nginx-deployment-65bbdb5f8-cbwp2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-cbwp2,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-4f99c,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4f99c/pods/nginx-deployment-65bbdb5f8-cbwp2,UID:53a319ae-2a88-11e9-927c-4a513db42ba3,ResourceVersion:16062,Generation:0,CreationTimestamp:2019-02-07 03:27:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.4.34/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 53a165cd-2a88-11e9-927c-4a513db42ba3 0xc002520880 0xc002520881}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mznr6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mznr6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-mznr6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-node-1-kubelet.devkubernetes01.mesos,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002520a30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002520a50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:41 +0000 UTC  }],Message:,Reason:,HostIP:9.0.1.3,PodIP:,StartTime:2019-02-07 03:27:41 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  7 03:27:43.945: INFO: Pod "nginx-deployment-65bbdb5f8-gn2j8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-gn2j8,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-4f99c,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4f99c/pods/nginx-deployment-65bbdb5f8-gn2j8,UID:53a94543-2a88-11e9-927c-4a513db42ba3,ResourceVersion:16061,Generation:0,CreationTimestamp:2019-02-07 03:27:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.4.33/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 53a165cd-2a88-11e9-927c-4a513db42ba3 0xc002520b60 0xc002520b61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mznr6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mznr6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-mznr6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-node-1-kubelet.devkubernetes01.mesos,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002520c40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002520c60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:41 +0000 UTC  }],Message:,Reason:,HostIP:9.0.1.3,PodIP:,StartTime:2019-02-07 03:27:41 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  7 03:27:43.945: INFO: Pod "nginx-deployment-65bbdb5f8-mgmkt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-mgmkt,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-4f99c,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4f99c/pods/nginx-deployment-65bbdb5f8-mgmkt,UID:54da1d8a-2a88-11e9-927c-4a513db42ba3,ResourceVersion:16090,Generation:0,CreationTimestamp:2019-02-07 03:27:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 53a165cd-2a88-11e9-927c-4a513db42ba3 0xc002520d20 0xc002520d21}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mznr6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mznr6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-mznr6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002520d90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002520db0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  7 03:27:43.945: INFO: Pod "nginx-deployment-65bbdb5f8-v2x4q" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-v2x4q,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-4f99c,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4f99c/pods/nginx-deployment-65bbdb5f8-v2x4q,UID:53a204d8-2a88-11e9-927c-4a513db42ba3,ResourceVersion:16069,Generation:0,CreationTimestamp:2019-02-07 03:27:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.3.43/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 53a165cd-2a88-11e9-927c-4a513db42ba3 0xc002520e17 0xc002520e18}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mznr6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mznr6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-mznr6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-node-2-kubelet.devkubernetes01.mesos,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002520e80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002520ea0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:41 +0000 UTC  }],Message:,Reason:,HostIP:9.0.2.4,PodIP:,StartTime:2019-02-07 03:27:41 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  7 03:27:43.945: INFO: Pod "nginx-deployment-65bbdb5f8-vwchd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-vwchd,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-4f99c,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4f99c/pods/nginx-deployment-65bbdb5f8-vwchd,UID:54da0f72-2a88-11e9-927c-4a513db42ba3,ResourceVersion:16089,Generation:0,CreationTimestamp:2019-02-07 03:27:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 53a165cd-2a88-11e9-927c-4a513db42ba3 0xc002520f60 0xc002520f61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mznr6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mznr6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-mznr6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002520fd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002520ff0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  7 03:27:43.946: INFO: Pod "nginx-deployment-65bbdb5f8-w298g" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-w298g,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-4f99c,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4f99c/pods/nginx-deployment-65bbdb5f8-w298g,UID:54d8efe8-2a88-11e9-927c-4a513db42ba3,ResourceVersion:16088,Generation:0,CreationTimestamp:2019-02-07 03:27:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 53a165cd-2a88-11e9-927c-4a513db42ba3 0xc002521047 0xc002521048}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mznr6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mznr6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-mznr6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-node-0-kubelet.devkubernetes01.mesos,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025210b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025210d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:43 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  7 03:27:43.946: INFO: Pod "nginx-deployment-65bbdb5f8-z2fcq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-z2fcq,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-4f99c,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4f99c/pods/nginx-deployment-65bbdb5f8-z2fcq,UID:53a86b04-2a88-11e9-927c-4a513db42ba3,ResourceVersion:16068,Generation:0,CreationTimestamp:2019-02-07 03:27:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.3.42/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 53a165cd-2a88-11e9-927c-4a513db42ba3 0xc002521150 0xc002521151}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mznr6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mznr6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-mznr6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-node-2-kubelet.devkubernetes01.mesos,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025211c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025211e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:41 +0000 UTC  }],Message:,Reason:,HostIP:9.0.2.4,PodIP:,StartTime:2019-02-07 03:27:41 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  7 03:27:43.946: INFO: Pod "nginx-deployment-65bbdb5f8-z44nb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-z44nb,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-4f99c,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4f99c/pods/nginx-deployment-65bbdb5f8-z44nb,UID:53a2f6ad-2a88-11e9-927c-4a513db42ba3,ResourceVersion:16064,Generation:0,CreationTimestamp:2019-02-07 03:27:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.5.145/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 53a165cd-2a88-11e9-927c-4a513db42ba3 0xc0025212b0 0xc0025212b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mznr6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mznr6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-mznr6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-node-0-kubelet.devkubernetes01.mesos,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002521320} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002521340}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:27:41 +0000 UTC  }],Message:,Reason:,HostIP:9.0.1.4,PodIP:,StartTime:2019-02-07 03:27:41 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:27:43.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-4f99c" for this suite.
Feb  7 03:27:51.980: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:27:52.022: INFO: namespace: e2e-tests-deployment-4f99c, resource: bindings, ignored listing per whitelist
Feb  7 03:27:52.077: INFO: namespace e2e-tests-deployment-4f99c deletion completed in 8.124729856s

• [SLOW TEST:14.351 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:27:52.077: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb  7 03:27:52.129: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:27:56.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-zmrqt" for this suite.
Feb  7 03:28:04.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:28:04.249: INFO: namespace: e2e-tests-init-container-zmrqt, resource: bindings, ignored listing per whitelist
Feb  7 03:28:04.335: INFO: namespace e2e-tests-init-container-zmrqt deletion completed in 8.103873858s

• [SLOW TEST:12.258 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:28:04.335: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb  7 03:28:04.394: INFO: Waiting up to 5m0s for pod "pod-610ffbc2-2a88-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-emptydir-f5mcw" to be "success or failure"
Feb  7 03:28:04.396: INFO: Pod "pod-610ffbc2-2a88-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.767578ms
Feb  7 03:28:06.399: INFO: Pod "pod-610ffbc2-2a88-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004735821s
STEP: Saw pod success
Feb  7 03:28:06.439: INFO: Pod "pod-610ffbc2-2a88-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:28:06.442: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod pod-610ffbc2-2a88-11e9-87fe-baa4eca941e3 container test-container: <nil>
STEP: delete the pod
Feb  7 03:28:06.456: INFO: Waiting for pod pod-610ffbc2-2a88-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:28:06.460: INFO: Pod pod-610ffbc2-2a88-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:28:06.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-f5mcw" for this suite.
Feb  7 03:28:12.856: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:28:12.932: INFO: namespace: e2e-tests-emptydir-f5mcw, resource: bindings, ignored listing per whitelist
Feb  7 03:28:12.950: INFO: namespace e2e-tests-emptydir-f5mcw deletion completed in 6.487739405s

• [SLOW TEST:8.615 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:28:12.951: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-94jj
STEP: Creating a pod to test atomic-volume-subpath
Feb  7 03:28:13.014: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-94jj" in namespace "e2e-tests-subpath-6xbsx" to be "success or failure"
Feb  7 03:28:13.016: INFO: Pod "pod-subpath-test-projected-94jj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.24266ms
Feb  7 03:28:15.019: INFO: Pod "pod-subpath-test-projected-94jj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005489551s
Feb  7 03:28:17.023: INFO: Pod "pod-subpath-test-projected-94jj": Phase="Running", Reason="", readiness=false. Elapsed: 4.008627677s
Feb  7 03:28:19.025: INFO: Pod "pod-subpath-test-projected-94jj": Phase="Running", Reason="", readiness=false. Elapsed: 6.011556989s
Feb  7 03:28:21.032: INFO: Pod "pod-subpath-test-projected-94jj": Phase="Running", Reason="", readiness=false. Elapsed: 8.018416471s
Feb  7 03:28:23.036: INFO: Pod "pod-subpath-test-projected-94jj": Phase="Running", Reason="", readiness=false. Elapsed: 10.022017235s
Feb  7 03:28:25.042: INFO: Pod "pod-subpath-test-projected-94jj": Phase="Running", Reason="", readiness=false. Elapsed: 12.028321074s
Feb  7 03:28:27.045: INFO: Pod "pod-subpath-test-projected-94jj": Phase="Running", Reason="", readiness=false. Elapsed: 14.031107558s
Feb  7 03:28:29.048: INFO: Pod "pod-subpath-test-projected-94jj": Phase="Running", Reason="", readiness=false. Elapsed: 16.034387903s
Feb  7 03:28:31.131: INFO: Pod "pod-subpath-test-projected-94jj": Phase="Running", Reason="", readiness=false. Elapsed: 18.117024621s
Feb  7 03:28:33.133: INFO: Pod "pod-subpath-test-projected-94jj": Phase="Running", Reason="", readiness=false. Elapsed: 20.119569883s
Feb  7 03:28:35.136: INFO: Pod "pod-subpath-test-projected-94jj": Phase="Running", Reason="", readiness=false. Elapsed: 22.122450096s
Feb  7 03:28:37.139: INFO: Pod "pod-subpath-test-projected-94jj": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.125469423s
STEP: Saw pod success
Feb  7 03:28:37.139: INFO: Pod "pod-subpath-test-projected-94jj" satisfied condition "success or failure"
Feb  7 03:28:37.234: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod pod-subpath-test-projected-94jj container test-container-subpath-projected-94jj: <nil>
STEP: delete the pod
Feb  7 03:28:37.250: INFO: Waiting for pod pod-subpath-test-projected-94jj to disappear
Feb  7 03:28:37.252: INFO: Pod pod-subpath-test-projected-94jj no longer exists
STEP: Deleting pod pod-subpath-test-projected-94jj
Feb  7 03:28:37.252: INFO: Deleting pod "pod-subpath-test-projected-94jj" in namespace "e2e-tests-subpath-6xbsx"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:28:37.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-6xbsx" for this suite.
Feb  7 03:28:43.654: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:28:43.706: INFO: namespace: e2e-tests-subpath-6xbsx, resource: bindings, ignored listing per whitelist
Feb  7 03:28:43.747: INFO: namespace e2e-tests-subpath-6xbsx deletion completed in 6.490208926s

• [SLOW TEST:30.796 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:28:43.747: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb  7 03:28:43.995: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:28:43.995: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:28:43.995: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:28:43.997: INFO: Number of nodes with available pods: 0
Feb  7 03:28:43.997: INFO: Node kube-node-0-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:28:45.032: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:28:45.032: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:28:45.032: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:28:45.034: INFO: Number of nodes with available pods: 0
Feb  7 03:28:45.034: INFO: Node kube-node-0-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:28:46.229: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:28:46.229: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:28:46.229: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:28:46.234: INFO: Number of nodes with available pods: 0
Feb  7 03:28:46.234: INFO: Node kube-node-0-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:28:47.001: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:28:47.001: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:28:47.001: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:28:47.004: INFO: Number of nodes with available pods: 3
Feb  7 03:28:47.004: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Feb  7 03:28:47.015: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:28:47.015: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:28:47.015: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:28:47.018: INFO: Number of nodes with available pods: 2
Feb  7 03:28:47.018: INFO: Node kube-node-2-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:28:48.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:28:48.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:28:48.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:28:48.025: INFO: Number of nodes with available pods: 2
Feb  7 03:28:48.025: INFO: Node kube-node-2-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:28:49.190: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:28:49.190: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:28:49.190: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:28:49.230: INFO: Number of nodes with available pods: 2
Feb  7 03:28:49.230: INFO: Node kube-node-2-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:28:50.040: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:28:50.040: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:28:50.040: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:28:50.043: INFO: Number of nodes with available pods: 2
Feb  7 03:28:50.043: INFO: Node kube-node-2-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:28:51.021: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:28:51.021: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:28:51.021: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:28:51.024: INFO: Number of nodes with available pods: 2
Feb  7 03:28:51.024: INFO: Node kube-node-2-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:28:52.026: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:28:52.026: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:28:52.026: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:28:52.029: INFO: Number of nodes with available pods: 2
Feb  7 03:28:52.029: INFO: Node kube-node-2-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:28:53.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:28:53.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:28:53.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:28:53.039: INFO: Number of nodes with available pods: 2
Feb  7 03:28:53.039: INFO: Node kube-node-2-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:28:54.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:28:54.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:28:54.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:28:54.024: INFO: Number of nodes with available pods: 2
Feb  7 03:28:54.024: INFO: Node kube-node-2-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:28:55.021: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:28:55.021: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:28:55.021: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:28:55.024: INFO: Number of nodes with available pods: 2
Feb  7 03:28:55.024: INFO: Node kube-node-2-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:28:56.021: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:28:56.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:28:56.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:28:56.024: INFO: Number of nodes with available pods: 2
Feb  7 03:28:56.024: INFO: Node kube-node-2-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:28:57.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:28:57.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:28:57.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:28:57.024: INFO: Number of nodes with available pods: 2
Feb  7 03:28:57.024: INFO: Node kube-node-2-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:28:58.021: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:28:58.021: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:28:58.021: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:28:58.024: INFO: Number of nodes with available pods: 2
Feb  7 03:28:58.025: INFO: Node kube-node-2-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:28:59.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:28:59.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:28:59.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:28:59.024: INFO: Number of nodes with available pods: 2
Feb  7 03:28:59.024: INFO: Node kube-node-2-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:29:00.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:00.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:00.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:00.024: INFO: Number of nodes with available pods: 2
Feb  7 03:29:00.024: INFO: Node kube-node-2-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:29:01.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:01.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:01.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:01.024: INFO: Number of nodes with available pods: 2
Feb  7 03:29:01.024: INFO: Node kube-node-2-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:29:02.031: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:02.031: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:02.031: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:02.037: INFO: Number of nodes with available pods: 2
Feb  7 03:29:02.037: INFO: Node kube-node-2-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:29:03.021: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:03.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:03.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:03.024: INFO: Number of nodes with available pods: 2
Feb  7 03:29:03.024: INFO: Node kube-node-2-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:29:04.530: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:04.530: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:04.530: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:04.532: INFO: Number of nodes with available pods: 2
Feb  7 03:29:04.532: INFO: Node kube-node-2-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:29:05.021: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:05.021: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:05.021: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:05.024: INFO: Number of nodes with available pods: 2
Feb  7 03:29:05.024: INFO: Node kube-node-2-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:29:06.031: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:06.031: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:06.031: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:06.035: INFO: Number of nodes with available pods: 2
Feb  7 03:29:06.035: INFO: Node kube-node-2-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:29:07.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:07.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:07.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:07.025: INFO: Number of nodes with available pods: 2
Feb  7 03:29:07.025: INFO: Node kube-node-2-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:29:08.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:08.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:08.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:08.025: INFO: Number of nodes with available pods: 2
Feb  7 03:29:08.025: INFO: Node kube-node-2-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:29:09.021: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:09.021: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:09.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:09.029: INFO: Number of nodes with available pods: 2
Feb  7 03:29:09.029: INFO: Node kube-node-2-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:29:10.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:10.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:10.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:10.024: INFO: Number of nodes with available pods: 2
Feb  7 03:29:10.024: INFO: Node kube-node-2-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:29:11.021: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:11.021: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:11.021: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:11.024: INFO: Number of nodes with available pods: 2
Feb  7 03:29:11.024: INFO: Node kube-node-2-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:29:12.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:12.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:12.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:12.025: INFO: Number of nodes with available pods: 2
Feb  7 03:29:12.025: INFO: Node kube-node-2-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:29:13.026: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:13.026: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:13.026: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:13.028: INFO: Number of nodes with available pods: 2
Feb  7 03:29:13.028: INFO: Node kube-node-2-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:29:14.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:14.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:14.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:14.024: INFO: Number of nodes with available pods: 2
Feb  7 03:29:14.024: INFO: Node kube-node-2-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:29:15.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:15.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:15.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:15.025: INFO: Number of nodes with available pods: 2
Feb  7 03:29:15.025: INFO: Node kube-node-2-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:29:16.021: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:16.021: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:16.021: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:16.029: INFO: Number of nodes with available pods: 2
Feb  7 03:29:16.029: INFO: Node kube-node-2-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:29:17.021: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:17.021: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:17.021: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:17.024: INFO: Number of nodes with available pods: 2
Feb  7 03:29:17.024: INFO: Node kube-node-2-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:29:18.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:18.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:18.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:18.024: INFO: Number of nodes with available pods: 2
Feb  7 03:29:18.024: INFO: Node kube-node-2-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:29:19.029: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:19.029: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:19.029: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:19.031: INFO: Number of nodes with available pods: 2
Feb  7 03:29:19.031: INFO: Node kube-node-2-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:29:20.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:20.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:20.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:20.024: INFO: Number of nodes with available pods: 2
Feb  7 03:29:20.024: INFO: Node kube-node-2-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:29:21.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:21.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:21.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:21.029: INFO: Number of nodes with available pods: 2
Feb  7 03:29:21.029: INFO: Node kube-node-2-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:29:22.021: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:22.021: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:22.021: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:22.024: INFO: Number of nodes with available pods: 2
Feb  7 03:29:22.024: INFO: Node kube-node-2-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:29:23.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:23.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:23.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:23.024: INFO: Number of nodes with available pods: 2
Feb  7 03:29:23.024: INFO: Node kube-node-2-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:29:24.163: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:24.163: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:24.163: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:24.166: INFO: Number of nodes with available pods: 2
Feb  7 03:29:24.166: INFO: Node kube-node-2-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:29:25.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:25.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:25.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:25.024: INFO: Number of nodes with available pods: 2
Feb  7 03:29:25.024: INFO: Node kube-node-2-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:29:26.030: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:26.030: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:26.030: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:26.032: INFO: Number of nodes with available pods: 2
Feb  7 03:29:26.032: INFO: Node kube-node-2-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:29:27.023: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:27.023: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:27.023: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:27.025: INFO: Number of nodes with available pods: 2
Feb  7 03:29:27.025: INFO: Node kube-node-2-kubelet.devkubernetes01.mesos is running more than one daemon pod
Feb  7 03:29:28.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-0-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:28.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-1-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:28.022: INFO: DaemonSet pods can't tolerate node kube-control-plane-2-instance.devkubernetes01.mesos with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoExecute TimeAdded:<nil>}], skip checking this node
Feb  7 03:29:28.024: INFO: Number of nodes with available pods: 3
Feb  7 03:29:28.024: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-jnvwh, will wait for the garbage collector to delete the pods
Feb  7 03:29:28.085: INFO: Deleting DaemonSet.extensions daemon-set took: 5.58155ms
Feb  7 03:29:28.185: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.217987ms
Feb  7 03:30:07.192: INFO: Number of nodes with available pods: 0
Feb  7 03:30:07.192: INFO: Number of running nodes: 0, number of available pods: 0
Feb  7 03:30:07.194: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-jnvwh/daemonsets","resourceVersion":"16868"},"items":null}

Feb  7 03:30:07.196: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-jnvwh/pods","resourceVersion":"16868"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:30:07.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-jnvwh" for this suite.
Feb  7 03:30:13.554: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:30:13.679: INFO: namespace: e2e-tests-daemonsets-jnvwh, resource: bindings, ignored listing per whitelist
Feb  7 03:30:13.745: INFO: namespace e2e-tests-daemonsets-jnvwh deletion completed in 6.53723961s

• [SLOW TEST:89.998 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:30:13.745: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  7 03:30:14.527: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ae327d82-2a88-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-projected-cvt6f" to be "success or failure"
Feb  7 03:30:14.530: INFO: Pod "downwardapi-volume-ae327d82-2a88-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.17896ms
Feb  7 03:30:16.532: INFO: Pod "downwardapi-volume-ae327d82-2a88-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004888458s
STEP: Saw pod success
Feb  7 03:30:16.532: INFO: Pod "downwardapi-volume-ae327d82-2a88-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:30:16.534: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod downwardapi-volume-ae327d82-2a88-11e9-87fe-baa4eca941e3 container client-container: <nil>
STEP: delete the pod
Feb  7 03:30:16.550: INFO: Waiting for pod downwardapi-volume-ae327d82-2a88-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:30:16.554: INFO: Pod downwardapi-volume-ae327d82-2a88-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:30:16.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-cvt6f" for this suite.
Feb  7 03:30:22.569: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:30:22.610: INFO: namespace: e2e-tests-projected-cvt6f, resource: bindings, ignored listing per whitelist
Feb  7 03:30:22.664: INFO: namespace e2e-tests-projected-cvt6f deletion completed in 6.106170691s

• [SLOW TEST:8.919 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:30:22.664: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-b382dd3a-2a88-11e9-87fe-baa4eca941e3
STEP: Creating a pod to test consume configMaps
Feb  7 03:30:22.724: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b3838661-2a88-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-projected-d4gmd" to be "success or failure"
Feb  7 03:30:22.726: INFO: Pod "pod-projected-configmaps-b3838661-2a88-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.100705ms
Feb  7 03:30:24.729: INFO: Pod "pod-projected-configmaps-b3838661-2a88-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004968382s
STEP: Saw pod success
Feb  7 03:30:24.729: INFO: Pod "pod-projected-configmaps-b3838661-2a88-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:30:24.731: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod pod-projected-configmaps-b3838661-2a88-11e9-87fe-baa4eca941e3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  7 03:30:24.839: INFO: Waiting for pod pod-projected-configmaps-b3838661-2a88-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:30:24.841: INFO: Pod pod-projected-configmaps-b3838661-2a88-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:30:24.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-d4gmd" for this suite.
Feb  7 03:30:30.854: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:30:30.943: INFO: namespace: e2e-tests-projected-d4gmd, resource: bindings, ignored listing per whitelist
Feb  7 03:30:30.951: INFO: namespace e2e-tests-projected-d4gmd deletion completed in 6.106890956s

• [SLOW TEST:8.287 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:30:30.951: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  7 03:30:31.285: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b87599f0-2a88-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-downward-api-gsgxk" to be "success or failure"
Feb  7 03:30:31.328: INFO: Pod "downwardapi-volume-b87599f0-2a88-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 42.384387ms
Feb  7 03:30:33.331: INFO: Pod "downwardapi-volume-b87599f0-2a88-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.045322509s
Feb  7 03:30:35.559: INFO: Pod "downwardapi-volume-b87599f0-2a88-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.274169003s
STEP: Saw pod success
Feb  7 03:30:35.559: INFO: Pod "downwardapi-volume-b87599f0-2a88-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:30:35.562: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod downwardapi-volume-b87599f0-2a88-11e9-87fe-baa4eca941e3 container client-container: <nil>
STEP: delete the pod
Feb  7 03:30:35.577: INFO: Waiting for pod downwardapi-volume-b87599f0-2a88-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:30:35.579: INFO: Pod downwardapi-volume-b87599f0-2a88-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:30:35.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-gsgxk" for this suite.
Feb  7 03:30:41.593: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:30:41.681: INFO: namespace: e2e-tests-downward-api-gsgxk, resource: bindings, ignored listing per whitelist
Feb  7 03:30:41.715: INFO: namespace e2e-tests-downward-api-gsgxk deletion completed in 6.13241059s

• [SLOW TEST:10.763 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:30:41.715: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-bee6ba83-2a88-11e9-87fe-baa4eca941e3
STEP: Creating a pod to test consume secrets
Feb  7 03:30:41.834: INFO: Waiting up to 5m0s for pod "pod-secrets-bee7a5c8-2a88-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-secrets-th5w2" to be "success or failure"
Feb  7 03:30:41.836: INFO: Pod "pod-secrets-bee7a5c8-2a88-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.104632ms
Feb  7 03:30:43.840: INFO: Pod "pod-secrets-bee7a5c8-2a88-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005737878s
STEP: Saw pod success
Feb  7 03:30:43.840: INFO: Pod "pod-secrets-bee7a5c8-2a88-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:30:43.842: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod pod-secrets-bee7a5c8-2a88-11e9-87fe-baa4eca941e3 container secret-volume-test: <nil>
STEP: delete the pod
Feb  7 03:30:43.951: INFO: Waiting for pod pod-secrets-bee7a5c8-2a88-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:30:43.954: INFO: Pod pod-secrets-bee7a5c8-2a88-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:30:43.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-th5w2" for this suite.
Feb  7 03:30:51.969: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:30:52.047: INFO: namespace: e2e-tests-secrets-th5w2, resource: bindings, ignored listing per whitelist
Feb  7 03:30:52.062: INFO: namespace e2e-tests-secrets-th5w2 deletion completed in 8.104618752s

• [SLOW TEST:10.347 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:30:52.062: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-c508dfca-2a88-11e9-87fe-baa4eca941e3
STEP: Creating a pod to test consume configMaps
Feb  7 03:30:52.122: INFO: Waiting up to 5m0s for pod "pod-configmaps-c50995f3-2a88-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-configmap-gwr2z" to be "success or failure"
Feb  7 03:30:52.124: INFO: Pod "pod-configmaps-c50995f3-2a88-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.895908ms
Feb  7 03:30:54.132: INFO: Pod "pod-configmaps-c50995f3-2a88-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009231825s
STEP: Saw pod success
Feb  7 03:30:54.132: INFO: Pod "pod-configmaps-c50995f3-2a88-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:30:54.134: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod pod-configmaps-c50995f3-2a88-11e9-87fe-baa4eca941e3 container configmap-volume-test: <nil>
STEP: delete the pod
Feb  7 03:30:54.149: INFO: Waiting for pod pod-configmaps-c50995f3-2a88-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:30:54.151: INFO: Pod pod-configmaps-c50995f3-2a88-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:30:54.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-gwr2z" for this suite.
Feb  7 03:31:00.171: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:31:00.204: INFO: namespace: e2e-tests-configmap-gwr2z, resource: bindings, ignored listing per whitelist
Feb  7 03:31:00.270: INFO: namespace e2e-tests-configmap-gwr2z deletion completed in 6.1145875s

• [SLOW TEST:8.207 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:31:00.270: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-c9ed20ee-2a88-11e9-87fe-baa4eca941e3
STEP: Creating a pod to test consume secrets
Feb  7 03:31:00.328: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c9edd9e6-2a88-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-projected-rvx4c" to be "success or failure"
Feb  7 03:31:00.330: INFO: Pod "pod-projected-secrets-c9edd9e6-2a88-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032226ms
Feb  7 03:31:03.225: INFO: Pod "pod-projected-secrets-c9edd9e6-2a88-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.896483736s
STEP: Saw pod success
Feb  7 03:31:03.225: INFO: Pod "pod-projected-secrets-c9edd9e6-2a88-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:31:03.230: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod pod-projected-secrets-c9edd9e6-2a88-11e9-87fe-baa4eca941e3 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb  7 03:31:03.246: INFO: Waiting for pod pod-projected-secrets-c9edd9e6-2a88-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:31:03.249: INFO: Pod pod-projected-secrets-c9edd9e6-2a88-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:31:03.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rvx4c" for this suite.
Feb  7 03:31:09.264: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:31:09.280: INFO: namespace: e2e-tests-projected-rvx4c, resource: bindings, ignored listing per whitelist
Feb  7 03:31:09.368: INFO: namespace e2e-tests-projected-rvx4c deletion completed in 6.116179856s

• [SLOW TEST:9.098 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:31:09.368: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  7 03:31:09.436: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
Feb  7 03:31:09.441: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-gpfv2/daemonsets","resourceVersion":"17183"},"items":null}

Feb  7 03:31:09.443: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-gpfv2/pods","resourceVersion":"17183"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:31:09.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-gpfv2" for this suite.
Feb  7 03:31:17.533: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:31:17.606: INFO: namespace: e2e-tests-daemonsets-gpfv2, resource: bindings, ignored listing per whitelist
Feb  7 03:31:17.646: INFO: namespace e2e-tests-daemonsets-gpfv2 deletion completed in 8.191780095s

S [SKIPPING] [8.278 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Feb  7 03:31:09.436: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
S
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:31:17.646: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  7 03:31:20.124: INFO: Waiting up to 5m0s for pod "client-envvars-d5b627ee-2a88-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-pods-qfj6x" to be "success or failure"
Feb  7 03:31:20.126: INFO: Pod "client-envvars-d5b627ee-2a88-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.42658ms
Feb  7 03:31:22.134: INFO: Pod "client-envvars-d5b627ee-2a88-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010054176s
STEP: Saw pod success
Feb  7 03:31:22.134: INFO: Pod "client-envvars-d5b627ee-2a88-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:31:22.136: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod client-envvars-d5b627ee-2a88-11e9-87fe-baa4eca941e3 container env3cont: <nil>
STEP: delete the pod
Feb  7 03:31:22.152: INFO: Waiting for pod client-envvars-d5b627ee-2a88-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:31:22.154: INFO: Pod client-envvars-d5b627ee-2a88-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:31:22.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-qfj6x" for this suite.
Feb  7 03:32:00.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:32:00.207: INFO: namespace: e2e-tests-pods-qfj6x, resource: bindings, ignored listing per whitelist
Feb  7 03:32:00.263: INFO: namespace e2e-tests-pods-qfj6x deletion completed in 38.105186926s

• [SLOW TEST:42.617 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:32:00.263: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-msf92
Feb  7 03:32:02.328: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-msf92
STEP: checking the pod's current state and verifying that restartCount is present
Feb  7 03:32:02.330: INFO: Initial restart count of pod liveness-http is 0
Feb  7 03:32:24.534: INFO: Restart count of pod e2e-tests-container-probe-msf92/liveness-http is now 1 (22.204594129s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:32:24.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-msf92" for this suite.
Feb  7 03:32:30.556: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:32:30.651: INFO: namespace: e2e-tests-container-probe-msf92, resource: bindings, ignored listing per whitelist
Feb  7 03:32:30.738: INFO: namespace e2e-tests-container-probe-msf92 deletion completed in 6.191810065s

• [SLOW TEST:30.475 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:32:30.738: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Feb  7 03:32:30.788: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 create -f - --namespace=e2e-tests-kubectl-5vchq'
Feb  7 03:32:31.144: INFO: stderr: ""
Feb  7 03:32:31.144: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb  7 03:32:32.147: INFO: Selector matched 1 pods for map[app:redis]
Feb  7 03:32:32.147: INFO: Found 0 / 1
Feb  7 03:32:33.694: INFO: Selector matched 1 pods for map[app:redis]
Feb  7 03:32:33.694: INFO: Found 1 / 1
Feb  7 03:32:33.694: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Feb  7 03:32:33.749: INFO: Selector matched 1 pods for map[app:redis]
Feb  7 03:32:33.749: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb  7 03:32:33.749: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 patch pod redis-master-4pthl --namespace=e2e-tests-kubectl-5vchq -p {"metadata":{"annotations":{"x":"y"}}}'
Feb  7 03:32:33.828: INFO: stderr: ""
Feb  7 03:32:33.828: INFO: stdout: "pod/redis-master-4pthl patched\n"
STEP: checking annotations
Feb  7 03:32:33.830: INFO: Selector matched 1 pods for map[app:redis]
Feb  7 03:32:33.830: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:32:33.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5vchq" for this suite.
Feb  7 03:32:55.848: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:32:55.858: INFO: namespace: e2e-tests-kubectl-5vchq, resource: bindings, ignored listing per whitelist
Feb  7 03:32:55.942: INFO: namespace e2e-tests-kubectl-5vchq deletion completed in 22.108285029s

• [SLOW TEST:25.204 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:32:55.942: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb  7 03:32:56.002: INFO: Waiting up to 5m0s for pod "downward-api-0edfdcdf-2a89-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-downward-api-lgbcn" to be "success or failure"
Feb  7 03:32:56.004: INFO: Pod "downward-api-0edfdcdf-2a89-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.122691ms
Feb  7 03:32:58.007: INFO: Pod "downward-api-0edfdcdf-2a89-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004906518s
STEP: Saw pod success
Feb  7 03:32:58.007: INFO: Pod "downward-api-0edfdcdf-2a89-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:32:58.011: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod downward-api-0edfdcdf-2a89-11e9-87fe-baa4eca941e3 container dapi-container: <nil>
STEP: delete the pod
Feb  7 03:32:58.026: INFO: Waiting for pod downward-api-0edfdcdf-2a89-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:32:58.028: INFO: Pod downward-api-0edfdcdf-2a89-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:32:58.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-lgbcn" for this suite.
Feb  7 03:33:04.196: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:33:04.270: INFO: namespace: e2e-tests-downward-api-lgbcn, resource: bindings, ignored listing per whitelist
Feb  7 03:33:04.293: INFO: namespace e2e-tests-downward-api-lgbcn deletion completed in 6.261837086s

• [SLOW TEST:8.351 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:33:04.294: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:33:06.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-rm6ld" for this suite.
Feb  7 03:33:46.381: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:33:46.474: INFO: namespace: e2e-tests-kubelet-test-rm6ld, resource: bindings, ignored listing per whitelist
Feb  7 03:33:46.522: INFO: namespace e2e-tests-kubelet-test-rm6ld deletion completed in 40.155168175s

• [SLOW TEST:42.228 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:33:46.522: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb  7 03:33:46.582: INFO: Waiting up to 5m0s for pod "downward-api-2d05e2f9-2a89-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-downward-api-vxzzh" to be "success or failure"
Feb  7 03:33:46.584: INFO: Pod "downward-api-2d05e2f9-2a89-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.863379ms
Feb  7 03:33:48.587: INFO: Pod "downward-api-2d05e2f9-2a89-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004761596s
STEP: Saw pod success
Feb  7 03:33:48.587: INFO: Pod "downward-api-2d05e2f9-2a89-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:33:48.589: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod downward-api-2d05e2f9-2a89-11e9-87fe-baa4eca941e3 container dapi-container: <nil>
STEP: delete the pod
Feb  7 03:33:48.604: INFO: Waiting for pod downward-api-2d05e2f9-2a89-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:33:48.606: INFO: Pod downward-api-2d05e2f9-2a89-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:33:48.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-vxzzh" for this suite.
Feb  7 03:33:56.946: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:33:57.126: INFO: namespace: e2e-tests-downward-api-vxzzh, resource: bindings, ignored listing per whitelist
Feb  7 03:33:57.139: INFO: namespace e2e-tests-downward-api-vxzzh deletion completed in 8.528776864s

• [SLOW TEST:10.617 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:33:57.139: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-335a1415-2a89-11e9-87fe-baa4eca941e3
STEP: Creating a pod to test consume secrets
Feb  7 03:33:57.204: INFO: Waiting up to 5m0s for pod "pod-secrets-335aeffb-2a89-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-secrets-l7b8q" to be "success or failure"
Feb  7 03:33:57.206: INFO: Pod "pod-secrets-335aeffb-2a89-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.962792ms
Feb  7 03:33:59.209: INFO: Pod "pod-secrets-335aeffb-2a89-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005001896s
STEP: Saw pod success
Feb  7 03:33:59.209: INFO: Pod "pod-secrets-335aeffb-2a89-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:33:59.220: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod pod-secrets-335aeffb-2a89-11e9-87fe-baa4eca941e3 container secret-env-test: <nil>
STEP: delete the pod
Feb  7 03:33:59.235: INFO: Waiting for pod pod-secrets-335aeffb-2a89-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:33:59.237: INFO: Pod pod-secrets-335aeffb-2a89-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:33:59.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-l7b8q" for this suite.
Feb  7 03:34:07.260: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:34:07.371: INFO: namespace: e2e-tests-secrets-l7b8q, resource: bindings, ignored listing per whitelist
Feb  7 03:34:07.498: INFO: namespace e2e-tests-secrets-l7b8q deletion completed in 8.256721799s

• [SLOW TEST:10.359 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:34:07.499: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:34:09.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-wmbmc" for this suite.
Feb  7 03:34:47.585: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:34:47.593: INFO: namespace: e2e-tests-kubelet-test-wmbmc, resource: bindings, ignored listing per whitelist
Feb  7 03:34:47.685: INFO: namespace e2e-tests-kubelet-test-wmbmc deletion completed in 38.110095741s

• [SLOW TEST:40.187 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:34:47.685: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb  7 03:34:47.745: INFO: Waiting up to 5m0s for pod "downward-api-517a91d9-2a89-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-downward-api-98nn4" to be "success or failure"
Feb  7 03:34:47.747: INFO: Pod "downward-api-517a91d9-2a89-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.99379ms
Feb  7 03:34:49.751: INFO: Pod "downward-api-517a91d9-2a89-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005169525s
STEP: Saw pod success
Feb  7 03:34:49.751: INFO: Pod "downward-api-517a91d9-2a89-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:34:49.753: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod downward-api-517a91d9-2a89-11e9-87fe-baa4eca941e3 container dapi-container: <nil>
STEP: delete the pod
Feb  7 03:34:49.768: INFO: Waiting for pod downward-api-517a91d9-2a89-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:34:49.771: INFO: Pod downward-api-517a91d9-2a89-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:34:49.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-98nn4" for this suite.
Feb  7 03:34:55.785: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:34:55.851: INFO: namespace: e2e-tests-downward-api-98nn4, resource: bindings, ignored listing per whitelist
Feb  7 03:34:55.934: INFO: namespace e2e-tests-downward-api-98nn4 deletion completed in 6.160054997s

• [SLOW TEST:8.249 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:34:55.935: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-56ef0a51-2a89-11e9-87fe-baa4eca941e3
STEP: Creating a pod to test consume configMaps
Feb  7 03:34:56.900: INFO: Waiting up to 5m0s for pod "pod-configmaps-56efc3de-2a89-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-configmap-vg4j7" to be "success or failure"
Feb  7 03:34:56.902: INFO: Pod "pod-configmaps-56efc3de-2a89-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.939631ms
Feb  7 03:34:58.905: INFO: Pod "pod-configmaps-56efc3de-2a89-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004934913s
STEP: Saw pod success
Feb  7 03:34:58.905: INFO: Pod "pod-configmaps-56efc3de-2a89-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:34:58.908: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod pod-configmaps-56efc3de-2a89-11e9-87fe-baa4eca941e3 container configmap-volume-test: <nil>
STEP: delete the pod
Feb  7 03:34:58.924: INFO: Waiting for pod pod-configmaps-56efc3de-2a89-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:34:58.927: INFO: Pod pod-configmaps-56efc3de-2a89-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:34:58.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-vg4j7" for this suite.
Feb  7 03:35:05.421: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:35:05.489: INFO: namespace: e2e-tests-configmap-vg4j7, resource: bindings, ignored listing per whitelist
Feb  7 03:35:05.537: INFO: namespace e2e-tests-configmap-vg4j7 deletion completed in 6.605711232s

• [SLOW TEST:9.602 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:35:05.537: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Feb  7 03:35:05.595: INFO: Waiting up to 5m0s for pod "var-expansion-5c1e3c01-2a89-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-var-expansion-9g27n" to be "success or failure"
Feb  7 03:35:05.597: INFO: Pod "var-expansion-5c1e3c01-2a89-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025451ms
Feb  7 03:35:07.600: INFO: Pod "var-expansion-5c1e3c01-2a89-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004828659s
STEP: Saw pod success
Feb  7 03:35:07.600: INFO: Pod "var-expansion-5c1e3c01-2a89-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:35:07.602: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod var-expansion-5c1e3c01-2a89-11e9-87fe-baa4eca941e3 container dapi-container: <nil>
STEP: delete the pod
Feb  7 03:35:07.619: INFO: Waiting for pod var-expansion-5c1e3c01-2a89-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:35:07.621: INFO: Pod var-expansion-5c1e3c01-2a89-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:35:07.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-9g27n" for this suite.
Feb  7 03:35:15.914: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:35:15.998: INFO: namespace: e2e-tests-var-expansion-9g27n, resource: bindings, ignored listing per whitelist
Feb  7 03:35:16.011: INFO: namespace e2e-tests-var-expansion-9g27n deletion completed in 8.387652497s

• [SLOW TEST:10.474 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:35:16.011: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb  7 03:35:16.062: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:35:19.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-gvh6f" for this suite.
Feb  7 03:35:27.518: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:35:27.832: INFO: namespace: e2e-tests-init-container-gvh6f, resource: bindings, ignored listing per whitelist
Feb  7 03:35:27.907: INFO: namespace e2e-tests-init-container-gvh6f deletion completed in 8.563804266s

• [SLOW TEST:11.896 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:35:27.907: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Feb  7 03:35:27.980: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 api-versions'
Feb  7 03:35:28.042: INFO: stderr: ""
Feb  7 03:35:28.042: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nark.heptio.com/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\ncsi.storage.k8s.io/v1alpha1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:35:28.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ml8ft" for this suite.
Feb  7 03:35:34.144: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:35:34.198: INFO: namespace: e2e-tests-kubectl-ml8ft, resource: bindings, ignored listing per whitelist
Feb  7 03:35:34.243: INFO: namespace e2e-tests-kubectl-ml8ft deletion completed in 6.196528243s

• [SLOW TEST:6.335 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:35:34.243: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb  7 03:35:34.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-hljcf'
Feb  7 03:35:34.374: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb  7 03:35:34.374: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Feb  7 03:35:34.376: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-hljcf'
Feb  7 03:35:35.144: INFO: stderr: ""
Feb  7 03:35:35.144: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:35:35.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hljcf" for this suite.
Feb  7 03:35:43.553: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:35:43.716: INFO: namespace: e2e-tests-kubectl-hljcf, resource: bindings, ignored listing per whitelist
Feb  7 03:35:43.718: INFO: namespace e2e-tests-kubectl-hljcf deletion completed in 8.570771906s

• [SLOW TEST:9.476 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:35:43.719: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-lg6rk
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb  7 03:35:43.770: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb  7 03:36:05.829: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 192.168.5.177 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-lg6rk PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  7 03:36:05.829: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
Feb  7 03:36:06.923: INFO: Found all expected endpoints: [netserver-0]
Feb  7 03:36:07.220: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 192.168.3.53 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-lg6rk PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  7 03:36:07.220: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
Feb  7 03:36:08.302: INFO: Found all expected endpoints: [netserver-1]
Feb  7 03:36:08.305: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 192.168.4.45 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-lg6rk PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  7 03:36:08.305: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
Feb  7 03:36:09.402: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:36:09.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-lg6rk" for this suite.
Feb  7 03:36:31.416: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:36:31.584: INFO: namespace: e2e-tests-pod-network-test-lg6rk, resource: bindings, ignored listing per whitelist
Feb  7 03:36:31.656: INFO: namespace e2e-tests-pod-network-test-lg6rk deletion completed in 22.250681031s

• [SLOW TEST:47.938 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:36:31.656: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:36:57.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-runtime-5hr8v" for this suite.
Feb  7 03:37:03.446: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:37:03.971: INFO: namespace: e2e-tests-container-runtime-5hr8v, resource: bindings, ignored listing per whitelist
Feb  7 03:37:04.078: INFO: namespace e2e-tests-container-runtime-5hr8v deletion completed in 6.92715754s

• [SLOW TEST:32.422 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  blackbox test
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:37:04.078: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-r589f
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb  7 03:37:04.131: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb  7 03:37:26.246: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.5.183:8080/dial?request=hostName&protocol=http&host=192.168.4.46&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-r589f PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  7 03:37:26.246: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
Feb  7 03:37:26.341: INFO: Waiting for endpoints: map[]
Feb  7 03:37:26.361: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.5.183:8080/dial?request=hostName&protocol=http&host=192.168.3.54&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-r589f PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  7 03:37:26.362: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
Feb  7 03:37:26.446: INFO: Waiting for endpoints: map[]
Feb  7 03:37:26.816: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.5.183:8080/dial?request=hostName&protocol=http&host=192.168.5.182&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-r589f PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  7 03:37:26.816: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
Feb  7 03:37:26.899: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:37:26.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-r589f" for this suite.
Feb  7 03:37:50.914: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:37:51.041: INFO: namespace: e2e-tests-pod-network-test-r589f, resource: bindings, ignored listing per whitelist
Feb  7 03:37:51.044: INFO: namespace e2e-tests-pod-network-test-r589f deletion completed in 24.141576727s

• [SLOW TEST:46.966 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:37:51.044: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  7 03:37:51.109: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bec5a1f1-2a89-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-projected-v42zx" to be "success or failure"
Feb  7 03:37:51.111: INFO: Pod "downwardapi-volume-bec5a1f1-2a89-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004027ms
Feb  7 03:37:53.114: INFO: Pod "downwardapi-volume-bec5a1f1-2a89-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004874747s
STEP: Saw pod success
Feb  7 03:37:53.114: INFO: Pod "downwardapi-volume-bec5a1f1-2a89-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:37:53.116: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod downwardapi-volume-bec5a1f1-2a89-11e9-87fe-baa4eca941e3 container client-container: <nil>
STEP: delete the pod
Feb  7 03:37:53.131: INFO: Waiting for pod downwardapi-volume-bec5a1f1-2a89-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:37:53.132: INFO: Pod downwardapi-volume-bec5a1f1-2a89-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:37:53.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-v42zx" for this suite.
Feb  7 03:38:01.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:38:01.170: INFO: namespace: e2e-tests-projected-v42zx, resource: bindings, ignored listing per whitelist
Feb  7 03:38:01.257: INFO: namespace e2e-tests-projected-v42zx deletion completed in 8.121191291s

• [SLOW TEST:10.213 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:38:01.257: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Feb  7 03:38:03.327: INFO: Pod pod-hostip-c4db56f5-2a89-11e9-87fe-baa4eca941e3 has hostIP: 9.0.1.4
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:38:03.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-76mjc" for this suite.
Feb  7 03:38:25.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:38:25.372: INFO: namespace: e2e-tests-pods-76mjc, resource: bindings, ignored listing per whitelist
Feb  7 03:38:25.436: INFO: namespace e2e-tests-pods-76mjc deletion completed in 22.105390628s

• [SLOW TEST:24.179 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:38:25.436: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb  7 03:38:25.490: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-sgtpf'
Feb  7 03:38:26.034: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb  7 03:38:26.034: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1268
Feb  7 03:38:28.040: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-sgtpf'
Feb  7 03:38:28.118: INFO: stderr: ""
Feb  7 03:38:28.118: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:38:28.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-sgtpf" for this suite.
Feb  7 03:38:36.131: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:38:36.178: INFO: namespace: e2e-tests-kubectl-sgtpf, resource: bindings, ignored listing per whitelist
Feb  7 03:38:36.231: INFO: namespace e2e-tests-kubectl-sgtpf deletion completed in 8.109801125s

• [SLOW TEST:10.796 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:38:36.232: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:38:41.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-rjhbr" for this suite.
Feb  7 03:38:47.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:38:47.187: INFO: namespace: e2e-tests-kubelet-test-rjhbr, resource: bindings, ignored listing per whitelist
Feb  7 03:38:47.215: INFO: namespace e2e-tests-kubelet-test-rjhbr deletion completed in 6.182122212s

• [SLOW TEST:10.983 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:38:47.215: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-e03fbcb0-2a89-11e9-87fe-baa4eca941e3
STEP: Creating a pod to test consume secrets
Feb  7 03:38:47.278: INFO: Waiting up to 5m0s for pod "pod-secrets-e0407c18-2a89-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-secrets-gqf5z" to be "success or failure"
Feb  7 03:38:47.280: INFO: Pod "pod-secrets-e0407c18-2a89-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.973687ms
Feb  7 03:38:49.283: INFO: Pod "pod-secrets-e0407c18-2a89-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004736423s
STEP: Saw pod success
Feb  7 03:38:49.283: INFO: Pod "pod-secrets-e0407c18-2a89-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:38:49.285: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod pod-secrets-e0407c18-2a89-11e9-87fe-baa4eca941e3 container secret-volume-test: <nil>
STEP: delete the pod
Feb  7 03:38:49.340: INFO: Waiting for pod pod-secrets-e0407c18-2a89-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:38:49.342: INFO: Pod pod-secrets-e0407c18-2a89-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:38:49.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-gqf5z" for this suite.
Feb  7 03:38:55.363: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:38:55.410: INFO: namespace: e2e-tests-secrets-gqf5z, resource: bindings, ignored listing per whitelist
Feb  7 03:38:55.461: INFO: namespace e2e-tests-secrets-gqf5z deletion completed in 6.115097969s

• [SLOW TEST:8.246 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:38:55.461: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb  7 03:38:55.516: INFO: Waiting up to 5m0s for pod "pod-e52979d8-2a89-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-emptydir-gxv6l" to be "success or failure"
Feb  7 03:38:55.518: INFO: Pod "pod-e52979d8-2a89-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.822306ms
Feb  7 03:38:57.521: INFO: Pod "pod-e52979d8-2a89-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005014194s
STEP: Saw pod success
Feb  7 03:38:57.521: INFO: Pod "pod-e52979d8-2a89-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:38:57.524: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod pod-e52979d8-2a89-11e9-87fe-baa4eca941e3 container test-container: <nil>
STEP: delete the pod
Feb  7 03:38:57.539: INFO: Waiting for pod pod-e52979d8-2a89-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:38:57.541: INFO: Pod pod-e52979d8-2a89-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:38:57.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-gxv6l" for this suite.
Feb  7 03:39:03.556: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:39:03.873: INFO: namespace: e2e-tests-emptydir-gxv6l, resource: bindings, ignored listing per whitelist
Feb  7 03:39:03.923: INFO: namespace e2e-tests-emptydir-gxv6l deletion completed in 6.378490182s

• [SLOW TEST:8.461 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:39:03.923: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  7 03:39:03.984: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ea356fbf-2a89-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-projected-6wnls" to be "success or failure"
Feb  7 03:39:03.986: INFO: Pod "downwardapi-volume-ea356fbf-2a89-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.911354ms
Feb  7 03:39:05.993: INFO: Pod "downwardapi-volume-ea356fbf-2a89-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009285812s
STEP: Saw pod success
Feb  7 03:39:05.993: INFO: Pod "downwardapi-volume-ea356fbf-2a89-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:39:05.995: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod downwardapi-volume-ea356fbf-2a89-11e9-87fe-baa4eca941e3 container client-container: <nil>
STEP: delete the pod
Feb  7 03:39:06.010: INFO: Waiting for pod downwardapi-volume-ea356fbf-2a89-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:39:06.012: INFO: Pod downwardapi-volume-ea356fbf-2a89-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:39:06.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6wnls" for this suite.
Feb  7 03:39:12.026: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:39:12.161: INFO: namespace: e2e-tests-projected-6wnls, resource: bindings, ignored listing per whitelist
Feb  7 03:39:12.188: INFO: namespace e2e-tests-projected-6wnls deletion completed in 6.173180158s

• [SLOW TEST:8.265 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:39:12.188: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Feb  7 03:39:12.432: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-4nvgz,SelfLink:/api/v1/namespaces/e2e-tests-watch-4nvgz/configmaps/e2e-watch-test-label-changed,UID:ef280854-2a89-11e9-809d-e6a419c8531a,ResourceVersion:18949,Generation:0,CreationTimestamp:2019-02-07 03:39:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb  7 03:39:12.432: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-4nvgz,SelfLink:/api/v1/namespaces/e2e-tests-watch-4nvgz/configmaps/e2e-watch-test-label-changed,UID:ef280854-2a89-11e9-809d-e6a419c8531a,ResourceVersion:18950,Generation:0,CreationTimestamp:2019-02-07 03:39:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb  7 03:39:12.432: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-4nvgz,SelfLink:/api/v1/namespaces/e2e-tests-watch-4nvgz/configmaps/e2e-watch-test-label-changed,UID:ef280854-2a89-11e9-809d-e6a419c8531a,ResourceVersion:18951,Generation:0,CreationTimestamp:2019-02-07 03:39:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Feb  7 03:39:22.533: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-4nvgz,SelfLink:/api/v1/namespaces/e2e-tests-watch-4nvgz/configmaps/e2e-watch-test-label-changed,UID:ef280854-2a89-11e9-809d-e6a419c8531a,ResourceVersion:18971,Generation:0,CreationTimestamp:2019-02-07 03:39:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb  7 03:39:22.534: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-4nvgz,SelfLink:/api/v1/namespaces/e2e-tests-watch-4nvgz/configmaps/e2e-watch-test-label-changed,UID:ef280854-2a89-11e9-809d-e6a419c8531a,ResourceVersion:18972,Generation:0,CreationTimestamp:2019-02-07 03:39:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Feb  7 03:39:22.534: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-4nvgz,SelfLink:/api/v1/namespaces/e2e-tests-watch-4nvgz/configmaps/e2e-watch-test-label-changed,UID:ef280854-2a89-11e9-809d-e6a419c8531a,ResourceVersion:18973,Generation:0,CreationTimestamp:2019-02-07 03:39:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:39:22.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-4nvgz" for this suite.
Feb  7 03:39:28.788: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:39:28.865: INFO: namespace: e2e-tests-watch-4nvgz, resource: bindings, ignored listing per whitelist
Feb  7 03:39:28.883: INFO: namespace e2e-tests-watch-4nvgz deletion completed in 6.345986584s

• [SLOW TEST:16.695 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:39:28.883: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Feb  7 03:39:28.957: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-4fkf8,SelfLink:/api/v1/namespaces/e2e-tests-watch-4fkf8/configmaps/e2e-watch-test-resource-version,UID:f91bb023-2a89-11e9-809d-e6a419c8531a,ResourceVersion:18999,Generation:0,CreationTimestamp:2019-02-07 03:39:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb  7 03:39:28.958: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-4fkf8,SelfLink:/api/v1/namespaces/e2e-tests-watch-4fkf8/configmaps/e2e-watch-test-resource-version,UID:f91bb023-2a89-11e9-809d-e6a419c8531a,ResourceVersion:19000,Generation:0,CreationTimestamp:2019-02-07 03:39:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:39:28.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-4fkf8" for this suite.
Feb  7 03:39:35.473: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:39:35.537: INFO: namespace: e2e-tests-watch-4fkf8, resource: bindings, ignored listing per whitelist
Feb  7 03:39:35.631: INFO: namespace e2e-tests-watch-4fkf8 deletion completed in 6.670910259s

• [SLOW TEST:6.749 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:39:35.632: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-r7tcq/configmap-test-fd1b2cce-2a89-11e9-87fe-baa4eca941e3
STEP: Creating a pod to test consume configMaps
Feb  7 03:39:35.692: INFO: Waiting up to 5m0s for pod "pod-configmaps-fd1bebe1-2a89-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-configmap-r7tcq" to be "success or failure"
Feb  7 03:39:35.694: INFO: Pod "pod-configmaps-fd1bebe1-2a89-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.810791ms
Feb  7 03:39:37.697: INFO: Pod "pod-configmaps-fd1bebe1-2a89-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004925167s
STEP: Saw pod success
Feb  7 03:39:37.697: INFO: Pod "pod-configmaps-fd1bebe1-2a89-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:39:37.699: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod pod-configmaps-fd1bebe1-2a89-11e9-87fe-baa4eca941e3 container env-test: <nil>
STEP: delete the pod
Feb  7 03:39:37.716: INFO: Waiting for pod pod-configmaps-fd1bebe1-2a89-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:39:37.718: INFO: Pod pod-configmaps-fd1bebe1-2a89-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:39:37.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-r7tcq" for this suite.
Feb  7 03:39:43.735: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:39:43.818: INFO: namespace: e2e-tests-configmap-r7tcq, resource: bindings, ignored listing per whitelist
Feb  7 03:39:43.833: INFO: namespace e2e-tests-configmap-r7tcq deletion completed in 6.11120711s

• [SLOW TEST:8.201 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:39:43.833: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0207 03:39:54.198409      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb  7 03:39:54.198: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:39:54.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-nhl5p" for this suite.
Feb  7 03:40:00.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:40:00.430: INFO: namespace: e2e-tests-gc-nhl5p, resource: bindings, ignored listing per whitelist
Feb  7 03:40:00.430: INFO: namespace e2e-tests-gc-nhl5p deletion completed in 6.228882975s

• [SLOW TEST:16.598 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:40:00.430: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb  7 03:40:04.515: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  7 03:40:04.517: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  7 03:40:06.518: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  7 03:40:06.521: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  7 03:40:08.518: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  7 03:40:08.663: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  7 03:40:10.518: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  7 03:40:10.520: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  7 03:40:12.518: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  7 03:40:12.520: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  7 03:40:14.518: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  7 03:40:14.525: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  7 03:40:16.518: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  7 03:40:16.521: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  7 03:40:18.518: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  7 03:40:18.520: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  7 03:40:20.518: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  7 03:40:20.521: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  7 03:40:22.518: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  7 03:40:22.521: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  7 03:40:24.518: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  7 03:40:24.521: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:40:24.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-m5wjb" for this suite.
Feb  7 03:40:46.548: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:40:46.649: INFO: namespace: e2e-tests-container-lifecycle-hook-m5wjb, resource: bindings, ignored listing per whitelist
Feb  7 03:40:46.649: INFO: namespace e2e-tests-container-lifecycle-hook-m5wjb deletion completed in 22.114908659s

• [SLOW TEST:46.219 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:40:46.649: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-tf2dt.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-tf2dt.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-tf2dt.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-tf2dt.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-tf2dt.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-tf2dt.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb  7 03:40:48.802: INFO: DNS probes using e2e-tests-dns-tf2dt/dns-test-277574c3-2a8a-11e9-87fe-baa4eca941e3 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:40:48.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-tf2dt" for this suite.
Feb  7 03:40:55.419: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:40:55.459: INFO: namespace: e2e-tests-dns-tf2dt, resource: bindings, ignored listing per whitelist
Feb  7 03:40:55.523: INFO: namespace e2e-tests-dns-tf2dt deletion completed in 6.707975209s

• [SLOW TEST:8.874 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:40:55.524: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-2cb9e807-2a8a-11e9-87fe-baa4eca941e3
STEP: Creating a pod to test consume configMaps
Feb  7 03:40:55.589: INFO: Waiting up to 5m0s for pod "pod-configmaps-2cbb05ca-2a8a-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-configmap-md77s" to be "success or failure"
Feb  7 03:40:55.591: INFO: Pod "pod-configmaps-2cbb05ca-2a8a-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.084461ms
Feb  7 03:40:57.770: INFO: Pod "pod-configmaps-2cbb05ca-2a8a-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.181557421s
STEP: Saw pod success
Feb  7 03:40:57.770: INFO: Pod "pod-configmaps-2cbb05ca-2a8a-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:40:57.772: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod pod-configmaps-2cbb05ca-2a8a-11e9-87fe-baa4eca941e3 container configmap-volume-test: <nil>
STEP: delete the pod
Feb  7 03:40:57.785: INFO: Waiting for pod pod-configmaps-2cbb05ca-2a8a-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:40:57.787: INFO: Pod pod-configmaps-2cbb05ca-2a8a-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:40:57.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-md77s" for this suite.
Feb  7 03:41:03.802: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:41:03.825: INFO: namespace: e2e-tests-configmap-md77s, resource: bindings, ignored listing per whitelist
Feb  7 03:41:03.899: INFO: namespace e2e-tests-configmap-md77s deletion completed in 6.108544683s

• [SLOW TEST:8.375 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:41:03.899: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  7 03:41:03.950: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Feb  7 03:41:03.958: INFO: Pod name sample-pod: Found 0 pods out of 1
Feb  7 03:41:08.965: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb  7 03:41:08.965: INFO: Creating deployment "test-rolling-update-deployment"
Feb  7 03:41:08.969: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Feb  7 03:41:08.974: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Feb  7 03:41:11.188: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Feb  7 03:41:11.190: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685107669, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685107669, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685107669, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685107668, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-68b55d7bc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  7 03:41:13.234: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb  7 03:41:13.316: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-5l9sb,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-5l9sb/deployments/test-rolling-update-deployment,UID:34bb4985-2a8a-11e9-809d-e6a419c8531a,ResourceVersion:19448,Generation:1,CreationTimestamp:2019-02-07 03:41:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-02-07 03:41:09 +0000 UTC 2019-02-07 03:41:09 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-02-07 03:41:11 +0000 UTC 2019-02-07 03:41:08 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-68b55d7bc6" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb  7 03:41:13.319: INFO: New ReplicaSet "test-rolling-update-deployment-68b55d7bc6" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6,GenerateName:,Namespace:e2e-tests-deployment-5l9sb,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-5l9sb/replicasets/test-rolling-update-deployment-68b55d7bc6,UID:34b76059-2a8a-11e9-927c-4a513db42ba3,ResourceVersion:19440,Generation:1,CreationTimestamp:2019-02-07 03:41:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 34bb4985-2a8a-11e9-809d-e6a419c8531a 0xc001a94a97 0xc001a94a98}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb  7 03:41:13.319: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Feb  7 03:41:13.319: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-5l9sb,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-5l9sb/replicasets/test-rolling-update-controller,UID:31be0791-2a8a-11e9-809d-e6a419c8531a,ResourceVersion:19447,Generation:2,CreationTimestamp:2019-02-07 03:41:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 34bb4985-2a8a-11e9-809d-e6a419c8531a 0xc001a949c7 0xc001a949c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb  7 03:41:13.322: INFO: Pod "test-rolling-update-deployment-68b55d7bc6-b58r6" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6-b58r6,GenerateName:test-rolling-update-deployment-68b55d7bc6-,Namespace:e2e-tests-deployment-5l9sb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5l9sb/pods/test-rolling-update-deployment-68b55d7bc6-b58r6,UID:34b7dbfb-2a8a-11e9-927c-4a513db42ba3,ResourceVersion:19439,Generation:0,CreationTimestamp:2019-02-07 03:41:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.4.47/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-68b55d7bc6 34b76059-2a8a-11e9-927c-4a513db42ba3 0xc00068b797 0xc00068b798}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dxq68 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dxq68,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-dxq68 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-node-1-kubelet.devkubernetes01.mesos,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00068b890} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00068b8c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:41:09 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:41:10 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:41:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:41:09 +0000 UTC  }],Message:,Reason:,HostIP:9.0.1.3,PodIP:192.168.4.47,StartTime:2019-02-07 03:41:09 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-02-07 03:41:09 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://3bf2a31c287d74ab07a9234fcd37d7d30c0dd3483d60bd2c6b85042b0546b1ad}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:41:13.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-5l9sb" for this suite.
Feb  7 03:41:19.339: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:41:19.386: INFO: namespace: e2e-tests-deployment-5l9sb, resource: bindings, ignored listing per whitelist
Feb  7 03:41:19.851: INFO: namespace e2e-tests-deployment-5l9sb deletion completed in 6.526296688s

• [SLOW TEST:15.952 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:41:19.851: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-3b3b138f-2a8a-11e9-87fe-baa4eca941e3
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:41:21.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-q4l6j" for this suite.
Feb  7 03:41:43.951: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:41:44.126: INFO: namespace: e2e-tests-configmap-q4l6j, resource: bindings, ignored listing per whitelist
Feb  7 03:41:44.135: INFO: namespace e2e-tests-configmap-q4l6j deletion completed in 22.194588704s

• [SLOW TEST:24.284 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:41:44.135: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Feb  7 03:41:44.187: INFO: namespace e2e-tests-kubectl-xh786
Feb  7 03:41:44.187: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 create -f - --namespace=e2e-tests-kubectl-xh786'
Feb  7 03:41:44.621: INFO: stderr: ""
Feb  7 03:41:44.621: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb  7 03:41:45.623: INFO: Selector matched 1 pods for map[app:redis]
Feb  7 03:41:45.623: INFO: Found 1 / 1
Feb  7 03:41:45.624: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb  7 03:41:45.626: INFO: Selector matched 1 pods for map[app:redis]
Feb  7 03:41:45.626: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb  7 03:41:45.626: INFO: wait on redis-master startup in e2e-tests-kubectl-xh786 
Feb  7 03:41:45.626: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 logs redis-master-dg6jf redis-master --namespace=e2e-tests-kubectl-xh786'
Feb  7 03:41:45.697: INFO: stderr: ""
Feb  7 03:41:45.697: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 07 Feb 03:41:45.355 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 07 Feb 03:41:45.355 # Server started, Redis version 3.2.12\n1:M 07 Feb 03:41:45.355 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 07 Feb 03:41:45.355 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Feb  7 03:41:45.697: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-xh786'
Feb  7 03:41:45.778: INFO: stderr: ""
Feb  7 03:41:45.778: INFO: stdout: "service/rm2 exposed\n"
Feb  7 03:41:45.780: INFO: Service rm2 in namespace e2e-tests-kubectl-xh786 found.
STEP: exposing service
Feb  7 03:41:47.816: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-xh786'
Feb  7 03:41:47.897: INFO: stderr: ""
Feb  7 03:41:47.897: INFO: stdout: "service/rm3 exposed\n"
Feb  7 03:41:47.900: INFO: Service rm3 in namespace e2e-tests-kubectl-xh786 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:41:49.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xh786" for this suite.
Feb  7 03:42:11.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:42:11.978: INFO: namespace: e2e-tests-kubectl-xh786, resource: bindings, ignored listing per whitelist
Feb  7 03:42:12.018: INFO: namespace e2e-tests-kubectl-xh786 deletion completed in 22.110688077s

• [SLOW TEST:27.884 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:42:12.019: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  7 03:42:12.083: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Feb  7 03:42:17.116: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb  7 03:42:17.116: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb  7 03:42:17.130: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-tvm2c,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-tvm2c/deployments/test-cleanup-deployment,UID:5d5b03ac-2a8a-11e9-809d-e6a419c8531a,ResourceVersion:19702,Generation:1,CreationTimestamp:2019-02-07 03:42:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Feb  7 03:42:17.132: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:42:17.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-tvm2c" for this suite.
Feb  7 03:42:25.148: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:42:25.259: INFO: namespace: e2e-tests-deployment-tvm2c, resource: bindings, ignored listing per whitelist
Feb  7 03:42:25.333: INFO: namespace e2e-tests-deployment-tvm2c deletion completed in 8.195189661s

• [SLOW TEST:13.315 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:42:25.333: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Feb  7 03:42:25.388: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb  7 03:42:25.394: INFO: Waiting for terminating namespaces to be deleted...
Feb  7 03:42:25.397: INFO: 
Logging pods the kubelet thinks is on node kube-node-0-kubelet.devkubernetes01.mesos before test
Feb  7 03:42:25.401: INFO: kube-proxy-kube-node-0-kubelet.devkubernetes01.mesos from kube-system started at <nil> (0 container statuses recorded)
Feb  7 03:42:25.401: INFO: local-dns-dispatcher-kube-node-0-kubelet.devkubernetes01.mesos from kube-system started at <nil> (0 container statuses recorded)
Feb  7 03:42:25.401: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-07 02:33:25 +0000 UTC (1 container statuses recorded)
Feb  7 03:42:25.401: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb  7 03:42:25.401: INFO: calico-node-n2c9f from kube-system started at 2019-02-07 02:26:23 +0000 UTC (2 container statuses recorded)
Feb  7 03:42:25.401: INFO: 	Container calico-node ready: true, restart count 0
Feb  7 03:42:25.401: INFO: 	Container install-cni ready: true, restart count 0
Feb  7 03:42:25.401: INFO: sonobuoy-systemd-logs-daemon-set-3418c9e540594be1-n22q8 from heptio-sonobuoy started at 2019-02-07 02:33:29 +0000 UTC (2 container statuses recorded)
Feb  7 03:42:25.401: INFO: 	Container sonobuoy-systemd-logs-config ready: false, restart count 18
Feb  7 03:42:25.401: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  7 03:42:25.401: INFO: 
Logging pods the kubelet thinks is on node kube-node-1-kubelet.devkubernetes01.mesos before test
Feb  7 03:42:25.405: INFO: sonobuoy-systemd-logs-daemon-set-3418c9e540594be1-cx7gt from heptio-sonobuoy started at 2019-02-07 02:33:29 +0000 UTC (2 container statuses recorded)
Feb  7 03:42:25.405: INFO: 	Container sonobuoy-systemd-logs-config ready: false, restart count 18
Feb  7 03:42:25.405: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  7 03:42:25.405: INFO: local-dns-dispatcher-kube-node-1-kubelet.devkubernetes01.mesos from kube-system started at <nil> (0 container statuses recorded)
Feb  7 03:42:25.405: INFO: calico-node-5snr5 from kube-system started at 2019-02-07 02:26:23 +0000 UTC (2 container statuses recorded)
Feb  7 03:42:25.405: INFO: 	Container calico-node ready: true, restart count 0
Feb  7 03:42:25.405: INFO: 	Container install-cni ready: true, restart count 0
Feb  7 03:42:25.405: INFO: kube-proxy-kube-node-1-kubelet.devkubernetes01.mesos from kube-system started at <nil> (0 container statuses recorded)
Feb  7 03:42:25.405: INFO: coredns-fb6c4f575-rzxqz from kube-system started at 2019-02-07 02:26:43 +0000 UTC (1 container statuses recorded)
Feb  7 03:42:25.405: INFO: 	Container coredns ready: true, restart count 0
Feb  7 03:42:25.405: INFO: sonobuoy-e2e-job-0cc94a58d02847bf from heptio-sonobuoy started at 2019-02-07 02:33:29 +0000 UTC (2 container statuses recorded)
Feb  7 03:42:25.405: INFO: 	Container e2e ready: true, restart count 0
Feb  7 03:42:25.405: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  7 03:42:25.405: INFO: 
Logging pods the kubelet thinks is on node kube-node-2-kubelet.devkubernetes01.mesos before test
Feb  7 03:42:25.410: INFO: coredns-fb6c4f575-8xlfk from kube-system started at 2019-02-07 02:26:36 +0000 UTC (1 container statuses recorded)
Feb  7 03:42:25.410: INFO: 	Container coredns ready: true, restart count 0
Feb  7 03:42:25.410: INFO: kubernetes-dashboard-6d87d489d4-d8zr7 from kube-system started at 2019-02-07 02:26:36 +0000 UTC (1 container statuses recorded)
Feb  7 03:42:25.410: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Feb  7 03:42:25.410: INFO: sonobuoy-systemd-logs-daemon-set-3418c9e540594be1-dd7p4 from heptio-sonobuoy started at 2019-02-07 02:33:29 +0000 UTC (2 container statuses recorded)
Feb  7 03:42:25.410: INFO: 	Container sonobuoy-systemd-logs-config ready: false, restart count 18
Feb  7 03:42:25.410: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  7 03:42:25.410: INFO: local-dns-dispatcher-kube-node-2-kubelet.devkubernetes01.mesos from kube-system started at <nil> (0 container statuses recorded)
Feb  7 03:42:25.410: INFO: calico-node-gmcd4 from kube-system started at 2019-02-07 02:26:17 +0000 UTC (2 container statuses recorded)
Feb  7 03:42:25.410: INFO: 	Container calico-node ready: true, restart count 0
Feb  7 03:42:25.410: INFO: 	Container install-cni ready: true, restart count 0
Feb  7 03:42:25.410: INFO: metrics-server-7ddfc7695-b8l5f from kube-system started at 2019-02-07 02:26:36 +0000 UTC (1 container statuses recorded)
Feb  7 03:42:25.410: INFO: 	Container metrics-server ready: true, restart count 0
Feb  7 03:42:25.410: INFO: kube-proxy-kube-node-2-kubelet.devkubernetes01.mesos from kube-system started at <nil> (0 container statuses recorded)
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1580f7fec5a6d743], Reason = [FailedScheduling], Message = [0/6 nodes are available: 6 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:42:26.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-9l2j8" for this suite.
Feb  7 03:42:32.446: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:42:32.557: INFO: namespace: e2e-tests-sched-pred-9l2j8, resource: bindings, ignored listing per whitelist
Feb  7 03:42:32.630: INFO: namespace e2e-tests-sched-pred-9l2j8 deletion completed in 6.195636822s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.296 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:42:32.630: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Feb  7 03:42:37.709: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:42:38.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-mw2km" for this suite.
Feb  7 03:43:02.737: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:43:02.861: INFO: namespace: e2e-tests-replicaset-mw2km, resource: bindings, ignored listing per whitelist
Feb  7 03:43:02.905: INFO: namespace e2e-tests-replicaset-mw2km deletion completed in 24.17786583s

• [SLOW TEST:30.275 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:43:02.905: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-2ztqt/configmap-test-78a6de79-2a8a-11e9-87fe-baa4eca941e3
STEP: Creating a pod to test consume configMaps
Feb  7 03:43:02.966: INFO: Waiting up to 5m0s for pod "pod-configmaps-78a7a144-2a8a-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-configmap-2ztqt" to be "success or failure"
Feb  7 03:43:02.968: INFO: Pod "pod-configmaps-78a7a144-2a8a-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.903365ms
Feb  7 03:43:05.539: INFO: Pod "pod-configmaps-78a7a144-2a8a-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.572836781s
STEP: Saw pod success
Feb  7 03:43:05.539: INFO: Pod "pod-configmaps-78a7a144-2a8a-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:43:05.613: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod pod-configmaps-78a7a144-2a8a-11e9-87fe-baa4eca941e3 container env-test: <nil>
STEP: delete the pod
Feb  7 03:43:05.635: INFO: Waiting for pod pod-configmaps-78a7a144-2a8a-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:43:05.637: INFO: Pod pod-configmaps-78a7a144-2a8a-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:43:05.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-2ztqt" for this suite.
Feb  7 03:43:11.717: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:43:11.918: INFO: namespace: e2e-tests-configmap-2ztqt, resource: bindings, ignored listing per whitelist
Feb  7 03:43:11.943: INFO: namespace e2e-tests-configmap-2ztqt deletion completed in 6.302574441s

• [SLOW TEST:9.039 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:43:11.944: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-7e09c4ad-2a8a-11e9-87fe-baa4eca941e3
STEP: Creating a pod to test consume configMaps
Feb  7 03:43:12.004: INFO: Waiting up to 5m0s for pod "pod-configmaps-7e0a8b14-2a8a-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-configmap-p6qx4" to be "success or failure"
Feb  7 03:43:12.006: INFO: Pod "pod-configmaps-7e0a8b14-2a8a-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.838354ms
Feb  7 03:43:14.008: INFO: Pod "pod-configmaps-7e0a8b14-2a8a-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004636222s
STEP: Saw pod success
Feb  7 03:43:14.008: INFO: Pod "pod-configmaps-7e0a8b14-2a8a-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:43:14.011: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod pod-configmaps-7e0a8b14-2a8a-11e9-87fe-baa4eca941e3 container configmap-volume-test: <nil>
STEP: delete the pod
Feb  7 03:43:14.093: INFO: Waiting for pod pod-configmaps-7e0a8b14-2a8a-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:43:14.095: INFO: Pod pod-configmaps-7e0a8b14-2a8a-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:43:14.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-p6qx4" for this suite.
Feb  7 03:43:20.608: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:43:20.728: INFO: namespace: e2e-tests-configmap-p6qx4, resource: bindings, ignored listing per whitelist
Feb  7 03:43:20.797: INFO: namespace e2e-tests-configmap-p6qx4 deletion completed in 6.699089474s

• [SLOW TEST:8.853 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:43:20.797: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb  7 03:43:20.855: INFO: Waiting up to 5m0s for pod "pod-8350c812-2a8a-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-emptydir-fzjww" to be "success or failure"
Feb  7 03:43:20.857: INFO: Pod "pod-8350c812-2a8a-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.904824ms
Feb  7 03:43:22.864: INFO: Pod "pod-8350c812-2a8a-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0089582s
STEP: Saw pod success
Feb  7 03:43:22.864: INFO: Pod "pod-8350c812-2a8a-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:43:22.866: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod pod-8350c812-2a8a-11e9-87fe-baa4eca941e3 container test-container: <nil>
STEP: delete the pod
Feb  7 03:43:22.880: INFO: Waiting for pod pod-8350c812-2a8a-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:43:22.882: INFO: Pod pod-8350c812-2a8a-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:43:22.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-fzjww" for this suite.
Feb  7 03:43:28.896: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:43:28.965: INFO: namespace: e2e-tests-emptydir-fzjww, resource: bindings, ignored listing per whitelist
Feb  7 03:43:28.993: INFO: namespace e2e-tests-emptydir-fzjww deletion completed in 6.107168071s

• [SLOW TEST:8.196 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:43:28.993: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  7 03:43:29.721: INFO: (0) /api/v1/nodes/kube-node-0-kubelet.devkubernetes01.mesos:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 4.566696ms)
Feb  7 03:43:29.724: INFO: (1) /api/v1/nodes/kube-node-0-kubelet.devkubernetes01.mesos:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 2.936561ms)
Feb  7 03:43:29.727: INFO: (2) /api/v1/nodes/kube-node-0-kubelet.devkubernetes01.mesos:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 2.98989ms)
Feb  7 03:43:29.730: INFO: (3) /api/v1/nodes/kube-node-0-kubelet.devkubernetes01.mesos:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 3.145664ms)
Feb  7 03:43:29.733: INFO: (4) /api/v1/nodes/kube-node-0-kubelet.devkubernetes01.mesos:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 2.951069ms)
Feb  7 03:43:29.738: INFO: (5) /api/v1/nodes/kube-node-0-kubelet.devkubernetes01.mesos:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 5.011819ms)
Feb  7 03:43:29.741: INFO: (6) /api/v1/nodes/kube-node-0-kubelet.devkubernetes01.mesos:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 2.975774ms)
Feb  7 03:43:29.744: INFO: (7) /api/v1/nodes/kube-node-0-kubelet.devkubernetes01.mesos:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 2.816248ms)
Feb  7 03:43:29.747: INFO: (8) /api/v1/nodes/kube-node-0-kubelet.devkubernetes01.mesos:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 2.670598ms)
Feb  7 03:43:29.750: INFO: (9) /api/v1/nodes/kube-node-0-kubelet.devkubernetes01.mesos:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 2.828107ms)
Feb  7 03:43:29.752: INFO: (10) /api/v1/nodes/kube-node-0-kubelet.devkubernetes01.mesos:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 2.685089ms)
Feb  7 03:43:29.755: INFO: (11) /api/v1/nodes/kube-node-0-kubelet.devkubernetes01.mesos:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 2.650901ms)
Feb  7 03:43:29.758: INFO: (12) /api/v1/nodes/kube-node-0-kubelet.devkubernetes01.mesos:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 2.829223ms)
Feb  7 03:43:29.761: INFO: (13) /api/v1/nodes/kube-node-0-kubelet.devkubernetes01.mesos:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 2.978555ms)
Feb  7 03:43:29.764: INFO: (14) /api/v1/nodes/kube-node-0-kubelet.devkubernetes01.mesos:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 2.696431ms)
Feb  7 03:43:29.766: INFO: (15) /api/v1/nodes/kube-node-0-kubelet.devkubernetes01.mesos:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 2.606804ms)
Feb  7 03:43:29.769: INFO: (16) /api/v1/nodes/kube-node-0-kubelet.devkubernetes01.mesos:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 2.440023ms)
Feb  7 03:43:29.771: INFO: (17) /api/v1/nodes/kube-node-0-kubelet.devkubernetes01.mesos:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 2.47055ms)
Feb  7 03:43:29.774: INFO: (18) /api/v1/nodes/kube-node-0-kubelet.devkubernetes01.mesos:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 2.771112ms)
Feb  7 03:43:29.777: INFO: (19) /api/v1/nodes/kube-node-0-kubelet.devkubernetes01.mesos:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="btmp">btmp... (200; 2.518521ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:43:29.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-fx5sn" for this suite.
Feb  7 03:43:35.790: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:43:35.893: INFO: namespace: e2e-tests-proxy-fx5sn, resource: bindings, ignored listing per whitelist
Feb  7 03:43:35.930: INFO: namespace e2e-tests-proxy-fx5sn deletion completed in 6.150089607s

• [SLOW TEST:6.937 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:43:35.930: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Feb  7 03:43:36.161: INFO: Pod name wrapped-volume-race-8c6e72be-2a8a-11e9-87fe-baa4eca941e3: Found 1 pods out of 5
Feb  7 03:43:41.166: INFO: Pod name wrapped-volume-race-8c6e72be-2a8a-11e9-87fe-baa4eca941e3: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-8c6e72be-2a8a-11e9-87fe-baa4eca941e3 in namespace e2e-tests-emptydir-wrapper-42f4t, will wait for the garbage collector to delete the pods
Feb  7 03:43:41.294: INFO: Deleting ReplicationController wrapped-volume-race-8c6e72be-2a8a-11e9-87fe-baa4eca941e3 took: 6.193738ms
Feb  7 03:43:41.394: INFO: Terminating ReplicationController wrapped-volume-race-8c6e72be-2a8a-11e9-87fe-baa4eca941e3 pods took: 100.262117ms
STEP: Creating RC which spawns configmap-volume pods
Feb  7 03:44:23.613: INFO: Pod name wrapped-volume-race-a8b756a0-2a8a-11e9-87fe-baa4eca941e3: Found 0 pods out of 5
Feb  7 03:44:28.618: INFO: Pod name wrapped-volume-race-a8b756a0-2a8a-11e9-87fe-baa4eca941e3: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-a8b756a0-2a8a-11e9-87fe-baa4eca941e3 in namespace e2e-tests-emptydir-wrapper-42f4t, will wait for the garbage collector to delete the pods
Feb  7 03:44:28.692: INFO: Deleting ReplicationController wrapped-volume-race-a8b756a0-2a8a-11e9-87fe-baa4eca941e3 took: 7.699659ms
Feb  7 03:44:29.692: INFO: Terminating ReplicationController wrapped-volume-race-a8b756a0-2a8a-11e9-87fe-baa4eca941e3 pods took: 1.000290081s
STEP: Creating RC which spawns configmap-volume pods
Feb  7 03:45:06.945: INFO: Pod name wrapped-volume-race-c22a8707-2a8a-11e9-87fe-baa4eca941e3: Found 0 pods out of 5
Feb  7 03:45:11.950: INFO: Pod name wrapped-volume-race-c22a8707-2a8a-11e9-87fe-baa4eca941e3: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-c22a8707-2a8a-11e9-87fe-baa4eca941e3 in namespace e2e-tests-emptydir-wrapper-42f4t, will wait for the garbage collector to delete the pods
Feb  7 03:45:12.073: INFO: Deleting ReplicationController wrapped-volume-race-c22a8707-2a8a-11e9-87fe-baa4eca941e3 took: 7.57229ms
Feb  7 03:45:12.873: INFO: Terminating ReplicationController wrapped-volume-race-c22a8707-2a8a-11e9-87fe-baa4eca941e3 pods took: 800.306648ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:45:53.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-42f4t" for this suite.
Feb  7 03:46:01.917: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:46:01.993: INFO: namespace: e2e-tests-emptydir-wrapper-42f4t, resource: bindings, ignored listing per whitelist
Feb  7 03:46:02.037: INFO: namespace e2e-tests-emptydir-wrapper-42f4t deletion completed in 8.164280022s

• [SLOW TEST:146.107 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:46:02.038: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Feb  7 03:46:02.104: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb  7 03:46:02.112: INFO: Waiting for terminating namespaces to be deleted...
Feb  7 03:46:02.114: INFO: 
Logging pods the kubelet thinks is on node kube-node-0-kubelet.devkubernetes01.mesos before test
Feb  7 03:46:02.119: INFO: sonobuoy-systemd-logs-daemon-set-3418c9e540594be1-n22q8 from heptio-sonobuoy started at 2019-02-07 02:33:29 +0000 UTC (2 container statuses recorded)
Feb  7 03:46:02.119: INFO: 	Container sonobuoy-systemd-logs-config ready: false, restart count 19
Feb  7 03:46:02.119: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  7 03:46:02.119: INFO: calico-node-n2c9f from kube-system started at 2019-02-07 02:26:23 +0000 UTC (2 container statuses recorded)
Feb  7 03:46:02.119: INFO: 	Container calico-node ready: true, restart count 0
Feb  7 03:46:02.119: INFO: 	Container install-cni ready: true, restart count 0
Feb  7 03:46:02.119: INFO: kube-proxy-kube-node-0-kubelet.devkubernetes01.mesos from kube-system started at <nil> (0 container statuses recorded)
Feb  7 03:46:02.119: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-07 02:33:25 +0000 UTC (1 container statuses recorded)
Feb  7 03:46:02.119: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb  7 03:46:02.119: INFO: local-dns-dispatcher-kube-node-0-kubelet.devkubernetes01.mesos from kube-system started at <nil> (0 container statuses recorded)
Feb  7 03:46:02.119: INFO: 
Logging pods the kubelet thinks is on node kube-node-1-kubelet.devkubernetes01.mesos before test
Feb  7 03:46:02.123: INFO: kube-proxy-kube-node-1-kubelet.devkubernetes01.mesos from kube-system started at <nil> (0 container statuses recorded)
Feb  7 03:46:02.123: INFO: local-dns-dispatcher-kube-node-1-kubelet.devkubernetes01.mesos from kube-system started at <nil> (0 container statuses recorded)
Feb  7 03:46:02.123: INFO: calico-node-5snr5 from kube-system started at 2019-02-07 02:26:23 +0000 UTC (2 container statuses recorded)
Feb  7 03:46:02.123: INFO: 	Container calico-node ready: true, restart count 0
Feb  7 03:46:02.123: INFO: 	Container install-cni ready: true, restart count 0
Feb  7 03:46:02.123: INFO: coredns-fb6c4f575-rzxqz from kube-system started at 2019-02-07 02:26:43 +0000 UTC (1 container statuses recorded)
Feb  7 03:46:02.123: INFO: 	Container coredns ready: true, restart count 0
Feb  7 03:46:02.123: INFO: sonobuoy-e2e-job-0cc94a58d02847bf from heptio-sonobuoy started at 2019-02-07 02:33:29 +0000 UTC (2 container statuses recorded)
Feb  7 03:46:02.123: INFO: 	Container e2e ready: true, restart count 0
Feb  7 03:46:02.123: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  7 03:46:02.123: INFO: sonobuoy-systemd-logs-daemon-set-3418c9e540594be1-cx7gt from heptio-sonobuoy started at 2019-02-07 02:33:29 +0000 UTC (2 container statuses recorded)
Feb  7 03:46:02.124: INFO: 	Container sonobuoy-systemd-logs-config ready: false, restart count 18
Feb  7 03:46:02.124: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  7 03:46:02.124: INFO: 
Logging pods the kubelet thinks is on node kube-node-2-kubelet.devkubernetes01.mesos before test
Feb  7 03:46:02.128: INFO: metrics-server-7ddfc7695-b8l5f from kube-system started at 2019-02-07 02:26:36 +0000 UTC (1 container statuses recorded)
Feb  7 03:46:02.128: INFO: 	Container metrics-server ready: true, restart count 0
Feb  7 03:46:02.128: INFO: kube-proxy-kube-node-2-kubelet.devkubernetes01.mesos from kube-system started at <nil> (0 container statuses recorded)
Feb  7 03:46:02.128: INFO: coredns-fb6c4f575-8xlfk from kube-system started at 2019-02-07 02:26:36 +0000 UTC (1 container statuses recorded)
Feb  7 03:46:02.128: INFO: 	Container coredns ready: true, restart count 0
Feb  7 03:46:02.128: INFO: kubernetes-dashboard-6d87d489d4-d8zr7 from kube-system started at 2019-02-07 02:26:36 +0000 UTC (1 container statuses recorded)
Feb  7 03:46:02.128: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Feb  7 03:46:02.128: INFO: sonobuoy-systemd-logs-daemon-set-3418c9e540594be1-dd7p4 from heptio-sonobuoy started at 2019-02-07 02:33:29 +0000 UTC (2 container statuses recorded)
Feb  7 03:46:02.128: INFO: 	Container sonobuoy-systemd-logs-config ready: false, restart count 19
Feb  7 03:46:02.128: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  7 03:46:02.128: INFO: local-dns-dispatcher-kube-node-2-kubelet.devkubernetes01.mesos from kube-system started at <nil> (0 container statuses recorded)
Feb  7 03:46:02.128: INFO: calico-node-gmcd4 from kube-system started at 2019-02-07 02:26:17 +0000 UTC (2 container statuses recorded)
Feb  7 03:46:02.128: INFO: 	Container calico-node ready: true, restart count 0
Feb  7 03:46:02.128: INFO: 	Container install-cni ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node kube-node-0-kubelet.devkubernetes01.mesos
STEP: verifying the node has the label node kube-node-1-kubelet.devkubernetes01.mesos
STEP: verifying the node has the label node kube-node-2-kubelet.devkubernetes01.mesos
Feb  7 03:46:02.168: INFO: Pod sonobuoy requesting resource cpu=0m on Node kube-node-0-kubelet.devkubernetes01.mesos
Feb  7 03:46:02.168: INFO: Pod sonobuoy-e2e-job-0cc94a58d02847bf requesting resource cpu=0m on Node kube-node-1-kubelet.devkubernetes01.mesos
Feb  7 03:46:02.168: INFO: Pod sonobuoy-systemd-logs-daemon-set-3418c9e540594be1-cx7gt requesting resource cpu=0m on Node kube-node-1-kubelet.devkubernetes01.mesos
Feb  7 03:46:02.168: INFO: Pod sonobuoy-systemd-logs-daemon-set-3418c9e540594be1-dd7p4 requesting resource cpu=0m on Node kube-node-2-kubelet.devkubernetes01.mesos
Feb  7 03:46:02.168: INFO: Pod sonobuoy-systemd-logs-daemon-set-3418c9e540594be1-n22q8 requesting resource cpu=0m on Node kube-node-0-kubelet.devkubernetes01.mesos
Feb  7 03:46:02.168: INFO: Pod calico-node-5snr5 requesting resource cpu=250m on Node kube-node-1-kubelet.devkubernetes01.mesos
Feb  7 03:46:02.168: INFO: Pod calico-node-gmcd4 requesting resource cpu=250m on Node kube-node-2-kubelet.devkubernetes01.mesos
Feb  7 03:46:02.168: INFO: Pod calico-node-n2c9f requesting resource cpu=250m on Node kube-node-0-kubelet.devkubernetes01.mesos
Feb  7 03:46:02.168: INFO: Pod coredns-fb6c4f575-8xlfk requesting resource cpu=100m on Node kube-node-2-kubelet.devkubernetes01.mesos
Feb  7 03:46:02.168: INFO: Pod coredns-fb6c4f575-rzxqz requesting resource cpu=100m on Node kube-node-1-kubelet.devkubernetes01.mesos
Feb  7 03:46:02.168: INFO: Pod kube-proxy-kube-node-0-kubelet.devkubernetes01.mesos requesting resource cpu=0m on Node kube-node-0-kubelet.devkubernetes01.mesos
Feb  7 03:46:02.168: INFO: Pod kube-proxy-kube-node-1-kubelet.devkubernetes01.mesos requesting resource cpu=0m on Node kube-node-1-kubelet.devkubernetes01.mesos
Feb  7 03:46:02.168: INFO: Pod kube-proxy-kube-node-2-kubelet.devkubernetes01.mesos requesting resource cpu=0m on Node kube-node-2-kubelet.devkubernetes01.mesos
Feb  7 03:46:02.168: INFO: Pod kubernetes-dashboard-6d87d489d4-d8zr7 requesting resource cpu=0m on Node kube-node-2-kubelet.devkubernetes01.mesos
Feb  7 03:46:02.168: INFO: Pod local-dns-dispatcher-kube-node-0-kubelet.devkubernetes01.mesos requesting resource cpu=100m on Node kube-node-0-kubelet.devkubernetes01.mesos
Feb  7 03:46:02.168: INFO: Pod local-dns-dispatcher-kube-node-1-kubelet.devkubernetes01.mesos requesting resource cpu=100m on Node kube-node-1-kubelet.devkubernetes01.mesos
Feb  7 03:46:02.168: INFO: Pod local-dns-dispatcher-kube-node-2-kubelet.devkubernetes01.mesos requesting resource cpu=100m on Node kube-node-2-kubelet.devkubernetes01.mesos
Feb  7 03:46:02.168: INFO: Pod metrics-server-7ddfc7695-b8l5f requesting resource cpu=0m on Node kube-node-2-kubelet.devkubernetes01.mesos
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e3787afe-2a8a-11e9-87fe-baa4eca941e3.1580f8313d40888a], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-hrhwk/filler-pod-e3787afe-2a8a-11e9-87fe-baa4eca941e3 to kube-node-0-kubelet.devkubernetes01.mesos]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e3787afe-2a8a-11e9-87fe-baa4eca941e3.1580f831898751b6], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e3787afe-2a8a-11e9-87fe-baa4eca941e3.1580f8318b46d03a], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e3787afe-2a8a-11e9-87fe-baa4eca941e3.1580f83193579025], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e37998ed-2a8a-11e9-87fe-baa4eca941e3.1580f8313d8c360b], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-hrhwk/filler-pod-e37998ed-2a8a-11e9-87fe-baa4eca941e3 to kube-node-1-kubelet.devkubernetes01.mesos]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e37998ed-2a8a-11e9-87fe-baa4eca941e3.1580f831679b99a7], Reason = [Pulling], Message = [pulling image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e37998ed-2a8a-11e9-87fe-baa4eca941e3.1580f8318c1bf180], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e37998ed-2a8a-11e9-87fe-baa4eca941e3.1580f8318e12ffe2], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e37998ed-2a8a-11e9-87fe-baa4eca941e3.1580f83198f9c763], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e37a0c12-2a8a-11e9-87fe-baa4eca941e3.1580f8313daa2134], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-hrhwk/filler-pod-e37a0c12-2a8a-11e9-87fe-baa4eca941e3 to kube-node-2-kubelet.devkubernetes01.mesos]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e37a0c12-2a8a-11e9-87fe-baa4eca941e3.1580f8316749658e], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e37a0c12-2a8a-11e9-87fe-baa4eca941e3.1580f8316923a585], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e37a0c12-2a8a-11e9-87fe-baa4eca941e3.1580f8317069d717], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1580f831b6186ded], Reason = [FailedScheduling], Message = [0/6 nodes are available: 3 Insufficient cpu, 3 node(s) had taints that the pod didn't tolerate.]
STEP: removing the label node off the node kube-node-0-kubelet.devkubernetes01.mesos
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node kube-node-1-kubelet.devkubernetes01.mesos
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node kube-node-2-kubelet.devkubernetes01.mesos
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:46:05.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-hrhwk" for this suite.
Feb  7 03:46:11.259: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:46:11.347: INFO: namespace: e2e-tests-sched-pred-hrhwk, resource: bindings, ignored listing per whitelist
Feb  7 03:46:11.358: INFO: namespace e2e-tests-sched-pred-hrhwk deletion completed in 6.109659703s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:9.321 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:46:11.358: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-xksv8
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-xksv8
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-xksv8
Feb  7 03:46:11.421: INFO: Found 0 stateful pods, waiting for 1
Feb  7 03:46:21.430: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Feb  7 03:46:21.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 exec --namespace=e2e-tests-statefulset-xksv8 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  7 03:46:21.579: INFO: stderr: ""
Feb  7 03:46:21.580: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  7 03:46:21.580: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  7 03:46:21.582: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb  7 03:46:31.589: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb  7 03:46:31.589: INFO: Waiting for statefulset status.replicas updated to 0
Feb  7 03:46:31.603: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999464s
Feb  7 03:46:32.607: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.997591682s
Feb  7 03:46:33.839: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.994233533s
Feb  7 03:46:34.842: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.761692014s
Feb  7 03:46:35.846: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.75852508s
Feb  7 03:46:36.849: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.755309453s
Feb  7 03:46:37.853: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.752070269s
Feb  7 03:46:38.856: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.748483168s
Feb  7 03:46:39.859: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.745328581s
Feb  7 03:46:40.862: INFO: Verifying statefulset ss doesn't scale past 1 for another 742.255144ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-xksv8
Feb  7 03:46:41.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 exec --namespace=e2e-tests-statefulset-xksv8 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  7 03:46:42.016: INFO: stderr: ""
Feb  7 03:46:42.016: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  7 03:46:42.017: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  7 03:46:42.019: INFO: Found 1 stateful pods, waiting for 3
Feb  7 03:46:52.027: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb  7 03:46:52.027: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb  7 03:46:52.027: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Feb  7 03:46:52.031: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 exec --namespace=e2e-tests-statefulset-xksv8 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  7 03:46:52.179: INFO: stderr: ""
Feb  7 03:46:52.179: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  7 03:46:52.179: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  7 03:46:52.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 exec --namespace=e2e-tests-statefulset-xksv8 ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  7 03:46:52.406: INFO: stderr: ""
Feb  7 03:46:52.406: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  7 03:46:52.406: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  7 03:46:52.407: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 exec --namespace=e2e-tests-statefulset-xksv8 ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  7 03:46:52.555: INFO: stderr: ""
Feb  7 03:46:52.555: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  7 03:46:52.555: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  7 03:46:52.555: INFO: Waiting for statefulset status.replicas updated to 0
Feb  7 03:46:52.557: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Feb  7 03:47:02.567: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb  7 03:47:02.567: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb  7 03:47:02.567: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb  7 03:47:02.575: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999407s
Feb  7 03:47:03.579: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997119086s
Feb  7 03:47:04.582: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.993631174s
Feb  7 03:47:05.859: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.990609619s
Feb  7 03:47:06.862: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.713535551s
Feb  7 03:47:07.866: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.710039866s
Feb  7 03:47:08.869: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.706243913s
Feb  7 03:47:10.215: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.703124553s
Feb  7 03:47:11.218: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.357084376s
Feb  7 03:47:12.225: INFO: Verifying statefulset ss doesn't scale past 3 for another 354.031197ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-xksv8
Feb  7 03:47:13.233: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 exec --namespace=e2e-tests-statefulset-xksv8 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  7 03:47:13.374: INFO: stderr: ""
Feb  7 03:47:13.374: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  7 03:47:13.374: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  7 03:47:13.374: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 exec --namespace=e2e-tests-statefulset-xksv8 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  7 03:47:13.591: INFO: stderr: ""
Feb  7 03:47:13.591: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  7 03:47:13.591: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  7 03:47:13.591: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 exec --namespace=e2e-tests-statefulset-xksv8 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  7 03:47:13.736: INFO: stderr: ""
Feb  7 03:47:13.736: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  7 03:47:13.736: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  7 03:47:13.736: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb  7 03:47:33.747: INFO: Deleting all statefulset in ns e2e-tests-statefulset-xksv8
Feb  7 03:47:33.749: INFO: Scaling statefulset ss to 0
Feb  7 03:47:33.756: INFO: Waiting for statefulset status.replicas updated to 0
Feb  7 03:47:33.758: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:47:33.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-xksv8" for this suite.
Feb  7 03:47:39.781: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:47:39.877: INFO: namespace: e2e-tests-statefulset-xksv8, resource: bindings, ignored listing per whitelist
Feb  7 03:47:39.936: INFO: namespace e2e-tests-statefulset-xksv8 deletion completed in 6.165201135s

• [SLOW TEST:88.578 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:47:39.936: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb  7 03:47:39.998: INFO: Waiting up to 5m0s for pod "downward-api-1dc6fb12-2a8b-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-downward-api-2rct7" to be "success or failure"
Feb  7 03:47:40.000: INFO: Pod "downward-api-1dc6fb12-2a8b-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.216174ms
Feb  7 03:47:42.004: INFO: Pod "downward-api-1dc6fb12-2a8b-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005307007s
STEP: Saw pod success
Feb  7 03:47:42.004: INFO: Pod "downward-api-1dc6fb12-2a8b-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:47:42.006: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod downward-api-1dc6fb12-2a8b-11e9-87fe-baa4eca941e3 container dapi-container: <nil>
STEP: delete the pod
Feb  7 03:47:42.022: INFO: Waiting for pod downward-api-1dc6fb12-2a8b-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:47:42.024: INFO: Pod downward-api-1dc6fb12-2a8b-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:47:42.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-2rct7" for this suite.
Feb  7 03:47:48.037: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:47:48.114: INFO: namespace: e2e-tests-downward-api-2rct7, resource: bindings, ignored listing per whitelist
Feb  7 03:47:48.194: INFO: namespace e2e-tests-downward-api-2rct7 deletion completed in 6.166497587s

• [SLOW TEST:8.258 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:47:48.194: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1134
STEP: creating an rc
Feb  7 03:47:48.242: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 create -f - --namespace=e2e-tests-kubectl-td9r9'
Feb  7 03:47:48.548: INFO: stderr: ""
Feb  7 03:47:48.548: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Feb  7 03:47:49.551: INFO: Selector matched 1 pods for map[app:redis]
Feb  7 03:47:49.551: INFO: Found 0 / 1
Feb  7 03:47:50.551: INFO: Selector matched 1 pods for map[app:redis]
Feb  7 03:47:50.551: INFO: Found 1 / 1
Feb  7 03:47:50.551: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb  7 03:47:50.553: INFO: Selector matched 1 pods for map[app:redis]
Feb  7 03:47:50.553: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Feb  7 03:47:50.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 logs redis-master-wxpq5 redis-master --namespace=e2e-tests-kubectl-td9r9'
Feb  7 03:47:50.655: INFO: stderr: ""
Feb  7 03:47:50.655: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 07 Feb 03:47:49.291 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 07 Feb 03:47:49.291 # Server started, Redis version 3.2.12\n1:M 07 Feb 03:47:49.291 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 07 Feb 03:47:49.291 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Feb  7 03:47:50.655: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 log redis-master-wxpq5 redis-master --namespace=e2e-tests-kubectl-td9r9 --tail=1'
Feb  7 03:47:50.743: INFO: stderr: ""
Feb  7 03:47:50.743: INFO: stdout: "1:M 07 Feb 03:47:49.291 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Feb  7 03:47:50.743: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 log redis-master-wxpq5 redis-master --namespace=e2e-tests-kubectl-td9r9 --limit-bytes=1'
Feb  7 03:47:50.824: INFO: stderr: ""
Feb  7 03:47:50.824: INFO: stdout: " "
STEP: exposing timestamps
Feb  7 03:47:50.824: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 log redis-master-wxpq5 redis-master --namespace=e2e-tests-kubectl-td9r9 --tail=1 --timestamps'
Feb  7 03:47:50.898: INFO: stderr: ""
Feb  7 03:47:50.898: INFO: stdout: "2019-02-07T03:47:49.291730305Z 1:M 07 Feb 03:47:49.291 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Feb  7 03:47:53.398: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 log redis-master-wxpq5 redis-master --namespace=e2e-tests-kubectl-td9r9 --since=1s'
Feb  7 03:47:53.471: INFO: stderr: ""
Feb  7 03:47:53.471: INFO: stdout: ""
Feb  7 03:47:53.471: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 log redis-master-wxpq5 redis-master --namespace=e2e-tests-kubectl-td9r9 --since=24h'
Feb  7 03:47:53.543: INFO: stderr: ""
Feb  7 03:47:53.543: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 07 Feb 03:47:49.291 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 07 Feb 03:47:49.291 # Server started, Redis version 3.2.12\n1:M 07 Feb 03:47:49.291 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 07 Feb 03:47:49.291 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1140
STEP: using delete to clean up resources
Feb  7 03:47:53.543: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-td9r9'
Feb  7 03:47:53.607: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  7 03:47:53.607: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Feb  7 03:47:53.607: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-td9r9'
Feb  7 03:47:53.675: INFO: stderr: "No resources found.\n"
Feb  7 03:47:53.675: INFO: stdout: ""
Feb  7 03:47:53.675: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 get pods -l name=nginx --namespace=e2e-tests-kubectl-td9r9 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb  7 03:47:53.741: INFO: stderr: ""
Feb  7 03:47:53.741: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:47:53.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-td9r9" for this suite.
Feb  7 03:47:59.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:47:59.767: INFO: namespace: e2e-tests-kubectl-td9r9, resource: bindings, ignored listing per whitelist
Feb  7 03:47:59.850: INFO: namespace e2e-tests-kubectl-td9r9 deletion completed in 6.10498787s

• [SLOW TEST:11.656 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:47:59.850: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-pvmvm
Feb  7 03:48:01.915: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-pvmvm
STEP: checking the pod's current state and verifying that restartCount is present
Feb  7 03:48:01.917: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:52:03.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-pvmvm" for this suite.
Feb  7 03:52:09.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:52:10.024: INFO: namespace: e2e-tests-container-probe-pvmvm, resource: bindings, ignored listing per whitelist
Feb  7 03:52:10.053: INFO: namespace e2e-tests-container-probe-pvmvm deletion completed in 6.110623011s

• [SLOW TEST:250.203 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:52:10.053: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Feb  7 03:52:10.114: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-cnt8j,SelfLink:/api/v1/namespaces/e2e-tests-watch-cnt8j/configmaps/e2e-watch-test-configmap-a,UID:beccbfd4-2a8b-11e9-809d-e6a419c8531a,ResourceVersion:22056,Generation:0,CreationTimestamp:2019-02-07 03:52:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb  7 03:52:10.114: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-cnt8j,SelfLink:/api/v1/namespaces/e2e-tests-watch-cnt8j/configmaps/e2e-watch-test-configmap-a,UID:beccbfd4-2a8b-11e9-809d-e6a419c8531a,ResourceVersion:22056,Generation:0,CreationTimestamp:2019-02-07 03:52:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Feb  7 03:52:20.214: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-cnt8j,SelfLink:/api/v1/namespaces/e2e-tests-watch-cnt8j/configmaps/e2e-watch-test-configmap-a,UID:beccbfd4-2a8b-11e9-809d-e6a419c8531a,ResourceVersion:22076,Generation:0,CreationTimestamp:2019-02-07 03:52:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb  7 03:52:20.214: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-cnt8j,SelfLink:/api/v1/namespaces/e2e-tests-watch-cnt8j/configmaps/e2e-watch-test-configmap-a,UID:beccbfd4-2a8b-11e9-809d-e6a419c8531a,ResourceVersion:22076,Generation:0,CreationTimestamp:2019-02-07 03:52:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Feb  7 03:52:30.225: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-cnt8j,SelfLink:/api/v1/namespaces/e2e-tests-watch-cnt8j/configmaps/e2e-watch-test-configmap-a,UID:beccbfd4-2a8b-11e9-809d-e6a419c8531a,ResourceVersion:22096,Generation:0,CreationTimestamp:2019-02-07 03:52:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb  7 03:52:30.225: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-cnt8j,SelfLink:/api/v1/namespaces/e2e-tests-watch-cnt8j/configmaps/e2e-watch-test-configmap-a,UID:beccbfd4-2a8b-11e9-809d-e6a419c8531a,ResourceVersion:22096,Generation:0,CreationTimestamp:2019-02-07 03:52:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Feb  7 03:52:40.614: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-cnt8j,SelfLink:/api/v1/namespaces/e2e-tests-watch-cnt8j/configmaps/e2e-watch-test-configmap-a,UID:beccbfd4-2a8b-11e9-809d-e6a419c8531a,ResourceVersion:22116,Generation:0,CreationTimestamp:2019-02-07 03:52:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb  7 03:52:40.614: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-cnt8j,SelfLink:/api/v1/namespaces/e2e-tests-watch-cnt8j/configmaps/e2e-watch-test-configmap-a,UID:beccbfd4-2a8b-11e9-809d-e6a419c8531a,ResourceVersion:22116,Generation:0,CreationTimestamp:2019-02-07 03:52:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Feb  7 03:52:50.624: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-cnt8j,SelfLink:/api/v1/namespaces/e2e-tests-watch-cnt8j/configmaps/e2e-watch-test-configmap-b,UID:d6f1db48-2a8b-11e9-809d-e6a419c8531a,ResourceVersion:22136,Generation:0,CreationTimestamp:2019-02-07 03:52:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb  7 03:52:50.624: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-cnt8j,SelfLink:/api/v1/namespaces/e2e-tests-watch-cnt8j/configmaps/e2e-watch-test-configmap-b,UID:d6f1db48-2a8b-11e9-809d-e6a419c8531a,ResourceVersion:22136,Generation:0,CreationTimestamp:2019-02-07 03:52:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Feb  7 03:53:00.717: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-cnt8j,SelfLink:/api/v1/namespaces/e2e-tests-watch-cnt8j/configmaps/e2e-watch-test-configmap-b,UID:d6f1db48-2a8b-11e9-809d-e6a419c8531a,ResourceVersion:22156,Generation:0,CreationTimestamp:2019-02-07 03:52:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb  7 03:53:00.717: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-cnt8j,SelfLink:/api/v1/namespaces/e2e-tests-watch-cnt8j/configmaps/e2e-watch-test-configmap-b,UID:d6f1db48-2a8b-11e9-809d-e6a419c8531a,ResourceVersion:22156,Generation:0,CreationTimestamp:2019-02-07 03:52:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:53:10.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-cnt8j" for this suite.
Feb  7 03:53:16.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:53:16.856: INFO: namespace: e2e-tests-watch-cnt8j, resource: bindings, ignored listing per whitelist
Feb  7 03:53:16.915: INFO: namespace e2e-tests-watch-cnt8j deletion completed in 6.18875848s

• [SLOW TEST:66.861 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:53:16.915: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  7 03:53:16.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-221081943 version'
Feb  7 03:53:17.023: INFO: stderr: ""
Feb  7 03:53:17.023: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.3\", GitCommit:\"721bfa751924da8d1680787490c54b9179b1fed0\", GitTreeState:\"clean\", BuildDate:\"2019-02-01T20:00:57Z\", GoVersion:\"go1.11.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:53:17.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hl9cv" for this suite.
Feb  7 03:53:23.037: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:53:23.125: INFO: namespace: e2e-tests-kubectl-hl9cv, resource: bindings, ignored listing per whitelist
Feb  7 03:53:23.133: INFO: namespace e2e-tests-kubectl-hl9cv deletion completed in 6.106468202s

• [SLOW TEST:6.219 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:53:23.133: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-l2r7f
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-l2r7f to expose endpoints map[]
Feb  7 03:53:23.194: INFO: Get endpoints failed (2.4258ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Feb  7 03:53:24.197: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-l2r7f exposes endpoints map[] (1.005158935s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-l2r7f
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-l2r7f to expose endpoints map[pod1:[100]]
Feb  7 03:53:26.571: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-l2r7f exposes endpoints map[pod1:[100]] (2.110451454s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-l2r7f
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-l2r7f to expose endpoints map[pod1:[100] pod2:[101]]
Feb  7 03:53:29.416: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-l2r7f exposes endpoints map[pod1:[100] pod2:[101]] (2.803443859s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-l2r7f
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-l2r7f to expose endpoints map[pod2:[101]]
Feb  7 03:53:30.430: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-l2r7f exposes endpoints map[pod2:[101]] (1.009643968s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-l2r7f
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-l2r7f to expose endpoints map[]
Feb  7 03:53:31.444: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-l2r7f exposes endpoints map[] (1.009184549s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:53:31.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-l2r7f" for this suite.
Feb  7 03:53:55.474: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:53:55.631: INFO: namespace: e2e-tests-services-l2r7f, resource: bindings, ignored listing per whitelist
Feb  7 03:53:55.648: INFO: namespace e2e-tests-services-l2r7f deletion completed in 24.185101639s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:32.515 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:53:55.649: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-jgw7t
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Feb  7 03:53:55.711: INFO: Found 0 stateful pods, waiting for 3
Feb  7 03:54:06.251: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb  7 03:54:06.251: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb  7 03:54:06.251: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Feb  7 03:54:06.864: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Feb  7 03:54:16.946: INFO: Updating stateful set ss2
Feb  7 03:54:16.951: INFO: Waiting for Pod e2e-tests-statefulset-jgw7t/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Feb  7 03:54:27.079: INFO: Found 2 stateful pods, waiting for 3
Feb  7 03:54:37.088: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb  7 03:54:37.088: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb  7 03:54:37.088: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Feb  7 03:54:37.108: INFO: Updating stateful set ss2
Feb  7 03:54:37.112: INFO: Waiting for Pod e2e-tests-statefulset-jgw7t/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb  7 03:54:47.374: INFO: Updating stateful set ss2
Feb  7 03:54:47.378: INFO: Waiting for StatefulSet e2e-tests-statefulset-jgw7t/ss2 to complete update
Feb  7 03:54:47.378: INFO: Waiting for Pod e2e-tests-statefulset-jgw7t/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb  7 03:54:58.057: INFO: Deleting all statefulset in ns e2e-tests-statefulset-jgw7t
Feb  7 03:54:58.059: INFO: Scaling statefulset ss2 to 0
Feb  7 03:55:28.075: INFO: Waiting for statefulset status.replicas updated to 0
Feb  7 03:55:28.077: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:55:28.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-jgw7t" for this suite.
Feb  7 03:55:34.893: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:55:35.039: INFO: namespace: e2e-tests-statefulset-jgw7t, resource: bindings, ignored listing per whitelist
Feb  7 03:55:35.155: INFO: namespace e2e-tests-statefulset-jgw7t deletion completed in 7.064791938s

• [SLOW TEST:99.507 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:55:35.155: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  7 03:55:55.785: INFO: Container started at 2019-02-07 03:55:36 +0000 UTC, pod became ready at 2019-02-07 03:55:55 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:55:55.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-z9pnj" for this suite.
Feb  7 03:56:17.861: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:56:18.011: INFO: namespace: e2e-tests-container-probe-z9pnj, resource: bindings, ignored listing per whitelist
Feb  7 03:56:18.055: INFO: namespace e2e-tests-container-probe-z9pnj deletion completed in 22.2670574s

• [SLOW TEST:42.900 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:56:18.055: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0207 03:56:48.676120      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb  7 03:56:48.676: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:56:48.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-tf75c" for this suite.
Feb  7 03:56:54.769: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:56:54.884: INFO: namespace: e2e-tests-gc-tf75c, resource: bindings, ignored listing per whitelist
Feb  7 03:56:54.891: INFO: namespace e2e-tests-gc-tf75c deletion completed in 6.210809378s

• [SLOW TEST:36.835 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:56:54.891: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-688e23a6-2a8c-11e9-87fe-baa4eca941e3
STEP: Creating a pod to test consume configMaps
Feb  7 03:56:54.954: INFO: Waiting up to 5m0s for pod "pod-configmaps-688ed88c-2a8c-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-configmap-2d5bf" to be "success or failure"
Feb  7 03:56:54.956: INFO: Pod "pod-configmaps-688ed88c-2a8c-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.853179ms
Feb  7 03:56:56.959: INFO: Pod "pod-configmaps-688ed88c-2a8c-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004936808s
STEP: Saw pod success
Feb  7 03:56:56.959: INFO: Pod "pod-configmaps-688ed88c-2a8c-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 03:56:56.962: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod pod-configmaps-688ed88c-2a8c-11e9-87fe-baa4eca941e3 container configmap-volume-test: <nil>
STEP: delete the pod
Feb  7 03:56:56.977: INFO: Waiting for pod pod-configmaps-688ed88c-2a8c-11e9-87fe-baa4eca941e3 to disappear
Feb  7 03:56:56.979: INFO: Pod pod-configmaps-688ed88c-2a8c-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:56:56.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-2d5bf" for this suite.
Feb  7 03:57:02.993: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:57:03.065: INFO: namespace: e2e-tests-configmap-2d5bf, resource: bindings, ignored listing per whitelist
Feb  7 03:57:03.087: INFO: namespace e2e-tests-configmap-2d5bf deletion completed in 6.104718828s

• [SLOW TEST:8.196 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:57:03.087: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-6d702c2f-2a8c-11e9-87fe-baa4eca941e3
Feb  7 03:57:03.143: INFO: Pod name my-hostname-basic-6d702c2f-2a8c-11e9-87fe-baa4eca941e3: Found 0 pods out of 1
Feb  7 03:57:08.146: INFO: Pod name my-hostname-basic-6d702c2f-2a8c-11e9-87fe-baa4eca941e3: Found 1 pods out of 1
Feb  7 03:57:08.146: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-6d702c2f-2a8c-11e9-87fe-baa4eca941e3" are running
Feb  7 03:57:08.149: INFO: Pod "my-hostname-basic-6d702c2f-2a8c-11e9-87fe-baa4eca941e3-8mmq7" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-07 03:57:03 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-07 03:57:04 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-07 03:57:04 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-07 03:57:03 +0000 UTC Reason: Message:}])
Feb  7 03:57:08.149: INFO: Trying to dial the pod
Feb  7 03:57:13.161: INFO: Controller my-hostname-basic-6d702c2f-2a8c-11e9-87fe-baa4eca941e3: Got expected result from replica 1 [my-hostname-basic-6d702c2f-2a8c-11e9-87fe-baa4eca941e3-8mmq7]: "my-hostname-basic-6d702c2f-2a8c-11e9-87fe-baa4eca941e3-8mmq7", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:57:13.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-9vsfh" for this suite.
Feb  7 03:57:19.259: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:57:19.372: INFO: namespace: e2e-tests-replication-controller-9vsfh, resource: bindings, ignored listing per whitelist
Feb  7 03:57:19.445: INFO: namespace e2e-tests-replication-controller-9vsfh deletion completed in 6.280213206s

• [SLOW TEST:16.357 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:57:19.445: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  7 03:57:19.953: INFO: Pod name rollover-pod: Found 0 pods out of 1
Feb  7 03:57:24.961: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb  7 03:57:24.961: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Feb  7 03:57:26.964: INFO: Creating deployment "test-rollover-deployment"
Feb  7 03:57:27.015: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Feb  7 03:57:29.050: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Feb  7 03:57:29.055: INFO: Ensure that both replica sets have 1 created replica
Feb  7 03:57:29.060: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Feb  7 03:57:29.067: INFO: Updating deployment test-rollover-deployment
Feb  7 03:57:29.067: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Feb  7 03:57:31.074: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Feb  7 03:57:31.078: INFO: Make sure deployment "test-rollover-deployment" is complete
Feb  7 03:57:31.083: INFO: all replica sets need to contain the pod-template-hash label
Feb  7 03:57:31.083: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685108647, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685108647, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685108650, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685108647, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  7 03:57:33.089: INFO: all replica sets need to contain the pod-template-hash label
Feb  7 03:57:33.089: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685108647, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685108647, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685108650, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685108647, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  7 03:57:35.157: INFO: all replica sets need to contain the pod-template-hash label
Feb  7 03:57:35.157: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685108647, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685108647, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685108650, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685108647, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  7 03:57:37.089: INFO: all replica sets need to contain the pod-template-hash label
Feb  7 03:57:37.089: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685108647, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685108647, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685108650, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685108647, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  7 03:57:39.091: INFO: all replica sets need to contain the pod-template-hash label
Feb  7 03:57:39.091: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685108647, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685108647, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685108650, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685108647, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  7 03:57:41.489: INFO: all replica sets need to contain the pod-template-hash label
Feb  7 03:57:41.489: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685108647, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685108647, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685108650, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685108647, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  7 03:57:43.089: INFO: 
Feb  7 03:57:43.089: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb  7 03:57:43.096: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-hmx6m,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-hmx6m/deployments/test-rollover-deployment,UID:7ba78c1b-2a8c-11e9-809d-e6a419c8531a,ResourceVersion:23256,Generation:2,CreationTimestamp:2019-02-07 03:57:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-02-07 03:57:27 +0000 UTC 2019-02-07 03:57:27 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-02-07 03:57:41 +0000 UTC 2019-02-07 03:57:27 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-6b7f9d6597" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb  7 03:57:43.099: INFO: New ReplicaSet "test-rollover-deployment-6b7f9d6597" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597,GenerateName:,Namespace:e2e-tests-deployment-hmx6m,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-hmx6m/replicasets/test-rollover-deployment-6b7f9d6597,UID:7ce48eac-2a8c-11e9-927c-4a513db42ba3,ResourceVersion:23246,Generation:2,CreationTimestamp:2019-02-07 03:57:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 7ba78c1b-2a8c-11e9-809d-e6a419c8531a 0xc0027c4507 0xc0027c4508}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb  7 03:57:43.099: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Feb  7 03:57:43.099: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-hmx6m,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-hmx6m/replicasets/test-rollover-controller,UID:77341b2e-2a8c-11e9-809d-e6a419c8531a,ResourceVersion:23255,Generation:2,CreationTimestamp:2019-02-07 03:57:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 7ba78c1b-2a8c-11e9-809d-e6a419c8531a 0xc0027c4377 0xc0027c4378}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb  7 03:57:43.099: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6586df867b,GenerateName:,Namespace:e2e-tests-deployment-hmx6m,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-hmx6m/replicasets/test-rollover-deployment-6586df867b,UID:7bb2d465-2a8c-11e9-927c-4a513db42ba3,ResourceVersion:23211,Generation:2,CreationTimestamp:2019-02-07 03:57:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 7ba78c1b-2a8c-11e9-809d-e6a419c8531a 0xc0027c4437 0xc0027c4438}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb  7 03:57:43.329: INFO: Pod "test-rollover-deployment-6b7f9d6597-lhcdh" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597-lhcdh,GenerateName:test-rollover-deployment-6b7f9d6597-,Namespace:e2e-tests-deployment-hmx6m,SelfLink:/api/v1/namespaces/e2e-tests-deployment-hmx6m/pods/test-rollover-deployment-6b7f9d6597-lhcdh,UID:7ce7b2e3-2a8c-11e9-927c-4a513db42ba3,ResourceVersion:23223,Generation:0,CreationTimestamp:2019-02-07 03:57:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.3.63/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-6b7f9d6597 7ce48eac-2a8c-11e9-927c-4a513db42ba3 0xc0027c5387 0xc0027c5388}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-v5pdd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-v5pdd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-v5pdd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-node-2-kubelet.devkubernetes01.mesos,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0027c5470} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0027c5490}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:57:29 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:57:30 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:57:30 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 03:57:29 +0000 UTC  }],Message:,Reason:,HostIP:9.0.2.4,PodIP:192.168.3.63,StartTime:2019-02-07 03:57:29 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-02-07 03:57:29 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://74cd03ded97dccbe12d87aac5c335d3092ed8d15ad7730f54d66eb560d500ee8}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 03:57:43.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-hmx6m" for this suite.
Feb  7 03:57:51.343: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 03:57:51.483: INFO: namespace: e2e-tests-deployment-hmx6m, resource: bindings, ignored listing per whitelist
Feb  7 03:57:51.501: INFO: namespace e2e-tests-deployment-hmx6m deletion completed in 8.167851726s

• [SLOW TEST:32.056 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 03:57:51.501: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-4tjsw
Feb  7 03:57:53.565: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-4tjsw
STEP: checking the pod's current state and verifying that restartCount is present
Feb  7 03:57:53.567: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 04:01:54.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-4tjsw" for this suite.
Feb  7 04:02:00.660: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 04:02:00.672: INFO: namespace: e2e-tests-container-probe-4tjsw, resource: bindings, ignored listing per whitelist
Feb  7 04:02:00.752: INFO: namespace e2e-tests-container-probe-4tjsw deletion completed in 6.120318554s

• [SLOW TEST:249.252 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 04:02:00.753: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-1edcc45b-2a8d-11e9-87fe-baa4eca941e3
STEP: Creating a pod to test consume secrets
Feb  7 04:02:00.815: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1edd8818-2a8d-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-projected-tzwcf" to be "success or failure"
Feb  7 04:02:00.817: INFO: Pod "pod-projected-secrets-1edd8818-2a8d-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.061903ms
Feb  7 04:02:02.820: INFO: Pod "pod-projected-secrets-1edd8818-2a8d-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004907329s
STEP: Saw pod success
Feb  7 04:02:02.820: INFO: Pod "pod-projected-secrets-1edd8818-2a8d-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 04:02:02.822: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod pod-projected-secrets-1edd8818-2a8d-11e9-87fe-baa4eca941e3 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb  7 04:02:02.926: INFO: Waiting for pod pod-projected-secrets-1edd8818-2a8d-11e9-87fe-baa4eca941e3 to disappear
Feb  7 04:02:02.928: INFO: Pod pod-projected-secrets-1edd8818-2a8d-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 04:02:02.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-tzwcf" for this suite.
Feb  7 04:02:11.273: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 04:02:11.331: INFO: namespace: e2e-tests-projected-tzwcf, resource: bindings, ignored listing per whitelist
Feb  7 04:02:11.369: INFO: namespace e2e-tests-projected-tzwcf deletion completed in 8.438461188s

• [SLOW TEST:10.617 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 04:02:11.369: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-p4rlx in namespace e2e-tests-proxy-556gk
I0207 04:02:11.436529      17 runners.go:184] Created replication controller with name: proxy-service-p4rlx, namespace: e2e-tests-proxy-556gk, replica count: 1
I0207 04:02:12.487070      17 runners.go:184] proxy-service-p4rlx Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0207 04:02:13.487271      17 runners.go:184] proxy-service-p4rlx Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0207 04:02:14.487478      17 runners.go:184] proxy-service-p4rlx Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0207 04:02:15.487677      17 runners.go:184] proxy-service-p4rlx Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0207 04:02:16.487881      17 runners.go:184] proxy-service-p4rlx Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0207 04:02:17.488080      17 runners.go:184] proxy-service-p4rlx Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0207 04:02:18.488306      17 runners.go:184] proxy-service-p4rlx Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0207 04:02:19.488614      17 runners.go:184] proxy-service-p4rlx Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0207 04:02:20.488841      17 runners.go:184] proxy-service-p4rlx Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0207 04:02:21.489087      17 runners.go:184] proxy-service-p4rlx Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb  7 04:02:21.496: INFO: setup took 10.073673957s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Feb  7 04:02:21.500: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:160/proxy/: foo (200; 3.893226ms)
Feb  7 04:02:21.501: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:160/proxy/: foo (200; 5.213791ms)
Feb  7 04:02:21.502: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:162/proxy/: bar (200; 5.637187ms)
Feb  7 04:02:21.502: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:1080/proxy/rewri... (200; 5.737809ms)
Feb  7 04:02:21.502: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj/proxy/rewriteme"... (200; 5.798635ms)
Feb  7 04:02:21.502: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:162/proxy/: bar (200; 5.940661ms)
Feb  7 04:02:21.502: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:1080/proxy/... (200; 5.947376ms)
Feb  7 04:02:21.502: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-556gk/services/http:proxy-service-p4rlx:portname1/proxy/: foo (200; 6.450027ms)
Feb  7 04:02:21.503: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-556gk/services/proxy-service-p4rlx:portname2/proxy/: bar (200; 6.588833ms)
Feb  7 04:02:21.503: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-556gk/services/proxy-service-p4rlx:portname1/proxy/: foo (200; 6.744652ms)
Feb  7 04:02:21.503: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-556gk/services/http:proxy-service-p4rlx:portname2/proxy/: bar (200; 6.863039ms)
Feb  7 04:02:21.507: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:460/proxy/: tls baz (200; 11.047719ms)
Feb  7 04:02:21.508: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:462/proxy/: tls qux (200; 12.488809ms)
Feb  7 04:02:21.509: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:443/proxy/... (200; 12.697415ms)
Feb  7 04:02:21.510: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-556gk/services/https:proxy-service-p4rlx:tlsportname1/proxy/: tls baz (200; 14.15377ms)
Feb  7 04:02:21.510: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-556gk/services/https:proxy-service-p4rlx:tlsportname2/proxy/: tls qux (200; 14.263917ms)
Feb  7 04:02:21.513: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:1080/proxy/rewri... (200; 3.127029ms)
Feb  7 04:02:21.514: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:162/proxy/: bar (200; 3.252775ms)
Feb  7 04:02:21.514: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:160/proxy/: foo (200; 3.234276ms)
Feb  7 04:02:21.514: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:443/proxy/... (200; 3.672391ms)
Feb  7 04:02:21.514: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:160/proxy/: foo (200; 3.939183ms)
Feb  7 04:02:21.514: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:1080/proxy/... (200; 3.909285ms)
Feb  7 04:02:21.515: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:162/proxy/: bar (200; 4.09107ms)
Feb  7 04:02:21.515: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:462/proxy/: tls qux (200; 4.074423ms)
Feb  7 04:02:21.515: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj/proxy/rewriteme"... (200; 4.533924ms)
Feb  7 04:02:21.515: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:460/proxy/: tls baz (200; 4.567024ms)
Feb  7 04:02:21.516: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-556gk/services/http:proxy-service-p4rlx:portname1/proxy/: foo (200; 5.15242ms)
Feb  7 04:02:21.518: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-556gk/services/https:proxy-service-p4rlx:tlsportname2/proxy/: tls qux (200; 7.276203ms)
Feb  7 04:02:21.518: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-556gk/services/http:proxy-service-p4rlx:portname2/proxy/: bar (200; 7.718686ms)
Feb  7 04:02:21.518: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-556gk/services/proxy-service-p4rlx:portname2/proxy/: bar (200; 7.733367ms)
Feb  7 04:02:21.518: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-556gk/services/proxy-service-p4rlx:portname1/proxy/: foo (200; 7.729557ms)
Feb  7 04:02:21.518: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-556gk/services/https:proxy-service-p4rlx:tlsportname1/proxy/: tls baz (200; 7.859571ms)
Feb  7 04:02:21.521: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:462/proxy/: tls qux (200; 2.788015ms)
Feb  7 04:02:21.522: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:160/proxy/: foo (200; 3.286053ms)
Feb  7 04:02:21.522: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj/proxy/rewriteme"... (200; 3.16398ms)
Feb  7 04:02:21.522: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:162/proxy/: bar (200; 3.264878ms)
Feb  7 04:02:21.522: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:160/proxy/: foo (200; 3.37653ms)
Feb  7 04:02:21.522: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:1080/proxy/rewri... (200; 3.148486ms)
Feb  7 04:02:21.522: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:460/proxy/: tls baz (200; 3.76494ms)
Feb  7 04:02:21.523: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:443/proxy/... (200; 4.108328ms)
Feb  7 04:02:21.523: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:162/proxy/: bar (200; 4.134704ms)
Feb  7 04:02:21.524: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-556gk/services/https:proxy-service-p4rlx:tlsportname2/proxy/: tls qux (200; 4.941263ms)
Feb  7 04:02:21.524: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:1080/proxy/... (200; 5.48179ms)
Feb  7 04:02:21.524: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-556gk/services/http:proxy-service-p4rlx:portname1/proxy/: foo (200; 5.454611ms)
Feb  7 04:02:21.524: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-556gk/services/https:proxy-service-p4rlx:tlsportname1/proxy/: tls baz (200; 5.422663ms)
Feb  7 04:02:21.525: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-556gk/services/http:proxy-service-p4rlx:portname2/proxy/: bar (200; 6.192182ms)
Feb  7 04:02:21.525: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-556gk/services/proxy-service-p4rlx:portname1/proxy/: foo (200; 6.346486ms)
Feb  7 04:02:21.525: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-556gk/services/proxy-service-p4rlx:portname2/proxy/: bar (200; 6.456263ms)
Feb  7 04:02:21.528: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:162/proxy/: bar (200; 2.639919ms)
Feb  7 04:02:21.528: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:460/proxy/: tls baz (200; 3.079886ms)
Feb  7 04:02:21.528: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:160/proxy/: foo (200; 3.206669ms)
Feb  7 04:02:21.528: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:443/proxy/... (200; 3.297373ms)
Feb  7 04:02:21.528: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:1080/proxy/... (200; 3.271353ms)
Feb  7 04:02:21.528: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:462/proxy/: tls qux (200; 3.382522ms)
Feb  7 04:02:21.530: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj/proxy/rewriteme"... (200; 4.624411ms)
Feb  7 04:02:21.530: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-556gk/services/http:proxy-service-p4rlx:portname1/proxy/: foo (200; 4.683274ms)
Feb  7 04:02:21.530: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:160/proxy/: foo (200; 4.665017ms)
Feb  7 04:02:21.530: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:162/proxy/: bar (200; 4.645589ms)
Feb  7 04:02:21.530: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:1080/proxy/rewri... (200; 4.598988ms)
Feb  7 04:02:21.531: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-556gk/services/http:proxy-service-p4rlx:portname2/proxy/: bar (200; 5.879347ms)
Feb  7 04:02:21.532: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-556gk/services/https:proxy-service-p4rlx:tlsportname1/proxy/: tls baz (200; 6.456113ms)
Feb  7 04:02:21.532: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-556gk/services/proxy-service-p4rlx:portname1/proxy/: foo (200; 6.469415ms)
Feb  7 04:02:21.532: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-556gk/services/proxy-service-p4rlx:portname2/proxy/: bar (200; 6.435954ms)
Feb  7 04:02:21.532: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-556gk/services/https:proxy-service-p4rlx:tlsportname2/proxy/: tls qux (200; 6.484241ms)
Feb  7 04:02:21.538: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:443/proxy/... (200; 5.7717ms)
Feb  7 04:02:21.538: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:462/proxy/: tls qux (200; 5.798372ms)
Feb  7 04:02:21.538: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:1080/proxy/... (200; 6.116104ms)
Feb  7 04:02:21.538: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:160/proxy/: foo (200; 6.314814ms)
Feb  7 04:02:21.538: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj/proxy/rewriteme"... (200; 6.407521ms)
Feb  7 04:02:21.538: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:1080/proxy/rewri... (200; 6.452736ms)
Feb  7 04:02:21.613: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:160/proxy/: foo (200; 80.716691ms)
Feb  7 04:02:21.613: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:162/proxy/: bar (200; 81.242072ms)
Feb  7 04:02:21.613: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:162/proxy/: bar (200; 81.181883ms)
Feb  7 04:02:21.613: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-556gk/services/proxy-service-p4rlx:portname1/proxy/: foo (200; 81.251572ms)
Feb  7 04:02:21.613: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-556gk/services/https:proxy-service-p4rlx:tlsportname1/proxy/: tls baz (200; 81.223168ms)
Feb  7 04:02:21.613: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:460/proxy/: tls baz (200; 81.216724ms)
Feb  7 04:02:21.613: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-556gk/services/https:proxy-service-p4rlx:tlsportname2/proxy/: tls qux (200; 81.193374ms)
Feb  7 04:02:21.613: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-556gk/services/http:proxy-service-p4rlx:portname1/proxy/: foo (200; 81.183259ms)
Feb  7 04:02:21.613: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-556gk/services/proxy-service-p4rlx:portname2/proxy/: bar (200; 81.164918ms)
Feb  7 04:02:21.613: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-556gk/services/http:proxy-service-p4rlx:portname2/proxy/: bar (200; 81.272785ms)
Feb  7 04:02:21.616: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj/proxy/rewriteme"... (200; 2.893549ms)
Feb  7 04:02:21.617: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:462/proxy/: tls qux (200; 3.737725ms)
Feb  7 04:02:21.617: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:460/proxy/: tls baz (200; 4.191931ms)
Feb  7 04:02:21.617: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:160/proxy/: foo (200; 4.221184ms)
Feb  7 04:02:21.617: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:162/proxy/: bar (200; 4.435129ms)
Feb  7 04:02:21.618: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:162/proxy/: bar (200; 4.37917ms)
Feb  7 04:02:21.618: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:1080/proxy/... (200; 4.502619ms)
Feb  7 04:02:21.618: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:443/proxy/... (200; 4.627771ms)
Feb  7 04:02:21.618: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:160/proxy/: foo (200; 5.194581ms)
Feb  7 04:02:21.618: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-556gk/services/proxy-service-p4rlx:portname1/proxy/: foo (200; 5.394362ms)
Feb  7 04:02:21.619: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:1080/proxy/rewri... (200; 5.529612ms)
Feb  7 04:02:21.619: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-556gk/services/http:proxy-service-p4rlx:portname1/proxy/: foo (200; 5.837188ms)
Feb  7 04:02:21.619: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-556gk/services/proxy-service-p4rlx:portname2/proxy/: bar (200; 5.992735ms)
Feb  7 04:02:21.620: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-556gk/services/https:proxy-service-p4rlx:tlsportname1/proxy/: tls baz (200; 6.436097ms)
Feb  7 04:02:21.620: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-556gk/services/http:proxy-service-p4rlx:portname2/proxy/: bar (200; 6.436284ms)
Feb  7 04:02:21.620: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-556gk/services/https:proxy-service-p4rlx:tlsportname2/proxy/: tls qux (200; 6.546484ms)
Feb  7 04:02:21.623: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:160/proxy/: foo (200; 3.039954ms)
Feb  7 04:02:21.623: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:160/proxy/: foo (200; 3.582971ms)
Feb  7 04:02:21.623: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:162/proxy/: bar (200; 3.704369ms)
Feb  7 04:02:21.623: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:443/proxy/... (200; 3.806482ms)
Feb  7 04:02:21.623: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:460/proxy/: tls baz (200; 3.827349ms)
Feb  7 04:02:21.624: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:1080/proxy/... (200; 4.333297ms)
Feb  7 04:02:21.624: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:1080/proxy/rewri... (200; 4.43631ms)
Feb  7 04:02:21.624: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:162/proxy/: bar (200; 4.335705ms)
Feb  7 04:02:21.624: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:462/proxy/: tls qux (200; 4.50722ms)
Feb  7 04:02:21.626: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-556gk/services/proxy-service-p4rlx:portname1/proxy/: foo (200; 5.85817ms)
Feb  7 04:02:21.626: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj/proxy/rewriteme"... (200; 5.826451ms)
Feb  7 04:02:21.626: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-556gk/services/https:proxy-service-p4rlx:tlsportname2/proxy/: tls qux (200; 6.138093ms)
Feb  7 04:02:21.626: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-556gk/services/proxy-service-p4rlx:portname2/proxy/: bar (200; 6.600836ms)
Feb  7 04:02:21.626: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-556gk/services/https:proxy-service-p4rlx:tlsportname1/proxy/: tls baz (200; 6.691259ms)
Feb  7 04:02:21.627: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-556gk/services/http:proxy-service-p4rlx:portname1/proxy/: foo (200; 6.94861ms)
Feb  7 04:02:21.627: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-556gk/services/http:proxy-service-p4rlx:portname2/proxy/: bar (200; 7.07191ms)
Feb  7 04:02:21.630: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:462/proxy/: tls qux (200; 2.725608ms)
Feb  7 04:02:21.630: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:162/proxy/: bar (200; 3.247804ms)
Feb  7 04:02:21.630: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:160/proxy/: foo (200; 3.146564ms)
Feb  7 04:02:21.631: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:1080/proxy/... (200; 3.930667ms)
Feb  7 04:02:21.631: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:160/proxy/: foo (200; 3.981484ms)
Feb  7 04:02:21.631: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj/proxy/rewriteme"... (200; 3.986141ms)
Feb  7 04:02:21.631: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:460/proxy/: tls baz (200; 4.210289ms)
Feb  7 04:02:21.631: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:443/proxy/... (200; 4.184322ms)
Feb  7 04:02:21.631: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:1080/proxy/rewri... (200; 4.27273ms)
Feb  7 04:02:21.632: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:162/proxy/: bar (200; 4.368242ms)
Feb  7 04:02:21.632: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-556gk/services/http:proxy-service-p4rlx:portname2/proxy/: bar (200; 5.255668ms)
Feb  7 04:02:21.633: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-556gk/services/https:proxy-service-p4rlx:tlsportname2/proxy/: tls qux (200; 5.806912ms)
Feb  7 04:02:21.633: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-556gk/services/http:proxy-service-p4rlx:portname1/proxy/: foo (200; 6.291621ms)
Feb  7 04:02:21.633: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-556gk/services/https:proxy-service-p4rlx:tlsportname1/proxy/: tls baz (200; 6.291472ms)
Feb  7 04:02:21.633: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-556gk/services/proxy-service-p4rlx:portname1/proxy/: foo (200; 6.445382ms)
Feb  7 04:02:21.633: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-556gk/services/proxy-service-p4rlx:portname2/proxy/: bar (200; 6.270652ms)
Feb  7 04:02:21.636: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:1080/proxy/rewri... (200; 2.755244ms)
Feb  7 04:02:21.637: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:160/proxy/: foo (200; 3.283812ms)
Feb  7 04:02:21.637: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj/proxy/rewriteme"... (200; 3.417407ms)
Feb  7 04:02:21.637: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:462/proxy/: tls qux (200; 3.852383ms)
Feb  7 04:02:21.637: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:162/proxy/: bar (200; 3.950744ms)
Feb  7 04:02:21.638: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:460/proxy/: tls baz (200; 3.810939ms)
Feb  7 04:02:21.638: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:1080/proxy/... (200; 4.050539ms)
Feb  7 04:02:21.638: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:160/proxy/: foo (200; 4.057751ms)
Feb  7 04:02:21.638: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-556gk/services/https:proxy-service-p4rlx:tlsportname2/proxy/: tls qux (200; 4.304006ms)
Feb  7 04:02:21.638: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:162/proxy/: bar (200; 4.697541ms)
Feb  7 04:02:21.639: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:443/proxy/... (200; 5.118213ms)
Feb  7 04:02:21.640: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-556gk/services/proxy-service-p4rlx:portname2/proxy/: bar (200; 6.060247ms)
Feb  7 04:02:21.640: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-556gk/services/http:proxy-service-p4rlx:portname2/proxy/: bar (200; 6.05612ms)
Feb  7 04:02:21.640: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-556gk/services/https:proxy-service-p4rlx:tlsportname1/proxy/: tls baz (200; 6.023393ms)
Feb  7 04:02:21.640: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-556gk/services/http:proxy-service-p4rlx:portname1/proxy/: foo (200; 6.439216ms)
Feb  7 04:02:21.640: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-556gk/services/proxy-service-p4rlx:portname1/proxy/: foo (200; 6.372315ms)
Feb  7 04:02:21.644: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:162/proxy/: bar (200; 3.929043ms)
Feb  7 04:02:21.644: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:460/proxy/: tls baz (200; 4.153072ms)
Feb  7 04:02:21.645: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:462/proxy/: tls qux (200; 4.416829ms)
Feb  7 04:02:21.645: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj/proxy/rewriteme"... (200; 4.596387ms)
Feb  7 04:02:21.645: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:162/proxy/: bar (200; 4.496479ms)
Feb  7 04:02:21.645: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:1080/proxy/rewri... (200; 4.534595ms)
Feb  7 04:02:21.645: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-556gk/services/https:proxy-service-p4rlx:tlsportname2/proxy/: tls qux (200; 5.211497ms)
Feb  7 04:02:21.645: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:160/proxy/: foo (200; 5.028604ms)
Feb  7 04:02:21.645: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:443/proxy/... (200; 5.055813ms)
Feb  7 04:02:21.645: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:160/proxy/: foo (200; 5.075013ms)
Feb  7 04:02:21.645: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:1080/proxy/... (200; 5.11623ms)
Feb  7 04:02:21.712: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-556gk/services/proxy-service-p4rlx:portname2/proxy/: bar (200; 72.004971ms)
Feb  7 04:02:21.713: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-556gk/services/http:proxy-service-p4rlx:portname1/proxy/: foo (200; 73.00353ms)
Feb  7 04:02:21.713: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-556gk/services/https:proxy-service-p4rlx:tlsportname1/proxy/: tls baz (200; 73.122324ms)
Feb  7 04:02:21.713: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-556gk/services/http:proxy-service-p4rlx:portname2/proxy/: bar (200; 73.018311ms)
Feb  7 04:02:21.713: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-556gk/services/proxy-service-p4rlx:portname1/proxy/: foo (200; 73.113785ms)
Feb  7 04:02:21.717: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:162/proxy/: bar (200; 3.175729ms)
Feb  7 04:02:21.718: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:1080/proxy/... (200; 4.418539ms)
Feb  7 04:02:21.718: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:162/proxy/: bar (200; 4.58533ms)
Feb  7 04:02:21.718: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:443/proxy/... (200; 4.640592ms)
Feb  7 04:02:21.718: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:1080/proxy/rewri... (200; 4.764104ms)
Feb  7 04:02:21.718: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:462/proxy/: tls qux (200; 4.567271ms)
Feb  7 04:02:21.718: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:160/proxy/: foo (200; 4.644451ms)
Feb  7 04:02:21.718: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:460/proxy/: tls baz (200; 4.601702ms)
Feb  7 04:02:21.718: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:160/proxy/: foo (200; 4.636339ms)
Feb  7 04:02:21.718: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj/proxy/rewriteme"... (200; 4.686113ms)
Feb  7 04:02:21.719: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-556gk/services/proxy-service-p4rlx:portname2/proxy/: bar (200; 5.240504ms)
Feb  7 04:02:21.721: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-556gk/services/http:proxy-service-p4rlx:portname2/proxy/: bar (200; 7.273985ms)
Feb  7 04:02:21.722: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-556gk/services/http:proxy-service-p4rlx:portname1/proxy/: foo (200; 8.47704ms)
Feb  7 04:02:21.722: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-556gk/services/https:proxy-service-p4rlx:tlsportname1/proxy/: tls baz (200; 8.603904ms)
Feb  7 04:02:21.722: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-556gk/services/https:proxy-service-p4rlx:tlsportname2/proxy/: tls qux (200; 8.514204ms)
Feb  7 04:02:21.722: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-556gk/services/proxy-service-p4rlx:portname1/proxy/: foo (200; 8.557376ms)
Feb  7 04:02:21.727: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:1080/proxy/... (200; 4.559734ms)
Feb  7 04:02:21.728: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:443/proxy/... (200; 5.781667ms)
Feb  7 04:02:21.728: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:162/proxy/: bar (200; 5.7662ms)
Feb  7 04:02:21.728: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:160/proxy/: foo (200; 5.713109ms)
Feb  7 04:02:21.728: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:162/proxy/: bar (200; 5.746138ms)
Feb  7 04:02:21.728: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-556gk/services/https:proxy-service-p4rlx:tlsportname2/proxy/: tls qux (200; 5.771703ms)
Feb  7 04:02:21.728: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:160/proxy/: foo (200; 5.778176ms)
Feb  7 04:02:21.728: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:462/proxy/: tls qux (200; 5.742926ms)
Feb  7 04:02:21.728: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:460/proxy/: tls baz (200; 5.683015ms)
Feb  7 04:02:21.728: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:1080/proxy/rewri... (200; 5.879808ms)
Feb  7 04:02:21.728: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj/proxy/rewriteme"... (200; 5.703925ms)
Feb  7 04:02:21.730: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-556gk/services/https:proxy-service-p4rlx:tlsportname1/proxy/: tls baz (200; 7.250229ms)
Feb  7 04:02:21.730: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-556gk/services/proxy-service-p4rlx:portname2/proxy/: bar (200; 7.279973ms)
Feb  7 04:02:21.730: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-556gk/services/http:proxy-service-p4rlx:portname1/proxy/: foo (200; 7.319968ms)
Feb  7 04:02:21.730: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-556gk/services/proxy-service-p4rlx:portname1/proxy/: foo (200; 7.302275ms)
Feb  7 04:02:21.730: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-556gk/services/http:proxy-service-p4rlx:portname2/proxy/: bar (200; 7.327173ms)
Feb  7 04:02:21.733: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:1080/proxy/rewri... (200; 3.495903ms)
Feb  7 04:02:21.734: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:443/proxy/... (200; 3.95173ms)
Feb  7 04:02:21.734: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:160/proxy/: foo (200; 4.00273ms)
Feb  7 04:02:21.735: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:162/proxy/: bar (200; 5.038115ms)
Feb  7 04:02:21.735: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:162/proxy/: bar (200; 5.220237ms)
Feb  7 04:02:21.735: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj/proxy/rewriteme"... (200; 5.321696ms)
Feb  7 04:02:21.735: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:462/proxy/: tls qux (200; 5.293049ms)
Feb  7 04:02:21.735: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:460/proxy/: tls baz (200; 5.635214ms)
Feb  7 04:02:21.736: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:160/proxy/: foo (200; 5.805621ms)
Feb  7 04:02:21.736: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-556gk/services/http:proxy-service-p4rlx:portname2/proxy/: bar (200; 5.979229ms)
Feb  7 04:02:21.736: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:1080/proxy/... (200; 5.848597ms)
Feb  7 04:02:21.737: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-556gk/services/http:proxy-service-p4rlx:portname1/proxy/: foo (200; 7.352797ms)
Feb  7 04:02:21.738: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-556gk/services/proxy-service-p4rlx:portname1/proxy/: foo (200; 8.563537ms)
Feb  7 04:02:21.738: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-556gk/services/https:proxy-service-p4rlx:tlsportname1/proxy/: tls baz (200; 8.574356ms)
Feb  7 04:02:21.738: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-556gk/services/https:proxy-service-p4rlx:tlsportname2/proxy/: tls qux (200; 8.599156ms)
Feb  7 04:02:21.738: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-556gk/services/proxy-service-p4rlx:portname2/proxy/: bar (200; 8.720518ms)
Feb  7 04:02:21.742: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:162/proxy/: bar (200; 3.367603ms)
Feb  7 04:02:21.742: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:160/proxy/: foo (200; 3.775037ms)
Feb  7 04:02:21.743: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:162/proxy/: bar (200; 4.206693ms)
Feb  7 04:02:21.743: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:1080/proxy/... (200; 4.163708ms)
Feb  7 04:02:21.743: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:460/proxy/: tls baz (200; 4.358597ms)
Feb  7 04:02:21.743: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:443/proxy/... (200; 4.311077ms)
Feb  7 04:02:21.743: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:160/proxy/: foo (200; 4.640174ms)
Feb  7 04:02:21.743: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:1080/proxy/rewri... (200; 4.846297ms)
Feb  7 04:02:21.744: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:462/proxy/: tls qux (200; 4.884374ms)
Feb  7 04:02:21.744: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj/proxy/rewriteme"... (200; 4.924354ms)
Feb  7 04:02:21.744: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-556gk/services/https:proxy-service-p4rlx:tlsportname2/proxy/: tls qux (200; 5.706629ms)
Feb  7 04:02:21.745: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-556gk/services/http:proxy-service-p4rlx:portname1/proxy/: foo (200; 6.768086ms)
Feb  7 04:02:21.746: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-556gk/services/http:proxy-service-p4rlx:portname2/proxy/: bar (200; 7.366047ms)
Feb  7 04:02:21.746: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-556gk/services/https:proxy-service-p4rlx:tlsportname1/proxy/: tls baz (200; 7.632555ms)
Feb  7 04:02:21.746: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-556gk/services/proxy-service-p4rlx:portname2/proxy/: bar (200; 7.618489ms)
Feb  7 04:02:21.746: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-556gk/services/proxy-service-p4rlx:portname1/proxy/: foo (200; 7.752749ms)
Feb  7 04:02:21.750: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:162/proxy/: bar (200; 3.45704ms)
Feb  7 04:02:21.750: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:460/proxy/: tls baz (200; 3.692541ms)
Feb  7 04:02:21.750: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:1080/proxy/... (200; 3.693334ms)
Feb  7 04:02:21.752: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:162/proxy/: bar (200; 5.03432ms)
Feb  7 04:02:21.752: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-556gk/services/http:proxy-service-p4rlx:portname1/proxy/: foo (200; 5.190171ms)
Feb  7 04:02:21.752: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:1080/proxy/rewri... (200; 5.189772ms)
Feb  7 04:02:21.752: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:462/proxy/: tls qux (200; 5.108849ms)
Feb  7 04:02:21.752: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj/proxy/rewriteme"... (200; 5.057583ms)
Feb  7 04:02:21.752: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:160/proxy/: foo (200; 5.135636ms)
Feb  7 04:02:21.752: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:443/proxy/... (200; 5.089297ms)
Feb  7 04:02:21.752: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:160/proxy/: foo (200; 5.459982ms)
Feb  7 04:02:21.753: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-556gk/services/https:proxy-service-p4rlx:tlsportname1/proxy/: tls baz (200; 6.131228ms)
Feb  7 04:02:21.812: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-556gk/services/proxy-service-p4rlx:portname1/proxy/: foo (200; 65.601164ms)
Feb  7 04:02:21.812: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-556gk/services/proxy-service-p4rlx:portname2/proxy/: bar (200; 65.742847ms)
Feb  7 04:02:21.812: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-556gk/services/http:proxy-service-p4rlx:portname2/proxy/: bar (200; 65.920028ms)
Feb  7 04:02:21.812: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-556gk/services/https:proxy-service-p4rlx:tlsportname2/proxy/: tls qux (200; 65.840556ms)
Feb  7 04:02:21.816: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:1080/proxy/rewri... (200; 3.660633ms)
Feb  7 04:02:21.818: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:1080/proxy/... (200; 5.347057ms)
Feb  7 04:02:21.818: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj/proxy/rewriteme"... (200; 5.36987ms)
Feb  7 04:02:21.818: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:160/proxy/: foo (200; 5.437535ms)
Feb  7 04:02:21.818: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:460/proxy/: tls baz (200; 5.733273ms)
Feb  7 04:02:21.818: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:443/proxy/... (200; 5.811857ms)
Feb  7 04:02:21.818: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:462/proxy/: tls qux (200; 5.742703ms)
Feb  7 04:02:21.818: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:162/proxy/: bar (200; 5.801702ms)
Feb  7 04:02:21.818: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-556gk/services/https:proxy-service-p4rlx:tlsportname1/proxy/: tls baz (200; 5.913621ms)
Feb  7 04:02:21.818: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:162/proxy/: bar (200; 5.859202ms)
Feb  7 04:02:21.818: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:160/proxy/: foo (200; 5.899982ms)
Feb  7 04:02:21.819: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-556gk/services/http:proxy-service-p4rlx:portname2/proxy/: bar (200; 6.252124ms)
Feb  7 04:02:21.819: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-556gk/services/proxy-service-p4rlx:portname2/proxy/: bar (200; 6.776668ms)
Feb  7 04:02:21.819: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-556gk/services/proxy-service-p4rlx:portname1/proxy/: foo (200; 6.803968ms)
Feb  7 04:02:21.820: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-556gk/services/https:proxy-service-p4rlx:tlsportname2/proxy/: tls qux (200; 7.156168ms)
Feb  7 04:02:21.820: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-556gk/services/http:proxy-service-p4rlx:portname1/proxy/: foo (200; 7.275097ms)
Feb  7 04:02:21.822: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:1080/proxy/rewri... (200; 2.595347ms)
Feb  7 04:02:21.823: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:160/proxy/: foo (200; 2.986062ms)
Feb  7 04:02:21.823: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:462/proxy/: tls qux (200; 2.982907ms)
Feb  7 04:02:21.823: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:160/proxy/: foo (200; 3.498678ms)
Feb  7 04:02:21.824: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:162/proxy/: bar (200; 3.704452ms)
Feb  7 04:02:21.824: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:162/proxy/: bar (200; 3.866009ms)
Feb  7 04:02:21.824: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:443/proxy/... (200; 3.82904ms)
Feb  7 04:02:21.824: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj/proxy/rewriteme"... (200; 3.782059ms)
Feb  7 04:02:21.824: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:1080/proxy/... (200; 3.821612ms)
Feb  7 04:02:21.824: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:460/proxy/: tls baz (200; 3.889334ms)
Feb  7 04:02:21.825: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-556gk/services/https:proxy-service-p4rlx:tlsportname1/proxy/: tls baz (200; 4.80597ms)
Feb  7 04:02:21.826: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-556gk/services/proxy-service-p4rlx:portname1/proxy/: foo (200; 6.428207ms)
Feb  7 04:02:21.826: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-556gk/services/http:proxy-service-p4rlx:portname2/proxy/: bar (200; 6.460206ms)
Feb  7 04:02:21.827: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-556gk/services/https:proxy-service-p4rlx:tlsportname2/proxy/: tls qux (200; 6.980229ms)
Feb  7 04:02:21.827: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-556gk/services/proxy-service-p4rlx:portname2/proxy/: bar (200; 7.057626ms)
Feb  7 04:02:21.827: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-556gk/services/http:proxy-service-p4rlx:portname1/proxy/: foo (200; 7.221639ms)
Feb  7 04:02:21.830: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:162/proxy/: bar (200; 2.784759ms)
Feb  7 04:02:21.830: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:1080/proxy/... (200; 3.245957ms)
Feb  7 04:02:21.830: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:162/proxy/: bar (200; 3.263411ms)
Feb  7 04:02:21.831: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:1080/proxy/rewri... (200; 3.826364ms)
Feb  7 04:02:21.831: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:462/proxy/: tls qux (200; 3.818196ms)
Feb  7 04:02:21.831: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:160/proxy/: foo (200; 4.29963ms)
Feb  7 04:02:21.831: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:443/proxy/... (200; 4.369597ms)
Feb  7 04:02:21.832: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj/proxy/rewriteme"... (200; 4.455157ms)
Feb  7 04:02:21.832: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:460/proxy/: tls baz (200; 4.438133ms)
Feb  7 04:02:21.832: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:160/proxy/: foo (200; 4.697305ms)
Feb  7 04:02:21.832: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-556gk/services/https:proxy-service-p4rlx:tlsportname2/proxy/: tls qux (200; 5.127465ms)
Feb  7 04:02:21.833: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-556gk/services/https:proxy-service-p4rlx:tlsportname1/proxy/: tls baz (200; 5.736817ms)
Feb  7 04:02:21.834: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-556gk/services/proxy-service-p4rlx:portname2/proxy/: bar (200; 6.400718ms)
Feb  7 04:02:21.834: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-556gk/services/proxy-service-p4rlx:portname1/proxy/: foo (200; 7.09769ms)
Feb  7 04:02:21.835: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-556gk/services/http:proxy-service-p4rlx:portname2/proxy/: bar (200; 7.508645ms)
Feb  7 04:02:21.835: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-556gk/services/http:proxy-service-p4rlx:portname1/proxy/: foo (200; 7.521748ms)
Feb  7 04:02:21.912: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:462/proxy/: tls qux (200; 77.404256ms)
Feb  7 04:02:21.912: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj/proxy/rewriteme"... (200; 77.504456ms)
Feb  7 04:02:21.912: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:460/proxy/: tls baz (200; 77.561077ms)
Feb  7 04:02:21.913: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:162/proxy/: bar (200; 77.710582ms)
Feb  7 04:02:21.913: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:160/proxy/: foo (200; 77.794713ms)
Feb  7 04:02:21.913: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:1080/proxy/... (200; 78.019351ms)
Feb  7 04:02:21.913: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:443/proxy/... (200; 78.525063ms)
Feb  7 04:02:21.914: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:162/proxy/: bar (200; 79.000078ms)
Feb  7 04:02:21.914: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:160/proxy/: foo (200; 79.132315ms)
Feb  7 04:02:21.914: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:1080/proxy/rewri... (200; 79.627316ms)
Feb  7 04:02:21.915: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-556gk/services/proxy-service-p4rlx:portname1/proxy/: foo (200; 80.137358ms)
Feb  7 04:02:21.915: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-556gk/services/proxy-service-p4rlx:portname2/proxy/: bar (200; 80.049936ms)
Feb  7 04:02:21.915: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-556gk/services/http:proxy-service-p4rlx:portname2/proxy/: bar (200; 80.538304ms)
Feb  7 04:02:21.915: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-556gk/services/https:proxy-service-p4rlx:tlsportname1/proxy/: tls baz (200; 80.575324ms)
Feb  7 04:02:21.915: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-556gk/services/https:proxy-service-p4rlx:tlsportname2/proxy/: tls qux (200; 80.552269ms)
Feb  7 04:02:21.916: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-556gk/services/http:proxy-service-p4rlx:portname1/proxy/: foo (200; 80.564732ms)
Feb  7 04:02:21.919: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:160/proxy/: foo (200; 3.61182ms)
Feb  7 04:02:21.920: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:160/proxy/: foo (200; 4.316486ms)
Feb  7 04:02:21.920: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:1080/proxy/... (200; 4.486725ms)
Feb  7 04:02:21.920: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:460/proxy/: tls baz (200; 4.82165ms)
Feb  7 04:02:21.920: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj/proxy/rewriteme"... (200; 4.690944ms)
Feb  7 04:02:21.920: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:443/proxy/... (200; 4.763926ms)
Feb  7 04:02:21.920: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/http:proxy-service-p4rlx-jfszj:162/proxy/: bar (200; 4.804188ms)
Feb  7 04:02:21.921: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/https:proxy-service-p4rlx-jfszj:462/proxy/: tls qux (200; 4.868547ms)
Feb  7 04:02:21.921: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:1080/proxy/rewri... (200; 5.175013ms)
Feb  7 04:02:21.921: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-556gk/pods/proxy-service-p4rlx-jfszj:162/proxy/: bar (200; 5.216964ms)
Feb  7 04:02:21.921: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-556gk/services/https:proxy-service-p4rlx:tlsportname2/proxy/: tls qux (200; 5.504458ms)
Feb  7 04:02:21.921: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-556gk/services/https:proxy-service-p4rlx:tlsportname1/proxy/: tls baz (200; 5.880324ms)
Feb  7 04:02:21.921: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-556gk/services/proxy-service-p4rlx:portname2/proxy/: bar (200; 5.788754ms)
Feb  7 04:02:21.922: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-556gk/services/proxy-service-p4rlx:portname1/proxy/: foo (200; 6.207731ms)
Feb  7 04:02:21.923: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-556gk/services/http:proxy-service-p4rlx:portname1/proxy/: foo (200; 7.532822ms)
Feb  7 04:02:21.924: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-556gk/services/http:proxy-service-p4rlx:portname2/proxy/: bar (200; 8.02727ms)
STEP: deleting ReplicationController proxy-service-p4rlx in namespace e2e-tests-proxy-556gk, will wait for the garbage collector to delete the pods
Feb  7 04:02:22.016: INFO: Deleting ReplicationController proxy-service-p4rlx took: 39.986091ms
Feb  7 04:02:22.116: INFO: Terminating ReplicationController proxy-service-p4rlx pods took: 100.245575ms
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 04:02:23.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-556gk" for this suite.
Feb  7 04:02:29.865: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 04:02:29.956: INFO: namespace: e2e-tests-proxy-556gk, resource: bindings, ignored listing per whitelist
Feb  7 04:02:30.374: INFO: namespace e2e-tests-proxy-556gk deletion completed in 6.553560907s

• [SLOW TEST:19.004 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 04:02:30.374: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb  7 04:02:30.432: INFO: Waiting up to 5m0s for pod "pod-30846542-2a8d-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-emptydir-5x8p4" to be "success or failure"
Feb  7 04:02:30.434: INFO: Pod "pod-30846542-2a8d-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.836013ms
Feb  7 04:02:32.512: INFO: Pod "pod-30846542-2a8d-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.080232084s
STEP: Saw pod success
Feb  7 04:02:32.512: INFO: Pod "pod-30846542-2a8d-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 04:02:32.514: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod pod-30846542-2a8d-11e9-87fe-baa4eca941e3 container test-container: <nil>
STEP: delete the pod
Feb  7 04:02:32.529: INFO: Waiting for pod pod-30846542-2a8d-11e9-87fe-baa4eca941e3 to disappear
Feb  7 04:02:32.531: INFO: Pod pod-30846542-2a8d-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 04:02:32.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-5x8p4" for this suite.
Feb  7 04:02:38.545: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 04:02:38.620: INFO: namespace: e2e-tests-emptydir-5x8p4, resource: bindings, ignored listing per whitelist
Feb  7 04:02:38.641: INFO: namespace e2e-tests-emptydir-5x8p4 deletion completed in 6.106872028s

• [SLOW TEST:8.267 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 04:02:38.641: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  7 04:02:38.701: INFO: Waiting up to 5m0s for pod "downwardapi-volume-35721452-2a8d-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-projected-8fs7z" to be "success or failure"
Feb  7 04:02:38.702: INFO: Pod "downwardapi-volume-35721452-2a8d-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.821505ms
Feb  7 04:02:40.714: INFO: Pod "downwardapi-volume-35721452-2a8d-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01288812s
STEP: Saw pod success
Feb  7 04:02:40.714: INFO: Pod "downwardapi-volume-35721452-2a8d-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 04:02:40.716: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod downwardapi-volume-35721452-2a8d-11e9-87fe-baa4eca941e3 container client-container: <nil>
STEP: delete the pod
Feb  7 04:02:40.731: INFO: Waiting for pod downwardapi-volume-35721452-2a8d-11e9-87fe-baa4eca941e3 to disappear
Feb  7 04:02:40.732: INFO: Pod downwardapi-volume-35721452-2a8d-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 04:02:40.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8fs7z" for this suite.
Feb  7 04:02:48.747: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 04:02:48.891: INFO: namespace: e2e-tests-projected-8fs7z, resource: bindings, ignored listing per whitelist
Feb  7 04:02:48.905: INFO: namespace e2e-tests-projected-8fs7z deletion completed in 8.169083107s

• [SLOW TEST:10.264 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 04:02:48.905: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-3bbeebd3-2a8d-11e9-87fe-baa4eca941e3
STEP: Creating configMap with name cm-test-opt-upd-3bbeec0f-2a8d-11e9-87fe-baa4eca941e3
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-3bbeebd3-2a8d-11e9-87fe-baa4eca941e3
STEP: Updating configmap cm-test-opt-upd-3bbeec0f-2a8d-11e9-87fe-baa4eca941e3
STEP: Creating configMap with name cm-test-opt-create-3bbeec25-2a8d-11e9-87fe-baa4eca941e3
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 04:02:53.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pr877" for this suite.
Feb  7 04:03:15.453: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 04:03:15.540: INFO: namespace: e2e-tests-projected-pr877, resource: bindings, ignored listing per whitelist
Feb  7 04:03:15.551: INFO: namespace e2e-tests-projected-pr877 deletion completed in 22.120132287s

• [SLOW TEST:26.646 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 04:03:15.551: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-4b721137-2a8d-11e9-87fe-baa4eca941e3
STEP: Creating secret with name secret-projected-all-test-volume-4b721117-2a8d-11e9-87fe-baa4eca941e3
STEP: Creating a pod to test Check all projections for projected volume plugin
Feb  7 04:03:15.617: INFO: Waiting up to 5m0s for pod "projected-volume-4b7210d6-2a8d-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-projected-bvkbk" to be "success or failure"
Feb  7 04:03:15.619: INFO: Pod "projected-volume-4b7210d6-2a8d-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015327ms
Feb  7 04:03:17.622: INFO: Pod "projected-volume-4b7210d6-2a8d-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004848566s
STEP: Saw pod success
Feb  7 04:03:17.622: INFO: Pod "projected-volume-4b7210d6-2a8d-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 04:03:17.624: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod projected-volume-4b7210d6-2a8d-11e9-87fe-baa4eca941e3 container projected-all-volume-test: <nil>
STEP: delete the pod
Feb  7 04:03:17.638: INFO: Waiting for pod projected-volume-4b7210d6-2a8d-11e9-87fe-baa4eca941e3 to disappear
Feb  7 04:03:17.640: INFO: Pod projected-volume-4b7210d6-2a8d-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 04:03:17.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bvkbk" for this suite.
Feb  7 04:03:24.247: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 04:03:24.312: INFO: namespace: e2e-tests-projected-bvkbk, resource: bindings, ignored listing per whitelist
Feb  7 04:03:24.347: INFO: namespace e2e-tests-projected-bvkbk deletion completed in 6.704150735s

• [SLOW TEST:8.796 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 04:03:24.347: INFO: >>> kubeConfig: /tmp/kubeconfig-221081943
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Feb  7 04:03:24.404: INFO: Waiting up to 5m0s for pod "pod-50afc62b-2a8d-11e9-87fe-baa4eca941e3" in namespace "e2e-tests-emptydir-9kngq" to be "success or failure"
Feb  7 04:03:24.406: INFO: Pod "pod-50afc62b-2a8d-11e9-87fe-baa4eca941e3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.987046ms
Feb  7 04:03:26.653: INFO: Pod "pod-50afc62b-2a8d-11e9-87fe-baa4eca941e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.249954546s
STEP: Saw pod success
Feb  7 04:03:26.654: INFO: Pod "pod-50afc62b-2a8d-11e9-87fe-baa4eca941e3" satisfied condition "success or failure"
Feb  7 04:03:26.656: INFO: Trying to get logs from node kube-node-0-kubelet.devkubernetes01.mesos pod pod-50afc62b-2a8d-11e9-87fe-baa4eca941e3 container test-container: <nil>
STEP: delete the pod
Feb  7 04:03:26.669: INFO: Waiting for pod pod-50afc62b-2a8d-11e9-87fe-baa4eca941e3 to disappear
Feb  7 04:03:26.671: INFO: Pod pod-50afc62b-2a8d-11e9-87fe-baa4eca941e3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 04:03:26.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-9kngq" for this suite.
Feb  7 04:03:32.685: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 04:03:32.762: INFO: namespace: e2e-tests-emptydir-9kngq, resource: bindings, ignored listing per whitelist
Feb  7 04:03:32.786: INFO: namespace e2e-tests-emptydir-9kngq deletion completed in 6.111221035s

• [SLOW TEST:8.439 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SFeb  7 04:03:32.786: INFO: Running AfterSuite actions on all nodes
Feb  7 04:03:32.786: INFO: Running AfterSuite actions on node 1
Feb  7 04:03:32.786: INFO: Skipping dumping logs from cluster

Ran 200 of 1946 Specs in 5380.582 seconds
SUCCESS! -- 200 Passed | 0 Failed | 0 Pending | 1746 Skipped PASS

Ginkgo ran 1 suite in 1h29m41.267887158s
Test Suite Passed
