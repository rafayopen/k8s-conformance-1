I0109 11:58:35.960271      18 test_context.go:358] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-580595478
I0109 11:58:35.960387      18 e2e.go:224] Starting e2e run "e4a50e76-1405-11e9-a571-02181533b527" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1547035115 - Will randomize all specs
Will run 201 of 1946 specs

Jan  9 11:58:36.060: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
Jan  9 11:58:36.062: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Jan  9 11:58:36.069: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Jan  9 11:58:36.085: INFO: 1 / 1 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Jan  9 11:58:36.085: INFO: expected 1 pod replicas in namespace 'kube-system', 1 are Running and Ready.
Jan  9 11:58:36.085: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Jan  9 11:58:36.090: INFO: e2e test version: v1.13.0
Jan  9 11:58:36.091: INFO: kube-apiserver version: v1.13.1
SSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 11:58:36.091: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename sched-pred
Jan  9 11:58:36.125: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Jan  9 11:58:36.125: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jan  9 11:58:36.128: INFO: Waiting for terminating namespaces to be deleted...
Jan  9 11:58:36.129: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-59-90 before test
Jan  9 11:58:36.136: INFO: kube-dns-6ccd496668-rmn4f from kube-system started at 2019-01-09 11:57:35 +0000 UTC (3 container statuses recorded)
Jan  9 11:58:36.136: INFO: 	Container dnsmasq ready: true, restart count 0
Jan  9 11:58:36.136: INFO: 	Container kubedns ready: true, restart count 0
Jan  9 11:58:36.136: INFO: 	Container sidecar ready: true, restart count 0
Jan  9 11:58:36.136: INFO: sonobuoy from heptio-sonobuoy started at 2019-01-09 11:58:10 +0000 UTC (1 container statuses recorded)
Jan  9 11:58:36.136: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jan  9 11:58:36.136: INFO: sonobuoy-e2e-job-73c0b4a4fe2f4aff from heptio-sonobuoy started at 2019-01-09 11:58:13 +0000 UTC (2 container statuses recorded)
Jan  9 11:58:36.136: INFO: 	Container e2e ready: false, restart count 0
Jan  9 11:58:36.136: INFO: 	Container sonobuoy-worker ready: false, restart count 0
Jan  9 11:58:36.136: INFO: sonobuoy-systemd-logs-daemon-set-c5e6e334b21d4f47-sjlb6 from heptio-sonobuoy started at 2019-01-09 11:58:13 +0000 UTC (2 container statuses recorded)
Jan  9 11:58:36.136: INFO: 	Container sonobuoy-systemd-logs-config ready: false, restart count 0
Jan  9 11:58:36.136: INFO: 	Container sonobuoy-worker ready: false, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15782c3dd8b9e518], Reason = [FailedScheduling], Message = [0/1 nodes are available: 1 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 11:58:37.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-c7xhp" for this suite.
Jan  9 11:58:43.150: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 11:58:43.172: INFO: namespace: e2e-tests-sched-pred-c7xhp, resource: bindings, ignored listing per whitelist
Jan  9 11:58:43.188: INFO: namespace e2e-tests-sched-pred-c7xhp deletion completed in 6.043154243s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.097 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 11:58:43.188: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan  9 11:58:43.224: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e9405d2b-1405-11e9-a571-02181533b527" in namespace "e2e-tests-downward-api-29jqm" to be "success or failure"
Jan  9 11:58:43.225: INFO: Pod "downwardapi-volume-e9405d2b-1405-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.449738ms
Jan  9 11:58:45.227: INFO: Pod "downwardapi-volume-e9405d2b-1405-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003384513s
Jan  9 11:58:47.229: INFO: Pod "downwardapi-volume-e9405d2b-1405-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005408762s
STEP: Saw pod success
Jan  9 11:58:47.229: INFO: Pod "downwardapi-volume-e9405d2b-1405-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 11:58:47.230: INFO: Trying to get logs from node ip-172-31-59-90 pod downwardapi-volume-e9405d2b-1405-11e9-a571-02181533b527 container client-container: <nil>
STEP: delete the pod
Jan  9 11:58:47.237: INFO: Waiting for pod downwardapi-volume-e9405d2b-1405-11e9-a571-02181533b527 to disappear
Jan  9 11:58:47.238: INFO: Pod downwardapi-volume-e9405d2b-1405-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 11:58:47.238: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-29jqm" for this suite.
Jan  9 11:58:53.246: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 11:58:53.271: INFO: namespace: e2e-tests-downward-api-29jqm, resource: bindings, ignored listing per whitelist
Jan  9 11:58:53.285: INFO: namespace e2e-tests-downward-api-29jqm deletion completed in 6.04580704s

• [SLOW TEST:10.097 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 11:58:53.285: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan  9 11:58:53.321: INFO: (0) /api/v1/nodes/ip-172-31-59-90/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 1.797049ms)
Jan  9 11:58:53.323: INFO: (1) /api/v1/nodes/ip-172-31-59-90/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 1.444081ms)
Jan  9 11:58:53.324: INFO: (2) /api/v1/nodes/ip-172-31-59-90/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 1.395379ms)
Jan  9 11:58:53.326: INFO: (3) /api/v1/nodes/ip-172-31-59-90/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 1.387333ms)
Jan  9 11:58:53.327: INFO: (4) /api/v1/nodes/ip-172-31-59-90/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 1.34525ms)
Jan  9 11:58:53.328: INFO: (5) /api/v1/nodes/ip-172-31-59-90/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 1.416221ms)
Jan  9 11:58:53.330: INFO: (6) /api/v1/nodes/ip-172-31-59-90/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 1.429916ms)
Jan  9 11:58:53.331: INFO: (7) /api/v1/nodes/ip-172-31-59-90/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 1.347169ms)
Jan  9 11:58:53.333: INFO: (8) /api/v1/nodes/ip-172-31-59-90/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 1.340474ms)
Jan  9 11:58:53.334: INFO: (9) /api/v1/nodes/ip-172-31-59-90/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 1.358656ms)
Jan  9 11:58:53.335: INFO: (10) /api/v1/nodes/ip-172-31-59-90/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 1.330072ms)
Jan  9 11:58:53.337: INFO: (11) /api/v1/nodes/ip-172-31-59-90/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 1.797481ms)
Jan  9 11:58:53.339: INFO: (12) /api/v1/nodes/ip-172-31-59-90/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 1.41317ms)
Jan  9 11:58:53.340: INFO: (13) /api/v1/nodes/ip-172-31-59-90/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 1.435691ms)
Jan  9 11:58:53.342: INFO: (14) /api/v1/nodes/ip-172-31-59-90/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 1.413973ms)
Jan  9 11:58:53.343: INFO: (15) /api/v1/nodes/ip-172-31-59-90/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 1.36729ms)
Jan  9 11:58:53.344: INFO: (16) /api/v1/nodes/ip-172-31-59-90/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 1.315494ms)
Jan  9 11:58:53.346: INFO: (17) /api/v1/nodes/ip-172-31-59-90/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 1.437913ms)
Jan  9 11:58:53.347: INFO: (18) /api/v1/nodes/ip-172-31-59-90/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 1.30307ms)
Jan  9 11:58:53.348: INFO: (19) /api/v1/nodes/ip-172-31-59-90/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 1.314893ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 11:58:53.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-qtfdx" for this suite.
Jan  9 11:58:59.356: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 11:58:59.372: INFO: namespace: e2e-tests-proxy-qtfdx, resource: bindings, ignored listing per whitelist
Jan  9 11:58:59.396: INFO: namespace e2e-tests-proxy-qtfdx deletion completed in 6.046215685s

• [SLOW TEST:6.110 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 11:58:59.396: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0109 11:59:29.455042      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan  9 11:59:29.455: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 11:59:29.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-2j26f" for this suite.
Jan  9 11:59:35.460: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 11:59:35.467: INFO: namespace: e2e-tests-gc-2j26f, resource: bindings, ignored listing per whitelist
Jan  9 11:59:35.495: INFO: namespace e2e-tests-gc-2j26f deletion completed in 6.03957536s

• [SLOW TEST:36.100 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 11:59:35.495: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:00:01.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-runtime-hdfz4" for this suite.
Jan  9 12:00:07.622: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:00:07.646: INFO: namespace: e2e-tests-container-runtime-hdfz4, resource: bindings, ignored listing per whitelist
Jan  9 12:00:07.658: INFO: namespace e2e-tests-container-runtime-hdfz4 deletion completed in 6.041643219s

• [SLOW TEST:32.163 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  blackbox test
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:00:07.658: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan  9 12:00:07.692: INFO: (0) /api/v1/nodes/ip-172-31-59-90:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 1.622118ms)
Jan  9 12:00:07.694: INFO: (1) /api/v1/nodes/ip-172-31-59-90:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 1.485173ms)
Jan  9 12:00:07.697: INFO: (2) /api/v1/nodes/ip-172-31-59-90:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.953047ms)
Jan  9 12:00:07.698: INFO: (3) /api/v1/nodes/ip-172-31-59-90:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 1.336964ms)
Jan  9 12:00:07.700: INFO: (4) /api/v1/nodes/ip-172-31-59-90:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 1.398407ms)
Jan  9 12:00:07.701: INFO: (5) /api/v1/nodes/ip-172-31-59-90:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 1.441283ms)
Jan  9 12:00:07.703: INFO: (6) /api/v1/nodes/ip-172-31-59-90:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 1.403098ms)
Jan  9 12:00:07.704: INFO: (7) /api/v1/nodes/ip-172-31-59-90:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 1.397453ms)
Jan  9 12:00:07.705: INFO: (8) /api/v1/nodes/ip-172-31-59-90:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 1.359797ms)
Jan  9 12:00:07.707: INFO: (9) /api/v1/nodes/ip-172-31-59-90:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 1.320376ms)
Jan  9 12:00:07.708: INFO: (10) /api/v1/nodes/ip-172-31-59-90:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 1.619709ms)
Jan  9 12:00:07.710: INFO: (11) /api/v1/nodes/ip-172-31-59-90:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 1.488063ms)
Jan  9 12:00:07.711: INFO: (12) /api/v1/nodes/ip-172-31-59-90:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 1.372175ms)
Jan  9 12:00:07.713: INFO: (13) /api/v1/nodes/ip-172-31-59-90:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 1.322378ms)
Jan  9 12:00:07.714: INFO: (14) /api/v1/nodes/ip-172-31-59-90:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 1.426318ms)
Jan  9 12:00:07.715: INFO: (15) /api/v1/nodes/ip-172-31-59-90:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 1.337599ms)
Jan  9 12:00:07.717: INFO: (16) /api/v1/nodes/ip-172-31-59-90:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 1.330614ms)
Jan  9 12:00:07.718: INFO: (17) /api/v1/nodes/ip-172-31-59-90:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 1.349462ms)
Jan  9 12:00:07.720: INFO: (18) /api/v1/nodes/ip-172-31-59-90:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 1.379997ms)
Jan  9 12:00:07.721: INFO: (19) /api/v1/nodes/ip-172-31-59-90:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 1.355315ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:00:07.721: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-hzstd" for this suite.
Jan  9 12:00:13.726: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:00:13.757: INFO: namespace: e2e-tests-proxy-hzstd, resource: bindings, ignored listing per whitelist
Jan  9 12:00:13.761: INFO: namespace e2e-tests-proxy-hzstd deletion completed in 6.039069238s

• [SLOW TEST:6.103 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:00:13.761: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jan  9 12:00:18.305: INFO: Successfully updated pod "pod-update-1f3c6fd7-1406-11e9-a571-02181533b527"
STEP: verifying the updated pod is in kubernetes
Jan  9 12:00:18.307: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:00:18.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-f4knm" for this suite.
Jan  9 12:00:40.313: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:00:40.318: INFO: namespace: e2e-tests-pods-f4knm, resource: bindings, ignored listing per whitelist
Jan  9 12:00:40.349: INFO: namespace e2e-tests-pods-f4knm deletion completed in 22.040717163s

• [SLOW TEST:26.588 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:00:40.349: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan  9 12:00:40.382: INFO: Pod name rollover-pod: Found 0 pods out of 1
Jan  9 12:00:45.385: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jan  9 12:00:45.385: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Jan  9 12:00:47.386: INFO: Creating deployment "test-rollover-deployment"
Jan  9 12:00:47.389: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Jan  9 12:00:49.392: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Jan  9 12:00:49.395: INFO: Ensure that both replica sets have 1 created replica
Jan  9 12:00:49.397: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Jan  9 12:00:49.400: INFO: Updating deployment test-rollover-deployment
Jan  9 12:00:49.400: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Jan  9 12:00:51.403: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Jan  9 12:00:51.406: INFO: Make sure deployment "test-rollover-deployment" is complete
Jan  9 12:00:51.408: INFO: all replica sets need to contain the pod-template-hash label
Jan  9 12:00:51.408: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682632047, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682632047, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682632049, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682632047, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan  9 12:00:53.412: INFO: all replica sets need to contain the pod-template-hash label
Jan  9 12:00:53.412: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682632047, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682632047, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682632052, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682632047, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan  9 12:00:55.413: INFO: all replica sets need to contain the pod-template-hash label
Jan  9 12:00:55.413: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682632047, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682632047, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682632052, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682632047, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan  9 12:00:57.412: INFO: all replica sets need to contain the pod-template-hash label
Jan  9 12:00:57.412: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682632047, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682632047, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682632052, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682632047, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan  9 12:00:59.412: INFO: all replica sets need to contain the pod-template-hash label
Jan  9 12:00:59.412: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682632047, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682632047, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682632052, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682632047, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan  9 12:01:01.412: INFO: all replica sets need to contain the pod-template-hash label
Jan  9 12:01:01.412: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682632047, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682632047, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682632052, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682632047, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan  9 12:01:03.412: INFO: 
Jan  9 12:01:03.412: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan  9 12:01:03.415: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-mf6b5,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-mf6b5/deployments/test-rollover-deployment,UID:3342a3bc-1406-11e9-90b5-12841864fc48,ResourceVersion:858,Generation:2,CreationTimestamp:2019-01-09 12:00:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-01-09 12:00:47 +0000 UTC 2019-01-09 12:00:47 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-01-09 12:01:02 +0000 UTC 2019-01-09 12:00:47 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-6b7f9d6597" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Jan  9 12:01:03.417: INFO: New ReplicaSet "test-rollover-deployment-6b7f9d6597" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597,GenerateName:,Namespace:e2e-tests-deployment-mf6b5,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-mf6b5/replicasets/test-rollover-deployment-6b7f9d6597,UID:3475de73-1406-11e9-90b5-12841864fc48,ResourceVersion:849,Generation:2,CreationTimestamp:2019-01-09 12:00:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 3342a3bc-1406-11e9-90b5-12841864fc48 0xc001e81087 0xc001e81088}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jan  9 12:01:03.417: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Jan  9 12:01:03.417: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-mf6b5,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-mf6b5/replicasets/test-rollover-controller,UID:2f156b40-1406-11e9-90b5-12841864fc48,ResourceVersion:857,Generation:2,CreationTimestamp:2019-01-09 12:00:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 3342a3bc-1406-11e9-90b5-12841864fc48 0xc001e80eff 0xc001e80f10}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan  9 12:01:03.417: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6586df867b,GenerateName:,Namespace:e2e-tests-deployment-mf6b5,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-mf6b5/replicasets/test-rollover-deployment-6586df867b,UID:334353d5-1406-11e9-90b5-12841864fc48,ResourceVersion:813,Generation:2,CreationTimestamp:2019-01-09 12:00:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 3342a3bc-1406-11e9-90b5-12841864fc48 0xc001e80fc7 0xc001e80fc8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan  9 12:01:03.418: INFO: Pod "test-rollover-deployment-6b7f9d6597-kcdht" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597-kcdht,GenerateName:test-rollover-deployment-6b7f9d6597-,Namespace:e2e-tests-deployment-mf6b5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-mf6b5/pods/test-rollover-deployment-6b7f9d6597-kcdht,UID:34785606-1406-11e9-90b5-12841864fc48,ResourceVersion:834,Generation:0,CreationTimestamp:2019-01-09 12:00:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-6b7f9d6597 3475de73-1406-11e9-90b5-12841864fc48 0xc001e81bb7 0xc001e81bb8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9pclk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9pclk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-9pclk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-59-90,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001e81c30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001e81c50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 12:00:49 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 12:00:52 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 12:00:52 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 12:00:49 +0000 UTC  }],Message:,Reason:,HostIP:172.31.59.90,PodIP:10.1.1.14,StartTime:2019-01-09 12:00:49 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-01-09 12:00:51 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://9fba9b8f65bee9b516bc2788ce4c874a57c3d1c7d5cb734dc61ec20bea93310c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:01:03.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-mf6b5" for this suite.
Jan  9 12:01:09.424: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:01:09.432: INFO: namespace: e2e-tests-deployment-mf6b5, resource: bindings, ignored listing per whitelist
Jan  9 12:01:09.460: INFO: namespace e2e-tests-deployment-mf6b5 deletion completed in 6.04063787s

• [SLOW TEST:29.111 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:01:09.460: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Jan  9 12:01:16.507: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:01:17.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-mtlk6" for this suite.
Jan  9 12:01:39.518: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:01:39.546: INFO: namespace: e2e-tests-replicaset-mtlk6, resource: bindings, ignored listing per whitelist
Jan  9 12:01:39.562: INFO: namespace e2e-tests-replicaset-mtlk6 deletion completed in 22.047933202s

• [SLOW TEST:30.101 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:01:39.562: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-5260ac25-1406-11e9-a571-02181533b527
STEP: Creating a pod to test consume configMaps
Jan  9 12:01:39.599: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-52611dc4-1406-11e9-a571-02181533b527" in namespace "e2e-tests-projected-94hfj" to be "success or failure"
Jan  9 12:01:39.600: INFO: Pod "pod-projected-configmaps-52611dc4-1406-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 996.26µs
Jan  9 12:01:41.602: INFO: Pod "pod-projected-configmaps-52611dc4-1406-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 2.002952648s
Jan  9 12:01:43.604: INFO: Pod "pod-projected-configmaps-52611dc4-1406-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.004901441s
STEP: Saw pod success
Jan  9 12:01:43.604: INFO: Pod "pod-projected-configmaps-52611dc4-1406-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 12:01:43.605: INFO: Trying to get logs from node ip-172-31-59-90 pod pod-projected-configmaps-52611dc4-1406-11e9-a571-02181533b527 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan  9 12:01:43.613: INFO: Waiting for pod pod-projected-configmaps-52611dc4-1406-11e9-a571-02181533b527 to disappear
Jan  9 12:01:43.614: INFO: Pod pod-projected-configmaps-52611dc4-1406-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:01:43.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-94hfj" for this suite.
Jan  9 12:01:49.620: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:01:49.658: INFO: namespace: e2e-tests-projected-94hfj, resource: bindings, ignored listing per whitelist
Jan  9 12:01:49.658: INFO: namespace e2e-tests-projected-94hfj deletion completed in 6.041968055s

• [SLOW TEST:10.096 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:01:49.658: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-4n845
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Jan  9 12:01:49.695: INFO: Found 0 stateful pods, waiting for 3
Jan  9 12:01:59.697: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jan  9 12:01:59.697: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jan  9 12:01:59.697: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Jan  9 12:01:59.714: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Jan  9 12:02:09.734: INFO: Updating stateful set ss2
Jan  9 12:02:09.739: INFO: Waiting for Pod e2e-tests-statefulset-4n845/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Jan  9 12:02:19.743: INFO: Waiting for Pod e2e-tests-statefulset-4n845/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Jan  9 12:02:29.755: INFO: Found 2 stateful pods, waiting for 3
Jan  9 12:02:39.758: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jan  9 12:02:39.758: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jan  9 12:02:39.758: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Jan  9 12:02:39.773: INFO: Updating stateful set ss2
Jan  9 12:02:39.776: INFO: Waiting for Pod e2e-tests-statefulset-4n845/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Jan  9 12:02:49.780: INFO: Waiting for Pod e2e-tests-statefulset-4n845/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Jan  9 12:02:59.794: INFO: Updating stateful set ss2
Jan  9 12:02:59.800: INFO: Waiting for StatefulSet e2e-tests-statefulset-4n845/ss2 to complete update
Jan  9 12:02:59.800: INFO: Waiting for Pod e2e-tests-statefulset-4n845/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Jan  9 12:03:09.804: INFO: Waiting for StatefulSet e2e-tests-statefulset-4n845/ss2 to complete update
Jan  9 12:03:09.804: INFO: Waiting for Pod e2e-tests-statefulset-4n845/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan  9 12:03:19.804: INFO: Deleting all statefulset in ns e2e-tests-statefulset-4n845
Jan  9 12:03:19.805: INFO: Scaling statefulset ss2 to 0
Jan  9 12:03:39.814: INFO: Waiting for statefulset status.replicas updated to 0
Jan  9 12:03:39.815: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:03:39.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-4n845" for this suite.
Jan  9 12:03:45.825: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:03:45.845: INFO: namespace: e2e-tests-statefulset-4n845, resource: bindings, ignored listing per whitelist
Jan  9 12:03:45.861: INFO: namespace e2e-tests-statefulset-4n845 deletion completed in 6.040327376s

• [SLOW TEST:116.203 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:03:45.861: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-9da86225-1406-11e9-a571-02181533b527
STEP: Creating secret with name s-test-opt-upd-9da8626a-1406-11e9-a571-02181533b527
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-9da86225-1406-11e9-a571-02181533b527
STEP: Updating secret s-test-opt-upd-9da8626a-1406-11e9-a571-02181533b527
STEP: Creating secret with name s-test-opt-create-9da86287-1406-11e9-a571-02181533b527
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:03:49.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hq9r5" for this suite.
Jan  9 12:04:11.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:04:11.969: INFO: namespace: e2e-tests-projected-hq9r5, resource: bindings, ignored listing per whitelist
Jan  9 12:04:11.974: INFO: namespace e2e-tests-projected-hq9r5 deletion completed in 22.03896685s

• [SLOW TEST:26.113 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:04:11.974: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-j2b8l
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Jan  9 12:04:12.013: INFO: Found 0 stateful pods, waiting for 3
Jan  9 12:04:22.015: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jan  9 12:04:22.015: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jan  9 12:04:22.015: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Jan  9 12:04:22.019: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 exec --namespace=e2e-tests-statefulset-j2b8l ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan  9 12:04:22.160: INFO: stderr: ""
Jan  9 12:04:22.160: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan  9 12:04:22.160: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Jan  9 12:04:32.181: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Jan  9 12:04:42.190: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 exec --namespace=e2e-tests-statefulset-j2b8l ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  9 12:04:42.318: INFO: stderr: ""
Jan  9 12:04:42.318: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan  9 12:04:42.318: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan  9 12:04:52.327: INFO: Waiting for StatefulSet e2e-tests-statefulset-j2b8l/ss2 to complete update
Jan  9 12:04:52.327: INFO: Waiting for Pod e2e-tests-statefulset-j2b8l/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Jan  9 12:04:52.327: INFO: Waiting for Pod e2e-tests-statefulset-j2b8l/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Jan  9 12:05:02.331: INFO: Waiting for StatefulSet e2e-tests-statefulset-j2b8l/ss2 to complete update
Jan  9 12:05:02.331: INFO: Waiting for Pod e2e-tests-statefulset-j2b8l/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Jan  9 12:05:12.331: INFO: Waiting for StatefulSet e2e-tests-statefulset-j2b8l/ss2 to complete update
STEP: Rolling back to a previous revision
Jan  9 12:05:22.331: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 exec --namespace=e2e-tests-statefulset-j2b8l ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan  9 12:05:22.470: INFO: stderr: ""
Jan  9 12:05:22.470: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan  9 12:05:22.470: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan  9 12:05:32.491: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Jan  9 12:05:42.500: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 exec --namespace=e2e-tests-statefulset-j2b8l ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  9 12:05:42.633: INFO: stderr: ""
Jan  9 12:05:42.633: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan  9 12:05:42.633: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan  9 12:05:52.642: INFO: Waiting for StatefulSet e2e-tests-statefulset-j2b8l/ss2 to complete update
Jan  9 12:05:52.642: INFO: Waiting for Pod e2e-tests-statefulset-j2b8l/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Jan  9 12:05:52.642: INFO: Waiting for Pod e2e-tests-statefulset-j2b8l/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Jan  9 12:06:02.645: INFO: Waiting for StatefulSet e2e-tests-statefulset-j2b8l/ss2 to complete update
Jan  9 12:06:02.645: INFO: Waiting for Pod e2e-tests-statefulset-j2b8l/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan  9 12:06:12.645: INFO: Deleting all statefulset in ns e2e-tests-statefulset-j2b8l
Jan  9 12:06:12.647: INFO: Scaling statefulset ss2 to 0
Jan  9 12:06:32.653: INFO: Waiting for statefulset status.replicas updated to 0
Jan  9 12:06:32.654: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:06:32.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-j2b8l" for this suite.
Jan  9 12:06:38.665: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:06:38.673: INFO: namespace: e2e-tests-statefulset-j2b8l, resource: bindings, ignored listing per whitelist
Jan  9 12:06:38.703: INFO: namespace e2e-tests-statefulset-j2b8l deletion completed in 6.042888533s

• [SLOW TEST:146.729 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:06:38.703: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:06:40.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-vhcs9" for this suite.
Jan  9 12:07:22.753: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:07:22.778: INFO: namespace: e2e-tests-kubelet-test-vhcs9, resource: bindings, ignored listing per whitelist
Jan  9 12:07:22.787: INFO: namespace e2e-tests-kubelet-test-vhcs9 deletion completed in 42.039021167s

• [SLOW TEST:44.084 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:07:22.788: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-wznd8
Jan  9 12:07:26.825: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-wznd8
STEP: checking the pod's current state and verifying that restartCount is present
Jan  9 12:07:26.826: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:11:27.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-wznd8" for this suite.
Jan  9 12:11:33.067: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:11:33.073: INFO: namespace: e2e-tests-container-probe-wznd8, resource: bindings, ignored listing per whitelist
Jan  9 12:11:33.102: INFO: namespace e2e-tests-container-probe-wznd8 deletion completed in 6.040122124s

• [SLOW TEST:250.315 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:11:33.103: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1527
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan  9 12:11:33.135: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-wq6rz'
Jan  9 12:11:33.349: INFO: stderr: ""
Jan  9 12:11:33.349: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1532
Jan  9 12:11:33.350: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-wq6rz'
Jan  9 12:11:40.935: INFO: stderr: ""
Jan  9 12:11:40.935: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:11:40.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wq6rz" for this suite.
Jan  9 12:11:46.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:11:46.961: INFO: namespace: e2e-tests-kubectl-wq6rz, resource: bindings, ignored listing per whitelist
Jan  9 12:11:46.976: INFO: namespace e2e-tests-kubectl-wq6rz deletion completed in 6.039376922s

• [SLOW TEST:13.873 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:11:46.976: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-5b8j8/secret-test-bc6d27db-1407-11e9-a571-02181533b527
STEP: Creating a pod to test consume secrets
Jan  9 12:11:47.014: INFO: Waiting up to 5m0s for pod "pod-configmaps-bc6d6578-1407-11e9-a571-02181533b527" in namespace "e2e-tests-secrets-5b8j8" to be "success or failure"
Jan  9 12:11:47.016: INFO: Pod "pod-configmaps-bc6d6578-1407-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.637307ms
Jan  9 12:11:49.018: INFO: Pod "pod-configmaps-bc6d6578-1407-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003224583s
STEP: Saw pod success
Jan  9 12:11:49.018: INFO: Pod "pod-configmaps-bc6d6578-1407-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 12:11:49.019: INFO: Trying to get logs from node ip-172-31-59-90 pod pod-configmaps-bc6d6578-1407-11e9-a571-02181533b527 container env-test: <nil>
STEP: delete the pod
Jan  9 12:11:49.031: INFO: Waiting for pod pod-configmaps-bc6d6578-1407-11e9-a571-02181533b527 to disappear
Jan  9 12:11:49.032: INFO: Pod pod-configmaps-bc6d6578-1407-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:11:49.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-5b8j8" for this suite.
Jan  9 12:11:55.038: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:11:55.046: INFO: namespace: e2e-tests-secrets-5b8j8, resource: bindings, ignored listing per whitelist
Jan  9 12:11:55.074: INFO: namespace e2e-tests-secrets-5b8j8 deletion completed in 6.04103181s

• [SLOW TEST:8.099 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:11:55.075: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-5tc9m
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-5tc9m to expose endpoints map[]
Jan  9 12:11:55.111: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-5tc9m exposes endpoints map[] (1.634525ms elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-5tc9m
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-5tc9m to expose endpoints map[pod1:[80]]
Jan  9 12:11:57.123: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-5tc9m exposes endpoints map[pod1:[80]] (2.008852371s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-5tc9m
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-5tc9m to expose endpoints map[pod1:[80] pod2:[80]]
Jan  9 12:11:59.136: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-5tc9m exposes endpoints map[pod1:[80] pod2:[80]] (2.01174471s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-5tc9m
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-5tc9m to expose endpoints map[pod2:[80]]
Jan  9 12:12:00.143: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-5tc9m exposes endpoints map[pod2:[80]] (1.005104866s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-5tc9m
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-5tc9m to expose endpoints map[]
Jan  9 12:12:01.148: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-5tc9m exposes endpoints map[] (1.00300543s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:12:01.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-5tc9m" for this suite.
Jan  9 12:12:23.159: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:12:23.179: INFO: namespace: e2e-tests-services-5tc9m, resource: bindings, ignored listing per whitelist
Jan  9 12:12:23.195: INFO: namespace e2e-tests-services-5tc9m deletion completed in 22.041562214s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:28.121 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:12:23.196: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0109 12:12:33.238455      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan  9 12:12:33.238: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:12:33.238: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-pmv4s" for this suite.
Jan  9 12:12:39.244: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:12:39.259: INFO: namespace: e2e-tests-gc-pmv4s, resource: bindings, ignored listing per whitelist
Jan  9 12:12:39.279: INFO: namespace e2e-tests-gc-pmv4s deletion completed in 6.039896184s

• [SLOW TEST:16.084 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:12:39.279: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan  9 12:12:39.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-nmqvp'
Jan  9 12:12:39.381: INFO: stderr: ""
Jan  9 12:12:39.381: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Jan  9 12:12:44.432: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-nmqvp -o json'
Jan  9 12:12:44.492: INFO: stderr: ""
Jan  9 12:12:44.492: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-01-09T12:12:39Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-nmqvp\",\n        \"resourceVersion\": \"2657\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-nmqvp/pods/e2e-test-nginx-pod\",\n        \"uid\": \"dba296c4-1407-11e9-90b5-12841864fc48\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-nrpg6\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-172-31-59-90\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-nrpg6\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-nrpg6\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-01-09T12:12:39Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-01-09T12:12:41Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-01-09T12:12:41Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-01-09T12:12:39Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://f99f6b285f4d8a4290e440627b1c7fa7f6fa4daa8969181148b1217cc266bc6b\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-01-09T12:12:40Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.31.59.90\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.1.1.43\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-01-09T12:12:39Z\"\n    }\n}\n"
STEP: replace the image in the pod
Jan  9 12:12:44.493: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 replace -f - --namespace=e2e-tests-kubectl-nmqvp'
Jan  9 12:12:44.660: INFO: stderr: ""
Jan  9 12:12:44.660: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
Jan  9 12:12:44.663: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-nmqvp'
Jan  9 12:12:50.935: INFO: stderr: ""
Jan  9 12:12:50.935: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:12:50.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-nmqvp" for this suite.
Jan  9 12:12:56.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:12:56.945: INFO: namespace: e2e-tests-kubectl-nmqvp, resource: bindings, ignored listing per whitelist
Jan  9 12:12:56.976: INFO: namespace e2e-tests-kubectl-nmqvp deletion completed in 6.039833264s

• [SLOW TEST:17.697 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:12:56.977: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-k28wq
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan  9 12:12:57.010: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan  9 12:13:15.034: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.1.1.44:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-k28wq PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan  9 12:13:15.034: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
Jan  9 12:13:15.108: INFO: Found all expected endpoints: [netserver-0]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:13:15.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-k28wq" for this suite.
Jan  9 12:13:37.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:13:37.130: INFO: namespace: e2e-tests-pod-network-test-k28wq, resource: bindings, ignored listing per whitelist
Jan  9 12:13:37.155: INFO: namespace e2e-tests-pod-network-test-k28wq deletion completed in 22.045246469s

• [SLOW TEST:40.179 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:13:37.155: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-fe18e0e0-1407-11e9-a571-02181533b527
STEP: Creating a pod to test consume configMaps
Jan  9 12:13:37.192: INFO: Waiting up to 5m0s for pod "pod-configmaps-fe191c7d-1407-11e9-a571-02181533b527" in namespace "e2e-tests-configmap-7xtr6" to be "success or failure"
Jan  9 12:13:37.193: INFO: Pod "pod-configmaps-fe191c7d-1407-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.000247ms
Jan  9 12:13:39.194: INFO: Pod "pod-configmaps-fe191c7d-1407-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 2.002520098s
Jan  9 12:13:41.196: INFO: Pod "pod-configmaps-fe191c7d-1407-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.004086675s
STEP: Saw pod success
Jan  9 12:13:41.196: INFO: Pod "pod-configmaps-fe191c7d-1407-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 12:13:41.197: INFO: Trying to get logs from node ip-172-31-59-90 pod pod-configmaps-fe191c7d-1407-11e9-a571-02181533b527 container configmap-volume-test: <nil>
STEP: delete the pod
Jan  9 12:13:41.204: INFO: Waiting for pod pod-configmaps-fe191c7d-1407-11e9-a571-02181533b527 to disappear
Jan  9 12:13:41.205: INFO: Pod pod-configmaps-fe191c7d-1407-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:13:41.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-7xtr6" for this suite.
Jan  9 12:13:47.212: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:13:47.232: INFO: namespace: e2e-tests-configmap-7xtr6, resource: bindings, ignored listing per whitelist
Jan  9 12:13:47.253: INFO: namespace e2e-tests-configmap-7xtr6 deletion completed in 6.046247922s

• [SLOW TEST:10.097 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:13:47.253: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan  9 12:13:47.287: INFO: Waiting up to 5m0s for pod "downwardapi-volume-041d923b-1408-11e9-a571-02181533b527" in namespace "e2e-tests-projected-kkkhx" to be "success or failure"
Jan  9 12:13:47.289: INFO: Pod "downwardapi-volume-041d923b-1408-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.551605ms
Jan  9 12:13:49.291: INFO: Pod "downwardapi-volume-041d923b-1408-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003456255s
Jan  9 12:13:51.293: INFO: Pod "downwardapi-volume-041d923b-1408-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005228282s
STEP: Saw pod success
Jan  9 12:13:51.293: INFO: Pod "downwardapi-volume-041d923b-1408-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 12:13:51.294: INFO: Trying to get logs from node ip-172-31-59-90 pod downwardapi-volume-041d923b-1408-11e9-a571-02181533b527 container client-container: <nil>
STEP: delete the pod
Jan  9 12:13:51.303: INFO: Waiting for pod downwardapi-volume-041d923b-1408-11e9-a571-02181533b527 to disappear
Jan  9 12:13:51.304: INFO: Pod downwardapi-volume-041d923b-1408-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:13:51.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-kkkhx" for this suite.
Jan  9 12:13:57.309: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:13:57.336: INFO: namespace: e2e-tests-projected-kkkhx, resource: bindings, ignored listing per whitelist
Jan  9 12:13:57.345: INFO: namespace e2e-tests-projected-kkkhx deletion completed in 6.039601112s

• [SLOW TEST:10.092 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:13:57.345: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Jan  9 12:13:57.379: INFO: Waiting up to 5m0s for pod "var-expansion-0a21857c-1408-11e9-a571-02181533b527" in namespace "e2e-tests-var-expansion-sb2sg" to be "success or failure"
Jan  9 12:13:57.380: INFO: Pod "var-expansion-0a21857c-1408-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 988.438µs
Jan  9 12:13:59.382: INFO: Pod "var-expansion-0a21857c-1408-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.002462218s
STEP: Saw pod success
Jan  9 12:13:59.382: INFO: Pod "var-expansion-0a21857c-1408-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 12:13:59.383: INFO: Trying to get logs from node ip-172-31-59-90 pod var-expansion-0a21857c-1408-11e9-a571-02181533b527 container dapi-container: <nil>
STEP: delete the pod
Jan  9 12:13:59.391: INFO: Waiting for pod var-expansion-0a21857c-1408-11e9-a571-02181533b527 to disappear
Jan  9 12:13:59.392: INFO: Pod var-expansion-0a21857c-1408-11e9-a571-02181533b527 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:13:59.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-sb2sg" for this suite.
Jan  9 12:14:05.399: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:14:05.424: INFO: namespace: e2e-tests-var-expansion-sb2sg, resource: bindings, ignored listing per whitelist
Jan  9 12:14:05.436: INFO: namespace e2e-tests-var-expansion-sb2sg deletion completed in 6.040997899s

• [SLOW TEST:8.091 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:14:05.436: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-0ef48519-1408-11e9-a571-02181533b527
STEP: Creating configMap with name cm-test-opt-upd-0ef4855d-1408-11e9-a571-02181533b527
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-0ef48519-1408-11e9-a571-02181533b527
STEP: Updating configmap cm-test-opt-upd-0ef4855d-1408-11e9-a571-02181533b527
STEP: Creating configMap with name cm-test-opt-create-0ef48578-1408-11e9-a571-02181533b527
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:14:09.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8dxqw" for this suite.
Jan  9 12:14:31.517: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:14:31.522: INFO: namespace: e2e-tests-projected-8dxqw, resource: bindings, ignored listing per whitelist
Jan  9 12:14:31.554: INFO: namespace e2e-tests-projected-8dxqw deletion completed in 22.041392971s

• [SLOW TEST:26.119 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:14:31.554: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Jan  9 12:14:31.591: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-clg52,SelfLink:/api/v1/namespaces/e2e-tests-watch-clg52/configmaps/e2e-watch-test-watch-closed,UID:1e85a224-1408-11e9-90b5-12841864fc48,ResourceVersion:2987,Generation:0,CreationTimestamp:2019-01-09 12:14:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan  9 12:14:31.591: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-clg52,SelfLink:/api/v1/namespaces/e2e-tests-watch-clg52/configmaps/e2e-watch-test-watch-closed,UID:1e85a224-1408-11e9-90b5-12841864fc48,ResourceVersion:2988,Generation:0,CreationTimestamp:2019-01-09 12:14:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Jan  9 12:14:31.596: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-clg52,SelfLink:/api/v1/namespaces/e2e-tests-watch-clg52/configmaps/e2e-watch-test-watch-closed,UID:1e85a224-1408-11e9-90b5-12841864fc48,ResourceVersion:2989,Generation:0,CreationTimestamp:2019-01-09 12:14:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan  9 12:14:31.596: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-clg52,SelfLink:/api/v1/namespaces/e2e-tests-watch-clg52/configmaps/e2e-watch-test-watch-closed,UID:1e85a224-1408-11e9-90b5-12841864fc48,ResourceVersion:2990,Generation:0,CreationTimestamp:2019-01-09 12:14:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:14:31.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-clg52" for this suite.
Jan  9 12:14:37.602: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:14:37.615: INFO: namespace: e2e-tests-watch-clg52, resource: bindings, ignored listing per whitelist
Jan  9 12:14:37.638: INFO: namespace e2e-tests-watch-clg52 deletion completed in 6.04005968s

• [SLOW TEST:6.083 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:14:37.638: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Jan  9 12:14:37.675: INFO: Waiting up to 5m0s for pod "pod-2225fd7f-1408-11e9-a571-02181533b527" in namespace "e2e-tests-emptydir-x4x74" to be "success or failure"
Jan  9 12:14:37.678: INFO: Pod "pod-2225fd7f-1408-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 2.719868ms
Jan  9 12:14:39.679: INFO: Pod "pod-2225fd7f-1408-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004446806s
Jan  9 12:14:41.681: INFO: Pod "pod-2225fd7f-1408-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006149099s
STEP: Saw pod success
Jan  9 12:14:41.681: INFO: Pod "pod-2225fd7f-1408-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 12:14:41.682: INFO: Trying to get logs from node ip-172-31-59-90 pod pod-2225fd7f-1408-11e9-a571-02181533b527 container test-container: <nil>
STEP: delete the pod
Jan  9 12:14:41.689: INFO: Waiting for pod pod-2225fd7f-1408-11e9-a571-02181533b527 to disappear
Jan  9 12:14:41.691: INFO: Pod pod-2225fd7f-1408-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:14:41.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-x4x74" for this suite.
Jan  9 12:14:47.697: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:14:47.727: INFO: namespace: e2e-tests-emptydir-x4x74, resource: bindings, ignored listing per whitelist
Jan  9 12:14:47.737: INFO: namespace e2e-tests-emptydir-x4x74 deletion completed in 6.044719541s

• [SLOW TEST:10.099 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:14:47.737: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Jan  9 12:14:47.960: INFO: Pod name wrapped-volume-race-283672f1-1408-11e9-a571-02181533b527: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-283672f1-1408-11e9-a571-02181533b527 in namespace e2e-tests-emptydir-wrapper-chmkc, will wait for the garbage collector to delete the pods
Jan  9 12:15:04.071: INFO: Deleting ReplicationController wrapped-volume-race-283672f1-1408-11e9-a571-02181533b527 took: 2.920974ms
Jan  9 12:15:04.172: INFO: Terminating ReplicationController wrapped-volume-race-283672f1-1408-11e9-a571-02181533b527 pods took: 100.257517ms
STEP: Creating RC which spawns configmap-volume pods
Jan  9 12:15:41.979: INFO: Pod name wrapped-volume-race-4879798d-1408-11e9-a571-02181533b527: Found 0 pods out of 5
Jan  9 12:15:46.983: INFO: Pod name wrapped-volume-race-4879798d-1408-11e9-a571-02181533b527: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-4879798d-1408-11e9-a571-02181533b527 in namespace e2e-tests-emptydir-wrapper-chmkc, will wait for the garbage collector to delete the pods
Jan  9 12:15:59.048: INFO: Deleting ReplicationController wrapped-volume-race-4879798d-1408-11e9-a571-02181533b527 took: 2.902066ms
Jan  9 12:15:59.148: INFO: Terminating ReplicationController wrapped-volume-race-4879798d-1408-11e9-a571-02181533b527 pods took: 100.272177ms
STEP: Creating RC which spawns configmap-volume pods
Jan  9 12:16:33.655: INFO: Pod name wrapped-volume-race-67469ffa-1408-11e9-a571-02181533b527: Found 0 pods out of 5
Jan  9 12:16:38.658: INFO: Pod name wrapped-volume-race-67469ffa-1408-11e9-a571-02181533b527: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-67469ffa-1408-11e9-a571-02181533b527 in namespace e2e-tests-emptydir-wrapper-chmkc, will wait for the garbage collector to delete the pods
Jan  9 12:16:50.721: INFO: Deleting ReplicationController wrapped-volume-race-67469ffa-1408-11e9-a571-02181533b527 took: 2.676044ms
Jan  9 12:16:50.822: INFO: Terminating ReplicationController wrapped-volume-race-67469ffa-1408-11e9-a571-02181533b527 pods took: 100.321815ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:17:32.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-chmkc" for this suite.
Jan  9 12:17:38.175: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:17:38.189: INFO: namespace: e2e-tests-emptydir-wrapper-chmkc, resource: bindings, ignored listing per whitelist
Jan  9 12:17:38.212: INFO: namespace e2e-tests-emptydir-wrapper-chmkc deletion completed in 6.077934687s

• [SLOW TEST:170.475 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:17:38.212: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:18:38.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-wq67k" for this suite.
Jan  9 12:19:00.257: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:19:00.262: INFO: namespace: e2e-tests-container-probe-wq67k, resource: bindings, ignored listing per whitelist
Jan  9 12:19:00.291: INFO: namespace e2e-tests-container-probe-wq67k deletion completed in 22.039676588s

• [SLOW TEST:82.079 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:19:00.291: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-beb3bbfd-1408-11e9-a571-02181533b527
STEP: Creating a pod to test consume configMaps
Jan  9 12:19:00.329: INFO: Waiting up to 5m0s for pod "pod-configmaps-beb3f035-1408-11e9-a571-02181533b527" in namespace "e2e-tests-configmap-mlpth" to be "success or failure"
Jan  9 12:19:00.330: INFO: Pod "pod-configmaps-beb3f035-1408-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.612609ms
Jan  9 12:19:02.332: INFO: Pod "pod-configmaps-beb3f035-1408-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003454453s
STEP: Saw pod success
Jan  9 12:19:02.332: INFO: Pod "pod-configmaps-beb3f035-1408-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 12:19:02.333: INFO: Trying to get logs from node ip-172-31-59-90 pod pod-configmaps-beb3f035-1408-11e9-a571-02181533b527 container configmap-volume-test: <nil>
STEP: delete the pod
Jan  9 12:19:02.340: INFO: Waiting for pod pod-configmaps-beb3f035-1408-11e9-a571-02181533b527 to disappear
Jan  9 12:19:02.341: INFO: Pod pod-configmaps-beb3f035-1408-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:19:02.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-mlpth" for this suite.
Jan  9 12:19:08.348: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:19:08.355: INFO: namespace: e2e-tests-configmap-mlpth, resource: bindings, ignored listing per whitelist
Jan  9 12:19:08.386: INFO: namespace e2e-tests-configmap-mlpth deletion completed in 6.043694809s

• [SLOW TEST:8.095 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:19:08.386: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan  9 12:19:08.417: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-26pk2'
Jan  9 12:19:08.486: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jan  9 12:19:08.486: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Jan  9 12:19:08.493: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-jkm78]
Jan  9 12:19:08.493: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-jkm78" in namespace "e2e-tests-kubectl-26pk2" to be "running and ready"
Jan  9 12:19:08.494: INFO: Pod "e2e-test-nginx-rc-jkm78": Phase="Pending", Reason="", readiness=false. Elapsed: 1.05352ms
Jan  9 12:19:10.496: INFO: Pod "e2e-test-nginx-rc-jkm78": Phase="Running", Reason="", readiness=true. Elapsed: 2.002898839s
Jan  9 12:19:10.496: INFO: Pod "e2e-test-nginx-rc-jkm78" satisfied condition "running and ready"
Jan  9 12:19:10.496: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-jkm78]
Jan  9 12:19:10.496: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-26pk2'
Jan  9 12:19:10.571: INFO: stderr: ""
Jan  9 12:19:10.571: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1303
Jan  9 12:19:10.571: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-26pk2'
Jan  9 12:19:10.636: INFO: stderr: ""
Jan  9 12:19:10.636: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:19:10.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-26pk2" for this suite.
Jan  9 12:19:32.642: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:19:32.656: INFO: namespace: e2e-tests-kubectl-26pk2, resource: bindings, ignored listing per whitelist
Jan  9 12:19:32.681: INFO: namespace e2e-tests-kubectl-26pk2 deletion completed in 22.043839465s

• [SLOW TEST:24.295 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:19:32.681: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-d201b7e6-1408-11e9-a571-02181533b527
STEP: Creating a pod to test consume secrets
Jan  9 12:19:32.717: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d201f20e-1408-11e9-a571-02181533b527" in namespace "e2e-tests-projected-4qvlj" to be "success or failure"
Jan  9 12:19:32.718: INFO: Pod "pod-projected-secrets-d201f20e-1408-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.057447ms
Jan  9 12:19:34.720: INFO: Pod "pod-projected-secrets-d201f20e-1408-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.002951222s
STEP: Saw pod success
Jan  9 12:19:34.720: INFO: Pod "pod-projected-secrets-d201f20e-1408-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 12:19:34.721: INFO: Trying to get logs from node ip-172-31-59-90 pod pod-projected-secrets-d201f20e-1408-11e9-a571-02181533b527 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan  9 12:19:34.733: INFO: Waiting for pod pod-projected-secrets-d201f20e-1408-11e9-a571-02181533b527 to disappear
Jan  9 12:19:34.734: INFO: Pod pod-projected-secrets-d201f20e-1408-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:19:34.734: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4qvlj" for this suite.
Jan  9 12:19:40.741: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:19:40.767: INFO: namespace: e2e-tests-projected-4qvlj, resource: bindings, ignored listing per whitelist
Jan  9 12:19:40.777: INFO: namespace e2e-tests-projected-4qvlj deletion completed in 6.042233267s

• [SLOW TEST:8.096 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:19:40.777: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Jan  9 12:19:44.829: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan  9 12:19:44.831: INFO: Pod pod-with-poststart-exec-hook still exists
Jan  9 12:19:46.831: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan  9 12:19:46.833: INFO: Pod pod-with-poststart-exec-hook still exists
Jan  9 12:19:48.831: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan  9 12:19:48.833: INFO: Pod pod-with-poststart-exec-hook still exists
Jan  9 12:19:50.831: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan  9 12:19:50.833: INFO: Pod pod-with-poststart-exec-hook still exists
Jan  9 12:19:52.831: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan  9 12:19:52.833: INFO: Pod pod-with-poststart-exec-hook still exists
Jan  9 12:19:54.831: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan  9 12:19:54.833: INFO: Pod pod-with-poststart-exec-hook still exists
Jan  9 12:19:56.831: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan  9 12:19:56.833: INFO: Pod pod-with-poststart-exec-hook still exists
Jan  9 12:19:58.831: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan  9 12:19:58.833: INFO: Pod pod-with-poststart-exec-hook still exists
Jan  9 12:20:00.833: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan  9 12:20:00.835: INFO: Pod pod-with-poststart-exec-hook still exists
Jan  9 12:20:02.831: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan  9 12:20:02.833: INFO: Pod pod-with-poststart-exec-hook still exists
Jan  9 12:20:04.831: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan  9 12:20:04.833: INFO: Pod pod-with-poststart-exec-hook still exists
Jan  9 12:20:06.831: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan  9 12:20:06.833: INFO: Pod pod-with-poststart-exec-hook still exists
Jan  9 12:20:08.831: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan  9 12:20:08.833: INFO: Pod pod-with-poststart-exec-hook still exists
Jan  9 12:20:10.831: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan  9 12:20:10.833: INFO: Pod pod-with-poststart-exec-hook still exists
Jan  9 12:20:12.831: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan  9 12:20:12.833: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:20:12.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-jxv7p" for this suite.
Jan  9 12:20:34.839: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:20:34.867: INFO: namespace: e2e-tests-container-lifecycle-hook-jxv7p, resource: bindings, ignored listing per whitelist
Jan  9 12:20:34.876: INFO: namespace e2e-tests-container-lifecycle-hook-jxv7p deletion completed in 22.042493499s

• [SLOW TEST:54.099 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:20:34.877: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan  9 12:20:34.913: INFO: Waiting up to 5m0s for pod "downward-api-f7144c22-1408-11e9-a571-02181533b527" in namespace "e2e-tests-downward-api-tvklb" to be "success or failure"
Jan  9 12:20:34.914: INFO: Pod "downward-api-f7144c22-1408-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.05736ms
Jan  9 12:20:36.916: INFO: Pod "downward-api-f7144c22-1408-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 2.002918019s
Jan  9 12:20:38.917: INFO: Pod "downward-api-f7144c22-1408-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00472152s
STEP: Saw pod success
Jan  9 12:20:38.917: INFO: Pod "downward-api-f7144c22-1408-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 12:20:38.919: INFO: Trying to get logs from node ip-172-31-59-90 pod downward-api-f7144c22-1408-11e9-a571-02181533b527 container dapi-container: <nil>
STEP: delete the pod
Jan  9 12:20:38.928: INFO: Waiting for pod downward-api-f7144c22-1408-11e9-a571-02181533b527 to disappear
Jan  9 12:20:38.929: INFO: Pod downward-api-f7144c22-1408-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:20:38.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-tvklb" for this suite.
Jan  9 12:20:44.934: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:20:44.940: INFO: namespace: e2e-tests-downward-api-tvklb, resource: bindings, ignored listing per whitelist
Jan  9 12:20:44.971: INFO: namespace e2e-tests-downward-api-tvklb deletion completed in 6.041361788s

• [SLOW TEST:10.095 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:20:44.971: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-tzhq2 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-tzhq2;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-tzhq2 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-tzhq2;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-tzhq2.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-tzhq2.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-tzhq2.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-tzhq2.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-tzhq2.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-tzhq2.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-tzhq2.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-tzhq2.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-tzhq2.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-tzhq2.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-tzhq2.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-tzhq2.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-tzhq2.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 35.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.35_udp@PTR;check="$$(dig +tcp +noall +answer +search 35.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.35_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-tzhq2 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-tzhq2;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-tzhq2 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-tzhq2;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-tzhq2.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-tzhq2.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-tzhq2.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-tzhq2.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-tzhq2.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-tzhq2.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-tzhq2.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-tzhq2.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-tzhq2.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-tzhq2.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-tzhq2.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-tzhq2.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-tzhq2.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 35.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.35_udp@PTR;check="$$(dig +tcp +noall +answer +search 35.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.35_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jan  9 12:20:55.018: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-tzhq2/dns-test-fd18d0a8-1408-11e9-a571-02181533b527: the server could not find the requested resource (get pods dns-test-fd18d0a8-1408-11e9-a571-02181533b527)
Jan  9 12:20:55.020: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-tzhq2/dns-test-fd18d0a8-1408-11e9-a571-02181533b527: the server could not find the requested resource (get pods dns-test-fd18d0a8-1408-11e9-a571-02181533b527)
Jan  9 12:20:55.021: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-tzhq2 from pod e2e-tests-dns-tzhq2/dns-test-fd18d0a8-1408-11e9-a571-02181533b527: the server could not find the requested resource (get pods dns-test-fd18d0a8-1408-11e9-a571-02181533b527)
Jan  9 12:20:55.022: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-tzhq2 from pod e2e-tests-dns-tzhq2/dns-test-fd18d0a8-1408-11e9-a571-02181533b527: the server could not find the requested resource (get pods dns-test-fd18d0a8-1408-11e9-a571-02181533b527)
Jan  9 12:20:55.024: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-tzhq2.svc from pod e2e-tests-dns-tzhq2/dns-test-fd18d0a8-1408-11e9-a571-02181533b527: the server could not find the requested resource (get pods dns-test-fd18d0a8-1408-11e9-a571-02181533b527)
Jan  9 12:20:55.025: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-tzhq2.svc from pod e2e-tests-dns-tzhq2/dns-test-fd18d0a8-1408-11e9-a571-02181533b527: the server could not find the requested resource (get pods dns-test-fd18d0a8-1408-11e9-a571-02181533b527)
Jan  9 12:20:55.026: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-tzhq2.svc from pod e2e-tests-dns-tzhq2/dns-test-fd18d0a8-1408-11e9-a571-02181533b527: the server could not find the requested resource (get pods dns-test-fd18d0a8-1408-11e9-a571-02181533b527)
Jan  9 12:20:55.027: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-tzhq2.svc from pod e2e-tests-dns-tzhq2/dns-test-fd18d0a8-1408-11e9-a571-02181533b527: the server could not find the requested resource (get pods dns-test-fd18d0a8-1408-11e9-a571-02181533b527)
Jan  9 12:20:55.037: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-tzhq2/dns-test-fd18d0a8-1408-11e9-a571-02181533b527: the server could not find the requested resource (get pods dns-test-fd18d0a8-1408-11e9-a571-02181533b527)
Jan  9 12:20:55.039: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-tzhq2/dns-test-fd18d0a8-1408-11e9-a571-02181533b527: the server could not find the requested resource (get pods dns-test-fd18d0a8-1408-11e9-a571-02181533b527)
Jan  9 12:20:55.040: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-tzhq2 from pod e2e-tests-dns-tzhq2/dns-test-fd18d0a8-1408-11e9-a571-02181533b527: the server could not find the requested resource (get pods dns-test-fd18d0a8-1408-11e9-a571-02181533b527)
Jan  9 12:20:55.041: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-tzhq2 from pod e2e-tests-dns-tzhq2/dns-test-fd18d0a8-1408-11e9-a571-02181533b527: the server could not find the requested resource (get pods dns-test-fd18d0a8-1408-11e9-a571-02181533b527)
Jan  9 12:20:55.042: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-tzhq2.svc from pod e2e-tests-dns-tzhq2/dns-test-fd18d0a8-1408-11e9-a571-02181533b527: the server could not find the requested resource (get pods dns-test-fd18d0a8-1408-11e9-a571-02181533b527)
Jan  9 12:20:55.055: INFO: Lookups using e2e-tests-dns-tzhq2/dns-test-fd18d0a8-1408-11e9-a571-02181533b527 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-tzhq2 wheezy_tcp@dns-test-service.e2e-tests-dns-tzhq2 wheezy_udp@dns-test-service.e2e-tests-dns-tzhq2.svc wheezy_tcp@dns-test-service.e2e-tests-dns-tzhq2.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-tzhq2.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-tzhq2.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-tzhq2 jessie_tcp@dns-test-service.e2e-tests-dns-tzhq2 jessie_udp@dns-test-service.e2e-tests-dns-tzhq2.svc]

Jan  9 12:21:00.099: INFO: DNS probes using e2e-tests-dns-tzhq2/dns-test-fd18d0a8-1408-11e9-a571-02181533b527 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:21:00.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-tzhq2" for this suite.
Jan  9 12:21:06.125: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:21:06.129: INFO: namespace: e2e-tests-dns-tzhq2, resource: bindings, ignored listing per whitelist
Jan  9 12:21:06.162: INFO: namespace e2e-tests-dns-tzhq2 deletion completed in 6.040755556s

• [SLOW TEST:21.191 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:21:06.162: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-09b9c304-1409-11e9-a571-02181533b527
STEP: Creating a pod to test consume secrets
Jan  9 12:21:06.197: INFO: Waiting up to 5m0s for pod "pod-secrets-09b9f976-1409-11e9-a571-02181533b527" in namespace "e2e-tests-secrets-tjjkr" to be "success or failure"
Jan  9 12:21:06.199: INFO: Pod "pod-secrets-09b9f976-1409-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.716394ms
Jan  9 12:21:08.201: INFO: Pod "pod-secrets-09b9f976-1409-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003374161s
STEP: Saw pod success
Jan  9 12:21:08.201: INFO: Pod "pod-secrets-09b9f976-1409-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 12:21:08.202: INFO: Trying to get logs from node ip-172-31-59-90 pod pod-secrets-09b9f976-1409-11e9-a571-02181533b527 container secret-volume-test: <nil>
STEP: delete the pod
Jan  9 12:21:08.209: INFO: Waiting for pod pod-secrets-09b9f976-1409-11e9-a571-02181533b527 to disappear
Jan  9 12:21:08.211: INFO: Pod pod-secrets-09b9f976-1409-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:21:08.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-tjjkr" for this suite.
Jan  9 12:21:14.216: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:21:14.244: INFO: namespace: e2e-tests-secrets-tjjkr, resource: bindings, ignored listing per whitelist
Jan  9 12:21:14.253: INFO: namespace e2e-tests-secrets-tjjkr deletion completed in 6.040880965s

• [SLOW TEST:8.091 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:21:14.253: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-tkkxw
Jan  9 12:21:18.290: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-tkkxw
STEP: checking the pod's current state and verifying that restartCount is present
Jan  9 12:21:18.291: INFO: Initial restart count of pod liveness-http is 0
Jan  9 12:21:42.314: INFO: Restart count of pod e2e-tests-container-probe-tkkxw/liveness-http is now 1 (24.023410354s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:21:42.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-tkkxw" for this suite.
Jan  9 12:21:48.323: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:21:48.327: INFO: namespace: e2e-tests-container-probe-tkkxw, resource: bindings, ignored listing per whitelist
Jan  9 12:21:48.361: INFO: namespace e2e-tests-container-probe-tkkxw deletion completed in 6.041971877s

• [SLOW TEST:34.107 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:21:48.362: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan  9 12:21:48.393: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-b55r5'
Jan  9 12:21:48.618: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jan  9 12:21:48.618: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1404
Jan  9 12:21:50.621: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-b55r5'
Jan  9 12:21:50.688: INFO: stderr: ""
Jan  9 12:21:50.688: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:21:50.688: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-b55r5" for this suite.
Jan  9 12:23:50.694: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:23:50.704: INFO: namespace: e2e-tests-kubectl-b55r5, resource: bindings, ignored listing per whitelist
Jan  9 12:23:50.731: INFO: namespace e2e-tests-kubectl-b55r5 deletion completed in 2m0.041723153s

• [SLOW TEST:122.370 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:23:50.731: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jan  9 12:23:50.771: INFO: Number of nodes with available pods: 0
Jan  9 12:23:50.771: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:23:51.774: INFO: Number of nodes with available pods: 0
Jan  9 12:23:51.774: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:23:52.774: INFO: Number of nodes with available pods: 0
Jan  9 12:23:52.775: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:23:53.774: INFO: Number of nodes with available pods: 1
Jan  9 12:23:53.774: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Stop a daemon pod, check that the daemon pod is revived.
Jan  9 12:23:53.780: INFO: Number of nodes with available pods: 0
Jan  9 12:23:53.780: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:23:54.783: INFO: Number of nodes with available pods: 0
Jan  9 12:23:54.783: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:23:55.783: INFO: Number of nodes with available pods: 0
Jan  9 12:23:55.783: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:23:56.783: INFO: Number of nodes with available pods: 0
Jan  9 12:23:56.783: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:23:57.783: INFO: Number of nodes with available pods: 0
Jan  9 12:23:57.783: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:23:58.783: INFO: Number of nodes with available pods: 0
Jan  9 12:23:58.783: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:23:59.784: INFO: Number of nodes with available pods: 0
Jan  9 12:23:59.784: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:24:00.783: INFO: Number of nodes with available pods: 0
Jan  9 12:24:00.783: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:24:01.783: INFO: Number of nodes with available pods: 0
Jan  9 12:24:01.783: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:24:02.783: INFO: Number of nodes with available pods: 0
Jan  9 12:24:02.783: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:24:03.783: INFO: Number of nodes with available pods: 0
Jan  9 12:24:03.783: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:24:04.783: INFO: Number of nodes with available pods: 0
Jan  9 12:24:04.783: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:24:05.783: INFO: Number of nodes with available pods: 0
Jan  9 12:24:05.783: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:24:06.783: INFO: Number of nodes with available pods: 0
Jan  9 12:24:06.783: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:24:07.783: INFO: Number of nodes with available pods: 0
Jan  9 12:24:07.783: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:24:08.783: INFO: Number of nodes with available pods: 0
Jan  9 12:24:08.783: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:24:09.783: INFO: Number of nodes with available pods: 0
Jan  9 12:24:09.783: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:24:10.783: INFO: Number of nodes with available pods: 0
Jan  9 12:24:10.784: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:24:11.783: INFO: Number of nodes with available pods: 0
Jan  9 12:24:11.783: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:24:12.783: INFO: Number of nodes with available pods: 0
Jan  9 12:24:12.783: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:24:13.783: INFO: Number of nodes with available pods: 0
Jan  9 12:24:13.783: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:24:14.783: INFO: Number of nodes with available pods: 0
Jan  9 12:24:14.783: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:24:15.784: INFO: Number of nodes with available pods: 0
Jan  9 12:24:15.784: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:24:16.783: INFO: Number of nodes with available pods: 0
Jan  9 12:24:16.783: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:24:17.783: INFO: Number of nodes with available pods: 0
Jan  9 12:24:17.783: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:24:18.783: INFO: Number of nodes with available pods: 0
Jan  9 12:24:18.783: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:24:19.783: INFO: Number of nodes with available pods: 0
Jan  9 12:24:19.784: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:24:20.783: INFO: Number of nodes with available pods: 0
Jan  9 12:24:20.783: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:24:21.783: INFO: Number of nodes with available pods: 0
Jan  9 12:24:21.783: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:24:22.783: INFO: Number of nodes with available pods: 0
Jan  9 12:24:22.783: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:24:23.783: INFO: Number of nodes with available pods: 0
Jan  9 12:24:23.783: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:24:24.783: INFO: Number of nodes with available pods: 0
Jan  9 12:24:24.783: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:24:25.783: INFO: Number of nodes with available pods: 0
Jan  9 12:24:25.783: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:24:26.783: INFO: Number of nodes with available pods: 0
Jan  9 12:24:26.783: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:24:27.783: INFO: Number of nodes with available pods: 0
Jan  9 12:24:27.783: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:24:28.783: INFO: Number of nodes with available pods: 0
Jan  9 12:24:28.783: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:24:29.783: INFO: Number of nodes with available pods: 0
Jan  9 12:24:29.783: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:24:30.783: INFO: Number of nodes with available pods: 0
Jan  9 12:24:30.783: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:24:31.783: INFO: Number of nodes with available pods: 0
Jan  9 12:24:31.783: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:24:32.783: INFO: Number of nodes with available pods: 0
Jan  9 12:24:32.783: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:24:33.783: INFO: Number of nodes with available pods: 1
Jan  9 12:24:33.783: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-ls2zk, will wait for the garbage collector to delete the pods
Jan  9 12:24:33.838: INFO: Deleting DaemonSet.extensions daemon-set took: 2.413821ms
Jan  9 12:24:33.938: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.229919ms
Jan  9 12:25:07.240: INFO: Number of nodes with available pods: 0
Jan  9 12:25:07.240: INFO: Number of running nodes: 0, number of available pods: 0
Jan  9 12:25:07.242: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-ls2zk/daemonsets","resourceVersion":"5011"},"items":null}

Jan  9 12:25:07.243: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-ls2zk/pods","resourceVersion":"5011"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:25:07.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-ls2zk" for this suite.
Jan  9 12:25:13.252: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:25:13.280: INFO: namespace: e2e-tests-daemonsets-ls2zk, resource: bindings, ignored listing per whitelist
Jan  9 12:25:13.287: INFO: namespace e2e-tests-daemonsets-ls2zk deletion completed in 6.04037395s

• [SLOW TEST:82.556 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:25:13.287: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-9d061560-1409-11e9-a571-02181533b527
STEP: Creating a pod to test consume configMaps
Jan  9 12:25:13.323: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9d064aad-1409-11e9-a571-02181533b527" in namespace "e2e-tests-projected-rf8zf" to be "success or failure"
Jan  9 12:25:13.324: INFO: Pod "pod-projected-configmaps-9d064aad-1409-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.758551ms
Jan  9 12:25:15.326: INFO: Pod "pod-projected-configmaps-9d064aad-1409-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003487862s
STEP: Saw pod success
Jan  9 12:25:15.326: INFO: Pod "pod-projected-configmaps-9d064aad-1409-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 12:25:15.327: INFO: Trying to get logs from node ip-172-31-59-90 pod pod-projected-configmaps-9d064aad-1409-11e9-a571-02181533b527 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan  9 12:25:15.336: INFO: Waiting for pod pod-projected-configmaps-9d064aad-1409-11e9-a571-02181533b527 to disappear
Jan  9 12:25:15.337: INFO: Pod pod-projected-configmaps-9d064aad-1409-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:25:15.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rf8zf" for this suite.
Jan  9 12:25:21.343: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:25:21.370: INFO: namespace: e2e-tests-projected-rf8zf, resource: bindings, ignored listing per whitelist
Jan  9 12:25:21.381: INFO: namespace e2e-tests-projected-rf8zf deletion completed in 6.042182355s

• [SLOW TEST:8.094 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:25:21.381: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jan  9 12:25:21.415: INFO: Waiting up to 5m0s for pod "pod-a1d9180e-1409-11e9-a571-02181533b527" in namespace "e2e-tests-emptydir-klkms" to be "success or failure"
Jan  9 12:25:21.416: INFO: Pod "pod-a1d9180e-1409-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 993.178µs
Jan  9 12:25:23.418: INFO: Pod "pod-a1d9180e-1409-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.002731482s
STEP: Saw pod success
Jan  9 12:25:23.418: INFO: Pod "pod-a1d9180e-1409-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 12:25:23.419: INFO: Trying to get logs from node ip-172-31-59-90 pod pod-a1d9180e-1409-11e9-a571-02181533b527 container test-container: <nil>
STEP: delete the pod
Jan  9 12:25:23.427: INFO: Waiting for pod pod-a1d9180e-1409-11e9-a571-02181533b527 to disappear
Jan  9 12:25:23.429: INFO: Pod pod-a1d9180e-1409-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:25:23.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-klkms" for this suite.
Jan  9 12:25:29.435: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:25:29.462: INFO: namespace: e2e-tests-emptydir-klkms, resource: bindings, ignored listing per whitelist
Jan  9 12:25:29.470: INFO: namespace e2e-tests-emptydir-klkms deletion completed in 6.039495146s

• [SLOW TEST:8.089 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:25:29.470: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Jan  9 12:25:29.504: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-580595478 proxy --unix-socket=/tmp/kubectl-proxy-unix189715837/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:25:29.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hsfsp" for this suite.
Jan  9 12:25:35.559: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:25:35.569: INFO: namespace: e2e-tests-kubectl-hsfsp, resource: bindings, ignored listing per whitelist
Jan  9 12:25:35.594: INFO: namespace e2e-tests-kubectl-hsfsp deletion completed in 6.039298514s

• [SLOW TEST:6.124 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:25:35.594: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jan  9 12:25:35.627: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:25:39.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-nltcz" for this suite.
Jan  9 12:25:45.612: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:25:45.632: INFO: namespace: e2e-tests-init-container-nltcz, resource: bindings, ignored listing per whitelist
Jan  9 12:25:45.653: INFO: namespace e2e-tests-init-container-nltcz deletion completed in 6.045674253s

• [SLOW TEST:10.059 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:25:45.653: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-qczfj
Jan  9 12:25:47.690: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-qczfj
STEP: checking the pod's current state and verifying that restartCount is present
Jan  9 12:25:47.692: INFO: Initial restart count of pod liveness-http is 0
Jan  9 12:26:05.709: INFO: Restart count of pod e2e-tests-container-probe-qczfj/liveness-http is now 1 (18.016984274s elapsed)
Jan  9 12:26:25.726: INFO: Restart count of pod e2e-tests-container-probe-qczfj/liveness-http is now 2 (38.034318846s elapsed)
Jan  9 12:26:45.743: INFO: Restart count of pod e2e-tests-container-probe-qczfj/liveness-http is now 3 (58.051879031s elapsed)
Jan  9 12:27:05.761: INFO: Restart count of pod e2e-tests-container-probe-qczfj/liveness-http is now 4 (1m18.069541056s elapsed)
Jan  9 12:28:15.828: INFO: Restart count of pod e2e-tests-container-probe-qczfj/liveness-http is now 5 (2m28.136482433s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:28:15.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-qczfj" for this suite.
Jan  9 12:28:21.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:28:21.867: INFO: namespace: e2e-tests-container-probe-qczfj, resource: bindings, ignored listing per whitelist
Jan  9 12:28:21.873: INFO: namespace e2e-tests-container-probe-qczfj deletion completed in 6.040929863s

• [SLOW TEST:156.220 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:28:21.873: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Jan  9 12:28:25.922: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan  9 12:28:25.924: INFO: Pod pod-with-poststart-http-hook still exists
Jan  9 12:28:27.925: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan  9 12:28:27.926: INFO: Pod pod-with-poststart-http-hook still exists
Jan  9 12:28:29.925: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan  9 12:28:29.926: INFO: Pod pod-with-poststart-http-hook still exists
Jan  9 12:28:31.925: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan  9 12:28:31.927: INFO: Pod pod-with-poststart-http-hook still exists
Jan  9 12:28:33.925: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan  9 12:28:33.926: INFO: Pod pod-with-poststart-http-hook still exists
Jan  9 12:28:35.925: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan  9 12:28:35.927: INFO: Pod pod-with-poststart-http-hook still exists
Jan  9 12:28:37.925: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan  9 12:28:37.927: INFO: Pod pod-with-poststart-http-hook still exists
Jan  9 12:28:39.925: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan  9 12:28:39.927: INFO: Pod pod-with-poststart-http-hook still exists
Jan  9 12:28:41.925: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan  9 12:28:41.926: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:28:41.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-77qbs" for this suite.
Jan  9 12:29:03.932: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:29:03.937: INFO: namespace: e2e-tests-container-lifecycle-hook-77qbs, resource: bindings, ignored listing per whitelist
Jan  9 12:29:03.971: INFO: namespace e2e-tests-container-lifecycle-hook-77qbs deletion completed in 22.043413376s

• [SLOW TEST:42.098 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:29:03.971: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Jan  9 12:29:04.512: INFO: created pod pod-service-account-defaultsa
Jan  9 12:29:04.512: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Jan  9 12:29:04.514: INFO: created pod pod-service-account-mountsa
Jan  9 12:29:04.514: INFO: pod pod-service-account-mountsa service account token volume mount: true
Jan  9 12:29:04.518: INFO: created pod pod-service-account-nomountsa
Jan  9 12:29:04.518: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Jan  9 12:29:04.520: INFO: created pod pod-service-account-defaultsa-mountspec
Jan  9 12:29:04.520: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Jan  9 12:29:04.523: INFO: created pod pod-service-account-mountsa-mountspec
Jan  9 12:29:04.523: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Jan  9 12:29:04.526: INFO: created pod pod-service-account-nomountsa-mountspec
Jan  9 12:29:04.526: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Jan  9 12:29:04.529: INFO: created pod pod-service-account-defaultsa-nomountspec
Jan  9 12:29:04.529: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Jan  9 12:29:04.535: INFO: created pod pod-service-account-mountsa-nomountspec
Jan  9 12:29:04.535: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Jan  9 12:29:04.538: INFO: created pod pod-service-account-nomountsa-nomountspec
Jan  9 12:29:04.538: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:29:04.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-xrlfw" for this suite.
Jan  9 12:29:26.551: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:29:26.586: INFO: namespace: e2e-tests-svcaccounts-xrlfw, resource: bindings, ignored listing per whitelist
Jan  9 12:29:26.588: INFO: namespace e2e-tests-svcaccounts-xrlfw deletion completed in 22.048248052s

• [SLOW TEST:22.617 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:29:26.588: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-8blcl.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-8blcl.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-8blcl.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-8blcl.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-8blcl.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-8blcl.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jan  9 12:29:30.654: INFO: DNS probes using e2e-tests-dns-8blcl/dns-test-340087b0-140a-11e9-a571-02181533b527 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:29:30.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-8blcl" for this suite.
Jan  9 12:29:36.665: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:29:36.682: INFO: namespace: e2e-tests-dns-8blcl, resource: bindings, ignored listing per whitelist
Jan  9 12:29:36.702: INFO: namespace e2e-tests-dns-8blcl deletion completed in 6.041541901s

• [SLOW TEST:10.114 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:29:36.702: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-zj54j
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan  9 12:29:36.736: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan  9 12:29:56.756: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.1.1.95 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-zj54j PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan  9 12:29:56.756: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
Jan  9 12:29:57.826: INFO: Found all expected endpoints: [netserver-0]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:29:57.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-zj54j" for this suite.
Jan  9 12:30:19.832: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:30:19.847: INFO: namespace: e2e-tests-pod-network-test-zj54j, resource: bindings, ignored listing per whitelist
Jan  9 12:30:19.870: INFO: namespace e2e-tests-pod-network-test-zj54j deletion completed in 22.041832454s

• [SLOW TEST:43.167 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:30:19.870: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan  9 12:30:19.911: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"53c3bbfa-140a-11e9-90b5-12841864fc48", Controller:(*bool)(0xc001a02402), BlockOwnerDeletion:(*bool)(0xc001a02403)}}
Jan  9 12:30:19.913: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"53c31c2b-140a-11e9-90b5-12841864fc48", Controller:(*bool)(0xc0014c5af6), BlockOwnerDeletion:(*bool)(0xc0014c5af7)}}
Jan  9 12:30:19.916: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"53c369ed-140a-11e9-90b5-12841864fc48", Controller:(*bool)(0xc001bb68f6), BlockOwnerDeletion:(*bool)(0xc001bb68f7)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:30:24.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-9tzk8" for this suite.
Jan  9 12:30:30.929: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:30:30.958: INFO: namespace: e2e-tests-gc-9tzk8, resource: bindings, ignored listing per whitelist
Jan  9 12:30:30.964: INFO: namespace e2e-tests-gc-9tzk8 deletion completed in 6.039368383s

• [SLOW TEST:11.094 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:30:30.964: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan  9 12:30:30.997: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5a5f9cfb-140a-11e9-a571-02181533b527" in namespace "e2e-tests-projected-ngl96" to be "success or failure"
Jan  9 12:30:30.999: INFO: Pod "downwardapi-volume-5a5f9cfb-140a-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.752229ms
Jan  9 12:30:33.001: INFO: Pod "downwardapi-volume-5a5f9cfb-140a-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003509855s
STEP: Saw pod success
Jan  9 12:30:33.001: INFO: Pod "downwardapi-volume-5a5f9cfb-140a-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 12:30:33.002: INFO: Trying to get logs from node ip-172-31-59-90 pod downwardapi-volume-5a5f9cfb-140a-11e9-a571-02181533b527 container client-container: <nil>
STEP: delete the pod
Jan  9 12:30:33.013: INFO: Waiting for pod downwardapi-volume-5a5f9cfb-140a-11e9-a571-02181533b527 to disappear
Jan  9 12:30:33.014: INFO: Pod downwardapi-volume-5a5f9cfb-140a-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:30:33.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ngl96" for this suite.
Jan  9 12:30:39.020: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:30:39.049: INFO: namespace: e2e-tests-projected-ngl96, resource: bindings, ignored listing per whitelist
Jan  9 12:30:39.058: INFO: namespace e2e-tests-projected-ngl96 deletion completed in 6.042847831s

• [SLOW TEST:8.094 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:30:39.059: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jan  9 12:30:39.093: INFO: Waiting up to 5m0s for pod "pod-5f32d42b-140a-11e9-a571-02181533b527" in namespace "e2e-tests-emptydir-9wrp5" to be "success or failure"
Jan  9 12:30:39.094: INFO: Pod "pod-5f32d42b-140a-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.0617ms
Jan  9 12:30:41.096: INFO: Pod "pod-5f32d42b-140a-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.002909521s
STEP: Saw pod success
Jan  9 12:30:41.096: INFO: Pod "pod-5f32d42b-140a-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 12:30:41.097: INFO: Trying to get logs from node ip-172-31-59-90 pod pod-5f32d42b-140a-11e9-a571-02181533b527 container test-container: <nil>
STEP: delete the pod
Jan  9 12:30:41.105: INFO: Waiting for pod pod-5f32d42b-140a-11e9-a571-02181533b527 to disappear
Jan  9 12:30:41.106: INFO: Pod pod-5f32d42b-140a-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:30:41.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-9wrp5" for this suite.
Jan  9 12:30:47.112: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:30:47.126: INFO: namespace: e2e-tests-emptydir-9wrp5, resource: bindings, ignored listing per whitelist
Jan  9 12:30:47.148: INFO: namespace e2e-tests-emptydir-9wrp5 deletion completed in 6.040443602s

• [SLOW TEST:8.090 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:30:47.148: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Jan  9 12:30:47.183: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-580595478 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:30:47.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2fln6" for this suite.
Jan  9 12:30:53.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:30:53.267: INFO: namespace: e2e-tests-kubectl-2fln6, resource: bindings, ignored listing per whitelist
Jan  9 12:30:53.278: INFO: namespace e2e-tests-kubectl-2fln6 deletion completed in 6.04021129s

• [SLOW TEST:6.130 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:30:53.278: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jan  9 12:30:55.879: INFO: Successfully updated pod "annotationupdate67b4beec-140a-11e9-a571-02181533b527"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:30:57.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-tgvlk" for this suite.
Jan  9 12:31:17.895: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:31:17.902: INFO: namespace: e2e-tests-projected-tgvlk, resource: bindings, ignored listing per whitelist
Jan  9 12:31:17.936: INFO: namespace e2e-tests-projected-tgvlk deletion completed in 20.046190626s

• [SLOW TEST:24.657 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:31:17.936: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Jan  9 12:31:17.967: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 create -f - --namespace=e2e-tests-kubectl-b7b8b'
Jan  9 12:31:18.099: INFO: stderr: ""
Jan  9 12:31:18.099: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan  9 12:31:18.099: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-b7b8b'
Jan  9 12:31:18.163: INFO: stderr: ""
Jan  9 12:31:18.163: INFO: stdout: "update-demo-nautilus-89xrl update-demo-nautilus-tb7fc "
Jan  9 12:31:18.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 get pods update-demo-nautilus-89xrl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-b7b8b'
Jan  9 12:31:18.222: INFO: stderr: ""
Jan  9 12:31:18.222: INFO: stdout: ""
Jan  9 12:31:18.222: INFO: update-demo-nautilus-89xrl is created but not running
Jan  9 12:31:23.222: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-b7b8b'
Jan  9 12:31:23.287: INFO: stderr: ""
Jan  9 12:31:23.287: INFO: stdout: "update-demo-nautilus-89xrl update-demo-nautilus-tb7fc "
Jan  9 12:31:23.287: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 get pods update-demo-nautilus-89xrl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-b7b8b'
Jan  9 12:31:23.347: INFO: stderr: ""
Jan  9 12:31:23.347: INFO: stdout: "true"
Jan  9 12:31:23.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 get pods update-demo-nautilus-89xrl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-b7b8b'
Jan  9 12:31:23.407: INFO: stderr: ""
Jan  9 12:31:23.407: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan  9 12:31:23.407: INFO: validating pod update-demo-nautilus-89xrl
Jan  9 12:31:23.409: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan  9 12:31:23.409: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan  9 12:31:23.409: INFO: update-demo-nautilus-89xrl is verified up and running
Jan  9 12:31:23.409: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 get pods update-demo-nautilus-tb7fc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-b7b8b'
Jan  9 12:31:23.469: INFO: stderr: ""
Jan  9 12:31:23.469: INFO: stdout: "true"
Jan  9 12:31:23.469: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 get pods update-demo-nautilus-tb7fc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-b7b8b'
Jan  9 12:31:23.527: INFO: stderr: ""
Jan  9 12:31:23.527: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan  9 12:31:23.527: INFO: validating pod update-demo-nautilus-tb7fc
Jan  9 12:31:23.529: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan  9 12:31:23.529: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan  9 12:31:23.529: INFO: update-demo-nautilus-tb7fc is verified up and running
STEP: scaling down the replication controller
Jan  9 12:31:23.530: INFO: scanned /root for discovery docs: <nil>
Jan  9 12:31:23.530: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-b7b8b'
Jan  9 12:31:24.607: INFO: stderr: ""
Jan  9 12:31:24.607: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan  9 12:31:24.607: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-b7b8b'
Jan  9 12:31:24.669: INFO: stderr: ""
Jan  9 12:31:24.669: INFO: stdout: "update-demo-nautilus-89xrl update-demo-nautilus-tb7fc "
STEP: Replicas for name=update-demo: expected=1 actual=2
Jan  9 12:31:29.669: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-b7b8b'
Jan  9 12:31:29.731: INFO: stderr: ""
Jan  9 12:31:29.731: INFO: stdout: "update-demo-nautilus-89xrl "
Jan  9 12:31:29.731: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 get pods update-demo-nautilus-89xrl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-b7b8b'
Jan  9 12:31:29.791: INFO: stderr: ""
Jan  9 12:31:29.791: INFO: stdout: "true"
Jan  9 12:31:29.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 get pods update-demo-nautilus-89xrl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-b7b8b'
Jan  9 12:31:29.851: INFO: stderr: ""
Jan  9 12:31:29.851: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan  9 12:31:29.851: INFO: validating pod update-demo-nautilus-89xrl
Jan  9 12:31:29.853: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan  9 12:31:29.853: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan  9 12:31:29.853: INFO: update-demo-nautilus-89xrl is verified up and running
STEP: scaling up the replication controller
Jan  9 12:31:29.854: INFO: scanned /root for discovery docs: <nil>
Jan  9 12:31:29.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-b7b8b'
Jan  9 12:31:30.928: INFO: stderr: ""
Jan  9 12:31:30.928: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan  9 12:31:30.928: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-b7b8b'
Jan  9 12:31:30.991: INFO: stderr: ""
Jan  9 12:31:30.991: INFO: stdout: "update-demo-nautilus-89xrl update-demo-nautilus-njdbr "
Jan  9 12:31:30.991: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 get pods update-demo-nautilus-89xrl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-b7b8b'
Jan  9 12:31:31.060: INFO: stderr: ""
Jan  9 12:31:31.060: INFO: stdout: "true"
Jan  9 12:31:31.060: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 get pods update-demo-nautilus-89xrl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-b7b8b'
Jan  9 12:31:31.120: INFO: stderr: ""
Jan  9 12:31:31.120: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan  9 12:31:31.120: INFO: validating pod update-demo-nautilus-89xrl
Jan  9 12:31:31.121: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan  9 12:31:31.121: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan  9 12:31:31.121: INFO: update-demo-nautilus-89xrl is verified up and running
Jan  9 12:31:31.121: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 get pods update-demo-nautilus-njdbr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-b7b8b'
Jan  9 12:31:31.187: INFO: stderr: ""
Jan  9 12:31:31.188: INFO: stdout: ""
Jan  9 12:31:31.188: INFO: update-demo-nautilus-njdbr is created but not running
Jan  9 12:31:36.188: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-b7b8b'
Jan  9 12:31:36.251: INFO: stderr: ""
Jan  9 12:31:36.251: INFO: stdout: "update-demo-nautilus-89xrl update-demo-nautilus-njdbr "
Jan  9 12:31:36.251: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 get pods update-demo-nautilus-89xrl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-b7b8b'
Jan  9 12:31:36.310: INFO: stderr: ""
Jan  9 12:31:36.310: INFO: stdout: "true"
Jan  9 12:31:36.310: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 get pods update-demo-nautilus-89xrl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-b7b8b'
Jan  9 12:31:36.373: INFO: stderr: ""
Jan  9 12:31:36.373: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan  9 12:31:36.373: INFO: validating pod update-demo-nautilus-89xrl
Jan  9 12:31:36.375: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan  9 12:31:36.375: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan  9 12:31:36.375: INFO: update-demo-nautilus-89xrl is verified up and running
Jan  9 12:31:36.375: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 get pods update-demo-nautilus-njdbr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-b7b8b'
Jan  9 12:31:36.434: INFO: stderr: ""
Jan  9 12:31:36.434: INFO: stdout: "true"
Jan  9 12:31:36.434: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 get pods update-demo-nautilus-njdbr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-b7b8b'
Jan  9 12:31:36.493: INFO: stderr: ""
Jan  9 12:31:36.493: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan  9 12:31:36.493: INFO: validating pod update-demo-nautilus-njdbr
Jan  9 12:31:36.495: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan  9 12:31:36.495: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan  9 12:31:36.495: INFO: update-demo-nautilus-njdbr is verified up and running
STEP: using delete to clean up resources
Jan  9 12:31:36.495: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-b7b8b'
Jan  9 12:31:36.555: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan  9 12:31:36.555: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jan  9 12:31:36.556: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-b7b8b'
Jan  9 12:31:36.637: INFO: stderr: "No resources found.\n"
Jan  9 12:31:36.637: INFO: stdout: ""
Jan  9 12:31:36.637: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 get pods -l name=update-demo --namespace=e2e-tests-kubectl-b7b8b -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan  9 12:31:36.708: INFO: stderr: ""
Jan  9 12:31:36.708: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:31:36.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-b7b8b" for this suite.
Jan  9 12:31:42.715: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:31:42.725: INFO: namespace: e2e-tests-kubectl-b7b8b, resource: bindings, ignored listing per whitelist
Jan  9 12:31:42.752: INFO: namespace e2e-tests-kubectl-b7b8b deletion completed in 6.042265239s

• [SLOW TEST:24.816 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:31:42.752: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan  9 12:31:42.786: INFO: Creating ReplicaSet my-hostname-basic-852a06b9-140a-11e9-a571-02181533b527
Jan  9 12:31:42.790: INFO: Pod name my-hostname-basic-852a06b9-140a-11e9-a571-02181533b527: Found 0 pods out of 1
Jan  9 12:31:47.792: INFO: Pod name my-hostname-basic-852a06b9-140a-11e9-a571-02181533b527: Found 1 pods out of 1
Jan  9 12:31:47.792: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-852a06b9-140a-11e9-a571-02181533b527" is running
Jan  9 12:31:47.793: INFO: Pod "my-hostname-basic-852a06b9-140a-11e9-a571-02181533b527-ltvll" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-09 12:31:42 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-09 12:31:45 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-09 12:31:45 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-09 12:31:42 +0000 UTC Reason: Message:}])
Jan  9 12:31:47.793: INFO: Trying to dial the pod
Jan  9 12:31:52.798: INFO: Controller my-hostname-basic-852a06b9-140a-11e9-a571-02181533b527: Got expected result from replica 1 [my-hostname-basic-852a06b9-140a-11e9-a571-02181533b527-ltvll]: "my-hostname-basic-852a06b9-140a-11e9-a571-02181533b527-ltvll", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:31:52.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-brdgr" for this suite.
Jan  9 12:31:58.805: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:31:58.822: INFO: namespace: e2e-tests-replicaset-brdgr, resource: bindings, ignored listing per whitelist
Jan  9 12:31:58.841: INFO: namespace e2e-tests-replicaset-brdgr deletion completed in 6.041763512s

• [SLOW TEST:16.089 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:31:58.841: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Jan  9 12:31:58.874: INFO: Waiting up to 5m0s for pod "var-expansion-8ec0758e-140a-11e9-a571-02181533b527" in namespace "e2e-tests-var-expansion-85mrp" to be "success or failure"
Jan  9 12:31:58.875: INFO: Pod "var-expansion-8ec0758e-140a-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 974.811µs
Jan  9 12:32:00.877: INFO: Pod "var-expansion-8ec0758e-140a-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.002837064s
STEP: Saw pod success
Jan  9 12:32:00.877: INFO: Pod "var-expansion-8ec0758e-140a-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 12:32:00.878: INFO: Trying to get logs from node ip-172-31-59-90 pod var-expansion-8ec0758e-140a-11e9-a571-02181533b527 container dapi-container: <nil>
STEP: delete the pod
Jan  9 12:32:00.887: INFO: Waiting for pod var-expansion-8ec0758e-140a-11e9-a571-02181533b527 to disappear
Jan  9 12:32:00.888: INFO: Pod var-expansion-8ec0758e-140a-11e9-a571-02181533b527 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:32:00.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-85mrp" for this suite.
Jan  9 12:32:06.893: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:32:06.930: INFO: namespace: e2e-tests-var-expansion-85mrp, resource: bindings, ignored listing per whitelist
Jan  9 12:32:06.930: INFO: namespace e2e-tests-var-expansion-85mrp deletion completed in 6.041281473s

• [SLOW TEST:8.089 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:32:06.930: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan  9 12:32:06.967: INFO: Waiting up to 5m0s for pod "downwardapi-volume-93935f5f-140a-11e9-a571-02181533b527" in namespace "e2e-tests-downward-api-b7jff" to be "success or failure"
Jan  9 12:32:06.968: INFO: Pod "downwardapi-volume-93935f5f-140a-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.427321ms
Jan  9 12:32:08.970: INFO: Pod "downwardapi-volume-93935f5f-140a-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003163375s
STEP: Saw pod success
Jan  9 12:32:08.970: INFO: Pod "downwardapi-volume-93935f5f-140a-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 12:32:08.971: INFO: Trying to get logs from node ip-172-31-59-90 pod downwardapi-volume-93935f5f-140a-11e9-a571-02181533b527 container client-container: <nil>
STEP: delete the pod
Jan  9 12:32:08.981: INFO: Waiting for pod downwardapi-volume-93935f5f-140a-11e9-a571-02181533b527 to disappear
Jan  9 12:32:08.982: INFO: Pod downwardapi-volume-93935f5f-140a-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:32:08.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-b7jff" for this suite.
Jan  9 12:32:14.988: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:32:15.010: INFO: namespace: e2e-tests-downward-api-b7jff, resource: bindings, ignored listing per whitelist
Jan  9 12:32:15.024: INFO: namespace e2e-tests-downward-api-b7jff deletion completed in 6.041026269s

• [SLOW TEST:8.094 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:32:15.024: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-98662aa6-140a-11e9-a571-02181533b527
STEP: Creating a pod to test consume configMaps
Jan  9 12:32:15.061: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-986666d2-140a-11e9-a571-02181533b527" in namespace "e2e-tests-projected-7sgc9" to be "success or failure"
Jan  9 12:32:15.062: INFO: Pod "pod-projected-configmaps-986666d2-140a-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.041077ms
Jan  9 12:32:17.064: INFO: Pod "pod-projected-configmaps-986666d2-140a-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.002882553s
STEP: Saw pod success
Jan  9 12:32:17.064: INFO: Pod "pod-projected-configmaps-986666d2-140a-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 12:32:17.065: INFO: Trying to get logs from node ip-172-31-59-90 pod pod-projected-configmaps-986666d2-140a-11e9-a571-02181533b527 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan  9 12:32:17.072: INFO: Waiting for pod pod-projected-configmaps-986666d2-140a-11e9-a571-02181533b527 to disappear
Jan  9 12:32:17.073: INFO: Pod pod-projected-configmaps-986666d2-140a-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:32:17.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7sgc9" for this suite.
Jan  9 12:32:23.079: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:32:23.115: INFO: namespace: e2e-tests-projected-7sgc9, resource: bindings, ignored listing per whitelist
Jan  9 12:32:23.115: INFO: namespace e2e-tests-projected-7sgc9 deletion completed in 6.041173331s

• [SLOW TEST:8.091 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:32:23.115: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan  9 12:32:23.148: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9d38795d-140a-11e9-a571-02181533b527" in namespace "e2e-tests-downward-api-n4rz9" to be "success or failure"
Jan  9 12:32:23.149: INFO: Pod "downwardapi-volume-9d38795d-140a-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.065354ms
Jan  9 12:32:25.151: INFO: Pod "downwardapi-volume-9d38795d-140a-11e9-a571-02181533b527": Phase="Running", Reason="", readiness=true. Elapsed: 2.002954223s
Jan  9 12:32:27.153: INFO: Pod "downwardapi-volume-9d38795d-140a-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00475511s
STEP: Saw pod success
Jan  9 12:32:27.153: INFO: Pod "downwardapi-volume-9d38795d-140a-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 12:32:27.154: INFO: Trying to get logs from node ip-172-31-59-90 pod downwardapi-volume-9d38795d-140a-11e9-a571-02181533b527 container client-container: <nil>
STEP: delete the pod
Jan  9 12:32:27.164: INFO: Waiting for pod downwardapi-volume-9d38795d-140a-11e9-a571-02181533b527 to disappear
Jan  9 12:32:27.165: INFO: Pod downwardapi-volume-9d38795d-140a-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:32:27.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-n4rz9" for this suite.
Jan  9 12:32:33.171: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:32:33.202: INFO: namespace: e2e-tests-downward-api-n4rz9, resource: bindings, ignored listing per whitelist
Jan  9 12:32:33.208: INFO: namespace e2e-tests-downward-api-n4rz9 deletion completed in 6.041798454s

• [SLOW TEST:10.092 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:32:33.208: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-a33cb62c-140a-11e9-a571-02181533b527
STEP: Creating a pod to test consume secrets
Jan  9 12:32:33.244: INFO: Waiting up to 5m0s for pod "pod-secrets-a33cedef-140a-11e9-a571-02181533b527" in namespace "e2e-tests-secrets-xkzzh" to be "success or failure"
Jan  9 12:32:33.246: INFO: Pod "pod-secrets-a33cedef-140a-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.650489ms
Jan  9 12:32:35.247: INFO: Pod "pod-secrets-a33cedef-140a-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003621285s
STEP: Saw pod success
Jan  9 12:32:35.248: INFO: Pod "pod-secrets-a33cedef-140a-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 12:32:35.249: INFO: Trying to get logs from node ip-172-31-59-90 pod pod-secrets-a33cedef-140a-11e9-a571-02181533b527 container secret-volume-test: <nil>
STEP: delete the pod
Jan  9 12:32:35.256: INFO: Waiting for pod pod-secrets-a33cedef-140a-11e9-a571-02181533b527 to disappear
Jan  9 12:32:35.258: INFO: Pod pod-secrets-a33cedef-140a-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:32:35.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-xkzzh" for this suite.
Jan  9 12:32:41.264: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:32:41.297: INFO: namespace: e2e-tests-secrets-xkzzh, resource: bindings, ignored listing per whitelist
Jan  9 12:32:41.302: INFO: namespace e2e-tests-secrets-xkzzh deletion completed in 6.042508622s

• [SLOW TEST:8.094 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:32:41.302: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jan  9 12:32:43.850: INFO: Successfully updated pod "annotationupdatea80fb49f-140a-11e9-a571-02181533b527"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:32:47.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-9r5zh" for this suite.
Jan  9 12:33:09.870: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:33:09.887: INFO: namespace: e2e-tests-downward-api-9r5zh, resource: bindings, ignored listing per whitelist
Jan  9 12:33:09.907: INFO: namespace e2e-tests-downward-api-9r5zh deletion completed in 22.042050407s

• [SLOW TEST:28.605 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:33:09.907: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Jan  9 12:33:09.938: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 create -f - --namespace=e2e-tests-kubectl-trfbx'
Jan  9 12:33:10.227: INFO: stderr: ""
Jan  9 12:33:10.227: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Jan  9 12:33:11.229: INFO: Selector matched 1 pods for map[app:redis]
Jan  9 12:33:11.229: INFO: Found 0 / 1
Jan  9 12:33:12.229: INFO: Selector matched 1 pods for map[app:redis]
Jan  9 12:33:12.229: INFO: Found 1 / 1
Jan  9 12:33:12.229: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Jan  9 12:33:12.230: INFO: Selector matched 1 pods for map[app:redis]
Jan  9 12:33:12.230: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jan  9 12:33:12.230: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 patch pod redis-master-tcs5k --namespace=e2e-tests-kubectl-trfbx -p {"metadata":{"annotations":{"x":"y"}}}'
Jan  9 12:33:12.292: INFO: stderr: ""
Jan  9 12:33:12.292: INFO: stdout: "pod/redis-master-tcs5k patched\n"
STEP: checking annotations
Jan  9 12:33:12.293: INFO: Selector matched 1 pods for map[app:redis]
Jan  9 12:33:12.293: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:33:12.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-trfbx" for this suite.
Jan  9 12:33:34.299: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:33:34.307: INFO: namespace: e2e-tests-kubectl-trfbx, resource: bindings, ignored listing per whitelist
Jan  9 12:33:34.337: INFO: namespace e2e-tests-kubectl-trfbx deletion completed in 22.043018242s

• [SLOW TEST:24.430 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:33:34.338: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:33:37.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-jtpjj" for this suite.
Jan  9 12:33:59.387: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:33:59.416: INFO: namespace: e2e-tests-replication-controller-jtpjj, resource: bindings, ignored listing per whitelist
Jan  9 12:33:59.425: INFO: namespace e2e-tests-replication-controller-jtpjj deletion completed in 22.042713443s

• [SLOW TEST:25.088 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:33:59.425: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:33:59.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-5lgxd" for this suite.
Jan  9 12:34:05.463: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:34:05.478: INFO: namespace: e2e-tests-services-5lgxd, resource: bindings, ignored listing per whitelist
Jan  9 12:34:05.498: INFO: namespace e2e-tests-services-5lgxd deletion completed in 6.039418524s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:6.073 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:34:05.498: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-da3f541e-140a-11e9-a571-02181533b527
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-da3f541e-140a-11e9-a571-02181533b527
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:35:25.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-glwj4" for this suite.
Jan  9 12:35:47.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:35:47.759: INFO: namespace: e2e-tests-projected-glwj4, resource: bindings, ignored listing per whitelist
Jan  9 12:35:47.789: INFO: namespace e2e-tests-projected-glwj4 deletion completed in 22.039127551s

• [SLOW TEST:102.291 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:35:47.790: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-1737633b-140b-11e9-a571-02181533b527
STEP: Creating a pod to test consume configMaps
Jan  9 12:35:47.825: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-17379bab-140b-11e9-a571-02181533b527" in namespace "e2e-tests-projected-nt557" to be "success or failure"
Jan  9 12:35:47.826: INFO: Pod "pod-projected-configmaps-17379bab-140b-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.182006ms
Jan  9 12:35:49.828: INFO: Pod "pod-projected-configmaps-17379bab-140b-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003012819s
STEP: Saw pod success
Jan  9 12:35:49.828: INFO: Pod "pod-projected-configmaps-17379bab-140b-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 12:35:49.829: INFO: Trying to get logs from node ip-172-31-59-90 pod pod-projected-configmaps-17379bab-140b-11e9-a571-02181533b527 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan  9 12:35:49.836: INFO: Waiting for pod pod-projected-configmaps-17379bab-140b-11e9-a571-02181533b527 to disappear
Jan  9 12:35:49.837: INFO: Pod pod-projected-configmaps-17379bab-140b-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:35:49.837: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-nt557" for this suite.
Jan  9 12:35:55.843: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:35:55.864: INFO: namespace: e2e-tests-projected-nt557, resource: bindings, ignored listing per whitelist
Jan  9 12:35:55.879: INFO: namespace e2e-tests-projected-nt557 deletion completed in 6.041079991s

• [SLOW TEST:8.090 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:35:55.879: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-jbrbr in namespace e2e-tests-proxy-57k8n
I0109 12:35:55.914137      18 runners.go:184] Created replication controller with name: proxy-service-jbrbr, namespace: e2e-tests-proxy-57k8n, replica count: 1
I0109 12:35:56.964680      18 runners.go:184] proxy-service-jbrbr Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0109 12:35:57.964900      18 runners.go:184] proxy-service-jbrbr Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0109 12:35:58.965105      18 runners.go:184] proxy-service-jbrbr Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0109 12:35:59.965325      18 runners.go:184] proxy-service-jbrbr Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0109 12:36:00.965464      18 runners.go:184] proxy-service-jbrbr Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0109 12:36:01.965677      18 runners.go:184] proxy-service-jbrbr Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0109 12:36:02.965905      18 runners.go:184] proxy-service-jbrbr Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0109 12:36:03.966167      18 runners.go:184] proxy-service-jbrbr Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0109 12:36:04.966393      18 runners.go:184] proxy-service-jbrbr Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jan  9 12:36:04.968: INFO: setup took 9.058555395s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Jan  9 12:36:04.971: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:162/proxy/: bar (200; 2.835051ms)
Jan  9 12:36:04.971: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:160/proxy/: foo (200; 3.251232ms)
Jan  9 12:36:04.972: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:1080/proxy/rewri... (200; 3.614773ms)
Jan  9 12:36:04.972: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:1080/proxy/... (200; 3.387654ms)
Jan  9 12:36:04.972: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/proxy-service-jbrbr:portname1/proxy/: foo (200; 3.386198ms)
Jan  9 12:36:04.972: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:160/proxy/: foo (200; 3.443246ms)
Jan  9 12:36:04.972: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/http:proxy-service-jbrbr:portname1/proxy/: foo (200; 3.60236ms)
Jan  9 12:36:04.972: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/proxy-service-jbrbr:portname2/proxy/: bar (200; 3.732554ms)
Jan  9 12:36:04.972: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:162/proxy/: bar (200; 3.627068ms)
Jan  9 12:36:04.973: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/http:proxy-service-jbrbr:portname2/proxy/: bar (200; 4.661846ms)
Jan  9 12:36:04.973: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w/proxy/rewriteme"... (200; 4.794132ms)
Jan  9 12:36:04.975: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:462/proxy/: tls qux (200; 7.393149ms)
Jan  9 12:36:04.976: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:460/proxy/: tls baz (200; 7.504714ms)
Jan  9 12:36:04.976: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/https:proxy-service-jbrbr:tlsportname1/proxy/: tls baz (200; 8.423533ms)
Jan  9 12:36:04.977: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/https:proxy-service-jbrbr:tlsportname2/proxy/: tls qux (200; 8.93661ms)
Jan  9 12:36:04.978: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:443/proxy/... (200; 10.378965ms)
Jan  9 12:36:04.980: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:162/proxy/: bar (200; 1.298816ms)
Jan  9 12:36:04.981: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/http:proxy-service-jbrbr:portname2/proxy/: bar (200; 2.817411ms)
Jan  9 12:36:04.981: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:462/proxy/: tls qux (200; 2.839562ms)
Jan  9 12:36:04.981: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:1080/proxy/... (200; 2.855516ms)
Jan  9 12:36:04.982: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:160/proxy/: foo (200; 2.970834ms)
Jan  9 12:36:04.982: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:162/proxy/: bar (200; 2.871131ms)
Jan  9 12:36:04.982: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:460/proxy/: tls baz (200; 2.92869ms)
Jan  9 12:36:04.982: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:1080/proxy/rewri... (200; 2.951434ms)
Jan  9 12:36:04.982: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:443/proxy/... (200; 3.05252ms)
Jan  9 12:36:04.982: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w/proxy/rewriteme"... (200; 3.063728ms)
Jan  9 12:36:04.982: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/http:proxy-service-jbrbr:portname1/proxy/: foo (200; 3.934135ms)
Jan  9 12:36:04.983: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/https:proxy-service-jbrbr:tlsportname1/proxy/: tls baz (200; 3.811803ms)
Jan  9 12:36:04.983: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/proxy-service-jbrbr:portname1/proxy/: foo (200; 3.983233ms)
Jan  9 12:36:04.983: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/https:proxy-service-jbrbr:tlsportname2/proxy/: tls qux (200; 3.867564ms)
Jan  9 12:36:04.983: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:160/proxy/: foo (200; 4.328524ms)
Jan  9 12:36:04.984: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/proxy-service-jbrbr:portname2/proxy/: bar (200; 4.986908ms)
Jan  9 12:36:04.986: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:443/proxy/... (200; 2.52127ms)
Jan  9 12:36:04.986: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:160/proxy/: foo (200; 2.619484ms)
Jan  9 12:36:04.986: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:162/proxy/: bar (200; 2.513387ms)
Jan  9 12:36:04.988: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/http:proxy-service-jbrbr:portname1/proxy/: foo (200; 3.706692ms)
Jan  9 12:36:04.988: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w/proxy/rewriteme"... (200; 3.619352ms)
Jan  9 12:36:04.988: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:1080/proxy/... (200; 3.62718ms)
Jan  9 12:36:04.988: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:160/proxy/: foo (200; 3.764407ms)
Jan  9 12:36:04.988: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/https:proxy-service-jbrbr:tlsportname2/proxy/: tls qux (200; 4.203984ms)
Jan  9 12:36:04.988: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:162/proxy/: bar (200; 4.211545ms)
Jan  9 12:36:04.988: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/proxy-service-jbrbr:portname2/proxy/: bar (200; 4.267378ms)
Jan  9 12:36:04.988: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:1080/proxy/rewri... (200; 4.328053ms)
Jan  9 12:36:04.989: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:462/proxy/: tls qux (200; 4.65916ms)
Jan  9 12:36:04.989: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/proxy-service-jbrbr:portname1/proxy/: foo (200; 4.713501ms)
Jan  9 12:36:04.989: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/https:proxy-service-jbrbr:tlsportname1/proxy/: tls baz (200; 4.883917ms)
Jan  9 12:36:04.989: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/http:proxy-service-jbrbr:portname2/proxy/: bar (200; 4.973056ms)
Jan  9 12:36:04.989: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:460/proxy/: tls baz (200; 5.049917ms)
Jan  9 12:36:04.991: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:1080/proxy/rewri... (200; 1.625361ms)
Jan  9 12:36:04.992: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/http:proxy-service-jbrbr:portname1/proxy/: foo (200; 3.35128ms)
Jan  9 12:36:04.992: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:462/proxy/: tls qux (200; 3.23271ms)
Jan  9 12:36:04.992: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:443/proxy/... (200; 3.321749ms)
Jan  9 12:36:04.993: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/https:proxy-service-jbrbr:tlsportname2/proxy/: tls qux (200; 3.284186ms)
Jan  9 12:36:04.993: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:162/proxy/: bar (200; 3.224477ms)
Jan  9 12:36:04.993: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:160/proxy/: foo (200; 3.771966ms)
Jan  9 12:36:04.993: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/https:proxy-service-jbrbr:tlsportname1/proxy/: tls baz (200; 3.807972ms)
Jan  9 12:36:04.993: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:162/proxy/: bar (200; 3.663206ms)
Jan  9 12:36:04.993: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/proxy-service-jbrbr:portname2/proxy/: bar (200; 3.791686ms)
Jan  9 12:36:04.993: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/http:proxy-service-jbrbr:portname2/proxy/: bar (200; 3.752854ms)
Jan  9 12:36:04.993: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:460/proxy/: tls baz (200; 3.686352ms)
Jan  9 12:36:04.993: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w/proxy/rewriteme"... (200; 3.695428ms)
Jan  9 12:36:04.993: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:1080/proxy/... (200; 3.65794ms)
Jan  9 12:36:04.993: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/proxy-service-jbrbr:portname1/proxy/: foo (200; 3.685981ms)
Jan  9 12:36:04.993: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:160/proxy/: foo (200; 3.828193ms)
Jan  9 12:36:04.995: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w/proxy/rewriteme"... (200; 1.865759ms)
Jan  9 12:36:04.995: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:443/proxy/... (200; 1.793226ms)
Jan  9 12:36:04.995: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:1080/proxy/rewri... (200; 1.938239ms)
Jan  9 12:36:04.995: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:160/proxy/: foo (200; 1.963227ms)
Jan  9 12:36:04.995: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:162/proxy/: bar (200; 2.015594ms)
Jan  9 12:36:04.995: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:1080/proxy/... (200; 1.966254ms)
Jan  9 12:36:04.995: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/http:proxy-service-jbrbr:portname2/proxy/: bar (200; 2.098937ms)
Jan  9 12:36:04.996: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/http:proxy-service-jbrbr:portname1/proxy/: foo (200; 2.376235ms)
Jan  9 12:36:04.996: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/proxy-service-jbrbr:portname2/proxy/: bar (200; 2.409241ms)
Jan  9 12:36:04.996: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:160/proxy/: foo (200; 2.383547ms)
Jan  9 12:36:04.996: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:462/proxy/: tls qux (200; 2.43781ms)
Jan  9 12:36:04.996: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:162/proxy/: bar (200; 2.426446ms)
Jan  9 12:36:04.996: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/https:proxy-service-jbrbr:tlsportname2/proxy/: tls qux (200; 3.114312ms)
Jan  9 12:36:04.996: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:460/proxy/: tls baz (200; 3.056767ms)
Jan  9 12:36:04.996: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/https:proxy-service-jbrbr:tlsportname1/proxy/: tls baz (200; 3.169229ms)
Jan  9 12:36:04.996: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/proxy-service-jbrbr:portname1/proxy/: foo (200; 3.079811ms)
Jan  9 12:36:04.998: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:1080/proxy/rewri... (200; 2.067995ms)
Jan  9 12:36:04.999: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:160/proxy/: foo (200; 2.16243ms)
Jan  9 12:36:04.999: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:460/proxy/: tls baz (200; 2.031539ms)
Jan  9 12:36:04.999: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w/proxy/rewriteme"... (200; 2.172158ms)
Jan  9 12:36:04.999: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/proxy-service-jbrbr:portname2/proxy/: bar (200; 2.624355ms)
Jan  9 12:36:04.999: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:160/proxy/: foo (200; 2.839434ms)
Jan  9 12:36:04.999: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/http:proxy-service-jbrbr:portname1/proxy/: foo (200; 2.830145ms)
Jan  9 12:36:04.999: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:1080/proxy/... (200; 2.89777ms)
Jan  9 12:36:04.999: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/https:proxy-service-jbrbr:tlsportname2/proxy/: tls qux (200; 2.854184ms)
Jan  9 12:36:04.999: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/https:proxy-service-jbrbr:tlsportname1/proxy/: tls baz (200; 2.903354ms)
Jan  9 12:36:04.999: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:162/proxy/: bar (200; 3.006127ms)
Jan  9 12:36:04.999: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:443/proxy/... (200; 2.921486ms)
Jan  9 12:36:04.999: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:462/proxy/: tls qux (200; 2.928243ms)
Jan  9 12:36:04.999: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/proxy-service-jbrbr:portname1/proxy/: foo (200; 3.026787ms)
Jan  9 12:36:05.000: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:162/proxy/: bar (200; 3.085507ms)
Jan  9 12:36:05.000: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/http:proxy-service-jbrbr:portname2/proxy/: bar (200; 3.052051ms)
Jan  9 12:36:05.003: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:162/proxy/: bar (200; 2.539597ms)
Jan  9 12:36:05.003: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:443/proxy/... (200; 3.008767ms)
Jan  9 12:36:05.003: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:160/proxy/: foo (200; 2.650618ms)
Jan  9 12:36:05.003: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/http:proxy-service-jbrbr:portname1/proxy/: foo (200; 2.913308ms)
Jan  9 12:36:05.003: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:1080/proxy/rewri... (200; 2.419787ms)
Jan  9 12:36:05.003: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:1080/proxy/... (200; 2.755662ms)
Jan  9 12:36:05.003: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:462/proxy/: tls qux (200; 3.031634ms)
Jan  9 12:36:05.003: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:162/proxy/: bar (200; 2.255028ms)
Jan  9 12:36:05.003: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/proxy-service-jbrbr:portname2/proxy/: bar (200; 3.250509ms)
Jan  9 12:36:05.003: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/https:proxy-service-jbrbr:tlsportname1/proxy/: tls baz (200; 2.406956ms)
Jan  9 12:36:05.003: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w/proxy/rewriteme"... (200; 2.857007ms)
Jan  9 12:36:05.003: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/http:proxy-service-jbrbr:portname2/proxy/: bar (200; 2.928899ms)
Jan  9 12:36:05.003: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:160/proxy/: foo (200; 3.185718ms)
Jan  9 12:36:05.003: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/https:proxy-service-jbrbr:tlsportname2/proxy/: tls qux (200; 2.357477ms)
Jan  9 12:36:05.003: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/proxy-service-jbrbr:portname1/proxy/: foo (200; 2.569538ms)
Jan  9 12:36:05.003: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:460/proxy/: tls baz (200; 2.854777ms)
Jan  9 12:36:05.006: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/http:proxy-service-jbrbr:portname2/proxy/: bar (200; 2.710641ms)
Jan  9 12:36:05.006: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:162/proxy/: bar (200; 2.653364ms)
Jan  9 12:36:05.006: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/proxy-service-jbrbr:portname1/proxy/: foo (200; 2.71348ms)
Jan  9 12:36:05.006: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:462/proxy/: tls qux (200; 2.762461ms)
Jan  9 12:36:05.006: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:1080/proxy/... (200; 2.710313ms)
Jan  9 12:36:05.006: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:460/proxy/: tls baz (200; 2.796857ms)
Jan  9 12:36:05.006: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w/proxy/rewriteme"... (200; 2.723567ms)
Jan  9 12:36:05.006: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:443/proxy/... (200; 2.699581ms)
Jan  9 12:36:05.006: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:160/proxy/: foo (200; 2.727263ms)
Jan  9 12:36:05.006: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/https:proxy-service-jbrbr:tlsportname1/proxy/: tls baz (200; 2.654076ms)
Jan  9 12:36:05.006: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/https:proxy-service-jbrbr:tlsportname2/proxy/: tls qux (200; 2.82805ms)
Jan  9 12:36:05.006: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:160/proxy/: foo (200; 2.712501ms)
Jan  9 12:36:05.006: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/http:proxy-service-jbrbr:portname1/proxy/: foo (200; 3.110822ms)
Jan  9 12:36:05.006: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:1080/proxy/rewri... (200; 3.184402ms)
Jan  9 12:36:05.006: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/proxy-service-jbrbr:portname2/proxy/: bar (200; 3.144715ms)
Jan  9 12:36:05.006: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:162/proxy/: bar (200; 3.163801ms)
Jan  9 12:36:05.008: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w/proxy/rewriteme"... (200; 1.186862ms)
Jan  9 12:36:05.009: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:160/proxy/: foo (200; 2.607022ms)
Jan  9 12:36:05.009: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:1080/proxy/rewri... (200; 2.702072ms)
Jan  9 12:36:05.009: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/proxy-service-jbrbr:portname1/proxy/: foo (200; 2.678356ms)
Jan  9 12:36:05.009: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/https:proxy-service-jbrbr:tlsportname2/proxy/: tls qux (200; 2.670255ms)
Jan  9 12:36:05.009: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/http:proxy-service-jbrbr:portname1/proxy/: foo (200; 2.673803ms)
Jan  9 12:36:05.009: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/http:proxy-service-jbrbr:portname2/proxy/: bar (200; 2.729855ms)
Jan  9 12:36:05.009: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/proxy-service-jbrbr:portname2/proxy/: bar (200; 2.793153ms)
Jan  9 12:36:05.010: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:160/proxy/: foo (200; 2.943321ms)
Jan  9 12:36:05.010: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/https:proxy-service-jbrbr:tlsportname1/proxy/: tls baz (200; 3.107654ms)
Jan  9 12:36:05.010: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:1080/proxy/... (200; 3.046087ms)
Jan  9 12:36:05.010: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:162/proxy/: bar (200; 3.067562ms)
Jan  9 12:36:05.010: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:162/proxy/: bar (200; 3.116411ms)
Jan  9 12:36:05.010: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:460/proxy/: tls baz (200; 3.016053ms)
Jan  9 12:36:05.010: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:443/proxy/... (200; 3.081689ms)
Jan  9 12:36:05.010: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:462/proxy/: tls qux (200; 3.020996ms)
Jan  9 12:36:05.012: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:462/proxy/: tls qux (200; 2.515176ms)
Jan  9 12:36:05.012: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:160/proxy/: foo (200; 2.328552ms)
Jan  9 12:36:05.012: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:1080/proxy/... (200; 2.506782ms)
Jan  9 12:36:05.012: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:1080/proxy/rewri... (200; 2.446605ms)
Jan  9 12:36:05.012: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:162/proxy/: bar (200; 2.499899ms)
Jan  9 12:36:05.012: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:460/proxy/: tls baz (200; 2.515317ms)
Jan  9 12:36:05.012: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/http:proxy-service-jbrbr:portname2/proxy/: bar (200; 2.704088ms)
Jan  9 12:36:05.012: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:160/proxy/: foo (200; 2.647602ms)
Jan  9 12:36:05.015: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w/proxy/rewriteme"... (200; 5.181084ms)
Jan  9 12:36:05.015: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:162/proxy/: bar (200; 5.07908ms)
Jan  9 12:36:05.015: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/proxy-service-jbrbr:portname2/proxy/: bar (200; 5.02264ms)
Jan  9 12:36:05.015: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/http:proxy-service-jbrbr:portname1/proxy/: foo (200; 5.093053ms)
Jan  9 12:36:05.015: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/proxy-service-jbrbr:portname1/proxy/: foo (200; 5.015579ms)
Jan  9 12:36:05.015: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/https:proxy-service-jbrbr:tlsportname1/proxy/: tls baz (200; 5.092601ms)
Jan  9 12:36:05.015: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:443/proxy/... (200; 5.085115ms)
Jan  9 12:36:05.016: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/https:proxy-service-jbrbr:tlsportname2/proxy/: tls qux (200; 5.776537ms)
Jan  9 12:36:05.018: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:1080/proxy/rewri... (200; 1.967366ms)
Jan  9 12:36:05.018: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/http:proxy-service-jbrbr:portname2/proxy/: bar (200; 2.479424ms)
Jan  9 12:36:05.018: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:443/proxy/... (200; 2.485952ms)
Jan  9 12:36:05.018: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:460/proxy/: tls baz (200; 2.515895ms)
Jan  9 12:36:05.018: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:162/proxy/: bar (200; 2.533122ms)
Jan  9 12:36:05.018: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/https:proxy-service-jbrbr:tlsportname1/proxy/: tls baz (200; 2.376769ms)
Jan  9 12:36:05.018: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/https:proxy-service-jbrbr:tlsportname2/proxy/: tls qux (200; 2.626701ms)
Jan  9 12:36:05.018: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:462/proxy/: tls qux (200; 2.59934ms)
Jan  9 12:36:05.018: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w/proxy/rewriteme"... (200; 2.661141ms)
Jan  9 12:36:05.018: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:160/proxy/: foo (200; 2.546317ms)
Jan  9 12:36:05.018: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:160/proxy/: foo (200; 2.63485ms)
Jan  9 12:36:05.019: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:1080/proxy/... (200; 2.961762ms)
Jan  9 12:36:05.019: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/http:proxy-service-jbrbr:portname1/proxy/: foo (200; 3.178467ms)
Jan  9 12:36:05.019: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/proxy-service-jbrbr:portname2/proxy/: bar (200; 3.113045ms)
Jan  9 12:36:05.019: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/proxy-service-jbrbr:portname1/proxy/: foo (200; 3.152947ms)
Jan  9 12:36:05.019: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:162/proxy/: bar (200; 3.360607ms)
Jan  9 12:36:05.021: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:162/proxy/: bar (200; 1.567627ms)
Jan  9 12:36:05.021: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:160/proxy/: foo (200; 1.897517ms)
Jan  9 12:36:05.021: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:160/proxy/: foo (200; 1.778772ms)
Jan  9 12:36:05.022: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:460/proxy/: tls baz (200; 2.308723ms)
Jan  9 12:36:05.022: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:1080/proxy/... (200; 2.259918ms)
Jan  9 12:36:05.022: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:462/proxy/: tls qux (200; 2.313346ms)
Jan  9 12:36:05.022: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:443/proxy/... (200; 2.470326ms)
Jan  9 12:36:05.022: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w/proxy/rewriteme"... (200; 2.557605ms)
Jan  9 12:36:05.022: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:1080/proxy/rewri... (200; 2.676606ms)
Jan  9 12:36:05.022: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/proxy-service-jbrbr:portname2/proxy/: bar (200; 2.740379ms)
Jan  9 12:36:05.022: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:162/proxy/: bar (200; 2.643781ms)
Jan  9 12:36:05.022: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/http:proxy-service-jbrbr:portname2/proxy/: bar (200; 3.096855ms)
Jan  9 12:36:05.023: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/https:proxy-service-jbrbr:tlsportname1/proxy/: tls baz (200; 3.108001ms)
Jan  9 12:36:05.023: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/proxy-service-jbrbr:portname1/proxy/: foo (200; 3.220816ms)
Jan  9 12:36:05.023: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/http:proxy-service-jbrbr:portname1/proxy/: foo (200; 3.26884ms)
Jan  9 12:36:05.023: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/https:proxy-service-jbrbr:tlsportname2/proxy/: tls qux (200; 3.304976ms)
Jan  9 12:36:05.025: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:1080/proxy/rewri... (200; 2.0964ms)
Jan  9 12:36:05.025: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:462/proxy/: tls qux (200; 2.030737ms)
Jan  9 12:36:05.026: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/http:proxy-service-jbrbr:portname2/proxy/: bar (200; 2.780123ms)
Jan  9 12:36:05.026: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w/proxy/rewriteme"... (200; 2.889224ms)
Jan  9 12:36:05.025: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:160/proxy/: foo (200; 2.751807ms)
Jan  9 12:36:05.026: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:443/proxy/... (200; 2.919021ms)
Jan  9 12:36:05.026: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/https:proxy-service-jbrbr:tlsportname1/proxy/: tls baz (200; 2.789023ms)
Jan  9 12:36:05.026: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/https:proxy-service-jbrbr:tlsportname2/proxy/: tls qux (200; 2.911107ms)
Jan  9 12:36:05.026: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:162/proxy/: bar (200; 2.807798ms)
Jan  9 12:36:05.026: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:460/proxy/: tls baz (200; 2.827101ms)
Jan  9 12:36:05.026: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/proxy-service-jbrbr:portname1/proxy/: foo (200; 2.840849ms)
Jan  9 12:36:05.026: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/proxy-service-jbrbr:portname2/proxy/: bar (200; 2.888182ms)
Jan  9 12:36:05.026: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:162/proxy/: bar (200; 2.915109ms)
Jan  9 12:36:05.026: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:1080/proxy/... (200; 2.826416ms)
Jan  9 12:36:05.026: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/http:proxy-service-jbrbr:portname1/proxy/: foo (200; 2.903217ms)
Jan  9 12:36:05.026: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:160/proxy/: foo (200; 2.879975ms)
Jan  9 12:36:05.027: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:1080/proxy/rewri... (200; 1.469013ms)
Jan  9 12:36:05.031: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w/proxy/rewriteme"... (200; 5.642702ms)
Jan  9 12:36:05.031: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:462/proxy/: tls qux (200; 5.756597ms)
Jan  9 12:36:05.031: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:162/proxy/: bar (200; 5.663553ms)
Jan  9 12:36:05.031: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:1080/proxy/... (200; 5.681697ms)
Jan  9 12:36:05.031: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:160/proxy/: foo (200; 5.714625ms)
Jan  9 12:36:05.031: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/proxy-service-jbrbr:portname1/proxy/: foo (200; 5.78357ms)
Jan  9 12:36:05.031: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:160/proxy/: foo (200; 5.760677ms)
Jan  9 12:36:05.031: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/proxy-service-jbrbr:portname2/proxy/: bar (200; 5.773011ms)
Jan  9 12:36:05.031: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/http:proxy-service-jbrbr:portname2/proxy/: bar (200; 5.774793ms)
Jan  9 12:36:05.031: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:443/proxy/... (200; 5.780654ms)
Jan  9 12:36:05.032: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/http:proxy-service-jbrbr:portname1/proxy/: foo (200; 5.823201ms)
Jan  9 12:36:05.032: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:162/proxy/: bar (200; 5.849829ms)
Jan  9 12:36:05.032: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/https:proxy-service-jbrbr:tlsportname2/proxy/: tls qux (200; 6.41621ms)
Jan  9 12:36:05.032: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:460/proxy/: tls baz (200; 6.415016ms)
Jan  9 12:36:05.032: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/https:proxy-service-jbrbr:tlsportname1/proxy/: tls baz (200; 6.44002ms)
Jan  9 12:36:05.034: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:443/proxy/... (200; 1.656688ms)
Jan  9 12:36:05.034: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:1080/proxy/... (200; 1.736406ms)
Jan  9 12:36:05.034: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:162/proxy/: bar (200; 1.797133ms)
Jan  9 12:36:05.034: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/http:proxy-service-jbrbr:portname2/proxy/: bar (200; 1.890515ms)
Jan  9 12:36:05.034: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:462/proxy/: tls qux (200; 1.964689ms)
Jan  9 12:36:05.034: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:160/proxy/: foo (200; 1.946719ms)
Jan  9 12:36:05.034: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:160/proxy/: foo (200; 1.935782ms)
Jan  9 12:36:05.034: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:1080/proxy/rewri... (200; 1.991116ms)
Jan  9 12:36:05.035: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/proxy-service-jbrbr:portname1/proxy/: foo (200; 2.822448ms)
Jan  9 12:36:05.035: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:162/proxy/: bar (200; 3.024655ms)
Jan  9 12:36:05.035: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:460/proxy/: tls baz (200; 3.043934ms)
Jan  9 12:36:05.035: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/http:proxy-service-jbrbr:portname1/proxy/: foo (200; 3.070536ms)
Jan  9 12:36:05.035: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w/proxy/rewriteme"... (200; 3.091039ms)
Jan  9 12:36:05.036: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/proxy-service-jbrbr:portname2/proxy/: bar (200; 3.555914ms)
Jan  9 12:36:05.036: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/https:proxy-service-jbrbr:tlsportname2/proxy/: tls qux (200; 3.574491ms)
Jan  9 12:36:05.036: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/https:proxy-service-jbrbr:tlsportname1/proxy/: tls baz (200; 3.612821ms)
Jan  9 12:36:05.038: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:460/proxy/: tls baz (200; 2.180787ms)
Jan  9 12:36:05.038: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:162/proxy/: bar (200; 2.223111ms)
Jan  9 12:36:05.038: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:162/proxy/: bar (200; 2.164052ms)
Jan  9 12:36:05.038: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:1080/proxy/... (200; 2.195116ms)
Jan  9 12:36:05.038: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/http:proxy-service-jbrbr:portname2/proxy/: bar (200; 2.32013ms)
Jan  9 12:36:05.038: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/https:proxy-service-jbrbr:tlsportname1/proxy/: tls baz (200; 2.314893ms)
Jan  9 12:36:05.038: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:160/proxy/: foo (200; 2.245324ms)
Jan  9 12:36:05.038: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:443/proxy/... (200; 2.3787ms)
Jan  9 12:36:05.038: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/proxy-service-jbrbr:portname1/proxy/: foo (200; 2.328127ms)
Jan  9 12:36:05.038: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/http:proxy-service-jbrbr:portname1/proxy/: foo (200; 2.278416ms)
Jan  9 12:36:05.038: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/proxy-service-jbrbr:portname2/proxy/: bar (200; 2.286321ms)
Jan  9 12:36:05.038: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:1080/proxy/rewri... (200; 2.342521ms)
Jan  9 12:36:05.038: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:160/proxy/: foo (200; 2.287502ms)
Jan  9 12:36:05.038: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w/proxy/rewriteme"... (200; 2.387532ms)
Jan  9 12:36:05.038: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/https:proxy-service-jbrbr:tlsportname2/proxy/: tls qux (200; 2.302663ms)
Jan  9 12:36:05.039: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:462/proxy/: tls qux (200; 2.359205ms)
Jan  9 12:36:05.041: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w/proxy/rewriteme"... (200; 1.900229ms)
Jan  9 12:36:05.041: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/http:proxy-service-jbrbr:portname1/proxy/: foo (200; 2.175448ms)
Jan  9 12:36:05.041: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:160/proxy/: foo (200; 2.072599ms)
Jan  9 12:36:05.041: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:1080/proxy/rewri... (200; 2.233905ms)
Jan  9 12:36:05.041: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:443/proxy/... (200; 2.10093ms)
Jan  9 12:36:05.041: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:160/proxy/: foo (200; 2.023102ms)
Jan  9 12:36:05.041: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/proxy-service-jbrbr:portname2/proxy/: bar (200; 2.223525ms)
Jan  9 12:36:05.041: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:162/proxy/: bar (200; 2.051631ms)
Jan  9 12:36:05.041: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:462/proxy/: tls qux (200; 2.206114ms)
Jan  9 12:36:05.041: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/http:proxy-service-jbrbr:portname2/proxy/: bar (200; 2.691655ms)
Jan  9 12:36:05.041: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:460/proxy/: tls baz (200; 2.578508ms)
Jan  9 12:36:05.041: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/https:proxy-service-jbrbr:tlsportname1/proxy/: tls baz (200; 2.878912ms)
Jan  9 12:36:05.041: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/https:proxy-service-jbrbr:tlsportname2/proxy/: tls qux (200; 2.864881ms)
Jan  9 12:36:05.041: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:162/proxy/: bar (200; 2.845164ms)
Jan  9 12:36:05.042: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:1080/proxy/... (200; 2.689297ms)
Jan  9 12:36:05.042: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/proxy-service-jbrbr:portname1/proxy/: foo (200; 2.676306ms)
Jan  9 12:36:05.047: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:162/proxy/: bar (200; 5.582785ms)
Jan  9 12:36:05.047: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:443/proxy/... (200; 5.393926ms)
Jan  9 12:36:05.047: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:160/proxy/: foo (200; 5.481357ms)
Jan  9 12:36:05.047: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:160/proxy/: foo (200; 5.297914ms)
Jan  9 12:36:05.047: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:460/proxy/: tls baz (200; 5.176078ms)
Jan  9 12:36:05.047: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/http:proxy-service-jbrbr:portname1/proxy/: foo (200; 5.586932ms)
Jan  9 12:36:05.047: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w/proxy/rewriteme"... (200; 5.005887ms)
Jan  9 12:36:05.047: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:462/proxy/: tls qux (200; 5.394641ms)
Jan  9 12:36:05.047: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:1080/proxy/... (200; 4.965768ms)
Jan  9 12:36:05.047: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:162/proxy/: bar (200; 5.281701ms)
Jan  9 12:36:05.048: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/http:proxy-service-jbrbr:portname2/proxy/: bar (200; 5.871429ms)
Jan  9 12:36:05.048: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/https:proxy-service-jbrbr:tlsportname1/proxy/: tls baz (200; 5.601097ms)
Jan  9 12:36:05.048: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/https:proxy-service-jbrbr:tlsportname2/proxy/: tls qux (200; 5.617107ms)
Jan  9 12:36:05.048: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:1080/proxy/rewri... (200; 5.826158ms)
Jan  9 12:36:05.048: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/proxy-service-jbrbr:portname2/proxy/: bar (200; 5.778273ms)
Jan  9 12:36:05.049: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/proxy-service-jbrbr:portname1/proxy/: foo (200; 7.029697ms)
Jan  9 12:36:05.051: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:1080/proxy/... (200; 2.107956ms)
Jan  9 12:36:05.051: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:162/proxy/: bar (200; 2.170851ms)
Jan  9 12:36:05.051: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:160/proxy/: foo (200; 2.089213ms)
Jan  9 12:36:05.051: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:460/proxy/: tls baz (200; 2.143511ms)
Jan  9 12:36:05.051: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:160/proxy/: foo (200; 2.168656ms)
Jan  9 12:36:05.052: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:162/proxy/: bar (200; 2.298566ms)
Jan  9 12:36:05.052: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:1080/proxy/rewri... (200; 2.299029ms)
Jan  9 12:36:05.052: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:443/proxy/... (200; 2.269759ms)
Jan  9 12:36:05.052: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/proxy-service-jbrbr:portname1/proxy/: foo (200; 2.286142ms)
Jan  9 12:36:05.052: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/proxy-service-jbrbr:portname2/proxy/: bar (200; 2.361088ms)
Jan  9 12:36:05.052: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/http:proxy-service-jbrbr:portname2/proxy/: bar (200; 2.381038ms)
Jan  9 12:36:05.052: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w/proxy/rewriteme"... (200; 2.480858ms)
Jan  9 12:36:05.052: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:462/proxy/: tls qux (200; 2.795552ms)
Jan  9 12:36:05.052: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/https:proxy-service-jbrbr:tlsportname1/proxy/: tls baz (200; 2.776835ms)
Jan  9 12:36:05.052: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/http:proxy-service-jbrbr:portname1/proxy/: foo (200; 3.10857ms)
Jan  9 12:36:05.052: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/https:proxy-service-jbrbr:tlsportname2/proxy/: tls qux (200; 3.025392ms)
Jan  9 12:36:05.054: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:1080/proxy/rewri... (200; 1.678016ms)
Jan  9 12:36:05.054: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:162/proxy/: bar (200; 1.399693ms)
Jan  9 12:36:05.055: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/https:proxy-service-jbrbr:tlsportname2/proxy/: tls qux (200; 2.523935ms)
Jan  9 12:36:05.055: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/proxy-service-jbrbr:portname2/proxy/: bar (200; 2.736246ms)
Jan  9 12:36:05.055: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/https:proxy-service-jbrbr:tlsportname1/proxy/: tls baz (200; 2.688737ms)
Jan  9 12:36:05.055: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:462/proxy/: tls qux (200; 2.297227ms)
Jan  9 12:36:05.055: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:443/proxy/... (200; 2.382857ms)
Jan  9 12:36:05.055: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:160/proxy/: foo (200; 2.454635ms)
Jan  9 12:36:05.055: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/http:proxy-service-jbrbr:portname1/proxy/: foo (200; 2.569506ms)
Jan  9 12:36:05.055: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w/proxy/rewriteme"... (200; 2.035417ms)
Jan  9 12:36:05.055: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-57k8n/pods/http:proxy-service-jbrbr-trm4w:1080/proxy/... (200; 1.989909ms)
Jan  9 12:36:05.055: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:160/proxy/: foo (200; 2.336787ms)
Jan  9 12:36:05.055: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/https:proxy-service-jbrbr-trm4w:460/proxy/: tls baz (200; 2.244117ms)
Jan  9 12:36:05.055: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/proxy-service-jbrbr:portname1/proxy/: foo (200; 2.193074ms)
Jan  9 12:36:05.055: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-57k8n/services/http:proxy-service-jbrbr:portname2/proxy/: bar (200; 2.156854ms)
Jan  9 12:36:05.055: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-57k8n/pods/proxy-service-jbrbr-trm4w:162/proxy/: bar (200; 2.325858ms)
STEP: deleting ReplicationController proxy-service-jbrbr in namespace e2e-tests-proxy-57k8n, will wait for the garbage collector to delete the pods
Jan  9 12:36:05.109: INFO: Deleting ReplicationController proxy-service-jbrbr took: 2.784358ms
Jan  9 12:36:05.210: INFO: Terminating ReplicationController proxy-service-jbrbr pods took: 100.224308ms
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:36:07.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-57k8n" for this suite.
Jan  9 12:36:13.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:36:13.130: INFO: namespace: e2e-tests-proxy-57k8n, resource: bindings, ignored listing per whitelist
Jan  9 12:36:13.156: INFO: namespace e2e-tests-proxy-57k8n deletion completed in 6.044373151s

• [SLOW TEST:17.277 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:36:13.156: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:36:19.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-v792d" for this suite.
Jan  9 12:36:25.222: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:36:25.254: INFO: namespace: e2e-tests-namespaces-v792d, resource: bindings, ignored listing per whitelist
Jan  9 12:36:25.261: INFO: namespace e2e-tests-namespaces-v792d deletion completed in 6.043656695s
STEP: Destroying namespace "e2e-tests-nsdeletetest-5k2h4" for this suite.
Jan  9 12:36:25.263: INFO: Namespace e2e-tests-nsdeletetest-5k2h4 was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-vhxnq" for this suite.
Jan  9 12:36:31.267: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:36:31.305: INFO: namespace: e2e-tests-nsdeletetest-vhxnq, resource: bindings, ignored listing per whitelist
Jan  9 12:36:31.307: INFO: namespace e2e-tests-nsdeletetest-vhxnq deletion completed in 6.044219856s

• [SLOW TEST:18.151 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:36:31.307: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-3127da0b-140b-11e9-a571-02181533b527
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-3127da0b-140b-11e9-a571-02181533b527
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:36:35.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-dk7xv" for this suite.
Jan  9 12:36:57.372: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:36:57.390: INFO: namespace: e2e-tests-configmap-dk7xv, resource: bindings, ignored listing per whitelist
Jan  9 12:36:57.407: INFO: namespace e2e-tests-configmap-dk7xv deletion completed in 22.039371828s

• [SLOW TEST:26.100 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:36:57.407: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Jan  9 12:36:57.438: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 cluster-info'
Jan  9 12:36:57.498: INFO: stderr: ""
Jan  9 12:36:57.498: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.152.183.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.152.183.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:36:57.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-4d5wc" for this suite.
Jan  9 12:37:03.504: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:37:03.512: INFO: namespace: e2e-tests-kubectl-4d5wc, resource: bindings, ignored listing per whitelist
Jan  9 12:37:03.543: INFO: namespace e2e-tests-kubectl-4d5wc deletion completed in 6.043430324s

• [SLOW TEST:6.136 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:37:03.543: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-75btd
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-75btd
STEP: Deleting pre-stop pod
Jan  9 12:37:14.592: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:37:14.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-75btd" for this suite.
Jan  9 12:37:52.600: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:37:52.634: INFO: namespace: e2e-tests-prestop-75btd, resource: bindings, ignored listing per whitelist
Jan  9 12:37:52.637: INFO: namespace e2e-tests-prestop-75btd deletion completed in 38.040799251s

• [SLOW TEST:49.093 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:37:52.637: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-61a1a366-140b-11e9-a571-02181533b527
STEP: Creating a pod to test consume secrets
Jan  9 12:37:52.672: INFO: Waiting up to 5m0s for pod "pod-secrets-61a1db59-140b-11e9-a571-02181533b527" in namespace "e2e-tests-secrets-9nt4c" to be "success or failure"
Jan  9 12:37:52.674: INFO: Pod "pod-secrets-61a1db59-140b-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.391708ms
Jan  9 12:37:54.675: INFO: Pod "pod-secrets-61a1db59-140b-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 2.002789898s
Jan  9 12:37:56.677: INFO: Pod "pod-secrets-61a1db59-140b-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.004386211s
STEP: Saw pod success
Jan  9 12:37:56.677: INFO: Pod "pod-secrets-61a1db59-140b-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 12:37:56.678: INFO: Trying to get logs from node ip-172-31-59-90 pod pod-secrets-61a1db59-140b-11e9-a571-02181533b527 container secret-volume-test: <nil>
STEP: delete the pod
Jan  9 12:37:56.685: INFO: Waiting for pod pod-secrets-61a1db59-140b-11e9-a571-02181533b527 to disappear
Jan  9 12:37:56.686: INFO: Pod pod-secrets-61a1db59-140b-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:37:56.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-9nt4c" for this suite.
Jan  9 12:38:02.692: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:38:02.698: INFO: namespace: e2e-tests-secrets-9nt4c, resource: bindings, ignored listing per whitelist
Jan  9 12:38:02.727: INFO: namespace e2e-tests-secrets-9nt4c deletion completed in 6.039148844s

• [SLOW TEST:10.090 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:38:02.727: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Jan  9 12:38:02.761: INFO: Waiting up to 5m0s for pod "pod-67a53aba-140b-11e9-a571-02181533b527" in namespace "e2e-tests-emptydir-f7t6d" to be "success or failure"
Jan  9 12:38:02.762: INFO: Pod "pod-67a53aba-140b-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.014416ms
Jan  9 12:38:04.764: INFO: Pod "pod-67a53aba-140b-11e9-a571-02181533b527": Phase="Running", Reason="", readiness=true. Elapsed: 2.002811724s
Jan  9 12:38:06.766: INFO: Pod "pod-67a53aba-140b-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.004712459s
STEP: Saw pod success
Jan  9 12:38:06.766: INFO: Pod "pod-67a53aba-140b-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 12:38:06.767: INFO: Trying to get logs from node ip-172-31-59-90 pod pod-67a53aba-140b-11e9-a571-02181533b527 container test-container: <nil>
STEP: delete the pod
Jan  9 12:38:06.775: INFO: Waiting for pod pod-67a53aba-140b-11e9-a571-02181533b527 to disappear
Jan  9 12:38:06.776: INFO: Pod pod-67a53aba-140b-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:38:06.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-f7t6d" for this suite.
Jan  9 12:38:12.782: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:38:12.792: INFO: namespace: e2e-tests-emptydir-f7t6d, resource: bindings, ignored listing per whitelist
Jan  9 12:38:12.821: INFO: namespace e2e-tests-emptydir-f7t6d deletion completed in 6.043126083s

• [SLOW TEST:10.094 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:38:12.821: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-djcp9/configmap-test-6da950f7-140b-11e9-a571-02181533b527
STEP: Creating a pod to test consume configMaps
Jan  9 12:38:12.856: INFO: Waiting up to 5m0s for pod "pod-configmaps-6da9a14f-140b-11e9-a571-02181533b527" in namespace "e2e-tests-configmap-djcp9" to be "success or failure"
Jan  9 12:38:12.857: INFO: Pod "pod-configmaps-6da9a14f-140b-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 987.127µs
Jan  9 12:38:14.859: INFO: Pod "pod-configmaps-6da9a14f-140b-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.002810489s
STEP: Saw pod success
Jan  9 12:38:14.859: INFO: Pod "pod-configmaps-6da9a14f-140b-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 12:38:14.860: INFO: Trying to get logs from node ip-172-31-59-90 pod pod-configmaps-6da9a14f-140b-11e9-a571-02181533b527 container env-test: <nil>
STEP: delete the pod
Jan  9 12:38:14.867: INFO: Waiting for pod pod-configmaps-6da9a14f-140b-11e9-a571-02181533b527 to disappear
Jan  9 12:38:14.871: INFO: Pod pod-configmaps-6da9a14f-140b-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:38:14.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-djcp9" for this suite.
Jan  9 12:38:20.877: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:38:20.899: INFO: namespace: e2e-tests-configmap-djcp9, resource: bindings, ignored listing per whitelist
Jan  9 12:38:20.916: INFO: namespace e2e-tests-configmap-djcp9 deletion completed in 6.043597407s

• [SLOW TEST:8.095 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:38:20.916: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 pods, got 2 pods
STEP: expected 0 rs, got 1 rs
STEP: Gathering metrics
W0109 12:38:21.963975      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan  9 12:38:21.964: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:38:21.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-fl4gg" for this suite.
Jan  9 12:38:27.971: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:38:27.998: INFO: namespace: e2e-tests-gc-fl4gg, resource: bindings, ignored listing per whitelist
Jan  9 12:38:28.006: INFO: namespace e2e-tests-gc-fl4gg deletion completed in 6.039831037s

• [SLOW TEST:7.090 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:38:28.006: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:38:30.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-9kl6g" for this suite.
Jan  9 12:38:36.063: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:38:36.073: INFO: namespace: e2e-tests-emptydir-wrapper-9kl6g, resource: bindings, ignored listing per whitelist
Jan  9 12:38:36.097: INFO: namespace e2e-tests-emptydir-wrapper-9kl6g deletion completed in 6.038801419s

• [SLOW TEST:8.091 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:38:36.098: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Jan  9 12:38:36.133: INFO: Waiting up to 5m0s for pod "pod-7b89679a-140b-11e9-a571-02181533b527" in namespace "e2e-tests-emptydir-4bvj9" to be "success or failure"
Jan  9 12:38:36.134: INFO: Pod "pod-7b89679a-140b-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 992.989µs
Jan  9 12:38:38.136: INFO: Pod "pod-7b89679a-140b-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.002789721s
STEP: Saw pod success
Jan  9 12:38:38.136: INFO: Pod "pod-7b89679a-140b-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 12:38:38.137: INFO: Trying to get logs from node ip-172-31-59-90 pod pod-7b89679a-140b-11e9-a571-02181533b527 container test-container: <nil>
STEP: delete the pod
Jan  9 12:38:38.145: INFO: Waiting for pod pod-7b89679a-140b-11e9-a571-02181533b527 to disappear
Jan  9 12:38:38.147: INFO: Pod pod-7b89679a-140b-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:38:38.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-4bvj9" for this suite.
Jan  9 12:38:44.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:38:44.185: INFO: namespace: e2e-tests-emptydir-4bvj9, resource: bindings, ignored listing per whitelist
Jan  9 12:38:44.191: INFO: namespace e2e-tests-emptydir-4bvj9 deletion completed in 6.043329397s

• [SLOW TEST:8.094 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:38:44.192: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Jan  9 12:38:44.230: INFO: Waiting up to 5m0s for pod "pod-805c1ea9-140b-11e9-a571-02181533b527" in namespace "e2e-tests-emptydir-xgf5k" to be "success or failure"
Jan  9 12:38:44.231: INFO: Pod "pod-805c1ea9-140b-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.533636ms
Jan  9 12:38:46.233: INFO: Pod "pod-805c1ea9-140b-11e9-a571-02181533b527": Phase="Running", Reason="", readiness=true. Elapsed: 2.003334316s
Jan  9 12:38:48.235: INFO: Pod "pod-805c1ea9-140b-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005195343s
STEP: Saw pod success
Jan  9 12:38:48.235: INFO: Pod "pod-805c1ea9-140b-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 12:38:48.236: INFO: Trying to get logs from node ip-172-31-59-90 pod pod-805c1ea9-140b-11e9-a571-02181533b527 container test-container: <nil>
STEP: delete the pod
Jan  9 12:38:48.244: INFO: Waiting for pod pod-805c1ea9-140b-11e9-a571-02181533b527 to disappear
Jan  9 12:38:48.245: INFO: Pod pod-805c1ea9-140b-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:38:48.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-xgf5k" for this suite.
Jan  9 12:38:54.251: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:38:54.275: INFO: namespace: e2e-tests-emptydir-xgf5k, resource: bindings, ignored listing per whitelist
Jan  9 12:38:54.285: INFO: namespace e2e-tests-emptydir-xgf5k deletion completed in 6.038759325s

• [SLOW TEST:10.093 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:38:54.285: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-86603183-140b-11e9-a571-02181533b527
STEP: Creating a pod to test consume secrets
Jan  9 12:38:54.319: INFO: Waiting up to 5m0s for pod "pod-secrets-8660628c-140b-11e9-a571-02181533b527" in namespace "e2e-tests-secrets-xh5d4" to be "success or failure"
Jan  9 12:38:54.320: INFO: Pod "pod-secrets-8660628c-140b-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 989.518µs
Jan  9 12:38:56.322: INFO: Pod "pod-secrets-8660628c-140b-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 2.002766277s
Jan  9 12:38:58.324: INFO: Pod "pod-secrets-8660628c-140b-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.004718632s
STEP: Saw pod success
Jan  9 12:38:58.324: INFO: Pod "pod-secrets-8660628c-140b-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 12:38:58.325: INFO: Trying to get logs from node ip-172-31-59-90 pod pod-secrets-8660628c-140b-11e9-a571-02181533b527 container secret-volume-test: <nil>
STEP: delete the pod
Jan  9 12:38:58.332: INFO: Waiting for pod pod-secrets-8660628c-140b-11e9-a571-02181533b527 to disappear
Jan  9 12:38:58.338: INFO: Pod pod-secrets-8660628c-140b-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:38:58.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-xh5d4" for this suite.
Jan  9 12:39:04.344: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:39:04.351: INFO: namespace: e2e-tests-secrets-xh5d4, resource: bindings, ignored listing per whitelist
Jan  9 12:39:04.379: INFO: namespace e2e-tests-secrets-xh5d4 deletion completed in 6.039592614s

• [SLOW TEST:10.094 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:39:04.379: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0109 12:39:44.429758      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan  9 12:39:44.430: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:39:44.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-2d7lq" for this suite.
Jan  9 12:39:50.435: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:39:50.467: INFO: namespace: e2e-tests-gc-2d7lq, resource: bindings, ignored listing per whitelist
Jan  9 12:39:50.477: INFO: namespace e2e-tests-gc-2d7lq deletion completed in 6.045878862s

• [SLOW TEST:46.098 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:39:50.477: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jan  9 12:39:50.508: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:39:54.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-tv8q6" for this suite.
Jan  9 12:40:16.668: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:40:16.700: INFO: namespace: e2e-tests-init-container-tv8q6, resource: bindings, ignored listing per whitelist
Jan  9 12:40:16.703: INFO: namespace e2e-tests-init-container-tv8q6 deletion completed in 22.040008914s

• [SLOW TEST:26.226 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:40:16.703: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:40:20.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-tr9t5" for this suite.
Jan  9 12:40:58.754: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:40:58.778: INFO: namespace: e2e-tests-kubelet-test-tr9t5, resource: bindings, ignored listing per whitelist
Jan  9 12:40:58.792: INFO: namespace e2e-tests-kubelet-test-tr9t5 deletion completed in 38.04270705s

• [SLOW TEST:42.089 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:40:58.792: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-d096b225-140b-11e9-a571-02181533b527
STEP: Creating a pod to test consume configMaps
Jan  9 12:40:58.835: INFO: Waiting up to 5m0s for pod "pod-configmaps-d096ee17-140b-11e9-a571-02181533b527" in namespace "e2e-tests-configmap-sxbnp" to be "success or failure"
Jan  9 12:40:58.836: INFO: Pod "pod-configmaps-d096ee17-140b-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.289551ms
Jan  9 12:41:00.838: INFO: Pod "pod-configmaps-d096ee17-140b-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003095463s
STEP: Saw pod success
Jan  9 12:41:00.838: INFO: Pod "pod-configmaps-d096ee17-140b-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 12:41:00.839: INFO: Trying to get logs from node ip-172-31-59-90 pod pod-configmaps-d096ee17-140b-11e9-a571-02181533b527 container configmap-volume-test: <nil>
STEP: delete the pod
Jan  9 12:41:00.846: INFO: Waiting for pod pod-configmaps-d096ee17-140b-11e9-a571-02181533b527 to disappear
Jan  9 12:41:00.847: INFO: Pod pod-configmaps-d096ee17-140b-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:41:00.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-sxbnp" for this suite.
Jan  9 12:41:06.853: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:41:06.884: INFO: namespace: e2e-tests-configmap-sxbnp, resource: bindings, ignored listing per whitelist
Jan  9 12:41:06.890: INFO: namespace e2e-tests-configmap-sxbnp deletion completed in 6.041191162s

• [SLOW TEST:8.098 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:41:06.890: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Jan  9 12:41:08.941: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:41:32.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-zgggj" for this suite.
Jan  9 12:41:38.965: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:41:38.988: INFO: namespace: e2e-tests-namespaces-zgggj, resource: bindings, ignored listing per whitelist
Jan  9 12:41:39.004: INFO: namespace e2e-tests-namespaces-zgggj deletion completed in 6.043016672s
STEP: Destroying namespace "e2e-tests-nsdeletetest-d9z95" for this suite.
Jan  9 12:41:39.005: INFO: Namespace e2e-tests-nsdeletetest-d9z95 was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-znnf4" for this suite.
Jan  9 12:41:45.013: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:41:45.047: INFO: namespace: e2e-tests-nsdeletetest-znnf4, resource: bindings, ignored listing per whitelist
Jan  9 12:41:45.051: INFO: namespace e2e-tests-nsdeletetest-znnf4 deletion completed in 6.045971715s

• [SLOW TEST:38.161 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:41:45.051: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-dmb9
STEP: Creating a pod to test atomic-volume-subpath
Jan  9 12:41:45.088: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-dmb9" in namespace "e2e-tests-subpath-vwz72" to be "success or failure"
Jan  9 12:41:45.089: INFO: Pod "pod-subpath-test-projected-dmb9": Phase="Pending", Reason="", readiness=false. Elapsed: 1.768697ms
Jan  9 12:41:47.091: INFO: Pod "pod-subpath-test-projected-dmb9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003845039s
Jan  9 12:41:49.093: INFO: Pod "pod-subpath-test-projected-dmb9": Phase="Running", Reason="", readiness=false. Elapsed: 4.005830541s
Jan  9 12:41:51.095: INFO: Pod "pod-subpath-test-projected-dmb9": Phase="Running", Reason="", readiness=false. Elapsed: 6.007747123s
Jan  9 12:41:53.097: INFO: Pod "pod-subpath-test-projected-dmb9": Phase="Running", Reason="", readiness=false. Elapsed: 8.009500318s
Jan  9 12:41:55.099: INFO: Pod "pod-subpath-test-projected-dmb9": Phase="Running", Reason="", readiness=false. Elapsed: 10.01133693s
Jan  9 12:41:57.101: INFO: Pod "pod-subpath-test-projected-dmb9": Phase="Running", Reason="", readiness=false. Elapsed: 12.013262191s
Jan  9 12:41:59.103: INFO: Pod "pod-subpath-test-projected-dmb9": Phase="Running", Reason="", readiness=false. Elapsed: 14.015173801s
Jan  9 12:42:01.105: INFO: Pod "pod-subpath-test-projected-dmb9": Phase="Running", Reason="", readiness=false. Elapsed: 16.017156413s
Jan  9 12:42:03.107: INFO: Pod "pod-subpath-test-projected-dmb9": Phase="Running", Reason="", readiness=false. Elapsed: 18.019307596s
Jan  9 12:42:05.109: INFO: Pod "pod-subpath-test-projected-dmb9": Phase="Running", Reason="", readiness=false. Elapsed: 20.021156909s
Jan  9 12:42:07.111: INFO: Pod "pod-subpath-test-projected-dmb9": Phase="Running", Reason="", readiness=false. Elapsed: 22.023035861s
Jan  9 12:42:09.112: INFO: Pod "pod-subpath-test-projected-dmb9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.024892426s
STEP: Saw pod success
Jan  9 12:42:09.112: INFO: Pod "pod-subpath-test-projected-dmb9" satisfied condition "success or failure"
Jan  9 12:42:09.114: INFO: Trying to get logs from node ip-172-31-59-90 pod pod-subpath-test-projected-dmb9 container test-container-subpath-projected-dmb9: <nil>
STEP: delete the pod
Jan  9 12:42:09.122: INFO: Waiting for pod pod-subpath-test-projected-dmb9 to disappear
Jan  9 12:42:09.123: INFO: Pod pod-subpath-test-projected-dmb9 no longer exists
STEP: Deleting pod pod-subpath-test-projected-dmb9
Jan  9 12:42:09.123: INFO: Deleting pod "pod-subpath-test-projected-dmb9" in namespace "e2e-tests-subpath-vwz72"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:42:09.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-vwz72" for this suite.
Jan  9 12:42:15.131: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:42:15.146: INFO: namespace: e2e-tests-subpath-vwz72, resource: bindings, ignored listing per whitelist
Jan  9 12:42:15.166: INFO: namespace e2e-tests-subpath-vwz72 deletion completed in 6.040147938s

• [SLOW TEST:30.114 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:42:15.166: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan  9 12:42:15.201: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fe1c7694-140b-11e9-a571-02181533b527" in namespace "e2e-tests-projected-t5jbq" to be "success or failure"
Jan  9 12:42:15.203: INFO: Pod "downwardapi-volume-fe1c7694-140b-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.322912ms
Jan  9 12:42:17.205: INFO: Pod "downwardapi-volume-fe1c7694-140b-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003259116s
Jan  9 12:42:19.207: INFO: Pod "downwardapi-volume-fe1c7694-140b-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005227928s
STEP: Saw pod success
Jan  9 12:42:19.207: INFO: Pod "downwardapi-volume-fe1c7694-140b-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 12:42:19.208: INFO: Trying to get logs from node ip-172-31-59-90 pod downwardapi-volume-fe1c7694-140b-11e9-a571-02181533b527 container client-container: <nil>
STEP: delete the pod
Jan  9 12:42:19.216: INFO: Waiting for pod downwardapi-volume-fe1c7694-140b-11e9-a571-02181533b527 to disappear
Jan  9 12:42:19.217: INFO: Pod downwardapi-volume-fe1c7694-140b-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:42:19.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-t5jbq" for this suite.
Jan  9 12:42:25.223: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:42:25.227: INFO: namespace: e2e-tests-projected-t5jbq, resource: bindings, ignored listing per whitelist
Jan  9 12:42:25.262: INFO: namespace e2e-tests-projected-t5jbq deletion completed in 6.043147681s

• [SLOW TEST:10.096 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:42:25.262: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Jan  9 12:42:25.295: INFO: Waiting up to 5m0s for pod "client-containers-0420a50d-140c-11e9-a571-02181533b527" in namespace "e2e-tests-containers-2nm9s" to be "success or failure"
Jan  9 12:42:25.296: INFO: Pod "client-containers-0420a50d-140c-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 955.095µs
Jan  9 12:42:27.298: INFO: Pod "client-containers-0420a50d-140c-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00321818s
Jan  9 12:42:29.300: INFO: Pod "client-containers-0420a50d-140c-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005080088s
STEP: Saw pod success
Jan  9 12:42:29.300: INFO: Pod "client-containers-0420a50d-140c-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 12:42:29.301: INFO: Trying to get logs from node ip-172-31-59-90 pod client-containers-0420a50d-140c-11e9-a571-02181533b527 container test-container: <nil>
STEP: delete the pod
Jan  9 12:42:29.312: INFO: Waiting for pod client-containers-0420a50d-140c-11e9-a571-02181533b527 to disappear
Jan  9 12:42:29.313: INFO: Pod client-containers-0420a50d-140c-11e9-a571-02181533b527 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:42:29.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-2nm9s" for this suite.
Jan  9 12:42:35.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:42:35.322: INFO: namespace: e2e-tests-containers-2nm9s, resource: bindings, ignored listing per whitelist
Jan  9 12:42:35.353: INFO: namespace e2e-tests-containers-2nm9s deletion completed in 6.038896914s

• [SLOW TEST:10.091 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:42:35.353: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:42:37.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-r2kqv" for this suite.
Jan  9 12:43:27.404: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:43:27.437: INFO: namespace: e2e-tests-kubelet-test-r2kqv, resource: bindings, ignored listing per whitelist
Jan  9 12:43:27.441: INFO: namespace e2e-tests-kubelet-test-r2kqv deletion completed in 50.041635746s

• [SLOW TEST:52.088 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a read only busybox container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:186
    should not write to root filesystem [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:43:27.441: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan  9 12:43:27.474: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2930903d-140c-11e9-a571-02181533b527" in namespace "e2e-tests-downward-api-wpzvv" to be "success or failure"
Jan  9 12:43:27.476: INFO: Pod "downwardapi-volume-2930903d-140c-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.708526ms
Jan  9 12:43:29.478: INFO: Pod "downwardapi-volume-2930903d-140c-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003758579s
STEP: Saw pod success
Jan  9 12:43:29.478: INFO: Pod "downwardapi-volume-2930903d-140c-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 12:43:29.479: INFO: Trying to get logs from node ip-172-31-59-90 pod downwardapi-volume-2930903d-140c-11e9-a571-02181533b527 container client-container: <nil>
STEP: delete the pod
Jan  9 12:43:29.488: INFO: Waiting for pod downwardapi-volume-2930903d-140c-11e9-a571-02181533b527 to disappear
Jan  9 12:43:29.489: INFO: Pod downwardapi-volume-2930903d-140c-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:43:29.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-wpzvv" for this suite.
Jan  9 12:43:35.497: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:43:35.514: INFO: namespace: e2e-tests-downward-api-wpzvv, resource: bindings, ignored listing per whitelist
Jan  9 12:43:35.533: INFO: namespace e2e-tests-downward-api-wpzvv deletion completed in 6.042460957s

• [SLOW TEST:8.092 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:43:35.533: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:43:39.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-tsj4g" for this suite.
Jan  9 12:43:45.578: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:43:45.599: INFO: namespace: e2e-tests-kubelet-test-tsj4g, resource: bindings, ignored listing per whitelist
Jan  9 12:43:45.613: INFO: namespace e2e-tests-kubelet-test-tsj4g deletion completed in 6.039101472s

• [SLOW TEST:10.080 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:43:45.613: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan  9 12:43:45.647: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-jddk5'
Jan  9 12:43:45.875: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jan  9 12:43:45.875: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1268
Jan  9 12:43:45.879: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-jddk5'
Jan  9 12:43:45.950: INFO: stderr: ""
Jan  9 12:43:45.950: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:43:45.950: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-jddk5" for this suite.
Jan  9 12:43:51.958: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:43:51.989: INFO: namespace: e2e-tests-kubectl-jddk5, resource: bindings, ignored listing per whitelist
Jan  9 12:43:51.996: INFO: namespace e2e-tests-kubectl-jddk5 deletion completed in 6.044670106s

• [SLOW TEST:6.383 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:43:51.996: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan  9 12:43:52.026: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:43:54.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-4j4xh" for this suite.
Jan  9 12:44:32.110: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:44:32.137: INFO: namespace: e2e-tests-pods-4j4xh, resource: bindings, ignored listing per whitelist
Jan  9 12:44:32.149: INFO: namespace e2e-tests-pods-4j4xh deletion completed in 38.042967039s

• [SLOW TEST:40.153 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:44:32.149: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan  9 12:44:32.184: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Jan  9 12:44:37.186: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jan  9 12:44:37.187: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan  9 12:44:37.194: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-xntmz,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-xntmz/deployments/test-cleanup-deployment,UID:52be9166-140c-11e9-90b5-12841864fc48,ResourceVersion:8279,Generation:1,CreationTimestamp:2019-01-09 12:44:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Jan  9 12:44:37.199: INFO: New ReplicaSet "test-cleanup-deployment-7dbbfcf846" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-7dbbfcf846,GenerateName:,Namespace:e2e-tests-deployment-xntmz,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-xntmz/replicasets/test-cleanup-deployment-7dbbfcf846,UID:52bf7753-140c-11e9-90b5-12841864fc48,ResourceVersion:8281,Generation:1,CreationTimestamp:2019-01-09 12:44:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 52be9166-140c-11e9-90b5-12841864fc48 0xc001ca63a7 0xc001ca63a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan  9 12:44:37.199: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Jan  9 12:44:37.199: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:e2e-tests-deployment-xntmz,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-xntmz/replicasets/test-cleanup-controller,UID:4fc299c5-140c-11e9-90b5-12841864fc48,ResourceVersion:8280,Generation:1,CreationTimestamp:2019-01-09 12:44:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 52be9166-140c-11e9-90b5-12841864fc48 0xc001ca621f 0xc001ca6230}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jan  9 12:44:37.201: INFO: Pod "test-cleanup-controller-8b99c" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-8b99c,GenerateName:test-cleanup-controller-,Namespace:e2e-tests-deployment-xntmz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xntmz/pods/test-cleanup-controller-8b99c,UID:4fc2f414-140c-11e9-90b5-12841864fc48,ResourceVersion:8274,Generation:0,CreationTimestamp:2019-01-09 12:44:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller 4fc299c5-140c-11e9-90b5-12841864fc48 0xc001ee291f 0xc001ee2930}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-bsn54 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bsn54,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bsn54 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-59-90,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ee29a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ee29c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 12:44:32 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 12:44:34 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 12:44:34 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 12:44:32 +0000 UTC  }],Message:,Reason:,HostIP:172.31.59.90,PodIP:10.1.1.150,StartTime:2019-01-09 12:44:32 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-09 12:44:33 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://cb0b2682a78a6e7479311bf1a27c74a957fa2d28f85dd526a5d087334c1d3bb8}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 12:44:37.201: INFO: Pod "test-cleanup-deployment-7dbbfcf846-wtqx5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-7dbbfcf846-wtqx5,GenerateName:test-cleanup-deployment-7dbbfcf846-,Namespace:e2e-tests-deployment-xntmz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xntmz/pods/test-cleanup-deployment-7dbbfcf846-wtqx5,UID:52bfb9ba-140c-11e9-90b5-12841864fc48,ResourceVersion:8282,Generation:0,CreationTimestamp:2019-01-09 12:44:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-7dbbfcf846 52bf7753-140c-11e9-90b5-12841864fc48 0xc001ee2a87 0xc001ee2a88}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-bsn54 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bsn54,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-bsn54 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ee2af0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ee2b10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:44:37.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-xntmz" for this suite.
Jan  9 12:44:43.210: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:44:43.216: INFO: namespace: e2e-tests-deployment-xntmz, resource: bindings, ignored listing per whitelist
Jan  9 12:44:43.247: INFO: namespace e2e-tests-deployment-xntmz deletion completed in 6.043658857s

• [SLOW TEST:11.098 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:44:43.247: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-565fa26f-140c-11e9-a571-02181533b527
STEP: Creating a pod to test consume secrets
Jan  9 12:44:43.282: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-565fd6c5-140c-11e9-a571-02181533b527" in namespace "e2e-tests-projected-pnq66" to be "success or failure"
Jan  9 12:44:43.283: INFO: Pod "pod-projected-secrets-565fd6c5-140c-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.574275ms
Jan  9 12:44:45.285: INFO: Pod "pod-projected-secrets-565fd6c5-140c-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003420179s
Jan  9 12:44:47.287: INFO: Pod "pod-projected-secrets-565fd6c5-140c-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005657259s
STEP: Saw pod success
Jan  9 12:44:47.287: INFO: Pod "pod-projected-secrets-565fd6c5-140c-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 12:44:47.289: INFO: Trying to get logs from node ip-172-31-59-90 pod pod-projected-secrets-565fd6c5-140c-11e9-a571-02181533b527 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan  9 12:44:47.296: INFO: Waiting for pod pod-projected-secrets-565fd6c5-140c-11e9-a571-02181533b527 to disappear
Jan  9 12:44:47.297: INFO: Pod pod-projected-secrets-565fd6c5-140c-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:44:47.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pnq66" for this suite.
Jan  9 12:44:53.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:44:53.328: INFO: namespace: e2e-tests-projected-pnq66, resource: bindings, ignored listing per whitelist
Jan  9 12:44:53.338: INFO: namespace e2e-tests-projected-pnq66 deletion completed in 6.039805823s

• [SLOW TEST:10.091 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:44:53.338: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Jan  9 12:44:53.379: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-z4hqq,SelfLink:/api/v1/namespaces/e2e-tests-watch-z4hqq/configmaps/e2e-watch-test-resource-version,UID:5c639e32-140c-11e9-90b5-12841864fc48,ResourceVersion:8372,Generation:0,CreationTimestamp:2019-01-09 12:44:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan  9 12:44:53.379: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-z4hqq,SelfLink:/api/v1/namespaces/e2e-tests-watch-z4hqq/configmaps/e2e-watch-test-resource-version,UID:5c639e32-140c-11e9-90b5-12841864fc48,ResourceVersion:8373,Generation:0,CreationTimestamp:2019-01-09 12:44:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:44:53.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-z4hqq" for this suite.
Jan  9 12:44:59.385: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:44:59.418: INFO: namespace: e2e-tests-watch-z4hqq, resource: bindings, ignored listing per whitelist
Jan  9 12:44:59.423: INFO: namespace e2e-tests-watch-z4hqq deletion completed in 6.042861633s

• [SLOW TEST:6.085 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:44:59.423: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Jan  9 12:45:03.470: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan  9 12:45:03.473: INFO: Pod pod-with-prestop-exec-hook still exists
Jan  9 12:45:05.474: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan  9 12:45:05.476: INFO: Pod pod-with-prestop-exec-hook still exists
Jan  9 12:45:07.473: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan  9 12:45:07.475: INFO: Pod pod-with-prestop-exec-hook still exists
Jan  9 12:45:09.473: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan  9 12:45:09.475: INFO: Pod pod-with-prestop-exec-hook still exists
Jan  9 12:45:11.473: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan  9 12:45:11.475: INFO: Pod pod-with-prestop-exec-hook still exists
Jan  9 12:45:13.474: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan  9 12:45:13.475: INFO: Pod pod-with-prestop-exec-hook still exists
Jan  9 12:45:15.473: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan  9 12:45:15.475: INFO: Pod pod-with-prestop-exec-hook still exists
Jan  9 12:45:17.473: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan  9 12:45:17.475: INFO: Pod pod-with-prestop-exec-hook still exists
Jan  9 12:45:19.473: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan  9 12:45:19.475: INFO: Pod pod-with-prestop-exec-hook still exists
Jan  9 12:45:21.473: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan  9 12:45:21.475: INFO: Pod pod-with-prestop-exec-hook still exists
Jan  9 12:45:23.473: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan  9 12:45:23.475: INFO: Pod pod-with-prestop-exec-hook still exists
Jan  9 12:45:25.473: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan  9 12:45:25.475: INFO: Pod pod-with-prestop-exec-hook still exists
Jan  9 12:45:27.473: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan  9 12:45:27.475: INFO: Pod pod-with-prestop-exec-hook still exists
Jan  9 12:45:29.473: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan  9 12:45:29.475: INFO: Pod pod-with-prestop-exec-hook still exists
Jan  9 12:45:31.473: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan  9 12:45:31.475: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:45:31.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-vdzpr" for this suite.
Jan  9 12:45:53.485: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:45:53.496: INFO: namespace: e2e-tests-container-lifecycle-hook-vdzpr, resource: bindings, ignored listing per whitelist
Jan  9 12:45:53.523: INFO: namespace e2e-tests-container-lifecycle-hook-vdzpr deletion completed in 22.041746638s

• [SLOW TEST:54.099 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:45:53.523: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-80431c07-140c-11e9-a571-02181533b527
STEP: Creating secret with name s-test-opt-upd-80431c50-140c-11e9-a571-02181533b527
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-80431c07-140c-11e9-a571-02181533b527
STEP: Updating secret s-test-opt-upd-80431c50-140c-11e9-a571-02181533b527
STEP: Creating secret with name s-test-opt-create-80431c6c-140c-11e9-a571-02181533b527
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:46:59.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-j4x4v" for this suite.
Jan  9 12:47:21.763: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:47:21.784: INFO: namespace: e2e-tests-secrets-j4x4v, resource: bindings, ignored listing per whitelist
Jan  9 12:47:21.800: INFO: namespace e2e-tests-secrets-j4x4v deletion completed in 22.041122001s

• [SLOW TEST:88.277 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:47:21.800: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan  9 12:47:21.836: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Jan  9 12:47:21.839: INFO: Number of nodes with available pods: 0
Jan  9 12:47:21.839: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Jan  9 12:47:21.847: INFO: Number of nodes with available pods: 0
Jan  9 12:47:21.847: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:47:22.848: INFO: Number of nodes with available pods: 0
Jan  9 12:47:22.848: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:47:23.849: INFO: Number of nodes with available pods: 1
Jan  9 12:47:23.849: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Jan  9 12:47:23.855: INFO: Number of nodes with available pods: 1
Jan  9 12:47:23.855: INFO: Number of running nodes: 0, number of available pods: 1
Jan  9 12:47:24.857: INFO: Number of nodes with available pods: 0
Jan  9 12:47:24.857: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Jan  9 12:47:24.863: INFO: Number of nodes with available pods: 0
Jan  9 12:47:24.863: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:47:25.864: INFO: Number of nodes with available pods: 0
Jan  9 12:47:25.864: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:47:26.865: INFO: Number of nodes with available pods: 0
Jan  9 12:47:26.865: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:47:27.865: INFO: Number of nodes with available pods: 0
Jan  9 12:47:27.865: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:47:28.865: INFO: Number of nodes with available pods: 0
Jan  9 12:47:28.865: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:47:29.865: INFO: Number of nodes with available pods: 0
Jan  9 12:47:29.865: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:47:30.865: INFO: Number of nodes with available pods: 0
Jan  9 12:47:30.865: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:47:31.865: INFO: Number of nodes with available pods: 0
Jan  9 12:47:31.865: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:47:32.865: INFO: Number of nodes with available pods: 0
Jan  9 12:47:32.865: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:47:33.865: INFO: Number of nodes with available pods: 0
Jan  9 12:47:33.865: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:47:34.865: INFO: Number of nodes with available pods: 0
Jan  9 12:47:34.865: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:47:35.865: INFO: Number of nodes with available pods: 0
Jan  9 12:47:35.865: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:47:36.864: INFO: Number of nodes with available pods: 0
Jan  9 12:47:36.865: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:47:37.864: INFO: Number of nodes with available pods: 0
Jan  9 12:47:37.864: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:47:38.865: INFO: Number of nodes with available pods: 0
Jan  9 12:47:38.865: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:47:39.864: INFO: Number of nodes with available pods: 0
Jan  9 12:47:39.864: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:47:40.864: INFO: Number of nodes with available pods: 0
Jan  9 12:47:40.864: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:47:41.865: INFO: Number of nodes with available pods: 0
Jan  9 12:47:41.865: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:47:42.864: INFO: Number of nodes with available pods: 0
Jan  9 12:47:42.864: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:47:43.865: INFO: Number of nodes with available pods: 0
Jan  9 12:47:43.865: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:47:44.864: INFO: Number of nodes with available pods: 0
Jan  9 12:47:44.864: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:47:45.865: INFO: Number of nodes with available pods: 0
Jan  9 12:47:45.865: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:47:46.864: INFO: Number of nodes with available pods: 0
Jan  9 12:47:46.864: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:47:47.864: INFO: Number of nodes with available pods: 0
Jan  9 12:47:47.865: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:47:48.865: INFO: Number of nodes with available pods: 0
Jan  9 12:47:48.865: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:47:49.864: INFO: Number of nodes with available pods: 0
Jan  9 12:47:49.865: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:47:50.864: INFO: Number of nodes with available pods: 0
Jan  9 12:47:50.864: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:47:51.865: INFO: Number of nodes with available pods: 0
Jan  9 12:47:51.865: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:47:52.864: INFO: Number of nodes with available pods: 0
Jan  9 12:47:52.864: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:47:53.865: INFO: Number of nodes with available pods: 0
Jan  9 12:47:53.865: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:47:54.865: INFO: Number of nodes with available pods: 0
Jan  9 12:47:54.865: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:47:55.864: INFO: Number of nodes with available pods: 0
Jan  9 12:47:55.864: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:47:56.865: INFO: Number of nodes with available pods: 0
Jan  9 12:47:56.865: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:47:57.864: INFO: Number of nodes with available pods: 0
Jan  9 12:47:57.865: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:47:58.865: INFO: Number of nodes with available pods: 0
Jan  9 12:47:58.865: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:47:59.865: INFO: Number of nodes with available pods: 0
Jan  9 12:47:59.865: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:48:00.865: INFO: Number of nodes with available pods: 0
Jan  9 12:48:00.865: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:48:01.864: INFO: Number of nodes with available pods: 0
Jan  9 12:48:01.864: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:48:02.865: INFO: Number of nodes with available pods: 0
Jan  9 12:48:02.865: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:48:03.865: INFO: Number of nodes with available pods: 1
Jan  9 12:48:03.865: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-hr28t, will wait for the garbage collector to delete the pods
Jan  9 12:48:03.922: INFO: Deleting DaemonSet.extensions daemon-set took: 3.600646ms
Jan  9 12:48:04.022: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.228994ms
Jan  9 12:48:37.324: INFO: Number of nodes with available pods: 0
Jan  9 12:48:37.324: INFO: Number of running nodes: 0, number of available pods: 0
Jan  9 12:48:37.325: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-hr28t/daemonsets","resourceVersion":"8789"},"items":null}

Jan  9 12:48:37.326: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-hr28t/pods","resourceVersion":"8789"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:48:37.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-hr28t" for this suite.
Jan  9 12:48:43.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:48:43.341: INFO: namespace: e2e-tests-daemonsets-hr28t, resource: bindings, ignored listing per whitelist
Jan  9 12:48:43.373: INFO: namespace e2e-tests-daemonsets-hr28t deletion completed in 6.040689828s

• [SLOW TEST:81.573 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:48:43.373: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Jan  9 12:48:43.403: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 create -f - --namespace=e2e-tests-kubectl-h92st'
Jan  9 12:48:43.537: INFO: stderr: ""
Jan  9 12:48:43.537: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan  9 12:48:43.537: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-h92st'
Jan  9 12:48:43.598: INFO: stderr: ""
Jan  9 12:48:43.598: INFO: stdout: "update-demo-nautilus-brzsb update-demo-nautilus-sd957 "
Jan  9 12:48:43.598: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 get pods update-demo-nautilus-brzsb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-h92st'
Jan  9 12:48:43.656: INFO: stderr: ""
Jan  9 12:48:43.656: INFO: stdout: ""
Jan  9 12:48:43.656: INFO: update-demo-nautilus-brzsb is created but not running
Jan  9 12:48:48.657: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-h92st'
Jan  9 12:48:48.720: INFO: stderr: ""
Jan  9 12:48:48.720: INFO: stdout: "update-demo-nautilus-brzsb update-demo-nautilus-sd957 "
Jan  9 12:48:48.720: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 get pods update-demo-nautilus-brzsb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-h92st'
Jan  9 12:48:48.780: INFO: stderr: ""
Jan  9 12:48:48.780: INFO: stdout: "true"
Jan  9 12:48:48.780: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 get pods update-demo-nautilus-brzsb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-h92st'
Jan  9 12:48:48.840: INFO: stderr: ""
Jan  9 12:48:48.840: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan  9 12:48:48.840: INFO: validating pod update-demo-nautilus-brzsb
Jan  9 12:48:48.842: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan  9 12:48:48.842: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan  9 12:48:48.842: INFO: update-demo-nautilus-brzsb is verified up and running
Jan  9 12:48:48.842: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 get pods update-demo-nautilus-sd957 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-h92st'
Jan  9 12:48:48.902: INFO: stderr: ""
Jan  9 12:48:48.902: INFO: stdout: "true"
Jan  9 12:48:48.902: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 get pods update-demo-nautilus-sd957 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-h92st'
Jan  9 12:48:48.964: INFO: stderr: ""
Jan  9 12:48:48.964: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan  9 12:48:48.964: INFO: validating pod update-demo-nautilus-sd957
Jan  9 12:48:48.966: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan  9 12:48:48.967: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan  9 12:48:48.967: INFO: update-demo-nautilus-sd957 is verified up and running
STEP: rolling-update to new replication controller
Jan  9 12:48:48.968: INFO: scanned /root for discovery docs: <nil>
Jan  9 12:48:48.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-h92st'
Jan  9 12:49:11.206: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Jan  9 12:49:11.206: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan  9 12:49:11.206: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-h92st'
Jan  9 12:49:11.272: INFO: stderr: ""
Jan  9 12:49:11.272: INFO: stdout: "update-demo-kitten-gbgmw update-demo-kitten-mbtrw "
Jan  9 12:49:11.272: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 get pods update-demo-kitten-gbgmw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-h92st'
Jan  9 12:49:11.333: INFO: stderr: ""
Jan  9 12:49:11.333: INFO: stdout: "true"
Jan  9 12:49:11.333: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 get pods update-demo-kitten-gbgmw -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-h92st'
Jan  9 12:49:11.398: INFO: stderr: ""
Jan  9 12:49:11.398: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Jan  9 12:49:11.398: INFO: validating pod update-demo-kitten-gbgmw
Jan  9 12:49:11.400: INFO: got data: {
  "image": "kitten.jpg"
}

Jan  9 12:49:11.400: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Jan  9 12:49:11.400: INFO: update-demo-kitten-gbgmw is verified up and running
Jan  9 12:49:11.400: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 get pods update-demo-kitten-mbtrw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-h92st'
Jan  9 12:49:11.460: INFO: stderr: ""
Jan  9 12:49:11.460: INFO: stdout: "true"
Jan  9 12:49:11.460: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 get pods update-demo-kitten-mbtrw -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-h92st'
Jan  9 12:49:11.519: INFO: stderr: ""
Jan  9 12:49:11.519: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Jan  9 12:49:11.519: INFO: validating pod update-demo-kitten-mbtrw
Jan  9 12:49:11.521: INFO: got data: {
  "image": "kitten.jpg"
}

Jan  9 12:49:11.521: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Jan  9 12:49:11.521: INFO: update-demo-kitten-mbtrw is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:49:11.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-h92st" for this suite.
Jan  9 12:49:33.527: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:49:33.532: INFO: namespace: e2e-tests-kubectl-h92st, resource: bindings, ignored listing per whitelist
Jan  9 12:49:33.564: INFO: namespace e2e-tests-kubectl-h92st deletion completed in 22.04161111s

• [SLOW TEST:50.191 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:49:33.564: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-036a78b3-140d-11e9-a571-02181533b527
STEP: Creating a pod to test consume secrets
Jan  9 12:49:33.598: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-036aae14-140d-11e9-a571-02181533b527" in namespace "e2e-tests-projected-nnp6z" to be "success or failure"
Jan  9 12:49:33.599: INFO: Pod "pod-projected-secrets-036aae14-140d-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.031395ms
Jan  9 12:49:35.601: INFO: Pod "pod-projected-secrets-036aae14-140d-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.002749694s
STEP: Saw pod success
Jan  9 12:49:35.601: INFO: Pod "pod-projected-secrets-036aae14-140d-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 12:49:35.602: INFO: Trying to get logs from node ip-172-31-59-90 pod pod-projected-secrets-036aae14-140d-11e9-a571-02181533b527 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan  9 12:49:35.613: INFO: Waiting for pod pod-projected-secrets-036aae14-140d-11e9-a571-02181533b527 to disappear
Jan  9 12:49:35.614: INFO: Pod pod-projected-secrets-036aae14-140d-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:49:35.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-nnp6z" for this suite.
Jan  9 12:49:41.619: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:49:41.625: INFO: namespace: e2e-tests-projected-nnp6z, resource: bindings, ignored listing per whitelist
Jan  9 12:49:41.655: INFO: namespace e2e-tests-projected-nnp6z deletion completed in 6.040185091s

• [SLOW TEST:8.091 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:49:41.656: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan  9 12:49:41.689: INFO: Waiting up to 5m0s for pod "downwardapi-volume-083d333e-140d-11e9-a571-02181533b527" in namespace "e2e-tests-projected-7wmvl" to be "success or failure"
Jan  9 12:49:41.690: INFO: Pod "downwardapi-volume-083d333e-140d-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.024115ms
Jan  9 12:49:43.692: INFO: Pod "downwardapi-volume-083d333e-140d-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.002674579s
STEP: Saw pod success
Jan  9 12:49:43.692: INFO: Pod "downwardapi-volume-083d333e-140d-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 12:49:43.693: INFO: Trying to get logs from node ip-172-31-59-90 pod downwardapi-volume-083d333e-140d-11e9-a571-02181533b527 container client-container: <nil>
STEP: delete the pod
Jan  9 12:49:43.701: INFO: Waiting for pod downwardapi-volume-083d333e-140d-11e9-a571-02181533b527 to disappear
Jan  9 12:49:43.702: INFO: Pod downwardapi-volume-083d333e-140d-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:49:43.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7wmvl" for this suite.
Jan  9 12:49:49.708: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:49:49.721: INFO: namespace: e2e-tests-projected-7wmvl, resource: bindings, ignored listing per whitelist
Jan  9 12:49:49.747: INFO: namespace e2e-tests-projected-7wmvl deletion completed in 6.043742288s

• [SLOW TEST:8.092 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:49:49.748: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Jan  9 12:49:53.794: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan  9 12:49:53.796: INFO: Pod pod-with-prestop-http-hook still exists
Jan  9 12:49:55.796: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan  9 12:49:55.798: INFO: Pod pod-with-prestop-http-hook still exists
Jan  9 12:49:57.796: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan  9 12:49:57.798: INFO: Pod pod-with-prestop-http-hook still exists
Jan  9 12:49:59.796: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan  9 12:49:59.798: INFO: Pod pod-with-prestop-http-hook still exists
Jan  9 12:50:01.796: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan  9 12:50:01.798: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:50:01.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-w2ssn" for this suite.
Jan  9 12:50:23.812: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:50:23.827: INFO: namespace: e2e-tests-container-lifecycle-hook-w2ssn, resource: bindings, ignored listing per whitelist
Jan  9 12:50:23.849: INFO: namespace e2e-tests-container-lifecycle-hook-w2ssn deletion completed in 22.045899182s

• [SLOW TEST:34.102 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:50:23.849: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-2163dd54-140d-11e9-a571-02181533b527
STEP: Creating a pod to test consume secrets
Jan  9 12:50:23.887: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-21641c56-140d-11e9-a571-02181533b527" in namespace "e2e-tests-projected-nv9qc" to be "success or failure"
Jan  9 12:50:23.888: INFO: Pod "pod-projected-secrets-21641c56-140d-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.028087ms
Jan  9 12:50:25.890: INFO: Pod "pod-projected-secrets-21641c56-140d-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00295617s
Jan  9 12:50:27.892: INFO: Pod "pod-projected-secrets-21641c56-140d-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.004883567s
STEP: Saw pod success
Jan  9 12:50:27.892: INFO: Pod "pod-projected-secrets-21641c56-140d-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 12:50:27.893: INFO: Trying to get logs from node ip-172-31-59-90 pod pod-projected-secrets-21641c56-140d-11e9-a571-02181533b527 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan  9 12:50:27.903: INFO: Waiting for pod pod-projected-secrets-21641c56-140d-11e9-a571-02181533b527 to disappear
Jan  9 12:50:27.904: INFO: Pod pod-projected-secrets-21641c56-140d-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:50:27.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-nv9qc" for this suite.
Jan  9 12:50:33.910: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:50:33.927: INFO: namespace: e2e-tests-projected-nv9qc, resource: bindings, ignored listing per whitelist
Jan  9 12:50:33.946: INFO: namespace e2e-tests-projected-nv9qc deletion completed in 6.040289122s

• [SLOW TEST:10.096 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:50:33.946: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Jan  9 12:50:33.980: INFO: Pod name pod-release: Found 0 pods out of 1
Jan  9 12:50:38.982: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:50:39.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-xvmvw" for this suite.
Jan  9 12:50:45.996: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:50:46.014: INFO: namespace: e2e-tests-replication-controller-xvmvw, resource: bindings, ignored listing per whitelist
Jan  9 12:50:46.032: INFO: namespace e2e-tests-replication-controller-xvmvw deletion completed in 6.041828385s

• [SLOW TEST:12.086 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:50:46.032: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan  9 12:50:46.072: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Jan  9 12:50:46.077: INFO: Number of nodes with available pods: 0
Jan  9 12:50:46.077: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:50:47.080: INFO: Number of nodes with available pods: 0
Jan  9 12:50:47.080: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:50:48.080: INFO: Number of nodes with available pods: 0
Jan  9 12:50:48.080: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:50:49.080: INFO: Number of nodes with available pods: 1
Jan  9 12:50:49.080: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Jan  9 12:50:49.089: INFO: Wrong image for pod: daemon-set-t79zs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 12:50:50.094: INFO: Wrong image for pod: daemon-set-t79zs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 12:50:51.094: INFO: Wrong image for pod: daemon-set-t79zs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 12:50:52.094: INFO: Wrong image for pod: daemon-set-t79zs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 12:50:53.094: INFO: Wrong image for pod: daemon-set-t79zs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 12:50:54.094: INFO: Wrong image for pod: daemon-set-t79zs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 12:50:55.094: INFO: Wrong image for pod: daemon-set-t79zs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 12:50:56.094: INFO: Wrong image for pod: daemon-set-t79zs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 12:50:57.094: INFO: Wrong image for pod: daemon-set-t79zs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 12:50:58.094: INFO: Wrong image for pod: daemon-set-t79zs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 12:50:59.094: INFO: Wrong image for pod: daemon-set-t79zs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 12:51:00.094: INFO: Wrong image for pod: daemon-set-t79zs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 12:51:01.094: INFO: Wrong image for pod: daemon-set-t79zs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 12:51:02.094: INFO: Wrong image for pod: daemon-set-t79zs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 12:51:03.094: INFO: Wrong image for pod: daemon-set-t79zs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 12:51:04.094: INFO: Wrong image for pod: daemon-set-t79zs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 12:51:05.094: INFO: Wrong image for pod: daemon-set-t79zs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 12:51:06.094: INFO: Wrong image for pod: daemon-set-t79zs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 12:51:07.094: INFO: Wrong image for pod: daemon-set-t79zs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 12:51:08.094: INFO: Wrong image for pod: daemon-set-t79zs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 12:51:09.094: INFO: Wrong image for pod: daemon-set-t79zs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 12:51:10.094: INFO: Wrong image for pod: daemon-set-t79zs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 12:51:11.094: INFO: Wrong image for pod: daemon-set-t79zs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 12:51:12.094: INFO: Wrong image for pod: daemon-set-t79zs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 12:51:13.094: INFO: Wrong image for pod: daemon-set-t79zs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 12:51:14.093: INFO: Wrong image for pod: daemon-set-t79zs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 12:51:15.094: INFO: Wrong image for pod: daemon-set-t79zs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 12:51:16.094: INFO: Wrong image for pod: daemon-set-t79zs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 12:51:17.094: INFO: Wrong image for pod: daemon-set-t79zs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 12:51:18.094: INFO: Wrong image for pod: daemon-set-t79zs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 12:51:19.094: INFO: Wrong image for pod: daemon-set-t79zs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 12:51:20.094: INFO: Wrong image for pod: daemon-set-t79zs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 12:51:21.094: INFO: Wrong image for pod: daemon-set-t79zs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 12:51:22.094: INFO: Wrong image for pod: daemon-set-t79zs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 12:51:22.094: INFO: Pod daemon-set-t79zs is not available
Jan  9 12:51:23.094: INFO: Wrong image for pod: daemon-set-t79zs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 12:51:23.094: INFO: Pod daemon-set-t79zs is not available
Jan  9 12:51:24.094: INFO: Wrong image for pod: daemon-set-t79zs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 12:51:24.094: INFO: Pod daemon-set-t79zs is not available
Jan  9 12:51:25.094: INFO: Wrong image for pod: daemon-set-t79zs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 12:51:25.094: INFO: Pod daemon-set-t79zs is not available
Jan  9 12:51:26.094: INFO: Wrong image for pod: daemon-set-t79zs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 12:51:26.094: INFO: Pod daemon-set-t79zs is not available
Jan  9 12:51:27.094: INFO: Wrong image for pod: daemon-set-t79zs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 12:51:27.094: INFO: Pod daemon-set-t79zs is not available
Jan  9 12:51:28.094: INFO: Wrong image for pod: daemon-set-t79zs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 12:51:28.094: INFO: Pod daemon-set-t79zs is not available
Jan  9 12:51:29.094: INFO: Wrong image for pod: daemon-set-t79zs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 12:51:29.094: INFO: Pod daemon-set-t79zs is not available
Jan  9 12:51:30.094: INFO: Wrong image for pod: daemon-set-t79zs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 12:51:30.094: INFO: Pod daemon-set-t79zs is not available
Jan  9 12:51:31.094: INFO: Pod daemon-set-s2jh9 is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Jan  9 12:51:31.097: INFO: Number of nodes with available pods: 0
Jan  9 12:51:31.097: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:51:32.101: INFO: Number of nodes with available pods: 0
Jan  9 12:51:32.101: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 12:51:33.101: INFO: Number of nodes with available pods: 1
Jan  9 12:51:33.101: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-2v57q, will wait for the garbage collector to delete the pods
Jan  9 12:51:33.162: INFO: Deleting DaemonSet.extensions daemon-set took: 2.994641ms
Jan  9 12:51:33.262: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.339097ms
Jan  9 12:51:40.964: INFO: Number of nodes with available pods: 0
Jan  9 12:51:40.964: INFO: Number of running nodes: 0, number of available pods: 0
Jan  9 12:51:40.965: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-2v57q/daemonsets","resourceVersion":"9375"},"items":null}

Jan  9 12:51:40.966: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-2v57q/pods","resourceVersion":"9375"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:51:40.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-2v57q" for this suite.
Jan  9 12:51:46.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:51:46.995: INFO: namespace: e2e-tests-daemonsets-2v57q, resource: bindings, ignored listing per whitelist
Jan  9 12:51:47.011: INFO: namespace e2e-tests-daemonsets-2v57q deletion completed in 6.041832186s

• [SLOW TEST:60.979 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:51:47.011: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan  9 12:51:47.045: INFO: Waiting up to 5m0s for pod "downwardapi-volume-52f50bef-140d-11e9-a571-02181533b527" in namespace "e2e-tests-projected-pz9s2" to be "success or failure"
Jan  9 12:51:47.046: INFO: Pod "downwardapi-volume-52f50bef-140d-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.039552ms
Jan  9 12:51:49.048: INFO: Pod "downwardapi-volume-52f50bef-140d-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.002828036s
STEP: Saw pod success
Jan  9 12:51:49.048: INFO: Pod "downwardapi-volume-52f50bef-140d-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 12:51:49.049: INFO: Trying to get logs from node ip-172-31-59-90 pod downwardapi-volume-52f50bef-140d-11e9-a571-02181533b527 container client-container: <nil>
STEP: delete the pod
Jan  9 12:51:49.057: INFO: Waiting for pod downwardapi-volume-52f50bef-140d-11e9-a571-02181533b527 to disappear
Jan  9 12:51:49.060: INFO: Pod downwardapi-volume-52f50bef-140d-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:51:49.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pz9s2" for this suite.
Jan  9 12:51:55.065: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:51:55.078: INFO: namespace: e2e-tests-projected-pz9s2, resource: bindings, ignored listing per whitelist
Jan  9 12:51:55.100: INFO: namespace e2e-tests-projected-pz9s2 deletion completed in 6.038959189s

• [SLOW TEST:8.089 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:51:55.100: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-57c74d48-140d-11e9-a571-02181533b527
STEP: Creating a pod to test consume configMaps
Jan  9 12:51:55.135: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-57c7847b-140d-11e9-a571-02181533b527" in namespace "e2e-tests-projected-c5rld" to be "success or failure"
Jan  9 12:51:55.136: INFO: Pod "pod-projected-configmaps-57c7847b-140d-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 950.724µs
Jan  9 12:51:57.138: INFO: Pod "pod-projected-configmaps-57c7847b-140d-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.002785281s
STEP: Saw pod success
Jan  9 12:51:57.138: INFO: Pod "pod-projected-configmaps-57c7847b-140d-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 12:51:57.139: INFO: Trying to get logs from node ip-172-31-59-90 pod pod-projected-configmaps-57c7847b-140d-11e9-a571-02181533b527 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan  9 12:51:57.146: INFO: Waiting for pod pod-projected-configmaps-57c7847b-140d-11e9-a571-02181533b527 to disappear
Jan  9 12:51:57.147: INFO: Pod pod-projected-configmaps-57c7847b-140d-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:51:57.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-c5rld" for this suite.
Jan  9 12:52:03.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:52:03.171: INFO: namespace: e2e-tests-projected-c5rld, resource: bindings, ignored listing per whitelist
Jan  9 12:52:03.194: INFO: namespace e2e-tests-projected-c5rld deletion completed in 6.045171626s

• [SLOW TEST:8.094 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:52:03.194: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Jan  9 12:52:03.228: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-swnhs" to be "success or failure"
Jan  9 12:52:03.229: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 1.219638ms
Jan  9 12:52:05.231: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003019139s
STEP: Saw pod success
Jan  9 12:52:05.231: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Jan  9 12:52:05.232: INFO: Trying to get logs from node ip-172-31-59-90 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Jan  9 12:52:05.246: INFO: Waiting for pod pod-host-path-test to disappear
Jan  9 12:52:05.247: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:52:05.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-swnhs" for this suite.
Jan  9 12:52:11.253: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:52:11.262: INFO: namespace: e2e-tests-hostpath-swnhs, resource: bindings, ignored listing per whitelist
Jan  9 12:52:11.289: INFO: namespace e2e-tests-hostpath-swnhs deletion completed in 6.039965796s

• [SLOW TEST:8.095 seconds]
[sig-storage] HostPath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:52:11.289: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-616dd008-140d-11e9-a571-02181533b527
STEP: Creating a pod to test consume configMaps
Jan  9 12:52:11.326: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-616e0732-140d-11e9-a571-02181533b527" in namespace "e2e-tests-projected-5ppjh" to be "success or failure"
Jan  9 12:52:11.327: INFO: Pod "pod-projected-configmaps-616e0732-140d-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 976.495µs
Jan  9 12:52:13.329: INFO: Pod "pod-projected-configmaps-616e0732-140d-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.002653571s
STEP: Saw pod success
Jan  9 12:52:13.329: INFO: Pod "pod-projected-configmaps-616e0732-140d-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 12:52:13.330: INFO: Trying to get logs from node ip-172-31-59-90 pod pod-projected-configmaps-616e0732-140d-11e9-a571-02181533b527 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan  9 12:52:13.337: INFO: Waiting for pod pod-projected-configmaps-616e0732-140d-11e9-a571-02181533b527 to disappear
Jan  9 12:52:13.338: INFO: Pod pod-projected-configmaps-616e0732-140d-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:52:13.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5ppjh" for this suite.
Jan  9 12:52:19.345: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:52:19.375: INFO: namespace: e2e-tests-projected-5ppjh, resource: bindings, ignored listing per whitelist
Jan  9 12:52:19.380: INFO: namespace e2e-tests-projected-5ppjh deletion completed in 6.039841033s

• [SLOW TEST:8.092 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:52:19.380: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-8srcs
I0109 12:52:19.416000      18 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-8srcs, replica count: 1
I0109 12:52:20.466444      18 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0109 12:52:21.466703      18 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jan  9 12:52:21.570: INFO: Created: latency-svc-4dvh4
Jan  9 12:52:21.571: INFO: Got endpoints: latency-svc-4dvh4 [4.935776ms]
Jan  9 12:52:21.575: INFO: Created: latency-svc-pz2nx
Jan  9 12:52:21.577: INFO: Created: latency-svc-4prmw
Jan  9 12:52:21.578: INFO: Got endpoints: latency-svc-pz2nx [6.112527ms]
Jan  9 12:52:21.580: INFO: Got endpoints: latency-svc-4prmw [6.956256ms]
Jan  9 12:52:21.580: INFO: Created: latency-svc-f848q
Jan  9 12:52:21.585: INFO: Created: latency-svc-s6zzd
Jan  9 12:52:21.585: INFO: Got endpoints: latency-svc-f848q [13.175268ms]
Jan  9 12:52:21.586: INFO: Got endpoints: latency-svc-s6zzd [14.148102ms]
Jan  9 12:52:21.587: INFO: Created: latency-svc-c8qbl
Jan  9 12:52:21.589: INFO: Created: latency-svc-tg2zs
Jan  9 12:52:21.589: INFO: Got endpoints: latency-svc-c8qbl [17.392515ms]
Jan  9 12:52:21.592: INFO: Created: latency-svc-cdlpb
Jan  9 12:52:21.592: INFO: Got endpoints: latency-svc-tg2zs [19.642282ms]
Jan  9 12:52:21.592: INFO: Created: latency-svc-mhnjz
Jan  9 12:52:21.593: INFO: Got endpoints: latency-svc-cdlpb [20.289356ms]
Jan  9 12:52:21.594: INFO: Created: latency-svc-z5dg9
Jan  9 12:52:21.594: INFO: Got endpoints: latency-svc-mhnjz [21.549794ms]
Jan  9 12:52:21.598: INFO: Got endpoints: latency-svc-z5dg9 [24.877938ms]
Jan  9 12:52:21.599: INFO: Created: latency-svc-2p7tc
Jan  9 12:52:21.600: INFO: Created: latency-svc-pktzx
Jan  9 12:52:21.602: INFO: Got endpoints: latency-svc-2p7tc [29.997112ms]
Jan  9 12:52:21.602: INFO: Got endpoints: latency-svc-pktzx [28.517567ms]
Jan  9 12:52:21.605: INFO: Created: latency-svc-q5544
Jan  9 12:52:21.605: INFO: Created: latency-svc-qql2v
Jan  9 12:52:21.606: INFO: Got endpoints: latency-svc-qql2v [32.753932ms]
Jan  9 12:52:21.606: INFO: Got endpoints: latency-svc-q5544 [33.7746ms]
Jan  9 12:52:21.608: INFO: Created: latency-svc-kxfjq
Jan  9 12:52:21.608: INFO: Created: latency-svc-bfdks
Jan  9 12:52:21.610: INFO: Got endpoints: latency-svc-bfdks [36.838317ms]
Jan  9 12:52:21.610: INFO: Got endpoints: latency-svc-kxfjq [36.906023ms]
Jan  9 12:52:21.611: INFO: Created: latency-svc-fk68v
Jan  9 12:52:21.614: INFO: Got endpoints: latency-svc-fk68v [36.385342ms]
Jan  9 12:52:21.615: INFO: Created: latency-svc-qdjm7
Jan  9 12:52:21.616: INFO: Created: latency-svc-899jp
Jan  9 12:52:21.617: INFO: Got endpoints: latency-svc-qdjm7 [36.433416ms]
Jan  9 12:52:21.619: INFO: Got endpoints: latency-svc-899jp [33.15426ms]
Jan  9 12:52:21.619: INFO: Created: latency-svc-mbndk
Jan  9 12:52:21.620: INFO: Created: latency-svc-w8g66
Jan  9 12:52:21.621: INFO: Got endpoints: latency-svc-mbndk [34.630366ms]
Jan  9 12:52:21.622: INFO: Created: latency-svc-g5nnk
Jan  9 12:52:21.622: INFO: Got endpoints: latency-svc-w8g66 [32.855743ms]
Jan  9 12:52:21.624: INFO: Got endpoints: latency-svc-g5nnk [32.555667ms]
Jan  9 12:52:21.624: INFO: Created: latency-svc-9ljzb
Jan  9 12:52:21.625: INFO: Created: latency-svc-tzmwl
Jan  9 12:52:21.626: INFO: Got endpoints: latency-svc-9ljzb [33.268371ms]
Jan  9 12:52:21.628: INFO: Created: latency-svc-rptg6
Jan  9 12:52:21.628: INFO: Got endpoints: latency-svc-tzmwl [34.044582ms]
Jan  9 12:52:21.632: INFO: Got endpoints: latency-svc-rptg6 [33.745795ms]
Jan  9 12:52:21.632: INFO: Created: latency-svc-9t6f7
Jan  9 12:52:21.633: INFO: Created: latency-svc-2w4w2
Jan  9 12:52:21.634: INFO: Got endpoints: latency-svc-9t6f7 [32.083724ms]
Jan  9 12:52:21.635: INFO: Got endpoints: latency-svc-2w4w2 [32.997951ms]
Jan  9 12:52:21.636: INFO: Created: latency-svc-2cnhv
Jan  9 12:52:21.639: INFO: Got endpoints: latency-svc-2cnhv [33.195961ms]
Jan  9 12:52:21.639: INFO: Created: latency-svc-bb5gr
Jan  9 12:52:21.640: INFO: Created: latency-svc-wp2rg
Jan  9 12:52:21.640: INFO: Got endpoints: latency-svc-bb5gr [34.09161ms]
Jan  9 12:52:21.642: INFO: Got endpoints: latency-svc-wp2rg [32.10546ms]
Jan  9 12:52:21.647: INFO: Created: latency-svc-5lqd2
Jan  9 12:52:21.647: INFO: Got endpoints: latency-svc-5lqd2 [37.453465ms]
Jan  9 12:52:21.650: INFO: Created: latency-svc-qq5pp
Jan  9 12:52:21.652: INFO: Created: latency-svc-2m64n
Jan  9 12:52:21.654: INFO: Created: latency-svc-plfnk
Jan  9 12:52:21.655: INFO: Created: latency-svc-d52d6
Jan  9 12:52:21.656: INFO: Created: latency-svc-tfw5f
Jan  9 12:52:21.659: INFO: Created: latency-svc-5cwq9
Jan  9 12:52:21.660: INFO: Created: latency-svc-n5vpl
Jan  9 12:52:21.662: INFO: Created: latency-svc-lmlx6
Jan  9 12:52:21.663: INFO: Created: latency-svc-k2zql
Jan  9 12:52:21.664: INFO: Created: latency-svc-stmdq
Jan  9 12:52:21.666: INFO: Created: latency-svc-mkq66
Jan  9 12:52:21.669: INFO: Created: latency-svc-mjd9g
Jan  9 12:52:21.670: INFO: Created: latency-svc-skwb5
Jan  9 12:52:21.672: INFO: Got endpoints: latency-svc-qq5pp [57.398535ms]
Jan  9 12:52:21.672: INFO: Created: latency-svc-ddlkq
Jan  9 12:52:21.673: INFO: Created: latency-svc-mjs7k
Jan  9 12:52:21.677: INFO: Created: latency-svc-czcjz
Jan  9 12:52:21.722: INFO: Got endpoints: latency-svc-2m64n [105.565198ms]
Jan  9 12:52:21.725: INFO: Created: latency-svc-9nv8b
Jan  9 12:52:21.773: INFO: Got endpoints: latency-svc-plfnk [154.267738ms]
Jan  9 12:52:21.776: INFO: Created: latency-svc-z8jt4
Jan  9 12:52:21.822: INFO: Got endpoints: latency-svc-d52d6 [200.863437ms]
Jan  9 12:52:21.825: INFO: Created: latency-svc-cxpk2
Jan  9 12:52:21.872: INFO: Got endpoints: latency-svc-tfw5f [249.423141ms]
Jan  9 12:52:21.874: INFO: Created: latency-svc-l76b5
Jan  9 12:52:21.922: INFO: Got endpoints: latency-svc-5cwq9 [297.547616ms]
Jan  9 12:52:21.926: INFO: Created: latency-svc-768vj
Jan  9 12:52:21.972: INFO: Got endpoints: latency-svc-n5vpl [346.086687ms]
Jan  9 12:52:21.976: INFO: Created: latency-svc-fq9gz
Jan  9 12:52:22.022: INFO: Got endpoints: latency-svc-lmlx6 [393.99804ms]
Jan  9 12:52:22.025: INFO: Created: latency-svc-wgc72
Jan  9 12:52:22.072: INFO: Got endpoints: latency-svc-k2zql [439.873285ms]
Jan  9 12:52:22.074: INFO: Created: latency-svc-jglgl
Jan  9 12:52:22.122: INFO: Got endpoints: latency-svc-stmdq [488.182063ms]
Jan  9 12:52:22.126: INFO: Created: latency-svc-nr4zx
Jan  9 12:52:22.172: INFO: Got endpoints: latency-svc-mkq66 [536.891633ms]
Jan  9 12:52:22.175: INFO: Created: latency-svc-cb2l2
Jan  9 12:52:22.222: INFO: Got endpoints: latency-svc-mjd9g [582.947755ms]
Jan  9 12:52:22.225: INFO: Created: latency-svc-vbfw6
Jan  9 12:52:22.272: INFO: Got endpoints: latency-svc-skwb5 [631.517901ms]
Jan  9 12:52:22.275: INFO: Created: latency-svc-4n2pv
Jan  9 12:52:22.322: INFO: Got endpoints: latency-svc-ddlkq [680.026789ms]
Jan  9 12:52:22.324: INFO: Created: latency-svc-25x9n
Jan  9 12:52:22.372: INFO: Got endpoints: latency-svc-mjs7k [724.592194ms]
Jan  9 12:52:22.374: INFO: Created: latency-svc-4jlcz
Jan  9 12:52:22.422: INFO: Got endpoints: latency-svc-czcjz [750.653581ms]
Jan  9 12:52:22.427: INFO: Created: latency-svc-xpv2p
Jan  9 12:52:22.473: INFO: Got endpoints: latency-svc-9nv8b [750.385937ms]
Jan  9 12:52:22.476: INFO: Created: latency-svc-njt2s
Jan  9 12:52:22.522: INFO: Got endpoints: latency-svc-z8jt4 [748.9239ms]
Jan  9 12:52:22.524: INFO: Created: latency-svc-hcdbw
Jan  9 12:52:22.572: INFO: Got endpoints: latency-svc-cxpk2 [749.725502ms]
Jan  9 12:52:22.574: INFO: Created: latency-svc-zj6r4
Jan  9 12:52:22.622: INFO: Got endpoints: latency-svc-l76b5 [750.245591ms]
Jan  9 12:52:22.624: INFO: Created: latency-svc-4rccm
Jan  9 12:52:22.672: INFO: Got endpoints: latency-svc-768vj [749.989314ms]
Jan  9 12:52:22.675: INFO: Created: latency-svc-6css5
Jan  9 12:52:22.723: INFO: Got endpoints: latency-svc-fq9gz [750.389077ms]
Jan  9 12:52:22.726: INFO: Created: latency-svc-jmzb6
Jan  9 12:52:22.772: INFO: Got endpoints: latency-svc-wgc72 [749.925697ms]
Jan  9 12:52:22.775: INFO: Created: latency-svc-psrzl
Jan  9 12:52:22.822: INFO: Got endpoints: latency-svc-jglgl [750.255827ms]
Jan  9 12:52:22.825: INFO: Created: latency-svc-78b6z
Jan  9 12:52:22.872: INFO: Got endpoints: latency-svc-nr4zx [749.606607ms]
Jan  9 12:52:22.874: INFO: Created: latency-svc-nlprl
Jan  9 12:52:22.922: INFO: Got endpoints: latency-svc-cb2l2 [749.821989ms]
Jan  9 12:52:22.928: INFO: Created: latency-svc-6bz7q
Jan  9 12:52:22.972: INFO: Got endpoints: latency-svc-vbfw6 [750.362361ms]
Jan  9 12:52:22.976: INFO: Created: latency-svc-w8t8d
Jan  9 12:52:23.022: INFO: Got endpoints: latency-svc-4n2pv [749.673556ms]
Jan  9 12:52:23.025: INFO: Created: latency-svc-h44fd
Jan  9 12:52:23.072: INFO: Got endpoints: latency-svc-25x9n [750.054101ms]
Jan  9 12:52:23.074: INFO: Created: latency-svc-t6rm5
Jan  9 12:52:23.122: INFO: Got endpoints: latency-svc-4jlcz [750.150958ms]
Jan  9 12:52:23.125: INFO: Created: latency-svc-4w9tc
Jan  9 12:52:23.172: INFO: Got endpoints: latency-svc-xpv2p [749.50857ms]
Jan  9 12:52:23.176: INFO: Created: latency-svc-9r7dr
Jan  9 12:52:23.222: INFO: Got endpoints: latency-svc-njt2s [749.310103ms]
Jan  9 12:52:23.225: INFO: Created: latency-svc-cm579
Jan  9 12:52:23.272: INFO: Got endpoints: latency-svc-hcdbw [749.832214ms]
Jan  9 12:52:23.274: INFO: Created: latency-svc-8hlsd
Jan  9 12:52:23.326: INFO: Got endpoints: latency-svc-zj6r4 [754.726341ms]
Jan  9 12:52:23.329: INFO: Created: latency-svc-r8hcw
Jan  9 12:52:23.372: INFO: Got endpoints: latency-svc-4rccm [749.855512ms]
Jan  9 12:52:23.374: INFO: Created: latency-svc-pjg9q
Jan  9 12:52:23.421: INFO: Got endpoints: latency-svc-6css5 [749.499613ms]
Jan  9 12:52:23.424: INFO: Created: latency-svc-57gtx
Jan  9 12:52:23.472: INFO: Got endpoints: latency-svc-jmzb6 [749.312391ms]
Jan  9 12:52:23.475: INFO: Created: latency-svc-27pkk
Jan  9 12:52:23.522: INFO: Got endpoints: latency-svc-psrzl [750.14493ms]
Jan  9 12:52:23.525: INFO: Created: latency-svc-8swdf
Jan  9 12:52:23.572: INFO: Got endpoints: latency-svc-78b6z [749.603941ms]
Jan  9 12:52:23.574: INFO: Created: latency-svc-9plxj
Jan  9 12:52:23.622: INFO: Got endpoints: latency-svc-nlprl [749.780792ms]
Jan  9 12:52:23.624: INFO: Created: latency-svc-gmnfp
Jan  9 12:52:23.672: INFO: Got endpoints: latency-svc-6bz7q [750.381727ms]
Jan  9 12:52:23.675: INFO: Created: latency-svc-ltlwv
Jan  9 12:52:23.722: INFO: Got endpoints: latency-svc-w8t8d [749.58344ms]
Jan  9 12:52:23.725: INFO: Created: latency-svc-jd9r4
Jan  9 12:52:23.772: INFO: Got endpoints: latency-svc-h44fd [750.002376ms]
Jan  9 12:52:23.775: INFO: Created: latency-svc-pttrr
Jan  9 12:52:23.822: INFO: Got endpoints: latency-svc-t6rm5 [749.87911ms]
Jan  9 12:52:23.825: INFO: Created: latency-svc-fm4cr
Jan  9 12:52:23.872: INFO: Got endpoints: latency-svc-4w9tc [749.86166ms]
Jan  9 12:52:23.875: INFO: Created: latency-svc-9cfn5
Jan  9 12:52:23.922: INFO: Got endpoints: latency-svc-9r7dr [750.006763ms]
Jan  9 12:52:23.925: INFO: Created: latency-svc-5fl87
Jan  9 12:52:23.972: INFO: Got endpoints: latency-svc-cm579 [749.958158ms]
Jan  9 12:52:23.975: INFO: Created: latency-svc-77jck
Jan  9 12:52:24.022: INFO: Got endpoints: latency-svc-8hlsd [750.429404ms]
Jan  9 12:52:24.026: INFO: Created: latency-svc-hd696
Jan  9 12:52:24.072: INFO: Got endpoints: latency-svc-r8hcw [745.66227ms]
Jan  9 12:52:24.075: INFO: Created: latency-svc-smfkt
Jan  9 12:52:24.122: INFO: Got endpoints: latency-svc-pjg9q [750.135174ms]
Jan  9 12:52:24.125: INFO: Created: latency-svc-wvbk4
Jan  9 12:52:24.172: INFO: Got endpoints: latency-svc-57gtx [750.915597ms]
Jan  9 12:52:24.176: INFO: Created: latency-svc-p947g
Jan  9 12:52:24.223: INFO: Got endpoints: latency-svc-27pkk [750.707219ms]
Jan  9 12:52:24.225: INFO: Created: latency-svc-zxdsd
Jan  9 12:52:24.272: INFO: Got endpoints: latency-svc-8swdf [749.710039ms]
Jan  9 12:52:24.275: INFO: Created: latency-svc-jrpcl
Jan  9 12:52:24.322: INFO: Got endpoints: latency-svc-9plxj [750.326581ms]
Jan  9 12:52:24.326: INFO: Created: latency-svc-9mxzq
Jan  9 12:52:24.372: INFO: Got endpoints: latency-svc-gmnfp [750.576813ms]
Jan  9 12:52:24.375: INFO: Created: latency-svc-scdtx
Jan  9 12:52:24.422: INFO: Got endpoints: latency-svc-ltlwv [749.533858ms]
Jan  9 12:52:24.425: INFO: Created: latency-svc-hpdlq
Jan  9 12:52:24.473: INFO: Got endpoints: latency-svc-jd9r4 [750.835097ms]
Jan  9 12:52:24.476: INFO: Created: latency-svc-z58dt
Jan  9 12:52:24.522: INFO: Got endpoints: latency-svc-pttrr [750.602597ms]
Jan  9 12:52:24.526: INFO: Created: latency-svc-jl2pz
Jan  9 12:52:24.572: INFO: Got endpoints: latency-svc-fm4cr [750.241421ms]
Jan  9 12:52:24.575: INFO: Created: latency-svc-77fc8
Jan  9 12:52:24.622: INFO: Got endpoints: latency-svc-9cfn5 [750.027094ms]
Jan  9 12:52:24.625: INFO: Created: latency-svc-5sdhw
Jan  9 12:52:24.672: INFO: Got endpoints: latency-svc-5fl87 [749.850056ms]
Jan  9 12:52:24.675: INFO: Created: latency-svc-9ww5b
Jan  9 12:52:24.722: INFO: Got endpoints: latency-svc-77jck [750.104226ms]
Jan  9 12:52:24.725: INFO: Created: latency-svc-85878
Jan  9 12:52:24.773: INFO: Got endpoints: latency-svc-hd696 [750.414406ms]
Jan  9 12:52:24.775: INFO: Created: latency-svc-9tkbg
Jan  9 12:52:24.822: INFO: Got endpoints: latency-svc-smfkt [749.927853ms]
Jan  9 12:52:24.825: INFO: Created: latency-svc-d6zsc
Jan  9 12:52:24.872: INFO: Got endpoints: latency-svc-wvbk4 [749.658891ms]
Jan  9 12:52:24.874: INFO: Created: latency-svc-x7ch4
Jan  9 12:52:24.922: INFO: Got endpoints: latency-svc-p947g [749.447686ms]
Jan  9 12:52:24.925: INFO: Created: latency-svc-f7lkh
Jan  9 12:52:24.973: INFO: Got endpoints: latency-svc-zxdsd [749.945618ms]
Jan  9 12:52:24.976: INFO: Created: latency-svc-jx55p
Jan  9 12:52:25.022: INFO: Got endpoints: latency-svc-jrpcl [749.819766ms]
Jan  9 12:52:25.025: INFO: Created: latency-svc-9z42s
Jan  9 12:52:25.072: INFO: Got endpoints: latency-svc-9mxzq [749.727408ms]
Jan  9 12:52:25.074: INFO: Created: latency-svc-54r98
Jan  9 12:52:25.122: INFO: Got endpoints: latency-svc-scdtx [749.526392ms]
Jan  9 12:52:25.124: INFO: Created: latency-svc-4pt92
Jan  9 12:52:25.172: INFO: Got endpoints: latency-svc-hpdlq [750.314839ms]
Jan  9 12:52:25.175: INFO: Created: latency-svc-fwl6j
Jan  9 12:52:25.223: INFO: Got endpoints: latency-svc-z58dt [749.679366ms]
Jan  9 12:52:25.225: INFO: Created: latency-svc-wg7kk
Jan  9 12:52:25.272: INFO: Got endpoints: latency-svc-jl2pz [750.052859ms]
Jan  9 12:52:25.275: INFO: Created: latency-svc-zkkbn
Jan  9 12:52:25.322: INFO: Got endpoints: latency-svc-77fc8 [750.149259ms]
Jan  9 12:52:25.325: INFO: Created: latency-svc-xfhzh
Jan  9 12:52:25.372: INFO: Got endpoints: latency-svc-5sdhw [750.111212ms]
Jan  9 12:52:25.375: INFO: Created: latency-svc-4rnjn
Jan  9 12:52:25.422: INFO: Got endpoints: latency-svc-9ww5b [750.063861ms]
Jan  9 12:52:25.425: INFO: Created: latency-svc-bccgf
Jan  9 12:52:25.472: INFO: Got endpoints: latency-svc-85878 [749.956678ms]
Jan  9 12:52:25.475: INFO: Created: latency-svc-fpp7c
Jan  9 12:52:25.522: INFO: Got endpoints: latency-svc-9tkbg [749.045692ms]
Jan  9 12:52:25.524: INFO: Created: latency-svc-v8jtd
Jan  9 12:52:25.572: INFO: Got endpoints: latency-svc-d6zsc [749.792164ms]
Jan  9 12:52:25.575: INFO: Created: latency-svc-xlc67
Jan  9 12:52:25.622: INFO: Got endpoints: latency-svc-x7ch4 [750.128181ms]
Jan  9 12:52:25.624: INFO: Created: latency-svc-jr7fw
Jan  9 12:52:25.672: INFO: Got endpoints: latency-svc-f7lkh [750.034135ms]
Jan  9 12:52:25.676: INFO: Created: latency-svc-vbvdm
Jan  9 12:52:25.723: INFO: Got endpoints: latency-svc-jx55p [749.84154ms]
Jan  9 12:52:25.725: INFO: Created: latency-svc-ttl76
Jan  9 12:52:25.772: INFO: Got endpoints: latency-svc-9z42s [750.375908ms]
Jan  9 12:52:25.775: INFO: Created: latency-svc-js5hw
Jan  9 12:52:25.822: INFO: Got endpoints: latency-svc-54r98 [750.010945ms]
Jan  9 12:52:25.825: INFO: Created: latency-svc-wq9nl
Jan  9 12:52:25.872: INFO: Got endpoints: latency-svc-4pt92 [750.126137ms]
Jan  9 12:52:25.874: INFO: Created: latency-svc-sgvtm
Jan  9 12:52:25.922: INFO: Got endpoints: latency-svc-fwl6j [750.286062ms]
Jan  9 12:52:25.925: INFO: Created: latency-svc-2kgzh
Jan  9 12:52:25.972: INFO: Got endpoints: latency-svc-wg7kk [749.782509ms]
Jan  9 12:52:25.976: INFO: Created: latency-svc-xmqxg
Jan  9 12:52:26.023: INFO: Got endpoints: latency-svc-zkkbn [750.001909ms]
Jan  9 12:52:26.026: INFO: Created: latency-svc-xmvnj
Jan  9 12:52:26.072: INFO: Got endpoints: latency-svc-xfhzh [749.645978ms]
Jan  9 12:52:26.074: INFO: Created: latency-svc-bj5jc
Jan  9 12:52:26.122: INFO: Got endpoints: latency-svc-4rnjn [749.63665ms]
Jan  9 12:52:26.125: INFO: Created: latency-svc-wpxm5
Jan  9 12:52:26.172: INFO: Got endpoints: latency-svc-bccgf [750.553397ms]
Jan  9 12:52:26.175: INFO: Created: latency-svc-f67vj
Jan  9 12:52:26.222: INFO: Got endpoints: latency-svc-fpp7c [750.2988ms]
Jan  9 12:52:26.226: INFO: Created: latency-svc-2pmcm
Jan  9 12:52:26.272: INFO: Got endpoints: latency-svc-v8jtd [750.153694ms]
Jan  9 12:52:26.276: INFO: Created: latency-svc-vs2w9
Jan  9 12:52:26.322: INFO: Got endpoints: latency-svc-xlc67 [749.657232ms]
Jan  9 12:52:26.324: INFO: Created: latency-svc-wsnvw
Jan  9 12:52:26.372: INFO: Got endpoints: latency-svc-jr7fw [749.870937ms]
Jan  9 12:52:26.374: INFO: Created: latency-svc-kqdb9
Jan  9 12:52:26.422: INFO: Got endpoints: latency-svc-vbvdm [750.270802ms]
Jan  9 12:52:26.427: INFO: Created: latency-svc-vx6md
Jan  9 12:52:26.474: INFO: Got endpoints: latency-svc-ttl76 [750.992916ms]
Jan  9 12:52:26.477: INFO: Created: latency-svc-xk28s
Jan  9 12:52:26.523: INFO: Got endpoints: latency-svc-js5hw [750.507757ms]
Jan  9 12:52:26.526: INFO: Created: latency-svc-rl58z
Jan  9 12:52:26.572: INFO: Got endpoints: latency-svc-wq9nl [750.152191ms]
Jan  9 12:52:26.576: INFO: Created: latency-svc-fzcqg
Jan  9 12:52:26.622: INFO: Got endpoints: latency-svc-sgvtm [750.249094ms]
Jan  9 12:52:26.625: INFO: Created: latency-svc-4xnhz
Jan  9 12:52:26.672: INFO: Got endpoints: latency-svc-2kgzh [749.339618ms]
Jan  9 12:52:26.675: INFO: Created: latency-svc-7sh6g
Jan  9 12:52:26.722: INFO: Got endpoints: latency-svc-xmqxg [749.790763ms]
Jan  9 12:52:26.726: INFO: Created: latency-svc-9tjrs
Jan  9 12:52:26.772: INFO: Got endpoints: latency-svc-xmvnj [749.604213ms]
Jan  9 12:52:26.775: INFO: Created: latency-svc-2t77d
Jan  9 12:52:26.822: INFO: Got endpoints: latency-svc-bj5jc [749.753412ms]
Jan  9 12:52:26.824: INFO: Created: latency-svc-xccfj
Jan  9 12:52:26.872: INFO: Got endpoints: latency-svc-wpxm5 [750.000046ms]
Jan  9 12:52:26.874: INFO: Created: latency-svc-jtzmv
Jan  9 12:52:26.922: INFO: Got endpoints: latency-svc-f67vj [749.703373ms]
Jan  9 12:52:26.925: INFO: Created: latency-svc-nxll8
Jan  9 12:52:26.973: INFO: Got endpoints: latency-svc-2pmcm [750.218656ms]
Jan  9 12:52:26.975: INFO: Created: latency-svc-xthbz
Jan  9 12:52:27.022: INFO: Got endpoints: latency-svc-vs2w9 [750.246753ms]
Jan  9 12:52:27.025: INFO: Created: latency-svc-cdt6f
Jan  9 12:52:27.072: INFO: Got endpoints: latency-svc-wsnvw [750.237966ms]
Jan  9 12:52:27.074: INFO: Created: latency-svc-vq8v2
Jan  9 12:52:27.122: INFO: Got endpoints: latency-svc-kqdb9 [750.004463ms]
Jan  9 12:52:27.124: INFO: Created: latency-svc-pdd7m
Jan  9 12:52:27.172: INFO: Got endpoints: latency-svc-vx6md [749.414955ms]
Jan  9 12:52:27.174: INFO: Created: latency-svc-5z5k7
Jan  9 12:52:27.222: INFO: Got endpoints: latency-svc-xk28s [748.67721ms]
Jan  9 12:52:27.226: INFO: Created: latency-svc-2vxnl
Jan  9 12:52:27.272: INFO: Got endpoints: latency-svc-rl58z [749.410687ms]
Jan  9 12:52:27.275: INFO: Created: latency-svc-gc8p6
Jan  9 12:52:27.322: INFO: Got endpoints: latency-svc-fzcqg [749.728344ms]
Jan  9 12:52:27.325: INFO: Created: latency-svc-7gfzd
Jan  9 12:52:27.372: INFO: Got endpoints: latency-svc-4xnhz [749.374765ms]
Jan  9 12:52:27.374: INFO: Created: latency-svc-688zm
Jan  9 12:52:27.422: INFO: Got endpoints: latency-svc-7sh6g [750.50226ms]
Jan  9 12:52:27.426: INFO: Created: latency-svc-rbkzk
Jan  9 12:52:27.473: INFO: Got endpoints: latency-svc-9tjrs [750.857384ms]
Jan  9 12:52:27.476: INFO: Created: latency-svc-b4q8k
Jan  9 12:52:27.522: INFO: Got endpoints: latency-svc-2t77d [750.163668ms]
Jan  9 12:52:27.525: INFO: Created: latency-svc-kjlhb
Jan  9 12:52:27.572: INFO: Got endpoints: latency-svc-xccfj [750.213551ms]
Jan  9 12:52:27.574: INFO: Created: latency-svc-pppq6
Jan  9 12:52:27.622: INFO: Got endpoints: latency-svc-jtzmv [750.129217ms]
Jan  9 12:52:27.626: INFO: Created: latency-svc-wfp5j
Jan  9 12:52:27.672: INFO: Got endpoints: latency-svc-nxll8 [750.074974ms]
Jan  9 12:52:27.675: INFO: Created: latency-svc-x472v
Jan  9 12:52:27.722: INFO: Got endpoints: latency-svc-xthbz [749.72959ms]
Jan  9 12:52:27.725: INFO: Created: latency-svc-t59fk
Jan  9 12:52:27.772: INFO: Got endpoints: latency-svc-cdt6f [749.847026ms]
Jan  9 12:52:27.776: INFO: Created: latency-svc-2hz4x
Jan  9 12:52:27.822: INFO: Got endpoints: latency-svc-vq8v2 [750.053842ms]
Jan  9 12:52:27.824: INFO: Created: latency-svc-nspxt
Jan  9 12:52:27.872: INFO: Got endpoints: latency-svc-pdd7m [750.005156ms]
Jan  9 12:52:27.874: INFO: Created: latency-svc-hw5c9
Jan  9 12:52:27.922: INFO: Got endpoints: latency-svc-5z5k7 [750.515313ms]
Jan  9 12:52:27.925: INFO: Created: latency-svc-bz5zv
Jan  9 12:52:27.972: INFO: Got endpoints: latency-svc-2vxnl [749.711986ms]
Jan  9 12:52:27.975: INFO: Created: latency-svc-gzdxj
Jan  9 12:52:28.022: INFO: Got endpoints: latency-svc-gc8p6 [749.96351ms]
Jan  9 12:52:28.025: INFO: Created: latency-svc-lpc25
Jan  9 12:52:28.072: INFO: Got endpoints: latency-svc-7gfzd [750.283771ms]
Jan  9 12:52:28.076: INFO: Created: latency-svc-sb5vp
Jan  9 12:52:28.122: INFO: Got endpoints: latency-svc-688zm [750.232325ms]
Jan  9 12:52:28.124: INFO: Created: latency-svc-l22df
Jan  9 12:52:28.172: INFO: Got endpoints: latency-svc-rbkzk [749.597687ms]
Jan  9 12:52:28.175: INFO: Created: latency-svc-2vtzs
Jan  9 12:52:28.222: INFO: Got endpoints: latency-svc-b4q8k [749.101353ms]
Jan  9 12:52:28.227: INFO: Created: latency-svc-zghn7
Jan  9 12:52:28.272: INFO: Got endpoints: latency-svc-kjlhb [749.947218ms]
Jan  9 12:52:28.275: INFO: Created: latency-svc-j9fxr
Jan  9 12:52:28.322: INFO: Got endpoints: latency-svc-pppq6 [749.893355ms]
Jan  9 12:52:28.324: INFO: Created: latency-svc-9n6lk
Jan  9 12:52:28.372: INFO: Got endpoints: latency-svc-wfp5j [749.95562ms]
Jan  9 12:52:28.376: INFO: Created: latency-svc-qdkn5
Jan  9 12:52:28.422: INFO: Got endpoints: latency-svc-x472v [749.450269ms]
Jan  9 12:52:28.426: INFO: Created: latency-svc-5sg5d
Jan  9 12:52:28.472: INFO: Got endpoints: latency-svc-t59fk [749.841388ms]
Jan  9 12:52:28.476: INFO: Created: latency-svc-6dd57
Jan  9 12:52:28.523: INFO: Got endpoints: latency-svc-2hz4x [750.402564ms]
Jan  9 12:52:28.525: INFO: Created: latency-svc-z7x66
Jan  9 12:52:28.572: INFO: Got endpoints: latency-svc-nspxt [749.882744ms]
Jan  9 12:52:28.575: INFO: Created: latency-svc-wb64x
Jan  9 12:52:28.622: INFO: Got endpoints: latency-svc-hw5c9 [749.905568ms]
Jan  9 12:52:28.625: INFO: Created: latency-svc-qb7g9
Jan  9 12:52:28.672: INFO: Got endpoints: latency-svc-bz5zv [749.486918ms]
Jan  9 12:52:28.675: INFO: Created: latency-svc-q592b
Jan  9 12:52:28.722: INFO: Got endpoints: latency-svc-gzdxj [750.15986ms]
Jan  9 12:52:28.726: INFO: Created: latency-svc-d8zgh
Jan  9 12:52:28.773: INFO: Got endpoints: latency-svc-lpc25 [750.528713ms]
Jan  9 12:52:28.776: INFO: Created: latency-svc-pv7bh
Jan  9 12:52:28.822: INFO: Got endpoints: latency-svc-sb5vp [749.601764ms]
Jan  9 12:52:28.825: INFO: Created: latency-svc-mkgsh
Jan  9 12:52:28.872: INFO: Got endpoints: latency-svc-l22df [749.932762ms]
Jan  9 12:52:28.875: INFO: Created: latency-svc-gkxv8
Jan  9 12:52:28.922: INFO: Got endpoints: latency-svc-2vtzs [750.215176ms]
Jan  9 12:52:28.925: INFO: Created: latency-svc-57ngc
Jan  9 12:52:28.972: INFO: Got endpoints: latency-svc-zghn7 [750.2258ms]
Jan  9 12:52:28.975: INFO: Created: latency-svc-48xjk
Jan  9 12:52:29.023: INFO: Got endpoints: latency-svc-j9fxr [750.405014ms]
Jan  9 12:52:29.026: INFO: Created: latency-svc-nfgh5
Jan  9 12:52:29.072: INFO: Got endpoints: latency-svc-9n6lk [750.282252ms]
Jan  9 12:52:29.075: INFO: Created: latency-svc-9kjsf
Jan  9 12:52:29.122: INFO: Got endpoints: latency-svc-qdkn5 [750.154301ms]
Jan  9 12:52:29.125: INFO: Created: latency-svc-zcfgf
Jan  9 12:52:29.172: INFO: Got endpoints: latency-svc-5sg5d [750.61604ms]
Jan  9 12:52:29.176: INFO: Created: latency-svc-vfqwf
Jan  9 12:52:29.223: INFO: Got endpoints: latency-svc-6dd57 [750.752375ms]
Jan  9 12:52:29.226: INFO: Created: latency-svc-p7269
Jan  9 12:52:29.273: INFO: Got endpoints: latency-svc-z7x66 [750.00518ms]
Jan  9 12:52:29.275: INFO: Created: latency-svc-xvh5d
Jan  9 12:52:29.322: INFO: Got endpoints: latency-svc-wb64x [749.899795ms]
Jan  9 12:52:29.325: INFO: Created: latency-svc-xchgb
Jan  9 12:52:29.372: INFO: Got endpoints: latency-svc-qb7g9 [749.946966ms]
Jan  9 12:52:29.375: INFO: Created: latency-svc-c57g9
Jan  9 12:52:29.422: INFO: Got endpoints: latency-svc-q592b [750.356924ms]
Jan  9 12:52:29.472: INFO: Got endpoints: latency-svc-d8zgh [750.185438ms]
Jan  9 12:52:29.523: INFO: Got endpoints: latency-svc-pv7bh [750.254367ms]
Jan  9 12:52:29.572: INFO: Got endpoints: latency-svc-mkgsh [750.284833ms]
Jan  9 12:52:29.622: INFO: Got endpoints: latency-svc-gkxv8 [749.855298ms]
Jan  9 12:52:29.672: INFO: Got endpoints: latency-svc-57ngc [749.55116ms]
Jan  9 12:52:29.723: INFO: Got endpoints: latency-svc-48xjk [750.075923ms]
Jan  9 12:52:29.772: INFO: Got endpoints: latency-svc-nfgh5 [749.331797ms]
Jan  9 12:52:29.822: INFO: Got endpoints: latency-svc-9kjsf [749.647591ms]
Jan  9 12:52:29.872: INFO: Got endpoints: latency-svc-zcfgf [749.719595ms]
Jan  9 12:52:29.922: INFO: Got endpoints: latency-svc-vfqwf [749.650749ms]
Jan  9 12:52:29.972: INFO: Got endpoints: latency-svc-p7269 [748.744379ms]
Jan  9 12:52:30.022: INFO: Got endpoints: latency-svc-xvh5d [749.805504ms]
Jan  9 12:52:30.072: INFO: Got endpoints: latency-svc-xchgb [749.908389ms]
Jan  9 12:52:30.122: INFO: Got endpoints: latency-svc-c57g9 [750.139945ms]
Jan  9 12:52:30.122: INFO: Latencies: [6.112527ms 6.956256ms 13.175268ms 14.148102ms 17.392515ms 19.642282ms 20.289356ms 21.549794ms 24.877938ms 28.517567ms 29.997112ms 32.083724ms 32.10546ms 32.555667ms 32.753932ms 32.855743ms 32.997951ms 33.15426ms 33.195961ms 33.268371ms 33.745795ms 33.7746ms 34.044582ms 34.09161ms 34.630366ms 36.385342ms 36.433416ms 36.838317ms 36.906023ms 37.453465ms 57.398535ms 105.565198ms 154.267738ms 200.863437ms 249.423141ms 297.547616ms 346.086687ms 393.99804ms 439.873285ms 488.182063ms 536.891633ms 582.947755ms 631.517901ms 680.026789ms 724.592194ms 745.66227ms 748.67721ms 748.744379ms 748.9239ms 749.045692ms 749.101353ms 749.310103ms 749.312391ms 749.331797ms 749.339618ms 749.374765ms 749.410687ms 749.414955ms 749.447686ms 749.450269ms 749.486918ms 749.499613ms 749.50857ms 749.526392ms 749.533858ms 749.55116ms 749.58344ms 749.597687ms 749.601764ms 749.603941ms 749.604213ms 749.606607ms 749.63665ms 749.645978ms 749.647591ms 749.650749ms 749.657232ms 749.658891ms 749.673556ms 749.679366ms 749.703373ms 749.710039ms 749.711986ms 749.719595ms 749.725502ms 749.727408ms 749.728344ms 749.72959ms 749.753412ms 749.780792ms 749.782509ms 749.790763ms 749.792164ms 749.805504ms 749.819766ms 749.821989ms 749.832214ms 749.841388ms 749.84154ms 749.847026ms 749.850056ms 749.855298ms 749.855512ms 749.86166ms 749.870937ms 749.87911ms 749.882744ms 749.893355ms 749.899795ms 749.905568ms 749.908389ms 749.925697ms 749.927853ms 749.932762ms 749.945618ms 749.946966ms 749.947218ms 749.95562ms 749.956678ms 749.958158ms 749.96351ms 749.989314ms 750.000046ms 750.001909ms 750.002376ms 750.004463ms 750.005156ms 750.00518ms 750.006763ms 750.010945ms 750.027094ms 750.034135ms 750.052859ms 750.053842ms 750.054101ms 750.063861ms 750.074974ms 750.075923ms 750.104226ms 750.111212ms 750.126137ms 750.128181ms 750.129217ms 750.135174ms 750.139945ms 750.14493ms 750.149259ms 750.150958ms 750.152191ms 750.153694ms 750.154301ms 750.15986ms 750.163668ms 750.185438ms 750.213551ms 750.215176ms 750.218656ms 750.2258ms 750.232325ms 750.237966ms 750.241421ms 750.245591ms 750.246753ms 750.249094ms 750.254367ms 750.255827ms 750.270802ms 750.282252ms 750.283771ms 750.284833ms 750.286062ms 750.2988ms 750.314839ms 750.326581ms 750.356924ms 750.362361ms 750.375908ms 750.381727ms 750.385937ms 750.389077ms 750.402564ms 750.405014ms 750.414406ms 750.429404ms 750.50226ms 750.507757ms 750.515313ms 750.528713ms 750.553397ms 750.576813ms 750.602597ms 750.61604ms 750.653581ms 750.707219ms 750.752375ms 750.835097ms 750.857384ms 750.915597ms 750.992916ms 754.726341ms]
Jan  9 12:52:30.122: INFO: 50 %ile: 749.850056ms
Jan  9 12:52:30.122: INFO: 90 %ile: 750.402564ms
Jan  9 12:52:30.122: INFO: 99 %ile: 750.992916ms
Jan  9 12:52:30.122: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:52:30.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-8srcs" for this suite.
Jan  9 12:52:42.128: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:52:42.144: INFO: namespace: e2e-tests-svc-latency-8srcs, resource: bindings, ignored listing per whitelist
Jan  9 12:52:42.164: INFO: namespace e2e-tests-svc-latency-8srcs deletion completed in 12.040521522s

• [SLOW TEST:22.784 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:52:42.164: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Jan  9 12:52:46.206: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-73d49295-140d-11e9-a571-02181533b527,GenerateName:,Namespace:e2e-tests-events-gwwv7,SelfLink:/api/v1/namespaces/e2e-tests-events-gwwv7/pods/send-events-73d49295-140d-11e9-a571-02181533b527,UID:73d4c855-140d-11e9-90b5-12841864fc48,ResourceVersion:10824,Generation:0,CreationTimestamp:2019-01-09 12:52:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 195220207,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xvkw9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xvkw9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-xvkw9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-59-90,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c45980} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c459a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 12:52:42 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 12:52:44 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 12:52:44 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 12:52:42 +0000 UTC  }],Message:,Reason:,HostIP:172.31.59.90,PodIP:10.1.1.176,StartTime:2019-01-09 12:52:42 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-01-09 12:52:43 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://a18652b66d1a0244e6bd093fb50c6241c94b750be476ca3afe5bb1af093ac40b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Jan  9 12:52:48.208: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Jan  9 12:52:50.210: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:52:50.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-gwwv7" for this suite.
Jan  9 12:53:28.219: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:53:28.236: INFO: namespace: e2e-tests-events-gwwv7, resource: bindings, ignored listing per whitelist
Jan  9 12:53:28.257: INFO: namespace e2e-tests-events-gwwv7 deletion completed in 38.042665795s

• [SLOW TEST:46.093 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:53:28.257: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan  9 12:53:28.289: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Jan  9 12:53:28.292: INFO: Pod name sample-pod: Found 0 pods out of 1
Jan  9 12:53:33.294: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jan  9 12:53:33.294: INFO: Creating deployment "test-rolling-update-deployment"
Jan  9 12:53:33.296: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Jan  9 12:53:33.299: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Jan  9 12:53:35.301: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Jan  9 12:53:35.303: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan  9 12:53:35.306: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-qfrdh,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-qfrdh/deployments/test-rolling-update-deployment,UID:9249c284-140d-11e9-90b5-12841864fc48,ResourceVersion:10946,Generation:1,CreationTimestamp:2019-01-09 12:53:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-01-09 12:53:33 +0000 UTC 2019-01-09 12:53:33 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-01-09 12:53:35 +0000 UTC 2019-01-09 12:53:33 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-68b55d7bc6" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Jan  9 12:53:35.308: INFO: New ReplicaSet "test-rolling-update-deployment-68b55d7bc6" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6,GenerateName:,Namespace:e2e-tests-deployment-qfrdh,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-qfrdh/replicasets/test-rolling-update-deployment-68b55d7bc6,UID:924a9228-140d-11e9-90b5-12841864fc48,ResourceVersion:10937,Generation:1,CreationTimestamp:2019-01-09 12:53:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 9249c284-140d-11e9-90b5-12841864fc48 0xc001b40fe7 0xc001b40fe8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jan  9 12:53:35.308: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Jan  9 12:53:35.308: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-qfrdh,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-qfrdh/replicasets/test-rolling-update-controller,UID:8f4e0fea-140d-11e9-90b5-12841864fc48,ResourceVersion:10945,Generation:2,CreationTimestamp:2019-01-09 12:53:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 9249c284-140d-11e9-90b5-12841864fc48 0xc001b40ea7 0xc001b40ea8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan  9 12:53:35.309: INFO: Pod "test-rolling-update-deployment-68b55d7bc6-cdfv9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6-cdfv9,GenerateName:test-rolling-update-deployment-68b55d7bc6-,Namespace:e2e-tests-deployment-qfrdh,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qfrdh/pods/test-rolling-update-deployment-68b55d7bc6-cdfv9,UID:924acb47-140d-11e9-90b5-12841864fc48,ResourceVersion:10936,Generation:0,CreationTimestamp:2019-01-09 12:53:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-68b55d7bc6 924a9228-140d-11e9-90b5-12841864fc48 0xc00241e2d7 0xc00241e2d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-gdnt9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-gdnt9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-gdnt9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-59-90,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00241e430} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00241e450}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 12:53:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 12:53:35 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 12:53:35 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 12:53:33 +0000 UTC  }],Message:,Reason:,HostIP:172.31.59.90,PodIP:10.1.1.178,StartTime:2019-01-09 12:53:33 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-01-09 12:53:34 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://9bf40069140b929bedc47907df28437ccc7247ccaefb97f468328acd10760e94}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:53:35.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-qfrdh" for this suite.
Jan  9 12:53:41.316: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:53:41.335: INFO: namespace: e2e-tests-deployment-qfrdh, resource: bindings, ignored listing per whitelist
Jan  9 12:53:41.353: INFO: namespace e2e-tests-deployment-qfrdh deletion completed in 6.041969226s

• [SLOW TEST:13.095 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:53:41.353: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-gs9b7
Jan  9 12:53:43.389: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-gs9b7
STEP: checking the pod's current state and verifying that restartCount is present
Jan  9 12:53:43.390: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:57:43.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-gs9b7" for this suite.
Jan  9 12:57:49.628: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:57:49.653: INFO: namespace: e2e-tests-container-probe-gs9b7, resource: bindings, ignored listing per whitelist
Jan  9 12:57:49.663: INFO: namespace e2e-tests-container-probe-gs9b7 deletion completed in 6.039355553s

• [SLOW TEST:248.310 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:57:49.663: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan  9 12:57:49.694: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 version'
Jan  9 12:57:49.751: INFO: stderr: ""
Jan  9 12:57:49.751: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.1\", GitCommit:\"eec55b9ba98609a46fee712359c7b5b365bdd920\", GitTreeState:\"clean\", BuildDate:\"2018-12-13T10:31:33Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:57:49.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6nssc" for this suite.
Jan  9 12:57:55.758: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:57:55.768: INFO: namespace: e2e-tests-kubectl-6nssc, resource: bindings, ignored listing per whitelist
Jan  9 12:57:55.795: INFO: namespace e2e-tests-kubectl-6nssc deletion completed in 6.042344151s

• [SLOW TEST:6.132 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:57:55.795: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1052
STEP: creating the pod
Jan  9 12:57:55.827: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 create -f - --namespace=e2e-tests-kubectl-vctsw'
Jan  9 12:57:56.123: INFO: stderr: ""
Jan  9 12:57:56.123: INFO: stdout: "pod/pause created\n"
Jan  9 12:57:56.123: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Jan  9 12:57:56.123: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-vctsw" to be "running and ready"
Jan  9 12:57:56.125: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 1.504462ms
Jan  9 12:57:58.127: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.003237183s
Jan  9 12:57:58.127: INFO: Pod "pause" satisfied condition "running and ready"
Jan  9 12:57:58.127: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Jan  9 12:57:58.127: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-vctsw'
Jan  9 12:57:58.189: INFO: stderr: ""
Jan  9 12:57:58.189: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Jan  9 12:57:58.189: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 get pod pause -L testing-label --namespace=e2e-tests-kubectl-vctsw'
Jan  9 12:57:58.248: INFO: stderr: ""
Jan  9 12:57:58.248: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Jan  9 12:57:58.248: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 label pods pause testing-label- --namespace=e2e-tests-kubectl-vctsw'
Jan  9 12:57:58.309: INFO: stderr: ""
Jan  9 12:57:58.310: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Jan  9 12:57:58.310: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 get pod pause -L testing-label --namespace=e2e-tests-kubectl-vctsw'
Jan  9 12:57:58.368: INFO: stderr: ""
Jan  9 12:57:58.368: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1059
STEP: using delete to clean up resources
Jan  9 12:57:58.368: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-vctsw'
Jan  9 12:57:58.429: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan  9 12:57:58.429: INFO: stdout: "pod \"pause\" force deleted\n"
Jan  9 12:57:58.429: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-vctsw'
Jan  9 12:57:58.492: INFO: stderr: "No resources found.\n"
Jan  9 12:57:58.492: INFO: stdout: ""
Jan  9 12:57:58.492: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 get pods -l name=pause --namespace=e2e-tests-kubectl-vctsw -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan  9 12:57:58.555: INFO: stderr: ""
Jan  9 12:57:58.555: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:57:58.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-vctsw" for this suite.
Jan  9 12:58:04.561: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:58:04.566: INFO: namespace: e2e-tests-kubectl-vctsw, resource: bindings, ignored listing per whitelist
Jan  9 12:58:04.597: INFO: namespace e2e-tests-kubectl-vctsw deletion completed in 6.041234557s

• [SLOW TEST:8.803 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:58:04.598: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-m8mdq
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan  9 12:58:04.629: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan  9 12:58:20.650: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.1.1.182:8080/dial?request=hostName&protocol=http&host=10.1.1.181&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-m8mdq PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan  9 12:58:20.650: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
Jan  9 12:58:20.730: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:58:20.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-m8mdq" for this suite.
Jan  9 12:58:42.736: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:58:42.768: INFO: namespace: e2e-tests-pod-network-test-m8mdq, resource: bindings, ignored listing per whitelist
Jan  9 12:58:42.778: INFO: namespace e2e-tests-pod-network-test-m8mdq deletion completed in 22.046359418s

• [SLOW TEST:38.181 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:58:42.778: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan  9 12:58:42.814: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4ac63e8a-140e-11e9-a571-02181533b527" in namespace "e2e-tests-downward-api-s4f9v" to be "success or failure"
Jan  9 12:58:42.815: INFO: Pod "downwardapi-volume-4ac63e8a-140e-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.0761ms
Jan  9 12:58:44.817: INFO: Pod "downwardapi-volume-4ac63e8a-140e-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00297936s
Jan  9 12:58:46.819: INFO: Pod "downwardapi-volume-4ac63e8a-140e-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00539295s
STEP: Saw pod success
Jan  9 12:58:46.819: INFO: Pod "downwardapi-volume-4ac63e8a-140e-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 12:58:46.820: INFO: Trying to get logs from node ip-172-31-59-90 pod downwardapi-volume-4ac63e8a-140e-11e9-a571-02181533b527 container client-container: <nil>
STEP: delete the pod
Jan  9 12:58:46.829: INFO: Waiting for pod downwardapi-volume-4ac63e8a-140e-11e9-a571-02181533b527 to disappear
Jan  9 12:58:46.830: INFO: Pod downwardapi-volume-4ac63e8a-140e-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:58:46.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-s4f9v" for this suite.
Jan  9 12:58:52.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:58:52.875: INFO: namespace: e2e-tests-downward-api-s4f9v, resource: bindings, ignored listing per whitelist
Jan  9 12:58:52.875: INFO: namespace e2e-tests-downward-api-s4f9v deletion completed in 6.043319727s

• [SLOW TEST:10.096 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:58:52.875: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-50caf41e-140e-11e9-a571-02181533b527
STEP: Creating a pod to test consume secrets
Jan  9 12:58:52.912: INFO: Waiting up to 5m0s for pod "pod-secrets-50cb2b6b-140e-11e9-a571-02181533b527" in namespace "e2e-tests-secrets-9lb72" to be "success or failure"
Jan  9 12:58:52.914: INFO: Pod "pod-secrets-50cb2b6b-140e-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.369582ms
Jan  9 12:58:54.916: INFO: Pod "pod-secrets-50cb2b6b-140e-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003248102s
Jan  9 12:58:56.918: INFO: Pod "pod-secrets-50cb2b6b-140e-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005090314s
STEP: Saw pod success
Jan  9 12:58:56.918: INFO: Pod "pod-secrets-50cb2b6b-140e-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 12:58:56.919: INFO: Trying to get logs from node ip-172-31-59-90 pod pod-secrets-50cb2b6b-140e-11e9-a571-02181533b527 container secret-volume-test: <nil>
STEP: delete the pod
Jan  9 12:58:56.932: INFO: Waiting for pod pod-secrets-50cb2b6b-140e-11e9-a571-02181533b527 to disappear
Jan  9 12:58:56.933: INFO: Pod pod-secrets-50cb2b6b-140e-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:58:56.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-9lb72" for this suite.
Jan  9 12:59:02.939: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:59:02.961: INFO: namespace: e2e-tests-secrets-9lb72, resource: bindings, ignored listing per whitelist
Jan  9 12:59:02.975: INFO: namespace e2e-tests-secrets-9lb72 deletion completed in 6.041288515s

• [SLOW TEST:10.101 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:59:02.976: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-zlzpq
Jan  9 12:59:07.013: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-zlzpq
STEP: checking the pod's current state and verifying that restartCount is present
Jan  9 12:59:07.015: INFO: Initial restart count of pod liveness-exec is 0
Jan  9 12:59:53.057: INFO: Restart count of pod e2e-tests-container-probe-zlzpq/liveness-exec is now 1 (46.041935179s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 12:59:53.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-zlzpq" for this suite.
Jan  9 12:59:59.065: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 12:59:59.092: INFO: namespace: e2e-tests-container-probe-zlzpq, resource: bindings, ignored listing per whitelist
Jan  9 12:59:59.104: INFO: namespace e2e-tests-container-probe-zlzpq deletion completed in 6.043319874s

• [SLOW TEST:56.129 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 12:59:59.104: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1358
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan  9 12:59:59.135: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-x8l6w'
Jan  9 12:59:59.200: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jan  9 12:59:59.200: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: rolling-update to same image controller
Jan  9 12:59:59.203: INFO: scanned /root for discovery docs: <nil>
Jan  9 12:59:59.203: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-x8l6w'
Jan  9 13:00:14.905: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Jan  9 13:00:14.905: INFO: stdout: "Created e2e-test-nginx-rc-734de949482ac25681cb91fa5674725b\nScaling up e2e-test-nginx-rc-734de949482ac25681cb91fa5674725b from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-734de949482ac25681cb91fa5674725b up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-734de949482ac25681cb91fa5674725b to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Jan  9 13:00:14.905: INFO: stdout: "Created e2e-test-nginx-rc-734de949482ac25681cb91fa5674725b\nScaling up e2e-test-nginx-rc-734de949482ac25681cb91fa5674725b from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-734de949482ac25681cb91fa5674725b up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-734de949482ac25681cb91fa5674725b to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Jan  9 13:00:14.905: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-x8l6w'
Jan  9 13:00:14.969: INFO: stderr: ""
Jan  9 13:00:14.969: INFO: stdout: "e2e-test-nginx-rc-734de949482ac25681cb91fa5674725b-ppvht "
Jan  9 13:00:14.969: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 get pods e2e-test-nginx-rc-734de949482ac25681cb91fa5674725b-ppvht -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-x8l6w'
Jan  9 13:00:15.031: INFO: stderr: ""
Jan  9 13:00:15.031: INFO: stdout: "true"
Jan  9 13:00:15.031: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 get pods e2e-test-nginx-rc-734de949482ac25681cb91fa5674725b-ppvht -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-x8l6w'
Jan  9 13:00:15.091: INFO: stderr: ""
Jan  9 13:00:15.091: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Jan  9 13:00:15.092: INFO: e2e-test-nginx-rc-734de949482ac25681cb91fa5674725b-ppvht is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1364
Jan  9 13:00:15.092: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-x8l6w'
Jan  9 13:00:15.155: INFO: stderr: ""
Jan  9 13:00:15.155: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:00:15.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-x8l6w" for this suite.
Jan  9 13:00:21.161: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:00:21.171: INFO: namespace: e2e-tests-kubectl-x8l6w, resource: bindings, ignored listing per whitelist
Jan  9 13:00:21.197: INFO: namespace e2e-tests-kubectl-x8l6w deletion completed in 6.040421297s

• [SLOW TEST:22.093 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:00:21.197: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-wtrfr
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-wtrfr
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-wtrfr
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-wtrfr
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-wtrfr
Jan  9 13:00:25.244: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-wtrfr, name: ss-0, uid: 87b56dd9-140e-11e9-90b5-12841864fc48, status phase: Pending. Waiting for statefulset controller to delete.
Jan  9 13:00:25.636: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-wtrfr, name: ss-0, uid: 87b56dd9-140e-11e9-90b5-12841864fc48, status phase: Failed. Waiting for statefulset controller to delete.
Jan  9 13:00:25.638: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-wtrfr, name: ss-0, uid: 87b56dd9-140e-11e9-90b5-12841864fc48, status phase: Failed. Waiting for statefulset controller to delete.
Jan  9 13:00:25.639: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-wtrfr
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-wtrfr
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-wtrfr and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan  9 13:00:29.649: INFO: Deleting all statefulset in ns e2e-tests-statefulset-wtrfr
Jan  9 13:00:29.650: INFO: Scaling statefulset ss to 0
Jan  9 13:00:49.657: INFO: Waiting for statefulset status.replicas updated to 0
Jan  9 13:00:49.658: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:00:49.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-wtrfr" for this suite.
Jan  9 13:00:55.668: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:00:55.674: INFO: namespace: e2e-tests-statefulset-wtrfr, resource: bindings, ignored listing per whitelist
Jan  9 13:00:55.704: INFO: namespace e2e-tests-statefulset-wtrfr deletion completed in 6.040561997s

• [SLOW TEST:34.507 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:00:55.704: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-9a014140-140e-11e9-a571-02181533b527
STEP: Creating secret with name secret-projected-all-test-volume-9a014125-140e-11e9-a571-02181533b527
STEP: Creating a pod to test Check all projections for projected volume plugin
Jan  9 13:00:55.743: INFO: Waiting up to 5m0s for pod "projected-volume-9a0140ea-140e-11e9-a571-02181533b527" in namespace "e2e-tests-projected-58f7g" to be "success or failure"
Jan  9 13:00:55.745: INFO: Pod "projected-volume-9a0140ea-140e-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.778588ms
Jan  9 13:00:57.746: INFO: Pod "projected-volume-9a0140ea-140e-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0032884s
STEP: Saw pod success
Jan  9 13:00:57.746: INFO: Pod "projected-volume-9a0140ea-140e-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 13:00:57.747: INFO: Trying to get logs from node ip-172-31-59-90 pod projected-volume-9a0140ea-140e-11e9-a571-02181533b527 container projected-all-volume-test: <nil>
STEP: delete the pod
Jan  9 13:00:57.756: INFO: Waiting for pod projected-volume-9a0140ea-140e-11e9-a571-02181533b527 to disappear
Jan  9 13:00:57.757: INFO: Pod projected-volume-9a0140ea-140e-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:00:57.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-58f7g" for this suite.
Jan  9 13:01:03.763: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:01:03.791: INFO: namespace: e2e-tests-projected-58f7g, resource: bindings, ignored listing per whitelist
Jan  9 13:01:03.800: INFO: namespace e2e-tests-projected-58f7g deletion completed in 6.041342353s

• [SLOW TEST:8.095 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:01:03.800: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jan  9 13:01:06.346: INFO: Successfully updated pod "labelsupdate9ed42eb9-140e-11e9-a571-02181533b527"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:01:08.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-lnbnr" for this suite.
Jan  9 13:01:30.362: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:01:30.375: INFO: namespace: e2e-tests-projected-lnbnr, resource: bindings, ignored listing per whitelist
Jan  9 13:01:30.396: INFO: namespace e2e-tests-projected-lnbnr deletion completed in 22.039703936s

• [SLOW TEST:26.597 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:01:30.397: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-d7n5m
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan  9 13:01:30.429: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan  9 13:01:52.449: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.1.1.193:8080/dial?request=hostName&protocol=udp&host=10.1.1.192&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-d7n5m PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan  9 13:01:52.449: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
Jan  9 13:01:52.526: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:01:52.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-d7n5m" for this suite.
Jan  9 13:02:14.532: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:02:14.554: INFO: namespace: e2e-tests-pod-network-test-d7n5m, resource: bindings, ignored listing per whitelist
Jan  9 13:02:14.568: INFO: namespace e2e-tests-pod-network-test-d7n5m deletion completed in 22.040614442s

• [SLOW TEST:44.171 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:02:14.568: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1134
STEP: creating an rc
Jan  9 13:02:14.599: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 create -f - --namespace=e2e-tests-kubectl-r88lx'
Jan  9 13:02:14.734: INFO: stderr: ""
Jan  9 13:02:14.734: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Jan  9 13:02:15.739: INFO: Selector matched 1 pods for map[app:redis]
Jan  9 13:02:15.739: INFO: Found 0 / 1
Jan  9 13:02:16.736: INFO: Selector matched 1 pods for map[app:redis]
Jan  9 13:02:16.736: INFO: Found 0 / 1
Jan  9 13:02:17.736: INFO: Selector matched 1 pods for map[app:redis]
Jan  9 13:02:17.736: INFO: Found 1 / 1
Jan  9 13:02:17.736: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jan  9 13:02:17.737: INFO: Selector matched 1 pods for map[app:redis]
Jan  9 13:02:17.737: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Jan  9 13:02:17.737: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 logs redis-master-mhbdh redis-master --namespace=e2e-tests-kubectl-r88lx'
Jan  9 13:02:17.809: INFO: stderr: ""
Jan  9 13:02:17.809: INFO: stdout: "1:M 09 Jan 13:02:15.949 # You requested maxclients of 10000 requiring at least 10032 max file descriptors.\n1:M 09 Jan 13:02:15.949 # Server can't set maximum open files to 10032 because of OS error: Operation not permitted.\n1:M 09 Jan 13:02:15.949 # Current maximum open files is 4096. maxclients has been reduced to 4064 to compensate for low ulimit. If you need higher maxclients increase 'ulimit -n'.\n                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 09 Jan 13:02:15.949 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 09 Jan 13:02:15.949 # Server started, Redis version 3.2.12\n1:M 09 Jan 13:02:15.949 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 09 Jan 13:02:15.949 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Jan  9 13:02:17.809: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 log redis-master-mhbdh redis-master --namespace=e2e-tests-kubectl-r88lx --tail=1'
Jan  9 13:02:17.875: INFO: stderr: ""
Jan  9 13:02:17.875: INFO: stdout: "1:M 09 Jan 13:02:15.949 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Jan  9 13:02:17.875: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 log redis-master-mhbdh redis-master --namespace=e2e-tests-kubectl-r88lx --limit-bytes=1'
Jan  9 13:02:17.942: INFO: stderr: ""
Jan  9 13:02:17.942: INFO: stdout: "1"
STEP: exposing timestamps
Jan  9 13:02:17.942: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 log redis-master-mhbdh redis-master --namespace=e2e-tests-kubectl-r88lx --tail=1 --timestamps'
Jan  9 13:02:18.010: INFO: stderr: ""
Jan  9 13:02:18.010: INFO: stdout: "2019-01-09T13:02:15.949685528Z 1:M 09 Jan 13:02:15.949 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Jan  9 13:02:20.510: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 log redis-master-mhbdh redis-master --namespace=e2e-tests-kubectl-r88lx --since=1s'
Jan  9 13:02:20.577: INFO: stderr: ""
Jan  9 13:02:20.577: INFO: stdout: ""
Jan  9 13:02:20.577: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 log redis-master-mhbdh redis-master --namespace=e2e-tests-kubectl-r88lx --since=24h'
Jan  9 13:02:20.645: INFO: stderr: ""
Jan  9 13:02:20.645: INFO: stdout: "1:M 09 Jan 13:02:15.949 # You requested maxclients of 10000 requiring at least 10032 max file descriptors.\n1:M 09 Jan 13:02:15.949 # Server can't set maximum open files to 10032 because of OS error: Operation not permitted.\n1:M 09 Jan 13:02:15.949 # Current maximum open files is 4096. maxclients has been reduced to 4064 to compensate for low ulimit. If you need higher maxclients increase 'ulimit -n'.\n                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 09 Jan 13:02:15.949 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 09 Jan 13:02:15.949 # Server started, Redis version 3.2.12\n1:M 09 Jan 13:02:15.949 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 09 Jan 13:02:15.949 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1140
STEP: using delete to clean up resources
Jan  9 13:02:20.645: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-r88lx'
Jan  9 13:02:20.707: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan  9 13:02:20.707: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Jan  9 13:02:20.707: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-r88lx'
Jan  9 13:02:20.770: INFO: stderr: "No resources found.\n"
Jan  9 13:02:20.770: INFO: stdout: ""
Jan  9 13:02:20.770: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 get pods -l name=nginx --namespace=e2e-tests-kubectl-r88lx -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan  9 13:02:20.832: INFO: stderr: ""
Jan  9 13:02:20.832: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:02:20.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-r88lx" for this suite.
Jan  9 13:02:42.838: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:02:42.865: INFO: namespace: e2e-tests-kubectl-r88lx, resource: bindings, ignored listing per whitelist
Jan  9 13:02:42.877: INFO: namespace e2e-tests-kubectl-r88lx deletion completed in 22.043353715s

• [SLOW TEST:28.309 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:02:42.877: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-m2fn
STEP: Creating a pod to test atomic-volume-subpath
Jan  9 13:02:42.913: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-m2fn" in namespace "e2e-tests-subpath-bv4np" to be "success or failure"
Jan  9 13:02:42.915: INFO: Pod "pod-subpath-test-downwardapi-m2fn": Phase="Pending", Reason="", readiness=false. Elapsed: 2.070806ms
Jan  9 13:02:44.917: INFO: Pod "pod-subpath-test-downwardapi-m2fn": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004175682s
Jan  9 13:02:46.919: INFO: Pod "pod-subpath-test-downwardapi-m2fn": Phase="Running", Reason="", readiness=false. Elapsed: 4.006109007s
Jan  9 13:02:48.921: INFO: Pod "pod-subpath-test-downwardapi-m2fn": Phase="Running", Reason="", readiness=false. Elapsed: 6.008023266s
Jan  9 13:02:50.923: INFO: Pod "pod-subpath-test-downwardapi-m2fn": Phase="Running", Reason="", readiness=false. Elapsed: 8.010030448s
Jan  9 13:02:52.924: INFO: Pod "pod-subpath-test-downwardapi-m2fn": Phase="Running", Reason="", readiness=false. Elapsed: 10.011746353s
Jan  9 13:02:54.926: INFO: Pod "pod-subpath-test-downwardapi-m2fn": Phase="Running", Reason="", readiness=false. Elapsed: 12.013739915s
Jan  9 13:02:56.928: INFO: Pod "pod-subpath-test-downwardapi-m2fn": Phase="Running", Reason="", readiness=false. Elapsed: 14.015660417s
Jan  9 13:02:58.930: INFO: Pod "pod-subpath-test-downwardapi-m2fn": Phase="Running", Reason="", readiness=false. Elapsed: 16.017450707s
Jan  9 13:03:00.933: INFO: Pod "pod-subpath-test-downwardapi-m2fn": Phase="Running", Reason="", readiness=false. Elapsed: 18.02043868s
Jan  9 13:03:02.935: INFO: Pod "pod-subpath-test-downwardapi-m2fn": Phase="Running", Reason="", readiness=false. Elapsed: 20.022424816s
Jan  9 13:03:04.937: INFO: Pod "pod-subpath-test-downwardapi-m2fn": Phase="Running", Reason="", readiness=false. Elapsed: 22.024337105s
Jan  9 13:03:06.939: INFO: Pod "pod-subpath-test-downwardapi-m2fn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.02622294s
STEP: Saw pod success
Jan  9 13:03:06.939: INFO: Pod "pod-subpath-test-downwardapi-m2fn" satisfied condition "success or failure"
Jan  9 13:03:06.940: INFO: Trying to get logs from node ip-172-31-59-90 pod pod-subpath-test-downwardapi-m2fn container test-container-subpath-downwardapi-m2fn: <nil>
STEP: delete the pod
Jan  9 13:03:06.948: INFO: Waiting for pod pod-subpath-test-downwardapi-m2fn to disappear
Jan  9 13:03:06.949: INFO: Pod pod-subpath-test-downwardapi-m2fn no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-m2fn
Jan  9 13:03:06.949: INFO: Deleting pod "pod-subpath-test-downwardapi-m2fn" in namespace "e2e-tests-subpath-bv4np"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:03:06.950: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-bv4np" for this suite.
Jan  9 13:03:12.956: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:03:12.974: INFO: namespace: e2e-tests-subpath-bv4np, resource: bindings, ignored listing per whitelist
Jan  9 13:03:12.993: INFO: namespace e2e-tests-subpath-bv4np deletion completed in 6.041980917s

• [SLOW TEST:30.116 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:03:12.993: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-ebd5942d-140e-11e9-a571-02181533b527
STEP: Creating a pod to test consume configMaps
Jan  9 13:03:13.029: INFO: Waiting up to 5m0s for pod "pod-configmaps-ebd5e514-140e-11e9-a571-02181533b527" in namespace "e2e-tests-configmap-2dwqq" to be "success or failure"
Jan  9 13:03:13.030: INFO: Pod "pod-configmaps-ebd5e514-140e-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.071096ms
Jan  9 13:03:15.032: INFO: Pod "pod-configmaps-ebd5e514-140e-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 2.002535769s
Jan  9 13:03:17.034: INFO: Pod "pod-configmaps-ebd5e514-140e-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.004339683s
STEP: Saw pod success
Jan  9 13:03:17.034: INFO: Pod "pod-configmaps-ebd5e514-140e-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 13:03:17.035: INFO: Trying to get logs from node ip-172-31-59-90 pod pod-configmaps-ebd5e514-140e-11e9-a571-02181533b527 container configmap-volume-test: <nil>
STEP: delete the pod
Jan  9 13:03:17.043: INFO: Waiting for pod pod-configmaps-ebd5e514-140e-11e9-a571-02181533b527 to disappear
Jan  9 13:03:17.044: INFO: Pod pod-configmaps-ebd5e514-140e-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:03:17.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-2dwqq" for this suite.
Jan  9 13:03:23.050: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:03:23.059: INFO: namespace: e2e-tests-configmap-2dwqq, resource: bindings, ignored listing per whitelist
Jan  9 13:03:23.086: INFO: namespace e2e-tests-configmap-2dwqq deletion completed in 6.040954028s

• [SLOW TEST:10.093 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:03:23.086: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Jan  9 13:03:23.124: INFO: Waiting up to 5m0s for pod "var-expansion-f1da4120-140e-11e9-a571-02181533b527" in namespace "e2e-tests-var-expansion-tlsrm" to be "success or failure"
Jan  9 13:03:23.125: INFO: Pod "var-expansion-f1da4120-140e-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.072899ms
Jan  9 13:03:25.127: INFO: Pod "var-expansion-f1da4120-140e-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00295554s
Jan  9 13:03:27.129: INFO: Pod "var-expansion-f1da4120-140e-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0049662s
STEP: Saw pod success
Jan  9 13:03:27.129: INFO: Pod "var-expansion-f1da4120-140e-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 13:03:27.130: INFO: Trying to get logs from node ip-172-31-59-90 pod var-expansion-f1da4120-140e-11e9-a571-02181533b527 container dapi-container: <nil>
STEP: delete the pod
Jan  9 13:03:27.139: INFO: Waiting for pod var-expansion-f1da4120-140e-11e9-a571-02181533b527 to disappear
Jan  9 13:03:27.140: INFO: Pod var-expansion-f1da4120-140e-11e9-a571-02181533b527 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:03:27.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-tlsrm" for this suite.
Jan  9 13:03:33.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:03:33.170: INFO: namespace: e2e-tests-var-expansion-tlsrm, resource: bindings, ignored listing per whitelist
Jan  9 13:03:33.181: INFO: namespace e2e-tests-var-expansion-tlsrm deletion completed in 6.040164431s

• [SLOW TEST:10.095 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:03:33.181: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-f7ddf456-140e-11e9-a571-02181533b527
STEP: Creating a pod to test consume secrets
Jan  9 13:03:33.216: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f7de2db6-140e-11e9-a571-02181533b527" in namespace "e2e-tests-projected-bwcs9" to be "success or failure"
Jan  9 13:03:33.217: INFO: Pod "pod-projected-secrets-f7de2db6-140e-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 977.475µs
Jan  9 13:03:35.219: INFO: Pod "pod-projected-secrets-f7de2db6-140e-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 2.002831479s
Jan  9 13:03:37.221: INFO: Pod "pod-projected-secrets-f7de2db6-140e-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.004672495s
STEP: Saw pod success
Jan  9 13:03:37.221: INFO: Pod "pod-projected-secrets-f7de2db6-140e-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 13:03:37.222: INFO: Trying to get logs from node ip-172-31-59-90 pod pod-projected-secrets-f7de2db6-140e-11e9-a571-02181533b527 container secret-volume-test: <nil>
STEP: delete the pod
Jan  9 13:03:37.230: INFO: Waiting for pod pod-projected-secrets-f7de2db6-140e-11e9-a571-02181533b527 to disappear
Jan  9 13:03:37.231: INFO: Pod pod-projected-secrets-f7de2db6-140e-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:03:37.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bwcs9" for this suite.
Jan  9 13:03:43.237: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:03:43.264: INFO: namespace: e2e-tests-projected-bwcs9, resource: bindings, ignored listing per whitelist
Jan  9 13:03:43.272: INFO: namespace e2e-tests-projected-bwcs9 deletion completed in 6.040641172s

• [SLOW TEST:10.091 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:03:43.273: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan  9 13:03:43.307: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fde1c9e7-140e-11e9-a571-02181533b527" in namespace "e2e-tests-downward-api-7db9t" to be "success or failure"
Jan  9 13:03:43.309: INFO: Pod "downwardapi-volume-fde1c9e7-140e-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 2.332889ms
Jan  9 13:03:45.311: INFO: Pod "downwardapi-volume-fde1c9e7-140e-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004148295s
Jan  9 13:03:47.313: INFO: Pod "downwardapi-volume-fde1c9e7-140e-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006051446s
STEP: Saw pod success
Jan  9 13:03:47.313: INFO: Pod "downwardapi-volume-fde1c9e7-140e-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 13:03:47.314: INFO: Trying to get logs from node ip-172-31-59-90 pod downwardapi-volume-fde1c9e7-140e-11e9-a571-02181533b527 container client-container: <nil>
STEP: delete the pod
Jan  9 13:03:47.324: INFO: Waiting for pod downwardapi-volume-fde1c9e7-140e-11e9-a571-02181533b527 to disappear
Jan  9 13:03:47.325: INFO: Pod downwardapi-volume-fde1c9e7-140e-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:03:47.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7db9t" for this suite.
Jan  9 13:03:53.330: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:03:53.347: INFO: namespace: e2e-tests-downward-api-7db9t, resource: bindings, ignored listing per whitelist
Jan  9 13:03:53.366: INFO: namespace e2e-tests-downward-api-7db9t deletion completed in 6.03984769s

• [SLOW TEST:10.093 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:03:53.366: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan  9 13:03:53.408: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
Jan  9 13:03:53.411: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-pnfbk/daemonsets","resourceVersion":"12434"},"items":null}

Jan  9 13:03:53.412: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-pnfbk/pods","resourceVersion":"12434"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:03:53.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-pnfbk" for this suite.
Jan  9 13:03:59.420: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:03:59.456: INFO: namespace: e2e-tests-daemonsets-pnfbk, resource: bindings, ignored listing per whitelist
Jan  9 13:03:59.457: INFO: namespace e2e-tests-daemonsets-pnfbk deletion completed in 6.041572534s

S [SKIPPING] [6.091 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Jan  9 13:03:53.408: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:03:59.457: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan  9 13:03:59.491: INFO: Waiting up to 5m0s for pod "downwardapi-volume-07875b1e-140f-11e9-a571-02181533b527" in namespace "e2e-tests-projected-gk5z9" to be "success or failure"
Jan  9 13:03:59.494: INFO: Pod "downwardapi-volume-07875b1e-140f-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 3.348301ms
Jan  9 13:04:01.496: INFO: Pod "downwardapi-volume-07875b1e-140f-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00521033s
Jan  9 13:04:03.498: INFO: Pod "downwardapi-volume-07875b1e-140f-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007114834s
STEP: Saw pod success
Jan  9 13:04:03.498: INFO: Pod "downwardapi-volume-07875b1e-140f-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 13:04:03.499: INFO: Trying to get logs from node ip-172-31-59-90 pod downwardapi-volume-07875b1e-140f-11e9-a571-02181533b527 container client-container: <nil>
STEP: delete the pod
Jan  9 13:04:03.506: INFO: Waiting for pod downwardapi-volume-07875b1e-140f-11e9-a571-02181533b527 to disappear
Jan  9 13:04:03.507: INFO: Pod downwardapi-volume-07875b1e-140f-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:04:03.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gk5z9" for this suite.
Jan  9 13:04:09.514: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:04:09.542: INFO: namespace: e2e-tests-projected-gk5z9, resource: bindings, ignored listing per whitelist
Jan  9 13:04:09.551: INFO: namespace e2e-tests-projected-gk5z9 deletion completed in 6.042493796s

• [SLOW TEST:10.094 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:04:09.551: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan  9 13:04:09.585: INFO: Creating deployment "test-recreate-deployment"
Jan  9 13:04:09.587: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Jan  9 13:04:09.589: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Jan  9 13:04:11.592: INFO: Waiting deployment "test-recreate-deployment" to complete
Jan  9 13:04:11.593: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682635849, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682635849, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682635849, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682635849, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-5dfdcc846d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan  9 13:04:13.595: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Jan  9 13:04:13.598: INFO: Updating deployment test-recreate-deployment
Jan  9 13:04:13.598: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan  9 13:04:13.628: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-vr66f,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-vr66f/deployments/test-recreate-deployment,UID:0d8c10e4-140f-11e9-90b5-12841864fc48,ResourceVersion:12529,Generation:2,CreationTimestamp:2019-01-09 13:04:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-01-09 13:04:13 +0000 UTC 2019-01-09 13:04:13 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-01-09 13:04:13 +0000 UTC 2019-01-09 13:04:09 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-697fbf54bf" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Jan  9 13:04:13.629: INFO: New ReplicaSet "test-recreate-deployment-697fbf54bf" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf,GenerateName:,Namespace:e2e-tests-deployment-vr66f,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-vr66f/replicasets/test-recreate-deployment-697fbf54bf,UID:0ff28c23-140f-11e9-90b5-12841864fc48,ResourceVersion:12527,Generation:1,CreationTimestamp:2019-01-09 13:04:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 0d8c10e4-140f-11e9-90b5-12841864fc48 0xc001aa0117 0xc001aa0118}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan  9 13:04:13.629: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Jan  9 13:04:13.629: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5dfdcc846d,GenerateName:,Namespace:e2e-tests-deployment-vr66f,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-vr66f/replicasets/test-recreate-deployment-5dfdcc846d,UID:0d8c5214-140f-11e9-90b5-12841864fc48,ResourceVersion:12518,Generation:2,CreationTimestamp:2019-01-09 13:04:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 0d8c10e4-140f-11e9-90b5-12841864fc48 0xc001941fa7 0xc001941fa8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan  9 13:04:13.631: INFO: Pod "test-recreate-deployment-697fbf54bf-k945f" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf-k945f,GenerateName:test-recreate-deployment-697fbf54bf-,Namespace:e2e-tests-deployment-vr66f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-vr66f/pods/test-recreate-deployment-697fbf54bf-k945f,UID:0ff2d231-140f-11e9-90b5-12841864fc48,ResourceVersion:12530,Generation:0,CreationTimestamp:2019-01-09 13:04:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-697fbf54bf 0ff28c23-140f-11e9-90b5-12841864fc48 0xc001aa0c47 0xc001aa0c48}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rsjxp {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rsjxp,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rsjxp true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-59-90,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001aa0cc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001aa0ce0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:04:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:04:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:04:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:04:13 +0000 UTC  }],Message:,Reason:,HostIP:172.31.59.90,PodIP:,StartTime:2019-01-09 13:04:13 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:04:13.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-vr66f" for this suite.
Jan  9 13:04:19.636: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:04:19.672: INFO: namespace: e2e-tests-deployment-vr66f, resource: bindings, ignored listing per whitelist
Jan  9 13:04:19.672: INFO: namespace e2e-tests-deployment-vr66f deletion completed in 6.040327027s

• [SLOW TEST:10.122 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:04:19.673: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-hsb4
STEP: Creating a pod to test atomic-volume-subpath
Jan  9 13:04:19.710: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-hsb4" in namespace "e2e-tests-subpath-flnmd" to be "success or failure"
Jan  9 13:04:19.712: INFO: Pod "pod-subpath-test-configmap-hsb4": Phase="Pending", Reason="", readiness=false. Elapsed: 1.832102ms
Jan  9 13:04:21.714: INFO: Pod "pod-subpath-test-configmap-hsb4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003861542s
Jan  9 13:04:23.716: INFO: Pod "pod-subpath-test-configmap-hsb4": Phase="Running", Reason="", readiness=false. Elapsed: 4.005814402s
Jan  9 13:04:25.718: INFO: Pod "pod-subpath-test-configmap-hsb4": Phase="Running", Reason="", readiness=false. Elapsed: 6.007759296s
Jan  9 13:04:27.720: INFO: Pod "pod-subpath-test-configmap-hsb4": Phase="Running", Reason="", readiness=false. Elapsed: 8.009666989s
Jan  9 13:04:29.722: INFO: Pod "pod-subpath-test-configmap-hsb4": Phase="Running", Reason="", readiness=false. Elapsed: 10.011609932s
Jan  9 13:04:31.724: INFO: Pod "pod-subpath-test-configmap-hsb4": Phase="Running", Reason="", readiness=false. Elapsed: 12.013648053s
Jan  9 13:04:33.726: INFO: Pod "pod-subpath-test-configmap-hsb4": Phase="Running", Reason="", readiness=false. Elapsed: 14.015658294s
Jan  9 13:04:35.728: INFO: Pod "pod-subpath-test-configmap-hsb4": Phase="Running", Reason="", readiness=false. Elapsed: 16.017517843s
Jan  9 13:04:37.730: INFO: Pod "pod-subpath-test-configmap-hsb4": Phase="Running", Reason="", readiness=false. Elapsed: 18.019458447s
Jan  9 13:04:39.732: INFO: Pod "pod-subpath-test-configmap-hsb4": Phase="Running", Reason="", readiness=false. Elapsed: 20.021314953s
Jan  9 13:04:41.734: INFO: Pod "pod-subpath-test-configmap-hsb4": Phase="Running", Reason="", readiness=false. Elapsed: 22.023244728s
Jan  9 13:04:43.736: INFO: Pod "pod-subpath-test-configmap-hsb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.02507097s
STEP: Saw pod success
Jan  9 13:04:43.736: INFO: Pod "pod-subpath-test-configmap-hsb4" satisfied condition "success or failure"
Jan  9 13:04:43.737: INFO: Trying to get logs from node ip-172-31-59-90 pod pod-subpath-test-configmap-hsb4 container test-container-subpath-configmap-hsb4: <nil>
STEP: delete the pod
Jan  9 13:04:43.747: INFO: Waiting for pod pod-subpath-test-configmap-hsb4 to disappear
Jan  9 13:04:43.748: INFO: Pod pod-subpath-test-configmap-hsb4 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-hsb4
Jan  9 13:04:43.748: INFO: Deleting pod "pod-subpath-test-configmap-hsb4" in namespace "e2e-tests-subpath-flnmd"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:04:43.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-flnmd" for this suite.
Jan  9 13:04:49.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:04:49.762: INFO: namespace: e2e-tests-subpath-flnmd, resource: bindings, ignored listing per whitelist
Jan  9 13:04:49.793: INFO: namespace e2e-tests-subpath-flnmd deletion completed in 6.042737463s

• [SLOW TEST:30.121 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:04:49.793: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:04:49.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-2b2mc" for this suite.
Jan  9 13:05:11.838: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:05:11.862: INFO: namespace: e2e-tests-pods-2b2mc, resource: bindings, ignored listing per whitelist
Jan  9 13:05:11.875: INFO: namespace e2e-tests-pods-2b2mc deletion completed in 22.042784701s

• [SLOW TEST:22.082 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:05:11.875: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Jan  9 13:05:12.412: INFO: Waiting up to 5m0s for pod "pod-service-account-32fe1d2f-140f-11e9-a571-02181533b527-djlkd" in namespace "e2e-tests-svcaccounts-p5kvr" to be "success or failure"
Jan  9 13:05:12.413: INFO: Pod "pod-service-account-32fe1d2f-140f-11e9-a571-02181533b527-djlkd": Phase="Pending", Reason="", readiness=false. Elapsed: 1.303949ms
Jan  9 13:05:14.416: INFO: Pod "pod-service-account-32fe1d2f-140f-11e9-a571-02181533b527-djlkd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004605842s
STEP: Saw pod success
Jan  9 13:05:14.416: INFO: Pod "pod-service-account-32fe1d2f-140f-11e9-a571-02181533b527-djlkd" satisfied condition "success or failure"
Jan  9 13:05:14.418: INFO: Trying to get logs from node ip-172-31-59-90 pod pod-service-account-32fe1d2f-140f-11e9-a571-02181533b527-djlkd container token-test: <nil>
STEP: delete the pod
Jan  9 13:05:14.426: INFO: Waiting for pod pod-service-account-32fe1d2f-140f-11e9-a571-02181533b527-djlkd to disappear
Jan  9 13:05:14.428: INFO: Pod pod-service-account-32fe1d2f-140f-11e9-a571-02181533b527-djlkd no longer exists
STEP: Creating a pod to test consume service account root CA
Jan  9 13:05:14.430: INFO: Waiting up to 5m0s for pod "pod-service-account-32fe1d2f-140f-11e9-a571-02181533b527-mxqlm" in namespace "e2e-tests-svcaccounts-p5kvr" to be "success or failure"
Jan  9 13:05:14.432: INFO: Pod "pod-service-account-32fe1d2f-140f-11e9-a571-02181533b527-mxqlm": Phase="Pending", Reason="", readiness=false. Elapsed: 2.141012ms
Jan  9 13:05:16.434: INFO: Pod "pod-service-account-32fe1d2f-140f-11e9-a571-02181533b527-mxqlm": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003981881s
STEP: Saw pod success
Jan  9 13:05:16.434: INFO: Pod "pod-service-account-32fe1d2f-140f-11e9-a571-02181533b527-mxqlm" satisfied condition "success or failure"
Jan  9 13:05:16.435: INFO: Trying to get logs from node ip-172-31-59-90 pod pod-service-account-32fe1d2f-140f-11e9-a571-02181533b527-mxqlm container root-ca-test: <nil>
STEP: delete the pod
Jan  9 13:05:16.445: INFO: Waiting for pod pod-service-account-32fe1d2f-140f-11e9-a571-02181533b527-mxqlm to disappear
Jan  9 13:05:16.446: INFO: Pod pod-service-account-32fe1d2f-140f-11e9-a571-02181533b527-mxqlm no longer exists
STEP: Creating a pod to test consume service account namespace
Jan  9 13:05:16.448: INFO: Waiting up to 5m0s for pod "pod-service-account-32fe1d2f-140f-11e9-a571-02181533b527-qdngm" in namespace "e2e-tests-svcaccounts-p5kvr" to be "success or failure"
Jan  9 13:05:16.450: INFO: Pod "pod-service-account-32fe1d2f-140f-11e9-a571-02181533b527-qdngm": Phase="Pending", Reason="", readiness=false. Elapsed: 1.607115ms
Jan  9 13:05:18.451: INFO: Pod "pod-service-account-32fe1d2f-140f-11e9-a571-02181533b527-qdngm": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003294281s
STEP: Saw pod success
Jan  9 13:05:18.451: INFO: Pod "pod-service-account-32fe1d2f-140f-11e9-a571-02181533b527-qdngm" satisfied condition "success or failure"
Jan  9 13:05:18.452: INFO: Trying to get logs from node ip-172-31-59-90 pod pod-service-account-32fe1d2f-140f-11e9-a571-02181533b527-qdngm container namespace-test: <nil>
STEP: delete the pod
Jan  9 13:05:18.465: INFO: Waiting for pod pod-service-account-32fe1d2f-140f-11e9-a571-02181533b527-qdngm to disappear
Jan  9 13:05:18.466: INFO: Pod pod-service-account-32fe1d2f-140f-11e9-a571-02181533b527-qdngm no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:05:18.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-p5kvr" for this suite.
Jan  9 13:05:24.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:05:24.477: INFO: namespace: e2e-tests-svcaccounts-p5kvr, resource: bindings, ignored listing per whitelist
Jan  9 13:05:24.514: INFO: namespace e2e-tests-svcaccounts-p5kvr deletion completed in 6.046495058s

• [SLOW TEST:12.639 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:05:24.514: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-3a3a3f4f-140f-11e9-a571-02181533b527
STEP: Creating a pod to test consume configMaps
Jan  9 13:05:24.553: INFO: Waiting up to 5m0s for pod "pod-configmaps-3a3a7972-140f-11e9-a571-02181533b527" in namespace "e2e-tests-configmap-77mrd" to be "success or failure"
Jan  9 13:05:24.554: INFO: Pod "pod-configmaps-3a3a7972-140f-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.071797ms
Jan  9 13:05:26.556: INFO: Pod "pod-configmaps-3a3a7972-140f-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.002815349s
STEP: Saw pod success
Jan  9 13:05:26.556: INFO: Pod "pod-configmaps-3a3a7972-140f-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 13:05:26.557: INFO: Trying to get logs from node ip-172-31-59-90 pod pod-configmaps-3a3a7972-140f-11e9-a571-02181533b527 container configmap-volume-test: <nil>
STEP: delete the pod
Jan  9 13:05:26.565: INFO: Waiting for pod pod-configmaps-3a3a7972-140f-11e9-a571-02181533b527 to disappear
Jan  9 13:05:26.566: INFO: Pod pod-configmaps-3a3a7972-140f-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:05:26.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-77mrd" for this suite.
Jan  9 13:05:32.573: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:05:32.577: INFO: namespace: e2e-tests-configmap-77mrd, resource: bindings, ignored listing per whitelist
Jan  9 13:05:32.608: INFO: namespace e2e-tests-configmap-77mrd deletion completed in 6.039517748s

• [SLOW TEST:8.094 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:05:32.608: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Jan  9 13:05:32.642: INFO: Waiting up to 5m0s for pod "pod-3f0d2300-140f-11e9-a571-02181533b527" in namespace "e2e-tests-emptydir-8nrnz" to be "success or failure"
Jan  9 13:05:32.643: INFO: Pod "pod-3f0d2300-140f-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.007978ms
Jan  9 13:05:34.648: INFO: Pod "pod-3f0d2300-140f-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005540873s
STEP: Saw pod success
Jan  9 13:05:34.648: INFO: Pod "pod-3f0d2300-140f-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 13:05:34.649: INFO: Trying to get logs from node ip-172-31-59-90 pod pod-3f0d2300-140f-11e9-a571-02181533b527 container test-container: <nil>
STEP: delete the pod
Jan  9 13:05:34.656: INFO: Waiting for pod pod-3f0d2300-140f-11e9-a571-02181533b527 to disappear
Jan  9 13:05:34.657: INFO: Pod pod-3f0d2300-140f-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:05:34.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-8nrnz" for this suite.
Jan  9 13:05:40.662: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:05:40.681: INFO: namespace: e2e-tests-emptydir-8nrnz, resource: bindings, ignored listing per whitelist
Jan  9 13:05:40.700: INFO: namespace e2e-tests-emptydir-8nrnz deletion completed in 6.042580849s

• [SLOW TEST:8.092 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:05:40.701: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-l5lzb
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-l5lzb
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-l5lzb
Jan  9 13:05:40.738: INFO: Found 0 stateful pods, waiting for 1
Jan  9 13:05:50.741: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Jan  9 13:05:50.742: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 exec --namespace=e2e-tests-statefulset-l5lzb ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan  9 13:05:50.876: INFO: stderr: ""
Jan  9 13:05:50.876: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan  9 13:05:50.876: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan  9 13:05:50.878: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jan  9 13:06:00.881: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan  9 13:06:00.881: INFO: Waiting for statefulset status.replicas updated to 0
Jan  9 13:06:00.886: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999062s
Jan  9 13:06:01.889: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.998382446s
Jan  9 13:06:02.891: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.996280366s
Jan  9 13:06:03.893: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.994165744s
Jan  9 13:06:04.895: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.991895993s
Jan  9 13:06:05.897: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.989624299s
Jan  9 13:06:06.900: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.987472554s
Jan  9 13:06:07.902: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.985295188s
Jan  9 13:06:08.904: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.98319179s
Jan  9 13:06:09.906: INFO: Verifying statefulset ss doesn't scale past 1 for another 981.030014ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-l5lzb
Jan  9 13:06:10.908: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 exec --namespace=e2e-tests-statefulset-l5lzb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  9 13:06:11.040: INFO: stderr: ""
Jan  9 13:06:11.040: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan  9 13:06:11.040: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan  9 13:06:11.042: INFO: Found 1 stateful pods, waiting for 3
Jan  9 13:06:21.044: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jan  9 13:06:21.044: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jan  9 13:06:21.044: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Jan  9 13:06:21.047: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 exec --namespace=e2e-tests-statefulset-l5lzb ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan  9 13:06:21.181: INFO: stderr: ""
Jan  9 13:06:21.181: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan  9 13:06:21.181: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan  9 13:06:21.181: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 exec --namespace=e2e-tests-statefulset-l5lzb ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan  9 13:06:21.319: INFO: stderr: ""
Jan  9 13:06:21.319: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan  9 13:06:21.319: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan  9 13:06:21.319: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 exec --namespace=e2e-tests-statefulset-l5lzb ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan  9 13:06:21.461: INFO: stderr: ""
Jan  9 13:06:21.461: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan  9 13:06:21.461: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan  9 13:06:21.461: INFO: Waiting for statefulset status.replicas updated to 0
Jan  9 13:06:21.463: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Jan  9 13:06:31.466: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan  9 13:06:31.466: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jan  9 13:06:31.466: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jan  9 13:06:31.471: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999998991s
Jan  9 13:06:32.474: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997487698s
Jan  9 13:06:33.476: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.995264287s
Jan  9 13:06:34.479: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.992952517s
Jan  9 13:06:35.481: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.990671054s
Jan  9 13:06:36.483: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.988360289s
Jan  9 13:06:37.486: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.986120214s
Jan  9 13:06:38.488: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.983807555s
Jan  9 13:06:39.490: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.981448697s
Jan  9 13:06:40.493: INFO: Verifying statefulset ss doesn't scale past 3 for another 979.131943ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-l5lzb
Jan  9 13:06:41.495: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 exec --namespace=e2e-tests-statefulset-l5lzb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  9 13:06:41.628: INFO: stderr: ""
Jan  9 13:06:41.628: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan  9 13:06:41.628: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan  9 13:06:41.628: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 exec --namespace=e2e-tests-statefulset-l5lzb ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  9 13:06:41.758: INFO: stderr: ""
Jan  9 13:06:41.758: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan  9 13:06:41.758: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan  9 13:06:41.758: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 exec --namespace=e2e-tests-statefulset-l5lzb ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  9 13:06:41.889: INFO: stderr: ""
Jan  9 13:06:41.889: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan  9 13:06:41.889: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan  9 13:06:41.889: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan  9 13:07:01.900: INFO: Deleting all statefulset in ns e2e-tests-statefulset-l5lzb
Jan  9 13:07:01.901: INFO: Scaling statefulset ss to 0
Jan  9 13:07:01.905: INFO: Waiting for statefulset status.replicas updated to 0
Jan  9 13:07:01.906: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:07:01.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-l5lzb" for this suite.
Jan  9 13:07:07.918: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:07:07.947: INFO: namespace: e2e-tests-statefulset-l5lzb, resource: bindings, ignored listing per whitelist
Jan  9 13:07:07.955: INFO: namespace e2e-tests-statefulset-l5lzb deletion completed in 6.041780403s

• [SLOW TEST:87.255 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:07:07.955: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Jan  9 13:07:07.990: INFO: Waiting up to 5m0s for pod "pod-77e20abd-140f-11e9-a571-02181533b527" in namespace "e2e-tests-emptydir-skz5t" to be "success or failure"
Jan  9 13:07:07.992: INFO: Pod "pod-77e20abd-140f-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.921444ms
Jan  9 13:07:09.994: INFO: Pod "pod-77e20abd-140f-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003825697s
STEP: Saw pod success
Jan  9 13:07:09.994: INFO: Pod "pod-77e20abd-140f-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 13:07:09.995: INFO: Trying to get logs from node ip-172-31-59-90 pod pod-77e20abd-140f-11e9-a571-02181533b527 container test-container: <nil>
STEP: delete the pod
Jan  9 13:07:10.002: INFO: Waiting for pod pod-77e20abd-140f-11e9-a571-02181533b527 to disappear
Jan  9 13:07:10.003: INFO: Pod pod-77e20abd-140f-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:07:10.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-skz5t" for this suite.
Jan  9 13:07:16.009: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:07:16.028: INFO: namespace: e2e-tests-emptydir-skz5t, resource: bindings, ignored listing per whitelist
Jan  9 13:07:16.047: INFO: namespace e2e-tests-emptydir-skz5t deletion completed in 6.042184899s

• [SLOW TEST:8.091 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:07:16.047: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Jan  9 13:07:16.079: INFO: Waiting up to 5m0s for pod "pod-7cb46226-140f-11e9-a571-02181533b527" in namespace "e2e-tests-emptydir-lw4cq" to be "success or failure"
Jan  9 13:07:16.080: INFO: Pod "pod-7cb46226-140f-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 967.891µs
Jan  9 13:07:18.082: INFO: Pod "pod-7cb46226-140f-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00260665s
STEP: Saw pod success
Jan  9 13:07:18.082: INFO: Pod "pod-7cb46226-140f-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 13:07:18.083: INFO: Trying to get logs from node ip-172-31-59-90 pod pod-7cb46226-140f-11e9-a571-02181533b527 container test-container: <nil>
STEP: delete the pod
Jan  9 13:07:18.092: INFO: Waiting for pod pod-7cb46226-140f-11e9-a571-02181533b527 to disappear
Jan  9 13:07:18.093: INFO: Pod pod-7cb46226-140f-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:07:18.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-lw4cq" for this suite.
Jan  9 13:07:24.099: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:07:24.103: INFO: namespace: e2e-tests-emptydir-lw4cq, resource: bindings, ignored listing per whitelist
Jan  9 13:07:24.136: INFO: namespace e2e-tests-emptydir-lw4cq deletion completed in 6.041965886s

• [SLOW TEST:8.089 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:07:24.136: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Jan  9 13:07:26.181: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-8187138e-140f-11e9-a571-02181533b527", GenerateName:"", Namespace:"e2e-tests-pods-87hbf", SelfLink:"/api/v1/namespaces/e2e-tests-pods-87hbf/pods/pod-submit-remove-8187138e-140f-11e9-a571-02181533b527", UID:"8187f062-140f-11e9-90b5-12841864fc48", ResourceVersion:"13242", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63682636044, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"168903444"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-g2j9g", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc002932740), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-g2j9g", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0027a0648), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-172-31-59-90", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0026743c0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0027a0690)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0027a06b0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0027a06b8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0027a06bc)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682636044, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682636046, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682636046, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682636044, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.31.59.90", PodIP:"10.1.1.215", StartTime:(*v1.Time)(0xc001c32720), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc001c32740), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96", ContainerID:"docker://96626d2c6322c80d770a59e7e013f6a446b4e3c15b9b9a94d40159f120930f25"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:07:40.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-87hbf" for this suite.
Jan  9 13:07:46.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:07:46.953: INFO: namespace: e2e-tests-pods-87hbf, resource: bindings, ignored listing per whitelist
Jan  9 13:07:46.976: INFO: namespace e2e-tests-pods-87hbf deletion completed in 6.040790228s

• [SLOW TEST:22.840 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:07:46.976: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-z6lb
STEP: Creating a pod to test atomic-volume-subpath
Jan  9 13:07:47.014: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-z6lb" in namespace "e2e-tests-subpath-skh7l" to be "success or failure"
Jan  9 13:07:47.015: INFO: Pod "pod-subpath-test-configmap-z6lb": Phase="Pending", Reason="", readiness=false. Elapsed: 1.539667ms
Jan  9 13:07:49.017: INFO: Pod "pod-subpath-test-configmap-z6lb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003412116s
Jan  9 13:07:51.019: INFO: Pod "pod-subpath-test-configmap-z6lb": Phase="Running", Reason="", readiness=false. Elapsed: 4.005313943s
Jan  9 13:07:53.021: INFO: Pod "pod-subpath-test-configmap-z6lb": Phase="Running", Reason="", readiness=false. Elapsed: 6.006898874s
Jan  9 13:07:55.023: INFO: Pod "pod-subpath-test-configmap-z6lb": Phase="Running", Reason="", readiness=false. Elapsed: 8.008824857s
Jan  9 13:07:57.024: INFO: Pod "pod-subpath-test-configmap-z6lb": Phase="Running", Reason="", readiness=false. Elapsed: 10.01061418s
Jan  9 13:07:59.026: INFO: Pod "pod-subpath-test-configmap-z6lb": Phase="Running", Reason="", readiness=false. Elapsed: 12.012480146s
Jan  9 13:08:01.028: INFO: Pod "pod-subpath-test-configmap-z6lb": Phase="Running", Reason="", readiness=false. Elapsed: 14.014523984s
Jan  9 13:08:03.030: INFO: Pod "pod-subpath-test-configmap-z6lb": Phase="Running", Reason="", readiness=false. Elapsed: 16.016439283s
Jan  9 13:08:05.032: INFO: Pod "pod-subpath-test-configmap-z6lb": Phase="Running", Reason="", readiness=false. Elapsed: 18.018297306s
Jan  9 13:08:07.034: INFO: Pod "pod-subpath-test-configmap-z6lb": Phase="Running", Reason="", readiness=false. Elapsed: 20.02020788s
Jan  9 13:08:09.036: INFO: Pod "pod-subpath-test-configmap-z6lb": Phase="Running", Reason="", readiness=false. Elapsed: 22.022100291s
Jan  9 13:08:11.038: INFO: Pod "pod-subpath-test-configmap-z6lb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.023990797s
STEP: Saw pod success
Jan  9 13:08:11.038: INFO: Pod "pod-subpath-test-configmap-z6lb" satisfied condition "success or failure"
Jan  9 13:08:11.039: INFO: Trying to get logs from node ip-172-31-59-90 pod pod-subpath-test-configmap-z6lb container test-container-subpath-configmap-z6lb: <nil>
STEP: delete the pod
Jan  9 13:08:11.050: INFO: Waiting for pod pod-subpath-test-configmap-z6lb to disappear
Jan  9 13:08:11.051: INFO: Pod pod-subpath-test-configmap-z6lb no longer exists
STEP: Deleting pod pod-subpath-test-configmap-z6lb
Jan  9 13:08:11.051: INFO: Deleting pod "pod-subpath-test-configmap-z6lb" in namespace "e2e-tests-subpath-skh7l"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:08:11.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-skh7l" for this suite.
Jan  9 13:08:17.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:08:17.077: INFO: namespace: e2e-tests-subpath-skh7l, resource: bindings, ignored listing per whitelist
Jan  9 13:08:17.093: INFO: namespace e2e-tests-subpath-skh7l deletion completed in 6.039938701s

• [SLOW TEST:30.117 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:08:17.094: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan  9 13:08:17.126: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 version --client'
Jan  9 13:08:17.175: INFO: stderr: ""
Jan  9 13:08:17.175: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Jan  9 13:08:17.176: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 create -f - --namespace=e2e-tests-kubectl-4wctp'
Jan  9 13:08:17.451: INFO: stderr: ""
Jan  9 13:08:17.451: INFO: stdout: "replicationcontroller/redis-master created\n"
Jan  9 13:08:17.451: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 create -f - --namespace=e2e-tests-kubectl-4wctp'
Jan  9 13:08:17.585: INFO: stderr: ""
Jan  9 13:08:17.585: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Jan  9 13:08:18.587: INFO: Selector matched 1 pods for map[app:redis]
Jan  9 13:08:18.587: INFO: Found 0 / 1
Jan  9 13:08:19.587: INFO: Selector matched 1 pods for map[app:redis]
Jan  9 13:08:19.587: INFO: Found 0 / 1
Jan  9 13:08:20.587: INFO: Selector matched 1 pods for map[app:redis]
Jan  9 13:08:20.587: INFO: Found 1 / 1
Jan  9 13:08:20.587: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jan  9 13:08:20.588: INFO: Selector matched 1 pods for map[app:redis]
Jan  9 13:08:20.588: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jan  9 13:08:20.588: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 describe pod redis-master-x24cq --namespace=e2e-tests-kubectl-4wctp'
Jan  9 13:08:20.660: INFO: stderr: ""
Jan  9 13:08:20.660: INFO: stdout: "Name:               redis-master-x24cq\nNamespace:          e2e-tests-kubectl-4wctp\nPriority:           0\nPriorityClassName:  <none>\nNode:               ip-172-31-59-90/172.31.59.90\nStart Time:         Wed, 09 Jan 2019 13:08:17 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.1.1.217\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://df5844ed3906a2001cbb21c1d8641a1bf51b56814996e98586ca2181f21ee2c1\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 09 Jan 2019 13:08:18 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-pwjtj (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-pwjtj:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-pwjtj\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                      Message\n  ----    ------     ----  ----                      -------\n  Normal  Scheduled  3s    default-scheduler         Successfully assigned e2e-tests-kubectl-4wctp/redis-master-x24cq to ip-172-31-59-90\n  Normal  Pulled     2s    kubelet, ip-172-31-59-90  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, ip-172-31-59-90  Created container\n  Normal  Started    2s    kubelet, ip-172-31-59-90  Started container\n"
Jan  9 13:08:20.660: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 describe rc redis-master --namespace=e2e-tests-kubectl-4wctp'
Jan  9 13:08:20.733: INFO: stderr: ""
Jan  9 13:08:20.733: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-4wctp\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-x24cq\n"
Jan  9 13:08:20.733: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 describe service redis-master --namespace=e2e-tests-kubectl-4wctp'
Jan  9 13:08:20.799: INFO: stderr: ""
Jan  9 13:08:20.799: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-4wctp\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.152.183.109\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.1.1.217:6379\nSession Affinity:  None\nEvents:            <none>\n"
Jan  9 13:08:20.800: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 describe node ip-172-31-59-90'
Jan  9 13:08:20.878: INFO: stderr: ""
Jan  9 13:08:20.878: INFO: stdout: "Name:               ip-172-31-59-90\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/hostname=ip-172-31-59-90\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Wed, 09 Jan 2019 11:55:24 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Wed, 09 Jan 2019 13:08:14 +0000   Wed, 09 Jan 2019 11:55:20 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Wed, 09 Jan 2019 13:08:14 +0000   Wed, 09 Jan 2019 11:55:20 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Wed, 09 Jan 2019 13:08:14 +0000   Wed, 09 Jan 2019 11:55:20 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Wed, 09 Jan 2019 13:08:14 +0000   Wed, 09 Jan 2019 11:55:24 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  172.31.59.90\n  Hostname:    ip-172-31-59-90\nCapacity:\n cpu:                8\n ephemeral-storage:  81253764Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             32939568Ki\n pods:               110\nAllocatable:\n cpu:                8\n ephemeral-storage:  80205188Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             32837168Ki\n pods:               110\nSystem Info:\n Machine ID:                 d320b89525a54cfbb89117d5f2c74361\n System UUID:                EC2943B1-FF3E-326C-2E65-627F1AC90CD1\n Boot ID:                    a812e9bf-ecf6-454f-a727-e71410430e61\n Kernel Version:             4.15.0-1021-aws\n OS Image:                   Ubuntu 18.04.1 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.1\n Kubelet Version:            v1.13.1\n Kube-Proxy Version:         v1.13.1\nNon-terminated Pods:         (5 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  e2e-tests-kubectl-4wctp    redis-master-x24cq                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         3s\n  heptio-sonobuoy            sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         70m\n  heptio-sonobuoy            sonobuoy-e2e-job-73c0b4a4fe2f4aff                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         70m\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-c5e6e334b21d4f47-sjlb6    0 (0%)        0 (0%)      0 (0%)           0 (0%)         70m\n  kube-system                kube-dns-6ccd496668-rmn4f                                  260m (3%)     0 (0%)      110Mi (0%)       170Mi (0%)     70m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                260m (3%)   0 (0%)\n  memory             110Mi (0%)  170Mi (0%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:              <none>\n"
Jan  9 13:08:20.878: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 describe namespace e2e-tests-kubectl-4wctp'
Jan  9 13:08:20.943: INFO: stderr: ""
Jan  9 13:08:20.943: INFO: stdout: "Name:         e2e-tests-kubectl-4wctp\nLabels:       e2e-framework=kubectl\n              e2e-run=e4a50e76-1405-11e9-a571-02181533b527\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:08:20.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-4wctp" for this suite.
Jan  9 13:08:42.949: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:08:42.982: INFO: namespace: e2e-tests-kubectl-4wctp, resource: bindings, ignored listing per whitelist
Jan  9 13:08:42.983: INFO: namespace e2e-tests-kubectl-4wctp deletion completed in 22.038798267s

• [SLOW TEST:25.890 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:08:42.983: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jan  9 13:08:43.023: INFO: Number of nodes with available pods: 0
Jan  9 13:08:43.023: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 13:08:44.026: INFO: Number of nodes with available pods: 0
Jan  9 13:08:44.026: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 13:08:45.026: INFO: Number of nodes with available pods: 1
Jan  9 13:08:45.026: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Jan  9 13:08:45.035: INFO: Number of nodes with available pods: 0
Jan  9 13:08:45.035: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 13:08:46.037: INFO: Number of nodes with available pods: 0
Jan  9 13:08:46.037: INFO: Node ip-172-31-59-90 is running more than one daemon pod
Jan  9 13:08:47.038: INFO: Number of nodes with available pods: 1
Jan  9 13:08:47.038: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-rjjdb, will wait for the garbage collector to delete the pods
Jan  9 13:08:47.094: INFO: Deleting DaemonSet.extensions daemon-set took: 2.967923ms
Jan  9 13:08:47.194: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.345867ms
Jan  9 13:09:21.296: INFO: Number of nodes with available pods: 0
Jan  9 13:09:21.296: INFO: Number of running nodes: 0, number of available pods: 0
Jan  9 13:09:21.297: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-rjjdb/daemonsets","resourceVersion":"13517"},"items":null}

Jan  9 13:09:21.298: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-rjjdb/pods","resourceVersion":"13517"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:09:21.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-rjjdb" for this suite.
Jan  9 13:09:27.307: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:09:27.326: INFO: namespace: e2e-tests-daemonsets-rjjdb, resource: bindings, ignored listing per whitelist
Jan  9 13:09:27.343: INFO: namespace e2e-tests-daemonsets-rjjdb deletion completed in 6.040763888s

• [SLOW TEST:44.360 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:09:27.343: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-caf6b6e0-140f-11e9-a571-02181533b527
STEP: Creating a pod to test consume configMaps
Jan  9 13:09:27.378: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-caf6f290-140f-11e9-a571-02181533b527" in namespace "e2e-tests-projected-pcmxq" to be "success or failure"
Jan  9 13:09:27.379: INFO: Pod "pod-projected-configmaps-caf6f290-140f-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 976.947µs
Jan  9 13:09:29.381: INFO: Pod "pod-projected-configmaps-caf6f290-140f-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.002922437s
STEP: Saw pod success
Jan  9 13:09:29.381: INFO: Pod "pod-projected-configmaps-caf6f290-140f-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 13:09:29.382: INFO: Trying to get logs from node ip-172-31-59-90 pod pod-projected-configmaps-caf6f290-140f-11e9-a571-02181533b527 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan  9 13:09:29.389: INFO: Waiting for pod pod-projected-configmaps-caf6f290-140f-11e9-a571-02181533b527 to disappear
Jan  9 13:09:29.390: INFO: Pod pod-projected-configmaps-caf6f290-140f-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:09:29.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pcmxq" for this suite.
Jan  9 13:09:35.396: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:09:35.431: INFO: namespace: e2e-tests-projected-pcmxq, resource: bindings, ignored listing per whitelist
Jan  9 13:09:35.436: INFO: namespace e2e-tests-projected-pcmxq deletion completed in 6.044231187s

• [SLOW TEST:8.093 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:09:35.436: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jan  9 13:09:35.470: INFO: Waiting up to 5m0s for pod "pod-cfc9b43d-140f-11e9-a571-02181533b527" in namespace "e2e-tests-emptydir-xp6xp" to be "success or failure"
Jan  9 13:09:35.471: INFO: Pod "pod-cfc9b43d-140f-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.077073ms
Jan  9 13:09:37.473: INFO: Pod "pod-cfc9b43d-140f-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00289328s
STEP: Saw pod success
Jan  9 13:09:37.473: INFO: Pod "pod-cfc9b43d-140f-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 13:09:37.474: INFO: Trying to get logs from node ip-172-31-59-90 pod pod-cfc9b43d-140f-11e9-a571-02181533b527 container test-container: <nil>
STEP: delete the pod
Jan  9 13:09:37.485: INFO: Waiting for pod pod-cfc9b43d-140f-11e9-a571-02181533b527 to disappear
Jan  9 13:09:37.486: INFO: Pod pod-cfc9b43d-140f-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:09:37.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-xp6xp" for this suite.
Jan  9 13:09:43.492: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:09:43.528: INFO: namespace: e2e-tests-emptydir-xp6xp, resource: bindings, ignored listing per whitelist
Jan  9 13:09:43.530: INFO: namespace e2e-tests-emptydir-xp6xp deletion completed in 6.04242455s

• [SLOW TEST:8.094 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:09:43.530: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan  9 13:09:43.564: INFO: Waiting up to 5m0s for pod "downward-api-d49cc747-140f-11e9-a571-02181533b527" in namespace "e2e-tests-downward-api-vfms7" to be "success or failure"
Jan  9 13:09:43.565: INFO: Pod "downward-api-d49cc747-140f-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.028963ms
Jan  9 13:09:45.567: INFO: Pod "downward-api-d49cc747-140f-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00295905s
STEP: Saw pod success
Jan  9 13:09:45.567: INFO: Pod "downward-api-d49cc747-140f-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 13:09:45.568: INFO: Trying to get logs from node ip-172-31-59-90 pod downward-api-d49cc747-140f-11e9-a571-02181533b527 container dapi-container: <nil>
STEP: delete the pod
Jan  9 13:09:45.576: INFO: Waiting for pod downward-api-d49cc747-140f-11e9-a571-02181533b527 to disappear
Jan  9 13:09:45.577: INFO: Pod downward-api-d49cc747-140f-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:09:45.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-vfms7" for this suite.
Jan  9 13:09:51.583: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:09:51.606: INFO: namespace: e2e-tests-downward-api-vfms7, resource: bindings, ignored listing per whitelist
Jan  9 13:09:51.619: INFO: namespace e2e-tests-downward-api-vfms7 deletion completed in 6.041171554s

• [SLOW TEST:8.089 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:09:51.620: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan  9 13:09:51.651: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-jpfqh'
Jan  9 13:09:51.722: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jan  9 13:09:51.722: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Jan  9 13:09:51.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-jpfqh'
Jan  9 13:09:51.784: INFO: stderr: ""
Jan  9 13:09:51.784: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:09:51.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-jpfqh" for this suite.
Jan  9 13:10:13.790: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:10:13.824: INFO: namespace: e2e-tests-kubectl-jpfqh, resource: bindings, ignored listing per whitelist
Jan  9 13:10:13.830: INFO: namespace e2e-tests-kubectl-jpfqh deletion completed in 22.044523808s

• [SLOW TEST:22.211 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:10:13.830: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Jan  9 13:10:13.862: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jan  9 13:10:13.864: INFO: Waiting for terminating namespaces to be deleted...
Jan  9 13:10:13.865: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-59-90 before test
Jan  9 13:10:13.868: INFO: kube-dns-6ccd496668-rmn4f from kube-system started at 2019-01-09 11:57:35 +0000 UTC (3 container statuses recorded)
Jan  9 13:10:13.868: INFO: 	Container dnsmasq ready: true, restart count 0
Jan  9 13:10:13.868: INFO: 	Container kubedns ready: true, restart count 0
Jan  9 13:10:13.868: INFO: 	Container sidecar ready: true, restart count 0
Jan  9 13:10:13.868: INFO: sonobuoy-systemd-logs-daemon-set-c5e6e334b21d4f47-sjlb6 from heptio-sonobuoy started at 2019-01-09 11:58:13 +0000 UTC (2 container statuses recorded)
Jan  9 13:10:13.868: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Jan  9 13:10:13.868: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Jan  9 13:10:13.868: INFO: sonobuoy from heptio-sonobuoy started at 2019-01-09 11:58:10 +0000 UTC (1 container statuses recorded)
Jan  9 13:10:13.868: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jan  9 13:10:13.868: INFO: sonobuoy-e2e-job-73c0b4a4fe2f4aff from heptio-sonobuoy started at 2019-01-09 11:58:13 +0000 UTC (2 container statuses recorded)
Jan  9 13:10:13.868: INFO: 	Container e2e ready: true, restart count 0
Jan  9 13:10:13.868: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node ip-172-31-59-90
Jan  9 13:10:13.877: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-172-31-59-90
Jan  9 13:10:13.877: INFO: Pod sonobuoy-e2e-job-73c0b4a4fe2f4aff requesting resource cpu=0m on Node ip-172-31-59-90
Jan  9 13:10:13.877: INFO: Pod sonobuoy-systemd-logs-daemon-set-c5e6e334b21d4f47-sjlb6 requesting resource cpu=0m on Node ip-172-31-59-90
Jan  9 13:10:13.877: INFO: Pod kube-dns-6ccd496668-rmn4f requesting resource cpu=260m on Node ip-172-31-59-90
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e6ae86ff-140f-11e9-a571-02181533b527.157830267df5eea2], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-7dns2/filler-pod-e6ae86ff-140f-11e9-a571-02181533b527 to ip-172-31-59-90]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e6ae86ff-140f-11e9-a571-02181533b527.15783026b7421d13], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e6ae86ff-140f-11e9-a571-02181533b527.15783026bc37a3cc], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e6ae86ff-140f-11e9-a571-02181533b527.15783026c7af40df], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15783026f58076ec], Reason = [FailedScheduling], Message = [0/1 nodes are available: 1 Insufficient cpu.]
STEP: removing the label node off the node ip-172-31-59-90
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:10:16.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-7dns2" for this suite.
Jan  9 13:10:22.900: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:10:22.934: INFO: namespace: e2e-tests-sched-pred-7dns2, resource: bindings, ignored listing per whitelist
Jan  9 13:10:22.935: INFO: namespace e2e-tests-sched-pred-7dns2 deletion completed in 6.040060347s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:9.105 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:10:22.936: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan  9 13:10:22.972: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ec19e8af-140f-11e9-a571-02181533b527" in namespace "e2e-tests-projected-tvgf4" to be "success or failure"
Jan  9 13:10:22.973: INFO: Pod "downwardapi-volume-ec19e8af-140f-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.040385ms
Jan  9 13:10:24.975: INFO: Pod "downwardapi-volume-ec19e8af-140f-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00298308s
Jan  9 13:10:26.977: INFO: Pod "downwardapi-volume-ec19e8af-140f-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005010639s
STEP: Saw pod success
Jan  9 13:10:26.977: INFO: Pod "downwardapi-volume-ec19e8af-140f-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 13:10:26.979: INFO: Trying to get logs from node ip-172-31-59-90 pod downwardapi-volume-ec19e8af-140f-11e9-a571-02181533b527 container client-container: <nil>
STEP: delete the pod
Jan  9 13:10:26.986: INFO: Waiting for pod downwardapi-volume-ec19e8af-140f-11e9-a571-02181533b527 to disappear
Jan  9 13:10:26.987: INFO: Pod downwardapi-volume-ec19e8af-140f-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:10:26.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-tvgf4" for this suite.
Jan  9 13:10:32.993: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:10:33.010: INFO: namespace: e2e-tests-projected-tvgf4, resource: bindings, ignored listing per whitelist
Jan  9 13:10:33.027: INFO: namespace e2e-tests-projected-tvgf4 deletion completed in 6.039198061s

• [SLOW TEST:10.092 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:10:33.028: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-f21e1827-140f-11e9-a571-02181533b527
STEP: Creating a pod to test consume secrets
Jan  9 13:10:33.067: INFO: Waiting up to 5m0s for pod "pod-secrets-f21e4e41-140f-11e9-a571-02181533b527" in namespace "e2e-tests-secrets-2sbpw" to be "success or failure"
Jan  9 13:10:33.068: INFO: Pod "pod-secrets-f21e4e41-140f-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.026022ms
Jan  9 13:10:35.070: INFO: Pod "pod-secrets-f21e4e41-140f-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003050845s
Jan  9 13:10:37.072: INFO: Pod "pod-secrets-f21e4e41-140f-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.004957069s
STEP: Saw pod success
Jan  9 13:10:37.072: INFO: Pod "pod-secrets-f21e4e41-140f-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 13:10:37.073: INFO: Trying to get logs from node ip-172-31-59-90 pod pod-secrets-f21e4e41-140f-11e9-a571-02181533b527 container secret-volume-test: <nil>
STEP: delete the pod
Jan  9 13:10:37.080: INFO: Waiting for pod pod-secrets-f21e4e41-140f-11e9-a571-02181533b527 to disappear
Jan  9 13:10:37.081: INFO: Pod pod-secrets-f21e4e41-140f-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:10:37.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-2sbpw" for this suite.
Jan  9 13:10:43.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:10:43.097: INFO: namespace: e2e-tests-secrets-2sbpw, resource: bindings, ignored listing per whitelist
Jan  9 13:10:43.122: INFO: namespace e2e-tests-secrets-2sbpw deletion completed in 6.039672605s

• [SLOW TEST:10.094 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:10:43.122: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan  9 13:10:43.154: INFO: Waiting up to 5m0s for pod "downward-api-f8218cd3-140f-11e9-a571-02181533b527" in namespace "e2e-tests-downward-api-6p59d" to be "success or failure"
Jan  9 13:10:43.155: INFO: Pod "downward-api-f8218cd3-140f-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.022943ms
Jan  9 13:10:45.157: INFO: Pod "downward-api-f8218cd3-140f-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003042898s
Jan  9 13:10:47.159: INFO: Pod "downward-api-f8218cd3-140f-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.004931238s
STEP: Saw pod success
Jan  9 13:10:47.159: INFO: Pod "downward-api-f8218cd3-140f-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 13:10:47.160: INFO: Trying to get logs from node ip-172-31-59-90 pod downward-api-f8218cd3-140f-11e9-a571-02181533b527 container dapi-container: <nil>
STEP: delete the pod
Jan  9 13:10:47.170: INFO: Waiting for pod downward-api-f8218cd3-140f-11e9-a571-02181533b527 to disappear
Jan  9 13:10:47.171: INFO: Pod downward-api-f8218cd3-140f-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:10:47.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-6p59d" for this suite.
Jan  9 13:10:53.177: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:10:53.186: INFO: namespace: e2e-tests-downward-api-6p59d, resource: bindings, ignored listing per whitelist
Jan  9 13:10:53.214: INFO: namespace e2e-tests-downward-api-6p59d deletion completed in 6.041477266s

• [SLOW TEST:10.092 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:10:53.214: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-fe261d01-140f-11e9-a571-02181533b527
STEP: Creating a pod to test consume secrets
Jan  9 13:10:53.263: INFO: Waiting up to 5m0s for pod "pod-secrets-fe2803dc-140f-11e9-a571-02181533b527" in namespace "e2e-tests-secrets-6gncg" to be "success or failure"
Jan  9 13:10:53.264: INFO: Pod "pod-secrets-fe2803dc-140f-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 981.693µs
Jan  9 13:10:55.268: INFO: Pod "pod-secrets-fe2803dc-140f-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004587343s
STEP: Saw pod success
Jan  9 13:10:55.268: INFO: Pod "pod-secrets-fe2803dc-140f-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 13:10:55.269: INFO: Trying to get logs from node ip-172-31-59-90 pod pod-secrets-fe2803dc-140f-11e9-a571-02181533b527 container secret-volume-test: <nil>
STEP: delete the pod
Jan  9 13:10:55.277: INFO: Waiting for pod pod-secrets-fe2803dc-140f-11e9-a571-02181533b527 to disappear
Jan  9 13:10:55.280: INFO: Pod pod-secrets-fe2803dc-140f-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:10:55.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-6gncg" for this suite.
Jan  9 13:11:01.286: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:11:01.293: INFO: namespace: e2e-tests-secrets-6gncg, resource: bindings, ignored listing per whitelist
Jan  9 13:11:01.328: INFO: namespace e2e-tests-secrets-6gncg deletion completed in 6.046381423s
STEP: Destroying namespace "e2e-tests-secret-namespace-zhqgw" for this suite.
Jan  9 13:11:07.334: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:11:07.342: INFO: namespace: e2e-tests-secret-namespace-zhqgw, resource: bindings, ignored listing per whitelist
Jan  9 13:11:07.370: INFO: namespace e2e-tests-secret-namespace-zhqgw deletion completed in 6.042235738s

• [SLOW TEST:14.156 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:11:07.370: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Jan  9 13:11:07.403: INFO: Waiting up to 5m0s for pod "client-containers-0695935d-1410-11e9-a571-02181533b527" in namespace "e2e-tests-containers-wfqmc" to be "success or failure"
Jan  9 13:11:07.404: INFO: Pod "client-containers-0695935d-1410-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.045197ms
Jan  9 13:11:09.406: INFO: Pod "client-containers-0695935d-1410-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.002698703s
STEP: Saw pod success
Jan  9 13:11:09.406: INFO: Pod "client-containers-0695935d-1410-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 13:11:09.407: INFO: Trying to get logs from node ip-172-31-59-90 pod client-containers-0695935d-1410-11e9-a571-02181533b527 container test-container: <nil>
STEP: delete the pod
Jan  9 13:11:09.415: INFO: Waiting for pod client-containers-0695935d-1410-11e9-a571-02181533b527 to disappear
Jan  9 13:11:09.416: INFO: Pod client-containers-0695935d-1410-11e9-a571-02181533b527 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:11:09.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-wfqmc" for this suite.
Jan  9 13:11:15.423: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:11:15.437: INFO: namespace: e2e-tests-containers-wfqmc, resource: bindings, ignored listing per whitelist
Jan  9 13:11:15.464: INFO: namespace e2e-tests-containers-wfqmc deletion completed in 6.045942244s

• [SLOW TEST:8.093 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:11:15.464: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0109 13:11:21.506036      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan  9 13:11:21.506: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:11:21.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-8j4cm" for this suite.
Jan  9 13:11:27.511: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:11:27.521: INFO: namespace: e2e-tests-gc-8j4cm, resource: bindings, ignored listing per whitelist
Jan  9 13:11:27.548: INFO: namespace e2e-tests-gc-8j4cm deletion completed in 6.041136817s

• [SLOW TEST:12.084 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:11:27.548: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan  9 13:11:27.587: INFO: Waiting up to 5m0s for pod "downwardapi-volume-129d75fb-1410-11e9-a571-02181533b527" in namespace "e2e-tests-downward-api-ttxgq" to be "success or failure"
Jan  9 13:11:27.588: INFO: Pod "downwardapi-volume-129d75fb-1410-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.140349ms
Jan  9 13:11:29.590: INFO: Pod "downwardapi-volume-129d75fb-1410-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.002959394s
STEP: Saw pod success
Jan  9 13:11:29.590: INFO: Pod "downwardapi-volume-129d75fb-1410-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 13:11:29.591: INFO: Trying to get logs from node ip-172-31-59-90 pod downwardapi-volume-129d75fb-1410-11e9-a571-02181533b527 container client-container: <nil>
STEP: delete the pod
Jan  9 13:11:29.598: INFO: Waiting for pod downwardapi-volume-129d75fb-1410-11e9-a571-02181533b527 to disappear
Jan  9 13:11:29.601: INFO: Pod downwardapi-volume-129d75fb-1410-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:11:29.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-ttxgq" for this suite.
Jan  9 13:11:35.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:11:35.633: INFO: namespace: e2e-tests-downward-api-ttxgq, resource: bindings, ignored listing per whitelist
Jan  9 13:11:35.648: INFO: namespace e2e-tests-downward-api-ttxgq deletion completed in 6.04485857s

• [SLOW TEST:8.100 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:11:35.648: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan  9 13:11:35.685: INFO: Waiting up to 5m0s for pod "downward-api-1771094c-1410-11e9-a571-02181533b527" in namespace "e2e-tests-downward-api-bvmww" to be "success or failure"
Jan  9 13:11:35.686: INFO: Pod "downward-api-1771094c-1410-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.042654ms
Jan  9 13:11:37.688: INFO: Pod "downward-api-1771094c-1410-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.002885089s
STEP: Saw pod success
Jan  9 13:11:37.688: INFO: Pod "downward-api-1771094c-1410-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 13:11:37.689: INFO: Trying to get logs from node ip-172-31-59-90 pod downward-api-1771094c-1410-11e9-a571-02181533b527 container dapi-container: <nil>
STEP: delete the pod
Jan  9 13:11:37.696: INFO: Waiting for pod downward-api-1771094c-1410-11e9-a571-02181533b527 to disappear
Jan  9 13:11:37.697: INFO: Pod downward-api-1771094c-1410-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:11:37.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-bvmww" for this suite.
Jan  9 13:11:43.703: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:11:43.731: INFO: namespace: e2e-tests-downward-api-bvmww, resource: bindings, ignored listing per whitelist
Jan  9 13:11:43.742: INFO: namespace e2e-tests-downward-api-bvmww deletion completed in 6.043226622s

• [SLOW TEST:8.093 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:11:43.742: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jan  9 13:11:43.777: INFO: Waiting up to 5m0s for pod "pod-1c43b574-1410-11e9-a571-02181533b527" in namespace "e2e-tests-emptydir-hjt8v" to be "success or failure"
Jan  9 13:11:43.778: INFO: Pod "pod-1c43b574-1410-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.0709ms
Jan  9 13:11:45.780: INFO: Pod "pod-1c43b574-1410-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 2.002948179s
Jan  9 13:11:47.782: INFO: Pod "pod-1c43b574-1410-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.004892779s
STEP: Saw pod success
Jan  9 13:11:47.782: INFO: Pod "pod-1c43b574-1410-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 13:11:47.783: INFO: Trying to get logs from node ip-172-31-59-90 pod pod-1c43b574-1410-11e9-a571-02181533b527 container test-container: <nil>
STEP: delete the pod
Jan  9 13:11:47.793: INFO: Waiting for pod pod-1c43b574-1410-11e9-a571-02181533b527 to disappear
Jan  9 13:11:47.795: INFO: Pod pod-1c43b574-1410-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:11:47.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-hjt8v" for this suite.
Jan  9 13:11:53.800: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:11:53.811: INFO: namespace: e2e-tests-emptydir-hjt8v, resource: bindings, ignored listing per whitelist
Jan  9 13:11:53.840: INFO: namespace e2e-tests-emptydir-hjt8v deletion completed in 6.044020835s

• [SLOW TEST:10.098 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:11:53.840: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-224915b3-1410-11e9-a571-02181533b527
STEP: Creating a pod to test consume configMaps
Jan  9 13:11:53.880: INFO: Waiting up to 5m0s for pod "pod-configmaps-2249513e-1410-11e9-a571-02181533b527" in namespace "e2e-tests-configmap-x4gl8" to be "success or failure"
Jan  9 13:11:53.881: INFO: Pod "pod-configmaps-2249513e-1410-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.403113ms
Jan  9 13:11:55.883: INFO: Pod "pod-configmaps-2249513e-1410-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.002911211s
STEP: Saw pod success
Jan  9 13:11:55.883: INFO: Pod "pod-configmaps-2249513e-1410-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 13:11:55.884: INFO: Trying to get logs from node ip-172-31-59-90 pod pod-configmaps-2249513e-1410-11e9-a571-02181533b527 container configmap-volume-test: <nil>
STEP: delete the pod
Jan  9 13:11:55.890: INFO: Waiting for pod pod-configmaps-2249513e-1410-11e9-a571-02181533b527 to disappear
Jan  9 13:11:55.891: INFO: Pod pod-configmaps-2249513e-1410-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:11:55.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-x4gl8" for this suite.
Jan  9 13:12:01.902: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:12:01.925: INFO: namespace: e2e-tests-configmap-x4gl8, resource: bindings, ignored listing per whitelist
Jan  9 13:12:01.940: INFO: namespace e2e-tests-configmap-x4gl8 deletion completed in 6.047471181s

• [SLOW TEST:8.100 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:12:01.940: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-m5g9d
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-m5g9d
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-m5g9d
Jan  9 13:12:01.978: INFO: Found 0 stateful pods, waiting for 1
Jan  9 13:12:11.980: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Jan  9 13:12:11.982: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 exec --namespace=e2e-tests-statefulset-m5g9d ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan  9 13:12:12.110: INFO: stderr: ""
Jan  9 13:12:12.110: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan  9 13:12:12.110: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan  9 13:12:12.112: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jan  9 13:12:22.114: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan  9 13:12:22.114: INFO: Waiting for statefulset status.replicas updated to 0
Jan  9 13:12:22.121: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
Jan  9 13:12:22.121: INFO: ss-0  ip-172-31-59-90  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:01 +0000 UTC  }]
Jan  9 13:12:22.121: INFO: 
Jan  9 13:12:22.121: INFO: StatefulSet ss has not reached scale 3, at 1
Jan  9 13:12:23.124: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.998495455s
Jan  9 13:12:24.126: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.99626085s
Jan  9 13:12:25.128: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.993930345s
Jan  9 13:12:26.130: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.991726104s
Jan  9 13:12:27.132: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.989654151s
Jan  9 13:12:28.135: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.987448942s
Jan  9 13:12:29.137: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.985071585s
Jan  9 13:12:30.139: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.982781753s
Jan  9 13:12:31.141: INFO: Verifying statefulset ss doesn't scale past 3 for another 980.54403ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-m5g9d
Jan  9 13:12:32.144: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 exec --namespace=e2e-tests-statefulset-m5g9d ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  9 13:12:32.272: INFO: stderr: ""
Jan  9 13:12:32.272: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan  9 13:12:32.272: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan  9 13:12:32.272: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 exec --namespace=e2e-tests-statefulset-m5g9d ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  9 13:12:32.403: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Jan  9 13:12:32.403: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan  9 13:12:32.403: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan  9 13:12:32.403: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 exec --namespace=e2e-tests-statefulset-m5g9d ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  9 13:12:32.532: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Jan  9 13:12:32.532: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan  9 13:12:32.532: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan  9 13:12:32.534: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Jan  9 13:12:42.537: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jan  9 13:12:42.537: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jan  9 13:12:42.537: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Jan  9 13:12:42.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 exec --namespace=e2e-tests-statefulset-m5g9d ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan  9 13:12:42.671: INFO: stderr: ""
Jan  9 13:12:42.671: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan  9 13:12:42.671: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan  9 13:12:42.671: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 exec --namespace=e2e-tests-statefulset-m5g9d ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan  9 13:12:42.812: INFO: stderr: ""
Jan  9 13:12:42.812: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan  9 13:12:42.812: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan  9 13:12:42.812: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 exec --namespace=e2e-tests-statefulset-m5g9d ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan  9 13:12:42.947: INFO: stderr: ""
Jan  9 13:12:42.947: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan  9 13:12:42.947: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan  9 13:12:42.947: INFO: Waiting for statefulset status.replicas updated to 0
Jan  9 13:12:42.948: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Jan  9 13:12:52.951: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan  9 13:12:52.951: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jan  9 13:12:52.951: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jan  9 13:12:52.957: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
Jan  9 13:12:52.957: INFO: ss-0  ip-172-31-59-90  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:01 +0000 UTC  }]
Jan  9 13:12:52.957: INFO: ss-1  ip-172-31-59-90  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:22 +0000 UTC  }]
Jan  9 13:12:52.957: INFO: ss-2  ip-172-31-59-90  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:22 +0000 UTC  }]
Jan  9 13:12:52.957: INFO: 
Jan  9 13:12:52.957: INFO: StatefulSet ss has not reached scale 0, at 3
Jan  9 13:12:53.959: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
Jan  9 13:12:53.959: INFO: ss-0  ip-172-31-59-90  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:01 +0000 UTC  }]
Jan  9 13:12:53.959: INFO: ss-1  ip-172-31-59-90  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:22 +0000 UTC  }]
Jan  9 13:12:53.959: INFO: ss-2  ip-172-31-59-90  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:22 +0000 UTC  }]
Jan  9 13:12:53.959: INFO: 
Jan  9 13:12:53.959: INFO: StatefulSet ss has not reached scale 0, at 3
Jan  9 13:12:54.962: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
Jan  9 13:12:54.962: INFO: ss-0  ip-172-31-59-90  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:01 +0000 UTC  }]
Jan  9 13:12:54.962: INFO: ss-1  ip-172-31-59-90  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:22 +0000 UTC  }]
Jan  9 13:12:54.962: INFO: ss-2  ip-172-31-59-90  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:22 +0000 UTC  }]
Jan  9 13:12:54.962: INFO: 
Jan  9 13:12:54.962: INFO: StatefulSet ss has not reached scale 0, at 3
Jan  9 13:12:55.964: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
Jan  9 13:12:55.964: INFO: ss-0  ip-172-31-59-90  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:01 +0000 UTC  }]
Jan  9 13:12:55.964: INFO: ss-1  ip-172-31-59-90  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:22 +0000 UTC  }]
Jan  9 13:12:55.964: INFO: ss-2  ip-172-31-59-90  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:22 +0000 UTC  }]
Jan  9 13:12:55.964: INFO: 
Jan  9 13:12:55.964: INFO: StatefulSet ss has not reached scale 0, at 3
Jan  9 13:12:56.966: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
Jan  9 13:12:56.966: INFO: ss-0  ip-172-31-59-90  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:01 +0000 UTC  }]
Jan  9 13:12:56.966: INFO: ss-1  ip-172-31-59-90  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:22 +0000 UTC  }]
Jan  9 13:12:56.966: INFO: ss-2  ip-172-31-59-90  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:22 +0000 UTC  }]
Jan  9 13:12:56.966: INFO: 
Jan  9 13:12:56.966: INFO: StatefulSet ss has not reached scale 0, at 3
Jan  9 13:12:57.968: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
Jan  9 13:12:57.968: INFO: ss-0  ip-172-31-59-90  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:01 +0000 UTC  }]
Jan  9 13:12:57.968: INFO: ss-1  ip-172-31-59-90  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:22 +0000 UTC  }]
Jan  9 13:12:57.968: INFO: ss-2  ip-172-31-59-90  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:22 +0000 UTC  }]
Jan  9 13:12:57.968: INFO: 
Jan  9 13:12:57.968: INFO: StatefulSet ss has not reached scale 0, at 3
Jan  9 13:12:58.970: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
Jan  9 13:12:58.970: INFO: ss-0  ip-172-31-59-90  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:01 +0000 UTC  }]
Jan  9 13:12:58.970: INFO: ss-1  ip-172-31-59-90  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:22 +0000 UTC  }]
Jan  9 13:12:58.970: INFO: ss-2  ip-172-31-59-90  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:22 +0000 UTC  }]
Jan  9 13:12:58.970: INFO: 
Jan  9 13:12:58.970: INFO: StatefulSet ss has not reached scale 0, at 3
Jan  9 13:12:59.973: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
Jan  9 13:12:59.973: INFO: ss-0  ip-172-31-59-90  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:01 +0000 UTC  }]
Jan  9 13:12:59.973: INFO: ss-1  ip-172-31-59-90  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:22 +0000 UTC  }]
Jan  9 13:12:59.973: INFO: ss-2  ip-172-31-59-90  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:12:22 +0000 UTC  }]
Jan  9 13:12:59.973: INFO: 
Jan  9 13:12:59.973: INFO: StatefulSet ss has not reached scale 0, at 3
Jan  9 13:13:00.975: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.981273564s
Jan  9 13:13:01.977: INFO: Verifying statefulset ss doesn't scale past 0 for another 979.092365ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-m5g9d
Jan  9 13:13:02.978: INFO: Scaling statefulset ss to 0
Jan  9 13:13:02.982: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan  9 13:13:02.983: INFO: Deleting all statefulset in ns e2e-tests-statefulset-m5g9d
Jan  9 13:13:02.984: INFO: Scaling statefulset ss to 0
Jan  9 13:13:02.988: INFO: Waiting for statefulset status.replicas updated to 0
Jan  9 13:13:02.990: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:13:02.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-m5g9d" for this suite.
Jan  9 13:13:09.000: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:13:09.013: INFO: namespace: e2e-tests-statefulset-m5g9d, resource: bindings, ignored listing per whitelist
Jan  9 13:13:09.035: INFO: namespace e2e-tests-statefulset-m5g9d deletion completed in 6.039616204s

• [SLOW TEST:67.095 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:13:09.035: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-vcvqh
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-vcvqh to expose endpoints map[]
Jan  9 13:13:09.070: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-vcvqh exposes endpoints map[] (1.451375ms elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-vcvqh
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-vcvqh to expose endpoints map[pod1:[100]]
Jan  9 13:13:11.081: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-vcvqh exposes endpoints map[pod1:[100]] (2.00765537s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-vcvqh
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-vcvqh to expose endpoints map[pod1:[100] pod2:[101]]
Jan  9 13:13:13.095: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-vcvqh exposes endpoints map[pod2:[101] pod1:[100]] (2.011537868s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-vcvqh
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-vcvqh to expose endpoints map[pod2:[101]]
Jan  9 13:13:13.101: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-vcvqh exposes endpoints map[pod2:[101]] (3.253656ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-vcvqh
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-vcvqh to expose endpoints map[]
Jan  9 13:13:14.106: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-vcvqh exposes endpoints map[] (1.003517285s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:13:14.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-vcvqh" for this suite.
Jan  9 13:13:20.119: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:13:20.145: INFO: namespace: e2e-tests-services-vcvqh, resource: bindings, ignored listing per whitelist
Jan  9 13:13:20.158: INFO: namespace e2e-tests-services-vcvqh deletion completed in 6.042962951s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:11.123 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:13:20.158: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan  9 13:13:20.198: INFO: Waiting up to 5m0s for pod "downwardapi-volume-55bc7615-1410-11e9-a571-02181533b527" in namespace "e2e-tests-projected-cqvjm" to be "success or failure"
Jan  9 13:13:20.199: INFO: Pod "downwardapi-volume-55bc7615-1410-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.020982ms
Jan  9 13:13:22.201: INFO: Pod "downwardapi-volume-55bc7615-1410-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003278456s
STEP: Saw pod success
Jan  9 13:13:22.201: INFO: Pod "downwardapi-volume-55bc7615-1410-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 13:13:22.202: INFO: Trying to get logs from node ip-172-31-59-90 pod downwardapi-volume-55bc7615-1410-11e9-a571-02181533b527 container client-container: <nil>
STEP: delete the pod
Jan  9 13:13:22.211: INFO: Waiting for pod downwardapi-volume-55bc7615-1410-11e9-a571-02181533b527 to disappear
Jan  9 13:13:22.213: INFO: Pod downwardapi-volume-55bc7615-1410-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:13:22.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-cqvjm" for this suite.
Jan  9 13:13:28.218: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:13:28.227: INFO: namespace: e2e-tests-projected-cqvjm, resource: bindings, ignored listing per whitelist
Jan  9 13:13:28.254: INFO: namespace e2e-tests-projected-cqvjm deletion completed in 6.040257943s

• [SLOW TEST:8.096 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:13:28.254: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jan  9 13:13:30.805: INFO: Successfully updated pod "labelsupdate5a8f0635-1410-11e9-a571-02181533b527"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:13:32.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-pqksj" for this suite.
Jan  9 13:13:54.820: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:13:54.831: INFO: namespace: e2e-tests-downward-api-pqksj, resource: bindings, ignored listing per whitelist
Jan  9 13:13:54.855: INFO: namespace e2e-tests-downward-api-pqksj deletion completed in 22.04000508s

• [SLOW TEST:26.601 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:13:54.855: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Jan  9 13:13:54.886: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 --namespace=e2e-tests-kubectl-4gqmw run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Jan  9 13:13:57.012: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Jan  9 13:13:57.012: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:13:59.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-4gqmw" for this suite.
Jan  9 13:14:05.022: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:14:05.053: INFO: namespace: e2e-tests-kubectl-4gqmw, resource: bindings, ignored listing per whitelist
Jan  9 13:14:05.059: INFO: namespace e2e-tests-kubectl-4gqmw deletion completed in 6.042677713s

• [SLOW TEST:10.204 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:14:05.059: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0109 13:14:15.115976      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan  9 13:14:15.116: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:14:15.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-978rl" for this suite.
Jan  9 13:14:21.121: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:14:21.133: INFO: namespace: e2e-tests-gc-978rl, resource: bindings, ignored listing per whitelist
Jan  9 13:14:21.158: INFO: namespace e2e-tests-gc-978rl deletion completed in 6.041273209s

• [SLOW TEST:16.099 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:14:21.158: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan  9 13:14:21.190: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:14:23.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-5stqw" for this suite.
Jan  9 13:15:13.211: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:15:13.228: INFO: namespace: e2e-tests-pods-5stqw, resource: bindings, ignored listing per whitelist
Jan  9 13:15:13.250: INFO: namespace e2e-tests-pods-5stqw deletion completed in 50.043306145s

• [SLOW TEST:52.092 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:15:13.250: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan  9 13:15:13.285: INFO: Waiting up to 5m0s for pod "downwardapi-volume-99242ac0-1410-11e9-a571-02181533b527" in namespace "e2e-tests-projected-9kckg" to be "success or failure"
Jan  9 13:15:13.286: INFO: Pod "downwardapi-volume-99242ac0-1410-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.656178ms
Jan  9 13:15:15.288: INFO: Pod "downwardapi-volume-99242ac0-1410-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003619764s
STEP: Saw pod success
Jan  9 13:15:15.288: INFO: Pod "downwardapi-volume-99242ac0-1410-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 13:15:15.290: INFO: Trying to get logs from node ip-172-31-59-90 pod downwardapi-volume-99242ac0-1410-11e9-a571-02181533b527 container client-container: <nil>
STEP: delete the pod
Jan  9 13:15:15.298: INFO: Waiting for pod downwardapi-volume-99242ac0-1410-11e9-a571-02181533b527 to disappear
Jan  9 13:15:15.299: INFO: Pod downwardapi-volume-99242ac0-1410-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:15:15.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9kckg" for this suite.
Jan  9 13:15:21.304: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:15:21.332: INFO: namespace: e2e-tests-projected-9kckg, resource: bindings, ignored listing per whitelist
Jan  9 13:15:21.341: INFO: namespace e2e-tests-projected-9kckg deletion completed in 6.040847637s

• [SLOW TEST:8.091 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:15:21.341: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan  9 13:15:23.387: INFO: Waiting up to 5m0s for pod "client-envvars-9f29bb39-1410-11e9-a571-02181533b527" in namespace "e2e-tests-pods-pkxmh" to be "success or failure"
Jan  9 13:15:23.388: INFO: Pod "client-envvars-9f29bb39-1410-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 980.87µs
Jan  9 13:15:25.390: INFO: Pod "client-envvars-9f29bb39-1410-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.002827179s
STEP: Saw pod success
Jan  9 13:15:25.390: INFO: Pod "client-envvars-9f29bb39-1410-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 13:15:25.391: INFO: Trying to get logs from node ip-172-31-59-90 pod client-envvars-9f29bb39-1410-11e9-a571-02181533b527 container env3cont: <nil>
STEP: delete the pod
Jan  9 13:15:25.398: INFO: Waiting for pod client-envvars-9f29bb39-1410-11e9-a571-02181533b527 to disappear
Jan  9 13:15:25.400: INFO: Pod client-envvars-9f29bb39-1410-11e9-a571-02181533b527 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:15:25.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-pkxmh" for this suite.
Jan  9 13:16:15.406: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:16:15.412: INFO: namespace: e2e-tests-pods-pkxmh, resource: bindings, ignored listing per whitelist
Jan  9 13:16:15.444: INFO: namespace e2e-tests-pods-pkxmh deletion completed in 50.042399444s

• [SLOW TEST:54.103 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:16:15.444: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Jan  9 13:16:15.477: INFO: Waiting up to 5m0s for pod "client-containers-be35efbd-1410-11e9-a571-02181533b527" in namespace "e2e-tests-containers-gwql2" to be "success or failure"
Jan  9 13:16:15.478: INFO: Pod "client-containers-be35efbd-1410-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 983.924µs
Jan  9 13:16:17.480: INFO: Pod "client-containers-be35efbd-1410-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.002835973s
STEP: Saw pod success
Jan  9 13:16:17.480: INFO: Pod "client-containers-be35efbd-1410-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 13:16:17.481: INFO: Trying to get logs from node ip-172-31-59-90 pod client-containers-be35efbd-1410-11e9-a571-02181533b527 container test-container: <nil>
STEP: delete the pod
Jan  9 13:16:17.490: INFO: Waiting for pod client-containers-be35efbd-1410-11e9-a571-02181533b527 to disappear
Jan  9 13:16:17.491: INFO: Pod client-containers-be35efbd-1410-11e9-a571-02181533b527 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:16:17.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-gwql2" for this suite.
Jan  9 13:16:23.497: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:16:23.524: INFO: namespace: e2e-tests-containers-gwql2, resource: bindings, ignored listing per whitelist
Jan  9 13:16:23.532: INFO: namespace e2e-tests-containers-gwql2 deletion completed in 6.03973199s

• [SLOW TEST:8.088 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:16:23.532: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Jan  9 13:16:23.564: INFO: namespace e2e-tests-kubectl-npmgq
Jan  9 13:16:23.564: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 create -f - --namespace=e2e-tests-kubectl-npmgq'
Jan  9 13:16:23.694: INFO: stderr: ""
Jan  9 13:16:23.694: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Jan  9 13:16:24.696: INFO: Selector matched 1 pods for map[app:redis]
Jan  9 13:16:24.696: INFO: Found 0 / 1
Jan  9 13:16:25.696: INFO: Selector matched 1 pods for map[app:redis]
Jan  9 13:16:25.696: INFO: Found 1 / 1
Jan  9 13:16:25.696: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jan  9 13:16:25.697: INFO: Selector matched 1 pods for map[app:redis]
Jan  9 13:16:25.697: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jan  9 13:16:25.697: INFO: wait on redis-master startup in e2e-tests-kubectl-npmgq 
Jan  9 13:16:25.698: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 logs redis-master-rzq22 redis-master --namespace=e2e-tests-kubectl-npmgq'
Jan  9 13:16:25.766: INFO: stderr: ""
Jan  9 13:16:25.766: INFO: stdout: "1:M 09 Jan 13:16:24.937 # You requested maxclients of 10000 requiring at least 10032 max file descriptors.\n1:M 09 Jan 13:16:24.938 # Server can't set maximum open files to 10032 because of OS error: Operation not permitted.\n1:M 09 Jan 13:16:24.938 # Current maximum open files is 4096. maxclients has been reduced to 4064 to compensate for low ulimit. If you need higher maxclients increase 'ulimit -n'.\n                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 09 Jan 13:16:24.938 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 09 Jan 13:16:24.938 # Server started, Redis version 3.2.12\n1:M 09 Jan 13:16:24.938 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 09 Jan 13:16:24.938 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Jan  9 13:16:25.766: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-npmgq'
Jan  9 13:16:25.838: INFO: stderr: ""
Jan  9 13:16:25.838: INFO: stdout: "service/rm2 exposed\n"
Jan  9 13:16:25.841: INFO: Service rm2 in namespace e2e-tests-kubectl-npmgq found.
STEP: exposing service
Jan  9 13:16:27.845: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-npmgq'
Jan  9 13:16:27.914: INFO: stderr: ""
Jan  9 13:16:27.914: INFO: stdout: "service/rm3 exposed\n"
Jan  9 13:16:27.915: INFO: Service rm3 in namespace e2e-tests-kubectl-npmgq found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:16:29.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-npmgq" for this suite.
Jan  9 13:16:51.924: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:16:51.956: INFO: namespace: e2e-tests-kubectl-npmgq, resource: bindings, ignored listing per whitelist
Jan  9 13:16:51.959: INFO: namespace e2e-tests-kubectl-npmgq deletion completed in 22.039997002s

• [SLOW TEST:28.427 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:16:51.959: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-d3f9d555-1410-11e9-a571-02181533b527
Jan  9 13:16:51.993: INFO: Pod name my-hostname-basic-d3f9d555-1410-11e9-a571-02181533b527: Found 0 pods out of 1
Jan  9 13:16:56.995: INFO: Pod name my-hostname-basic-d3f9d555-1410-11e9-a571-02181533b527: Found 1 pods out of 1
Jan  9 13:16:56.995: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-d3f9d555-1410-11e9-a571-02181533b527" are running
Jan  9 13:16:56.996: INFO: Pod "my-hostname-basic-d3f9d555-1410-11e9-a571-02181533b527-s5dsk" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-09 13:16:52 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-09 13:16:53 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-09 13:16:53 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-09 13:16:51 +0000 UTC Reason: Message:}])
Jan  9 13:16:56.996: INFO: Trying to dial the pod
Jan  9 13:17:02.001: INFO: Controller my-hostname-basic-d3f9d555-1410-11e9-a571-02181533b527: Got expected result from replica 1 [my-hostname-basic-d3f9d555-1410-11e9-a571-02181533b527-s5dsk]: "my-hostname-basic-d3f9d555-1410-11e9-a571-02181533b527-s5dsk", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:17:02.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-2zzwj" for this suite.
Jan  9 13:17:08.007: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:17:08.032: INFO: namespace: e2e-tests-replication-controller-2zzwj, resource: bindings, ignored listing per whitelist
Jan  9 13:17:08.044: INFO: namespace e2e-tests-replication-controller-2zzwj deletion completed in 6.041728118s

• [SLOW TEST:16.085 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:17:08.044: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jan  9 13:17:08.078: INFO: Waiting up to 5m0s for pod "pod-dd903128-1410-11e9-a571-02181533b527" in namespace "e2e-tests-emptydir-mlcpq" to be "success or failure"
Jan  9 13:17:08.079: INFO: Pod "pod-dd903128-1410-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.686082ms
Jan  9 13:17:10.081: INFO: Pod "pod-dd903128-1410-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003360594s
STEP: Saw pod success
Jan  9 13:17:10.081: INFO: Pod "pod-dd903128-1410-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 13:17:10.082: INFO: Trying to get logs from node ip-172-31-59-90 pod pod-dd903128-1410-11e9-a571-02181533b527 container test-container: <nil>
STEP: delete the pod
Jan  9 13:17:10.092: INFO: Waiting for pod pod-dd903128-1410-11e9-a571-02181533b527 to disappear
Jan  9 13:17:10.093: INFO: Pod pod-dd903128-1410-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:17:10.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-mlcpq" for this suite.
Jan  9 13:17:16.098: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:17:16.112: INFO: namespace: e2e-tests-emptydir-mlcpq, resource: bindings, ignored listing per whitelist
Jan  9 13:17:16.134: INFO: namespace e2e-tests-emptydir-mlcpq deletion completed in 6.039472424s

• [SLOW TEST:8.089 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:17:16.134: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Jan  9 13:17:16.168: INFO: Waiting up to 5m0s for pod "client-containers-e262a7dd-1410-11e9-a571-02181533b527" in namespace "e2e-tests-containers-2lch2" to be "success or failure"
Jan  9 13:17:16.169: INFO: Pod "client-containers-e262a7dd-1410-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.00643ms
Jan  9 13:17:18.171: INFO: Pod "client-containers-e262a7dd-1410-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.002686111s
STEP: Saw pod success
Jan  9 13:17:18.171: INFO: Pod "client-containers-e262a7dd-1410-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 13:17:18.172: INFO: Trying to get logs from node ip-172-31-59-90 pod client-containers-e262a7dd-1410-11e9-a571-02181533b527 container test-container: <nil>
STEP: delete the pod
Jan  9 13:17:18.181: INFO: Waiting for pod client-containers-e262a7dd-1410-11e9-a571-02181533b527 to disappear
Jan  9 13:17:18.182: INFO: Pod client-containers-e262a7dd-1410-11e9-a571-02181533b527 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:17:18.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-2lch2" for this suite.
Jan  9 13:17:24.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:17:24.205: INFO: namespace: e2e-tests-containers-2lch2, resource: bindings, ignored listing per whitelist
Jan  9 13:17:24.224: INFO: namespace e2e-tests-containers-2lch2 deletion completed in 6.041299711s

• [SLOW TEST:8.090 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:17:24.224: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Jan  9 13:17:26.265: INFO: Pod pod-hostip-e735789b-1410-11e9-a571-02181533b527 has hostIP: 172.31.59.90
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:17:26.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-pf2df" for this suite.
Jan  9 13:17:48.271: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:17:48.305: INFO: namespace: e2e-tests-pods-pf2df, resource: bindings, ignored listing per whitelist
Jan  9 13:17:48.309: INFO: namespace e2e-tests-pods-pf2df deletion completed in 22.042008307s

• [SLOW TEST:24.084 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:17:48.309: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-f5902e59-1410-11e9-a571-02181533b527
STEP: Creating a pod to test consume secrets
Jan  9 13:17:48.344: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f59065a4-1410-11e9-a571-02181533b527" in namespace "e2e-tests-projected-7zx5r" to be "success or failure"
Jan  9 13:17:48.347: INFO: Pod "pod-projected-secrets-f59065a4-1410-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 2.238622ms
Jan  9 13:17:50.349: INFO: Pod "pod-projected-secrets-f59065a4-1410-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004077091s
Jan  9 13:17:52.351: INFO: Pod "pod-projected-secrets-f59065a4-1410-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006089401s
STEP: Saw pod success
Jan  9 13:17:52.351: INFO: Pod "pod-projected-secrets-f59065a4-1410-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 13:17:52.353: INFO: Trying to get logs from node ip-172-31-59-90 pod pod-projected-secrets-f59065a4-1410-11e9-a571-02181533b527 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan  9 13:17:52.362: INFO: Waiting for pod pod-projected-secrets-f59065a4-1410-11e9-a571-02181533b527 to disappear
Jan  9 13:17:52.363: INFO: Pod pod-projected-secrets-f59065a4-1410-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:17:52.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7zx5r" for this suite.
Jan  9 13:17:58.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:17:58.395: INFO: namespace: e2e-tests-projected-7zx5r, resource: bindings, ignored listing per whitelist
Jan  9 13:17:58.406: INFO: namespace e2e-tests-projected-7zx5r deletion completed in 6.041601123s

• [SLOW TEST:10.097 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:17:58.406: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Jan  9 13:18:04.452: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-zwfzl PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan  9 13:18:04.452: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
Jan  9 13:18:04.524: INFO: Exec stderr: ""
Jan  9 13:18:04.524: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-zwfzl PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan  9 13:18:04.524: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
Jan  9 13:18:04.594: INFO: Exec stderr: ""
Jan  9 13:18:04.594: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-zwfzl PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan  9 13:18:04.594: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
Jan  9 13:18:04.666: INFO: Exec stderr: ""
Jan  9 13:18:04.666: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-zwfzl PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan  9 13:18:04.666: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
Jan  9 13:18:04.737: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Jan  9 13:18:04.737: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-zwfzl PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan  9 13:18:04.737: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
Jan  9 13:18:04.806: INFO: Exec stderr: ""
Jan  9 13:18:04.806: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-zwfzl PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan  9 13:18:04.806: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
Jan  9 13:18:04.875: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Jan  9 13:18:04.875: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-zwfzl PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan  9 13:18:04.875: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
Jan  9 13:18:04.942: INFO: Exec stderr: ""
Jan  9 13:18:04.942: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-zwfzl PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan  9 13:18:04.942: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
Jan  9 13:18:05.010: INFO: Exec stderr: ""
Jan  9 13:18:05.010: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-zwfzl PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan  9 13:18:05.010: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
Jan  9 13:18:05.083: INFO: Exec stderr: ""
Jan  9 13:18:05.083: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-zwfzl PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan  9 13:18:05.083: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
Jan  9 13:18:05.153: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:18:05.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-zwfzl" for this suite.
Jan  9 13:18:55.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:18:55.179: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-zwfzl, resource: bindings, ignored listing per whitelist
Jan  9 13:18:55.200: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-zwfzl deletion completed in 50.044794117s

• [SLOW TEST:56.794 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:18:55.200: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jan  9 13:18:55.231: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:18:58.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-kszpg" for this suite.
Jan  9 13:19:04.220: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:19:04.237: INFO: namespace: e2e-tests-init-container-kszpg, resource: bindings, ignored listing per whitelist
Jan  9 13:19:04.257: INFO: namespace e2e-tests-init-container-kszpg deletion completed in 6.042213135s

• [SLOW TEST:9.058 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:19:04.258: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan  9 13:19:04.294: INFO: Waiting up to 5m0s for pod "downwardapi-volume-22d5669b-1411-11e9-a571-02181533b527" in namespace "e2e-tests-downward-api-jpz2v" to be "success or failure"
Jan  9 13:19:04.295: INFO: Pod "downwardapi-volume-22d5669b-1411-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.076186ms
Jan  9 13:19:06.297: INFO: Pod "downwardapi-volume-22d5669b-1411-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.002794005s
STEP: Saw pod success
Jan  9 13:19:06.297: INFO: Pod "downwardapi-volume-22d5669b-1411-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 13:19:06.298: INFO: Trying to get logs from node ip-172-31-59-90 pod downwardapi-volume-22d5669b-1411-11e9-a571-02181533b527 container client-container: <nil>
STEP: delete the pod
Jan  9 13:19:06.308: INFO: Waiting for pod downwardapi-volume-22d5669b-1411-11e9-a571-02181533b527 to disappear
Jan  9 13:19:06.309: INFO: Pod downwardapi-volume-22d5669b-1411-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:19:06.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-jpz2v" for this suite.
Jan  9 13:19:12.314: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:19:12.321: INFO: namespace: e2e-tests-downward-api-jpz2v, resource: bindings, ignored listing per whitelist
Jan  9 13:19:12.353: INFO: namespace e2e-tests-downward-api-jpz2v deletion completed in 6.043134186s

• [SLOW TEST:8.096 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:19:12.353: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Jan  9 13:19:12.384: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jan  9 13:19:12.387: INFO: Waiting for terminating namespaces to be deleted...
Jan  9 13:19:12.388: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-59-90 before test
Jan  9 13:19:12.390: INFO: sonobuoy-systemd-logs-daemon-set-c5e6e334b21d4f47-sjlb6 from heptio-sonobuoy started at 2019-01-09 11:58:13 +0000 UTC (2 container statuses recorded)
Jan  9 13:19:12.390: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Jan  9 13:19:12.390: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Jan  9 13:19:12.390: INFO: sonobuoy from heptio-sonobuoy started at 2019-01-09 11:58:10 +0000 UTC (1 container statuses recorded)
Jan  9 13:19:12.390: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jan  9 13:19:12.390: INFO: sonobuoy-e2e-job-73c0b4a4fe2f4aff from heptio-sonobuoy started at 2019-01-09 11:58:13 +0000 UTC (2 container statuses recorded)
Jan  9 13:19:12.390: INFO: 	Container e2e ready: true, restart count 0
Jan  9 13:19:12.390: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan  9 13:19:12.390: INFO: kube-dns-6ccd496668-rmn4f from kube-system started at 2019-01-09 11:57:35 +0000 UTC (3 container statuses recorded)
Jan  9 13:19:12.390: INFO: 	Container dnsmasq ready: true, restart count 0
Jan  9 13:19:12.390: INFO: 	Container kubedns ready: true, restart count 0
Jan  9 13:19:12.390: INFO: 	Container sidecar ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-28dbc6d3-1411-11e9-a571-02181533b527 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-28dbc6d3-1411-11e9-a571-02181533b527 off the node ip-172-31-59-90
STEP: verifying the node doesn't have the label kubernetes.io/e2e-28dbc6d3-1411-11e9-a571-02181533b527
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:19:16.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-dsdnd" for this suite.
Jan  9 13:19:26.423: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:19:26.454: INFO: namespace: e2e-tests-sched-pred-dsdnd, resource: bindings, ignored listing per whitelist
Jan  9 13:19:26.459: INFO: namespace e2e-tests-sched-pred-dsdnd deletion completed in 10.04081352s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:14.106 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:19:26.459: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-3010a97b-1411-11e9-a571-02181533b527
STEP: Creating a pod to test consume configMaps
Jan  9 13:19:26.494: INFO: Waiting up to 5m0s for pod "pod-configmaps-3010e0b1-1411-11e9-a571-02181533b527" in namespace "e2e-tests-configmap-z7jgk" to be "success or failure"
Jan  9 13:19:26.495: INFO: Pod "pod-configmaps-3010e0b1-1411-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.041611ms
Jan  9 13:19:28.497: INFO: Pod "pod-configmaps-3010e0b1-1411-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.002572482s
STEP: Saw pod success
Jan  9 13:19:28.497: INFO: Pod "pod-configmaps-3010e0b1-1411-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 13:19:28.498: INFO: Trying to get logs from node ip-172-31-59-90 pod pod-configmaps-3010e0b1-1411-11e9-a571-02181533b527 container configmap-volume-test: <nil>
STEP: delete the pod
Jan  9 13:19:28.505: INFO: Waiting for pod pod-configmaps-3010e0b1-1411-11e9-a571-02181533b527 to disappear
Jan  9 13:19:28.506: INFO: Pod pod-configmaps-3010e0b1-1411-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:19:28.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-z7jgk" for this suite.
Jan  9 13:19:34.512: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:19:34.540: INFO: namespace: e2e-tests-configmap-z7jgk, resource: bindings, ignored listing per whitelist
Jan  9 13:19:34.550: INFO: namespace e2e-tests-configmap-z7jgk deletion completed in 6.042533264s

• [SLOW TEST:8.091 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:19:34.550: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan  9 13:19:34.580: INFO: Creating deployment "nginx-deployment"
Jan  9 13:19:34.582: INFO: Waiting for observed generation 1
Jan  9 13:19:36.587: INFO: Waiting for all required pods to come up
Jan  9 13:19:36.589: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Jan  9 13:19:42.593: INFO: Waiting for deployment "nginx-deployment" to complete
Jan  9 13:19:42.595: INFO: Updating deployment "nginx-deployment" with a non-existent image
Jan  9 13:19:42.599: INFO: Updating deployment nginx-deployment
Jan  9 13:19:42.599: INFO: Waiting for observed generation 2
Jan  9 13:19:44.602: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Jan  9 13:19:44.603: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Jan  9 13:19:44.604: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Jan  9 13:19:44.607: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Jan  9 13:19:44.607: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Jan  9 13:19:44.608: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Jan  9 13:19:44.610: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Jan  9 13:19:44.610: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Jan  9 13:19:44.614: INFO: Updating deployment nginx-deployment
Jan  9 13:19:44.614: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Jan  9 13:19:44.616: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Jan  9 13:19:44.620: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan  9 13:19:44.629: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-p5rgd,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-p5rgd/deployments/nginx-deployment,UID:34e32021-1411-11e9-90b5-12841864fc48,ResourceVersion:16017,Generation:3,CreationTimestamp:2019-01-09 13:19:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[{Progressing True 2019-01-09 13:19:42 +0000 UTC 2019-01-09 13:19:34 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-65bbdb5f8" is progressing.} {Available False 2019-01-09 13:19:44 +0000 UTC 2019-01-09 13:19:44 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}],ReadyReplicas:8,CollisionCount:nil,},}

Jan  9 13:19:44.633: INFO: New ReplicaSet "nginx-deployment-65bbdb5f8" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8,GenerateName:,Namespace:e2e-tests-deployment-p5rgd,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-p5rgd/replicasets/nginx-deployment-65bbdb5f8,UID:39aaa40e-1411-11e9-90b5-12841864fc48,ResourceVersion:16015,Generation:3,CreationTimestamp:2019-01-09 13:19:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 34e32021-1411-11e9-90b5-12841864fc48 0xc0027a0fa7 0xc0027a0fa8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan  9 13:19:44.633: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Jan  9 13:19:44.633: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965,GenerateName:,Namespace:e2e-tests-deployment-p5rgd,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-p5rgd/replicasets/nginx-deployment-555b55d965,UID:34e37c00-1411-11e9-90b5-12841864fc48,ResourceVersion:16013,Generation:3,CreationTimestamp:2019-01-09 13:19:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 34e32021-1411-11e9-90b5-12841864fc48 0xc0027a0e27 0xc0027a0e28}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Jan  9 13:19:44.640: INFO: Pod "nginx-deployment-555b55d965-2mqcl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-2mqcl,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-p5rgd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p5rgd/pods/nginx-deployment-555b55d965-2mqcl,UID:3ae127ee-1411-11e9-90b5-12841864fc48,ResourceVersion:16051,Generation:0,CreationTimestamp:2019-01-09 13:19:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 34e37c00-1411-11e9-90b5-12841864fc48 0xc0028554c7 0xc0028554c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tbplj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbplj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tbplj true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002855530} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002855550}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 13:19:44.640: INFO: Pod "nginx-deployment-555b55d965-7drmr" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-7drmr,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-p5rgd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p5rgd/pods/nginx-deployment-555b55d965-7drmr,UID:34e498e7-1411-11e9-90b5-12841864fc48,ResourceVersion:15896,Generation:0,CreationTimestamp:2019-01-09 13:19:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 34e37c00-1411-11e9-90b5-12841864fc48 0xc0028555a7 0xc0028555a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tbplj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbplj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tbplj true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-59-90,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002855760} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002855780}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:37 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:37 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:34 +0000 UTC  }],Message:,Reason:,HostIP:172.31.59.90,PodIP:10.1.1.29,StartTime:2019-01-09 13:19:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-09 13:19:36 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://cb0c35be42752d1d211efa1e73a406276badbcd4fc679505390e1ac6366a284a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 13:19:44.640: INFO: Pod "nginx-deployment-555b55d965-7tk6v" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-7tk6v,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-p5rgd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p5rgd/pods/nginx-deployment-555b55d965-7tk6v,UID:34e575d4-1411-11e9-90b5-12841864fc48,ResourceVersion:15914,Generation:0,CreationTimestamp:2019-01-09 13:19:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 34e37c00-1411-11e9-90b5-12841864fc48 0xc002855840 0xc002855841}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tbplj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbplj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tbplj true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-59-90,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028558b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028558d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:37 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:37 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:34 +0000 UTC  }],Message:,Reason:,HostIP:172.31.59.90,PodIP:10.1.1.35,StartTime:2019-01-09 13:19:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-09 13:19:37 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://093a787aad35922edfe7cdeee743251fdce8969347dea7b5d6c56133d4548517}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 13:19:44.640: INFO: Pod "nginx-deployment-555b55d965-8zlp7" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-8zlp7,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-p5rgd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p5rgd/pods/nginx-deployment-555b55d965-8zlp7,UID:34e52354-1411-11e9-90b5-12841864fc48,ResourceVersion:15926,Generation:0,CreationTimestamp:2019-01-09 13:19:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 34e37c00-1411-11e9-90b5-12841864fc48 0xc002855990 0xc002855991}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tbplj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbplj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tbplj true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-59-90,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002855a00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002855a20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:37 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:37 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:34 +0000 UTC  }],Message:,Reason:,HostIP:172.31.59.90,PodIP:10.1.1.32,StartTime:2019-01-09 13:19:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-09 13:19:36 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://df192b4f2e905b022cf139c973c120548cebcc2a09ede040c331b1939462e0a1}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 13:19:44.640: INFO: Pod "nginx-deployment-555b55d965-9mdtt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-9mdtt,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-p5rgd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p5rgd/pods/nginx-deployment-555b55d965-9mdtt,UID:3ae11c8f-1411-11e9-90b5-12841864fc48,ResourceVersion:16048,Generation:0,CreationTimestamp:2019-01-09 13:19:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 34e37c00-1411-11e9-90b5-12841864fc48 0xc002855ae0 0xc002855ae1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tbplj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbplj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tbplj true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002855b40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002855b60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 13:19:44.641: INFO: Pod "nginx-deployment-555b55d965-cnwc4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-cnwc4,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-p5rgd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p5rgd/pods/nginx-deployment-555b55d965-cnwc4,UID:3ae07486-1411-11e9-90b5-12841864fc48,ResourceVersion:16052,Generation:0,CreationTimestamp:2019-01-09 13:19:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 34e37c00-1411-11e9-90b5-12841864fc48 0xc002855bb7 0xc002855bb8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tbplj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbplj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tbplj true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-59-90,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002855c30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002855c50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:44 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 13:19:44.641: INFO: Pod "nginx-deployment-555b55d965-dkv75" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-dkv75,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-p5rgd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p5rgd/pods/nginx-deployment-555b55d965-dkv75,UID:3ade9b63-1411-11e9-90b5-12841864fc48,ResourceVersion:16021,Generation:0,CreationTimestamp:2019-01-09 13:19:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 34e37c00-1411-11e9-90b5-12841864fc48 0xc002855cc0 0xc002855cc1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tbplj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbplj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tbplj true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-59-90,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002855d30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002855d50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:44 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 13:19:44.641: INFO: Pod "nginx-deployment-555b55d965-fsz5t" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-fsz5t,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-p5rgd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p5rgd/pods/nginx-deployment-555b55d965-fsz5t,UID:34e508d9-1411-11e9-90b5-12841864fc48,ResourceVersion:15899,Generation:0,CreationTimestamp:2019-01-09 13:19:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 34e37c00-1411-11e9-90b5-12841864fc48 0xc002855dc0 0xc002855dc1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tbplj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbplj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tbplj true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-59-90,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002855e30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002855e50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:37 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:37 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:34 +0000 UTC  }],Message:,Reason:,HostIP:172.31.59.90,PodIP:10.1.1.34,StartTime:2019-01-09 13:19:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-09 13:19:37 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://dce0314c085fe7722bc5ccc8b1abf7b254c86090aab83340446f36a9a97e770d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 13:19:44.641: INFO: Pod "nginx-deployment-555b55d965-gffm2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-gffm2,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-p5rgd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p5rgd/pods/nginx-deployment-555b55d965-gffm2,UID:3ae118fb-1411-11e9-90b5-12841864fc48,ResourceVersion:16047,Generation:0,CreationTimestamp:2019-01-09 13:19:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 34e37c00-1411-11e9-90b5-12841864fc48 0xc002855f20 0xc002855f21}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tbplj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbplj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tbplj true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002855f80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002855fa0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 13:19:44.641: INFO: Pod "nginx-deployment-555b55d965-kbkjs" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-kbkjs,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-p5rgd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p5rgd/pods/nginx-deployment-555b55d965-kbkjs,UID:34e590a5-1411-11e9-90b5-12841864fc48,ResourceVersion:15932,Generation:0,CreationTimestamp:2019-01-09 13:19:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 34e37c00-1411-11e9-90b5-12841864fc48 0xc002855ff7 0xc002855ff8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tbplj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbplj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tbplj true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-59-90,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d02070} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d02090}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:38 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:38 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:34 +0000 UTC  }],Message:,Reason:,HostIP:172.31.59.90,PodIP:10.1.1.37,StartTime:2019-01-09 13:19:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-09 13:19:37 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://4978d8f2381dc262500211e128ef1218e7a9c3de06ef611603abb32020758c21}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 13:19:44.641: INFO: Pod "nginx-deployment-555b55d965-kght2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-kght2,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-p5rgd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p5rgd/pods/nginx-deployment-555b55d965-kght2,UID:3adf53c3-1411-11e9-90b5-12841864fc48,ResourceVersion:16031,Generation:0,CreationTimestamp:2019-01-09 13:19:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 34e37c00-1411-11e9-90b5-12841864fc48 0xc001d02150 0xc001d02151}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tbplj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbplj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tbplj true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-59-90,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d021c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d02220}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:44 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 13:19:44.641: INFO: Pod "nginx-deployment-555b55d965-ks7ph" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-ks7ph,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-p5rgd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p5rgd/pods/nginx-deployment-555b55d965-ks7ph,UID:3adf51ef-1411-11e9-90b5-12841864fc48,ResourceVersion:16025,Generation:0,CreationTimestamp:2019-01-09 13:19:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 34e37c00-1411-11e9-90b5-12841864fc48 0xc001d02290 0xc001d02291}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tbplj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbplj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tbplj true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-59-90,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d02330} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d02350}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:44 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 13:19:44.641: INFO: Pod "nginx-deployment-555b55d965-lvqhc" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-lvqhc,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-p5rgd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p5rgd/pods/nginx-deployment-555b55d965-lvqhc,UID:34e51a8c-1411-11e9-90b5-12841864fc48,ResourceVersion:15919,Generation:0,CreationTimestamp:2019-01-09 13:19:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 34e37c00-1411-11e9-90b5-12841864fc48 0xc001d02430 0xc001d02431}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tbplj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbplj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tbplj true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-59-90,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d024a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d024c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:37 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:37 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:34 +0000 UTC  }],Message:,Reason:,HostIP:172.31.59.90,PodIP:10.1.1.31,StartTime:2019-01-09 13:19:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-09 13:19:36 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://968556ae551cc629f1c940f808a0155d66612cbea097f7f525454b15f149279d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 13:19:44.641: INFO: Pod "nginx-deployment-555b55d965-pfl98" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-pfl98,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-p5rgd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p5rgd/pods/nginx-deployment-555b55d965-pfl98,UID:3ae1429b-1411-11e9-90b5-12841864fc48,ResourceVersion:16050,Generation:0,CreationTimestamp:2019-01-09 13:19:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 34e37c00-1411-11e9-90b5-12841864fc48 0xc001d02580 0xc001d02581}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tbplj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbplj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tbplj true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d025e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d02600}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 13:19:44.641: INFO: Pod "nginx-deployment-555b55d965-r9665" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-r9665,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-p5rgd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p5rgd/pods/nginx-deployment-555b55d965-r9665,UID:3ae08271-1411-11e9-90b5-12841864fc48,ResourceVersion:16057,Generation:0,CreationTimestamp:2019-01-09 13:19:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 34e37c00-1411-11e9-90b5-12841864fc48 0xc001d02657 0xc001d02658}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tbplj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbplj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tbplj true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-59-90,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d026d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d026f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:44 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 13:19:44.641: INFO: Pod "nginx-deployment-555b55d965-rpzxq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-rpzxq,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-p5rgd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p5rgd/pods/nginx-deployment-555b55d965-rpzxq,UID:3ae07d46-1411-11e9-90b5-12841864fc48,ResourceVersion:16056,Generation:0,CreationTimestamp:2019-01-09 13:19:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 34e37c00-1411-11e9-90b5-12841864fc48 0xc001d02770 0xc001d02771}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tbplj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbplj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tbplj true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-59-90,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d027e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d02800}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:44 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 13:19:44.642: INFO: Pod "nginx-deployment-555b55d965-rrpxk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-rrpxk,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-p5rgd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p5rgd/pods/nginx-deployment-555b55d965-rrpxk,UID:3ae090da-1411-11e9-90b5-12841864fc48,ResourceVersion:16055,Generation:0,CreationTimestamp:2019-01-09 13:19:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 34e37c00-1411-11e9-90b5-12841864fc48 0xc001d02870 0xc001d02871}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tbplj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbplj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tbplj true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-59-90,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d02950} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d02970}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:44 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 13:19:44.642: INFO: Pod "nginx-deployment-555b55d965-trrnf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-trrnf,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-p5rgd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p5rgd/pods/nginx-deployment-555b55d965-trrnf,UID:3ae13657-1411-11e9-90b5-12841864fc48,ResourceVersion:16046,Generation:0,CreationTimestamp:2019-01-09 13:19:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 34e37c00-1411-11e9-90b5-12841864fc48 0xc001d029e0 0xc001d029e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tbplj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbplj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tbplj true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d02a40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d02a60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 13:19:44.649: INFO: Pod "nginx-deployment-555b55d965-v24qd" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-v24qd,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-p5rgd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p5rgd/pods/nginx-deployment-555b55d965-v24qd,UID:34e513b8-1411-11e9-90b5-12841864fc48,ResourceVersion:15909,Generation:0,CreationTimestamp:2019-01-09 13:19:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 34e37c00-1411-11e9-90b5-12841864fc48 0xc001d02ab7 0xc001d02ab8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tbplj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbplj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tbplj true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-59-90,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d02b30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d02b50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:37 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:37 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:34 +0000 UTC  }],Message:,Reason:,HostIP:172.31.59.90,PodIP:10.1.1.33,StartTime:2019-01-09 13:19:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-09 13:19:36 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://19ef0e894cc78fcea6a496110fd4974bc5e63dceaad3ac3a9521742e33b15654}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 13:19:44.649: INFO: Pod "nginx-deployment-555b55d965-w2vrk" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-w2vrk,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-p5rgd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p5rgd/pods/nginx-deployment-555b55d965-w2vrk,UID:34e41f60-1411-11e9-90b5-12841864fc48,ResourceVersion:15904,Generation:0,CreationTimestamp:2019-01-09 13:19:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 34e37c00-1411-11e9-90b5-12841864fc48 0xc001d02c10 0xc001d02c11}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tbplj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbplj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tbplj true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-59-90,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d02c80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d02ca0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:37 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:37 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:34 +0000 UTC  }],Message:,Reason:,HostIP:172.31.59.90,PodIP:10.1.1.28,StartTime:2019-01-09 13:19:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-09 13:19:35 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://671f0eb92f0f57634b253a2ec1778d106b92af7172c5e2c96de499899dc82fd6}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 13:19:44.650: INFO: Pod "nginx-deployment-65bbdb5f8-6hgw6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-6hgw6,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-p5rgd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p5rgd/pods/nginx-deployment-65bbdb5f8-6hgw6,UID:3adf1e65-1411-11e9-90b5-12841864fc48,ResourceVersion:16026,Generation:0,CreationTimestamp:2019-01-09 13:19:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 39aaa40e-1411-11e9-90b5-12841864fc48 0xc001d02d70 0xc001d02d71}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tbplj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbplj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tbplj true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-59-90,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d02df0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d02e10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:44 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 13:19:44.650: INFO: Pod "nginx-deployment-65bbdb5f8-bshnt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-bshnt,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-p5rgd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p5rgd/pods/nginx-deployment-65bbdb5f8-bshnt,UID:3adfc279-1411-11e9-90b5-12841864fc48,ResourceVersion:16040,Generation:0,CreationTimestamp:2019-01-09 13:19:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 39aaa40e-1411-11e9-90b5-12841864fc48 0xc001d02e80 0xc001d02e81}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tbplj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbplj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tbplj true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-59-90,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d02f00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d02f20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:44 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 13:19:44.650: INFO: Pod "nginx-deployment-65bbdb5f8-gtltr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-gtltr,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-p5rgd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p5rgd/pods/nginx-deployment-65bbdb5f8-gtltr,UID:3ae043ce-1411-11e9-90b5-12841864fc48,ResourceVersion:16042,Generation:0,CreationTimestamp:2019-01-09 13:19:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 39aaa40e-1411-11e9-90b5-12841864fc48 0xc001d02f90 0xc001d02f91}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tbplj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbplj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tbplj true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-59-90,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d03020} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d03040}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:44 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 13:19:44.650: INFO: Pod "nginx-deployment-65bbdb5f8-hltbv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-hltbv,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-p5rgd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p5rgd/pods/nginx-deployment-65bbdb5f8-hltbv,UID:39ae6ae6-1411-11e9-90b5-12841864fc48,ResourceVersion:15992,Generation:0,CreationTimestamp:2019-01-09 13:19:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 39aaa40e-1411-11e9-90b5-12841864fc48 0xc001d030b0 0xc001d030b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tbplj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbplj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tbplj true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-59-90,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d03130} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d03150}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:42 +0000 UTC  }],Message:,Reason:,HostIP:172.31.59.90,PodIP:,StartTime:2019-01-09 13:19:42 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 13:19:44.650: INFO: Pod "nginx-deployment-65bbdb5f8-hwdw7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-hwdw7,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-p5rgd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p5rgd/pods/nginx-deployment-65bbdb5f8-hwdw7,UID:39ae194f-1411-11e9-90b5-12841864fc48,ResourceVersion:16002,Generation:0,CreationTimestamp:2019-01-09 13:19:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 39aaa40e-1411-11e9-90b5-12841864fc48 0xc001d03210 0xc001d03211}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tbplj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbplj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tbplj true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-59-90,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d03290} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d032b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:42 +0000 UTC  }],Message:,Reason:,HostIP:172.31.59.90,PodIP:10.1.1.38,StartTime:2019-01-09 13:19:42 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 13:19:44.650: INFO: Pod "nginx-deployment-65bbdb5f8-krh79" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-krh79,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-p5rgd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p5rgd/pods/nginx-deployment-65bbdb5f8-krh79,UID:39ab130d-1411-11e9-90b5-12841864fc48,ResourceVersion:16011,Generation:0,CreationTimestamp:2019-01-09 13:19:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 39aaa40e-1411-11e9-90b5-12841864fc48 0xc001d03390 0xc001d03391}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tbplj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbplj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tbplj true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-59-90,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d03410} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d03430}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:42 +0000 UTC  }],Message:,Reason:,HostIP:172.31.59.90,PodIP:10.1.1.40,StartTime:2019-01-09 13:19:42 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 13:19:44.650: INFO: Pod "nginx-deployment-65bbdb5f8-n4rdd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-n4rdd,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-p5rgd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p5rgd/pods/nginx-deployment-65bbdb5f8-n4rdd,UID:3ae04186-1411-11e9-90b5-12841864fc48,ResourceVersion:16043,Generation:0,CreationTimestamp:2019-01-09 13:19:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 39aaa40e-1411-11e9-90b5-12841864fc48 0xc001d03510 0xc001d03511}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tbplj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbplj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tbplj true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-59-90,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d03590} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d035b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:44 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 13:19:44.651: INFO: Pod "nginx-deployment-65bbdb5f8-pqp7n" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-pqp7n,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-p5rgd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p5rgd/pods/nginx-deployment-65bbdb5f8-pqp7n,UID:3ae062b7-1411-11e9-90b5-12841864fc48,ResourceVersion:16045,Generation:0,CreationTimestamp:2019-01-09 13:19:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 39aaa40e-1411-11e9-90b5-12841864fc48 0xc001d03620 0xc001d03621}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tbplj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbplj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tbplj true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-59-90,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d036a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d036c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:44 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 13:19:44.651: INFO: Pod "nginx-deployment-65bbdb5f8-tvn8x" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-tvn8x,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-p5rgd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p5rgd/pods/nginx-deployment-65bbdb5f8-tvn8x,UID:3adfc6ac-1411-11e9-90b5-12841864fc48,ResourceVersion:16032,Generation:0,CreationTimestamp:2019-01-09 13:19:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 39aaa40e-1411-11e9-90b5-12841864fc48 0xc001d03730 0xc001d03731}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tbplj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbplj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tbplj true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-59-90,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d037b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d037d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:44 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 13:19:44.652: INFO: Pod "nginx-deployment-65bbdb5f8-vtrw5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-vtrw5,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-p5rgd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p5rgd/pods/nginx-deployment-65bbdb5f8-vtrw5,UID:3ae06628-1411-11e9-90b5-12841864fc48,ResourceVersion:16053,Generation:0,CreationTimestamp:2019-01-09 13:19:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 39aaa40e-1411-11e9-90b5-12841864fc48 0xc001d03840 0xc001d03841}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tbplj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbplj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tbplj true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-59-90,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d038c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d038e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:44 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 13:19:44.652: INFO: Pod "nginx-deployment-65bbdb5f8-vw2sq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-vw2sq,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-p5rgd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p5rgd/pods/nginx-deployment-65bbdb5f8-vw2sq,UID:3ae12def-1411-11e9-90b5-12841864fc48,ResourceVersion:16054,Generation:0,CreationTimestamp:2019-01-09 13:19:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 39aaa40e-1411-11e9-90b5-12841864fc48 0xc001d03950 0xc001d03951}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tbplj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbplj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tbplj true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d039c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d039e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 13:19:44.652: INFO: Pod "nginx-deployment-65bbdb5f8-z49xh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-z49xh,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-p5rgd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p5rgd/pods/nginx-deployment-65bbdb5f8-z49xh,UID:39aadd7f-1411-11e9-90b5-12841864fc48,ResourceVersion:16008,Generation:0,CreationTimestamp:2019-01-09 13:19:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 39aaa40e-1411-11e9-90b5-12841864fc48 0xc001d03a37 0xc001d03a38}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tbplj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbplj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tbplj true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-59-90,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d03ab0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d03ad0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:42 +0000 UTC  }],Message:,Reason:,HostIP:172.31.59.90,PodIP:10.1.1.39,StartTime:2019-01-09 13:19:42 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 13:19:44.652: INFO: Pod "nginx-deployment-65bbdb5f8-ztj2q" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-ztj2q,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-p5rgd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p5rgd/pods/nginx-deployment-65bbdb5f8-ztj2q,UID:39ab2aca-1411-11e9-90b5-12841864fc48,ResourceVersion:15986,Generation:0,CreationTimestamp:2019-01-09 13:19:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 39aaa40e-1411-11e9-90b5-12841864fc48 0xc001d03bb0 0xc001d03bb1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tbplj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbplj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tbplj true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-59-90,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d03c30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d03c50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 13:19:42 +0000 UTC  }],Message:,Reason:,HostIP:172.31.59.90,PodIP:,StartTime:2019-01-09 13:19:42 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:19:44.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-p5rgd" for this suite.
Jan  9 13:19:50.670: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:19:50.703: INFO: namespace: e2e-tests-deployment-p5rgd, resource: bindings, ignored listing per whitelist
Jan  9 13:19:50.712: INFO: namespace e2e-tests-deployment-p5rgd deletion completed in 6.055467763s

• [SLOW TEST:16.162 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:19:50.712: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Jan  9 13:19:50.753: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-sr4lp,SelfLink:/api/v1/namespaces/e2e-tests-watch-sr4lp/configmaps/e2e-watch-test-configmap-a,UID:3e869d25-1411-11e9-90b5-12841864fc48,ResourceVersion:16281,Generation:0,CreationTimestamp:2019-01-09 13:19:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan  9 13:19:50.753: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-sr4lp,SelfLink:/api/v1/namespaces/e2e-tests-watch-sr4lp/configmaps/e2e-watch-test-configmap-a,UID:3e869d25-1411-11e9-90b5-12841864fc48,ResourceVersion:16281,Generation:0,CreationTimestamp:2019-01-09 13:19:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Jan  9 13:20:00.757: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-sr4lp,SelfLink:/api/v1/namespaces/e2e-tests-watch-sr4lp/configmaps/e2e-watch-test-configmap-a,UID:3e869d25-1411-11e9-90b5-12841864fc48,ResourceVersion:16294,Generation:0,CreationTimestamp:2019-01-09 13:19:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Jan  9 13:20:00.757: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-sr4lp,SelfLink:/api/v1/namespaces/e2e-tests-watch-sr4lp/configmaps/e2e-watch-test-configmap-a,UID:3e869d25-1411-11e9-90b5-12841864fc48,ResourceVersion:16294,Generation:0,CreationTimestamp:2019-01-09 13:19:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Jan  9 13:20:10.761: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-sr4lp,SelfLink:/api/v1/namespaces/e2e-tests-watch-sr4lp/configmaps/e2e-watch-test-configmap-a,UID:3e869d25-1411-11e9-90b5-12841864fc48,ResourceVersion:16307,Generation:0,CreationTimestamp:2019-01-09 13:19:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan  9 13:20:10.761: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-sr4lp,SelfLink:/api/v1/namespaces/e2e-tests-watch-sr4lp/configmaps/e2e-watch-test-configmap-a,UID:3e869d25-1411-11e9-90b5-12841864fc48,ResourceVersion:16307,Generation:0,CreationTimestamp:2019-01-09 13:19:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Jan  9 13:20:20.764: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-sr4lp,SelfLink:/api/v1/namespaces/e2e-tests-watch-sr4lp/configmaps/e2e-watch-test-configmap-a,UID:3e869d25-1411-11e9-90b5-12841864fc48,ResourceVersion:16320,Generation:0,CreationTimestamp:2019-01-09 13:19:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan  9 13:20:20.764: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-sr4lp,SelfLink:/api/v1/namespaces/e2e-tests-watch-sr4lp/configmaps/e2e-watch-test-configmap-a,UID:3e869d25-1411-11e9-90b5-12841864fc48,ResourceVersion:16320,Generation:0,CreationTimestamp:2019-01-09 13:19:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Jan  9 13:20:30.768: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-sr4lp,SelfLink:/api/v1/namespaces/e2e-tests-watch-sr4lp/configmaps/e2e-watch-test-configmap-b,UID:56602c31-1411-11e9-90b5-12841864fc48,ResourceVersion:16333,Generation:0,CreationTimestamp:2019-01-09 13:20:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan  9 13:20:30.768: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-sr4lp,SelfLink:/api/v1/namespaces/e2e-tests-watch-sr4lp/configmaps/e2e-watch-test-configmap-b,UID:56602c31-1411-11e9-90b5-12841864fc48,ResourceVersion:16333,Generation:0,CreationTimestamp:2019-01-09 13:20:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Jan  9 13:20:40.771: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-sr4lp,SelfLink:/api/v1/namespaces/e2e-tests-watch-sr4lp/configmaps/e2e-watch-test-configmap-b,UID:56602c31-1411-11e9-90b5-12841864fc48,ResourceVersion:16346,Generation:0,CreationTimestamp:2019-01-09 13:20:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan  9 13:20:40.771: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-sr4lp,SelfLink:/api/v1/namespaces/e2e-tests-watch-sr4lp/configmaps/e2e-watch-test-configmap-b,UID:56602c31-1411-11e9-90b5-12841864fc48,ResourceVersion:16346,Generation:0,CreationTimestamp:2019-01-09 13:20:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:20:50.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-sr4lp" for this suite.
Jan  9 13:20:56.778: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:20:56.789: INFO: namespace: e2e-tests-watch-sr4lp, resource: bindings, ignored listing per whitelist
Jan  9 13:20:56.815: INFO: namespace e2e-tests-watch-sr4lp deletion completed in 6.041939081s

• [SLOW TEST:66.103 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:20:56.815: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Jan  9 13:20:56.853: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-4t74d,SelfLink:/api/v1/namespaces/e2e-tests-watch-4t74d/configmaps/e2e-watch-test-label-changed,UID:65ec0fd7-1411-11e9-90b5-12841864fc48,ResourceVersion:16378,Generation:0,CreationTimestamp:2019-01-09 13:20:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan  9 13:20:56.853: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-4t74d,SelfLink:/api/v1/namespaces/e2e-tests-watch-4t74d/configmaps/e2e-watch-test-label-changed,UID:65ec0fd7-1411-11e9-90b5-12841864fc48,ResourceVersion:16379,Generation:0,CreationTimestamp:2019-01-09 13:20:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Jan  9 13:20:56.853: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-4t74d,SelfLink:/api/v1/namespaces/e2e-tests-watch-4t74d/configmaps/e2e-watch-test-label-changed,UID:65ec0fd7-1411-11e9-90b5-12841864fc48,ResourceVersion:16380,Generation:0,CreationTimestamp:2019-01-09 13:20:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Jan  9 13:21:06.864: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-4t74d,SelfLink:/api/v1/namespaces/e2e-tests-watch-4t74d/configmaps/e2e-watch-test-label-changed,UID:65ec0fd7-1411-11e9-90b5-12841864fc48,ResourceVersion:16394,Generation:0,CreationTimestamp:2019-01-09 13:20:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan  9 13:21:06.864: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-4t74d,SelfLink:/api/v1/namespaces/e2e-tests-watch-4t74d/configmaps/e2e-watch-test-label-changed,UID:65ec0fd7-1411-11e9-90b5-12841864fc48,ResourceVersion:16395,Generation:0,CreationTimestamp:2019-01-09 13:20:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Jan  9 13:21:06.864: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-4t74d,SelfLink:/api/v1/namespaces/e2e-tests-watch-4t74d/configmaps/e2e-watch-test-label-changed,UID:65ec0fd7-1411-11e9-90b5-12841864fc48,ResourceVersion:16396,Generation:0,CreationTimestamp:2019-01-09 13:20:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:21:06.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-4t74d" for this suite.
Jan  9 13:21:12.870: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:21:12.897: INFO: namespace: e2e-tests-watch-4t74d, resource: bindings, ignored listing per whitelist
Jan  9 13:21:12.909: INFO: namespace e2e-tests-watch-4t74d deletion completed in 6.042965783s

• [SLOW TEST:16.094 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:21:12.909: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Jan  9 13:21:12.941: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 create -f - --namespace=e2e-tests-kubectl-7rglg'
Jan  9 13:21:13.223: INFO: stderr: ""
Jan  9 13:21:13.223: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan  9 13:21:13.224: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-7rglg'
Jan  9 13:21:13.288: INFO: stderr: ""
Jan  9 13:21:13.288: INFO: stdout: "update-demo-nautilus-kc7qg update-demo-nautilus-sr5z5 "
Jan  9 13:21:13.288: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 get pods update-demo-nautilus-kc7qg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7rglg'
Jan  9 13:21:13.348: INFO: stderr: ""
Jan  9 13:21:13.348: INFO: stdout: ""
Jan  9 13:21:13.348: INFO: update-demo-nautilus-kc7qg is created but not running
Jan  9 13:21:18.348: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-7rglg'
Jan  9 13:21:18.411: INFO: stderr: ""
Jan  9 13:21:18.411: INFO: stdout: "update-demo-nautilus-kc7qg update-demo-nautilus-sr5z5 "
Jan  9 13:21:18.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 get pods update-demo-nautilus-kc7qg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7rglg'
Jan  9 13:21:18.471: INFO: stderr: ""
Jan  9 13:21:18.471: INFO: stdout: "true"
Jan  9 13:21:18.471: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 get pods update-demo-nautilus-kc7qg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7rglg'
Jan  9 13:21:18.531: INFO: stderr: ""
Jan  9 13:21:18.531: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan  9 13:21:18.531: INFO: validating pod update-demo-nautilus-kc7qg
Jan  9 13:21:18.533: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan  9 13:21:18.533: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan  9 13:21:18.533: INFO: update-demo-nautilus-kc7qg is verified up and running
Jan  9 13:21:18.533: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 get pods update-demo-nautilus-sr5z5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7rglg'
Jan  9 13:21:18.594: INFO: stderr: ""
Jan  9 13:21:18.594: INFO: stdout: "true"
Jan  9 13:21:18.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 get pods update-demo-nautilus-sr5z5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7rglg'
Jan  9 13:21:18.652: INFO: stderr: ""
Jan  9 13:21:18.652: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan  9 13:21:18.652: INFO: validating pod update-demo-nautilus-sr5z5
Jan  9 13:21:18.654: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan  9 13:21:18.654: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan  9 13:21:18.654: INFO: update-demo-nautilus-sr5z5 is verified up and running
STEP: using delete to clean up resources
Jan  9 13:21:18.654: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-7rglg'
Jan  9 13:21:18.715: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan  9 13:21:18.715: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jan  9 13:21:18.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-7rglg'
Jan  9 13:21:18.785: INFO: stderr: "No resources found.\n"
Jan  9 13:21:18.785: INFO: stdout: ""
Jan  9 13:21:18.785: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 get pods -l name=update-demo --namespace=e2e-tests-kubectl-7rglg -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan  9 13:21:18.856: INFO: stderr: ""
Jan  9 13:21:18.856: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:21:18.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-7rglg" for this suite.
Jan  9 13:21:40.864: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:21:40.883: INFO: namespace: e2e-tests-kubectl-7rglg, resource: bindings, ignored listing per whitelist
Jan  9 13:21:40.906: INFO: namespace e2e-tests-kubectl-7rglg deletion completed in 22.04855572s

• [SLOW TEST:27.998 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:21:40.907: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-8033dd44-1411-11e9-a571-02181533b527
STEP: Creating a pod to test consume secrets
Jan  9 13:21:40.943: INFO: Waiting up to 5m0s for pod "pod-secrets-80341f8c-1411-11e9-a571-02181533b527" in namespace "e2e-tests-secrets-jngsk" to be "success or failure"
Jan  9 13:21:40.944: INFO: Pod "pod-secrets-80341f8c-1411-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.013662ms
Jan  9 13:21:42.946: INFO: Pod "pod-secrets-80341f8c-1411-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.002800661s
STEP: Saw pod success
Jan  9 13:21:42.946: INFO: Pod "pod-secrets-80341f8c-1411-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 13:21:42.947: INFO: Trying to get logs from node ip-172-31-59-90 pod pod-secrets-80341f8c-1411-11e9-a571-02181533b527 container secret-env-test: <nil>
STEP: delete the pod
Jan  9 13:21:42.954: INFO: Waiting for pod pod-secrets-80341f8c-1411-11e9-a571-02181533b527 to disappear
Jan  9 13:21:42.956: INFO: Pod pod-secrets-80341f8c-1411-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:21:42.956: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-jngsk" for this suite.
Jan  9 13:21:48.962: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:21:48.998: INFO: namespace: e2e-tests-secrets-jngsk, resource: bindings, ignored listing per whitelist
Jan  9 13:21:49.003: INFO: namespace e2e-tests-secrets-jngsk deletion completed in 6.045779211s

• [SLOW TEST:8.097 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:21:49.003: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-997z
STEP: Creating a pod to test atomic-volume-subpath
Jan  9 13:21:49.041: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-997z" in namespace "e2e-tests-subpath-92pxr" to be "success or failure"
Jan  9 13:21:49.042: INFO: Pod "pod-subpath-test-secret-997z": Phase="Pending", Reason="", readiness=false. Elapsed: 1.526537ms
Jan  9 13:21:51.044: INFO: Pod "pod-subpath-test-secret-997z": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003482844s
Jan  9 13:21:53.047: INFO: Pod "pod-subpath-test-secret-997z": Phase="Running", Reason="", readiness=false. Elapsed: 4.00691841s
Jan  9 13:21:55.049: INFO: Pod "pod-subpath-test-secret-997z": Phase="Running", Reason="", readiness=false. Elapsed: 6.008847303s
Jan  9 13:21:57.051: INFO: Pod "pod-subpath-test-secret-997z": Phase="Running", Reason="", readiness=false. Elapsed: 8.010684405s
Jan  9 13:21:59.053: INFO: Pod "pod-subpath-test-secret-997z": Phase="Running", Reason="", readiness=false. Elapsed: 10.012300918s
Jan  9 13:22:01.055: INFO: Pod "pod-subpath-test-secret-997z": Phase="Running", Reason="", readiness=false. Elapsed: 12.014213405s
Jan  9 13:22:03.057: INFO: Pod "pod-subpath-test-secret-997z": Phase="Running", Reason="", readiness=false. Elapsed: 14.016064059s
Jan  9 13:22:05.059: INFO: Pod "pod-subpath-test-secret-997z": Phase="Running", Reason="", readiness=false. Elapsed: 16.018267177s
Jan  9 13:22:07.064: INFO: Pod "pod-subpath-test-secret-997z": Phase="Running", Reason="", readiness=false. Elapsed: 18.02331884s
Jan  9 13:22:09.066: INFO: Pod "pod-subpath-test-secret-997z": Phase="Running", Reason="", readiness=false. Elapsed: 20.025281479s
Jan  9 13:22:11.068: INFO: Pod "pod-subpath-test-secret-997z": Phase="Running", Reason="", readiness=false. Elapsed: 22.027219079s
Jan  9 13:22:13.070: INFO: Pod "pod-subpath-test-secret-997z": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.029079019s
STEP: Saw pod success
Jan  9 13:22:13.070: INFO: Pod "pod-subpath-test-secret-997z" satisfied condition "success or failure"
Jan  9 13:22:13.071: INFO: Trying to get logs from node ip-172-31-59-90 pod pod-subpath-test-secret-997z container test-container-subpath-secret-997z: <nil>
STEP: delete the pod
Jan  9 13:22:13.078: INFO: Waiting for pod pod-subpath-test-secret-997z to disappear
Jan  9 13:22:13.080: INFO: Pod pod-subpath-test-secret-997z no longer exists
STEP: Deleting pod pod-subpath-test-secret-997z
Jan  9 13:22:13.080: INFO: Deleting pod "pod-subpath-test-secret-997z" in namespace "e2e-tests-subpath-92pxr"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:22:13.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-92pxr" for this suite.
Jan  9 13:22:19.087: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:22:19.098: INFO: namespace: e2e-tests-subpath-92pxr, resource: bindings, ignored listing per whitelist
Jan  9 13:22:19.126: INFO: namespace e2e-tests-subpath-92pxr deletion completed in 6.043672918s

• [SLOW TEST:30.123 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:22:19.126: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Jan  9 13:22:19.158: INFO: Waiting up to 5m0s for pod "pod-96fb5a92-1411-11e9-a571-02181533b527" in namespace "e2e-tests-emptydir-s8zb6" to be "success or failure"
Jan  9 13:22:19.160: INFO: Pod "pod-96fb5a92-1411-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.022958ms
Jan  9 13:22:21.161: INFO: Pod "pod-96fb5a92-1411-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 2.002925166s
Jan  9 13:22:23.163: INFO: Pod "pod-96fb5a92-1411-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00479623s
STEP: Saw pod success
Jan  9 13:22:23.163: INFO: Pod "pod-96fb5a92-1411-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 13:22:23.164: INFO: Trying to get logs from node ip-172-31-59-90 pod pod-96fb5a92-1411-11e9-a571-02181533b527 container test-container: <nil>
STEP: delete the pod
Jan  9 13:22:23.173: INFO: Waiting for pod pod-96fb5a92-1411-11e9-a571-02181533b527 to disappear
Jan  9 13:22:23.174: INFO: Pod pod-96fb5a92-1411-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:22:23.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-s8zb6" for this suite.
Jan  9 13:22:29.181: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:22:29.195: INFO: namespace: e2e-tests-emptydir-s8zb6, resource: bindings, ignored listing per whitelist
Jan  9 13:22:29.219: INFO: namespace e2e-tests-emptydir-s8zb6 deletion completed in 6.043243563s

• [SLOW TEST:10.093 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:22:29.219: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:22:29.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-ln9nw" for this suite.
Jan  9 13:22:35.273: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:22:35.284: INFO: namespace: e2e-tests-kubelet-test-ln9nw, resource: bindings, ignored listing per whitelist
Jan  9 13:22:35.310: INFO: namespace e2e-tests-kubelet-test-ln9nw deletion completed in 6.043419293s

• [SLOW TEST:6.091 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:22:35.310: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan  9 13:22:59.348: INFO: Container started at 2019-01-09 13:22:36 +0000 UTC, pod became ready at 2019-01-09 13:22:58 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:22:59.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-2rtk8" for this suite.
Jan  9 13:23:21.354: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:23:21.363: INFO: namespace: e2e-tests-container-probe-2rtk8, resource: bindings, ignored listing per whitelist
Jan  9 13:23:21.389: INFO: namespace e2e-tests-container-probe-2rtk8 deletion completed in 22.039939465s

• [SLOW TEST:46.079 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:23:21.389: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jan  9 13:23:21.422: INFO: Waiting up to 5m0s for pod "pod-bc181109-1411-11e9-a571-02181533b527" in namespace "e2e-tests-emptydir-rtf2s" to be "success or failure"
Jan  9 13:23:21.424: INFO: Pod "pod-bc181109-1411-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.784507ms
Jan  9 13:23:23.426: INFO: Pod "pod-bc181109-1411-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003532157s
Jan  9 13:23:25.428: INFO: Pod "pod-bc181109-1411-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00534184s
STEP: Saw pod success
Jan  9 13:23:25.428: INFO: Pod "pod-bc181109-1411-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 13:23:25.429: INFO: Trying to get logs from node ip-172-31-59-90 pod pod-bc181109-1411-11e9-a571-02181533b527 container test-container: <nil>
STEP: delete the pod
Jan  9 13:23:25.437: INFO: Waiting for pod pod-bc181109-1411-11e9-a571-02181533b527 to disappear
Jan  9 13:23:25.438: INFO: Pod pod-bc181109-1411-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:23:25.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-rtf2s" for this suite.
Jan  9 13:23:31.443: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:23:31.460: INFO: namespace: e2e-tests-emptydir-rtf2s, resource: bindings, ignored listing per whitelist
Jan  9 13:23:31.478: INFO: namespace e2e-tests-emptydir-rtf2s deletion completed in 6.039283188s

• [SLOW TEST:10.089 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:23:31.478: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-c21bc67e-1411-11e9-a571-02181533b527
STEP: Creating configMap with name cm-test-opt-upd-c21bc6b9-1411-11e9-a571-02181533b527
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-c21bc67e-1411-11e9-a571-02181533b527
STEP: Updating configmap cm-test-opt-upd-c21bc6b9-1411-11e9-a571-02181533b527
STEP: Creating configMap with name cm-test-opt-create-c21bc6d3-1411-11e9-a571-02181533b527
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:24:53.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-pgbpz" for this suite.
Jan  9 13:25:15.757: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:25:15.790: INFO: namespace: e2e-tests-configmap-pgbpz, resource: bindings, ignored listing per whitelist
Jan  9 13:25:15.794: INFO: namespace e2e-tests-configmap-pgbpz deletion completed in 22.042046831s

• [SLOW TEST:104.315 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:25:15.794: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Jan  9 13:25:15.826: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 api-versions'
Jan  9 13:25:15.888: INFO: stderr: ""
Jan  9 13:25:15.888: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:25:15.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-45mwx" for this suite.
Jan  9 13:25:21.894: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:25:21.922: INFO: namespace: e2e-tests-kubectl-45mwx, resource: bindings, ignored listing per whitelist
Jan  9 13:25:21.932: INFO: namespace e2e-tests-kubectl-45mwx deletion completed in 6.042474838s

• [SLOW TEST:6.138 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:25:21.933: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jan  9 13:25:21.963: INFO: PodSpec: initContainers in spec.initContainers
Jan  9 13:26:05.439: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-03f1760c-1412-11e9-a571-02181533b527", GenerateName:"", Namespace:"e2e-tests-init-container-pwsk6", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-pwsk6/pods/pod-init-03f1760c-1412-11e9-a571-02181533b527", UID:"03f1ad2c-1412-11e9-90b5-12841864fc48", ResourceVersion:"17054", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63682637121, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"963373543"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-dfwsj", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0019e20c0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-dfwsj", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-dfwsj", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}, "cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-dfwsj", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0019de248), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-172-31-59-90", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00151a1e0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0019de2d0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0019de2f0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0019de2f8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0019de2fc)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682637121, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682637121, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682637121, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682637121, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.31.59.90", PodIP:"10.1.1.71", StartTime:(*v1.Time)(0xc000c08080), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0018881c0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001888310)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://b4ee64f29a7f9352c715ea5d4a97af6794e791a04e71556c117b052f84806851"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc000c08100), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc000c080c0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:26:05.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-pwsk6" for this suite.
Jan  9 13:26:17.446: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:26:17.454: INFO: namespace: e2e-tests-init-container-pwsk6, resource: bindings, ignored listing per whitelist
Jan  9 13:26:17.481: INFO: namespace e2e-tests-init-container-pwsk6 deletion completed in 12.039534858s

• [SLOW TEST:55.549 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:26:17.481: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-250e05e9-1412-11e9-a571-02181533b527
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:26:21.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-zdpjv" for this suite.
Jan  9 13:26:43.537: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:26:43.558: INFO: namespace: e2e-tests-configmap-zdpjv, resource: bindings, ignored listing per whitelist
Jan  9 13:26:43.584: INFO: namespace e2e-tests-configmap-zdpjv deletion completed in 22.052258988s

• [SLOW TEST:26.103 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:26:43.584: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-xs6t5/configmap-test-349ca80e-1412-11e9-a571-02181533b527
STEP: Creating a pod to test consume configMaps
Jan  9 13:26:43.620: INFO: Waiting up to 5m0s for pod "pod-configmaps-349d0581-1412-11e9-a571-02181533b527" in namespace "e2e-tests-configmap-xs6t5" to be "success or failure"
Jan  9 13:26:43.621: INFO: Pod "pod-configmaps-349d0581-1412-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.018784ms
Jan  9 13:26:45.623: INFO: Pod "pod-configmaps-349d0581-1412-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 2.002807604s
Jan  9 13:26:47.625: INFO: Pod "pod-configmaps-349d0581-1412-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.004607507s
STEP: Saw pod success
Jan  9 13:26:47.625: INFO: Pod "pod-configmaps-349d0581-1412-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 13:26:47.626: INFO: Trying to get logs from node ip-172-31-59-90 pod pod-configmaps-349d0581-1412-11e9-a571-02181533b527 container env-test: <nil>
STEP: delete the pod
Jan  9 13:26:47.633: INFO: Waiting for pod pod-configmaps-349d0581-1412-11e9-a571-02181533b527 to disappear
Jan  9 13:26:47.634: INFO: Pod pod-configmaps-349d0581-1412-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:26:47.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-xs6t5" for this suite.
Jan  9 13:26:53.640: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:26:53.670: INFO: namespace: e2e-tests-configmap-xs6t5, resource: bindings, ignored listing per whitelist
Jan  9 13:26:53.678: INFO: namespace e2e-tests-configmap-xs6t5 deletion completed in 6.041872458s

• [SLOW TEST:10.093 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:26:53.678: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan  9 13:26:53.712: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3aa0cc32-1412-11e9-a571-02181533b527" in namespace "e2e-tests-downward-api-95n9v" to be "success or failure"
Jan  9 13:26:53.713: INFO: Pod "downwardapi-volume-3aa0cc32-1412-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.02795ms
Jan  9 13:26:55.714: INFO: Pod "downwardapi-volume-3aa0cc32-1412-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 2.002789994s
Jan  9 13:26:57.716: INFO: Pod "downwardapi-volume-3aa0cc32-1412-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.004673833s
STEP: Saw pod success
Jan  9 13:26:57.716: INFO: Pod "downwardapi-volume-3aa0cc32-1412-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 13:26:57.717: INFO: Trying to get logs from node ip-172-31-59-90 pod downwardapi-volume-3aa0cc32-1412-11e9-a571-02181533b527 container client-container: <nil>
STEP: delete the pod
Jan  9 13:26:57.725: INFO: Waiting for pod downwardapi-volume-3aa0cc32-1412-11e9-a571-02181533b527 to disappear
Jan  9 13:26:57.726: INFO: Pod downwardapi-volume-3aa0cc32-1412-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:26:57.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-95n9v" for this suite.
Jan  9 13:27:03.731: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:27:03.741: INFO: namespace: e2e-tests-downward-api-95n9v, resource: bindings, ignored listing per whitelist
Jan  9 13:27:03.766: INFO: namespace e2e-tests-downward-api-95n9v deletion completed in 6.038966061s

• [SLOW TEST:10.088 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:27:03.766: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Jan  9 13:27:03.799: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Jan  9 13:27:03.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 create -f - --namespace=e2e-tests-kubectl-rzqgx'
Jan  9 13:27:03.935: INFO: stderr: ""
Jan  9 13:27:03.935: INFO: stdout: "service/redis-slave created\n"
Jan  9 13:27:03.935: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Jan  9 13:27:03.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 create -f - --namespace=e2e-tests-kubectl-rzqgx'
Jan  9 13:27:04.073: INFO: stderr: ""
Jan  9 13:27:04.073: INFO: stdout: "service/redis-master created\n"
Jan  9 13:27:04.073: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Jan  9 13:27:04.073: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 create -f - --namespace=e2e-tests-kubectl-rzqgx'
Jan  9 13:27:04.216: INFO: stderr: ""
Jan  9 13:27:04.216: INFO: stdout: "service/frontend created\n"
Jan  9 13:27:04.216: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Jan  9 13:27:04.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 create -f - --namespace=e2e-tests-kubectl-rzqgx'
Jan  9 13:27:04.353: INFO: stderr: ""
Jan  9 13:27:04.353: INFO: stdout: "deployment.extensions/frontend created\n"
Jan  9 13:27:04.354: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Jan  9 13:27:04.354: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 create -f - --namespace=e2e-tests-kubectl-rzqgx'
Jan  9 13:27:04.489: INFO: stderr: ""
Jan  9 13:27:04.489: INFO: stdout: "deployment.extensions/redis-master created\n"
Jan  9 13:27:04.489: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Jan  9 13:27:04.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 create -f - --namespace=e2e-tests-kubectl-rzqgx'
Jan  9 13:27:04.624: INFO: stderr: ""
Jan  9 13:27:04.624: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Jan  9 13:27:04.624: INFO: Waiting for all frontend pods to be Running.
Jan  9 13:27:24.675: INFO: Waiting for frontend to serve content.
Jan  9 13:27:24.683: INFO: Trying to add a new entry to the guestbook.
Jan  9 13:27:24.690: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Jan  9 13:27:24.698: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-rzqgx'
Jan  9 13:27:24.763: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan  9 13:27:24.763: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Jan  9 13:27:24.763: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-rzqgx'
Jan  9 13:27:24.826: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan  9 13:27:24.826: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Jan  9 13:27:24.826: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-rzqgx'
Jan  9 13:27:24.888: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan  9 13:27:24.888: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Jan  9 13:27:24.888: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-rzqgx'
Jan  9 13:27:24.952: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan  9 13:27:24.952: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Jan  9 13:27:24.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-rzqgx'
Jan  9 13:27:25.020: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan  9 13:27:25.020: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Jan  9 13:27:25.021: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-580595478 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-rzqgx'
Jan  9 13:27:25.101: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan  9 13:27:25.101: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:27:25.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-rzqgx" for this suite.
Jan  9 13:28:03.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:28:03.130: INFO: namespace: e2e-tests-kubectl-rzqgx, resource: bindings, ignored listing per whitelist
Jan  9 13:28:03.153: INFO: namespace e2e-tests-kubectl-rzqgx deletion completed in 38.051013857s

• [SLOW TEST:59.387 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:28:03.153: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan  9 13:28:03.186: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:28:04.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-tsrlp" for this suite.
Jan  9 13:28:10.210: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:28:10.240: INFO: namespace: e2e-tests-custom-resource-definition-tsrlp, resource: bindings, ignored listing per whitelist
Jan  9 13:28:10.250: INFO: namespace e2e-tests-custom-resource-definition-tsrlp deletion completed in 6.045145805s

• [SLOW TEST:7.097 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:28:10.250: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jan  9 13:28:14.795: INFO: Successfully updated pod "pod-update-activedeadlineseconds-6844ff93-1412-11e9-a571-02181533b527"
Jan  9 13:28:14.795: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-6844ff93-1412-11e9-a571-02181533b527" in namespace "e2e-tests-pods-kstfs" to be "terminated due to deadline exceeded"
Jan  9 13:28:14.797: INFO: Pod "pod-update-activedeadlineseconds-6844ff93-1412-11e9-a571-02181533b527": Phase="Running", Reason="", readiness=true. Elapsed: 2.004218ms
Jan  9 13:28:16.799: INFO: Pod "pod-update-activedeadlineseconds-6844ff93-1412-11e9-a571-02181533b527": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.003944621s
Jan  9 13:28:16.799: INFO: Pod "pod-update-activedeadlineseconds-6844ff93-1412-11e9-a571-02181533b527" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:28:16.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-kstfs" for this suite.
Jan  9 13:28:22.805: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:28:22.830: INFO: namespace: e2e-tests-pods-kstfs, resource: bindings, ignored listing per whitelist
Jan  9 13:28:22.840: INFO: namespace e2e-tests-pods-kstfs deletion completed in 6.039359504s

• [SLOW TEST:12.589 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan  9 13:28:22.840: INFO: >>> kubeConfig: /tmp/kubeconfig-580595478
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan  9 13:28:22.875: INFO: Waiting up to 5m0s for pod "downward-api-6fc607e2-1412-11e9-a571-02181533b527" in namespace "e2e-tests-downward-api-fhsjq" to be "success or failure"
Jan  9 13:28:22.876: INFO: Pod "downward-api-6fc607e2-1412-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 1.027099ms
Jan  9 13:28:24.878: INFO: Pod "downward-api-6fc607e2-1412-11e9-a571-02181533b527": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003075981s
Jan  9 13:28:26.880: INFO: Pod "downward-api-6fc607e2-1412-11e9-a571-02181533b527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.004928217s
STEP: Saw pod success
Jan  9 13:28:26.880: INFO: Pod "downward-api-6fc607e2-1412-11e9-a571-02181533b527" satisfied condition "success or failure"
Jan  9 13:28:26.881: INFO: Trying to get logs from node ip-172-31-59-90 pod downward-api-6fc607e2-1412-11e9-a571-02181533b527 container dapi-container: <nil>
STEP: delete the pod
Jan  9 13:28:26.890: INFO: Waiting for pod downward-api-6fc607e2-1412-11e9-a571-02181533b527 to disappear
Jan  9 13:28:26.891: INFO: Pod downward-api-6fc607e2-1412-11e9-a571-02181533b527 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan  9 13:28:26.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-fhsjq" for this suite.
Jan  9 13:28:32.896: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 13:28:32.914: INFO: namespace: e2e-tests-downward-api-fhsjq, resource: bindings, ignored listing per whitelist
Jan  9 13:28:32.934: INFO: namespace e2e-tests-downward-api-fhsjq deletion completed in 6.041515927s

• [SLOW TEST:10.094 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSJan  9 13:28:32.934: INFO: Running AfterSuite actions on all nodes
Jan  9 13:28:32.934: INFO: Running AfterSuite actions on node 1
Jan  9 13:28:32.934: INFO: Skipping dumping logs from cluster

Ran 200 of 1946 Specs in 5396.874 seconds
SUCCESS! -- 200 Passed | 0 Failed | 0 Pending | 1746 Skipped PASS

Ginkgo ran 1 suite in 1h29m57.516276541s
Test Suite Passed
