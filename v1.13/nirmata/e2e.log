I0207 18:12:04.443706      15 test_context.go:358] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-206495916
I0207 18:12:04.443996      15 e2e.go:224] Starting e2e run "de71a073-2b03-11e9-90f5-5e78944a5b53" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1549563122 - Will randomize all specs
Will run 201 of 1946 specs

Feb  7 18:12:04.817: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
Feb  7 18:12:04.824: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Feb  7 18:12:04.843: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Feb  7 18:12:05.030: INFO: 3 / 3 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Feb  7 18:12:05.030: INFO: expected 2 pod replicas in namespace 'kube-system', 2 are Running and Ready.
Feb  7 18:12:05.031: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Feb  7 18:12:05.055: INFO: 1 / 1 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds' (0 seconds elapsed)
Feb  7 18:12:05.055: INFO: e2e test version: v1.13.0
Feb  7 18:12:05.067: INFO: kube-apiserver version: v1.13.3
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:12:05.067: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename downward-api
Feb  7 18:12:06.255: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  7 18:12:06.280: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e07b57ac-2b03-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-downward-api-jzx2r" to be "success or failure"
Feb  7 18:12:06.465: INFO: Pod "downwardapi-volume-e07b57ac-2b03-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 184.336511ms
Feb  7 18:12:08.470: INFO: Pod "downwardapi-volume-e07b57ac-2b03-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 2.189291817s
Feb  7 18:12:10.475: INFO: Pod "downwardapi-volume-e07b57ac-2b03-11e9-90f5-5e78944a5b53": Phase="Running", Reason="", readiness=true. Elapsed: 4.194733973s
Feb  7 18:12:12.480: INFO: Pod "downwardapi-volume-e07b57ac-2b03-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.199608516s
STEP: Saw pod success
Feb  7 18:12:12.480: INFO: Pod "downwardapi-volume-e07b57ac-2b03-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 18:12:12.485: INFO: Trying to get logs from node conformance0 pod downwardapi-volume-e07b57ac-2b03-11e9-90f5-5e78944a5b53 container client-container: <nil>
STEP: delete the pod
Feb  7 18:12:12.552: INFO: Waiting for pod downwardapi-volume-e07b57ac-2b03-11e9-90f5-5e78944a5b53 to disappear
Feb  7 18:12:12.558: INFO: Pod downwardapi-volume-e07b57ac-2b03-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:12:12.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-jzx2r" for this suite.
Feb  7 18:12:18.583: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:12:18.641: INFO: namespace: e2e-tests-downward-api-jzx2r, resource: bindings, ignored listing per whitelist
Feb  7 18:12:18.763: INFO: namespace e2e-tests-downward-api-jzx2r deletion completed in 6.200113514s

• [SLOW TEST:13.696 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:12:18.764: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:12:22.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-bsq25" for this suite.
Feb  7 18:13:17.141: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:13:17.245: INFO: namespace: e2e-tests-kubelet-test-bsq25, resource: bindings, ignored listing per whitelist
Feb  7 18:13:17.303: INFO: namespace e2e-tests-kubelet-test-bsq25 deletion completed in 54.357556809s

• [SLOW TEST:58.540 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:13:17.304: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0207 18:13:27.566432      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb  7 18:13:27.566: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:13:27.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-8ns52" for this suite.
Feb  7 18:13:35.589: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:13:35.625: INFO: namespace: e2e-tests-gc-8ns52, resource: bindings, ignored listing per whitelist
Feb  7 18:13:35.765: INFO: namespace e2e-tests-gc-8ns52 deletion completed in 8.193224723s

• [SLOW TEST:18.461 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:13:35.765: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-15ebd471-2b04-11e9-90f5-5e78944a5b53
STEP: Creating a pod to test consume configMaps
Feb  7 18:13:35.934: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-15ecd61d-2b04-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-projected-v7sn2" to be "success or failure"
Feb  7 18:13:35.940: INFO: Pod "pod-projected-configmaps-15ecd61d-2b04-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 5.794756ms
Feb  7 18:13:37.944: INFO: Pod "pod-projected-configmaps-15ecd61d-2b04-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009795251s
STEP: Saw pod success
Feb  7 18:13:37.944: INFO: Pod "pod-projected-configmaps-15ecd61d-2b04-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 18:13:37.949: INFO: Trying to get logs from node conformance0 pod pod-projected-configmaps-15ecd61d-2b04-11e9-90f5-5e78944a5b53 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  7 18:13:37.975: INFO: Waiting for pod pod-projected-configmaps-15ecd61d-2b04-11e9-90f5-5e78944a5b53 to disappear
Feb  7 18:13:37.989: INFO: Pod pod-projected-configmaps-15ecd61d-2b04-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:13:37.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-v7sn2" for this suite.
Feb  7 18:13:44.011: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:13:44.129: INFO: namespace: e2e-tests-projected-v7sn2, resource: bindings, ignored listing per whitelist
Feb  7 18:13:44.149: INFO: namespace e2e-tests-projected-v7sn2 deletion completed in 6.1531581s

• [SLOW TEST:8.383 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:13:44.149: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Feb  7 18:13:44.276: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 api-versions'
Feb  7 18:13:44.447: INFO: stderr: ""
Feb  7 18:13:44.447: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:13:44.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-sc92s" for this suite.
Feb  7 18:13:50.474: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:13:50.581: INFO: namespace: e2e-tests-kubectl-sc92s, resource: bindings, ignored listing per whitelist
Feb  7 18:13:50.624: INFO: namespace e2e-tests-kubectl-sc92s deletion completed in 6.168881061s

• [SLOW TEST:6.475 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:13:50.624: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:13:50.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-rrvhw" for this suite.
Feb  7 18:14:12.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:14:12.871: INFO: namespace: e2e-tests-pods-rrvhw, resource: bindings, ignored listing per whitelist
Feb  7 18:14:12.996: INFO: namespace e2e-tests-pods-rrvhw deletion completed in 22.184006065s

• [SLOW TEST:22.372 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:14:12.997: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb  7 18:14:17.708: INFO: Successfully updated pod "labelsupdate2c17299a-2b04-11e9-90f5-5e78944a5b53"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:14:19.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-s2sgg" for this suite.
Feb  7 18:14:41.763: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:14:41.821: INFO: namespace: e2e-tests-projected-s2sgg, resource: bindings, ignored listing per whitelist
Feb  7 18:14:41.903: INFO: namespace e2e-tests-projected-s2sgg deletion completed in 22.159893908s

• [SLOW TEST:28.906 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:14:41.904: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb  7 18:14:42.034: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:14:45.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-wlgwz" for this suite.
Feb  7 18:14:51.909: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:14:51.971: INFO: namespace: e2e-tests-init-container-wlgwz, resource: bindings, ignored listing per whitelist
Feb  7 18:14:52.071: INFO: namespace e2e-tests-init-container-wlgwz deletion completed in 6.18109993s

• [SLOW TEST:10.167 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:14:52.073: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb  7 18:14:52.224: INFO: Waiting up to 5m0s for pod "pod-4364f40e-2b04-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-emptydir-jrw4f" to be "success or failure"
Feb  7 18:14:52.247: INFO: Pod "pod-4364f40e-2b04-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 23.459386ms
Feb  7 18:14:54.252: INFO: Pod "pod-4364f40e-2b04-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028551218s
Feb  7 18:14:56.257: INFO: Pod "pod-4364f40e-2b04-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 4.033259723s
Feb  7 18:14:58.262: INFO: Pod "pod-4364f40e-2b04-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.038429995s
STEP: Saw pod success
Feb  7 18:14:58.263: INFO: Pod "pod-4364f40e-2b04-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 18:14:58.269: INFO: Trying to get logs from node conformance0 pod pod-4364f40e-2b04-11e9-90f5-5e78944a5b53 container test-container: <nil>
STEP: delete the pod
Feb  7 18:14:58.305: INFO: Waiting for pod pod-4364f40e-2b04-11e9-90f5-5e78944a5b53 to disappear
Feb  7 18:14:58.313: INFO: Pod pod-4364f40e-2b04-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:14:58.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-jrw4f" for this suite.
Feb  7 18:15:04.388: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:15:04.428: INFO: namespace: e2e-tests-emptydir-jrw4f, resource: bindings, ignored listing per whitelist
Feb  7 18:15:04.526: INFO: namespace e2e-tests-emptydir-jrw4f deletion completed in 6.200546615s

• [SLOW TEST:12.454 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:15:04.527: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-4acef566-2b04-11e9-90f5-5e78944a5b53
STEP: Creating a pod to test consume configMaps
Feb  7 18:15:04.663: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4ad024c4-2b04-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-projected-mwfvf" to be "success or failure"
Feb  7 18:15:04.670: INFO: Pod "pod-projected-configmaps-4ad024c4-2b04-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 7.034127ms
Feb  7 18:15:06.678: INFO: Pod "pod-projected-configmaps-4ad024c4-2b04-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014320634s
STEP: Saw pod success
Feb  7 18:15:06.678: INFO: Pod "pod-projected-configmaps-4ad024c4-2b04-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 18:15:06.693: INFO: Trying to get logs from node conformance0 pod pod-projected-configmaps-4ad024c4-2b04-11e9-90f5-5e78944a5b53 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  7 18:15:06.755: INFO: Waiting for pod pod-projected-configmaps-4ad024c4-2b04-11e9-90f5-5e78944a5b53 to disappear
Feb  7 18:15:06.761: INFO: Pod pod-projected-configmaps-4ad024c4-2b04-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:15:06.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mwfvf" for this suite.
Feb  7 18:15:12.788: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:15:12.843: INFO: namespace: e2e-tests-projected-mwfvf, resource: bindings, ignored listing per whitelist
Feb  7 18:15:12.958: INFO: namespace e2e-tests-projected-mwfvf deletion completed in 6.189342349s

• [SLOW TEST:8.431 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:15:12.959: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  7 18:15:13.083: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4fd46619-2b04-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-downward-api-mnhrl" to be "success or failure"
Feb  7 18:15:13.088: INFO: Pod "downwardapi-volume-4fd46619-2b04-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 4.676991ms
Feb  7 18:15:15.092: INFO: Pod "downwardapi-volume-4fd46619-2b04-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009223828s
STEP: Saw pod success
Feb  7 18:15:15.093: INFO: Pod "downwardapi-volume-4fd46619-2b04-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 18:15:15.101: INFO: Trying to get logs from node conformance0 pod downwardapi-volume-4fd46619-2b04-11e9-90f5-5e78944a5b53 container client-container: <nil>
STEP: delete the pod
Feb  7 18:15:15.142: INFO: Waiting for pod downwardapi-volume-4fd46619-2b04-11e9-90f5-5e78944a5b53 to disappear
Feb  7 18:15:15.163: INFO: Pod downwardapi-volume-4fd46619-2b04-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:15:15.163: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-mnhrl" for this suite.
Feb  7 18:15:21.194: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:15:21.346: INFO: namespace: e2e-tests-downward-api-mnhrl, resource: bindings, ignored listing per whitelist
Feb  7 18:15:21.352: INFO: namespace e2e-tests-downward-api-mnhrl deletion completed in 6.176731354s

• [SLOW TEST:8.393 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:15:21.352: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Feb  7 18:15:21.508: INFO: Waiting up to 5m0s for pod "client-containers-54d9a60f-2b04-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-containers-hmr5j" to be "success or failure"
Feb  7 18:15:21.521: INFO: Pod "client-containers-54d9a60f-2b04-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 13.130185ms
Feb  7 18:15:23.527: INFO: Pod "client-containers-54d9a60f-2b04-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018654101s
Feb  7 18:15:25.535: INFO: Pod "client-containers-54d9a60f-2b04-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026599502s
STEP: Saw pod success
Feb  7 18:15:25.535: INFO: Pod "client-containers-54d9a60f-2b04-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 18:15:25.544: INFO: Trying to get logs from node conformance0 pod client-containers-54d9a60f-2b04-11e9-90f5-5e78944a5b53 container test-container: <nil>
STEP: delete the pod
Feb  7 18:15:25.577: INFO: Waiting for pod client-containers-54d9a60f-2b04-11e9-90f5-5e78944a5b53 to disappear
Feb  7 18:15:25.582: INFO: Pod client-containers-54d9a60f-2b04-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:15:25.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-hmr5j" for this suite.
Feb  7 18:15:31.605: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:15:31.661: INFO: namespace: e2e-tests-containers-hmr5j, resource: bindings, ignored listing per whitelist
Feb  7 18:15:31.775: INFO: namespace e2e-tests-containers-hmr5j deletion completed in 6.187718638s

• [SLOW TEST:10.424 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:15:31.776: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0207 18:15:37.944949      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb  7 18:15:37.945: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:15:37.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-lb9m8" for this suite.
Feb  7 18:15:43.972: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:15:44.064: INFO: namespace: e2e-tests-gc-lb9m8, resource: bindings, ignored listing per whitelist
Feb  7 18:15:44.143: INFO: namespace e2e-tests-gc-lb9m8 deletion completed in 6.191642998s

• [SLOW TEST:12.367 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:15:44.144: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  7 18:15:44.284: INFO: Waiting up to 5m0s for pod "downwardapi-volume-626c4ed3-2b04-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-downward-api-96hfv" to be "success or failure"
Feb  7 18:15:44.308: INFO: Pod "downwardapi-volume-626c4ed3-2b04-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 23.728076ms
Feb  7 18:15:46.313: INFO: Pod "downwardapi-volume-626c4ed3-2b04-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029538242s
Feb  7 18:15:48.319: INFO: Pod "downwardapi-volume-626c4ed3-2b04-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034951412s
STEP: Saw pod success
Feb  7 18:15:48.319: INFO: Pod "downwardapi-volume-626c4ed3-2b04-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 18:15:48.324: INFO: Trying to get logs from node conformance0 pod downwardapi-volume-626c4ed3-2b04-11e9-90f5-5e78944a5b53 container client-container: <nil>
STEP: delete the pod
Feb  7 18:15:48.361: INFO: Waiting for pod downwardapi-volume-626c4ed3-2b04-11e9-90f5-5e78944a5b53 to disappear
Feb  7 18:15:48.369: INFO: Pod downwardapi-volume-626c4ed3-2b04-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:15:48.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-96hfv" for this suite.
Feb  7 18:15:54.395: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:15:54.493: INFO: namespace: e2e-tests-downward-api-96hfv, resource: bindings, ignored listing per whitelist
Feb  7 18:15:54.551: INFO: namespace e2e-tests-downward-api-96hfv deletion completed in 6.174759619s

• [SLOW TEST:10.407 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:15:54.551: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:15:54.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-hkdcs" for this suite.
Feb  7 18:16:00.742: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:16:00.904: INFO: namespace: e2e-tests-kubelet-test-hkdcs, resource: bindings, ignored listing per whitelist
Feb  7 18:16:00.930: INFO: namespace e2e-tests-kubelet-test-hkdcs deletion completed in 6.216845335s

• [SLOW TEST:6.379 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:16:00.930: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb  7 18:16:01.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-pdfs9'
Feb  7 18:16:01.517: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb  7 18:16:01.517: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1268
Feb  7 18:16:03.527: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-pdfs9'
Feb  7 18:16:03.718: INFO: stderr: ""
Feb  7 18:16:03.718: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:16:03.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-pdfs9" for this suite.
Feb  7 18:16:09.768: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:16:09.877: INFO: namespace: e2e-tests-kubectl-pdfs9, resource: bindings, ignored listing per whitelist
Feb  7 18:16:09.924: INFO: namespace e2e-tests-kubectl-pdfs9 deletion completed in 6.196577769s

• [SLOW TEST:8.994 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:16:09.925: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-xdh88
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb  7 18:16:10.044: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb  7 18:16:34.191: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.244.0.44 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-xdh88 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  7 18:16:34.191: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
Feb  7 18:16:35.300: INFO: Found all expected endpoints: [netserver-0]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:16:35.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-xdh88" for this suite.
Feb  7 18:16:59.327: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:16:59.407: INFO: namespace: e2e-tests-pod-network-test-xdh88, resource: bindings, ignored listing per whitelist
Feb  7 18:16:59.498: INFO: namespace e2e-tests-pod-network-test-xdh88 deletion completed in 24.190424426s

• [SLOW TEST:49.573 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:16:59.499: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-f8m92 in namespace e2e-tests-proxy-hsv4c
I0207 18:16:59.644079      15 runners.go:184] Created replication controller with name: proxy-service-f8m92, namespace: e2e-tests-proxy-hsv4c, replica count: 1
I0207 18:17:00.694627      15 runners.go:184] proxy-service-f8m92 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0207 18:17:01.694936      15 runners.go:184] proxy-service-f8m92 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0207 18:17:02.695342      15 runners.go:184] proxy-service-f8m92 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0207 18:17:03.695708      15 runners.go:184] proxy-service-f8m92 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0207 18:17:04.696049      15 runners.go:184] proxy-service-f8m92 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0207 18:17:05.696298      15 runners.go:184] proxy-service-f8m92 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb  7 18:17:05.700: INFO: setup took 6.091548117s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Feb  7 18:17:05.731: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/http:proxy-service-f8m92:portname1/proxy/: foo (200; 29.557879ms)
Feb  7 18:17:05.746: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/proxy-service-f8m92:portname1/proxy/: foo (200; 45.165437ms)
Feb  7 18:17:05.758: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm/proxy/rewriteme"... (200; 57.029835ms)
Feb  7 18:17:05.758: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:1080/proxy/rewri... (200; 56.897602ms)
Feb  7 18:17:05.770: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:1080/proxy/... (200; 69.308797ms)
Feb  7 18:17:05.770: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:160/proxy/: foo (200; 69.250563ms)
Feb  7 18:17:05.770: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:162/proxy/: bar (200; 68.67705ms)
Feb  7 18:17:05.770: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:162/proxy/: bar (200; 68.654774ms)
Feb  7 18:17:05.770: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/https:proxy-service-f8m92:tlsportname1/proxy/: tls baz (200; 69.298297ms)
Feb  7 18:17:05.770: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/proxy-service-f8m92:portname2/proxy/: bar (200; 69.163132ms)
Feb  7 18:17:05.770: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/http:proxy-service-f8m92:portname2/proxy/: bar (200; 69.144405ms)
Feb  7 18:17:05.770: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:160/proxy/: foo (200; 69.361294ms)
Feb  7 18:17:05.772: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:443/proxy/... (200; 72.10859ms)
Feb  7 18:17:05.772: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:460/proxy/: tls baz (200; 71.117058ms)
Feb  7 18:17:05.773: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:462/proxy/: tls qux (200; 71.980269ms)
Feb  7 18:17:05.774: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/https:proxy-service-f8m92:tlsportname2/proxy/: tls qux (200; 74.057592ms)
Feb  7 18:17:05.792: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:1080/proxy/rewri... (200; 17.604366ms)
Feb  7 18:17:05.793: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:162/proxy/: bar (200; 18.125574ms)
Feb  7 18:17:05.794: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:460/proxy/: tls baz (200; 19.367879ms)
Feb  7 18:17:05.804: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:162/proxy/: bar (200; 28.314061ms)
Feb  7 18:17:05.804: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:1080/proxy/... (200; 28.712905ms)
Feb  7 18:17:05.804: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/proxy-service-f8m92:portname2/proxy/: bar (200; 29.193917ms)
Feb  7 18:17:05.804: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:160/proxy/: foo (200; 29.064614ms)
Feb  7 18:17:05.805: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/http:proxy-service-f8m92:portname1/proxy/: foo (200; 29.794292ms)
Feb  7 18:17:05.806: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:462/proxy/: tls qux (200; 29.769822ms)
Feb  7 18:17:05.807: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:160/proxy/: foo (200; 30.897715ms)
Feb  7 18:17:05.812: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/proxy-service-f8m92:portname1/proxy/: foo (200; 36.576984ms)
Feb  7 18:17:05.819: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/https:proxy-service-f8m92:tlsportname1/proxy/: tls baz (200; 43.065259ms)
Feb  7 18:17:05.820: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:443/proxy/... (200; 43.411197ms)
Feb  7 18:17:05.820: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/https:proxy-service-f8m92:tlsportname2/proxy/: tls qux (200; 43.736195ms)
Feb  7 18:17:05.820: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm/proxy/rewriteme"... (200; 43.37234ms)
Feb  7 18:17:05.820: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/http:proxy-service-f8m92:portname2/proxy/: bar (200; 43.311912ms)
Feb  7 18:17:05.836: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:443/proxy/... (200; 14.91058ms)
Feb  7 18:17:05.840: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:160/proxy/: foo (200; 19.331711ms)
Feb  7 18:17:05.852: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:1080/proxy/... (200; 31.309665ms)
Feb  7 18:17:05.856: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:460/proxy/: tls baz (200; 33.834426ms)
Feb  7 18:17:05.857: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm/proxy/rewriteme"... (200; 36.504852ms)
Feb  7 18:17:05.858: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:462/proxy/: tls qux (200; 36.546161ms)
Feb  7 18:17:05.859: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:162/proxy/: bar (200; 38.021344ms)
Feb  7 18:17:05.865: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:1080/proxy/rewri... (200; 43.166445ms)
Feb  7 18:17:05.872: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:160/proxy/: foo (200; 51.124493ms)
Feb  7 18:17:05.893: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:162/proxy/: bar (200; 71.374131ms)
Feb  7 18:17:05.894: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/https:proxy-service-f8m92:tlsportname2/proxy/: tls qux (200; 73.263659ms)
Feb  7 18:17:05.894: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/http:proxy-service-f8m92:portname1/proxy/: foo (200; 73.899064ms)
Feb  7 18:17:05.895: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/proxy-service-f8m92:portname2/proxy/: bar (200; 72.865911ms)
Feb  7 18:17:05.896: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/http:proxy-service-f8m92:portname2/proxy/: bar (200; 74.78081ms)
Feb  7 18:17:05.897: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/proxy-service-f8m92:portname1/proxy/: foo (200; 75.892122ms)
Feb  7 18:17:05.898: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/https:proxy-service-f8m92:tlsportname1/proxy/: tls baz (200; 76.440561ms)
Feb  7 18:17:05.914: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:1080/proxy/... (200; 15.554083ms)
Feb  7 18:17:05.915: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/proxy-service-f8m92:portname2/proxy/: bar (200; 17.075278ms)
Feb  7 18:17:05.920: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:162/proxy/: bar (200; 21.138575ms)
Feb  7 18:17:05.923: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:160/proxy/: foo (200; 24.236178ms)
Feb  7 18:17:05.933: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/http:proxy-service-f8m92:portname1/proxy/: foo (200; 32.46425ms)
Feb  7 18:17:05.937: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:443/proxy/... (200; 38.192171ms)
Feb  7 18:17:05.943: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/proxy-service-f8m92:portname1/proxy/: foo (200; 44.125312ms)
Feb  7 18:17:05.945: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/https:proxy-service-f8m92:tlsportname2/proxy/: tls qux (200; 46.288207ms)
Feb  7 18:17:05.945: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm/proxy/rewriteme"... (200; 45.68903ms)
Feb  7 18:17:05.947: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:462/proxy/: tls qux (200; 47.394875ms)
Feb  7 18:17:05.947: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:460/proxy/: tls baz (200; 46.665482ms)
Feb  7 18:17:05.947: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:160/proxy/: foo (200; 48.050569ms)
Feb  7 18:17:05.947: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/https:proxy-service-f8m92:tlsportname1/proxy/: tls baz (200; 47.770411ms)
Feb  7 18:17:05.948: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/http:proxy-service-f8m92:portname2/proxy/: bar (200; 48.779223ms)
Feb  7 18:17:05.951: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:1080/proxy/rewri... (200; 51.293245ms)
Feb  7 18:17:05.952: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:162/proxy/: bar (200; 51.692857ms)
Feb  7 18:17:05.969: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:162/proxy/: bar (200; 17.242196ms)
Feb  7 18:17:05.975: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:460/proxy/: tls baz (200; 22.604779ms)
Feb  7 18:17:05.975: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/proxy-service-f8m92:portname2/proxy/: bar (200; 23.034054ms)
Feb  7 18:17:05.983: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/http:proxy-service-f8m92:portname2/proxy/: bar (200; 31.795892ms)
Feb  7 18:17:05.985: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm/proxy/rewriteme"... (200; 31.483782ms)
Feb  7 18:17:05.987: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/https:proxy-service-f8m92:tlsportname2/proxy/: tls qux (200; 34.664645ms)
Feb  7 18:17:05.989: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:1080/proxy/... (200; 36.955102ms)
Feb  7 18:17:05.991: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:162/proxy/: bar (200; 38.170977ms)
Feb  7 18:17:05.991: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/http:proxy-service-f8m92:portname1/proxy/: foo (200; 38.777064ms)
Feb  7 18:17:05.994: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/https:proxy-service-f8m92:tlsportname1/proxy/: tls baz (200; 40.051102ms)
Feb  7 18:17:05.994: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:443/proxy/... (200; 40.38995ms)
Feb  7 18:17:05.994: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/proxy-service-f8m92:portname1/proxy/: foo (200; 40.919055ms)
Feb  7 18:17:05.994: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:160/proxy/: foo (200; 41.55458ms)
Feb  7 18:17:05.995: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:160/proxy/: foo (200; 41.845795ms)
Feb  7 18:17:05.997: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:462/proxy/: tls qux (200; 43.305756ms)
Feb  7 18:17:05.998: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:1080/proxy/rewri... (200; 44.062532ms)
Feb  7 18:17:06.011: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:162/proxy/: bar (200; 12.395492ms)
Feb  7 18:17:06.011: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:160/proxy/: foo (200; 13.195821ms)
Feb  7 18:17:06.013: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:1080/proxy/... (200; 14.666179ms)
Feb  7 18:17:06.013: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:160/proxy/: foo (200; 14.157275ms)
Feb  7 18:17:06.022: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:462/proxy/: tls qux (200; 23.27772ms)
Feb  7 18:17:06.023: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:443/proxy/... (200; 24.148199ms)
Feb  7 18:17:06.023: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/https:proxy-service-f8m92:tlsportname2/proxy/: tls qux (200; 24.514706ms)
Feb  7 18:17:06.024: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm/proxy/rewriteme"... (200; 24.198376ms)
Feb  7 18:17:06.027: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:1080/proxy/rewri... (200; 27.611337ms)
Feb  7 18:17:06.030: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:460/proxy/: tls baz (200; 30.384968ms)
Feb  7 18:17:06.031: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:162/proxy/: bar (200; 31.162664ms)
Feb  7 18:17:06.035: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/http:proxy-service-f8m92:portname2/proxy/: bar (200; 35.606099ms)
Feb  7 18:17:06.036: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/proxy-service-f8m92:portname1/proxy/: foo (200; 37.165541ms)
Feb  7 18:17:06.037: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/proxy-service-f8m92:portname2/proxy/: bar (200; 38.752172ms)
Feb  7 18:17:06.037: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/https:proxy-service-f8m92:tlsportname1/proxy/: tls baz (200; 37.496983ms)
Feb  7 18:17:06.037: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/http:proxy-service-f8m92:portname1/proxy/: foo (200; 37.34755ms)
Feb  7 18:17:06.057: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:162/proxy/: bar (200; 18.305722ms)
Feb  7 18:17:06.068: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:462/proxy/: tls qux (200; 30.813932ms)
Feb  7 18:17:06.068: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:460/proxy/: tls baz (200; 29.966386ms)
Feb  7 18:17:06.070: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/http:proxy-service-f8m92:portname2/proxy/: bar (200; 32.093748ms)
Feb  7 18:17:06.076: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm/proxy/rewriteme"... (200; 36.217626ms)
Feb  7 18:17:06.077: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:160/proxy/: foo (200; 37.80555ms)
Feb  7 18:17:06.078: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:1080/proxy/... (200; 39.057545ms)
Feb  7 18:17:06.078: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:162/proxy/: bar (200; 38.840798ms)
Feb  7 18:17:06.078: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/https:proxy-service-f8m92:tlsportname1/proxy/: tls baz (200; 38.755107ms)
Feb  7 18:17:06.081: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:160/proxy/: foo (200; 41.754432ms)
Feb  7 18:17:06.081: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:443/proxy/... (200; 41.463225ms)
Feb  7 18:17:06.082: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/https:proxy-service-f8m92:tlsportname2/proxy/: tls qux (200; 43.298519ms)
Feb  7 18:17:06.083: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:1080/proxy/rewri... (200; 45.468877ms)
Feb  7 18:17:06.084: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/http:proxy-service-f8m92:portname1/proxy/: foo (200; 46.475193ms)
Feb  7 18:17:06.086: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/proxy-service-f8m92:portname1/proxy/: foo (200; 46.956371ms)
Feb  7 18:17:06.086: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/proxy-service-f8m92:portname2/proxy/: bar (200; 48.297852ms)
Feb  7 18:17:06.097: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:162/proxy/: bar (200; 10.573931ms)
Feb  7 18:17:06.107: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:460/proxy/: tls baz (200; 18.673883ms)
Feb  7 18:17:06.112: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/https:proxy-service-f8m92:tlsportname1/proxy/: tls baz (200; 25.670696ms)
Feb  7 18:17:06.115: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/https:proxy-service-f8m92:tlsportname2/proxy/: tls qux (200; 26.870002ms)
Feb  7 18:17:06.117: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:1080/proxy/... (200; 28.549953ms)
Feb  7 18:17:06.118: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:443/proxy/... (200; 31.333163ms)
Feb  7 18:17:06.119: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:160/proxy/: foo (200; 29.994288ms)
Feb  7 18:17:06.119: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/proxy-service-f8m92:portname1/proxy/: foo (200; 31.160028ms)
Feb  7 18:17:06.120: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/proxy-service-f8m92:portname2/proxy/: bar (200; 31.933129ms)
Feb  7 18:17:06.121: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:1080/proxy/rewri... (200; 33.132496ms)
Feb  7 18:17:06.124: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/http:proxy-service-f8m92:portname1/proxy/: foo (200; 36.110924ms)
Feb  7 18:17:06.125: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:162/proxy/: bar (200; 36.769388ms)
Feb  7 18:17:06.125: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm/proxy/rewriteme"... (200; 38.657725ms)
Feb  7 18:17:06.126: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:462/proxy/: tls qux (200; 38.845669ms)
Feb  7 18:17:06.127: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:160/proxy/: foo (200; 39.656094ms)
Feb  7 18:17:06.127: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/http:proxy-service-f8m92:portname2/proxy/: bar (200; 39.274888ms)
Feb  7 18:17:06.136: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:1080/proxy/... (200; 9.432711ms)
Feb  7 18:17:06.147: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:162/proxy/: bar (200; 18.880795ms)
Feb  7 18:17:06.147: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm/proxy/rewriteme"... (200; 18.848553ms)
Feb  7 18:17:06.155: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/https:proxy-service-f8m92:tlsportname1/proxy/: tls baz (200; 26.75332ms)
Feb  7 18:17:06.157: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/http:proxy-service-f8m92:portname1/proxy/: foo (200; 30.272161ms)
Feb  7 18:17:06.158: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/https:proxy-service-f8m92:tlsportname2/proxy/: tls qux (200; 30.343333ms)
Feb  7 18:17:06.159: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/http:proxy-service-f8m92:portname2/proxy/: bar (200; 30.058113ms)
Feb  7 18:17:06.160: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:160/proxy/: foo (200; 31.328762ms)
Feb  7 18:17:06.160: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:1080/proxy/rewri... (200; 32.822942ms)
Feb  7 18:17:06.160: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:162/proxy/: bar (200; 32.797951ms)
Feb  7 18:17:06.161: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:462/proxy/: tls qux (200; 32.528506ms)
Feb  7 18:17:06.161: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:460/proxy/: tls baz (200; 33.882146ms)
Feb  7 18:17:06.161: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/proxy-service-f8m92:portname1/proxy/: foo (200; 33.703521ms)
Feb  7 18:17:06.161: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:443/proxy/... (200; 32.821431ms)
Feb  7 18:17:06.162: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/proxy-service-f8m92:portname2/proxy/: bar (200; 34.312929ms)
Feb  7 18:17:06.162: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:160/proxy/: foo (200; 33.078562ms)
Feb  7 18:17:06.180: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:460/proxy/: tls baz (200; 17.2572ms)
Feb  7 18:17:06.181: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:443/proxy/... (200; 19.018226ms)
Feb  7 18:17:06.183: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:160/proxy/: foo (200; 20.867236ms)
Feb  7 18:17:06.191: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:162/proxy/: bar (200; 27.638175ms)
Feb  7 18:17:06.192: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:1080/proxy/rewri... (200; 29.369651ms)
Feb  7 18:17:06.195: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/https:proxy-service-f8m92:tlsportname1/proxy/: tls baz (200; 32.104387ms)
Feb  7 18:17:06.195: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm/proxy/rewriteme"... (200; 32.396396ms)
Feb  7 18:17:06.196: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:1080/proxy/... (200; 32.869408ms)
Feb  7 18:17:06.196: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:462/proxy/: tls qux (200; 33.466434ms)
Feb  7 18:17:06.196: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/http:proxy-service-f8m92:portname1/proxy/: foo (200; 33.810734ms)
Feb  7 18:17:06.196: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/https:proxy-service-f8m92:tlsportname2/proxy/: tls qux (200; 34.42503ms)
Feb  7 18:17:06.196: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/proxy-service-f8m92:portname1/proxy/: foo (200; 33.21894ms)
Feb  7 18:17:06.197: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/http:proxy-service-f8m92:portname2/proxy/: bar (200; 33.613007ms)
Feb  7 18:17:06.197: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:160/proxy/: foo (200; 33.990084ms)
Feb  7 18:17:06.197: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/proxy-service-f8m92:portname2/proxy/: bar (200; 34.659461ms)
Feb  7 18:17:06.198: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:162/proxy/: bar (200; 34.550797ms)
Feb  7 18:17:06.217: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:162/proxy/: bar (200; 18.515403ms)
Feb  7 18:17:06.217: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/proxy-service-f8m92:portname1/proxy/: foo (200; 18.528019ms)
Feb  7 18:17:06.218: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm/proxy/rewriteme"... (200; 20.341679ms)
Feb  7 18:17:06.219: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:160/proxy/: foo (200; 20.816556ms)
Feb  7 18:17:06.225: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:460/proxy/: tls baz (200; 26.452116ms)
Feb  7 18:17:06.229: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:1080/proxy/rewri... (200; 30.563724ms)
Feb  7 18:17:06.230: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/http:proxy-service-f8m92:portname1/proxy/: foo (200; 31.522516ms)
Feb  7 18:17:06.231: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/http:proxy-service-f8m92:portname2/proxy/: bar (200; 32.496689ms)
Feb  7 18:17:06.234: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:443/proxy/... (200; 35.251916ms)
Feb  7 18:17:06.234: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:1080/proxy/... (200; 35.33664ms)
Feb  7 18:17:06.236: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:462/proxy/: tls qux (200; 37.033265ms)
Feb  7 18:17:06.237: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/proxy-service-f8m92:portname2/proxy/: bar (200; 38.019267ms)
Feb  7 18:17:06.237: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:160/proxy/: foo (200; 38.195363ms)
Feb  7 18:17:06.238: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/https:proxy-service-f8m92:tlsportname2/proxy/: tls qux (200; 38.978352ms)
Feb  7 18:17:06.239: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/https:proxy-service-f8m92:tlsportname1/proxy/: tls baz (200; 39.685979ms)
Feb  7 18:17:06.240: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:162/proxy/: bar (200; 41.655209ms)
Feb  7 18:17:06.252: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:160/proxy/: foo (200; 11.716221ms)
Feb  7 18:17:06.254: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:460/proxy/: tls baz (200; 12.672268ms)
Feb  7 18:17:06.254: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:1080/proxy/rewri... (200; 13.675492ms)
Feb  7 18:17:06.255: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:162/proxy/: bar (200; 14.911302ms)
Feb  7 18:17:06.264: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:1080/proxy/... (200; 23.385429ms)
Feb  7 18:17:06.265: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/https:proxy-service-f8m92:tlsportname1/proxy/: tls baz (200; 24.43172ms)
Feb  7 18:17:06.267: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm/proxy/rewriteme"... (200; 25.592266ms)
Feb  7 18:17:06.267: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/http:proxy-service-f8m92:portname1/proxy/: foo (200; 26.42486ms)
Feb  7 18:17:06.267: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:160/proxy/: foo (200; 26.146172ms)
Feb  7 18:17:06.269: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:443/proxy/... (200; 28.012564ms)
Feb  7 18:17:06.271: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:462/proxy/: tls qux (200; 29.764034ms)
Feb  7 18:17:06.272: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/proxy-service-f8m92:portname2/proxy/: bar (200; 31.544466ms)
Feb  7 18:17:06.273: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:162/proxy/: bar (200; 32.624941ms)
Feb  7 18:17:06.273: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/http:proxy-service-f8m92:portname2/proxy/: bar (200; 32.030223ms)
Feb  7 18:17:06.274: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/proxy-service-f8m92:portname1/proxy/: foo (200; 33.303102ms)
Feb  7 18:17:06.276: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/https:proxy-service-f8m92:tlsportname2/proxy/: tls qux (200; 34.828453ms)
Feb  7 18:17:06.301: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/http:proxy-service-f8m92:portname2/proxy/: bar (200; 24.357732ms)
Feb  7 18:17:06.306: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:1080/proxy/rewri... (200; 29.517169ms)
Feb  7 18:17:06.306: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:162/proxy/: bar (200; 29.309629ms)
Feb  7 18:17:06.308: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:160/proxy/: foo (200; 30.576261ms)
Feb  7 18:17:06.308: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/http:proxy-service-f8m92:portname1/proxy/: foo (200; 31.501423ms)
Feb  7 18:17:06.309: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm/proxy/rewriteme"... (200; 31.92754ms)
Feb  7 18:17:06.313: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/https:proxy-service-f8m92:tlsportname2/proxy/: tls qux (200; 36.758933ms)
Feb  7 18:17:06.314: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/https:proxy-service-f8m92:tlsportname1/proxy/: tls baz (200; 38.060638ms)
Feb  7 18:17:06.315: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/proxy-service-f8m92:portname1/proxy/: foo (200; 38.66407ms)
Feb  7 18:17:06.316: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/proxy-service-f8m92:portname2/proxy/: bar (200; 39.27833ms)
Feb  7 18:17:06.318: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:1080/proxy/... (200; 42.497889ms)
Feb  7 18:17:06.319: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:462/proxy/: tls qux (200; 41.818488ms)
Feb  7 18:17:06.320: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:162/proxy/: bar (200; 43.601503ms)
Feb  7 18:17:06.321: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:443/proxy/... (200; 44.727559ms)
Feb  7 18:17:06.322: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:160/proxy/: foo (200; 46.319988ms)
Feb  7 18:17:06.324: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:460/proxy/: tls baz (200; 47.883934ms)
Feb  7 18:17:06.341: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:162/proxy/: bar (200; 15.932358ms)
Feb  7 18:17:06.348: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:460/proxy/: tls baz (200; 22.733674ms)
Feb  7 18:17:06.351: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:162/proxy/: bar (200; 26.32858ms)
Feb  7 18:17:06.353: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:443/proxy/... (200; 27.048724ms)
Feb  7 18:17:06.361: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:1080/proxy/rewri... (200; 33.995728ms)
Feb  7 18:17:06.363: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/proxy-service-f8m92:portname1/proxy/: foo (200; 36.660194ms)
Feb  7 18:17:06.363: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/https:proxy-service-f8m92:tlsportname1/proxy/: tls baz (200; 36.197634ms)
Feb  7 18:17:06.363: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:160/proxy/: foo (200; 37.004036ms)
Feb  7 18:17:06.364: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:1080/proxy/... (200; 38.739718ms)
Feb  7 18:17:06.364: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:160/proxy/: foo (200; 38.041573ms)
Feb  7 18:17:06.364: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:462/proxy/: tls qux (200; 37.777226ms)
Feb  7 18:17:06.365: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/http:proxy-service-f8m92:portname1/proxy/: foo (200; 40.159953ms)
Feb  7 18:17:06.368: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm/proxy/rewriteme"... (200; 41.53768ms)
Feb  7 18:17:06.368: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/https:proxy-service-f8m92:tlsportname2/proxy/: tls qux (200; 42.206541ms)
Feb  7 18:17:06.368: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/proxy-service-f8m92:portname2/proxy/: bar (200; 42.974361ms)
Feb  7 18:17:06.371: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/http:proxy-service-f8m92:portname2/proxy/: bar (200; 46.002575ms)
Feb  7 18:17:06.390: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:160/proxy/: foo (200; 18.828187ms)
Feb  7 18:17:06.393: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:462/proxy/: tls qux (200; 20.628575ms)
Feb  7 18:17:06.394: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:1080/proxy/... (200; 23.021901ms)
Feb  7 18:17:06.398: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:460/proxy/: tls baz (200; 27.57127ms)
Feb  7 18:17:06.401: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:1080/proxy/rewri... (200; 29.233946ms)
Feb  7 18:17:06.401: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:443/proxy/... (200; 29.314227ms)
Feb  7 18:17:06.402: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/http:proxy-service-f8m92:portname2/proxy/: bar (200; 29.726136ms)
Feb  7 18:17:06.403: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:162/proxy/: bar (200; 29.979404ms)
Feb  7 18:17:06.403: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:162/proxy/: bar (200; 31.477917ms)
Feb  7 18:17:06.405: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/https:proxy-service-f8m92:tlsportname2/proxy/: tls qux (200; 34.147803ms)
Feb  7 18:17:06.406: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm/proxy/rewriteme"... (200; 34.234264ms)
Feb  7 18:17:06.406: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/proxy-service-f8m92:portname2/proxy/: bar (200; 33.627408ms)
Feb  7 18:17:06.406: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/https:proxy-service-f8m92:tlsportname1/proxy/: tls baz (200; 34.500695ms)
Feb  7 18:17:06.407: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:160/proxy/: foo (200; 35.23773ms)
Feb  7 18:17:06.407: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/http:proxy-service-f8m92:portname1/proxy/: foo (200; 34.158384ms)
Feb  7 18:17:06.407: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/proxy-service-f8m92:portname1/proxy/: foo (200; 36.408951ms)
Feb  7 18:17:06.423: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:460/proxy/: tls baz (200; 15.109805ms)
Feb  7 18:17:06.426: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:1080/proxy/... (200; 18.689919ms)
Feb  7 18:17:06.430: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:160/proxy/: foo (200; 22.631013ms)
Feb  7 18:17:06.436: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/https:proxy-service-f8m92:tlsportname2/proxy/: tls qux (200; 28.230392ms)
Feb  7 18:17:06.438: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:160/proxy/: foo (200; 29.678057ms)
Feb  7 18:17:06.438: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:462/proxy/: tls qux (200; 29.976241ms)
Feb  7 18:17:06.438: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/proxy-service-f8m92:portname1/proxy/: foo (200; 30.389525ms)
Feb  7 18:17:06.443: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm/proxy/rewriteme"... (200; 34.625885ms)
Feb  7 18:17:06.445: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:1080/proxy/rewri... (200; 37.046597ms)
Feb  7 18:17:06.446: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:162/proxy/: bar (200; 37.529896ms)
Feb  7 18:17:06.447: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:443/proxy/... (200; 39.101376ms)
Feb  7 18:17:06.452: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:162/proxy/: bar (200; 43.743893ms)
Feb  7 18:17:06.454: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/https:proxy-service-f8m92:tlsportname1/proxy/: tls baz (200; 45.213184ms)
Feb  7 18:17:06.454: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/proxy-service-f8m92:portname2/proxy/: bar (200; 45.808455ms)
Feb  7 18:17:06.454: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/http:proxy-service-f8m92:portname2/proxy/: bar (200; 46.151174ms)
Feb  7 18:17:06.455: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/http:proxy-service-f8m92:portname1/proxy/: foo (200; 47.021432ms)
Feb  7 18:17:06.478: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:1080/proxy/... (200; 22.220538ms)
Feb  7 18:17:06.480: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:162/proxy/: bar (200; 23.439404ms)
Feb  7 18:17:06.485: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm/proxy/rewriteme"... (200; 28.894299ms)
Feb  7 18:17:06.487: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:460/proxy/: tls baz (200; 31.42593ms)
Feb  7 18:17:06.487: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:443/proxy/... (200; 31.744075ms)
Feb  7 18:17:06.495: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:1080/proxy/rewri... (200; 39.645309ms)
Feb  7 18:17:06.495: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:462/proxy/: tls qux (200; 39.425469ms)
Feb  7 18:17:06.495: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/http:proxy-service-f8m92:portname2/proxy/: bar (200; 38.566719ms)
Feb  7 18:17:06.495: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:160/proxy/: foo (200; 38.868079ms)
Feb  7 18:17:06.496: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/https:proxy-service-f8m92:tlsportname1/proxy/: tls baz (200; 39.030571ms)
Feb  7 18:17:06.497: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/https:proxy-service-f8m92:tlsportname2/proxy/: tls qux (200; 41.390932ms)
Feb  7 18:17:06.498: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:160/proxy/: foo (200; 41.566473ms)
Feb  7 18:17:06.498: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/proxy-service-f8m92:portname1/proxy/: foo (200; 41.921591ms)
Feb  7 18:17:06.500: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:162/proxy/: bar (200; 43.276065ms)
Feb  7 18:17:06.500: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/proxy-service-f8m92:portname2/proxy/: bar (200; 43.506194ms)
Feb  7 18:17:06.501: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/http:proxy-service-f8m92:portname1/proxy/: foo (200; 44.775178ms)
Feb  7 18:17:06.507: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:162/proxy/: bar (200; 6.540845ms)
Feb  7 18:17:06.518: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:160/proxy/: foo (200; 16.767956ms)
Feb  7 18:17:06.518: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:1080/proxy/rewri... (200; 16.977383ms)
Feb  7 18:17:06.519: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:162/proxy/: bar (200; 17.885829ms)
Feb  7 18:17:06.523: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/proxy-service-f8m92:portname1/proxy/: foo (200; 21.939087ms)
Feb  7 18:17:06.528: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:460/proxy/: tls baz (200; 27.083799ms)
Feb  7 18:17:06.536: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:443/proxy/... (200; 33.768561ms)
Feb  7 18:17:06.540: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:1080/proxy/... (200; 38.161024ms)
Feb  7 18:17:06.543: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:462/proxy/: tls qux (200; 40.979723ms)
Feb  7 18:17:06.543: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:160/proxy/: foo (200; 41.243138ms)
Feb  7 18:17:06.543: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm/proxy/rewriteme"... (200; 41.466404ms)
Feb  7 18:17:06.547: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/https:proxy-service-f8m92:tlsportname2/proxy/: tls qux (200; 45.696156ms)
Feb  7 18:17:06.548: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/http:proxy-service-f8m92:portname2/proxy/: bar (200; 46.195849ms)
Feb  7 18:17:06.549: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/https:proxy-service-f8m92:tlsportname1/proxy/: tls baz (200; 47.292551ms)
Feb  7 18:17:06.550: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/http:proxy-service-f8m92:portname1/proxy/: foo (200; 48.506102ms)
Feb  7 18:17:06.550: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/proxy-service-f8m92:portname2/proxy/: bar (200; 48.392939ms)
Feb  7 18:17:06.578: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:1080/proxy/rewri... (200; 27.200185ms)
Feb  7 18:17:06.578: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:462/proxy/: tls qux (200; 27.79991ms)
Feb  7 18:17:06.584: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:443/proxy/... (200; 32.807507ms)
Feb  7 18:17:06.585: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm/proxy/rewriteme"... (200; 33.775652ms)
Feb  7 18:17:06.586: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:160/proxy/: foo (200; 34.518142ms)
Feb  7 18:17:06.597: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:160/proxy/: foo (200; 46.455796ms)
Feb  7 18:17:06.597: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/https:proxy-service-f8m92:tlsportname2/proxy/: tls qux (200; 47.258356ms)
Feb  7 18:17:06.598: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:1080/proxy/... (200; 47.587647ms)
Feb  7 18:17:06.598: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:460/proxy/: tls baz (200; 47.363705ms)
Feb  7 18:17:06.600: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/http:proxy-service-f8m92:portname2/proxy/: bar (200; 48.997356ms)
Feb  7 18:17:06.602: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/https:proxy-service-f8m92:tlsportname1/proxy/: tls baz (200; 51.192728ms)
Feb  7 18:17:06.603: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:162/proxy/: bar (200; 52.212373ms)
Feb  7 18:17:06.603: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:162/proxy/: bar (200; 51.787271ms)
Feb  7 18:17:06.603: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/proxy-service-f8m92:portname1/proxy/: foo (200; 51.748216ms)
Feb  7 18:17:06.606: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/http:proxy-service-f8m92:portname1/proxy/: foo (200; 55.128526ms)
Feb  7 18:17:06.608: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/proxy-service-f8m92:portname2/proxy/: bar (200; 56.835777ms)
Feb  7 18:17:06.629: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:162/proxy/: bar (200; 20.87584ms)
Feb  7 18:17:06.632: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:460/proxy/: tls baz (200; 23.889183ms)
Feb  7 18:17:06.633: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm/proxy/rewriteme"... (200; 24.575636ms)
Feb  7 18:17:06.633: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:1080/proxy/rewri... (200; 25.481196ms)
Feb  7 18:17:06.634: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:160/proxy/: foo (200; 26.648504ms)
Feb  7 18:17:06.640: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:160/proxy/: foo (200; 31.197529ms)
Feb  7 18:17:06.647: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:443/proxy/... (200; 38.275504ms)
Feb  7 18:17:06.647: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/http:proxy-service-f8m92-cbmjm:1080/proxy/... (200; 38.744267ms)
Feb  7 18:17:06.649: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/https:proxy-service-f8m92-cbmjm:462/proxy/: tls qux (200; 40.528874ms)
Feb  7 18:17:06.650: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-hsv4c/pods/proxy-service-f8m92-cbmjm:162/proxy/: bar (200; 42.361351ms)
Feb  7 18:17:06.653: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/http:proxy-service-f8m92:portname1/proxy/: foo (200; 44.448833ms)
Feb  7 18:17:06.653: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/https:proxy-service-f8m92:tlsportname1/proxy/: tls baz (200; 45.463396ms)
Feb  7 18:17:06.654: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/https:proxy-service-f8m92:tlsportname2/proxy/: tls qux (200; 45.578978ms)
Feb  7 18:17:06.656: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/proxy-service-f8m92:portname1/proxy/: foo (200; 47.39658ms)
Feb  7 18:17:06.658: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/proxy-service-f8m92:portname2/proxy/: bar (200; 50.223946ms)
Feb  7 18:17:06.658: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-hsv4c/services/http:proxy-service-f8m92:portname2/proxy/: bar (200; 49.518026ms)
STEP: deleting ReplicationController proxy-service-f8m92 in namespace e2e-tests-proxy-hsv4c, will wait for the garbage collector to delete the pods
Feb  7 18:17:06.730: INFO: Deleting ReplicationController proxy-service-f8m92 took: 16.488857ms
Feb  7 18:17:06.831: INFO: Terminating ReplicationController proxy-service-f8m92 pods took: 100.661911ms
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:17:18.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-hsv4c" for this suite.
Feb  7 18:17:24.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:17:24.847: INFO: namespace: e2e-tests-proxy-hsv4c, resource: bindings, ignored listing per whitelist
Feb  7 18:17:24.914: INFO: namespace e2e-tests-proxy-hsv4c deletion completed in 6.174757121s

• [SLOW TEST:25.415 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:17:24.915: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-kcpk2
Feb  7 18:17:27.070: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-kcpk2
STEP: checking the pod's current state and verifying that restartCount is present
Feb  7 18:17:27.073: INFO: Initial restart count of pod liveness-exec is 0
Feb  7 18:18:15.198: INFO: Restart count of pod e2e-tests-container-probe-kcpk2/liveness-exec is now 1 (48.124395163s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:18:15.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-kcpk2" for this suite.
Feb  7 18:18:21.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:18:21.320: INFO: namespace: e2e-tests-container-probe-kcpk2, resource: bindings, ignored listing per whitelist
Feb  7 18:18:21.402: INFO: namespace e2e-tests-container-probe-kcpk2 deletion completed in 6.169644167s

• [SLOW TEST:56.487 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:18:21.403: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Feb  7 18:18:21.537: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-b4jc6,SelfLink:/api/v1/namespaces/e2e-tests-watch-b4jc6/configmaps/e2e-watch-test-configmap-a,UID:c029a2ff-2b04-11e9-a946-ceb99be2323d,ResourceVersion:1760,Generation:0,CreationTimestamp:2019-02-07 18:18:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb  7 18:18:21.537: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-b4jc6,SelfLink:/api/v1/namespaces/e2e-tests-watch-b4jc6/configmaps/e2e-watch-test-configmap-a,UID:c029a2ff-2b04-11e9-a946-ceb99be2323d,ResourceVersion:1760,Generation:0,CreationTimestamp:2019-02-07 18:18:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Feb  7 18:18:31.550: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-b4jc6,SelfLink:/api/v1/namespaces/e2e-tests-watch-b4jc6/configmaps/e2e-watch-test-configmap-a,UID:c029a2ff-2b04-11e9-a946-ceb99be2323d,ResourceVersion:1764,Generation:0,CreationTimestamp:2019-02-07 18:18:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb  7 18:18:31.551: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-b4jc6,SelfLink:/api/v1/namespaces/e2e-tests-watch-b4jc6/configmaps/e2e-watch-test-configmap-a,UID:c029a2ff-2b04-11e9-a946-ceb99be2323d,ResourceVersion:1764,Generation:0,CreationTimestamp:2019-02-07 18:18:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Feb  7 18:18:41.565: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-b4jc6,SelfLink:/api/v1/namespaces/e2e-tests-watch-b4jc6/configmaps/e2e-watch-test-configmap-a,UID:c029a2ff-2b04-11e9-a946-ceb99be2323d,ResourceVersion:1769,Generation:0,CreationTimestamp:2019-02-07 18:18:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb  7 18:18:41.565: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-b4jc6,SelfLink:/api/v1/namespaces/e2e-tests-watch-b4jc6/configmaps/e2e-watch-test-configmap-a,UID:c029a2ff-2b04-11e9-a946-ceb99be2323d,ResourceVersion:1769,Generation:0,CreationTimestamp:2019-02-07 18:18:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Feb  7 18:18:51.580: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-b4jc6,SelfLink:/api/v1/namespaces/e2e-tests-watch-b4jc6/configmaps/e2e-watch-test-configmap-a,UID:c029a2ff-2b04-11e9-a946-ceb99be2323d,ResourceVersion:1773,Generation:0,CreationTimestamp:2019-02-07 18:18:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb  7 18:18:51.580: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-b4jc6,SelfLink:/api/v1/namespaces/e2e-tests-watch-b4jc6/configmaps/e2e-watch-test-configmap-a,UID:c029a2ff-2b04-11e9-a946-ceb99be2323d,ResourceVersion:1773,Generation:0,CreationTimestamp:2019-02-07 18:18:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Feb  7 18:19:01.593: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-b4jc6,SelfLink:/api/v1/namespaces/e2e-tests-watch-b4jc6/configmaps/e2e-watch-test-configmap-b,UID:d808aa7a-2b04-11e9-a946-ceb99be2323d,ResourceVersion:1777,Generation:0,CreationTimestamp:2019-02-07 18:19:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb  7 18:19:01.593: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-b4jc6,SelfLink:/api/v1/namespaces/e2e-tests-watch-b4jc6/configmaps/e2e-watch-test-configmap-b,UID:d808aa7a-2b04-11e9-a946-ceb99be2323d,ResourceVersion:1777,Generation:0,CreationTimestamp:2019-02-07 18:19:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Feb  7 18:19:11.603: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-b4jc6,SelfLink:/api/v1/namespaces/e2e-tests-watch-b4jc6/configmaps/e2e-watch-test-configmap-b,UID:d808aa7a-2b04-11e9-a946-ceb99be2323d,ResourceVersion:1782,Generation:0,CreationTimestamp:2019-02-07 18:19:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb  7 18:19:11.603: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-b4jc6,SelfLink:/api/v1/namespaces/e2e-tests-watch-b4jc6/configmaps/e2e-watch-test-configmap-b,UID:d808aa7a-2b04-11e9-a946-ceb99be2323d,ResourceVersion:1782,Generation:0,CreationTimestamp:2019-02-07 18:19:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:19:21.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-b4jc6" for this suite.
Feb  7 18:19:27.625: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:19:27.731: INFO: namespace: e2e-tests-watch-b4jc6, resource: bindings, ignored listing per whitelist
Feb  7 18:19:27.783: INFO: namespace e2e-tests-watch-b4jc6 deletion completed in 6.173650298s

• [SLOW TEST:66.380 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:19:27.783: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Feb  7 18:19:27.917: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-qwzst,SelfLink:/api/v1/namespaces/e2e-tests-watch-qwzst/configmaps/e2e-watch-test-watch-closed,UID:e7b90e5f-2b04-11e9-a946-ceb99be2323d,ResourceVersion:1797,Generation:0,CreationTimestamp:2019-02-07 18:19:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb  7 18:19:27.918: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-qwzst,SelfLink:/api/v1/namespaces/e2e-tests-watch-qwzst/configmaps/e2e-watch-test-watch-closed,UID:e7b90e5f-2b04-11e9-a946-ceb99be2323d,ResourceVersion:1798,Generation:0,CreationTimestamp:2019-02-07 18:19:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Feb  7 18:19:27.942: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-qwzst,SelfLink:/api/v1/namespaces/e2e-tests-watch-qwzst/configmaps/e2e-watch-test-watch-closed,UID:e7b90e5f-2b04-11e9-a946-ceb99be2323d,ResourceVersion:1799,Generation:0,CreationTimestamp:2019-02-07 18:19:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb  7 18:19:27.942: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-qwzst,SelfLink:/api/v1/namespaces/e2e-tests-watch-qwzst/configmaps/e2e-watch-test-watch-closed,UID:e7b90e5f-2b04-11e9-a946-ceb99be2323d,ResourceVersion:1800,Generation:0,CreationTimestamp:2019-02-07 18:19:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:19:27.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-qwzst" for this suite.
Feb  7 18:19:33.964: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:19:34.046: INFO: namespace: e2e-tests-watch-qwzst, resource: bindings, ignored listing per whitelist
Feb  7 18:19:34.133: INFO: namespace e2e-tests-watch-qwzst deletion completed in 6.185603905s

• [SLOW TEST:6.350 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:19:34.134: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Feb  7 18:19:40.321: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-eb842c95-2b04-11e9-90f5-5e78944a5b53,GenerateName:,Namespace:e2e-tests-events-g2x6b,SelfLink:/api/v1/namespaces/e2e-tests-events-g2x6b/pods/send-events-eb842c95-2b04-11e9-90f5-5e78944a5b53,UID:eb857840-2b04-11e9-a946-ceb99be2323d,ResourceVersion:1821,Generation:0,CreationTimestamp:2019-02-07 18:19:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 268238002,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4fvfs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4fvfs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-4fvfs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001209a60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001209a80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 18:19:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 18:19:38 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 18:19:38 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 18:19:34 +0000 UTC  }],Message:,Reason:,HostIP:10.10.1.212,PodIP:10.244.0.48,StartTime:2019-02-07 18:19:34 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-02-07 18:19:37 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://2b062f745350632d053f4bdc65d48673bcd83cc8f40c9004ab545251191f4a1c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Feb  7 18:19:42.327: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Feb  7 18:19:44.332: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:19:44.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-g2x6b" for this suite.
Feb  7 18:20:22.399: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:20:22.472: INFO: namespace: e2e-tests-events-g2x6b, resource: bindings, ignored listing per whitelist
Feb  7 18:20:22.550: INFO: namespace e2e-tests-events-g2x6b deletion completed in 38.187249081s

• [SLOW TEST:48.416 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:20:22.550: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-085ce07a-2b05-11e9-90f5-5e78944a5b53
STEP: Creating a pod to test consume secrets
Feb  7 18:20:22.683: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-085dcd55-2b05-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-projected-d4zhd" to be "success or failure"
Feb  7 18:20:22.702: INFO: Pod "pod-projected-secrets-085dcd55-2b05-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 18.623025ms
Feb  7 18:20:24.706: INFO: Pod "pod-projected-secrets-085dcd55-2b05-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023357311s
STEP: Saw pod success
Feb  7 18:20:24.706: INFO: Pod "pod-projected-secrets-085dcd55-2b05-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 18:20:24.712: INFO: Trying to get logs from node conformance0 pod pod-projected-secrets-085dcd55-2b05-11e9-90f5-5e78944a5b53 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb  7 18:20:24.754: INFO: Waiting for pod pod-projected-secrets-085dcd55-2b05-11e9-90f5-5e78944a5b53 to disappear
Feb  7 18:20:24.764: INFO: Pod pod-projected-secrets-085dcd55-2b05-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:20:24.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-d4zhd" for this suite.
Feb  7 18:20:30.795: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:20:30.911: INFO: namespace: e2e-tests-projected-d4zhd, resource: bindings, ignored listing per whitelist
Feb  7 18:20:30.956: INFO: namespace e2e-tests-projected-d4zhd deletion completed in 6.177909967s

• [SLOW TEST:8.406 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:20:30.957: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-bvcdz
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb  7 18:20:31.066: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb  7 18:20:49.182: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.0.51:8080/dial?request=hostName&protocol=udp&host=10.244.0.50&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-bvcdz PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  7 18:20:49.183: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
Feb  7 18:20:49.328: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:20:49.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-bvcdz" for this suite.
Feb  7 18:21:13.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:21:13.465: INFO: namespace: e2e-tests-pod-network-test-bvcdz, resource: bindings, ignored listing per whitelist
Feb  7 18:21:13.521: INFO: namespace e2e-tests-pod-network-test-bvcdz deletion completed in 24.185842037s

• [SLOW TEST:42.564 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:21:13.521: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  7 18:21:13.640: INFO: Waiting up to 5m0s for pod "downwardapi-volume-26bcd28f-2b05-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-downward-api-gllmr" to be "success or failure"
Feb  7 18:21:13.645: INFO: Pod "downwardapi-volume-26bcd28f-2b05-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 5.529242ms
Feb  7 18:21:15.653: INFO: Pod "downwardapi-volume-26bcd28f-2b05-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012902267s
STEP: Saw pod success
Feb  7 18:21:15.653: INFO: Pod "downwardapi-volume-26bcd28f-2b05-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 18:21:15.658: INFO: Trying to get logs from node conformance0 pod downwardapi-volume-26bcd28f-2b05-11e9-90f5-5e78944a5b53 container client-container: <nil>
STEP: delete the pod
Feb  7 18:21:15.728: INFO: Waiting for pod downwardapi-volume-26bcd28f-2b05-11e9-90f5-5e78944a5b53 to disappear
Feb  7 18:21:15.747: INFO: Pod downwardapi-volume-26bcd28f-2b05-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:21:15.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-gllmr" for this suite.
Feb  7 18:21:21.768: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:21:21.853: INFO: namespace: e2e-tests-downward-api-gllmr, resource: bindings, ignored listing per whitelist
Feb  7 18:21:21.904: INFO: namespace e2e-tests-downward-api-gllmr deletion completed in 6.150554912s

• [SLOW TEST:8.383 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:21:21.904: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb  7 18:21:24.576: INFO: Successfully updated pod "labelsupdate2bbc09d1-2b05-11e9-90f5-5e78944a5b53"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:21:28.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-87dl4" for this suite.
Feb  7 18:21:50.649: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:21:50.764: INFO: namespace: e2e-tests-downward-api-87dl4, resource: bindings, ignored listing per whitelist
Feb  7 18:21:50.829: INFO: namespace e2e-tests-downward-api-87dl4 deletion completed in 22.198974238s

• [SLOW TEST:28.924 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:21:50.830: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  7 18:21:50.961: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:22:00.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-p5ttp" for this suite.
Feb  7 18:22:06.066: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:22:06.203: INFO: namespace: e2e-tests-custom-resource-definition-p5ttp, resource: bindings, ignored listing per whitelist
Feb  7 18:22:06.213: INFO: namespace e2e-tests-custom-resource-definition-p5ttp deletion completed in 6.164729013s

• [SLOW TEST:15.384 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:22:06.214: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-hgz6w.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-hgz6w.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-hgz6w.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-hgz6w.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-hgz6w.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-hgz6w.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb  7 18:22:32.458: INFO: DNS probes using e2e-tests-dns-hgz6w/dns-test-4627065e-2b05-11e9-90f5-5e78944a5b53 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:22:32.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-hgz6w" for this suite.
Feb  7 18:22:38.601: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:22:38.744: INFO: namespace: e2e-tests-dns-hgz6w, resource: bindings, ignored listing per whitelist
Feb  7 18:22:38.809: INFO: namespace e2e-tests-dns-hgz6w deletion completed in 6.241325867s

• [SLOW TEST:32.596 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:22:38.810: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-5999875d-2b05-11e9-90f5-5e78944a5b53
STEP: Creating a pod to test consume configMaps
Feb  7 18:22:38.975: INFO: Waiting up to 5m0s for pod "pod-configmaps-599ace9e-2b05-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-configmap-llzhd" to be "success or failure"
Feb  7 18:22:39.013: INFO: Pod "pod-configmaps-599ace9e-2b05-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 37.963332ms
Feb  7 18:22:41.018: INFO: Pod "pod-configmaps-599ace9e-2b05-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042881798s
Feb  7 18:22:43.022: INFO: Pod "pod-configmaps-599ace9e-2b05-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047071477s
STEP: Saw pod success
Feb  7 18:22:43.022: INFO: Pod "pod-configmaps-599ace9e-2b05-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 18:22:43.025: INFO: Trying to get logs from node conformance0 pod pod-configmaps-599ace9e-2b05-11e9-90f5-5e78944a5b53 container configmap-volume-test: <nil>
STEP: delete the pod
Feb  7 18:22:43.055: INFO: Waiting for pod pod-configmaps-599ace9e-2b05-11e9-90f5-5e78944a5b53 to disappear
Feb  7 18:22:43.068: INFO: Pod pod-configmaps-599ace9e-2b05-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:22:43.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-llzhd" for this suite.
Feb  7 18:22:49.099: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:22:49.252: INFO: namespace: e2e-tests-configmap-llzhd, resource: bindings, ignored listing per whitelist
Feb  7 18:22:49.289: INFO: namespace e2e-tests-configmap-llzhd deletion completed in 6.207848279s

• [SLOW TEST:10.479 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:22:49.289: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-5fd6d21a-2b05-11e9-90f5-5e78944a5b53
STEP: Creating secret with name s-test-opt-upd-5fd6d2bb-2b05-11e9-90f5-5e78944a5b53
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-5fd6d21a-2b05-11e9-90f5-5e78944a5b53
STEP: Updating secret s-test-opt-upd-5fd6d2bb-2b05-11e9-90f5-5e78944a5b53
STEP: Creating secret with name s-test-opt-create-5fd6d30e-2b05-11e9-90f5-5e78944a5b53
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:24:00.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-2c9jb" for this suite.
Feb  7 18:24:24.061: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:24:24.126: INFO: namespace: e2e-tests-secrets-2c9jb, resource: bindings, ignored listing per whitelist
Feb  7 18:24:24.219: INFO: namespace e2e-tests-secrets-2c9jb deletion completed in 24.176554596s

• [SLOW TEST:94.930 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:24:24.220: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0207 18:24:25.401965      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb  7 18:24:25.402: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:24:25.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-b7ts5" for this suite.
Feb  7 18:24:31.424: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:24:31.472: INFO: namespace: e2e-tests-gc-b7ts5, resource: bindings, ignored listing per whitelist
Feb  7 18:24:31.594: INFO: namespace e2e-tests-gc-b7ts5 deletion completed in 6.187670461s

• [SLOW TEST:7.374 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:24:31.595: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  7 18:24:33.845: INFO: Waiting up to 5m0s for pod "client-envvars-9e0fddec-2b05-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-pods-p5tc7" to be "success or failure"
Feb  7 18:24:33.889: INFO: Pod "client-envvars-9e0fddec-2b05-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 44.489302ms
Feb  7 18:24:35.894: INFO: Pod "client-envvars-9e0fddec-2b05-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.049156718s
STEP: Saw pod success
Feb  7 18:24:35.894: INFO: Pod "client-envvars-9e0fddec-2b05-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 18:24:35.899: INFO: Trying to get logs from node conformance0 pod client-envvars-9e0fddec-2b05-11e9-90f5-5e78944a5b53 container env3cont: <nil>
STEP: delete the pod
Feb  7 18:24:35.931: INFO: Waiting for pod client-envvars-9e0fddec-2b05-11e9-90f5-5e78944a5b53 to disappear
Feb  7 18:24:35.947: INFO: Pod client-envvars-9e0fddec-2b05-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:24:35.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-p5tc7" for this suite.
Feb  7 18:25:19.983: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:25:20.088: INFO: namespace: e2e-tests-pods-p5tc7, resource: bindings, ignored listing per whitelist
Feb  7 18:25:20.126: INFO: namespace e2e-tests-pods-p5tc7 deletion completed in 44.167029358s

• [SLOW TEST:48.532 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:25:20.127: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-mjjw
STEP: Creating a pod to test atomic-volume-subpath
Feb  7 18:25:20.247: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-mjjw" in namespace "e2e-tests-subpath-99znc" to be "success or failure"
Feb  7 18:25:20.252: INFO: Pod "pod-subpath-test-downwardapi-mjjw": Phase="Pending", Reason="", readiness=false. Elapsed: 5.727566ms
Feb  7 18:25:22.271: INFO: Pod "pod-subpath-test-downwardapi-mjjw": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024319824s
Feb  7 18:25:24.276: INFO: Pod "pod-subpath-test-downwardapi-mjjw": Phase="Running", Reason="", readiness=false. Elapsed: 4.029190618s
Feb  7 18:25:26.280: INFO: Pod "pod-subpath-test-downwardapi-mjjw": Phase="Running", Reason="", readiness=false. Elapsed: 6.033753168s
Feb  7 18:25:28.285: INFO: Pod "pod-subpath-test-downwardapi-mjjw": Phase="Running", Reason="", readiness=false. Elapsed: 8.037851275s
Feb  7 18:25:30.290: INFO: Pod "pod-subpath-test-downwardapi-mjjw": Phase="Running", Reason="", readiness=false. Elapsed: 10.042915123s
Feb  7 18:25:32.295: INFO: Pod "pod-subpath-test-downwardapi-mjjw": Phase="Running", Reason="", readiness=false. Elapsed: 12.048581457s
Feb  7 18:25:34.300: INFO: Pod "pod-subpath-test-downwardapi-mjjw": Phase="Running", Reason="", readiness=false. Elapsed: 14.053247362s
Feb  7 18:25:36.305: INFO: Pod "pod-subpath-test-downwardapi-mjjw": Phase="Running", Reason="", readiness=false. Elapsed: 16.058030331s
Feb  7 18:25:38.310: INFO: Pod "pod-subpath-test-downwardapi-mjjw": Phase="Running", Reason="", readiness=false. Elapsed: 18.062895998s
Feb  7 18:25:40.314: INFO: Pod "pod-subpath-test-downwardapi-mjjw": Phase="Running", Reason="", readiness=false. Elapsed: 20.067288925s
Feb  7 18:25:42.322: INFO: Pod "pod-subpath-test-downwardapi-mjjw": Phase="Running", Reason="", readiness=false. Elapsed: 22.075345944s
Feb  7 18:25:44.327: INFO: Pod "pod-subpath-test-downwardapi-mjjw": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.080605119s
STEP: Saw pod success
Feb  7 18:25:44.327: INFO: Pod "pod-subpath-test-downwardapi-mjjw" satisfied condition "success or failure"
Feb  7 18:25:44.331: INFO: Trying to get logs from node conformance0 pod pod-subpath-test-downwardapi-mjjw container test-container-subpath-downwardapi-mjjw: <nil>
STEP: delete the pod
Feb  7 18:25:44.384: INFO: Waiting for pod pod-subpath-test-downwardapi-mjjw to disappear
Feb  7 18:25:44.402: INFO: Pod pod-subpath-test-downwardapi-mjjw no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-mjjw
Feb  7 18:25:44.402: INFO: Deleting pod "pod-subpath-test-downwardapi-mjjw" in namespace "e2e-tests-subpath-99znc"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:25:44.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-99znc" for this suite.
Feb  7 18:25:50.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:25:50.598: INFO: namespace: e2e-tests-subpath-99znc, resource: bindings, ignored listing per whitelist
Feb  7 18:25:50.611: INFO: namespace e2e-tests-subpath-99znc deletion completed in 6.189144526s

• [SLOW TEST:30.485 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:25:50.612: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-cbea5383-2b05-11e9-90f5-5e78944a5b53
STEP: Creating a pod to test consume secrets
Feb  7 18:25:50.772: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-cbeb8796-2b05-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-projected-zvrq6" to be "success or failure"
Feb  7 18:25:50.788: INFO: Pod "pod-projected-secrets-cbeb8796-2b05-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 15.804306ms
Feb  7 18:25:52.794: INFO: Pod "pod-projected-secrets-cbeb8796-2b05-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021490959s
STEP: Saw pod success
Feb  7 18:25:52.794: INFO: Pod "pod-projected-secrets-cbeb8796-2b05-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 18:25:52.798: INFO: Trying to get logs from node conformance0 pod pod-projected-secrets-cbeb8796-2b05-11e9-90f5-5e78944a5b53 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb  7 18:25:52.855: INFO: Waiting for pod pod-projected-secrets-cbeb8796-2b05-11e9-90f5-5e78944a5b53 to disappear
Feb  7 18:25:52.866: INFO: Pod pod-projected-secrets-cbeb8796-2b05-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:25:52.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zvrq6" for this suite.
Feb  7 18:25:58.894: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:25:58.980: INFO: namespace: e2e-tests-projected-zvrq6, resource: bindings, ignored listing per whitelist
Feb  7 18:25:59.045: INFO: namespace e2e-tests-projected-zvrq6 deletion completed in 6.173478683s

• [SLOW TEST:8.433 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:25:59.046: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb  7 18:25:59.201: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:26:03.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-rq8j5" for this suite.
Feb  7 18:26:25.162: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:26:25.243: INFO: namespace: e2e-tests-init-container-rq8j5, resource: bindings, ignored listing per whitelist
Feb  7 18:26:25.345: INFO: namespace e2e-tests-init-container-rq8j5 deletion completed in 22.204567872s

• [SLOW TEST:26.299 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:26:25.347: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Feb  7 18:26:25.485: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb  7 18:26:25.496: INFO: Waiting for terminating namespaces to be deleted...
Feb  7 18:26:25.501: INFO: 
Logging pods the kubelet thinks is on node conformance0 before test
Feb  7 18:26:25.513: INFO: sonobuoy-e2e-job-946df599e97f4154 from heptio-sonobuoy started at 2019-02-07 18:11:13 +0000 UTC (2 container statuses recorded)
Feb  7 18:26:25.513: INFO: 	Container e2e ready: true, restart count 0
Feb  7 18:26:25.513: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  7 18:26:25.513: INFO: nirmata-kube-controller-7bc4774558-hdvmg from nirmata started at 2019-02-07 17:59:05 +0000 UTC (1 container statuses recorded)
Feb  7 18:26:25.513: INFO: 	Container nirmata-kube-controller ready: true, restart count 0
Feb  7 18:26:25.513: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-07 18:11:07 +0000 UTC (1 container statuses recorded)
Feb  7 18:26:25.513: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb  7 18:26:25.513: INFO: ingress-default-backend-55c6dddf9b-bsb5j from ingress-haproxy started at 2019-02-07 17:59:13 +0000 UTC (1 container statuses recorded)
Feb  7 18:26:25.513: INFO: 	Container ingress-default-backend ready: true, restart count 0
Feb  7 18:26:25.513: INFO: sonobuoy-systemd-logs-daemon-set-0f8450d3236a4290-khwsz from heptio-sonobuoy started at 2019-02-07 18:11:13 +0000 UTC (2 container statuses recorded)
Feb  7 18:26:25.513: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb  7 18:26:25.513: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  7 18:26:25.513: INFO: haproxy-ingress-6cd7fb8fc-bswfw from ingress-haproxy started at 2019-02-07 17:59:13 +0000 UTC (1 container statuses recorded)
Feb  7 18:26:25.514: INFO: 	Container haproxy-ingress ready: true, restart count 0
Feb  7 18:26:25.514: INFO: metrics-server-58fd5b7956-55hhh from kube-system started at 2019-02-07 17:59:35 +0000 UTC (1 container statuses recorded)
Feb  7 18:26:25.514: INFO: 	Container metrics-server ready: true, restart count 0
Feb  7 18:26:25.514: INFO: kube-dns-6fbf99bd5-vln22 from kube-system started at 2019-02-07 17:59:05 +0000 UTC (3 container statuses recorded)
Feb  7 18:26:25.514: INFO: 	Container dnsmasq ready: true, restart count 0
Feb  7 18:26:25.514: INFO: 	Container kubedns ready: true, restart count 0
Feb  7 18:26:25.514: INFO: 	Container sidecar ready: true, restart count 0
Feb  7 18:26:25.514: INFO: nirmata-cni-installer-548lz from nirmata started at 2019-02-07 17:59:05 +0000 UTC (1 container statuses recorded)
Feb  7 18:26:25.514: INFO: 	Container install-cni ready: true, restart count 0
Feb  7 18:26:25.514: INFO: kube-flannel-ds-l2rpk from kube-system started at 2019-02-07 17:58:51 +0000 UTC (1 container statuses recorded)
Feb  7 18:26:25.514: INFO: 	Container kube-flannel ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-e30c02d0-2b05-11e9-90f5-5e78944a5b53 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-e30c02d0-2b05-11e9-90f5-5e78944a5b53 off the node conformance0
STEP: verifying the node doesn't have the label kubernetes.io/e2e-e30c02d0-2b05-11e9-90f5-5e78944a5b53
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:26:33.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-gtsqp" for this suite.
Feb  7 18:26:53.700: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:26:53.912: INFO: namespace: e2e-tests-sched-pred-gtsqp, resource: bindings, ignored listing per whitelist
Feb  7 18:26:53.931: INFO: namespace e2e-tests-sched-pred-gtsqp deletion completed in 20.247235749s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:28.585 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:26:53.932: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-f1ad41ec-2b05-11e9-90f5-5e78944a5b53
STEP: Creating a pod to test consume secrets
Feb  7 18:26:54.129: INFO: Waiting up to 5m0s for pod "pod-secrets-f1ae7b7d-2b05-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-secrets-9kz22" to be "success or failure"
Feb  7 18:26:54.163: INFO: Pod "pod-secrets-f1ae7b7d-2b05-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 34.019855ms
Feb  7 18:26:56.167: INFO: Pod "pod-secrets-f1ae7b7d-2b05-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.038632337s
STEP: Saw pod success
Feb  7 18:26:56.167: INFO: Pod "pod-secrets-f1ae7b7d-2b05-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 18:26:56.175: INFO: Trying to get logs from node conformance0 pod pod-secrets-f1ae7b7d-2b05-11e9-90f5-5e78944a5b53 container secret-volume-test: <nil>
STEP: delete the pod
Feb  7 18:26:56.207: INFO: Waiting for pod pod-secrets-f1ae7b7d-2b05-11e9-90f5-5e78944a5b53 to disappear
Feb  7 18:26:56.219: INFO: Pod pod-secrets-f1ae7b7d-2b05-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:26:56.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-9kz22" for this suite.
Feb  7 18:27:02.246: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:27:02.381: INFO: namespace: e2e-tests-secrets-9kz22, resource: bindings, ignored listing per whitelist
Feb  7 18:27:02.384: INFO: namespace e2e-tests-secrets-9kz22 deletion completed in 6.15959339s

• [SLOW TEST:8.453 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:27:02.385: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-cxvhl
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Feb  7 18:27:02.524: INFO: Found 0 stateful pods, waiting for 3
Feb  7 18:27:12.534: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb  7 18:27:12.535: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb  7 18:27:12.535: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Feb  7 18:27:12.550: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 exec --namespace=e2e-tests-statefulset-cxvhl ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  7 18:27:12.914: INFO: stderr: ""
Feb  7 18:27:12.914: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  7 18:27:12.914: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Feb  7 18:27:22.961: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Feb  7 18:27:32.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 exec --namespace=e2e-tests-statefulset-cxvhl ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  7 18:27:33.256: INFO: stderr: ""
Feb  7 18:27:33.256: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  7 18:27:33.256: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  7 18:27:53.285: INFO: Waiting for StatefulSet e2e-tests-statefulset-cxvhl/ss2 to complete update
STEP: Rolling back to a previous revision
Feb  7 18:28:03.294: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 exec --namespace=e2e-tests-statefulset-cxvhl ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  7 18:28:03.562: INFO: stderr: ""
Feb  7 18:28:03.562: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  7 18:28:03.562: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  7 18:28:13.607: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Feb  7 18:28:23.652: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 exec --namespace=e2e-tests-statefulset-cxvhl ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  7 18:28:23.906: INFO: stderr: ""
Feb  7 18:28:23.906: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  7 18:28:23.906: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb  7 18:28:43.953: INFO: Deleting all statefulset in ns e2e-tests-statefulset-cxvhl
Feb  7 18:28:43.958: INFO: Scaling statefulset ss2 to 0
Feb  7 18:29:14.003: INFO: Waiting for statefulset status.replicas updated to 0
Feb  7 18:29:14.008: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:29:14.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-cxvhl" for this suite.
Feb  7 18:29:22.064: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:29:22.155: INFO: namespace: e2e-tests-statefulset-cxvhl, resource: bindings, ignored listing per whitelist
Feb  7 18:29:22.219: INFO: namespace e2e-tests-statefulset-cxvhl deletion completed in 8.180266065s

• [SLOW TEST:139.835 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:29:22.220: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-szxkf/configmap-test-4a096fd5-2b06-11e9-90f5-5e78944a5b53
STEP: Creating a pod to test consume configMaps
Feb  7 18:29:22.363: INFO: Waiting up to 5m0s for pod "pod-configmaps-4a0a831f-2b06-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-configmap-szxkf" to be "success or failure"
Feb  7 18:29:22.368: INFO: Pod "pod-configmaps-4a0a831f-2b06-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 4.787081ms
Feb  7 18:29:24.373: INFO: Pod "pod-configmaps-4a0a831f-2b06-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009122131s
STEP: Saw pod success
Feb  7 18:29:24.373: INFO: Pod "pod-configmaps-4a0a831f-2b06-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 18:29:24.376: INFO: Trying to get logs from node conformance0 pod pod-configmaps-4a0a831f-2b06-11e9-90f5-5e78944a5b53 container env-test: <nil>
STEP: delete the pod
Feb  7 18:29:24.424: INFO: Waiting for pod pod-configmaps-4a0a831f-2b06-11e9-90f5-5e78944a5b53 to disappear
Feb  7 18:29:24.434: INFO: Pod pod-configmaps-4a0a831f-2b06-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:29:24.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-szxkf" for this suite.
Feb  7 18:29:30.462: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:29:30.516: INFO: namespace: e2e-tests-configmap-szxkf, resource: bindings, ignored listing per whitelist
Feb  7 18:29:30.621: INFO: namespace e2e-tests-configmap-szxkf deletion completed in 6.177358854s

• [SLOW TEST:8.401 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:29:30.621: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb  7 18:29:30.813: INFO: Waiting up to 5m0s for pod "pod-4f139f6b-2b06-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-emptydir-km4sr" to be "success or failure"
Feb  7 18:29:30.822: INFO: Pod "pod-4f139f6b-2b06-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 9.32597ms
Feb  7 18:29:32.827: INFO: Pod "pod-4f139f6b-2b06-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013630235s
Feb  7 18:29:34.831: INFO: Pod "pod-4f139f6b-2b06-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017892054s
STEP: Saw pod success
Feb  7 18:29:34.831: INFO: Pod "pod-4f139f6b-2b06-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 18:29:34.836: INFO: Trying to get logs from node conformance0 pod pod-4f139f6b-2b06-11e9-90f5-5e78944a5b53 container test-container: <nil>
STEP: delete the pod
Feb  7 18:29:34.873: INFO: Waiting for pod pod-4f139f6b-2b06-11e9-90f5-5e78944a5b53 to disappear
Feb  7 18:29:34.884: INFO: Pod pod-4f139f6b-2b06-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:29:34.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-km4sr" for this suite.
Feb  7 18:29:40.911: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:29:40.940: INFO: namespace: e2e-tests-emptydir-km4sr, resource: bindings, ignored listing per whitelist
Feb  7 18:29:41.067: INFO: namespace e2e-tests-emptydir-km4sr deletion completed in 6.173935697s

• [SLOW TEST:10.446 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:29:41.068: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Feb  7 18:29:43.239: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-55440a80-2b06-11e9-90f5-5e78944a5b53", GenerateName:"", Namespace:"e2e-tests-pods-n5jlr", SelfLink:"/api/v1/namespaces/e2e-tests-pods-n5jlr/pods/pod-submit-remove-55440a80-2b06-11e9-90f5-5e78944a5b53", UID:"5545e365-2b06-11e9-a946-ceb99be2323d", ResourceVersion:"2965", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63685160981, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"183155194"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-6m8mg", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc002781ac0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-6m8mg", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc00178ee08), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"conformance0", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc000705860), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00178ee50)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00178ee70)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc00178ee78), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00178ee7c)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685160981, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685160983, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685160983, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685160981, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.10.1.212", PodIP:"10.244.0.76", StartTime:(*v1.Time)(0xc000fd6fa0), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc000fd6fc0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632", ContainerID:"docker://e564a26f63ad337a7d9a49a9d07aa53c61e13c29d3c5eb1beb74d6b9509c2b0a"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:29:48.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-n5jlr" for this suite.
Feb  7 18:29:54.761: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:29:54.872: INFO: namespace: e2e-tests-pods-n5jlr, resource: bindings, ignored listing per whitelist
Feb  7 18:29:55.004: INFO: namespace e2e-tests-pods-n5jlr deletion completed in 6.264690403s

• [SLOW TEST:13.937 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:29:55.005: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-5d9cab6f-2b06-11e9-90f5-5e78944a5b53
STEP: Creating configMap with name cm-test-opt-upd-5d9cac06-2b06-11e9-90f5-5e78944a5b53
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-5d9cab6f-2b06-11e9-90f5-5e78944a5b53
STEP: Updating configmap cm-test-opt-upd-5d9cac06-2b06-11e9-90f5-5e78944a5b53
STEP: Creating configMap with name cm-test-opt-create-5d9cac8d-2b06-11e9-90f5-5e78944a5b53
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:31:22.005: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-nplb4" for this suite.
Feb  7 18:31:46.037: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:31:46.107: INFO: namespace: e2e-tests-configmap-nplb4, resource: bindings, ignored listing per whitelist
Feb  7 18:31:46.227: INFO: namespace e2e-tests-configmap-nplb4 deletion completed in 24.215414943s

• [SLOW TEST:111.222 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:31:46.228: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:31:59.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-g4k6k" for this suite.
Feb  7 18:32:21.468: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:32:21.572: INFO: namespace: e2e-tests-replication-controller-g4k6k, resource: bindings, ignored listing per whitelist
Feb  7 18:32:21.638: INFO: namespace e2e-tests-replication-controller-g4k6k deletion completed in 22.197281241s

• [SLOW TEST:35.410 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:32:21.638: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb  7 18:32:29.934: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  7 18:32:29.940: INFO: Pod pod-with-poststart-http-hook still exists
Feb  7 18:32:31.941: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  7 18:32:31.946: INFO: Pod pod-with-poststart-http-hook still exists
Feb  7 18:32:33.941: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  7 18:32:33.948: INFO: Pod pod-with-poststart-http-hook still exists
Feb  7 18:32:35.941: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  7 18:32:35.946: INFO: Pod pod-with-poststart-http-hook still exists
Feb  7 18:32:37.941: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  7 18:32:37.947: INFO: Pod pod-with-poststart-http-hook still exists
Feb  7 18:32:39.941: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  7 18:32:39.946: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:32:39.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-zq5zt" for this suite.
Feb  7 18:32:53.969: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:32:54.124: INFO: namespace: e2e-tests-container-lifecycle-hook-zq5zt, resource: bindings, ignored listing per whitelist
Feb  7 18:32:54.180: INFO: namespace e2e-tests-container-lifecycle-hook-zq5zt deletion completed in 14.227050907s

• [SLOW TEST:32.542 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:32:54.180: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-9b99w
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-9b99w to expose endpoints map[]
Feb  7 18:32:54.331: INFO: Get endpoints failed (5.222091ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Feb  7 18:32:55.335: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-9b99w exposes endpoints map[] (1.009363484s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-9b99w
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-9b99w to expose endpoints map[pod1:[80]]
Feb  7 18:32:57.395: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-9b99w exposes endpoints map[pod1:[80]] (2.042562365s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-9b99w
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-9b99w to expose endpoints map[pod1:[80] pod2:[80]]
Feb  7 18:32:59.479: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-9b99w exposes endpoints map[pod1:[80] pod2:[80]] (2.071443253s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-9b99w
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-9b99w to expose endpoints map[pod2:[80]]
Feb  7 18:33:00.540: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-9b99w exposes endpoints map[pod2:[80]] (1.052551043s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-9b99w
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-9b99w to expose endpoints map[]
Feb  7 18:33:00.574: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-9b99w exposes endpoints map[] (16.328969ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:33:00.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-9b99w" for this suite.
Feb  7 18:33:06.645: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:33:06.734: INFO: namespace: e2e-tests-services-9b99w, resource: bindings, ignored listing per whitelist
Feb  7 18:33:06.843: INFO: namespace e2e-tests-services-9b99w deletion completed in 6.217294172s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:12.663 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:33:06.844: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1134
STEP: creating an rc
Feb  7 18:33:06.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 create -f - --namespace=e2e-tests-kubectl-tq4rf'
Feb  7 18:33:07.645: INFO: stderr: ""
Feb  7 18:33:07.645: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Feb  7 18:33:08.649: INFO: Selector matched 1 pods for map[app:redis]
Feb  7 18:33:08.649: INFO: Found 0 / 1
Feb  7 18:33:09.650: INFO: Selector matched 1 pods for map[app:redis]
Feb  7 18:33:09.650: INFO: Found 0 / 1
Feb  7 18:33:10.651: INFO: Selector matched 1 pods for map[app:redis]
Feb  7 18:33:10.651: INFO: Found 1 / 1
Feb  7 18:33:10.651: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb  7 18:33:10.658: INFO: Selector matched 1 pods for map[app:redis]
Feb  7 18:33:10.658: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Feb  7 18:33:10.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 logs redis-master-7zntk redis-master --namespace=e2e-tests-kubectl-tq4rf'
Feb  7 18:33:10.839: INFO: stderr: ""
Feb  7 18:33:10.839: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 07 Feb 18:33:10.015 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 07 Feb 18:33:10.015 # Server started, Redis version 3.2.12\n1:M 07 Feb 18:33:10.015 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 07 Feb 18:33:10.015 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Feb  7 18:33:10.839: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 log redis-master-7zntk redis-master --namespace=e2e-tests-kubectl-tq4rf --tail=1'
Feb  7 18:33:11.034: INFO: stderr: ""
Feb  7 18:33:11.034: INFO: stdout: "1:M 07 Feb 18:33:10.015 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Feb  7 18:33:11.034: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 log redis-master-7zntk redis-master --namespace=e2e-tests-kubectl-tq4rf --limit-bytes=1'
Feb  7 18:33:11.243: INFO: stderr: ""
Feb  7 18:33:11.243: INFO: stdout: " "
STEP: exposing timestamps
Feb  7 18:33:11.244: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 log redis-master-7zntk redis-master --namespace=e2e-tests-kubectl-tq4rf --tail=1 --timestamps'
Feb  7 18:33:11.433: INFO: stderr: ""
Feb  7 18:33:11.433: INFO: stdout: "2019-02-07T18:33:10.024307582Z 1:M 07 Feb 18:33:10.015 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Feb  7 18:33:13.934: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 log redis-master-7zntk redis-master --namespace=e2e-tests-kubectl-tq4rf --since=1s'
Feb  7 18:33:14.108: INFO: stderr: ""
Feb  7 18:33:14.108: INFO: stdout: ""
Feb  7 18:33:14.108: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 log redis-master-7zntk redis-master --namespace=e2e-tests-kubectl-tq4rf --since=24h'
Feb  7 18:33:14.301: INFO: stderr: ""
Feb  7 18:33:14.301: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 07 Feb 18:33:10.015 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 07 Feb 18:33:10.015 # Server started, Redis version 3.2.12\n1:M 07 Feb 18:33:10.015 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 07 Feb 18:33:10.015 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1140
STEP: using delete to clean up resources
Feb  7 18:33:14.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-tq4rf'
Feb  7 18:33:14.457: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  7 18:33:14.457: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Feb  7 18:33:14.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-tq4rf'
Feb  7 18:33:14.669: INFO: stderr: "No resources found.\n"
Feb  7 18:33:14.669: INFO: stdout: ""
Feb  7 18:33:14.669: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 get pods -l name=nginx --namespace=e2e-tests-kubectl-tq4rf -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb  7 18:33:14.853: INFO: stderr: ""
Feb  7 18:33:14.853: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:33:14.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-tq4rf" for this suite.
Feb  7 18:33:20.887: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:33:20.958: INFO: namespace: e2e-tests-kubectl-tq4rf, resource: bindings, ignored listing per whitelist
Feb  7 18:33:21.051: INFO: namespace e2e-tests-kubectl-tq4rf deletion completed in 6.192439586s

• [SLOW TEST:14.207 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:33:21.052: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  7 18:33:21.188: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d864814a-2b06-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-downward-api-f622s" to be "success or failure"
Feb  7 18:33:21.200: INFO: Pod "downwardapi-volume-d864814a-2b06-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 11.594591ms
Feb  7 18:33:23.204: INFO: Pod "downwardapi-volume-d864814a-2b06-11e9-90f5-5e78944a5b53": Phase="Running", Reason="", readiness=true. Elapsed: 2.01554373s
Feb  7 18:33:25.209: INFO: Pod "downwardapi-volume-d864814a-2b06-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020350153s
STEP: Saw pod success
Feb  7 18:33:25.209: INFO: Pod "downwardapi-volume-d864814a-2b06-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 18:33:25.215: INFO: Trying to get logs from node conformance0 pod downwardapi-volume-d864814a-2b06-11e9-90f5-5e78944a5b53 container client-container: <nil>
STEP: delete the pod
Feb  7 18:33:25.262: INFO: Waiting for pod downwardapi-volume-d864814a-2b06-11e9-90f5-5e78944a5b53 to disappear
Feb  7 18:33:25.272: INFO: Pod downwardapi-volume-d864814a-2b06-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:33:25.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-f622s" for this suite.
Feb  7 18:33:31.298: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:33:31.342: INFO: namespace: e2e-tests-downward-api-f622s, resource: bindings, ignored listing per whitelist
Feb  7 18:33:31.466: INFO: namespace e2e-tests-downward-api-f622s deletion completed in 6.186034781s

• [SLOW TEST:10.414 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:33:31.467: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb  7 18:33:31.592: INFO: Waiting up to 5m0s for pod "downward-api-de97d013-2b06-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-downward-api-hsmbn" to be "success or failure"
Feb  7 18:33:31.600: INFO: Pod "downward-api-de97d013-2b06-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 8.686475ms
Feb  7 18:33:33.605: INFO: Pod "downward-api-de97d013-2b06-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013480426s
STEP: Saw pod success
Feb  7 18:33:33.605: INFO: Pod "downward-api-de97d013-2b06-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 18:33:33.609: INFO: Trying to get logs from node conformance0 pod downward-api-de97d013-2b06-11e9-90f5-5e78944a5b53 container dapi-container: <nil>
STEP: delete the pod
Feb  7 18:33:33.653: INFO: Waiting for pod downward-api-de97d013-2b06-11e9-90f5-5e78944a5b53 to disappear
Feb  7 18:33:33.658: INFO: Pod downward-api-de97d013-2b06-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:33:33.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-hsmbn" for this suite.
Feb  7 18:33:39.678: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:33:39.727: INFO: namespace: e2e-tests-downward-api-hsmbn, resource: bindings, ignored listing per whitelist
Feb  7 18:33:39.835: INFO: namespace e2e-tests-downward-api-hsmbn deletion completed in 6.172255075s

• [SLOW TEST:8.369 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:33:39.836: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb  7 18:33:39.970: INFO: Waiting up to 5m0s for pod "pod-e395823d-2b06-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-emptydir-hgmch" to be "success or failure"
Feb  7 18:33:39.980: INFO: Pod "pod-e395823d-2b06-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 10.312143ms
Feb  7 18:33:41.985: INFO: Pod "pod-e395823d-2b06-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015401143s
STEP: Saw pod success
Feb  7 18:33:41.985: INFO: Pod "pod-e395823d-2b06-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 18:33:41.990: INFO: Trying to get logs from node conformance0 pod pod-e395823d-2b06-11e9-90f5-5e78944a5b53 container test-container: <nil>
STEP: delete the pod
Feb  7 18:33:42.018: INFO: Waiting for pod pod-e395823d-2b06-11e9-90f5-5e78944a5b53 to disappear
Feb  7 18:33:42.036: INFO: Pod pod-e395823d-2b06-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:33:42.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-hgmch" for this suite.
Feb  7 18:33:48.060: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:33:48.096: INFO: namespace: e2e-tests-emptydir-hgmch, resource: bindings, ignored listing per whitelist
Feb  7 18:33:48.200: INFO: namespace e2e-tests-emptydir-hgmch deletion completed in 6.15775802s

• [SLOW TEST:8.365 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:33:48.201: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:34:48.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-r6jcg" for this suite.
Feb  7 18:35:10.403: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:35:10.463: INFO: namespace: e2e-tests-container-probe-r6jcg, resource: bindings, ignored listing per whitelist
Feb  7 18:35:10.547: INFO: namespace e2e-tests-container-probe-r6jcg deletion completed in 22.160104721s

• [SLOW TEST:82.346 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:35:10.548: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb  7 18:35:10.667: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-s6fxr'
Feb  7 18:35:10.854: INFO: stderr: ""
Feb  7 18:35:10.854: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Feb  7 18:35:15.905: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-s6fxr -o json'
Feb  7 18:35:16.046: INFO: stderr: ""
Feb  7 18:35:16.046: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-02-07T18:35:10Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-s6fxr\",\n        \"resourceVersion\": \"3420\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-s6fxr/pods/e2e-test-nginx-pod\",\n        \"uid\": \"19bfd408-2b07-11e9-a946-ceb99be2323d\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-wdw7m\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"conformance0\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-wdw7m\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-wdw7m\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-07T18:35:10Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-07T18:35:13Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-07T18:35:13Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-07T18:35:10Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://e3be9d64348af9498706a02a24ecff2a6815837f325b607ecf3c3b7be113cc42\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-02-07T18:35:12Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.10.1.212\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.244.0.88\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-02-07T18:35:10Z\"\n    }\n}\n"
STEP: replace the image in the pod
Feb  7 18:35:16.046: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 replace -f - --namespace=e2e-tests-kubectl-s6fxr'
Feb  7 18:35:16.435: INFO: stderr: ""
Feb  7 18:35:16.435: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
Feb  7 18:35:16.442: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-s6fxr'
Feb  7 18:35:19.980: INFO: stderr: ""
Feb  7 18:35:19.980: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:35:19.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-s6fxr" for this suite.
Feb  7 18:35:26.017: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:35:26.184: INFO: namespace: e2e-tests-kubectl-s6fxr, resource: bindings, ignored listing per whitelist
Feb  7 18:35:26.208: INFO: namespace e2e-tests-kubectl-s6fxr deletion completed in 6.220580639s

• [SLOW TEST:15.660 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:35:26.209: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-s2mr9
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb  7 18:35:26.346: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb  7 18:35:42.445: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.0.90:8080/dial?request=hostName&protocol=http&host=10.244.0.89&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-s2mr9 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  7 18:35:42.445: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
Feb  7 18:35:42.567: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:35:42.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-s2mr9" for this suite.
Feb  7 18:36:06.590: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:36:06.703: INFO: namespace: e2e-tests-pod-network-test-s2mr9, resource: bindings, ignored listing per whitelist
Feb  7 18:36:06.789: INFO: namespace e2e-tests-pod-network-test-s2mr9 deletion completed in 24.217082262s

• [SLOW TEST:40.580 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:36:06.790: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  7 18:36:06.918: INFO: (0) /api/v1/nodes/conformance0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 7.519395ms)
Feb  7 18:36:06.926: INFO: (1) /api/v1/nodes/conformance0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 7.797509ms)
Feb  7 18:36:06.933: INFO: (2) /api/v1/nodes/conformance0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 6.691981ms)
Feb  7 18:36:06.946: INFO: (3) /api/v1/nodes/conformance0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 13.379829ms)
Feb  7 18:36:06.965: INFO: (4) /api/v1/nodes/conformance0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 18.973214ms)
Feb  7 18:36:06.974: INFO: (5) /api/v1/nodes/conformance0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 8.368846ms)
Feb  7 18:36:06.991: INFO: (6) /api/v1/nodes/conformance0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 16.872137ms)
Feb  7 18:36:07.005: INFO: (7) /api/v1/nodes/conformance0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 14.535922ms)
Feb  7 18:36:07.013: INFO: (8) /api/v1/nodes/conformance0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 7.90729ms)
Feb  7 18:36:07.020: INFO: (9) /api/v1/nodes/conformance0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 7.038174ms)
Feb  7 18:36:07.030: INFO: (10) /api/v1/nodes/conformance0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 9.920516ms)
Feb  7 18:36:07.036: INFO: (11) /api/v1/nodes/conformance0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 5.32613ms)
Feb  7 18:36:07.043: INFO: (12) /api/v1/nodes/conformance0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 6.537372ms)
Feb  7 18:36:07.053: INFO: (13) /api/v1/nodes/conformance0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 6.289298ms)
Feb  7 18:36:07.059: INFO: (14) /api/v1/nodes/conformance0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 5.803913ms)
Feb  7 18:36:07.065: INFO: (15) /api/v1/nodes/conformance0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 5.929011ms)
Feb  7 18:36:07.070: INFO: (16) /api/v1/nodes/conformance0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 5.469616ms)
Feb  7 18:36:07.077: INFO: (17) /api/v1/nodes/conformance0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 6.624835ms)
Feb  7 18:36:07.084: INFO: (18) /api/v1/nodes/conformance0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 6.46532ms)
Feb  7 18:36:07.091: INFO: (19) /api/v1/nodes/conformance0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 7.285136ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:36:07.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-5v6xc" for this suite.
Feb  7 18:36:13.113: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:36:13.182: INFO: namespace: e2e-tests-proxy-5v6xc, resource: bindings, ignored listing per whitelist
Feb  7 18:36:13.294: INFO: namespace e2e-tests-proxy-5v6xc deletion completed in 6.197819864s

• [SLOW TEST:6.504 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:36:13.295: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  7 18:36:13.428: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3f0d8592-2b07-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-projected-glbp6" to be "success or failure"
Feb  7 18:36:13.433: INFO: Pod "downwardapi-volume-3f0d8592-2b07-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 5.643407ms
Feb  7 18:36:15.439: INFO: Pod "downwardapi-volume-3f0d8592-2b07-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011677085s
STEP: Saw pod success
Feb  7 18:36:15.440: INFO: Pod "downwardapi-volume-3f0d8592-2b07-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 18:36:15.450: INFO: Trying to get logs from node conformance0 pod downwardapi-volume-3f0d8592-2b07-11e9-90f5-5e78944a5b53 container client-container: <nil>
STEP: delete the pod
Feb  7 18:36:15.510: INFO: Waiting for pod downwardapi-volume-3f0d8592-2b07-11e9-90f5-5e78944a5b53 to disappear
Feb  7 18:36:15.525: INFO: Pod downwardapi-volume-3f0d8592-2b07-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:36:15.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-glbp6" for this suite.
Feb  7 18:36:21.556: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:36:21.677: INFO: namespace: e2e-tests-projected-glbp6, resource: bindings, ignored listing per whitelist
Feb  7 18:36:21.739: INFO: namespace e2e-tests-projected-glbp6 deletion completed in 6.205195677s

• [SLOW TEST:8.444 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:36:21.740: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-6r2wq
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-6r2wq
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-6r2wq
Feb  7 18:36:21.903: INFO: Found 0 stateful pods, waiting for 1
Feb  7 18:36:31.908: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Feb  7 18:36:31.915: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 exec --namespace=e2e-tests-statefulset-6r2wq ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  7 18:36:32.184: INFO: stderr: ""
Feb  7 18:36:32.184: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  7 18:36:32.184: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  7 18:36:32.189: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb  7 18:36:42.195: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb  7 18:36:42.195: INFO: Waiting for statefulset status.replicas updated to 0
Feb  7 18:36:42.219: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999996499s
Feb  7 18:36:43.224: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.994141918s
Feb  7 18:36:44.230: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.988535294s
Feb  7 18:36:45.235: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.983171528s
Feb  7 18:36:46.241: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.978518055s
Feb  7 18:36:47.246: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.972339685s
Feb  7 18:36:48.251: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.967499909s
Feb  7 18:36:49.256: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.961722982s
Feb  7 18:36:50.262: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.956623822s
Feb  7 18:36:51.267: INFO: Verifying statefulset ss doesn't scale past 1 for another 950.79198ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-6r2wq
Feb  7 18:36:52.275: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 exec --namespace=e2e-tests-statefulset-6r2wq ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  7 18:36:52.592: INFO: stderr: ""
Feb  7 18:36:52.592: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  7 18:36:52.592: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  7 18:36:52.597: INFO: Found 1 stateful pods, waiting for 3
Feb  7 18:37:02.602: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb  7 18:37:02.602: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb  7 18:37:02.602: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Feb  7 18:37:02.613: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 exec --namespace=e2e-tests-statefulset-6r2wq ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  7 18:37:02.893: INFO: stderr: ""
Feb  7 18:37:02.893: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  7 18:37:02.893: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  7 18:37:02.893: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 exec --namespace=e2e-tests-statefulset-6r2wq ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  7 18:37:03.173: INFO: stderr: ""
Feb  7 18:37:03.173: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  7 18:37:03.173: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  7 18:37:03.173: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 exec --namespace=e2e-tests-statefulset-6r2wq ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  7 18:37:03.495: INFO: stderr: ""
Feb  7 18:37:03.495: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  7 18:37:03.495: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  7 18:37:03.495: INFO: Waiting for statefulset status.replicas updated to 0
Feb  7 18:37:03.500: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Feb  7 18:37:13.511: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb  7 18:37:13.511: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb  7 18:37:13.511: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb  7 18:37:13.535: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999996644s
Feb  7 18:37:14.548: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.991205699s
Feb  7 18:37:15.596: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.97900135s
Feb  7 18:37:16.601: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.930835512s
Feb  7 18:37:17.609: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.924820159s
Feb  7 18:37:18.615: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.917630367s
Feb  7 18:37:19.620: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.911887634s
Feb  7 18:37:20.626: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.906519102s
Feb  7 18:37:21.632: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.900721993s
Feb  7 18:37:22.637: INFO: Verifying statefulset ss doesn't scale past 3 for another 894.933053ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-6r2wq
Feb  7 18:37:23.645: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 exec --namespace=e2e-tests-statefulset-6r2wq ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  7 18:37:23.945: INFO: stderr: ""
Feb  7 18:37:23.945: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  7 18:37:23.945: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  7 18:37:23.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 exec --namespace=e2e-tests-statefulset-6r2wq ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  7 18:37:24.234: INFO: stderr: ""
Feb  7 18:37:24.234: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  7 18:37:24.234: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  7 18:37:24.234: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 exec --namespace=e2e-tests-statefulset-6r2wq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  7 18:37:24.554: INFO: stderr: ""
Feb  7 18:37:24.554: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  7 18:37:24.554: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  7 18:37:24.554: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb  7 18:37:54.578: INFO: Deleting all statefulset in ns e2e-tests-statefulset-6r2wq
Feb  7 18:37:54.583: INFO: Scaling statefulset ss to 0
Feb  7 18:37:54.600: INFO: Waiting for statefulset status.replicas updated to 0
Feb  7 18:37:54.605: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:37:54.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-6r2wq" for this suite.
Feb  7 18:38:00.651: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:38:00.769: INFO: namespace: e2e-tests-statefulset-6r2wq, resource: bindings, ignored listing per whitelist
Feb  7 18:38:00.829: INFO: namespace e2e-tests-statefulset-6r2wq deletion completed in 6.196291531s

• [SLOW TEST:99.090 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:38:00.830: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-7f2448e3-2b07-11e9-90f5-5e78944a5b53
STEP: Creating a pod to test consume secrets
Feb  7 18:38:00.951: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7f250766-2b07-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-projected-7pmsb" to be "success or failure"
Feb  7 18:38:00.962: INFO: Pod "pod-projected-secrets-7f250766-2b07-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 10.386462ms
Feb  7 18:38:02.969: INFO: Pod "pod-projected-secrets-7f250766-2b07-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01715187s
STEP: Saw pod success
Feb  7 18:38:02.969: INFO: Pod "pod-projected-secrets-7f250766-2b07-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 18:38:02.972: INFO: Trying to get logs from node conformance0 pod pod-projected-secrets-7f250766-2b07-11e9-90f5-5e78944a5b53 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb  7 18:38:03.028: INFO: Waiting for pod pod-projected-secrets-7f250766-2b07-11e9-90f5-5e78944a5b53 to disappear
Feb  7 18:38:03.038: INFO: Pod pod-projected-secrets-7f250766-2b07-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:38:03.038: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7pmsb" for this suite.
Feb  7 18:38:09.059: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:38:09.111: INFO: namespace: e2e-tests-projected-7pmsb, resource: bindings, ignored listing per whitelist
Feb  7 18:38:09.209: INFO: namespace e2e-tests-projected-7pmsb deletion completed in 6.165226887s

• [SLOW TEST:8.379 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:38:09.209: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-7h8l4
I0207 18:38:09.339151      15 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-7h8l4, replica count: 1
I0207 18:38:10.389744      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0207 18:38:11.390151      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb  7 18:38:11.516: INFO: Created: latency-svc-nbtgn
Feb  7 18:38:11.546: INFO: Got endpoints: latency-svc-nbtgn [54.961017ms]
Feb  7 18:38:11.600: INFO: Created: latency-svc-th9n4
Feb  7 18:38:11.632: INFO: Got endpoints: latency-svc-th9n4 [85.550014ms]
Feb  7 18:38:11.633: INFO: Created: latency-svc-zzxpt
Feb  7 18:38:11.634: INFO: Created: latency-svc-b9ztf
Feb  7 18:38:11.635: INFO: Created: latency-svc-xmhpm
Feb  7 18:38:11.637: INFO: Got endpoints: latency-svc-b9ztf [89.759439ms]
Feb  7 18:38:11.638: INFO: Got endpoints: latency-svc-zzxpt [90.430918ms]
Feb  7 18:38:11.660: INFO: Got endpoints: latency-svc-xmhpm [111.68249ms]
Feb  7 18:38:11.672: INFO: Created: latency-svc-9mpt7
Feb  7 18:38:11.672: INFO: Got endpoints: latency-svc-9mpt7 [123.554858ms]
Feb  7 18:38:11.683: INFO: Created: latency-svc-sl5pb
Feb  7 18:38:11.690: INFO: Got endpoints: latency-svc-sl5pb [141.990845ms]
Feb  7 18:38:11.695: INFO: Created: latency-svc-29nlz
Feb  7 18:38:11.716: INFO: Got endpoints: latency-svc-29nlz [167.883436ms]
Feb  7 18:38:11.721: INFO: Created: latency-svc-smmmt
Feb  7 18:38:11.729: INFO: Created: latency-svc-qw6ck
Feb  7 18:38:11.742: INFO: Got endpoints: latency-svc-smmmt [193.174189ms]
Feb  7 18:38:11.744: INFO: Got endpoints: latency-svc-qw6ck [53.808151ms]
Feb  7 18:38:11.754: INFO: Created: latency-svc-8wgfq
Feb  7 18:38:11.766: INFO: Created: latency-svc-wnpss
Feb  7 18:38:11.780: INFO: Got endpoints: latency-svc-8wgfq [231.014553ms]
Feb  7 18:38:11.787: INFO: Created: latency-svc-kfwjw
Feb  7 18:38:11.789: INFO: Got endpoints: latency-svc-wnpss [239.566821ms]
Feb  7 18:38:11.811: INFO: Got endpoints: latency-svc-kfwjw [261.377831ms]
Feb  7 18:38:11.840: INFO: Created: latency-svc-hqfr6
Feb  7 18:38:11.865: INFO: Got endpoints: latency-svc-hqfr6 [314.859384ms]
Feb  7 18:38:11.872: INFO: Created: latency-svc-q7tzt
Feb  7 18:38:11.892: INFO: Created: latency-svc-wcrmh
Feb  7 18:38:11.900: INFO: Got endpoints: latency-svc-q7tzt [350.452666ms]
Feb  7 18:38:11.902: INFO: Created: latency-svc-knxrs
Feb  7 18:38:11.902: INFO: Got endpoints: latency-svc-knxrs [351.452272ms]
Feb  7 18:38:11.920: INFO: Created: latency-svc-lps92
Feb  7 18:38:11.924: INFO: Got endpoints: latency-svc-wcrmh [372.62054ms]
Feb  7 18:38:11.934: INFO: Got endpoints: latency-svc-lps92 [296.649478ms]
Feb  7 18:38:11.945: INFO: Created: latency-svc-dhkbq
Feb  7 18:38:11.968: INFO: Got endpoints: latency-svc-dhkbq [335.526157ms]
Feb  7 18:38:11.972: INFO: Created: latency-svc-6mbpg
Feb  7 18:38:11.988: INFO: Created: latency-svc-r7mc6
Feb  7 18:38:11.996: INFO: Got endpoints: latency-svc-6mbpg [336.673802ms]
Feb  7 18:38:12.003: INFO: Got endpoints: latency-svc-r7mc6 [365.448761ms]
Feb  7 18:38:12.008: INFO: Created: latency-svc-22mbz
Feb  7 18:38:12.024: INFO: Created: latency-svc-9dzjg
Feb  7 18:38:12.032: INFO: Got endpoints: latency-svc-22mbz [360.62039ms]
Feb  7 18:38:12.047: INFO: Got endpoints: latency-svc-9dzjg [329.892498ms]
Feb  7 18:38:12.060: INFO: Created: latency-svc-vbcn9
Feb  7 18:38:12.072: INFO: Got endpoints: latency-svc-vbcn9 [329.677149ms]
Feb  7 18:38:12.097: INFO: Created: latency-svc-l4rgq
Feb  7 18:38:12.100: INFO: Created: latency-svc-jcn2n
Feb  7 18:38:12.125: INFO: Created: latency-svc-dc58s
Feb  7 18:38:12.129: INFO: Got endpoints: latency-svc-l4rgq [348.612032ms]
Feb  7 18:38:12.129: INFO: Got endpoints: latency-svc-jcn2n [384.416011ms]
Feb  7 18:38:12.182: INFO: Created: latency-svc-bfdbr
Feb  7 18:38:12.198: INFO: Got endpoints: latency-svc-dc58s [409.157019ms]
Feb  7 18:38:12.230: INFO: Got endpoints: latency-svc-bfdbr [419.035732ms]
Feb  7 18:38:12.243: INFO: Created: latency-svc-wzq22
Feb  7 18:38:12.255: INFO: Got endpoints: latency-svc-wzq22 [390.211653ms]
Feb  7 18:38:12.270: INFO: Created: latency-svc-sczsp
Feb  7 18:38:12.308: INFO: Got endpoints: latency-svc-sczsp [407.810664ms]
Feb  7 18:38:12.311: INFO: Created: latency-svc-nh8rs
Feb  7 18:38:12.312: INFO: Created: latency-svc-hw6j8
Feb  7 18:38:12.325: INFO: Got endpoints: latency-svc-nh8rs [423.033555ms]
Feb  7 18:38:12.334: INFO: Got endpoints: latency-svc-hw6j8 [410.197437ms]
Feb  7 18:38:12.339: INFO: Created: latency-svc-pz4dq
Feb  7 18:38:12.379: INFO: Got endpoints: latency-svc-pz4dq [444.237738ms]
Feb  7 18:38:12.380: INFO: Created: latency-svc-4wd9r
Feb  7 18:38:12.390: INFO: Created: latency-svc-lhr4q
Feb  7 18:38:12.393: INFO: Got endpoints: latency-svc-4wd9r [424.877162ms]
Feb  7 18:38:12.405: INFO: Created: latency-svc-x5x4v
Feb  7 18:38:12.422: INFO: Got endpoints: latency-svc-x5x4v [418.693118ms]
Feb  7 18:38:12.436: INFO: Got endpoints: latency-svc-lhr4q [439.251458ms]
Feb  7 18:38:12.440: INFO: Created: latency-svc-q55ph
Feb  7 18:38:12.450: INFO: Created: latency-svc-z9bnb
Feb  7 18:38:12.474: INFO: Got endpoints: latency-svc-q55ph [441.829688ms]
Feb  7 18:38:12.476: INFO: Created: latency-svc-24hd2
Feb  7 18:38:12.485: INFO: Got endpoints: latency-svc-z9bnb [438.468645ms]
Feb  7 18:38:12.493: INFO: Created: latency-svc-sfl2n
Feb  7 18:38:12.507: INFO: Got endpoints: latency-svc-24hd2 [435.321481ms]
Feb  7 18:38:12.514: INFO: Created: latency-svc-hdzd7
Feb  7 18:38:12.525: INFO: Got endpoints: latency-svc-sfl2n [395.762563ms]
Feb  7 18:38:12.538: INFO: Got endpoints: latency-svc-hdzd7 [408.62831ms]
Feb  7 18:38:12.549: INFO: Created: latency-svc-z7wdk
Feb  7 18:38:12.567: INFO: Created: latency-svc-dwmsh
Feb  7 18:38:12.583: INFO: Got endpoints: latency-svc-z7wdk [385.247737ms]
Feb  7 18:38:12.588: INFO: Created: latency-svc-v6hm6
Feb  7 18:38:12.604: INFO: Created: latency-svc-fpm59
Feb  7 18:38:12.612: INFO: Got endpoints: latency-svc-dwmsh [381.557654ms]
Feb  7 18:38:12.612: INFO: Got endpoints: latency-svc-v6hm6 [356.361602ms]
Feb  7 18:38:12.630: INFO: Created: latency-svc-k4trd
Feb  7 18:38:12.639: INFO: Got endpoints: latency-svc-k4trd [314.607233ms]
Feb  7 18:38:12.640: INFO: Got endpoints: latency-svc-fpm59 [331.640615ms]
Feb  7 18:38:12.652: INFO: Created: latency-svc-877qw
Feb  7 18:38:12.665: INFO: Got endpoints: latency-svc-877qw [330.576487ms]
Feb  7 18:38:12.672: INFO: Created: latency-svc-wfl9j
Feb  7 18:38:12.683: INFO: Created: latency-svc-nzsdf
Feb  7 18:38:12.724: INFO: Got endpoints: latency-svc-nzsdf [331.367363ms]
Feb  7 18:38:12.724: INFO: Got endpoints: latency-svc-wfl9j [345.832209ms]
Feb  7 18:38:12.730: INFO: Created: latency-svc-mkwrn
Feb  7 18:38:12.742: INFO: Created: latency-svc-sttx9
Feb  7 18:38:12.753: INFO: Got endpoints: latency-svc-mkwrn [331.251424ms]
Feb  7 18:38:12.789: INFO: Got endpoints: latency-svc-sttx9 [353.279774ms]
Feb  7 18:38:12.789: INFO: Created: latency-svc-nv2h9
Feb  7 18:38:12.791: INFO: Got endpoints: latency-svc-nv2h9 [317.01148ms]
Feb  7 18:38:12.807: INFO: Created: latency-svc-vmcpl
Feb  7 18:38:12.819: INFO: Got endpoints: latency-svc-vmcpl [333.942702ms]
Feb  7 18:38:12.837: INFO: Created: latency-svc-v7bq8
Feb  7 18:38:12.859: INFO: Got endpoints: latency-svc-v7bq8 [352.092856ms]
Feb  7 18:38:12.876: INFO: Created: latency-svc-phd22
Feb  7 18:38:12.897: INFO: Got endpoints: latency-svc-phd22 [370.942763ms]
Feb  7 18:38:12.897: INFO: Created: latency-svc-mzxt2
Feb  7 18:38:12.908: INFO: Got endpoints: latency-svc-mzxt2 [370.21925ms]
Feb  7 18:38:12.930: INFO: Created: latency-svc-85wxb
Feb  7 18:38:12.930: INFO: Got endpoints: latency-svc-85wxb [346.80561ms]
Feb  7 18:38:12.942: INFO: Created: latency-svc-4j6jg
Feb  7 18:38:12.949: INFO: Created: latency-svc-d45gx
Feb  7 18:38:12.959: INFO: Got endpoints: latency-svc-4j6jg [347.135726ms]
Feb  7 18:38:12.974: INFO: Created: latency-svc-25r92
Feb  7 18:38:12.989: INFO: Created: latency-svc-6nnwg
Feb  7 18:38:13.004: INFO: Got endpoints: latency-svc-d45gx [392.162892ms]
Feb  7 18:38:13.015: INFO: Created: latency-svc-q6hk9
Feb  7 18:38:13.032: INFO: Created: latency-svc-5fkdb
Feb  7 18:38:13.039: INFO: Created: latency-svc-b2dhd
Feb  7 18:38:13.055: INFO: Got endpoints: latency-svc-25r92 [415.263634ms]
Feb  7 18:38:13.077: INFO: Created: latency-svc-swvlj
Feb  7 18:38:13.089: INFO: Got endpoints: latency-svc-6nnwg [449.272151ms]
Feb  7 18:38:13.101: INFO: Created: latency-svc-4z9w7
Feb  7 18:38:13.117: INFO: Created: latency-svc-d96p9
Feb  7 18:38:13.139: INFO: Created: latency-svc-t4l7n
Feb  7 18:38:13.152: INFO: Created: latency-svc-dzxwb
Feb  7 18:38:13.167: INFO: Got endpoints: latency-svc-q6hk9 [501.841938ms]
Feb  7 18:38:13.177: INFO: Created: latency-svc-m9z6g
Feb  7 18:38:13.188: INFO: Created: latency-svc-x5bhx
Feb  7 18:38:13.196: INFO: Got endpoints: latency-svc-5fkdb [471.354094ms]
Feb  7 18:38:13.213: INFO: Created: latency-svc-spwm8
Feb  7 18:38:13.218: INFO: Created: latency-svc-5mvm6
Feb  7 18:38:13.236: INFO: Created: latency-svc-dz9lg
Feb  7 18:38:13.244: INFO: Got endpoints: latency-svc-b2dhd [519.695543ms]
Feb  7 18:38:13.292: INFO: Created: latency-svc-dv7tt
Feb  7 18:38:13.292: INFO: Created: latency-svc-q7lt9
Feb  7 18:38:13.293: INFO: Created: latency-svc-kq7hw
Feb  7 18:38:13.293: INFO: Created: latency-svc-wjlkv
Feb  7 18:38:13.299: INFO: Created: latency-svc-xh2ks
Feb  7 18:38:13.301: INFO: Got endpoints: latency-svc-swvlj [547.383302ms]
Feb  7 18:38:13.335: INFO: Created: latency-svc-xzbql
Feb  7 18:38:13.348: INFO: Got endpoints: latency-svc-4z9w7 [558.875679ms]
Feb  7 18:38:13.383: INFO: Created: latency-svc-n4nbk
Feb  7 18:38:13.394: INFO: Got endpoints: latency-svc-d96p9 [575.15363ms]
Feb  7 18:38:13.415: INFO: Created: latency-svc-jxwzk
Feb  7 18:38:13.436: INFO: Got endpoints: latency-svc-t4l7n [644.00807ms]
Feb  7 18:38:13.456: INFO: Created: latency-svc-wfzsj
Feb  7 18:38:13.485: INFO: Got endpoints: latency-svc-dzxwb [624.993969ms]
Feb  7 18:38:13.504: INFO: Created: latency-svc-xbbw9
Feb  7 18:38:13.532: INFO: Got endpoints: latency-svc-m9z6g [634.913431ms]
Feb  7 18:38:13.550: INFO: Created: latency-svc-jf2gs
Feb  7 18:38:13.583: INFO: Got endpoints: latency-svc-x5bhx [675.216507ms]
Feb  7 18:38:13.602: INFO: Created: latency-svc-npkqd
Feb  7 18:38:13.631: INFO: Got endpoints: latency-svc-spwm8 [700.316293ms]
Feb  7 18:38:13.650: INFO: Created: latency-svc-dkw8j
Feb  7 18:38:13.682: INFO: Got endpoints: latency-svc-5mvm6 [722.652393ms]
Feb  7 18:38:13.704: INFO: Created: latency-svc-4nf4s
Feb  7 18:38:13.732: INFO: Got endpoints: latency-svc-dz9lg [727.933689ms]
Feb  7 18:38:13.768: INFO: Created: latency-svc-4tfzj
Feb  7 18:38:13.783: INFO: Got endpoints: latency-svc-dv7tt [727.711396ms]
Feb  7 18:38:13.835: INFO: Got endpoints: latency-svc-q7lt9 [745.648775ms]
Feb  7 18:38:13.852: INFO: Created: latency-svc-cvm44
Feb  7 18:38:13.863: INFO: Created: latency-svc-4wf69
Feb  7 18:38:13.881: INFO: Got endpoints: latency-svc-wjlkv [714.202202ms]
Feb  7 18:38:13.902: INFO: Created: latency-svc-dbjpg
Feb  7 18:38:13.932: INFO: Got endpoints: latency-svc-kq7hw [735.932792ms]
Feb  7 18:38:13.960: INFO: Created: latency-svc-dqdqv
Feb  7 18:38:13.981: INFO: Got endpoints: latency-svc-xh2ks [736.667547ms]
Feb  7 18:38:14.003: INFO: Created: latency-svc-rsncc
Feb  7 18:38:14.032: INFO: Got endpoints: latency-svc-xzbql [730.857354ms]
Feb  7 18:38:14.060: INFO: Created: latency-svc-m2j4v
Feb  7 18:38:14.084: INFO: Got endpoints: latency-svc-n4nbk [735.69454ms]
Feb  7 18:38:14.110: INFO: Created: latency-svc-d56hh
Feb  7 18:38:14.132: INFO: Got endpoints: latency-svc-jxwzk [737.190476ms]
Feb  7 18:38:14.152: INFO: Created: latency-svc-7m6s8
Feb  7 18:38:14.182: INFO: Got endpoints: latency-svc-wfzsj [745.956992ms]
Feb  7 18:38:14.196: INFO: Created: latency-svc-xmjx9
Feb  7 18:38:14.232: INFO: Got endpoints: latency-svc-xbbw9 [747.106929ms]
Feb  7 18:38:14.250: INFO: Created: latency-svc-nks9r
Feb  7 18:38:14.283: INFO: Got endpoints: latency-svc-jf2gs [751.104163ms]
Feb  7 18:38:14.308: INFO: Created: latency-svc-rwnjd
Feb  7 18:38:14.334: INFO: Got endpoints: latency-svc-npkqd [750.319496ms]
Feb  7 18:38:14.360: INFO: Created: latency-svc-mstnh
Feb  7 18:38:14.381: INFO: Got endpoints: latency-svc-dkw8j [750.590605ms]
Feb  7 18:38:14.406: INFO: Created: latency-svc-5j9lq
Feb  7 18:38:14.432: INFO: Got endpoints: latency-svc-4nf4s [750.090381ms]
Feb  7 18:38:14.450: INFO: Created: latency-svc-hw9xm
Feb  7 18:38:14.482: INFO: Got endpoints: latency-svc-4tfzj [749.731625ms]
Feb  7 18:38:14.514: INFO: Created: latency-svc-6gl6v
Feb  7 18:38:14.536: INFO: Got endpoints: latency-svc-cvm44 [753.46225ms]
Feb  7 18:38:14.557: INFO: Created: latency-svc-d56w6
Feb  7 18:38:14.593: INFO: Got endpoints: latency-svc-4wf69 [757.681416ms]
Feb  7 18:38:14.620: INFO: Created: latency-svc-l7sbd
Feb  7 18:38:14.630: INFO: Got endpoints: latency-svc-dbjpg [749.168797ms]
Feb  7 18:38:14.661: INFO: Created: latency-svc-v5nz5
Feb  7 18:38:14.698: INFO: Got endpoints: latency-svc-dqdqv [765.460295ms]
Feb  7 18:38:14.739: INFO: Created: latency-svc-cjvrg
Feb  7 18:38:14.761: INFO: Got endpoints: latency-svc-rsncc [780.244357ms]
Feb  7 18:38:14.788: INFO: Got endpoints: latency-svc-m2j4v [756.310119ms]
Feb  7 18:38:14.808: INFO: Created: latency-svc-wzgp5
Feb  7 18:38:14.818: INFO: Created: latency-svc-ct7vk
Feb  7 18:38:14.834: INFO: Got endpoints: latency-svc-d56hh [749.796685ms]
Feb  7 18:38:14.855: INFO: Created: latency-svc-2sbv2
Feb  7 18:38:14.880: INFO: Got endpoints: latency-svc-7m6s8 [748.206675ms]
Feb  7 18:38:14.903: INFO: Created: latency-svc-c8xz7
Feb  7 18:38:14.935: INFO: Got endpoints: latency-svc-xmjx9 [753.040995ms]
Feb  7 18:38:14.958: INFO: Created: latency-svc-f7clc
Feb  7 18:38:14.982: INFO: Got endpoints: latency-svc-nks9r [750.227674ms]
Feb  7 18:38:15.003: INFO: Created: latency-svc-n85g4
Feb  7 18:38:15.030: INFO: Got endpoints: latency-svc-rwnjd [747.212909ms]
Feb  7 18:38:15.054: INFO: Created: latency-svc-jvgb4
Feb  7 18:38:15.085: INFO: Got endpoints: latency-svc-mstnh [751.23982ms]
Feb  7 18:38:15.100: INFO: Created: latency-svc-rcdjj
Feb  7 18:38:15.130: INFO: Got endpoints: latency-svc-5j9lq [748.17887ms]
Feb  7 18:38:15.149: INFO: Created: latency-svc-qspw7
Feb  7 18:38:15.189: INFO: Got endpoints: latency-svc-hw9xm [757.020035ms]
Feb  7 18:38:15.225: INFO: Created: latency-svc-sh7pt
Feb  7 18:38:15.238: INFO: Got endpoints: latency-svc-6gl6v [755.665169ms]
Feb  7 18:38:15.269: INFO: Created: latency-svc-flz7s
Feb  7 18:38:15.284: INFO: Got endpoints: latency-svc-d56w6 [747.984207ms]
Feb  7 18:38:15.301: INFO: Created: latency-svc-m2mxk
Feb  7 18:38:15.329: INFO: Got endpoints: latency-svc-l7sbd [736.632424ms]
Feb  7 18:38:15.350: INFO: Created: latency-svc-k4fkr
Feb  7 18:38:15.382: INFO: Got endpoints: latency-svc-v5nz5 [751.299129ms]
Feb  7 18:38:15.399: INFO: Created: latency-svc-z66qz
Feb  7 18:38:15.446: INFO: Got endpoints: latency-svc-cjvrg [747.92474ms]
Feb  7 18:38:15.462: INFO: Created: latency-svc-jck6n
Feb  7 18:38:15.481: INFO: Got endpoints: latency-svc-wzgp5 [719.833101ms]
Feb  7 18:38:15.499: INFO: Created: latency-svc-wk5qp
Feb  7 18:38:15.532: INFO: Got endpoints: latency-svc-ct7vk [743.675542ms]
Feb  7 18:38:15.567: INFO: Created: latency-svc-pwgwt
Feb  7 18:38:15.585: INFO: Got endpoints: latency-svc-2sbv2 [751.148074ms]
Feb  7 18:38:15.612: INFO: Created: latency-svc-zwjvm
Feb  7 18:38:15.633: INFO: Got endpoints: latency-svc-c8xz7 [752.746115ms]
Feb  7 18:38:15.650: INFO: Created: latency-svc-5gmjv
Feb  7 18:38:15.685: INFO: Got endpoints: latency-svc-f7clc [750.572282ms]
Feb  7 18:38:15.709: INFO: Created: latency-svc-j5z6c
Feb  7 18:38:15.741: INFO: Got endpoints: latency-svc-n85g4 [758.784655ms]
Feb  7 18:38:15.779: INFO: Created: latency-svc-sg47p
Feb  7 18:38:15.788: INFO: Got endpoints: latency-svc-jvgb4 [757.235136ms]
Feb  7 18:38:15.807: INFO: Created: latency-svc-qh9p2
Feb  7 18:38:15.833: INFO: Got endpoints: latency-svc-rcdjj [748.211691ms]
Feb  7 18:38:15.852: INFO: Created: latency-svc-bg2bt
Feb  7 18:38:15.881: INFO: Got endpoints: latency-svc-qspw7 [750.814624ms]
Feb  7 18:38:15.903: INFO: Created: latency-svc-gh7ft
Feb  7 18:38:15.934: INFO: Got endpoints: latency-svc-sh7pt [744.788438ms]
Feb  7 18:38:15.951: INFO: Created: latency-svc-xmzjk
Feb  7 18:38:15.984: INFO: Got endpoints: latency-svc-flz7s [746.317847ms]
Feb  7 18:38:16.009: INFO: Created: latency-svc-lczd4
Feb  7 18:38:16.032: INFO: Got endpoints: latency-svc-m2mxk [747.216209ms]
Feb  7 18:38:16.055: INFO: Created: latency-svc-p6m8b
Feb  7 18:38:16.082: INFO: Got endpoints: latency-svc-k4fkr [752.579527ms]
Feb  7 18:38:16.106: INFO: Created: latency-svc-jsmkn
Feb  7 18:38:16.140: INFO: Got endpoints: latency-svc-z66qz [758.136749ms]
Feb  7 18:38:16.162: INFO: Created: latency-svc-58plw
Feb  7 18:38:16.183: INFO: Got endpoints: latency-svc-jck6n [736.950642ms]
Feb  7 18:38:16.212: INFO: Created: latency-svc-4lc7r
Feb  7 18:38:16.231: INFO: Got endpoints: latency-svc-wk5qp [749.763464ms]
Feb  7 18:38:16.255: INFO: Created: latency-svc-stlrx
Feb  7 18:38:16.281: INFO: Got endpoints: latency-svc-pwgwt [749.290382ms]
Feb  7 18:38:16.301: INFO: Created: latency-svc-9c7j5
Feb  7 18:38:16.352: INFO: Got endpoints: latency-svc-zwjvm [766.588275ms]
Feb  7 18:38:16.371: INFO: Created: latency-svc-9sdhb
Feb  7 18:38:16.383: INFO: Got endpoints: latency-svc-5gmjv [749.619735ms]
Feb  7 18:38:16.400: INFO: Created: latency-svc-c5k8l
Feb  7 18:38:16.433: INFO: Got endpoints: latency-svc-j5z6c [747.031069ms]
Feb  7 18:38:16.455: INFO: Created: latency-svc-vnxk7
Feb  7 18:38:16.488: INFO: Got endpoints: latency-svc-sg47p [746.702877ms]
Feb  7 18:38:16.505: INFO: Created: latency-svc-94sll
Feb  7 18:38:16.535: INFO: Got endpoints: latency-svc-qh9p2 [746.831233ms]
Feb  7 18:38:16.562: INFO: Created: latency-svc-28lq6
Feb  7 18:38:16.582: INFO: Got endpoints: latency-svc-bg2bt [748.517831ms]
Feb  7 18:38:16.608: INFO: Created: latency-svc-r2c7t
Feb  7 18:38:16.633: INFO: Got endpoints: latency-svc-gh7ft [751.954469ms]
Feb  7 18:38:16.654: INFO: Created: latency-svc-rxmcd
Feb  7 18:38:16.686: INFO: Got endpoints: latency-svc-xmzjk [751.673189ms]
Feb  7 18:38:16.716: INFO: Created: latency-svc-zk65c
Feb  7 18:38:16.732: INFO: Got endpoints: latency-svc-lczd4 [747.340086ms]
Feb  7 18:38:16.791: INFO: Got endpoints: latency-svc-p6m8b [758.696426ms]
Feb  7 18:38:16.791: INFO: Created: latency-svc-f5nkn
Feb  7 18:38:16.819: INFO: Created: latency-svc-9ptz2
Feb  7 18:38:16.834: INFO: Got endpoints: latency-svc-jsmkn [751.776604ms]
Feb  7 18:38:16.852: INFO: Created: latency-svc-bxvh4
Feb  7 18:38:16.880: INFO: Got endpoints: latency-svc-58plw [740.458939ms]
Feb  7 18:38:16.904: INFO: Created: latency-svc-q92mx
Feb  7 18:38:16.929: INFO: Got endpoints: latency-svc-4lc7r [746.005012ms]
Feb  7 18:38:16.956: INFO: Created: latency-svc-g7ssj
Feb  7 18:38:16.981: INFO: Got endpoints: latency-svc-stlrx [749.86859ms]
Feb  7 18:38:17.006: INFO: Created: latency-svc-8ktt2
Feb  7 18:38:17.031: INFO: Got endpoints: latency-svc-9c7j5 [749.75641ms]
Feb  7 18:38:17.056: INFO: Created: latency-svc-pg95v
Feb  7 18:38:17.082: INFO: Got endpoints: latency-svc-9sdhb [729.752004ms]
Feb  7 18:38:17.110: INFO: Created: latency-svc-tqx82
Feb  7 18:38:17.142: INFO: Got endpoints: latency-svc-c5k8l [758.94035ms]
Feb  7 18:38:17.162: INFO: Created: latency-svc-krwfk
Feb  7 18:38:17.185: INFO: Got endpoints: latency-svc-vnxk7 [751.980878ms]
Feb  7 18:38:17.214: INFO: Created: latency-svc-b26lg
Feb  7 18:38:17.238: INFO: Got endpoints: latency-svc-94sll [750.677381ms]
Feb  7 18:38:17.263: INFO: Created: latency-svc-7dq7n
Feb  7 18:38:17.285: INFO: Got endpoints: latency-svc-28lq6 [750.671221ms]
Feb  7 18:38:17.311: INFO: Created: latency-svc-m2wlk
Feb  7 18:38:17.333: INFO: Got endpoints: latency-svc-r2c7t [750.3521ms]
Feb  7 18:38:17.358: INFO: Created: latency-svc-w2trk
Feb  7 18:38:17.381: INFO: Got endpoints: latency-svc-rxmcd [748.073298ms]
Feb  7 18:38:17.401: INFO: Created: latency-svc-5qcwp
Feb  7 18:38:17.462: INFO: Got endpoints: latency-svc-zk65c [776.359419ms]
Feb  7 18:38:17.484: INFO: Got endpoints: latency-svc-f5nkn [751.739596ms]
Feb  7 18:38:17.510: INFO: Created: latency-svc-5pgq9
Feb  7 18:38:17.519: INFO: Created: latency-svc-gk5gl
Feb  7 18:38:17.536: INFO: Got endpoints: latency-svc-9ptz2 [745.81184ms]
Feb  7 18:38:17.575: INFO: Created: latency-svc-qqkht
Feb  7 18:38:17.589: INFO: Got endpoints: latency-svc-bxvh4 [755.294104ms]
Feb  7 18:38:17.608: INFO: Created: latency-svc-rvgg7
Feb  7 18:38:17.632: INFO: Got endpoints: latency-svc-q92mx [751.384453ms]
Feb  7 18:38:17.680: INFO: Created: latency-svc-bn8s8
Feb  7 18:38:17.690: INFO: Got endpoints: latency-svc-g7ssj [760.853498ms]
Feb  7 18:38:17.708: INFO: Created: latency-svc-4nmr6
Feb  7 18:38:17.732: INFO: Got endpoints: latency-svc-8ktt2 [750.454258ms]
Feb  7 18:38:17.784: INFO: Created: latency-svc-5jfjg
Feb  7 18:38:17.798: INFO: Got endpoints: latency-svc-pg95v [766.388502ms]
Feb  7 18:38:17.813: INFO: Created: latency-svc-9h9q9
Feb  7 18:38:17.830: INFO: Got endpoints: latency-svc-tqx82 [748.485961ms]
Feb  7 18:38:17.848: INFO: Created: latency-svc-vz6v2
Feb  7 18:38:17.884: INFO: Got endpoints: latency-svc-krwfk [742.375951ms]
Feb  7 18:38:17.903: INFO: Created: latency-svc-2fmkh
Feb  7 18:38:17.931: INFO: Got endpoints: latency-svc-b26lg [746.077098ms]
Feb  7 18:38:17.952: INFO: Created: latency-svc-q4hwg
Feb  7 18:38:17.985: INFO: Got endpoints: latency-svc-7dq7n [746.842279ms]
Feb  7 18:38:18.014: INFO: Created: latency-svc-l6d5s
Feb  7 18:38:18.032: INFO: Got endpoints: latency-svc-m2wlk [746.241948ms]
Feb  7 18:38:18.051: INFO: Created: latency-svc-c7bcp
Feb  7 18:38:18.083: INFO: Got endpoints: latency-svc-w2trk [750.564242ms]
Feb  7 18:38:18.098: INFO: Created: latency-svc-5626p
Feb  7 18:38:18.129: INFO: Got endpoints: latency-svc-5qcwp [748.424023ms]
Feb  7 18:38:18.152: INFO: Created: latency-svc-kz782
Feb  7 18:38:18.182: INFO: Got endpoints: latency-svc-5pgq9 [719.361567ms]
Feb  7 18:38:18.198: INFO: Created: latency-svc-ccqnp
Feb  7 18:38:18.233: INFO: Got endpoints: latency-svc-gk5gl [749.216969ms]
Feb  7 18:38:18.257: INFO: Created: latency-svc-gl2mq
Feb  7 18:38:18.285: INFO: Got endpoints: latency-svc-qqkht [748.02709ms]
Feb  7 18:38:18.307: INFO: Created: latency-svc-gmh9b
Feb  7 18:38:18.333: INFO: Got endpoints: latency-svc-rvgg7 [742.970812ms]
Feb  7 18:38:18.350: INFO: Created: latency-svc-xn7bz
Feb  7 18:38:18.382: INFO: Got endpoints: latency-svc-bn8s8 [749.595921ms]
Feb  7 18:38:18.404: INFO: Created: latency-svc-xcl27
Feb  7 18:38:18.433: INFO: Got endpoints: latency-svc-4nmr6 [742.954686ms]
Feb  7 18:38:18.456: INFO: Created: latency-svc-zkvbv
Feb  7 18:38:18.485: INFO: Got endpoints: latency-svc-5jfjg [752.950877ms]
Feb  7 18:38:18.515: INFO: Created: latency-svc-m528x
Feb  7 18:38:18.536: INFO: Got endpoints: latency-svc-9h9q9 [737.786813ms]
Feb  7 18:38:18.558: INFO: Created: latency-svc-659lf
Feb  7 18:38:18.588: INFO: Got endpoints: latency-svc-vz6v2 [757.569522ms]
Feb  7 18:38:18.608: INFO: Created: latency-svc-bl785
Feb  7 18:38:18.632: INFO: Got endpoints: latency-svc-2fmkh [748.144487ms]
Feb  7 18:38:18.663: INFO: Created: latency-svc-kxgdj
Feb  7 18:38:18.682: INFO: Got endpoints: latency-svc-q4hwg [750.867502ms]
Feb  7 18:38:18.724: INFO: Created: latency-svc-qv8w7
Feb  7 18:38:18.739: INFO: Got endpoints: latency-svc-l6d5s [753.714315ms]
Feb  7 18:38:18.780: INFO: Created: latency-svc-zcrsk
Feb  7 18:38:18.794: INFO: Got endpoints: latency-svc-c7bcp [761.881406ms]
Feb  7 18:38:18.813: INFO: Created: latency-svc-8fdqm
Feb  7 18:38:18.834: INFO: Got endpoints: latency-svc-5626p [750.624625ms]
Feb  7 18:38:18.853: INFO: Created: latency-svc-94xj5
Feb  7 18:38:18.883: INFO: Got endpoints: latency-svc-kz782 [753.095562ms]
Feb  7 18:38:18.906: INFO: Created: latency-svc-nmt9p
Feb  7 18:38:18.929: INFO: Got endpoints: latency-svc-ccqnp [747.778535ms]
Feb  7 18:38:18.949: INFO: Created: latency-svc-kh46w
Feb  7 18:38:18.980: INFO: Got endpoints: latency-svc-gl2mq [746.847316ms]
Feb  7 18:38:19.001: INFO: Created: latency-svc-chkmr
Feb  7 18:38:19.032: INFO: Got endpoints: latency-svc-gmh9b [747.439769ms]
Feb  7 18:38:19.048: INFO: Created: latency-svc-qscdr
Feb  7 18:38:19.079: INFO: Got endpoints: latency-svc-xn7bz [746.7663ms]
Feb  7 18:38:19.102: INFO: Created: latency-svc-p6dc4
Feb  7 18:38:19.130: INFO: Got endpoints: latency-svc-xcl27 [748.310258ms]
Feb  7 18:38:19.151: INFO: Created: latency-svc-4bnvh
Feb  7 18:38:19.186: INFO: Got endpoints: latency-svc-zkvbv [753.558185ms]
Feb  7 18:38:19.204: INFO: Created: latency-svc-ks9zt
Feb  7 18:38:19.232: INFO: Got endpoints: latency-svc-m528x [747.732768ms]
Feb  7 18:38:19.260: INFO: Created: latency-svc-pmvnn
Feb  7 18:38:19.284: INFO: Got endpoints: latency-svc-659lf [748.385651ms]
Feb  7 18:38:19.332: INFO: Created: latency-svc-bhcmg
Feb  7 18:38:19.338: INFO: Got endpoints: latency-svc-bl785 [749.808894ms]
Feb  7 18:38:19.366: INFO: Created: latency-svc-lc9mx
Feb  7 18:38:19.383: INFO: Got endpoints: latency-svc-kxgdj [750.462369ms]
Feb  7 18:38:19.432: INFO: Got endpoints: latency-svc-qv8w7 [749.763793ms]
Feb  7 18:38:19.481: INFO: Got endpoints: latency-svc-zcrsk [741.439908ms]
Feb  7 18:38:19.531: INFO: Got endpoints: latency-svc-8fdqm [736.765835ms]
Feb  7 18:38:19.583: INFO: Got endpoints: latency-svc-94xj5 [749.101181ms]
Feb  7 18:38:19.633: INFO: Got endpoints: latency-svc-nmt9p [750.282522ms]
Feb  7 18:38:19.684: INFO: Got endpoints: latency-svc-kh46w [754.642065ms]
Feb  7 18:38:19.737: INFO: Got endpoints: latency-svc-chkmr [756.413352ms]
Feb  7 18:38:19.782: INFO: Got endpoints: latency-svc-qscdr [749.880464ms]
Feb  7 18:38:19.833: INFO: Got endpoints: latency-svc-p6dc4 [753.152199ms]
Feb  7 18:38:19.884: INFO: Got endpoints: latency-svc-4bnvh [753.82779ms]
Feb  7 18:38:19.938: INFO: Got endpoints: latency-svc-ks9zt [751.052519ms]
Feb  7 18:38:19.982: INFO: Got endpoints: latency-svc-pmvnn [749.532743ms]
Feb  7 18:38:20.032: INFO: Got endpoints: latency-svc-bhcmg [747.624667ms]
Feb  7 18:38:20.086: INFO: Got endpoints: latency-svc-lc9mx [748.061364ms]
Feb  7 18:38:20.086: INFO: Latencies: [53.808151ms 85.550014ms 89.759439ms 90.430918ms 111.68249ms 123.554858ms 141.990845ms 167.883436ms 193.174189ms 231.014553ms 239.566821ms 261.377831ms 296.649478ms 314.607233ms 314.859384ms 317.01148ms 329.677149ms 329.892498ms 330.576487ms 331.251424ms 331.367363ms 331.640615ms 333.942702ms 335.526157ms 336.673802ms 345.832209ms 346.80561ms 347.135726ms 348.612032ms 350.452666ms 351.452272ms 352.092856ms 353.279774ms 356.361602ms 360.62039ms 365.448761ms 370.21925ms 370.942763ms 372.62054ms 381.557654ms 384.416011ms 385.247737ms 390.211653ms 392.162892ms 395.762563ms 407.810664ms 408.62831ms 409.157019ms 410.197437ms 415.263634ms 418.693118ms 419.035732ms 423.033555ms 424.877162ms 435.321481ms 438.468645ms 439.251458ms 441.829688ms 444.237738ms 449.272151ms 471.354094ms 501.841938ms 519.695543ms 547.383302ms 558.875679ms 575.15363ms 624.993969ms 634.913431ms 644.00807ms 675.216507ms 700.316293ms 714.202202ms 719.361567ms 719.833101ms 722.652393ms 727.711396ms 727.933689ms 729.752004ms 730.857354ms 735.69454ms 735.932792ms 736.632424ms 736.667547ms 736.765835ms 736.950642ms 737.190476ms 737.786813ms 740.458939ms 741.439908ms 742.375951ms 742.954686ms 742.970812ms 743.675542ms 744.788438ms 745.648775ms 745.81184ms 745.956992ms 746.005012ms 746.077098ms 746.241948ms 746.317847ms 746.702877ms 746.7663ms 746.831233ms 746.842279ms 746.847316ms 747.031069ms 747.106929ms 747.212909ms 747.216209ms 747.340086ms 747.439769ms 747.624667ms 747.732768ms 747.778535ms 747.92474ms 747.984207ms 748.02709ms 748.061364ms 748.073298ms 748.144487ms 748.17887ms 748.206675ms 748.211691ms 748.310258ms 748.385651ms 748.424023ms 748.485961ms 748.517831ms 749.101181ms 749.168797ms 749.216969ms 749.290382ms 749.532743ms 749.595921ms 749.619735ms 749.731625ms 749.75641ms 749.763464ms 749.763793ms 749.796685ms 749.808894ms 749.86859ms 749.880464ms 750.090381ms 750.227674ms 750.282522ms 750.319496ms 750.3521ms 750.454258ms 750.462369ms 750.564242ms 750.572282ms 750.590605ms 750.624625ms 750.671221ms 750.677381ms 750.814624ms 750.867502ms 751.052519ms 751.104163ms 751.148074ms 751.23982ms 751.299129ms 751.384453ms 751.673189ms 751.739596ms 751.776604ms 751.954469ms 751.980878ms 752.579527ms 752.746115ms 752.950877ms 753.040995ms 753.095562ms 753.152199ms 753.46225ms 753.558185ms 753.714315ms 753.82779ms 754.642065ms 755.294104ms 755.665169ms 756.310119ms 756.413352ms 757.020035ms 757.235136ms 757.569522ms 757.681416ms 758.136749ms 758.696426ms 758.784655ms 758.94035ms 760.853498ms 761.881406ms 765.460295ms 766.388502ms 766.588275ms 776.359419ms 780.244357ms]
Feb  7 18:38:20.086: INFO: 50 %ile: 746.317847ms
Feb  7 18:38:20.086: INFO: 90 %ile: 754.642065ms
Feb  7 18:38:20.086: INFO: 99 %ile: 776.359419ms
Feb  7 18:38:20.086: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:38:20.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-7h8l4" for this suite.
Feb  7 18:38:42.122: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:38:42.231: INFO: namespace: e2e-tests-svc-latency-7h8l4, resource: bindings, ignored listing per whitelist
Feb  7 18:38:42.282: INFO: namespace e2e-tests-svc-latency-7h8l4 deletion completed in 22.181324679s

• [SLOW TEST:33.073 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:38:42.282: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:38:46.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-vlt9j" for this suite.
Feb  7 18:38:52.452: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:38:52.482: INFO: namespace: e2e-tests-kubelet-test-vlt9j, resource: bindings, ignored listing per whitelist
Feb  7 18:38:52.603: INFO: namespace e2e-tests-kubelet-test-vlt9j deletion completed in 6.169879851s

• [SLOW TEST:10.321 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:38:52.604: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb  7 18:38:52.775: INFO: Waiting up to 5m0s for pod "pod-9e02a2d7-2b07-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-emptydir-m8qqz" to be "success or failure"
Feb  7 18:38:52.800: INFO: Pod "pod-9e02a2d7-2b07-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 24.90095ms
Feb  7 18:38:54.804: INFO: Pod "pod-9e02a2d7-2b07-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029103346s
Feb  7 18:38:56.808: INFO: Pod "pod-9e02a2d7-2b07-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03323978s
STEP: Saw pod success
Feb  7 18:38:56.808: INFO: Pod "pod-9e02a2d7-2b07-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 18:38:56.814: INFO: Trying to get logs from node conformance0 pod pod-9e02a2d7-2b07-11e9-90f5-5e78944a5b53 container test-container: <nil>
STEP: delete the pod
Feb  7 18:38:56.855: INFO: Waiting for pod pod-9e02a2d7-2b07-11e9-90f5-5e78944a5b53 to disappear
Feb  7 18:38:56.860: INFO: Pod pod-9e02a2d7-2b07-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:38:56.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-m8qqz" for this suite.
Feb  7 18:39:02.898: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:39:02.934: INFO: namespace: e2e-tests-emptydir-m8qqz, resource: bindings, ignored listing per whitelist
Feb  7 18:39:03.081: INFO: namespace e2e-tests-emptydir-m8qqz deletion completed in 6.205149138s

• [SLOW TEST:10.477 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:39:03.082: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  7 18:39:03.205: INFO: Creating deployment "test-recreate-deployment"
Feb  7 18:39:03.214: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Feb  7 18:39:03.227: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Feb  7 18:39:05.236: INFO: Waiting deployment "test-recreate-deployment" to complete
Feb  7 18:39:05.250: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685161543, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685161543, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685161543, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685161543, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-5dfdcc846d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  7 18:39:07.254: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Feb  7 18:39:07.275: INFO: Updating deployment test-recreate-deployment
Feb  7 18:39:07.275: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb  7 18:39:07.672: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-q7s2n,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-q7s2n/deployments/test-recreate-deployment,UID:a442283f-2b07-11e9-a946-ceb99be2323d,ResourceVersion:5174,Generation:2,CreationTimestamp:2019-02-07 18:39:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-02-07 18:39:07 +0000 UTC 2019-02-07 18:39:07 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-02-07 18:39:07 +0000 UTC 2019-02-07 18:39:03 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-697fbf54bf" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Feb  7 18:39:07.686: INFO: New ReplicaSet "test-recreate-deployment-697fbf54bf" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf,GenerateName:,Namespace:e2e-tests-deployment-q7s2n,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-q7s2n/replicasets/test-recreate-deployment-697fbf54bf,UID:a6c21fbb-2b07-11e9-a946-ceb99be2323d,ResourceVersion:5171,Generation:1,CreationTimestamp:2019-02-07 18:39:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment a442283f-2b07-11e9-a946-ceb99be2323d 0xc002889147 0xc002889148}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb  7 18:39:07.686: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Feb  7 18:39:07.686: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5dfdcc846d,GenerateName:,Namespace:e2e-tests-deployment-q7s2n,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-q7s2n/replicasets/test-recreate-deployment-5dfdcc846d,UID:a444ad2b-2b07-11e9-a946-ceb99be2323d,ResourceVersion:5160,Generation:2,CreationTimestamp:2019-02-07 18:39:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment a442283f-2b07-11e9-a946-ceb99be2323d 0xc002889097 0xc002889098}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb  7 18:39:07.693: INFO: Pod "test-recreate-deployment-697fbf54bf-mv858" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf-mv858,GenerateName:test-recreate-deployment-697fbf54bf-,Namespace:e2e-tests-deployment-q7s2n,SelfLink:/api/v1/namespaces/e2e-tests-deployment-q7s2n/pods/test-recreate-deployment-697fbf54bf-mv858,UID:a6c63599-2b07-11e9-a946-ceb99be2323d,ResourceVersion:5172,Generation:0,CreationTimestamp:2019-02-07 18:39:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-697fbf54bf a6c21fbb-2b07-11e9-a946-ceb99be2323d 0xc0024e1937 0xc0024e1938}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-67c2t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-67c2t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-67c2t true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024e19b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024e19d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 18:39:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 18:39:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 18:39:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 18:39:07 +0000 UTC  }],Message:,Reason:,HostIP:10.10.1.212,PodIP:,StartTime:2019-02-07 18:39:07 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:39:07.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-q7s2n" for this suite.
Feb  7 18:39:13.743: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:39:13.778: INFO: namespace: e2e-tests-deployment-q7s2n, resource: bindings, ignored listing per whitelist
Feb  7 18:39:13.907: INFO: namespace e2e-tests-deployment-q7s2n deletion completed in 6.200856382s

• [SLOW TEST:10.825 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:39:13.908: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1358
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb  7 18:39:14.035: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-t2tb4'
Feb  7 18:39:14.206: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb  7 18:39:14.206: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Feb  7 18:39:14.218: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Feb  7 18:39:14.293: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Feb  7 18:39:14.328: INFO: scanned /root for discovery docs: <nil>
Feb  7 18:39:14.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-t2tb4'
Feb  7 18:39:30.337: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb  7 18:39:30.337: INFO: stdout: "Created e2e-test-nginx-rc-6b4f5ede494a1109c192e7373f10c603\nScaling up e2e-test-nginx-rc-6b4f5ede494a1109c192e7373f10c603 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-6b4f5ede494a1109c192e7373f10c603 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-6b4f5ede494a1109c192e7373f10c603 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Feb  7 18:39:30.337: INFO: stdout: "Created e2e-test-nginx-rc-6b4f5ede494a1109c192e7373f10c603\nScaling up e2e-test-nginx-rc-6b4f5ede494a1109c192e7373f10c603 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-6b4f5ede494a1109c192e7373f10c603 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-6b4f5ede494a1109c192e7373f10c603 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Feb  7 18:39:30.337: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-t2tb4'
Feb  7 18:39:30.504: INFO: stderr: ""
Feb  7 18:39:30.504: INFO: stdout: "e2e-test-nginx-rc-6b4f5ede494a1109c192e7373f10c603-x4l6q "
Feb  7 18:39:30.505: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 get pods e2e-test-nginx-rc-6b4f5ede494a1109c192e7373f10c603-x4l6q -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-t2tb4'
Feb  7 18:39:30.659: INFO: stderr: ""
Feb  7 18:39:30.659: INFO: stdout: "true"
Feb  7 18:39:30.659: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 get pods e2e-test-nginx-rc-6b4f5ede494a1109c192e7373f10c603-x4l6q -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-t2tb4'
Feb  7 18:39:30.820: INFO: stderr: ""
Feb  7 18:39:30.820: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Feb  7 18:39:30.820: INFO: e2e-test-nginx-rc-6b4f5ede494a1109c192e7373f10c603-x4l6q is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1364
Feb  7 18:39:30.820: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-t2tb4'
Feb  7 18:39:31.008: INFO: stderr: ""
Feb  7 18:39:31.008: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:39:31.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-t2tb4" for this suite.
Feb  7 18:39:37.059: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:39:37.123: INFO: namespace: e2e-tests-kubectl-t2tb4, resource: bindings, ignored listing per whitelist
Feb  7 18:39:37.211: INFO: namespace e2e-tests-kubectl-t2tb4 deletion completed in 6.191703253s

• [SLOW TEST:23.303 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:39:37.212: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Feb  7 18:39:37.353: INFO: Waiting up to 5m0s for pod "client-containers-b8994ff9-2b07-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-containers-tv2hg" to be "success or failure"
Feb  7 18:39:37.388: INFO: Pod "client-containers-b8994ff9-2b07-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 35.219477ms
Feb  7 18:39:39.398: INFO: Pod "client-containers-b8994ff9-2b07-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.045449432s
STEP: Saw pod success
Feb  7 18:39:39.399: INFO: Pod "client-containers-b8994ff9-2b07-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 18:39:39.404: INFO: Trying to get logs from node conformance0 pod client-containers-b8994ff9-2b07-11e9-90f5-5e78944a5b53 container test-container: <nil>
STEP: delete the pod
Feb  7 18:39:39.466: INFO: Waiting for pod client-containers-b8994ff9-2b07-11e9-90f5-5e78944a5b53 to disappear
Feb  7 18:39:39.472: INFO: Pod client-containers-b8994ff9-2b07-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:39:39.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-tv2hg" for this suite.
Feb  7 18:39:45.493: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:39:45.557: INFO: namespace: e2e-tests-containers-tv2hg, resource: bindings, ignored listing per whitelist
Feb  7 18:39:45.638: INFO: namespace e2e-tests-containers-tv2hg deletion completed in 6.160552403s

• [SLOW TEST:8.427 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:39:45.639: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  7 18:39:45.785: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bda096f9-2b07-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-projected-9hqts" to be "success or failure"
Feb  7 18:39:45.791: INFO: Pod "downwardapi-volume-bda096f9-2b07-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 5.943316ms
Feb  7 18:39:47.796: INFO: Pod "downwardapi-volume-bda096f9-2b07-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010920002s
STEP: Saw pod success
Feb  7 18:39:47.796: INFO: Pod "downwardapi-volume-bda096f9-2b07-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 18:39:47.801: INFO: Trying to get logs from node conformance0 pod downwardapi-volume-bda096f9-2b07-11e9-90f5-5e78944a5b53 container client-container: <nil>
STEP: delete the pod
Feb  7 18:39:47.844: INFO: Waiting for pod downwardapi-volume-bda096f9-2b07-11e9-90f5-5e78944a5b53 to disappear
Feb  7 18:39:47.853: INFO: Pod downwardapi-volume-bda096f9-2b07-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:39:47.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9hqts" for this suite.
Feb  7 18:39:53.876: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:39:54.027: INFO: namespace: e2e-tests-projected-9hqts, resource: bindings, ignored listing per whitelist
Feb  7 18:39:54.027: INFO: namespace e2e-tests-projected-9hqts deletion completed in 6.168640215s

• [SLOW TEST:8.388 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:39:54.029: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-r8826
Feb  7 18:39:56.203: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-r8826
STEP: checking the pod's current state and verifying that restartCount is present
Feb  7 18:39:56.206: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:43:56.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-r8826" for this suite.
Feb  7 18:44:02.853: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:44:03.012: INFO: namespace: e2e-tests-container-probe-r8826, resource: bindings, ignored listing per whitelist
Feb  7 18:44:03.012: INFO: namespace e2e-tests-container-probe-r8826 deletion completed in 6.184711356s

• [SLOW TEST:248.984 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:44:03.012: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb  7 18:44:05.682: INFO: Successfully updated pod "pod-update-activedeadlineseconds-57070c2f-2b08-11e9-90f5-5e78944a5b53"
Feb  7 18:44:05.683: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-57070c2f-2b08-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-pods-rlwnn" to be "terminated due to deadline exceeded"
Feb  7 18:44:05.689: INFO: Pod "pod-update-activedeadlineseconds-57070c2f-2b08-11e9-90f5-5e78944a5b53": Phase="Running", Reason="", readiness=true. Elapsed: 6.134019ms
Feb  7 18:44:07.693: INFO: Pod "pod-update-activedeadlineseconds-57070c2f-2b08-11e9-90f5-5e78944a5b53": Phase="Running", Reason="", readiness=true. Elapsed: 2.010932403s
Feb  7 18:44:09.699: INFO: Pod "pod-update-activedeadlineseconds-57070c2f-2b08-11e9-90f5-5e78944a5b53": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.016443969s
Feb  7 18:44:09.699: INFO: Pod "pod-update-activedeadlineseconds-57070c2f-2b08-11e9-90f5-5e78944a5b53" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:44:09.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-rlwnn" for this suite.
Feb  7 18:44:15.723: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:44:15.893: INFO: namespace: e2e-tests-pods-rlwnn, resource: bindings, ignored listing per whitelist
Feb  7 18:44:15.953: INFO: namespace e2e-tests-pods-rlwnn deletion completed in 6.248704853s

• [SLOW TEST:12.941 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:44:15.954: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Feb  7 18:44:16.075: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb  7 18:44:16.091: INFO: Waiting for terminating namespaces to be deleted...
Feb  7 18:44:16.096: INFO: 
Logging pods the kubelet thinks is on node conformance0 before test
Feb  7 18:44:16.106: INFO: kube-dns-6fbf99bd5-vln22 from kube-system started at 2019-02-07 17:59:05 +0000 UTC (3 container statuses recorded)
Feb  7 18:44:16.106: INFO: 	Container dnsmasq ready: true, restart count 0
Feb  7 18:44:16.106: INFO: 	Container kubedns ready: true, restart count 0
Feb  7 18:44:16.106: INFO: 	Container sidecar ready: true, restart count 0
Feb  7 18:44:16.106: INFO: nirmata-cni-installer-548lz from nirmata started at 2019-02-07 17:59:05 +0000 UTC (1 container statuses recorded)
Feb  7 18:44:16.106: INFO: 	Container install-cni ready: true, restart count 0
Feb  7 18:44:16.106: INFO: haproxy-ingress-6cd7fb8fc-bswfw from ingress-haproxy started at 2019-02-07 17:59:13 +0000 UTC (1 container statuses recorded)
Feb  7 18:44:16.106: INFO: 	Container haproxy-ingress ready: true, restart count 0
Feb  7 18:44:16.106: INFO: metrics-server-58fd5b7956-55hhh from kube-system started at 2019-02-07 17:59:35 +0000 UTC (1 container statuses recorded)
Feb  7 18:44:16.106: INFO: 	Container metrics-server ready: true, restart count 0
Feb  7 18:44:16.106: INFO: kube-flannel-ds-l2rpk from kube-system started at 2019-02-07 17:58:51 +0000 UTC (1 container statuses recorded)
Feb  7 18:44:16.106: INFO: 	Container kube-flannel ready: true, restart count 0
Feb  7 18:44:16.106: INFO: nirmata-kube-controller-7bc4774558-hdvmg from nirmata started at 2019-02-07 17:59:05 +0000 UTC (1 container statuses recorded)
Feb  7 18:44:16.106: INFO: 	Container nirmata-kube-controller ready: true, restart count 0
Feb  7 18:44:16.106: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-07 18:11:07 +0000 UTC (1 container statuses recorded)
Feb  7 18:44:16.106: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb  7 18:44:16.106: INFO: sonobuoy-e2e-job-946df599e97f4154 from heptio-sonobuoy started at 2019-02-07 18:11:13 +0000 UTC (2 container statuses recorded)
Feb  7 18:44:16.106: INFO: 	Container e2e ready: true, restart count 0
Feb  7 18:44:16.106: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  7 18:44:16.106: INFO: ingress-default-backend-55c6dddf9b-bsb5j from ingress-haproxy started at 2019-02-07 17:59:13 +0000 UTC (1 container statuses recorded)
Feb  7 18:44:16.106: INFO: 	Container ingress-default-backend ready: true, restart count 0
Feb  7 18:44:16.106: INFO: sonobuoy-systemd-logs-daemon-set-0f8450d3236a4290-khwsz from heptio-sonobuoy started at 2019-02-07 18:11:13 +0000 UTC (2 container statuses recorded)
Feb  7 18:44:16.106: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb  7 18:44:16.106: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node conformance0
Feb  7 18:44:16.152: INFO: Pod sonobuoy requesting resource cpu=0m on Node conformance0
Feb  7 18:44:16.152: INFO: Pod sonobuoy-e2e-job-946df599e97f4154 requesting resource cpu=0m on Node conformance0
Feb  7 18:44:16.152: INFO: Pod sonobuoy-systemd-logs-daemon-set-0f8450d3236a4290-khwsz requesting resource cpu=0m on Node conformance0
Feb  7 18:44:16.152: INFO: Pod haproxy-ingress-6cd7fb8fc-bswfw requesting resource cpu=0m on Node conformance0
Feb  7 18:44:16.152: INFO: Pod ingress-default-backend-55c6dddf9b-bsb5j requesting resource cpu=0m on Node conformance0
Feb  7 18:44:16.152: INFO: Pod kube-dns-6fbf99bd5-vln22 requesting resource cpu=260m on Node conformance0
Feb  7 18:44:16.152: INFO: Pod kube-flannel-ds-l2rpk requesting resource cpu=0m on Node conformance0
Feb  7 18:44:16.152: INFO: Pod metrics-server-58fd5b7956-55hhh requesting resource cpu=0m on Node conformance0
Feb  7 18:44:16.152: INFO: Pod nirmata-cni-installer-548lz requesting resource cpu=0m on Node conformance0
Feb  7 18:44:16.152: INFO: Pod nirmata-kube-controller-7bc4774558-hdvmg requesting resource cpu=0m on Node conformance0
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5ec9d541-2b08-11e9-90f5-5e78944a5b53.158129356a612bee], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-pvv5n/filler-pod-5ec9d541-2b08-11e9-90f5-5e78944a5b53 to conformance0]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5ec9d541-2b08-11e9-90f5-5e78944a5b53.158129359cc299b8], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5ec9d541-2b08-11e9-90f5-5e78944a5b53.15812935a1577db6], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5ec9d541-2b08-11e9-90f5-5e78944a5b53.15812935acfe77f9], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15812935e2ab5359], Reason = [FailedScheduling], Message = [0/1 nodes are available: 1 Insufficient cpu.]
STEP: removing the label node off the node conformance0
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:44:19.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-pvv5n" for this suite.
Feb  7 18:44:25.280: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:44:25.364: INFO: namespace: e2e-tests-sched-pred-pvv5n, resource: bindings, ignored listing per whitelist
Feb  7 18:44:25.440: INFO: namespace e2e-tests-sched-pred-pvv5n deletion completed in 6.18584676s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:9.487 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:44:25.441: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb  7 18:44:25.562: INFO: Waiting up to 5m0s for pod "downward-api-6463be59-2b08-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-downward-api-bkrx7" to be "success or failure"
Feb  7 18:44:25.582: INFO: Pod "downward-api-6463be59-2b08-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 20.341431ms
Feb  7 18:44:27.587: INFO: Pod "downward-api-6463be59-2b08-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025209866s
Feb  7 18:44:29.592: INFO: Pod "downward-api-6463be59-2b08-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030045488s
STEP: Saw pod success
Feb  7 18:44:29.592: INFO: Pod "downward-api-6463be59-2b08-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 18:44:29.597: INFO: Trying to get logs from node conformance0 pod downward-api-6463be59-2b08-11e9-90f5-5e78944a5b53 container dapi-container: <nil>
STEP: delete the pod
Feb  7 18:44:29.634: INFO: Waiting for pod downward-api-6463be59-2b08-11e9-90f5-5e78944a5b53 to disappear
Feb  7 18:44:29.639: INFO: Pod downward-api-6463be59-2b08-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:44:29.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-bkrx7" for this suite.
Feb  7 18:44:35.660: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:44:35.720: INFO: namespace: e2e-tests-downward-api-bkrx7, resource: bindings, ignored listing per whitelist
Feb  7 18:44:35.817: INFO: namespace e2e-tests-downward-api-bkrx7 deletion completed in 6.173335152s

• [SLOW TEST:10.377 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:44:35.818: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-v2lh9
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb  7 18:44:35.926: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb  7 18:44:58.034: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.0.109:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-v2lh9 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  7 18:44:58.034: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
Feb  7 18:44:58.156: INFO: Found all expected endpoints: [netserver-0]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:44:58.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-v2lh9" for this suite.
Feb  7 18:45:22.179: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:45:22.335: INFO: namespace: e2e-tests-pod-network-test-v2lh9, resource: bindings, ignored listing per whitelist
Feb  7 18:45:22.336: INFO: namespace e2e-tests-pod-network-test-v2lh9 deletion completed in 24.173561082s

• [SLOW TEST:46.518 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:45:22.336: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Feb  7 18:45:22.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 --namespace=e2e-tests-kubectl-jtdqq run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Feb  7 18:45:25.513: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Feb  7 18:45:25.513: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:45:27.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-jtdqq" for this suite.
Feb  7 18:45:33.557: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:45:33.678: INFO: namespace: e2e-tests-kubectl-jtdqq, resource: bindings, ignored listing per whitelist
Feb  7 18:45:33.714: INFO: namespace e2e-tests-kubectl-jtdqq deletion completed in 6.185882868s

• [SLOW TEST:11.378 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:45:33.714: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb  7 18:45:33.855: INFO: Waiting up to 5m0s for pod "pod-8d182f88-2b08-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-emptydir-74r6s" to be "success or failure"
Feb  7 18:45:33.863: INFO: Pod "pod-8d182f88-2b08-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 8.397393ms
Feb  7 18:45:35.869: INFO: Pod "pod-8d182f88-2b08-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014188947s
STEP: Saw pod success
Feb  7 18:45:35.869: INFO: Pod "pod-8d182f88-2b08-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 18:45:35.874: INFO: Trying to get logs from node conformance0 pod pod-8d182f88-2b08-11e9-90f5-5e78944a5b53 container test-container: <nil>
STEP: delete the pod
Feb  7 18:45:35.930: INFO: Waiting for pod pod-8d182f88-2b08-11e9-90f5-5e78944a5b53 to disappear
Feb  7 18:45:35.934: INFO: Pod pod-8d182f88-2b08-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:45:35.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-74r6s" for this suite.
Feb  7 18:45:41.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:45:42.031: INFO: namespace: e2e-tests-emptydir-74r6s, resource: bindings, ignored listing per whitelist
Feb  7 18:45:42.113: INFO: namespace e2e-tests-emptydir-74r6s deletion completed in 6.173086906s

• [SLOW TEST:8.399 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:45:42.114: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-9215c586-2b08-11e9-90f5-5e78944a5b53
STEP: Creating a pod to test consume configMaps
Feb  7 18:45:42.236: INFO: Waiting up to 5m0s for pod "pod-configmaps-9217a6ae-2b08-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-configmap-kn8rg" to be "success or failure"
Feb  7 18:45:42.241: INFO: Pod "pod-configmaps-9217a6ae-2b08-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 5.094203ms
Feb  7 18:45:44.248: INFO: Pod "pod-configmaps-9217a6ae-2b08-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011239401s
STEP: Saw pod success
Feb  7 18:45:44.248: INFO: Pod "pod-configmaps-9217a6ae-2b08-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 18:45:44.254: INFO: Trying to get logs from node conformance0 pod pod-configmaps-9217a6ae-2b08-11e9-90f5-5e78944a5b53 container configmap-volume-test: <nil>
STEP: delete the pod
Feb  7 18:45:44.291: INFO: Waiting for pod pod-configmaps-9217a6ae-2b08-11e9-90f5-5e78944a5b53 to disappear
Feb  7 18:45:44.308: INFO: Pod pod-configmaps-9217a6ae-2b08-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:45:44.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-kn8rg" for this suite.
Feb  7 18:45:50.338: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:45:50.440: INFO: namespace: e2e-tests-configmap-kn8rg, resource: bindings, ignored listing per whitelist
Feb  7 18:45:50.511: INFO: namespace e2e-tests-configmap-kn8rg deletion completed in 6.195758692s

• [SLOW TEST:8.398 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:45:50.513: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-971a9f1c-2b08-11e9-90f5-5e78944a5b53
STEP: Creating a pod to test consume secrets
Feb  7 18:45:50.652: INFO: Waiting up to 5m0s for pod "pod-secrets-971bbc74-2b08-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-secrets-wj97h" to be "success or failure"
Feb  7 18:45:50.659: INFO: Pod "pod-secrets-971bbc74-2b08-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 6.335917ms
Feb  7 18:45:52.664: INFO: Pod "pod-secrets-971bbc74-2b08-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010982174s
STEP: Saw pod success
Feb  7 18:45:52.664: INFO: Pod "pod-secrets-971bbc74-2b08-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 18:45:52.669: INFO: Trying to get logs from node conformance0 pod pod-secrets-971bbc74-2b08-11e9-90f5-5e78944a5b53 container secret-volume-test: <nil>
STEP: delete the pod
Feb  7 18:45:52.743: INFO: Waiting for pod pod-secrets-971bbc74-2b08-11e9-90f5-5e78944a5b53 to disappear
Feb  7 18:45:52.764: INFO: Pod pod-secrets-971bbc74-2b08-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:45:52.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-wj97h" for this suite.
Feb  7 18:45:58.793: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:45:58.864: INFO: namespace: e2e-tests-secrets-wj97h, resource: bindings, ignored listing per whitelist
Feb  7 18:45:58.952: INFO: namespace e2e-tests-secrets-wj97h deletion completed in 6.181077919s

• [SLOW TEST:8.440 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:45:58.953: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-gszb
STEP: Creating a pod to test atomic-volume-subpath
Feb  7 18:45:59.092: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-gszb" in namespace "e2e-tests-subpath-chhxh" to be "success or failure"
Feb  7 18:45:59.099: INFO: Pod "pod-subpath-test-configmap-gszb": Phase="Pending", Reason="", readiness=false. Elapsed: 6.72779ms
Feb  7 18:46:01.103: INFO: Pod "pod-subpath-test-configmap-gszb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01083183s
Feb  7 18:46:03.108: INFO: Pod "pod-subpath-test-configmap-gszb": Phase="Running", Reason="", readiness=false. Elapsed: 4.016069809s
Feb  7 18:46:05.113: INFO: Pod "pod-subpath-test-configmap-gszb": Phase="Running", Reason="", readiness=false. Elapsed: 6.021089648s
Feb  7 18:46:07.118: INFO: Pod "pod-subpath-test-configmap-gszb": Phase="Running", Reason="", readiness=false. Elapsed: 8.025496552s
Feb  7 18:46:09.122: INFO: Pod "pod-subpath-test-configmap-gszb": Phase="Running", Reason="", readiness=false. Elapsed: 10.029760154s
Feb  7 18:46:11.127: INFO: Pod "pod-subpath-test-configmap-gszb": Phase="Running", Reason="", readiness=false. Elapsed: 12.034824165s
Feb  7 18:46:13.132: INFO: Pod "pod-subpath-test-configmap-gszb": Phase="Running", Reason="", readiness=false. Elapsed: 14.039419561s
Feb  7 18:46:15.137: INFO: Pod "pod-subpath-test-configmap-gszb": Phase="Running", Reason="", readiness=false. Elapsed: 16.044279626s
Feb  7 18:46:17.142: INFO: Pod "pod-subpath-test-configmap-gszb": Phase="Running", Reason="", readiness=false. Elapsed: 18.049463237s
Feb  7 18:46:19.147: INFO: Pod "pod-subpath-test-configmap-gszb": Phase="Running", Reason="", readiness=false. Elapsed: 20.054988405s
Feb  7 18:46:21.152: INFO: Pod "pod-subpath-test-configmap-gszb": Phase="Running", Reason="", readiness=false. Elapsed: 22.05964358s
Feb  7 18:46:23.160: INFO: Pod "pod-subpath-test-configmap-gszb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.067878578s
STEP: Saw pod success
Feb  7 18:46:23.160: INFO: Pod "pod-subpath-test-configmap-gszb" satisfied condition "success or failure"
Feb  7 18:46:23.167: INFO: Trying to get logs from node conformance0 pod pod-subpath-test-configmap-gszb container test-container-subpath-configmap-gszb: <nil>
STEP: delete the pod
Feb  7 18:46:23.333: INFO: Waiting for pod pod-subpath-test-configmap-gszb to disappear
Feb  7 18:46:23.337: INFO: Pod pod-subpath-test-configmap-gszb no longer exists
STEP: Deleting pod pod-subpath-test-configmap-gszb
Feb  7 18:46:23.338: INFO: Deleting pod "pod-subpath-test-configmap-gszb" in namespace "e2e-tests-subpath-chhxh"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:46:23.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-chhxh" for this suite.
Feb  7 18:46:29.376: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:46:29.445: INFO: namespace: e2e-tests-subpath-chhxh, resource: bindings, ignored listing per whitelist
Feb  7 18:46:29.518: INFO: namespace e2e-tests-subpath-chhxh deletion completed in 6.159618467s

• [SLOW TEST:30.566 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:46:29.519: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-ae595985-2b08-11e9-90f5-5e78944a5b53
STEP: Creating a pod to test consume configMaps
Feb  7 18:46:29.658: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ae5a80c7-2b08-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-projected-szzn4" to be "success or failure"
Feb  7 18:46:29.672: INFO: Pod "pod-projected-configmaps-ae5a80c7-2b08-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 13.442243ms
Feb  7 18:46:31.680: INFO: Pod "pod-projected-configmaps-ae5a80c7-2b08-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021244607s
STEP: Saw pod success
Feb  7 18:46:31.680: INFO: Pod "pod-projected-configmaps-ae5a80c7-2b08-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 18:46:31.685: INFO: Trying to get logs from node conformance0 pod pod-projected-configmaps-ae5a80c7-2b08-11e9-90f5-5e78944a5b53 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  7 18:46:31.729: INFO: Waiting for pod pod-projected-configmaps-ae5a80c7-2b08-11e9-90f5-5e78944a5b53 to disappear
Feb  7 18:46:31.735: INFO: Pod pod-projected-configmaps-ae5a80c7-2b08-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:46:31.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-szzn4" for this suite.
Feb  7 18:46:37.794: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:46:37.847: INFO: namespace: e2e-tests-projected-szzn4, resource: bindings, ignored listing per whitelist
Feb  7 18:46:37.966: INFO: namespace e2e-tests-projected-szzn4 deletion completed in 6.194827546s

• [SLOW TEST:8.447 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:46:37.966: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-b3620c8a-2b08-11e9-90f5-5e78944a5b53
STEP: Creating a pod to test consume configMaps
Feb  7 18:46:38.100: INFO: Waiting up to 5m0s for pod "pod-configmaps-b36391db-2b08-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-configmap-7dbpq" to be "success or failure"
Feb  7 18:46:38.109: INFO: Pod "pod-configmaps-b36391db-2b08-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 8.662514ms
Feb  7 18:46:40.113: INFO: Pod "pod-configmaps-b36391db-2b08-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012461368s
Feb  7 18:46:42.118: INFO: Pod "pod-configmaps-b36391db-2b08-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017294221s
STEP: Saw pod success
Feb  7 18:46:42.118: INFO: Pod "pod-configmaps-b36391db-2b08-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 18:46:42.124: INFO: Trying to get logs from node conformance0 pod pod-configmaps-b36391db-2b08-11e9-90f5-5e78944a5b53 container configmap-volume-test: <nil>
STEP: delete the pod
Feb  7 18:46:42.172: INFO: Waiting for pod pod-configmaps-b36391db-2b08-11e9-90f5-5e78944a5b53 to disappear
Feb  7 18:46:42.187: INFO: Pod pod-configmaps-b36391db-2b08-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:46:42.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-7dbpq" for this suite.
Feb  7 18:46:48.211: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:46:48.295: INFO: namespace: e2e-tests-configmap-7dbpq, resource: bindings, ignored listing per whitelist
Feb  7 18:46:48.360: INFO: namespace e2e-tests-configmap-7dbpq deletion completed in 6.166451551s

• [SLOW TEST:10.393 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:46:48.361: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  7 18:46:48.482: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b993c4ec-2b08-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-projected-x4x79" to be "success or failure"
Feb  7 18:46:48.491: INFO: Pod "downwardapi-volume-b993c4ec-2b08-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 9.210948ms
Feb  7 18:46:50.495: INFO: Pod "downwardapi-volume-b993c4ec-2b08-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013674997s
STEP: Saw pod success
Feb  7 18:46:50.495: INFO: Pod "downwardapi-volume-b993c4ec-2b08-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 18:46:50.501: INFO: Trying to get logs from node conformance0 pod downwardapi-volume-b993c4ec-2b08-11e9-90f5-5e78944a5b53 container client-container: <nil>
STEP: delete the pod
Feb  7 18:46:50.535: INFO: Waiting for pod downwardapi-volume-b993c4ec-2b08-11e9-90f5-5e78944a5b53 to disappear
Feb  7 18:46:50.550: INFO: Pod downwardapi-volume-b993c4ec-2b08-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:46:50.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-x4x79" for this suite.
Feb  7 18:46:56.580: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:46:56.649: INFO: namespace: e2e-tests-projected-x4x79, resource: bindings, ignored listing per whitelist
Feb  7 18:46:56.762: INFO: namespace e2e-tests-projected-x4x79 deletion completed in 6.202744703s

• [SLOW TEST:8.402 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:46:56.764: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:46:56.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-qkxcg" for this suite.
Feb  7 18:47:02.921: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:47:02.960: INFO: namespace: e2e-tests-services-qkxcg, resource: bindings, ignored listing per whitelist
Feb  7 18:47:03.085: INFO: namespace e2e-tests-services-qkxcg deletion completed in 6.182673723s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:6.322 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:47:03.086: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  7 18:47:03.229: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
Feb  7 18:47:03.242: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-4bxml/daemonsets","resourceVersion":"5895"},"items":null}

Feb  7 18:47:03.248: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-4bxml/pods","resourceVersion":"5895"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:47:03.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-4bxml" for this suite.
Feb  7 18:47:09.284: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:47:09.364: INFO: namespace: e2e-tests-daemonsets-4bxml, resource: bindings, ignored listing per whitelist
Feb  7 18:47:09.424: INFO: namespace e2e-tests-daemonsets-4bxml deletion completed in 6.157400807s

S [SKIPPING] [6.339 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Feb  7 18:47:03.229: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:47:09.425: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  7 18:47:09.541: INFO: (0) /api/v1/nodes/conformance0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 6.340718ms)
Feb  7 18:47:09.548: INFO: (1) /api/v1/nodes/conformance0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 6.089429ms)
Feb  7 18:47:09.553: INFO: (2) /api/v1/nodes/conformance0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 5.758166ms)
Feb  7 18:47:09.558: INFO: (3) /api/v1/nodes/conformance0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.919883ms)
Feb  7 18:47:09.563: INFO: (4) /api/v1/nodes/conformance0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.884891ms)
Feb  7 18:47:09.569: INFO: (5) /api/v1/nodes/conformance0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 5.485506ms)
Feb  7 18:47:09.575: INFO: (6) /api/v1/nodes/conformance0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 5.981796ms)
Feb  7 18:47:09.580: INFO: (7) /api/v1/nodes/conformance0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 5.021759ms)
Feb  7 18:47:09.585: INFO: (8) /api/v1/nodes/conformance0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.796866ms)
Feb  7 18:47:09.591: INFO: (9) /api/v1/nodes/conformance0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 6.232914ms)
Feb  7 18:47:09.598: INFO: (10) /api/v1/nodes/conformance0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 6.090031ms)
Feb  7 18:47:09.602: INFO: (11) /api/v1/nodes/conformance0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.572411ms)
Feb  7 18:47:09.608: INFO: (12) /api/v1/nodes/conformance0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 6.032916ms)
Feb  7 18:47:09.615: INFO: (13) /api/v1/nodes/conformance0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 6.203211ms)
Feb  7 18:47:09.621: INFO: (14) /api/v1/nodes/conformance0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 6.444062ms)
Feb  7 18:47:09.626: INFO: (15) /api/v1/nodes/conformance0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 5.043521ms)
Feb  7 18:47:09.631: INFO: (16) /api/v1/nodes/conformance0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.850227ms)
Feb  7 18:47:09.637: INFO: (17) /api/v1/nodes/conformance0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 5.17783ms)
Feb  7 18:47:09.642: INFO: (18) /api/v1/nodes/conformance0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 5.438483ms)
Feb  7 18:47:09.652: INFO: (19) /api/v1/nodes/conformance0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 9.851393ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:47:09.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-ns6bw" for this suite.
Feb  7 18:47:15.675: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:47:15.778: INFO: namespace: e2e-tests-proxy-ns6bw, resource: bindings, ignored listing per whitelist
Feb  7 18:47:15.858: INFO: namespace e2e-tests-proxy-ns6bw deletion completed in 6.200994226s

• [SLOW TEST:6.434 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:47:15.859: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-k6r4s
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-k6r4s
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-k6r4s
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-k6r4s
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-k6r4s
Feb  7 18:47:20.127: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-k6r4s, name: ss-0, uid: cc2d33d6-2b08-11e9-a946-ceb99be2323d, status phase: Pending. Waiting for statefulset controller to delete.
Feb  7 18:47:20.225: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-k6r4s, name: ss-0, uid: cc2d33d6-2b08-11e9-a946-ceb99be2323d, status phase: Failed. Waiting for statefulset controller to delete.
Feb  7 18:47:20.243: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-k6r4s, name: ss-0, uid: cc2d33d6-2b08-11e9-a946-ceb99be2323d, status phase: Failed. Waiting for statefulset controller to delete.
Feb  7 18:47:20.259: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-k6r4s
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-k6r4s
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-k6r4s and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb  7 18:47:24.337: INFO: Deleting all statefulset in ns e2e-tests-statefulset-k6r4s
Feb  7 18:47:24.345: INFO: Scaling statefulset ss to 0
Feb  7 18:47:34.368: INFO: Waiting for statefulset status.replicas updated to 0
Feb  7 18:47:34.375: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:47:34.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-k6r4s" for this suite.
Feb  7 18:47:40.421: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:47:40.500: INFO: namespace: e2e-tests-statefulset-k6r4s, resource: bindings, ignored listing per whitelist
Feb  7 18:47:40.576: INFO: namespace e2e-tests-statefulset-k6r4s deletion completed in 6.172244497s

• [SLOW TEST:24.717 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:47:40.577: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-d8b42fe2-2b08-11e9-90f5-5e78944a5b53
STEP: Creating a pod to test consume configMaps
Feb  7 18:47:40.733: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d8b58c6b-2b08-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-projected-cshd8" to be "success or failure"
Feb  7 18:47:40.740: INFO: Pod "pod-projected-configmaps-d8b58c6b-2b08-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 7.531982ms
Feb  7 18:47:42.745: INFO: Pod "pod-projected-configmaps-d8b58c6b-2b08-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01212683s
Feb  7 18:47:44.760: INFO: Pod "pod-projected-configmaps-d8b58c6b-2b08-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02719092s
STEP: Saw pod success
Feb  7 18:47:44.760: INFO: Pod "pod-projected-configmaps-d8b58c6b-2b08-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 18:47:44.766: INFO: Trying to get logs from node conformance0 pod pod-projected-configmaps-d8b58c6b-2b08-11e9-90f5-5e78944a5b53 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  7 18:47:44.812: INFO: Waiting for pod pod-projected-configmaps-d8b58c6b-2b08-11e9-90f5-5e78944a5b53 to disappear
Feb  7 18:47:44.823: INFO: Pod pod-projected-configmaps-d8b58c6b-2b08-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:47:44.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-cshd8" for this suite.
Feb  7 18:47:50.851: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:47:50.983: INFO: namespace: e2e-tests-projected-cshd8, resource: bindings, ignored listing per whitelist
Feb  7 18:47:51.039: INFO: namespace e2e-tests-projected-cshd8 deletion completed in 6.207395423s

• [SLOW TEST:10.462 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:47:51.039: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-lq4fj
Feb  7 18:47:55.182: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-lq4fj
STEP: checking the pod's current state and verifying that restartCount is present
Feb  7 18:47:55.206: INFO: Initial restart count of pod liveness-http is 0
Feb  7 18:48:09.254: INFO: Restart count of pod e2e-tests-container-probe-lq4fj/liveness-http is now 1 (14.047069078s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:48:09.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-lq4fj" for this suite.
Feb  7 18:48:15.315: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:48:15.345: INFO: namespace: e2e-tests-container-probe-lq4fj, resource: bindings, ignored listing per whitelist
Feb  7 18:48:15.502: INFO: namespace e2e-tests-container-probe-lq4fj deletion completed in 6.214021499s

• [SLOW TEST:24.463 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:48:15.502: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-ed958c23-2b08-11e9-90f5-5e78944a5b53
STEP: Creating a pod to test consume configMaps
Feb  7 18:48:15.740: INFO: Waiting up to 5m0s for pod "pod-configmaps-ed96720a-2b08-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-configmap-gkmqv" to be "success or failure"
Feb  7 18:48:15.776: INFO: Pod "pod-configmaps-ed96720a-2b08-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 35.359785ms
Feb  7 18:48:17.780: INFO: Pod "pod-configmaps-ed96720a-2b08-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.039910505s
STEP: Saw pod success
Feb  7 18:48:17.780: INFO: Pod "pod-configmaps-ed96720a-2b08-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 18:48:17.786: INFO: Trying to get logs from node conformance0 pod pod-configmaps-ed96720a-2b08-11e9-90f5-5e78944a5b53 container configmap-volume-test: <nil>
STEP: delete the pod
Feb  7 18:48:17.837: INFO: Waiting for pod pod-configmaps-ed96720a-2b08-11e9-90f5-5e78944a5b53 to disappear
Feb  7 18:48:17.847: INFO: Pod pod-configmaps-ed96720a-2b08-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:48:17.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-gkmqv" for this suite.
Feb  7 18:48:23.872: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:48:23.940: INFO: namespace: e2e-tests-configmap-gkmqv, resource: bindings, ignored listing per whitelist
Feb  7 18:48:24.024: INFO: namespace e2e-tests-configmap-gkmqv deletion completed in 6.169556048s

• [SLOW TEST:8.521 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:48:24.025: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Feb  7 18:48:24.123: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 cluster-info'
Feb  7 18:48:24.273: INFO: stderr: ""
Feb  7 18:48:24.273: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.10.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.10.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:48:24.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-4vfhm" for this suite.
Feb  7 18:48:30.299: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:48:30.417: INFO: namespace: e2e-tests-kubectl-4vfhm, resource: bindings, ignored listing per whitelist
Feb  7 18:48:30.450: INFO: namespace e2e-tests-kubectl-4vfhm deletion completed in 6.170395608s

• [SLOW TEST:6.426 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:48:30.451: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb  7 18:48:30.578: INFO: Waiting up to 5m0s for pod "pod-f66e1519-2b08-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-emptydir-7m7dz" to be "success or failure"
Feb  7 18:48:30.599: INFO: Pod "pod-f66e1519-2b08-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 20.773089ms
Feb  7 18:48:32.603: INFO: Pod "pod-f66e1519-2b08-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025419168s
STEP: Saw pod success
Feb  7 18:48:32.604: INFO: Pod "pod-f66e1519-2b08-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 18:48:32.608: INFO: Trying to get logs from node conformance0 pod pod-f66e1519-2b08-11e9-90f5-5e78944a5b53 container test-container: <nil>
STEP: delete the pod
Feb  7 18:48:32.642: INFO: Waiting for pod pod-f66e1519-2b08-11e9-90f5-5e78944a5b53 to disappear
Feb  7 18:48:32.651: INFO: Pod pod-f66e1519-2b08-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:48:32.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-7m7dz" for this suite.
Feb  7 18:48:38.675: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:48:38.747: INFO: namespace: e2e-tests-emptydir-7m7dz, resource: bindings, ignored listing per whitelist
Feb  7 18:48:38.845: INFO: namespace e2e-tests-emptydir-7m7dz deletion completed in 6.18863335s

• [SLOW TEST:8.395 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:48:38.846: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:48:41.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-m95zs" for this suite.
Feb  7 18:48:47.100: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:48:47.251: INFO: namespace: e2e-tests-emptydir-wrapper-m95zs, resource: bindings, ignored listing per whitelist
Feb  7 18:48:47.292: INFO: namespace e2e-tests-emptydir-wrapper-m95zs deletion completed in 6.222526985s

• [SLOW TEST:8.446 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:48:47.292: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Feb  7 18:48:47.409: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 create -f - --namespace=e2e-tests-kubectl-rxkr7'
Feb  7 18:48:47.934: INFO: stderr: ""
Feb  7 18:48:47.934: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb  7 18:48:47.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-rxkr7'
Feb  7 18:48:48.171: INFO: stderr: ""
Feb  7 18:48:48.171: INFO: stdout: "update-demo-nautilus-852rv update-demo-nautilus-nkdfh "
Feb  7 18:48:48.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 get pods update-demo-nautilus-852rv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rxkr7'
Feb  7 18:48:48.353: INFO: stderr: ""
Feb  7 18:48:48.353: INFO: stdout: ""
Feb  7 18:48:48.354: INFO: update-demo-nautilus-852rv is created but not running
Feb  7 18:48:53.354: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-rxkr7'
Feb  7 18:48:53.538: INFO: stderr: ""
Feb  7 18:48:53.539: INFO: stdout: "update-demo-nautilus-852rv update-demo-nautilus-nkdfh "
Feb  7 18:48:53.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 get pods update-demo-nautilus-852rv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rxkr7'
Feb  7 18:48:53.686: INFO: stderr: ""
Feb  7 18:48:53.686: INFO: stdout: "true"
Feb  7 18:48:53.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 get pods update-demo-nautilus-852rv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rxkr7'
Feb  7 18:48:53.848: INFO: stderr: ""
Feb  7 18:48:53.849: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  7 18:48:53.849: INFO: validating pod update-demo-nautilus-852rv
Feb  7 18:48:53.855: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  7 18:48:53.855: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  7 18:48:53.855: INFO: update-demo-nautilus-852rv is verified up and running
Feb  7 18:48:53.856: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 get pods update-demo-nautilus-nkdfh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rxkr7'
Feb  7 18:48:54.003: INFO: stderr: ""
Feb  7 18:48:54.003: INFO: stdout: "true"
Feb  7 18:48:54.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 get pods update-demo-nautilus-nkdfh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rxkr7'
Feb  7 18:48:54.157: INFO: stderr: ""
Feb  7 18:48:54.157: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  7 18:48:54.157: INFO: validating pod update-demo-nautilus-nkdfh
Feb  7 18:48:54.166: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  7 18:48:54.166: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  7 18:48:54.166: INFO: update-demo-nautilus-nkdfh is verified up and running
STEP: using delete to clean up resources
Feb  7 18:48:54.166: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-rxkr7'
Feb  7 18:48:54.318: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  7 18:48:54.318: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb  7 18:48:54.319: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-rxkr7'
Feb  7 18:48:54.619: INFO: stderr: "No resources found.\n"
Feb  7 18:48:54.619: INFO: stdout: ""
Feb  7 18:48:54.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 get pods -l name=update-demo --namespace=e2e-tests-kubectl-rxkr7 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb  7 18:48:54.879: INFO: stderr: ""
Feb  7 18:48:54.879: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:48:54.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-rxkr7" for this suite.
Feb  7 18:49:00.915: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:49:00.973: INFO: namespace: e2e-tests-kubectl-rxkr7, resource: bindings, ignored listing per whitelist
Feb  7 18:49:01.068: INFO: namespace e2e-tests-kubectl-rxkr7 deletion completed in 6.181415098s

• [SLOW TEST:13.776 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:49:01.069: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:49:23.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-runtime-pvb7x" for this suite.
Feb  7 18:49:29.633: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:49:29.718: INFO: namespace: e2e-tests-container-runtime-pvb7x, resource: bindings, ignored listing per whitelist
Feb  7 18:49:29.830: INFO: namespace e2e-tests-container-runtime-pvb7x deletion completed in 6.220795068s

• [SLOW TEST:28.761 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  blackbox test
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:49:29.831: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Feb  7 18:49:31.989: INFO: Pod pod-hostip-19d48f8c-2b09-11e9-90f5-5e78944a5b53 has hostIP: 10.10.1.212
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:49:31.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-556qj" for this suite.
Feb  7 18:49:54.012: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:49:54.096: INFO: namespace: e2e-tests-pods-556qj, resource: bindings, ignored listing per whitelist
Feb  7 18:49:54.165: INFO: namespace e2e-tests-pods-556qj deletion completed in 22.169038248s

• [SLOW TEST:24.334 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:49:54.165: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  7 18:49:54.331: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Feb  7 18:49:54.380: INFO: Number of nodes with available pods: 0
Feb  7 18:49:54.380: INFO: Node conformance0 is running more than one daemon pod
Feb  7 18:49:55.390: INFO: Number of nodes with available pods: 0
Feb  7 18:49:55.390: INFO: Node conformance0 is running more than one daemon pod
Feb  7 18:49:56.394: INFO: Number of nodes with available pods: 0
Feb  7 18:49:56.394: INFO: Node conformance0 is running more than one daemon pod
Feb  7 18:49:57.390: INFO: Number of nodes with available pods: 1
Feb  7 18:49:57.390: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Feb  7 18:49:57.434: INFO: Wrong image for pod: daemon-set-5w2x6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 18:49:58.458: INFO: Wrong image for pod: daemon-set-5w2x6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 18:49:59.458: INFO: Wrong image for pod: daemon-set-5w2x6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 18:50:00.459: INFO: Wrong image for pod: daemon-set-5w2x6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 18:50:01.459: INFO: Wrong image for pod: daemon-set-5w2x6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 18:50:02.459: INFO: Wrong image for pod: daemon-set-5w2x6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 18:50:03.459: INFO: Wrong image for pod: daemon-set-5w2x6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 18:50:04.460: INFO: Wrong image for pod: daemon-set-5w2x6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 18:50:05.458: INFO: Wrong image for pod: daemon-set-5w2x6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 18:50:06.459: INFO: Wrong image for pod: daemon-set-5w2x6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 18:50:07.459: INFO: Wrong image for pod: daemon-set-5w2x6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 18:50:08.458: INFO: Wrong image for pod: daemon-set-5w2x6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 18:50:09.459: INFO: Wrong image for pod: daemon-set-5w2x6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 18:50:10.460: INFO: Wrong image for pod: daemon-set-5w2x6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 18:50:11.459: INFO: Wrong image for pod: daemon-set-5w2x6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 18:50:12.458: INFO: Wrong image for pod: daemon-set-5w2x6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 18:50:13.458: INFO: Wrong image for pod: daemon-set-5w2x6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 18:50:14.458: INFO: Wrong image for pod: daemon-set-5w2x6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 18:50:15.459: INFO: Wrong image for pod: daemon-set-5w2x6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 18:50:16.459: INFO: Wrong image for pod: daemon-set-5w2x6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 18:50:17.459: INFO: Wrong image for pod: daemon-set-5w2x6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 18:50:18.459: INFO: Wrong image for pod: daemon-set-5w2x6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 18:50:19.461: INFO: Wrong image for pod: daemon-set-5w2x6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 18:50:20.458: INFO: Wrong image for pod: daemon-set-5w2x6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 18:50:21.459: INFO: Wrong image for pod: daemon-set-5w2x6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 18:50:22.460: INFO: Wrong image for pod: daemon-set-5w2x6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 18:50:23.459: INFO: Wrong image for pod: daemon-set-5w2x6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 18:50:24.458: INFO: Wrong image for pod: daemon-set-5w2x6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 18:50:25.459: INFO: Wrong image for pod: daemon-set-5w2x6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 18:50:26.459: INFO: Wrong image for pod: daemon-set-5w2x6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 18:50:27.460: INFO: Wrong image for pod: daemon-set-5w2x6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 18:50:28.458: INFO: Wrong image for pod: daemon-set-5w2x6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 18:50:29.460: INFO: Wrong image for pod: daemon-set-5w2x6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 18:50:30.458: INFO: Wrong image for pod: daemon-set-5w2x6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 18:50:30.459: INFO: Pod daemon-set-5w2x6 is not available
Feb  7 18:50:31.459: INFO: Wrong image for pod: daemon-set-5w2x6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 18:50:31.459: INFO: Pod daemon-set-5w2x6 is not available
Feb  7 18:50:32.459: INFO: Wrong image for pod: daemon-set-5w2x6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 18:50:32.459: INFO: Pod daemon-set-5w2x6 is not available
Feb  7 18:50:33.458: INFO: Wrong image for pod: daemon-set-5w2x6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 18:50:33.458: INFO: Pod daemon-set-5w2x6 is not available
Feb  7 18:50:34.459: INFO: Wrong image for pod: daemon-set-5w2x6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 18:50:34.459: INFO: Pod daemon-set-5w2x6 is not available
Feb  7 18:50:35.459: INFO: Wrong image for pod: daemon-set-5w2x6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 18:50:35.459: INFO: Pod daemon-set-5w2x6 is not available
Feb  7 18:50:36.459: INFO: Wrong image for pod: daemon-set-5w2x6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 18:50:36.459: INFO: Pod daemon-set-5w2x6 is not available
Feb  7 18:50:37.459: INFO: Wrong image for pod: daemon-set-5w2x6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 18:50:37.459: INFO: Pod daemon-set-5w2x6 is not available
Feb  7 18:50:38.460: INFO: Wrong image for pod: daemon-set-5w2x6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  7 18:50:38.460: INFO: Pod daemon-set-5w2x6 is not available
Feb  7 18:50:39.460: INFO: Pod daemon-set-w4mwq is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Feb  7 18:50:39.482: INFO: Number of nodes with available pods: 0
Feb  7 18:50:39.482: INFO: Node conformance0 is running more than one daemon pod
Feb  7 18:50:40.491: INFO: Number of nodes with available pods: 1
Feb  7 18:50:40.492: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-9lzhc, will wait for the garbage collector to delete the pods
Feb  7 18:50:40.603: INFO: Deleting DaemonSet.extensions daemon-set took: 22.566461ms
Feb  7 18:50:40.704: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.25581ms
Feb  7 18:50:48.808: INFO: Number of nodes with available pods: 0
Feb  7 18:50:48.808: INFO: Number of running nodes: 0, number of available pods: 0
Feb  7 18:50:48.814: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-9lzhc/daemonsets","resourceVersion":"6478"},"items":null}

Feb  7 18:50:48.819: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-9lzhc/pods","resourceVersion":"6478"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:50:48.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-9lzhc" for this suite.
Feb  7 18:50:54.857: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:50:54.931: INFO: namespace: e2e-tests-daemonsets-9lzhc, resource: bindings, ignored listing per whitelist
Feb  7 18:50:55.000: INFO: namespace e2e-tests-daemonsets-9lzhc deletion completed in 6.164215534s

• [SLOW TEST:60.835 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:50:55.000: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  7 18:50:55.154: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4c973f85-2b09-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-projected-tzdhm" to be "success or failure"
Feb  7 18:50:55.181: INFO: Pod "downwardapi-volume-4c973f85-2b09-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 26.625123ms
Feb  7 18:50:57.186: INFO: Pod "downwardapi-volume-4c973f85-2b09-11e9-90f5-5e78944a5b53": Phase="Running", Reason="", readiness=true. Elapsed: 2.031347534s
Feb  7 18:50:59.191: INFO: Pod "downwardapi-volume-4c973f85-2b09-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036482359s
STEP: Saw pod success
Feb  7 18:50:59.191: INFO: Pod "downwardapi-volume-4c973f85-2b09-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 18:50:59.196: INFO: Trying to get logs from node conformance0 pod downwardapi-volume-4c973f85-2b09-11e9-90f5-5e78944a5b53 container client-container: <nil>
STEP: delete the pod
Feb  7 18:50:59.239: INFO: Waiting for pod downwardapi-volume-4c973f85-2b09-11e9-90f5-5e78944a5b53 to disappear
Feb  7 18:50:59.249: INFO: Pod downwardapi-volume-4c973f85-2b09-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:50:59.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-tzdhm" for this suite.
Feb  7 18:51:05.275: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:51:05.376: INFO: namespace: e2e-tests-projected-tzdhm, resource: bindings, ignored listing per whitelist
Feb  7 18:51:05.427: INFO: namespace e2e-tests-projected-tzdhm deletion completed in 6.169530925s

• [SLOW TEST:10.427 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:51:05.429: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb  7 18:51:05.559: INFO: Waiting up to 5m0s for pod "pod-52ce69e2-2b09-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-emptydir-bgmcr" to be "success or failure"
Feb  7 18:51:05.568: INFO: Pod "pod-52ce69e2-2b09-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 8.448443ms
Feb  7 18:51:07.572: INFO: Pod "pod-52ce69e2-2b09-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012554932s
STEP: Saw pod success
Feb  7 18:51:07.572: INFO: Pod "pod-52ce69e2-2b09-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 18:51:07.578: INFO: Trying to get logs from node conformance0 pod pod-52ce69e2-2b09-11e9-90f5-5e78944a5b53 container test-container: <nil>
STEP: delete the pod
Feb  7 18:51:07.614: INFO: Waiting for pod pod-52ce69e2-2b09-11e9-90f5-5e78944a5b53 to disappear
Feb  7 18:51:07.632: INFO: Pod pod-52ce69e2-2b09-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:51:07.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-bgmcr" for this suite.
Feb  7 18:51:13.697: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:51:13.780: INFO: namespace: e2e-tests-emptydir-bgmcr, resource: bindings, ignored listing per whitelist
Feb  7 18:51:13.858: INFO: namespace e2e-tests-emptydir-bgmcr deletion completed in 6.193030903s

• [SLOW TEST:8.430 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:51:13.860: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Feb  7 18:51:13.988: INFO: Pod name pod-release: Found 0 pods out of 1
Feb  7 18:51:18.994: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:51:19.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-6jt42" for this suite.
Feb  7 18:51:25.105: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:51:25.212: INFO: namespace: e2e-tests-replication-controller-6jt42, resource: bindings, ignored listing per whitelist
Feb  7 18:51:25.269: INFO: namespace e2e-tests-replication-controller-6jt42 deletion completed in 6.205468123s

• [SLOW TEST:11.410 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:51:25.271: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Feb  7 18:51:25.423: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-4j96h,SelfLink:/api/v1/namespaces/e2e-tests-watch-4j96h/configmaps/e2e-watch-test-label-changed,UID:5ea22d30-2b09-11e9-a946-ceb99be2323d,ResourceVersion:6608,Generation:0,CreationTimestamp:2019-02-07 18:51:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb  7 18:51:25.424: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-4j96h,SelfLink:/api/v1/namespaces/e2e-tests-watch-4j96h/configmaps/e2e-watch-test-label-changed,UID:5ea22d30-2b09-11e9-a946-ceb99be2323d,ResourceVersion:6609,Generation:0,CreationTimestamp:2019-02-07 18:51:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb  7 18:51:25.424: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-4j96h,SelfLink:/api/v1/namespaces/e2e-tests-watch-4j96h/configmaps/e2e-watch-test-label-changed,UID:5ea22d30-2b09-11e9-a946-ceb99be2323d,ResourceVersion:6610,Generation:0,CreationTimestamp:2019-02-07 18:51:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Feb  7 18:51:35.474: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-4j96h,SelfLink:/api/v1/namespaces/e2e-tests-watch-4j96h/configmaps/e2e-watch-test-label-changed,UID:5ea22d30-2b09-11e9-a946-ceb99be2323d,ResourceVersion:6615,Generation:0,CreationTimestamp:2019-02-07 18:51:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb  7 18:51:35.474: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-4j96h,SelfLink:/api/v1/namespaces/e2e-tests-watch-4j96h/configmaps/e2e-watch-test-label-changed,UID:5ea22d30-2b09-11e9-a946-ceb99be2323d,ResourceVersion:6616,Generation:0,CreationTimestamp:2019-02-07 18:51:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Feb  7 18:51:35.474: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-4j96h,SelfLink:/api/v1/namespaces/e2e-tests-watch-4j96h/configmaps/e2e-watch-test-label-changed,UID:5ea22d30-2b09-11e9-a946-ceb99be2323d,ResourceVersion:6617,Generation:0,CreationTimestamp:2019-02-07 18:51:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:51:35.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-4j96h" for this suite.
Feb  7 18:51:41.498: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:51:41.587: INFO: namespace: e2e-tests-watch-4j96h, resource: bindings, ignored listing per whitelist
Feb  7 18:51:41.674: INFO: namespace e2e-tests-watch-4j96h deletion completed in 6.191952959s

• [SLOW TEST:16.403 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:51:41.676: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Feb  7 18:51:41.832: INFO: Waiting up to 5m0s for pod "pod-686be416-2b09-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-emptydir-9mj6p" to be "success or failure"
Feb  7 18:51:41.850: INFO: Pod "pod-686be416-2b09-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 18.312295ms
Feb  7 18:51:43.854: INFO: Pod "pod-686be416-2b09-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022267035s
STEP: Saw pod success
Feb  7 18:51:43.854: INFO: Pod "pod-686be416-2b09-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 18:51:43.858: INFO: Trying to get logs from node conformance0 pod pod-686be416-2b09-11e9-90f5-5e78944a5b53 container test-container: <nil>
STEP: delete the pod
Feb  7 18:51:43.908: INFO: Waiting for pod pod-686be416-2b09-11e9-90f5-5e78944a5b53 to disappear
Feb  7 18:51:43.922: INFO: Pod pod-686be416-2b09-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:51:43.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-9mj6p" for this suite.
Feb  7 18:51:49.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:51:50.016: INFO: namespace: e2e-tests-emptydir-9mj6p, resource: bindings, ignored listing per whitelist
Feb  7 18:51:50.082: INFO: namespace e2e-tests-emptydir-9mj6p deletion completed in 6.153796144s

• [SLOW TEST:8.406 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:51:50.082: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Feb  7 18:51:50.201: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-206495916 proxy --unix-socket=/tmp/kubectl-proxy-unix359753755/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:51:50.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-m5jzz" for this suite.
Feb  7 18:51:56.334: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:51:56.530: INFO: namespace: e2e-tests-kubectl-m5jzz, resource: bindings, ignored listing per whitelist
Feb  7 18:51:56.550: INFO: namespace e2e-tests-kubectl-m5jzz deletion completed in 6.235693504s

• [SLOW TEST:6.468 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:51:56.553: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  7 18:51:56.685: INFO: Waiting up to 5m0s for pod "downwardapi-volume-71473c93-2b09-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-projected-w2rs8" to be "success or failure"
Feb  7 18:51:56.689: INFO: Pod "downwardapi-volume-71473c93-2b09-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 4.288484ms
Feb  7 18:51:58.699: INFO: Pod "downwardapi-volume-71473c93-2b09-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013614247s
STEP: Saw pod success
Feb  7 18:51:58.699: INFO: Pod "downwardapi-volume-71473c93-2b09-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 18:51:58.711: INFO: Trying to get logs from node conformance0 pod downwardapi-volume-71473c93-2b09-11e9-90f5-5e78944a5b53 container client-container: <nil>
STEP: delete the pod
Feb  7 18:51:58.764: INFO: Waiting for pod downwardapi-volume-71473c93-2b09-11e9-90f5-5e78944a5b53 to disappear
Feb  7 18:51:58.775: INFO: Pod downwardapi-volume-71473c93-2b09-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:51:58.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-w2rs8" for this suite.
Feb  7 18:52:04.832: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:52:04.966: INFO: namespace: e2e-tests-projected-w2rs8, resource: bindings, ignored listing per whitelist
Feb  7 18:52:04.984: INFO: namespace e2e-tests-projected-w2rs8 deletion completed in 6.201689907s

• [SLOW TEST:8.431 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:52:04.984: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-764bb719-2b09-11e9-90f5-5e78944a5b53
STEP: Creating a pod to test consume secrets
Feb  7 18:52:05.104: INFO: Waiting up to 5m0s for pod "pod-secrets-764cd615-2b09-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-secrets-tnlmt" to be "success or failure"
Feb  7 18:52:05.113: INFO: Pod "pod-secrets-764cd615-2b09-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 8.817697ms
Feb  7 18:52:07.120: INFO: Pod "pod-secrets-764cd615-2b09-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015497196s
STEP: Saw pod success
Feb  7 18:52:07.120: INFO: Pod "pod-secrets-764cd615-2b09-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 18:52:07.126: INFO: Trying to get logs from node conformance0 pod pod-secrets-764cd615-2b09-11e9-90f5-5e78944a5b53 container secret-volume-test: <nil>
STEP: delete the pod
Feb  7 18:52:07.181: INFO: Waiting for pod pod-secrets-764cd615-2b09-11e9-90f5-5e78944a5b53 to disappear
Feb  7 18:52:07.192: INFO: Pod pod-secrets-764cd615-2b09-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:52:07.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-tnlmt" for this suite.
Feb  7 18:52:13.217: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:52:13.309: INFO: namespace: e2e-tests-secrets-tnlmt, resource: bindings, ignored listing per whitelist
Feb  7 18:52:13.361: INFO: namespace e2e-tests-secrets-tnlmt deletion completed in 6.162241786s

• [SLOW TEST:8.376 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:52:13.361: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:52:17.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-7hpd6" for this suite.
Feb  7 18:53:01.580: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:53:01.715: INFO: namespace: e2e-tests-kubelet-test-7hpd6, resource: bindings, ignored listing per whitelist
Feb  7 18:53:01.742: INFO: namespace e2e-tests-kubelet-test-7hpd6 deletion completed in 44.178694408s

• [SLOW TEST:48.381 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a read only busybox container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:186
    should not write to root filesystem [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:53:01.743: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb  7 18:53:06.426: INFO: Successfully updated pod "pod-update-9823ac20-2b09-11e9-90f5-5e78944a5b53"
STEP: verifying the updated pod is in kubernetes
Feb  7 18:53:06.442: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:53:06.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-xsf9q" for this suite.
Feb  7 18:53:28.461: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:53:28.583: INFO: namespace: e2e-tests-pods-xsf9q, resource: bindings, ignored listing per whitelist
Feb  7 18:53:28.641: INFO: namespace e2e-tests-pods-xsf9q deletion completed in 22.194945298s

• [SLOW TEST:26.899 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:53:28.643: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  7 18:53:28.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 version'
Feb  7 18:53:28.922: INFO: stderr: ""
Feb  7 18:53:28.922: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.3\", GitCommit:\"721bfa751924da8d1680787490c54b9179b1fed0\", GitTreeState:\"clean\", BuildDate:\"2019-02-01T20:00:57Z\", GoVersion:\"go1.11.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:53:28.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2hvt9" for this suite.
Feb  7 18:53:34.944: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:53:35.044: INFO: namespace: e2e-tests-kubectl-2hvt9, resource: bindings, ignored listing per whitelist
Feb  7 18:53:35.106: INFO: namespace e2e-tests-kubectl-2hvt9 deletion completed in 6.178105574s

• [SLOW TEST:6.463 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:53:35.106: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb  7 18:53:35.231: INFO: Waiting up to 5m0s for pod "pod-ac04020d-2b09-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-emptydir-z48qj" to be "success or failure"
Feb  7 18:53:35.238: INFO: Pod "pod-ac04020d-2b09-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 7.138224ms
Feb  7 18:53:37.243: INFO: Pod "pod-ac04020d-2b09-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011719533s
Feb  7 18:53:39.247: INFO: Pod "pod-ac04020d-2b09-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015870839s
STEP: Saw pod success
Feb  7 18:53:39.247: INFO: Pod "pod-ac04020d-2b09-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 18:53:39.254: INFO: Trying to get logs from node conformance0 pod pod-ac04020d-2b09-11e9-90f5-5e78944a5b53 container test-container: <nil>
STEP: delete the pod
Feb  7 18:53:39.307: INFO: Waiting for pod pod-ac04020d-2b09-11e9-90f5-5e78944a5b53 to disappear
Feb  7 18:53:39.315: INFO: Pod pod-ac04020d-2b09-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:53:39.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-z48qj" for this suite.
Feb  7 18:53:45.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:53:45.467: INFO: namespace: e2e-tests-emptydir-z48qj, resource: bindings, ignored listing per whitelist
Feb  7 18:53:45.481: INFO: namespace e2e-tests-emptydir-z48qj deletion completed in 6.158914771s

• [SLOW TEST:10.374 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:53:45.481: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-7z4k
STEP: Creating a pod to test atomic-volume-subpath
Feb  7 18:53:45.688: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-7z4k" in namespace "e2e-tests-subpath-lcrql" to be "success or failure"
Feb  7 18:53:45.709: INFO: Pod "pod-subpath-test-configmap-7z4k": Phase="Pending", Reason="", readiness=false. Elapsed: 20.704002ms
Feb  7 18:53:47.717: INFO: Pod "pod-subpath-test-configmap-7z4k": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029032705s
Feb  7 18:53:49.726: INFO: Pod "pod-subpath-test-configmap-7z4k": Phase="Running", Reason="", readiness=false. Elapsed: 4.037320311s
Feb  7 18:53:51.730: INFO: Pod "pod-subpath-test-configmap-7z4k": Phase="Running", Reason="", readiness=false. Elapsed: 6.041202914s
Feb  7 18:53:53.734: INFO: Pod "pod-subpath-test-configmap-7z4k": Phase="Running", Reason="", readiness=false. Elapsed: 8.045955799s
Feb  7 18:53:55.744: INFO: Pod "pod-subpath-test-configmap-7z4k": Phase="Running", Reason="", readiness=false. Elapsed: 10.055751794s
Feb  7 18:53:57.756: INFO: Pod "pod-subpath-test-configmap-7z4k": Phase="Running", Reason="", readiness=false. Elapsed: 12.06803912s
Feb  7 18:53:59.767: INFO: Pod "pod-subpath-test-configmap-7z4k": Phase="Running", Reason="", readiness=false. Elapsed: 14.078317925s
Feb  7 18:54:01.772: INFO: Pod "pod-subpath-test-configmap-7z4k": Phase="Running", Reason="", readiness=false. Elapsed: 16.083248061s
Feb  7 18:54:03.776: INFO: Pod "pod-subpath-test-configmap-7z4k": Phase="Running", Reason="", readiness=false. Elapsed: 18.087885768s
Feb  7 18:54:05.780: INFO: Pod "pod-subpath-test-configmap-7z4k": Phase="Running", Reason="", readiness=false. Elapsed: 20.092054109s
Feb  7 18:54:07.785: INFO: Pod "pod-subpath-test-configmap-7z4k": Phase="Running", Reason="", readiness=false. Elapsed: 22.096717253s
Feb  7 18:54:09.789: INFO: Pod "pod-subpath-test-configmap-7z4k": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.100313278s
STEP: Saw pod success
Feb  7 18:54:09.789: INFO: Pod "pod-subpath-test-configmap-7z4k" satisfied condition "success or failure"
Feb  7 18:54:09.794: INFO: Trying to get logs from node conformance0 pod pod-subpath-test-configmap-7z4k container test-container-subpath-configmap-7z4k: <nil>
STEP: delete the pod
Feb  7 18:54:09.825: INFO: Waiting for pod pod-subpath-test-configmap-7z4k to disappear
Feb  7 18:54:09.837: INFO: Pod pod-subpath-test-configmap-7z4k no longer exists
STEP: Deleting pod pod-subpath-test-configmap-7z4k
Feb  7 18:54:09.837: INFO: Deleting pod "pod-subpath-test-configmap-7z4k" in namespace "e2e-tests-subpath-lcrql"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:54:09.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-lcrql" for this suite.
Feb  7 18:54:15.887: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:54:15.935: INFO: namespace: e2e-tests-subpath-lcrql, resource: bindings, ignored listing per whitelist
Feb  7 18:54:16.022: INFO: namespace e2e-tests-subpath-lcrql deletion completed in 6.161738641s

• [SLOW TEST:30.541 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:54:16.022: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-c4665cef-2b09-11e9-90f5-5e78944a5b53
STEP: Creating a pod to test consume secrets
Feb  7 18:54:16.143: INFO: Waiting up to 5m0s for pod "pod-secrets-c467948e-2b09-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-secrets-kl85q" to be "success or failure"
Feb  7 18:54:16.150: INFO: Pod "pod-secrets-c467948e-2b09-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 7.73856ms
Feb  7 18:54:18.159: INFO: Pod "pod-secrets-c467948e-2b09-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016229089s
STEP: Saw pod success
Feb  7 18:54:18.159: INFO: Pod "pod-secrets-c467948e-2b09-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 18:54:18.167: INFO: Trying to get logs from node conformance0 pod pod-secrets-c467948e-2b09-11e9-90f5-5e78944a5b53 container secret-volume-test: <nil>
STEP: delete the pod
Feb  7 18:54:18.204: INFO: Waiting for pod pod-secrets-c467948e-2b09-11e9-90f5-5e78944a5b53 to disappear
Feb  7 18:54:18.216: INFO: Pod pod-secrets-c467948e-2b09-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:54:18.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-kl85q" for this suite.
Feb  7 18:54:24.248: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:54:24.303: INFO: namespace: e2e-tests-secrets-kl85q, resource: bindings, ignored listing per whitelist
Feb  7 18:54:24.412: INFO: namespace e2e-tests-secrets-kl85q deletion completed in 6.182492198s

• [SLOW TEST:8.390 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:54:24.413: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-c9670f7e-2b09-11e9-90f5-5e78944a5b53
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-c9670f7e-2b09-11e9-90f5-5e78944a5b53
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:54:28.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-dg5r2" for this suite.
Feb  7 18:54:50.627: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:54:50.677: INFO: namespace: e2e-tests-configmap-dg5r2, resource: bindings, ignored listing per whitelist
Feb  7 18:54:50.806: INFO: namespace e2e-tests-configmap-dg5r2 deletion completed in 22.20022245s

• [SLOW TEST:26.394 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:54:50.807: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-d922e491-2b09-11e9-90f5-5e78944a5b53
STEP: Creating a pod to test consume secrets
Feb  7 18:54:50.935: INFO: Waiting up to 5m0s for pod "pod-secrets-d9243111-2b09-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-secrets-fklm6" to be "success or failure"
Feb  7 18:54:50.939: INFO: Pod "pod-secrets-d9243111-2b09-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 4.154742ms
Feb  7 18:54:52.945: INFO: Pod "pod-secrets-d9243111-2b09-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00929778s
STEP: Saw pod success
Feb  7 18:54:52.945: INFO: Pod "pod-secrets-d9243111-2b09-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 18:54:52.965: INFO: Trying to get logs from node conformance0 pod pod-secrets-d9243111-2b09-11e9-90f5-5e78944a5b53 container secret-volume-test: <nil>
STEP: delete the pod
Feb  7 18:54:53.019: INFO: Waiting for pod pod-secrets-d9243111-2b09-11e9-90f5-5e78944a5b53 to disappear
Feb  7 18:54:53.028: INFO: Pod pod-secrets-d9243111-2b09-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:54:53.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-fklm6" for this suite.
Feb  7 18:54:59.071: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:54:59.203: INFO: namespace: e2e-tests-secrets-fklm6, resource: bindings, ignored listing per whitelist
Feb  7 18:54:59.225: INFO: namespace e2e-tests-secrets-fklm6 deletion completed in 6.184990851s

• [SLOW TEST:8.418 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:54:59.226: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-4cjg
STEP: Creating a pod to test atomic-volume-subpath
Feb  7 18:54:59.366: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-4cjg" in namespace "e2e-tests-subpath-rfqg5" to be "success or failure"
Feb  7 18:54:59.416: INFO: Pod "pod-subpath-test-secret-4cjg": Phase="Pending", Reason="", readiness=false. Elapsed: 49.967291ms
Feb  7 18:55:01.422: INFO: Pod "pod-subpath-test-secret-4cjg": Phase="Pending", Reason="", readiness=false. Elapsed: 2.055750889s
Feb  7 18:55:03.427: INFO: Pod "pod-subpath-test-secret-4cjg": Phase="Running", Reason="", readiness=false. Elapsed: 4.061000477s
Feb  7 18:55:05.432: INFO: Pod "pod-subpath-test-secret-4cjg": Phase="Running", Reason="", readiness=false. Elapsed: 6.065766941s
Feb  7 18:55:07.437: INFO: Pod "pod-subpath-test-secret-4cjg": Phase="Running", Reason="", readiness=false. Elapsed: 8.070563809s
Feb  7 18:55:09.442: INFO: Pod "pod-subpath-test-secret-4cjg": Phase="Running", Reason="", readiness=false. Elapsed: 10.075565141s
Feb  7 18:55:11.447: INFO: Pod "pod-subpath-test-secret-4cjg": Phase="Running", Reason="", readiness=false. Elapsed: 12.080386988s
Feb  7 18:55:13.451: INFO: Pod "pod-subpath-test-secret-4cjg": Phase="Running", Reason="", readiness=false. Elapsed: 14.08479105s
Feb  7 18:55:15.456: INFO: Pod "pod-subpath-test-secret-4cjg": Phase="Running", Reason="", readiness=false. Elapsed: 16.089457273s
Feb  7 18:55:17.460: INFO: Pod "pod-subpath-test-secret-4cjg": Phase="Running", Reason="", readiness=false. Elapsed: 18.094171473s
Feb  7 18:55:19.466: INFO: Pod "pod-subpath-test-secret-4cjg": Phase="Running", Reason="", readiness=false. Elapsed: 20.100016364s
Feb  7 18:55:21.470: INFO: Pod "pod-subpath-test-secret-4cjg": Phase="Running", Reason="", readiness=false. Elapsed: 22.10422803s
Feb  7 18:55:23.476: INFO: Pod "pod-subpath-test-secret-4cjg": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.109429591s
STEP: Saw pod success
Feb  7 18:55:23.476: INFO: Pod "pod-subpath-test-secret-4cjg" satisfied condition "success or failure"
Feb  7 18:55:23.483: INFO: Trying to get logs from node conformance0 pod pod-subpath-test-secret-4cjg container test-container-subpath-secret-4cjg: <nil>
STEP: delete the pod
Feb  7 18:55:23.522: INFO: Waiting for pod pod-subpath-test-secret-4cjg to disappear
Feb  7 18:55:23.548: INFO: Pod pod-subpath-test-secret-4cjg no longer exists
STEP: Deleting pod pod-subpath-test-secret-4cjg
Feb  7 18:55:23.548: INFO: Deleting pod "pod-subpath-test-secret-4cjg" in namespace "e2e-tests-subpath-rfqg5"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:55:23.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-rfqg5" for this suite.
Feb  7 18:55:29.606: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:55:29.679: INFO: namespace: e2e-tests-subpath-rfqg5, resource: bindings, ignored listing per whitelist
Feb  7 18:55:29.749: INFO: namespace e2e-tests-subpath-rfqg5 deletion completed in 6.188281521s

• [SLOW TEST:30.523 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:55:29.749: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  7 18:55:29.883: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Feb  7 18:55:34.889: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb  7 18:55:34.889: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb  7 18:55:36.959: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-dwf2g,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-dwf2g/deployments/test-cleanup-deployment,UID:f359cef9-2b09-11e9-a946-ceb99be2323d,ResourceVersion:7076,Generation:1,CreationTimestamp:2019-02-07 18:55:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 1,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-02-07 18:55:35 +0000 UTC 2019-02-07 18:55:35 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-02-07 18:55:36 +0000 UTC 2019-02-07 18:55:34 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-cleanup-deployment-7dbbfcf846" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb  7 18:55:36.966: INFO: New ReplicaSet "test-cleanup-deployment-7dbbfcf846" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-7dbbfcf846,GenerateName:,Namespace:e2e-tests-deployment-dwf2g,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-dwf2g/replicasets/test-cleanup-deployment-7dbbfcf846,UID:f35f54d4-2b09-11e9-a946-ceb99be2323d,ResourceVersion:7067,Generation:1,CreationTimestamp:2019-02-07 18:55:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment f359cef9-2b09-11e9-a946-ceb99be2323d 0xc0025813f7 0xc0025813f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb  7 18:55:36.970: INFO: Pod "test-cleanup-deployment-7dbbfcf846-wshjl" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-7dbbfcf846-wshjl,GenerateName:test-cleanup-deployment-7dbbfcf846-,Namespace:e2e-tests-deployment-dwf2g,SelfLink:/api/v1/namespaces/e2e-tests-deployment-dwf2g/pods/test-cleanup-deployment-7dbbfcf846-wshjl,UID:f360dd7c-2b09-11e9-a946-ceb99be2323d,ResourceVersion:7066,Generation:0,CreationTimestamp:2019-02-07 18:55:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-7dbbfcf846 f35f54d4-2b09-11e9-a946-ceb99be2323d 0xc0022e9567 0xc0022e9568}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-txpfl {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-txpfl,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-txpfl true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022e95e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022e9600}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 18:55:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 18:55:36 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 18:55:36 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 18:55:34 +0000 UTC  }],Message:,Reason:,HostIP:10.10.1.212,PodIP:10.244.0.151,StartTime:2019-02-07 18:55:34 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-02-07 18:55:36 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://1acdb3e1cf4c2b684c04a5c3ab0487585c1afe52758c7164a55afe2fa5269b12}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:55:36.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-dwf2g" for this suite.
Feb  7 18:55:43.013: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:55:43.162: INFO: namespace: e2e-tests-deployment-dwf2g, resource: bindings, ignored listing per whitelist
Feb  7 18:55:43.165: INFO: namespace e2e-tests-deployment-dwf2g deletion completed in 6.186210471s

• [SLOW TEST:13.416 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:55:43.167: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb  7 18:55:49.428: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  7 18:55:49.437: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  7 18:55:51.437: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  7 18:55:51.443: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  7 18:55:53.437: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  7 18:55:53.443: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  7 18:55:55.437: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  7 18:55:55.443: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  7 18:55:57.437: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  7 18:55:57.442: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  7 18:55:59.437: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  7 18:55:59.443: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  7 18:56:01.437: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  7 18:56:01.443: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  7 18:56:03.437: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  7 18:56:03.444: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  7 18:56:05.437: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  7 18:56:05.444: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  7 18:56:07.437: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  7 18:56:07.443: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  7 18:56:09.437: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  7 18:56:09.443: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  7 18:56:11.437: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  7 18:56:11.442: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  7 18:56:13.437: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  7 18:56:13.443: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  7 18:56:15.437: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  7 18:56:15.442: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  7 18:56:17.437: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  7 18:56:17.442: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  7 18:56:19.437: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  7 18:56:19.441: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 18:56:19.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-m5lzl" for this suite.
Feb  7 18:56:41.470: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 18:56:41.508: INFO: namespace: e2e-tests-container-lifecycle-hook-m5lzl, resource: bindings, ignored listing per whitelist
Feb  7 18:56:41.623: INFO: namespace e2e-tests-container-lifecycle-hook-m5lzl deletion completed in 22.1735823s

• [SLOW TEST:58.457 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 18:56:41.624: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-899x6
Feb  7 18:56:43.830: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-899x6
STEP: checking the pod's current state and verifying that restartCount is present
Feb  7 18:56:43.835: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:00:44.523: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-899x6" for this suite.
Feb  7 19:00:50.558: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:00:50.646: INFO: namespace: e2e-tests-container-probe-899x6, resource: bindings, ignored listing per whitelist
Feb  7 19:00:50.711: INFO: namespace e2e-tests-container-probe-899x6 deletion completed in 6.177187214s

• [SLOW TEST:249.086 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:00:50.711: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Feb  7 19:00:50.883: INFO: Waiting up to 5m0s for pod "pod-afb02304-2b0a-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-emptydir-cbslj" to be "success or failure"
Feb  7 19:00:50.891: INFO: Pod "pod-afb02304-2b0a-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 7.727637ms
Feb  7 19:00:52.896: INFO: Pod "pod-afb02304-2b0a-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01217395s
Feb  7 19:00:54.901: INFO: Pod "pod-afb02304-2b0a-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017088054s
STEP: Saw pod success
Feb  7 19:00:54.901: INFO: Pod "pod-afb02304-2b0a-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 19:00:54.906: INFO: Trying to get logs from node conformance0 pod pod-afb02304-2b0a-11e9-90f5-5e78944a5b53 container test-container: <nil>
STEP: delete the pod
Feb  7 19:00:54.944: INFO: Waiting for pod pod-afb02304-2b0a-11e9-90f5-5e78944a5b53 to disappear
Feb  7 19:00:54.967: INFO: Pod pod-afb02304-2b0a-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:00:54.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-cbslj" for this suite.
Feb  7 19:01:01.003: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:01:01.038: INFO: namespace: e2e-tests-emptydir-cbslj, resource: bindings, ignored listing per whitelist
Feb  7 19:01:01.161: INFO: namespace e2e-tests-emptydir-cbslj deletion completed in 6.188765685s

• [SLOW TEST:10.450 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:01:01.161: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb  7 19:01:01.299: INFO: Number of nodes with available pods: 0
Feb  7 19:01:01.299: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:01:02.311: INFO: Number of nodes with available pods: 0
Feb  7 19:01:02.311: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:01:03.307: INFO: Number of nodes with available pods: 0
Feb  7 19:01:03.308: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:01:04.310: INFO: Number of nodes with available pods: 0
Feb  7 19:01:04.310: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:01:05.308: INFO: Number of nodes with available pods: 1
Feb  7 19:01:05.308: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Stop a daemon pod, check that the daemon pod is revived.
Feb  7 19:01:05.339: INFO: Number of nodes with available pods: 0
Feb  7 19:01:05.339: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:01:06.351: INFO: Number of nodes with available pods: 0
Feb  7 19:01:06.351: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:01:07.351: INFO: Number of nodes with available pods: 0
Feb  7 19:01:07.351: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:01:08.349: INFO: Number of nodes with available pods: 0
Feb  7 19:01:08.349: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:01:09.351: INFO: Number of nodes with available pods: 0
Feb  7 19:01:09.351: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:01:10.353: INFO: Number of nodes with available pods: 0
Feb  7 19:01:10.353: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:01:11.350: INFO: Number of nodes with available pods: 0
Feb  7 19:01:11.350: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:01:12.350: INFO: Number of nodes with available pods: 0
Feb  7 19:01:12.350: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:01:13.351: INFO: Number of nodes with available pods: 0
Feb  7 19:01:13.351: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:01:14.349: INFO: Number of nodes with available pods: 0
Feb  7 19:01:14.349: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:01:15.347: INFO: Number of nodes with available pods: 0
Feb  7 19:01:15.347: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:01:16.349: INFO: Number of nodes with available pods: 0
Feb  7 19:01:16.349: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:01:17.351: INFO: Number of nodes with available pods: 0
Feb  7 19:01:17.351: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:01:18.349: INFO: Number of nodes with available pods: 0
Feb  7 19:01:18.349: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:01:19.350: INFO: Number of nodes with available pods: 0
Feb  7 19:01:19.350: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:01:20.350: INFO: Number of nodes with available pods: 0
Feb  7 19:01:20.350: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:01:21.348: INFO: Number of nodes with available pods: 0
Feb  7 19:01:21.348: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:01:22.351: INFO: Number of nodes with available pods: 0
Feb  7 19:01:22.351: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:01:23.350: INFO: Number of nodes with available pods: 0
Feb  7 19:01:23.350: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:01:24.360: INFO: Number of nodes with available pods: 0
Feb  7 19:01:24.360: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:01:25.349: INFO: Number of nodes with available pods: 0
Feb  7 19:01:25.349: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:01:26.349: INFO: Number of nodes with available pods: 0
Feb  7 19:01:26.349: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:01:27.350: INFO: Number of nodes with available pods: 0
Feb  7 19:01:27.350: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:01:28.348: INFO: Number of nodes with available pods: 0
Feb  7 19:01:28.348: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:01:29.350: INFO: Number of nodes with available pods: 0
Feb  7 19:01:29.350: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:01:30.350: INFO: Number of nodes with available pods: 0
Feb  7 19:01:30.350: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:01:31.349: INFO: Number of nodes with available pods: 0
Feb  7 19:01:31.349: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:01:32.349: INFO: Number of nodes with available pods: 0
Feb  7 19:01:32.349: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:01:33.349: INFO: Number of nodes with available pods: 0
Feb  7 19:01:33.349: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:01:34.349: INFO: Number of nodes with available pods: 0
Feb  7 19:01:34.349: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:01:35.349: INFO: Number of nodes with available pods: 0
Feb  7 19:01:35.349: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:01:36.347: INFO: Number of nodes with available pods: 0
Feb  7 19:01:36.347: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:01:37.349: INFO: Number of nodes with available pods: 0
Feb  7 19:01:37.349: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:01:38.349: INFO: Number of nodes with available pods: 0
Feb  7 19:01:38.349: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:01:39.349: INFO: Number of nodes with available pods: 0
Feb  7 19:01:39.349: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:01:40.349: INFO: Number of nodes with available pods: 0
Feb  7 19:01:40.349: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:01:41.351: INFO: Number of nodes with available pods: 0
Feb  7 19:01:41.351: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:01:42.350: INFO: Number of nodes with available pods: 0
Feb  7 19:01:42.350: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:01:43.350: INFO: Number of nodes with available pods: 0
Feb  7 19:01:43.350: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:01:44.351: INFO: Number of nodes with available pods: 0
Feb  7 19:01:44.351: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:01:45.352: INFO: Number of nodes with available pods: 0
Feb  7 19:01:45.352: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:01:46.350: INFO: Number of nodes with available pods: 0
Feb  7 19:01:46.350: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:01:47.352: INFO: Number of nodes with available pods: 0
Feb  7 19:01:47.352: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:01:48.350: INFO: Number of nodes with available pods: 0
Feb  7 19:01:48.350: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:01:49.347: INFO: Number of nodes with available pods: 0
Feb  7 19:01:49.348: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:01:50.350: INFO: Number of nodes with available pods: 1
Feb  7 19:01:50.350: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-vh6tt, will wait for the garbage collector to delete the pods
Feb  7 19:01:50.430: INFO: Deleting DaemonSet.extensions daemon-set took: 22.195712ms
Feb  7 19:01:50.530: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.386249ms
Feb  7 19:02:23.535: INFO: Number of nodes with available pods: 0
Feb  7 19:02:23.535: INFO: Number of running nodes: 0, number of available pods: 0
Feb  7 19:02:23.540: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-vh6tt/daemonsets","resourceVersion":"7377"},"items":null}

Feb  7 19:02:23.544: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-vh6tt/pods","resourceVersion":"7377"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:02:23.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-vh6tt" for this suite.
Feb  7 19:02:29.575: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:02:29.710: INFO: namespace: e2e-tests-daemonsets-vh6tt, resource: bindings, ignored listing per whitelist
Feb  7 19:02:29.723: INFO: namespace e2e-tests-daemonsets-vh6tt deletion completed in 6.165576369s

• [SLOW TEST:88.561 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:02:29.723: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  7 19:02:29.830: INFO: Creating ReplicaSet my-hostname-basic-eaabba27-2b0a-11e9-90f5-5e78944a5b53
Feb  7 19:02:29.846: INFO: Pod name my-hostname-basic-eaabba27-2b0a-11e9-90f5-5e78944a5b53: Found 0 pods out of 1
Feb  7 19:02:34.851: INFO: Pod name my-hostname-basic-eaabba27-2b0a-11e9-90f5-5e78944a5b53: Found 1 pods out of 1
Feb  7 19:02:34.851: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-eaabba27-2b0a-11e9-90f5-5e78944a5b53" is running
Feb  7 19:02:34.857: INFO: Pod "my-hostname-basic-eaabba27-2b0a-11e9-90f5-5e78944a5b53-z2q8n" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-07 19:02:29 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-07 19:02:31 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-07 19:02:31 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-07 19:02:29 +0000 UTC Reason: Message:}])
Feb  7 19:02:34.857: INFO: Trying to dial the pod
Feb  7 19:02:39.873: INFO: Controller my-hostname-basic-eaabba27-2b0a-11e9-90f5-5e78944a5b53: Got expected result from replica 1 [my-hostname-basic-eaabba27-2b0a-11e9-90f5-5e78944a5b53-z2q8n]: "my-hostname-basic-eaabba27-2b0a-11e9-90f5-5e78944a5b53-z2q8n", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:02:39.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-vs7qg" for this suite.
Feb  7 19:02:45.900: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:02:45.959: INFO: namespace: e2e-tests-replicaset-vs7qg, resource: bindings, ignored listing per whitelist
Feb  7 19:02:46.043: INFO: namespace e2e-tests-replicaset-vs7qg deletion completed in 6.162451747s

• [SLOW TEST:16.319 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:02:46.043: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb  7 19:02:52.242: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb  7 19:02:52.251: INFO: Pod pod-with-prestop-http-hook still exists
Feb  7 19:02:54.251: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb  7 19:02:54.257: INFO: Pod pod-with-prestop-http-hook still exists
Feb  7 19:02:56.251: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb  7 19:02:56.259: INFO: Pod pod-with-prestop-http-hook still exists
Feb  7 19:02:58.251: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb  7 19:02:58.257: INFO: Pod pod-with-prestop-http-hook still exists
Feb  7 19:03:00.251: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb  7 19:03:00.257: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:03:00.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-swz7c" for this suite.
Feb  7 19:03:24.295: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:03:24.382: INFO: namespace: e2e-tests-container-lifecycle-hook-swz7c, resource: bindings, ignored listing per whitelist
Feb  7 19:03:24.461: INFO: namespace e2e-tests-container-lifecycle-hook-swz7c deletion completed in 24.186452012s

• [SLOW TEST:38.418 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:03:24.463: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Feb  7 19:03:24.634: INFO: Waiting up to 5m0s for pod "client-containers-0b53b47a-2b0b-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-containers-77jrx" to be "success or failure"
Feb  7 19:03:24.649: INFO: Pod "client-containers-0b53b47a-2b0b-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 14.80241ms
Feb  7 19:03:26.657: INFO: Pod "client-containers-0b53b47a-2b0b-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022825917s
Feb  7 19:03:28.662: INFO: Pod "client-containers-0b53b47a-2b0b-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027200062s
STEP: Saw pod success
Feb  7 19:03:28.662: INFO: Pod "client-containers-0b53b47a-2b0b-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 19:03:28.667: INFO: Trying to get logs from node conformance0 pod client-containers-0b53b47a-2b0b-11e9-90f5-5e78944a5b53 container test-container: <nil>
STEP: delete the pod
Feb  7 19:03:28.706: INFO: Waiting for pod client-containers-0b53b47a-2b0b-11e9-90f5-5e78944a5b53 to disappear
Feb  7 19:03:28.715: INFO: Pod client-containers-0b53b47a-2b0b-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:03:28.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-77jrx" for this suite.
Feb  7 19:03:34.749: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:03:34.895: INFO: namespace: e2e-tests-containers-77jrx, resource: bindings, ignored listing per whitelist
Feb  7 19:03:34.918: INFO: namespace e2e-tests-containers-77jrx deletion completed in 6.18996393s

• [SLOW TEST:10.454 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:03:34.918: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb  7 19:03:35.033: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:03:38.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-4w6z5" for this suite.
Feb  7 19:03:44.470: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:03:44.598: INFO: namespace: e2e-tests-init-container-4w6z5, resource: bindings, ignored listing per whitelist
Feb  7 19:03:44.686: INFO: namespace e2e-tests-init-container-4w6z5 deletion completed in 6.233284038s

• [SLOW TEST:9.768 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:03:44.686: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  7 19:03:44.827: INFO: Creating deployment "nginx-deployment"
Feb  7 19:03:44.837: INFO: Waiting for observed generation 1
Feb  7 19:03:46.849: INFO: Waiting for all required pods to come up
Feb  7 19:03:46.861: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Feb  7 19:03:52.929: INFO: Waiting for deployment "nginx-deployment" to complete
Feb  7 19:03:52.938: INFO: Updating deployment "nginx-deployment" with a non-existent image
Feb  7 19:03:52.950: INFO: Updating deployment nginx-deployment
Feb  7 19:03:52.950: INFO: Waiting for observed generation 2
Feb  7 19:03:54.959: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Feb  7 19:03:54.968: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Feb  7 19:03:54.975: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Feb  7 19:03:55.000: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Feb  7 19:03:55.000: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Feb  7 19:03:55.010: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Feb  7 19:03:55.025: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Feb  7 19:03:55.025: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Feb  7 19:03:55.054: INFO: Updating deployment nginx-deployment
Feb  7 19:03:55.054: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Feb  7 19:03:55.078: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Feb  7 19:03:57.091: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb  7 19:03:57.105: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-grgj2,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-grgj2/deployments/nginx-deployment,UID:175fc64f-2b0b-11e9-a946-ceb99be2323d,ResourceVersion:7799,Generation:3,CreationTimestamp:2019-02-07 19:03:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-02-07 19:03:55 +0000 UTC 2019-02-07 19:03:55 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-02-07 19:03:55 +0000 UTC 2019-02-07 19:03:44 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-65bbdb5f8" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Feb  7 19:03:57.111: INFO: New ReplicaSet "nginx-deployment-65bbdb5f8" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8,GenerateName:,Namespace:e2e-tests-deployment-grgj2,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-grgj2/replicasets/nginx-deployment-65bbdb5f8,UID:1c37fdf9-2b0b-11e9-a946-ceb99be2323d,ResourceVersion:7789,Generation:3,CreationTimestamp:2019-02-07 19:03:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 175fc64f-2b0b-11e9-a946-ceb99be2323d 0xc002866727 0xc002866728}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb  7 19:03:57.111: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Feb  7 19:03:57.112: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965,GenerateName:,Namespace:e2e-tests-deployment-grgj2,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-grgj2/replicasets/nginx-deployment-555b55d965,UID:176234de-2b0b-11e9-a946-ceb99be2323d,ResourceVersion:7794,Generation:3,CreationTimestamp:2019-02-07 19:03:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 175fc64f-2b0b-11e9-a946-ceb99be2323d 0xc002866607 0xc002866608}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Feb  7 19:03:57.134: INFO: Pod "nginx-deployment-555b55d965-5bwnr" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-5bwnr,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-grgj2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-grgj2/pods/nginx-deployment-555b55d965-5bwnr,UID:176fd650-2b0b-11e9-a946-ceb99be2323d,ResourceVersion:7650,Generation:0,CreationTimestamp:2019-02-07 19:03:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 176234de-2b0b-11e9-a946-ceb99be2323d 0xc00194dc50 0xc00194dc51}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qwp6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qwp6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7qwp6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00194dcc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00194dce0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:45 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:51 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:51 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:45 +0000 UTC  }],Message:,Reason:,HostIP:10.10.1.212,PodIP:10.244.0.168,StartTime:2019-02-07 19:03:45 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-07 19:03:50 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://11e3fb6ca5e81c31df97d900938776219aa0c1cd1d964644b2ca83d45fd90e59}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  7 19:03:57.135: INFO: Pod "nginx-deployment-555b55d965-68clm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-68clm,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-grgj2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-grgj2/pods/nginx-deployment-555b55d965-68clm,UID:1db95523-2b0b-11e9-a946-ceb99be2323d,ResourceVersion:7787,Generation:0,CreationTimestamp:2019-02-07 19:03:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 176234de-2b0b-11e9-a946-ceb99be2323d 0xc00194de10 0xc00194de11}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qwp6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qwp6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7qwp6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00194de80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00194dea0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:55 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  7 19:03:57.135: INFO: Pod "nginx-deployment-555b55d965-b7bcw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-b7bcw,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-grgj2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-grgj2/pods/nginx-deployment-555b55d965-b7bcw,UID:1da561c4-2b0b-11e9-a946-ceb99be2323d,ResourceVersion:7767,Generation:0,CreationTimestamp:2019-02-07 19:03:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 176234de-2b0b-11e9-a946-ceb99be2323d 0xc00194df50 0xc00194df51}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qwp6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qwp6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7qwp6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00194dfc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00194dfe0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:55 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  7 19:03:57.135: INFO: Pod "nginx-deployment-555b55d965-d49kg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-d49kg,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-grgj2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-grgj2/pods/nginx-deployment-555b55d965-d49kg,UID:1d90f5e0-2b0b-11e9-a946-ceb99be2323d,ResourceVersion:7830,Generation:0,CreationTimestamp:2019-02-07 19:03:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 176234de-2b0b-11e9-a946-ceb99be2323d 0xc00097a050 0xc00097a051}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qwp6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qwp6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7qwp6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00097a0c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00097a0e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:55 +0000 UTC  }],Message:,Reason:,HostIP:10.10.1.212,PodIP:,StartTime:2019-02-07 19:03:55 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  7 19:03:57.136: INFO: Pod "nginx-deployment-555b55d965-f5xj6" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-f5xj6,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-grgj2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-grgj2/pods/nginx-deployment-555b55d965-f5xj6,UID:1770d240-2b0b-11e9-a946-ceb99be2323d,ResourceVersion:7674,Generation:0,CreationTimestamp:2019-02-07 19:03:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 176234de-2b0b-11e9-a946-ceb99be2323d 0xc00097a340 0xc00097a341}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qwp6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qwp6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7qwp6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00097a3b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00097a3d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:45 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:51 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:51 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:45 +0000 UTC  }],Message:,Reason:,HostIP:10.10.1.212,PodIP:10.244.0.167,StartTime:2019-02-07 19:03:45 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-07 19:03:50 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://46319b951f8fc90f0c1221ab7748d927cb61602f3bd4756073bddc1adb4d4903}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  7 19:03:57.136: INFO: Pod "nginx-deployment-555b55d965-hdmk9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-hdmk9,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-grgj2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-grgj2/pods/nginx-deployment-555b55d965-hdmk9,UID:17696035-2b0b-11e9-a946-ceb99be2323d,ResourceVersion:7647,Generation:0,CreationTimestamp:2019-02-07 19:03:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 176234de-2b0b-11e9-a946-ceb99be2323d 0xc00097a520 0xc00097a521}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qwp6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qwp6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7qwp6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00097a610} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00097a690}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:45 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:51 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:51 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:44 +0000 UTC  }],Message:,Reason:,HostIP:10.10.1.212,PodIP:10.244.0.165,StartTime:2019-02-07 19:03:45 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-07 19:03:49 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://39aeea59c6d8ec76ac769131e76a3a7b2292120101fee109eb523b29ff701a74}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  7 19:03:57.136: INFO: Pod "nginx-deployment-555b55d965-j4whz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-j4whz,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-grgj2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-grgj2/pods/nginx-deployment-555b55d965-j4whz,UID:1db66b34-2b0b-11e9-a946-ceb99be2323d,ResourceVersion:7780,Generation:0,CreationTimestamp:2019-02-07 19:03:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 176234de-2b0b-11e9-a946-ceb99be2323d 0xc00097a750 0xc00097a751}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qwp6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qwp6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7qwp6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00097a7c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00097a970}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:55 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  7 19:03:57.137: INFO: Pod "nginx-deployment-555b55d965-jndjk" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-jndjk,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-grgj2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-grgj2/pods/nginx-deployment-555b55d965-jndjk,UID:1766eb4a-2b0b-11e9-a946-ceb99be2323d,ResourceVersion:7633,Generation:0,CreationTimestamp:2019-02-07 19:03:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 176234de-2b0b-11e9-a946-ceb99be2323d 0xc00097a9e0 0xc00097a9e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qwp6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qwp6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7qwp6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00097aa50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00097aa70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:44 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:49 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:49 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:44 +0000 UTC  }],Message:,Reason:,HostIP:10.10.1.212,PodIP:10.244.0.163,StartTime:2019-02-07 19:03:44 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-07 19:03:47 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://a6d3ba98bd27c0274dac058850c1222db6c1a36e53196e08e72283efff239d7a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  7 19:03:57.137: INFO: Pod "nginx-deployment-555b55d965-jvv4b" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-jvv4b,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-grgj2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-grgj2/pods/nginx-deployment-555b55d965-jvv4b,UID:1770b626-2b0b-11e9-a946-ceb99be2323d,ResourceVersion:7657,Generation:0,CreationTimestamp:2019-02-07 19:03:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 176234de-2b0b-11e9-a946-ceb99be2323d 0xc00097ac90 0xc00097ac91}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qwp6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qwp6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7qwp6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00097ad00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00097ad20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:45 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:51 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:51 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:45 +0000 UTC  }],Message:,Reason:,HostIP:10.10.1.212,PodIP:10.244.0.166,StartTime:2019-02-07 19:03:45 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-07 19:03:49 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://53f7d85509c8b83232bd7d1584018837538ecef4e8cf012776ef7ba79e89ac71}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  7 19:03:57.137: INFO: Pod "nginx-deployment-555b55d965-jwft2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-jwft2,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-grgj2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-grgj2/pods/nginx-deployment-555b55d965-jwft2,UID:1d924d3b-2b0b-11e9-a946-ceb99be2323d,ResourceVersion:7824,Generation:0,CreationTimestamp:2019-02-07 19:03:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 176234de-2b0b-11e9-a946-ceb99be2323d 0xc00097aec0 0xc00097aec1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qwp6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qwp6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7qwp6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00097af30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00097af50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:55 +0000 UTC  }],Message:,Reason:,HostIP:10.10.1.212,PodIP:,StartTime:2019-02-07 19:03:55 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  7 19:03:57.138: INFO: Pod "nginx-deployment-555b55d965-klwjs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-klwjs,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-grgj2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-grgj2/pods/nginx-deployment-555b55d965-klwjs,UID:1db98e1a-2b0b-11e9-a946-ceb99be2323d,ResourceVersion:7788,Generation:0,CreationTimestamp:2019-02-07 19:03:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 176234de-2b0b-11e9-a946-ceb99be2323d 0xc00097b0c0 0xc00097b0c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qwp6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qwp6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7qwp6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00097b130} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00097b150}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:55 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  7 19:03:57.138: INFO: Pod "nginx-deployment-555b55d965-l55cq" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-l55cq,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-grgj2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-grgj2/pods/nginx-deployment-555b55d965-l55cq,UID:177b5c1d-2b0b-11e9-a946-ceb99be2323d,ResourceVersion:7671,Generation:0,CreationTimestamp:2019-02-07 19:03:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 176234de-2b0b-11e9-a946-ceb99be2323d 0xc00097b1c0 0xc00097b1c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qwp6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qwp6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7qwp6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00097b2c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00097b2e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:45 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:51 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:51 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:45 +0000 UTC  }],Message:,Reason:,HostIP:10.10.1.212,PodIP:10.244.0.171,StartTime:2019-02-07 19:03:45 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-07 19:03:50 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://8eef33f414a30f379648306d6469ab251909750c278fa73c0e4888b7be08083d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  7 19:03:57.138: INFO: Pod "nginx-deployment-555b55d965-lz22k" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-lz22k,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-grgj2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-grgj2/pods/nginx-deployment-555b55d965-lz22k,UID:1db5fb1f-2b0b-11e9-a946-ceb99be2323d,ResourceVersion:7778,Generation:0,CreationTimestamp:2019-02-07 19:03:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 176234de-2b0b-11e9-a946-ceb99be2323d 0xc00097b3a0 0xc00097b3a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qwp6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qwp6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7qwp6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00097b480} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00097b4a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:55 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  7 19:03:57.138: INFO: Pod "nginx-deployment-555b55d965-pdrpx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-pdrpx,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-grgj2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-grgj2/pods/nginx-deployment-555b55d965-pdrpx,UID:1da6476c-2b0b-11e9-a946-ceb99be2323d,ResourceVersion:7770,Generation:0,CreationTimestamp:2019-02-07 19:03:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 176234de-2b0b-11e9-a946-ceb99be2323d 0xc00097b510 0xc00097b511}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qwp6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qwp6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7qwp6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00097b580} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00097b5a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:55 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  7 19:03:57.139: INFO: Pod "nginx-deployment-555b55d965-rtrfq" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-rtrfq,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-grgj2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-grgj2/pods/nginx-deployment-555b55d965-rtrfq,UID:1770e033-2b0b-11e9-a946-ceb99be2323d,ResourceVersion:7660,Generation:0,CreationTimestamp:2019-02-07 19:03:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 176234de-2b0b-11e9-a946-ceb99be2323d 0xc00097b690 0xc00097b691}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qwp6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qwp6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7qwp6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00097b700} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00097b720}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:45 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:51 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:51 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:45 +0000 UTC  }],Message:,Reason:,HostIP:10.10.1.212,PodIP:10.244.0.169,StartTime:2019-02-07 19:03:45 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-07 19:03:50 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://6498f65302ca7a56df0b0f4dc52d5071e14dd141d2c5ff19c4dd585889d2812b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  7 19:03:57.139: INFO: Pod "nginx-deployment-555b55d965-rvftm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-rvftm,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-grgj2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-grgj2/pods/nginx-deployment-555b55d965-rvftm,UID:1da66aaf-2b0b-11e9-a946-ceb99be2323d,ResourceVersion:7765,Generation:0,CreationTimestamp:2019-02-07 19:03:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 176234de-2b0b-11e9-a946-ceb99be2323d 0xc00097b830 0xc00097b831}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qwp6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qwp6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7qwp6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00097b8a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00097b8c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:55 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  7 19:03:57.139: INFO: Pod "nginx-deployment-555b55d965-sjpcw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-sjpcw,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-grgj2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-grgj2/pods/nginx-deployment-555b55d965-sjpcw,UID:1d838c82-2b0b-11e9-a946-ceb99be2323d,ResourceVersion:7797,Generation:0,CreationTimestamp:2019-02-07 19:03:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 176234de-2b0b-11e9-a946-ceb99be2323d 0xc00097b930 0xc00097b931}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qwp6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qwp6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7qwp6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00097b9a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00097b9c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:55 +0000 UTC  }],Message:,Reason:,HostIP:10.10.1.212,PodIP:,StartTime:2019-02-07 19:03:55 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  7 19:03:57.140: INFO: Pod "nginx-deployment-555b55d965-tc5n4" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-tc5n4,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-grgj2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-grgj2/pods/nginx-deployment-555b55d965-tc5n4,UID:1768e6dd-2b0b-11e9-a946-ceb99be2323d,ResourceVersion:7664,Generation:0,CreationTimestamp:2019-02-07 19:03:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 176234de-2b0b-11e9-a946-ceb99be2323d 0xc00097ba70 0xc00097ba71}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qwp6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qwp6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7qwp6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00097bae0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00097bb00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:44 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:51 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:51 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:44 +0000 UTC  }],Message:,Reason:,HostIP:10.10.1.212,PodIP:10.244.0.164,StartTime:2019-02-07 19:03:44 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-07 19:03:48 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://701ceb1d71904803dcce0daff2052726b09588dd76670d3efa37e015551b0438}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  7 19:03:57.140: INFO: Pod "nginx-deployment-555b55d965-vbp8m" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-vbp8m,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-grgj2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-grgj2/pods/nginx-deployment-555b55d965-vbp8m,UID:1da6be74-2b0b-11e9-a946-ceb99be2323d,ResourceVersion:7769,Generation:0,CreationTimestamp:2019-02-07 19:03:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 176234de-2b0b-11e9-a946-ceb99be2323d 0xc00097bbc0 0xc00097bbc1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qwp6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qwp6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7qwp6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00097bc30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00097bc50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:55 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  7 19:03:57.140: INFO: Pod "nginx-deployment-555b55d965-x2sdl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-x2sdl,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-grgj2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-grgj2/pods/nginx-deployment-555b55d965-x2sdl,UID:1db6db50-2b0b-11e9-a946-ceb99be2323d,ResourceVersion:7786,Generation:0,CreationTimestamp:2019-02-07 19:03:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 176234de-2b0b-11e9-a946-ceb99be2323d 0xc00097bcc0 0xc00097bcc1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qwp6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qwp6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7qwp6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00097bd30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00097bd50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:55 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  7 19:03:57.140: INFO: Pod "nginx-deployment-65bbdb5f8-2bvnq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-2bvnq,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-grgj2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-grgj2/pods/nginx-deployment-65bbdb5f8-2bvnq,UID:1d8a6dfa-2b0b-11e9-a946-ceb99be2323d,ResourceVersion:7827,Generation:0,CreationTimestamp:2019-02-07 19:03:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 1c37fdf9-2b0b-11e9-a946-ceb99be2323d 0xc00097bdc0 0xc00097bdc1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qwp6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qwp6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7qwp6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00097be40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00097be60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:55 +0000 UTC  }],Message:,Reason:,HostIP:10.10.1.212,PodIP:,StartTime:2019-02-07 19:03:55 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  7 19:03:57.141: INFO: Pod "nginx-deployment-65bbdb5f8-6p7f8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-6p7f8,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-grgj2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-grgj2/pods/nginx-deployment-65bbdb5f8-6p7f8,UID:1c3ac26e-2b0b-11e9-a946-ceb99be2323d,ResourceVersion:7692,Generation:0,CreationTimestamp:2019-02-07 19:03:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 1c37fdf9-2b0b-11e9-a946-ceb99be2323d 0xc00097bf20 0xc00097bf21}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qwp6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qwp6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7qwp6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00097bfa0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00097bfc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:52 +0000 UTC  }],Message:,Reason:,HostIP:10.10.1.212,PodIP:,StartTime:2019-02-07 19:03:52 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  7 19:03:57.141: INFO: Pod "nginx-deployment-65bbdb5f8-9xtmh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-9xtmh,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-grgj2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-grgj2/pods/nginx-deployment-65bbdb5f8-9xtmh,UID:1c6fc84e-2b0b-11e9-a946-ceb99be2323d,ResourceVersion:7725,Generation:0,CreationTimestamp:2019-02-07 19:03:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 1c37fdf9-2b0b-11e9-a946-ceb99be2323d 0xc001ac80b0 0xc001ac80b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qwp6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qwp6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7qwp6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ac81a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ac81c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:53 +0000 UTC  }],Message:,Reason:,HostIP:10.10.1.212,PodIP:,StartTime:2019-02-07 19:03:53 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  7 19:03:57.141: INFO: Pod "nginx-deployment-65bbdb5f8-d5nsd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-d5nsd,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-grgj2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-grgj2/pods/nginx-deployment-65bbdb5f8-d5nsd,UID:1da5b9a2-2b0b-11e9-a946-ceb99be2323d,ResourceVersion:7833,Generation:0,CreationTimestamp:2019-02-07 19:03:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 1c37fdf9-2b0b-11e9-a946-ceb99be2323d 0xc001ac8290 0xc001ac8291}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qwp6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qwp6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7qwp6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ac8310} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ac8450}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:55 +0000 UTC  }],Message:,Reason:,HostIP:10.10.1.212,PodIP:,StartTime:2019-02-07 19:03:56 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  7 19:03:57.141: INFO: Pod "nginx-deployment-65bbdb5f8-gfv7q" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-gfv7q,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-grgj2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-grgj2/pods/nginx-deployment-65bbdb5f8-gfv7q,UID:1c4030a9-2b0b-11e9-a946-ceb99be2323d,ResourceVersion:7714,Generation:0,CreationTimestamp:2019-02-07 19:03:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 1c37fdf9-2b0b-11e9-a946-ceb99be2323d 0xc001ac8510 0xc001ac8511}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qwp6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qwp6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7qwp6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ac8600} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ac8620}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:53 +0000 UTC  }],Message:,Reason:,HostIP:10.10.1.212,PodIP:,StartTime:2019-02-07 19:03:53 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  7 19:03:57.141: INFO: Pod "nginx-deployment-65bbdb5f8-mdmf7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-mdmf7,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-grgj2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-grgj2/pods/nginx-deployment-65bbdb5f8-mdmf7,UID:1da60b6c-2b0b-11e9-a946-ceb99be2323d,ResourceVersion:7768,Generation:0,CreationTimestamp:2019-02-07 19:03:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 1c37fdf9-2b0b-11e9-a946-ceb99be2323d 0xc001ac86e0 0xc001ac86e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qwp6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qwp6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7qwp6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ac8830} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ac8850}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:55 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  7 19:03:57.142: INFO: Pod "nginx-deployment-65bbdb5f8-nj2kn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-nj2kn,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-grgj2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-grgj2/pods/nginx-deployment-65bbdb5f8-nj2kn,UID:1d97ecf0-2b0b-11e9-a946-ceb99be2323d,ResourceVersion:7760,Generation:0,CreationTimestamp:2019-02-07 19:03:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 1c37fdf9-2b0b-11e9-a946-ceb99be2323d 0xc001ac88c0 0xc001ac88c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qwp6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qwp6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7qwp6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ac8940} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ac8960}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:55 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  7 19:03:57.142: INFO: Pod "nginx-deployment-65bbdb5f8-npzlv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-npzlv,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-grgj2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-grgj2/pods/nginx-deployment-65bbdb5f8-npzlv,UID:1c44c072-2b0b-11e9-a946-ceb99be2323d,ResourceVersion:7724,Generation:0,CreationTimestamp:2019-02-07 19:03:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 1c37fdf9-2b0b-11e9-a946-ceb99be2323d 0xc001ac8a60 0xc001ac8a61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qwp6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qwp6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7qwp6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ac8ae0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ac8b00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:53 +0000 UTC  }],Message:,Reason:,HostIP:10.10.1.212,PodIP:,StartTime:2019-02-07 19:03:53 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  7 19:03:57.142: INFO: Pod "nginx-deployment-65bbdb5f8-qz6j7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-qz6j7,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-grgj2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-grgj2/pods/nginx-deployment-65bbdb5f8-qz6j7,UID:1da5e47b-2b0b-11e9-a946-ceb99be2323d,ResourceVersion:7766,Generation:0,CreationTimestamp:2019-02-07 19:03:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 1c37fdf9-2b0b-11e9-a946-ceb99be2323d 0xc001ac8c70 0xc001ac8c71}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qwp6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qwp6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7qwp6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ac8cf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ac8d10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:55 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  7 19:03:57.142: INFO: Pod "nginx-deployment-65bbdb5f8-r5w2l" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-r5w2l,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-grgj2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-grgj2/pods/nginx-deployment-65bbdb5f8-r5w2l,UID:1db34681-2b0b-11e9-a946-ceb99be2323d,ResourceVersion:7779,Generation:0,CreationTimestamp:2019-02-07 19:03:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 1c37fdf9-2b0b-11e9-a946-ceb99be2323d 0xc001ac8df0 0xc001ac8df1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qwp6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qwp6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7qwp6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ac8e70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ac8e90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:55 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  7 19:03:57.151: INFO: Pod "nginx-deployment-65bbdb5f8-swxxl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-swxxl,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-grgj2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-grgj2/pods/nginx-deployment-65bbdb5f8-swxxl,UID:1c809c91-2b0b-11e9-a946-ceb99be2323d,ResourceVersion:7726,Generation:0,CreationTimestamp:2019-02-07 19:03:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 1c37fdf9-2b0b-11e9-a946-ceb99be2323d 0xc001ac8f00 0xc001ac8f01}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qwp6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qwp6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7qwp6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ac8f80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ac8fa0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:53 +0000 UTC  }],Message:,Reason:,HostIP:10.10.1.212,PodIP:,StartTime:2019-02-07 19:03:53 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  7 19:03:57.151: INFO: Pod "nginx-deployment-65bbdb5f8-tt4px" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-tt4px,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-grgj2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-grgj2/pods/nginx-deployment-65bbdb5f8-tt4px,UID:1d983bb6-2b0b-11e9-a946-ceb99be2323d,ResourceVersion:7832,Generation:0,CreationTimestamp:2019-02-07 19:03:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 1c37fdf9-2b0b-11e9-a946-ceb99be2323d 0xc001ac9140 0xc001ac9141}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qwp6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qwp6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7qwp6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ac91c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ac91e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:55 +0000 UTC  }],Message:,Reason:,HostIP:10.10.1.212,PodIP:,StartTime:2019-02-07 19:03:55 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  7 19:03:57.151: INFO: Pod "nginx-deployment-65bbdb5f8-vxxjw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-vxxjw,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-grgj2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-grgj2/pods/nginx-deployment-65bbdb5f8-vxxjw,UID:1da2d4af-2b0b-11e9-a946-ceb99be2323d,ResourceVersion:7771,Generation:0,CreationTimestamp:2019-02-07 19:03:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 1c37fdf9-2b0b-11e9-a946-ceb99be2323d 0xc001ac9360 0xc001ac9361}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qwp6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qwp6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7qwp6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ac93e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ac9400}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:03:55 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:03:57.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-grgj2" for this suite.
Feb  7 19:04:07.204: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:04:07.434: INFO: namespace: e2e-tests-deployment-grgj2, resource: bindings, ignored listing per whitelist
Feb  7 19:04:07.731: INFO: namespace e2e-tests-deployment-grgj2 deletion completed in 10.573880643s

• [SLOW TEST:23.045 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:04:07.731: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb  7 19:04:22.143: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  7 19:04:22.151: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  7 19:04:24.151: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  7 19:04:24.157: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  7 19:04:26.151: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  7 19:04:26.156: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  7 19:04:28.151: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  7 19:04:28.157: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  7 19:04:30.151: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  7 19:04:30.157: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  7 19:04:32.151: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  7 19:04:32.155: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  7 19:04:34.151: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  7 19:04:34.159: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  7 19:04:36.151: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  7 19:04:36.155: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  7 19:04:38.151: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  7 19:04:38.157: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  7 19:04:40.151: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  7 19:04:40.156: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  7 19:04:42.151: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  7 19:04:42.156: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:04:42.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-7x2ft" for this suite.
Feb  7 19:05:06.191: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:05:06.269: INFO: namespace: e2e-tests-container-lifecycle-hook-7x2ft, resource: bindings, ignored listing per whitelist
Feb  7 19:05:06.341: INFO: namespace e2e-tests-container-lifecycle-hook-7x2ft deletion completed in 24.165799184s

• [SLOW TEST:58.610 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:05:06.342: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  7 19:05:06.487: INFO: Waiting up to 5m0s for pod "downwardapi-volume-480930d3-2b0b-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-downward-api-mxkxc" to be "success or failure"
Feb  7 19:05:06.494: INFO: Pod "downwardapi-volume-480930d3-2b0b-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 6.429036ms
Feb  7 19:05:08.498: INFO: Pod "downwardapi-volume-480930d3-2b0b-11e9-90f5-5e78944a5b53": Phase="Running", Reason="", readiness=true. Elapsed: 2.010687962s
Feb  7 19:05:10.503: INFO: Pod "downwardapi-volume-480930d3-2b0b-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015804399s
STEP: Saw pod success
Feb  7 19:05:10.503: INFO: Pod "downwardapi-volume-480930d3-2b0b-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 19:05:10.509: INFO: Trying to get logs from node conformance0 pod downwardapi-volume-480930d3-2b0b-11e9-90f5-5e78944a5b53 container client-container: <nil>
STEP: delete the pod
Feb  7 19:05:10.551: INFO: Waiting for pod downwardapi-volume-480930d3-2b0b-11e9-90f5-5e78944a5b53 to disappear
Feb  7 19:05:10.564: INFO: Pod downwardapi-volume-480930d3-2b0b-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:05:10.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-mxkxc" for this suite.
Feb  7 19:05:16.589: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:05:16.708: INFO: namespace: e2e-tests-downward-api-mxkxc, resource: bindings, ignored listing per whitelist
Feb  7 19:05:16.744: INFO: namespace e2e-tests-downward-api-mxkxc deletion completed in 6.1728646s

• [SLOW TEST:10.402 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:05:16.745: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Feb  7 19:05:16.865: INFO: Waiting up to 5m0s for pod "var-expansion-4e392fb6-2b0b-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-var-expansion-68fq2" to be "success or failure"
Feb  7 19:05:16.878: INFO: Pod "var-expansion-4e392fb6-2b0b-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 12.363603ms
Feb  7 19:05:18.882: INFO: Pod "var-expansion-4e392fb6-2b0b-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017140337s
STEP: Saw pod success
Feb  7 19:05:18.882: INFO: Pod "var-expansion-4e392fb6-2b0b-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 19:05:18.886: INFO: Trying to get logs from node conformance0 pod var-expansion-4e392fb6-2b0b-11e9-90f5-5e78944a5b53 container dapi-container: <nil>
STEP: delete the pod
Feb  7 19:05:18.923: INFO: Waiting for pod var-expansion-4e392fb6-2b0b-11e9-90f5-5e78944a5b53 to disappear
Feb  7 19:05:18.935: INFO: Pod var-expansion-4e392fb6-2b0b-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:05:18.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-68fq2" for this suite.
Feb  7 19:05:24.958: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:05:25.039: INFO: namespace: e2e-tests-var-expansion-68fq2, resource: bindings, ignored listing per whitelist
Feb  7 19:05:25.102: INFO: namespace e2e-tests-var-expansion-68fq2 deletion completed in 6.162194715s

• [SLOW TEST:8.357 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:05:25.102: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1527
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb  7 19:05:25.207: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-dv699'
Feb  7 19:05:25.673: INFO: stderr: ""
Feb  7 19:05:25.673: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1532
Feb  7 19:05:25.694: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-dv699'
Feb  7 19:05:28.725: INFO: stderr: ""
Feb  7 19:05:28.725: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:05:28.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-dv699" for this suite.
Feb  7 19:05:34.765: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:05:34.911: INFO: namespace: e2e-tests-kubectl-dv699, resource: bindings, ignored listing per whitelist
Feb  7 19:05:34.945: INFO: namespace e2e-tests-kubectl-dv699 deletion completed in 6.214737152s

• [SLOW TEST:9.843 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:05:34.947: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  7 19:05:35.071: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Feb  7 19:05:35.085: INFO: Pod name sample-pod: Found 0 pods out of 1
Feb  7 19:05:40.091: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb  7 19:05:40.091: INFO: Creating deployment "test-rolling-update-deployment"
Feb  7 19:05:40.102: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Feb  7 19:05:40.112: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Feb  7 19:05:42.122: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Feb  7 19:05:42.126: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb  7 19:05:42.140: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-8jb7w,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-8jb7w/deployments/test-rolling-update-deployment,UID:5c13bda9-2b0b-11e9-a946-ceb99be2323d,ResourceVersion:8210,Generation:1,CreationTimestamp:2019-02-07 19:05:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-02-07 19:05:40 +0000 UTC 2019-02-07 19:05:40 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-02-07 19:05:41 +0000 UTC 2019-02-07 19:05:40 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-68b55d7bc6" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb  7 19:05:42.147: INFO: New ReplicaSet "test-rolling-update-deployment-68b55d7bc6" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6,GenerateName:,Namespace:e2e-tests-deployment-8jb7w,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-8jb7w/replicasets/test-rolling-update-deployment-68b55d7bc6,UID:5c1a1f80-2b0b-11e9-a946-ceb99be2323d,ResourceVersion:8201,Generation:1,CreationTimestamp:2019-02-07 19:05:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 5c13bda9-2b0b-11e9-a946-ceb99be2323d 0xc0022a3867 0xc0022a3868}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb  7 19:05:42.147: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Feb  7 19:05:42.148: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-8jb7w,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-8jb7w/replicasets/test-rolling-update-controller,UID:5915ac08-2b0b-11e9-a946-ceb99be2323d,ResourceVersion:8209,Generation:2,CreationTimestamp:2019-02-07 19:05:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 5c13bda9-2b0b-11e9-a946-ceb99be2323d 0xc0022a379f 0xc0022a37b0}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb  7 19:05:42.154: INFO: Pod "test-rolling-update-deployment-68b55d7bc6-79f5k" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6-79f5k,GenerateName:test-rolling-update-deployment-68b55d7bc6-,Namespace:e2e-tests-deployment-8jb7w,SelfLink:/api/v1/namespaces/e2e-tests-deployment-8jb7w/pods/test-rolling-update-deployment-68b55d7bc6-79f5k,UID:5c1bd7a6-2b0b-11e9-a946-ceb99be2323d,ResourceVersion:8200,Generation:0,CreationTimestamp:2019-02-07 19:05:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-68b55d7bc6 5c1a1f80-2b0b-11e9-a946-ceb99be2323d 0xc0007ca1a7 0xc0007ca1a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-r5cbn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r5cbn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-r5cbn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0007ca290} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0007ca2b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:05:40 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:05:41 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:05:41 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:05:40 +0000 UTC  }],Message:,Reason:,HostIP:10.10.1.212,PodIP:10.244.0.199,StartTime:2019-02-07 19:05:40 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-02-07 19:05:41 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://3b5f78b9dd70080c7ec3bede7cf4a004f4760e325226f664c2032718cf7e2867}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:05:42.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-8jb7w" for this suite.
Feb  7 19:05:48.178: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:05:48.257: INFO: namespace: e2e-tests-deployment-8jb7w, resource: bindings, ignored listing per whitelist
Feb  7 19:05:48.351: INFO: namespace e2e-tests-deployment-8jb7w deletion completed in 6.191689888s

• [SLOW TEST:13.405 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:05:48.352: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  7 19:05:48.499: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Feb  7 19:05:48.514: INFO: Number of nodes with available pods: 0
Feb  7 19:05:48.514: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Feb  7 19:05:48.545: INFO: Number of nodes with available pods: 0
Feb  7 19:05:48.546: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:05:49.550: INFO: Number of nodes with available pods: 0
Feb  7 19:05:49.550: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:05:50.551: INFO: Number of nodes with available pods: 1
Feb  7 19:05:50.551: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Feb  7 19:05:50.585: INFO: Number of nodes with available pods: 1
Feb  7 19:05:50.585: INFO: Number of running nodes: 0, number of available pods: 1
Feb  7 19:05:51.593: INFO: Number of nodes with available pods: 0
Feb  7 19:05:51.594: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Feb  7 19:05:51.621: INFO: Number of nodes with available pods: 0
Feb  7 19:05:51.621: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:05:52.625: INFO: Number of nodes with available pods: 0
Feb  7 19:05:52.625: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:05:53.627: INFO: Number of nodes with available pods: 0
Feb  7 19:05:53.627: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:05:54.626: INFO: Number of nodes with available pods: 0
Feb  7 19:05:54.626: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:05:55.626: INFO: Number of nodes with available pods: 0
Feb  7 19:05:55.626: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:05:56.626: INFO: Number of nodes with available pods: 0
Feb  7 19:05:56.626: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:05:57.626: INFO: Number of nodes with available pods: 0
Feb  7 19:05:57.626: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:05:58.625: INFO: Number of nodes with available pods: 0
Feb  7 19:05:58.626: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:05:59.626: INFO: Number of nodes with available pods: 0
Feb  7 19:05:59.626: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:06:00.627: INFO: Number of nodes with available pods: 0
Feb  7 19:06:00.627: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:06:01.626: INFO: Number of nodes with available pods: 0
Feb  7 19:06:01.626: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:06:02.626: INFO: Number of nodes with available pods: 0
Feb  7 19:06:02.626: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:06:03.626: INFO: Number of nodes with available pods: 0
Feb  7 19:06:03.627: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:06:04.626: INFO: Number of nodes with available pods: 0
Feb  7 19:06:04.627: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:06:05.626: INFO: Number of nodes with available pods: 0
Feb  7 19:06:05.626: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:06:06.626: INFO: Number of nodes with available pods: 0
Feb  7 19:06:06.626: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:06:07.627: INFO: Number of nodes with available pods: 0
Feb  7 19:06:07.627: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:06:08.626: INFO: Number of nodes with available pods: 0
Feb  7 19:06:08.626: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:06:09.626: INFO: Number of nodes with available pods: 0
Feb  7 19:06:09.626: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:06:10.627: INFO: Number of nodes with available pods: 0
Feb  7 19:06:10.627: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:06:11.626: INFO: Number of nodes with available pods: 0
Feb  7 19:06:11.626: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:06:12.626: INFO: Number of nodes with available pods: 0
Feb  7 19:06:12.626: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:06:13.626: INFO: Number of nodes with available pods: 0
Feb  7 19:06:13.626: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:06:14.627: INFO: Number of nodes with available pods: 0
Feb  7 19:06:14.627: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:06:15.626: INFO: Number of nodes with available pods: 0
Feb  7 19:06:15.626: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:06:16.626: INFO: Number of nodes with available pods: 0
Feb  7 19:06:16.626: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:06:17.626: INFO: Number of nodes with available pods: 0
Feb  7 19:06:17.626: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:06:18.629: INFO: Number of nodes with available pods: 0
Feb  7 19:06:18.629: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:06:19.627: INFO: Number of nodes with available pods: 0
Feb  7 19:06:19.627: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:06:20.626: INFO: Number of nodes with available pods: 0
Feb  7 19:06:20.626: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:06:21.626: INFO: Number of nodes with available pods: 0
Feb  7 19:06:21.626: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:06:22.627: INFO: Number of nodes with available pods: 0
Feb  7 19:06:22.627: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:06:23.627: INFO: Number of nodes with available pods: 0
Feb  7 19:06:23.627: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:06:24.626: INFO: Number of nodes with available pods: 0
Feb  7 19:06:24.626: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:06:25.627: INFO: Number of nodes with available pods: 0
Feb  7 19:06:25.627: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:06:26.627: INFO: Number of nodes with available pods: 1
Feb  7 19:06:26.627: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-mjttl, will wait for the garbage collector to delete the pods
Feb  7 19:06:26.718: INFO: Deleting DaemonSet.extensions daemon-set took: 27.594586ms
Feb  7 19:06:26.818: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.387674ms
Feb  7 19:07:08.824: INFO: Number of nodes with available pods: 0
Feb  7 19:07:08.824: INFO: Number of running nodes: 0, number of available pods: 0
Feb  7 19:07:08.830: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-mjttl/daemonsets","resourceVersion":"8315"},"items":null}

Feb  7 19:07:08.834: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-mjttl/pods","resourceVersion":"8315"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:07:08.854: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-mjttl" for this suite.
Feb  7 19:07:14.880: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:07:14.927: INFO: namespace: e2e-tests-daemonsets-mjttl, resource: bindings, ignored listing per whitelist
Feb  7 19:07:15.059: INFO: namespace e2e-tests-daemonsets-mjttl deletion completed in 6.195997572s

• [SLOW TEST:86.707 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:07:15.060: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb  7 19:07:17.786: INFO: Successfully updated pod "annotationupdate94c52591-2b0b-11e9-90f5-5e78944a5b53"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:07:19.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-blxhl" for this suite.
Feb  7 19:07:41.839: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:07:41.886: INFO: namespace: e2e-tests-downward-api-blxhl, resource: bindings, ignored listing per whitelist
Feb  7 19:07:42.008: INFO: namespace e2e-tests-downward-api-blxhl deletion completed in 22.186447s

• [SLOW TEST:26.949 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:07:42.010: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-5dbzf
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Feb  7 19:07:42.161: INFO: Found 0 stateful pods, waiting for 3
Feb  7 19:07:52.166: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb  7 19:07:52.166: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb  7 19:07:52.166: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Feb  7 19:07:52.208: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Feb  7 19:08:02.255: INFO: Updating stateful set ss2
Feb  7 19:08:02.272: INFO: Waiting for Pod e2e-tests-statefulset-5dbzf/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Feb  7 19:08:12.551: INFO: Found 2 stateful pods, waiting for 3
Feb  7 19:08:22.558: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb  7 19:08:22.558: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb  7 19:08:22.558: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Feb  7 19:08:22.587: INFO: Updating stateful set ss2
Feb  7 19:08:22.605: INFO: Waiting for Pod e2e-tests-statefulset-5dbzf/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb  7 19:08:32.640: INFO: Updating stateful set ss2
Feb  7 19:08:32.652: INFO: Waiting for StatefulSet e2e-tests-statefulset-5dbzf/ss2 to complete update
Feb  7 19:08:32.652: INFO: Waiting for Pod e2e-tests-statefulset-5dbzf/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb  7 19:08:42.661: INFO: Deleting all statefulset in ns e2e-tests-statefulset-5dbzf
Feb  7 19:08:42.666: INFO: Scaling statefulset ss2 to 0
Feb  7 19:09:02.702: INFO: Waiting for statefulset status.replicas updated to 0
Feb  7 19:09:02.707: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:09:02.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-5dbzf" for this suite.
Feb  7 19:09:08.776: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:09:08.858: INFO: namespace: e2e-tests-statefulset-5dbzf, resource: bindings, ignored listing per whitelist
Feb  7 19:09:08.963: INFO: namespace e2e-tests-statefulset-5dbzf deletion completed in 6.209034772s

• [SLOW TEST:86.953 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:09:08.963: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-d8a47e88-2b0b-11e9-90f5-5e78944a5b53
STEP: Creating a pod to test consume secrets
Feb  7 19:09:09.096: INFO: Waiting up to 5m0s for pod "pod-secrets-d8a5734a-2b0b-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-secrets-zwqzr" to be "success or failure"
Feb  7 19:09:09.103: INFO: Pod "pod-secrets-d8a5734a-2b0b-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 7.208039ms
Feb  7 19:09:11.108: INFO: Pod "pod-secrets-d8a5734a-2b0b-11e9-90f5-5e78944a5b53": Phase="Running", Reason="", readiness=true. Elapsed: 2.011806836s
Feb  7 19:09:13.112: INFO: Pod "pod-secrets-d8a5734a-2b0b-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016264133s
STEP: Saw pod success
Feb  7 19:09:13.112: INFO: Pod "pod-secrets-d8a5734a-2b0b-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 19:09:13.118: INFO: Trying to get logs from node conformance0 pod pod-secrets-d8a5734a-2b0b-11e9-90f5-5e78944a5b53 container secret-volume-test: <nil>
STEP: delete the pod
Feb  7 19:09:13.167: INFO: Waiting for pod pod-secrets-d8a5734a-2b0b-11e9-90f5-5e78944a5b53 to disappear
Feb  7 19:09:13.172: INFO: Pod pod-secrets-d8a5734a-2b0b-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:09:13.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-zwqzr" for this suite.
Feb  7 19:09:19.195: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:09:19.332: INFO: namespace: e2e-tests-secrets-zwqzr, resource: bindings, ignored listing per whitelist
Feb  7 19:09:19.356: INFO: namespace e2e-tests-secrets-zwqzr deletion completed in 6.177492252s

• [SLOW TEST:10.393 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:09:19.357: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb  7 19:09:19.476: INFO: Waiting up to 5m0s for pod "downward-api-ded50528-2b0b-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-downward-api-wxl46" to be "success or failure"
Feb  7 19:09:19.482: INFO: Pod "downward-api-ded50528-2b0b-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 6.139749ms
Feb  7 19:09:21.488: INFO: Pod "downward-api-ded50528-2b0b-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011679862s
STEP: Saw pod success
Feb  7 19:09:21.488: INFO: Pod "downward-api-ded50528-2b0b-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 19:09:21.492: INFO: Trying to get logs from node conformance0 pod downward-api-ded50528-2b0b-11e9-90f5-5e78944a5b53 container dapi-container: <nil>
STEP: delete the pod
Feb  7 19:09:21.545: INFO: Waiting for pod downward-api-ded50528-2b0b-11e9-90f5-5e78944a5b53 to disappear
Feb  7 19:09:21.560: INFO: Pod downward-api-ded50528-2b0b-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:09:21.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-wxl46" for this suite.
Feb  7 19:09:27.612: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:09:27.707: INFO: namespace: e2e-tests-downward-api-wxl46, resource: bindings, ignored listing per whitelist
Feb  7 19:09:27.752: INFO: namespace e2e-tests-downward-api-wxl46 deletion completed in 6.181294141s

• [SLOW TEST:8.395 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:09:27.753: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-e3d6f428-2b0b-11e9-90f5-5e78944a5b53
STEP: Creating a pod to test consume configMaps
Feb  7 19:09:27.885: INFO: Waiting up to 5m0s for pod "pod-configmaps-e3d82deb-2b0b-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-configmap-dk42n" to be "success or failure"
Feb  7 19:09:27.895: INFO: Pod "pod-configmaps-e3d82deb-2b0b-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 10.074158ms
Feb  7 19:09:29.900: INFO: Pod "pod-configmaps-e3d82deb-2b0b-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015033257s
STEP: Saw pod success
Feb  7 19:09:29.900: INFO: Pod "pod-configmaps-e3d82deb-2b0b-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 19:09:29.906: INFO: Trying to get logs from node conformance0 pod pod-configmaps-e3d82deb-2b0b-11e9-90f5-5e78944a5b53 container configmap-volume-test: <nil>
STEP: delete the pod
Feb  7 19:09:29.959: INFO: Waiting for pod pod-configmaps-e3d82deb-2b0b-11e9-90f5-5e78944a5b53 to disappear
Feb  7 19:09:29.970: INFO: Pod pod-configmaps-e3d82deb-2b0b-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:09:29.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-dk42n" for this suite.
Feb  7 19:09:36.021: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:09:36.059: INFO: namespace: e2e-tests-configmap-dk42n, resource: bindings, ignored listing per whitelist
Feb  7 19:09:36.182: INFO: namespace e2e-tests-configmap-dk42n deletion completed in 6.203952336s

• [SLOW TEST:8.429 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:09:36.182: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Feb  7 19:09:36.316: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-2vchd" to be "success or failure"
Feb  7 19:09:36.322: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 6.463784ms
Feb  7 19:09:38.331: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014533505s
STEP: Saw pod success
Feb  7 19:09:38.331: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Feb  7 19:09:38.337: INFO: Trying to get logs from node conformance0 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Feb  7 19:09:38.377: INFO: Waiting for pod pod-host-path-test to disappear
Feb  7 19:09:38.382: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:09:38.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-2vchd" for this suite.
Feb  7 19:09:44.410: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:09:44.463: INFO: namespace: e2e-tests-hostpath-2vchd, resource: bindings, ignored listing per whitelist
Feb  7 19:09:44.580: INFO: namespace e2e-tests-hostpath-2vchd deletion completed in 6.191189023s

• [SLOW TEST:8.397 seconds]
[sig-storage] HostPath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:09:44.581: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Feb  7 19:09:49.748: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:09:49.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-xhgv6" for this suite.
Feb  7 19:10:11.834: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:10:11.954: INFO: namespace: e2e-tests-replicaset-xhgv6, resource: bindings, ignored listing per whitelist
Feb  7 19:10:12.001: INFO: namespace e2e-tests-replicaset-xhgv6 deletion completed in 22.200250502s

• [SLOW TEST:27.420 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:10:12.002: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  7 19:10:12.133: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fe369db5-2b0b-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-projected-prk8z" to be "success or failure"
Feb  7 19:10:12.142: INFO: Pod "downwardapi-volume-fe369db5-2b0b-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 8.525837ms
Feb  7 19:10:14.147: INFO: Pod "downwardapi-volume-fe369db5-2b0b-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013311834s
STEP: Saw pod success
Feb  7 19:10:14.147: INFO: Pod "downwardapi-volume-fe369db5-2b0b-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 19:10:14.151: INFO: Trying to get logs from node conformance0 pod downwardapi-volume-fe369db5-2b0b-11e9-90f5-5e78944a5b53 container client-container: <nil>
STEP: delete the pod
Feb  7 19:10:14.187: INFO: Waiting for pod downwardapi-volume-fe369db5-2b0b-11e9-90f5-5e78944a5b53 to disappear
Feb  7 19:10:14.203: INFO: Pod downwardapi-volume-fe369db5-2b0b-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:10:14.203: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-prk8z" for this suite.
Feb  7 19:10:20.249: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:10:20.334: INFO: namespace: e2e-tests-projected-prk8z, resource: bindings, ignored listing per whitelist
Feb  7 19:10:20.383: INFO: namespace e2e-tests-projected-prk8z deletion completed in 6.162455739s

• [SLOW TEST:8.382 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:10:20.384: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Feb  7 19:10:20.540: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-xjt77,SelfLink:/api/v1/namespaces/e2e-tests-watch-xjt77/configmaps/e2e-watch-test-resource-version,UID:0336329c-2b0c-11e9-a946-ceb99be2323d,ResourceVersion:8881,Generation:0,CreationTimestamp:2019-02-07 19:10:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb  7 19:10:20.548: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-xjt77,SelfLink:/api/v1/namespaces/e2e-tests-watch-xjt77/configmaps/e2e-watch-test-resource-version,UID:0336329c-2b0c-11e9-a946-ceb99be2323d,ResourceVersion:8882,Generation:0,CreationTimestamp:2019-02-07 19:10:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:10:20.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-xjt77" for this suite.
Feb  7 19:10:26.586: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:10:26.738: INFO: namespace: e2e-tests-watch-xjt77, resource: bindings, ignored listing per whitelist
Feb  7 19:10:26.762: INFO: namespace e2e-tests-watch-xjt77 deletion completed in 6.19045343s

• [SLOW TEST:6.378 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:10:26.763: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Feb  7 19:10:26.902: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 create -f - --namespace=e2e-tests-kubectl-zks7g'
Feb  7 19:10:27.367: INFO: stderr: ""
Feb  7 19:10:27.367: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb  7 19:10:27.368: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-zks7g'
Feb  7 19:10:27.633: INFO: stderr: ""
Feb  7 19:10:27.633: INFO: stdout: "update-demo-nautilus-6jc8z update-demo-nautilus-fv2lr "
Feb  7 19:10:27.633: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 get pods update-demo-nautilus-6jc8z -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zks7g'
Feb  7 19:10:27.806: INFO: stderr: ""
Feb  7 19:10:27.806: INFO: stdout: ""
Feb  7 19:10:27.806: INFO: update-demo-nautilus-6jc8z is created but not running
Feb  7 19:10:32.806: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-zks7g'
Feb  7 19:10:32.968: INFO: stderr: ""
Feb  7 19:10:32.968: INFO: stdout: "update-demo-nautilus-6jc8z update-demo-nautilus-fv2lr "
Feb  7 19:10:32.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 get pods update-demo-nautilus-6jc8z -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zks7g'
Feb  7 19:10:33.117: INFO: stderr: ""
Feb  7 19:10:33.117: INFO: stdout: "true"
Feb  7 19:10:33.117: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 get pods update-demo-nautilus-6jc8z -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zks7g'
Feb  7 19:10:33.272: INFO: stderr: ""
Feb  7 19:10:33.272: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  7 19:10:33.272: INFO: validating pod update-demo-nautilus-6jc8z
Feb  7 19:10:33.280: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  7 19:10:33.280: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  7 19:10:33.280: INFO: update-demo-nautilus-6jc8z is verified up and running
Feb  7 19:10:33.280: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 get pods update-demo-nautilus-fv2lr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zks7g'
Feb  7 19:10:33.424: INFO: stderr: ""
Feb  7 19:10:33.424: INFO: stdout: "true"
Feb  7 19:10:33.425: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 get pods update-demo-nautilus-fv2lr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zks7g'
Feb  7 19:10:33.576: INFO: stderr: ""
Feb  7 19:10:33.576: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  7 19:10:33.576: INFO: validating pod update-demo-nautilus-fv2lr
Feb  7 19:10:33.586: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  7 19:10:33.586: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  7 19:10:33.586: INFO: update-demo-nautilus-fv2lr is verified up and running
STEP: scaling down the replication controller
Feb  7 19:10:33.594: INFO: scanned /root for discovery docs: <nil>
Feb  7 19:10:33.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-zks7g'
Feb  7 19:10:34.842: INFO: stderr: ""
Feb  7 19:10:34.842: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb  7 19:10:34.842: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-zks7g'
Feb  7 19:10:35.000: INFO: stderr: ""
Feb  7 19:10:35.000: INFO: stdout: "update-demo-nautilus-6jc8z update-demo-nautilus-fv2lr "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb  7 19:10:40.001: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-zks7g'
Feb  7 19:10:40.155: INFO: stderr: ""
Feb  7 19:10:40.155: INFO: stdout: "update-demo-nautilus-6jc8z "
Feb  7 19:10:40.155: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 get pods update-demo-nautilus-6jc8z -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zks7g'
Feb  7 19:10:40.316: INFO: stderr: ""
Feb  7 19:10:40.316: INFO: stdout: "true"
Feb  7 19:10:40.316: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 get pods update-demo-nautilus-6jc8z -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zks7g'
Feb  7 19:10:40.475: INFO: stderr: ""
Feb  7 19:10:40.475: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  7 19:10:40.475: INFO: validating pod update-demo-nautilus-6jc8z
Feb  7 19:10:40.483: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  7 19:10:40.483: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  7 19:10:40.483: INFO: update-demo-nautilus-6jc8z is verified up and running
STEP: scaling up the replication controller
Feb  7 19:10:40.488: INFO: scanned /root for discovery docs: <nil>
Feb  7 19:10:40.488: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-zks7g'
Feb  7 19:10:41.726: INFO: stderr: ""
Feb  7 19:10:41.726: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb  7 19:10:41.726: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-zks7g'
Feb  7 19:10:41.946: INFO: stderr: ""
Feb  7 19:10:41.946: INFO: stdout: "update-demo-nautilus-6jc8z update-demo-nautilus-9vdcc "
Feb  7 19:10:41.946: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 get pods update-demo-nautilus-6jc8z -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zks7g'
Feb  7 19:10:42.121: INFO: stderr: ""
Feb  7 19:10:42.121: INFO: stdout: "true"
Feb  7 19:10:42.121: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 get pods update-demo-nautilus-6jc8z -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zks7g'
Feb  7 19:10:42.273: INFO: stderr: ""
Feb  7 19:10:42.273: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  7 19:10:42.273: INFO: validating pod update-demo-nautilus-6jc8z
Feb  7 19:10:42.280: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  7 19:10:42.280: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  7 19:10:42.280: INFO: update-demo-nautilus-6jc8z is verified up and running
Feb  7 19:10:42.280: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 get pods update-demo-nautilus-9vdcc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zks7g'
Feb  7 19:10:42.422: INFO: stderr: ""
Feb  7 19:10:42.422: INFO: stdout: ""
Feb  7 19:10:42.422: INFO: update-demo-nautilus-9vdcc is created but not running
Feb  7 19:10:47.423: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-zks7g'
Feb  7 19:10:47.591: INFO: stderr: ""
Feb  7 19:10:47.591: INFO: stdout: "update-demo-nautilus-6jc8z update-demo-nautilus-9vdcc "
Feb  7 19:10:47.592: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 get pods update-demo-nautilus-6jc8z -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zks7g'
Feb  7 19:10:47.751: INFO: stderr: ""
Feb  7 19:10:47.751: INFO: stdout: "true"
Feb  7 19:10:47.751: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 get pods update-demo-nautilus-6jc8z -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zks7g'
Feb  7 19:10:47.915: INFO: stderr: ""
Feb  7 19:10:47.916: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  7 19:10:47.916: INFO: validating pod update-demo-nautilus-6jc8z
Feb  7 19:10:47.923: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  7 19:10:47.923: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  7 19:10:47.923: INFO: update-demo-nautilus-6jc8z is verified up and running
Feb  7 19:10:47.924: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 get pods update-demo-nautilus-9vdcc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zks7g'
Feb  7 19:10:48.089: INFO: stderr: ""
Feb  7 19:10:48.089: INFO: stdout: "true"
Feb  7 19:10:48.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 get pods update-demo-nautilus-9vdcc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zks7g'
Feb  7 19:10:48.275: INFO: stderr: ""
Feb  7 19:10:48.275: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  7 19:10:48.275: INFO: validating pod update-demo-nautilus-9vdcc
Feb  7 19:10:48.282: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  7 19:10:48.282: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  7 19:10:48.282: INFO: update-demo-nautilus-9vdcc is verified up and running
STEP: using delete to clean up resources
Feb  7 19:10:48.282: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-zks7g'
Feb  7 19:10:48.427: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  7 19:10:48.427: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb  7 19:10:48.427: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-zks7g'
Feb  7 19:10:48.761: INFO: stderr: "No resources found.\n"
Feb  7 19:10:48.761: INFO: stdout: ""
Feb  7 19:10:48.762: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 get pods -l name=update-demo --namespace=e2e-tests-kubectl-zks7g -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb  7 19:10:48.957: INFO: stderr: ""
Feb  7 19:10:48.957: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:10:48.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-zks7g" for this suite.
Feb  7 19:11:10.985: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:11:11.104: INFO: namespace: e2e-tests-kubectl-zks7g, resource: bindings, ignored listing per whitelist
Feb  7 19:11:11.201: INFO: namespace e2e-tests-kubectl-zks7g deletion completed in 22.23755617s

• [SLOW TEST:44.439 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:11:11.202: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-217dfa61-2b0c-11e9-90f5-5e78944a5b53
STEP: Creating a pod to test consume secrets
Feb  7 19:11:11.316: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-217ee361-2b0c-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-projected-8xt4v" to be "success or failure"
Feb  7 19:11:11.321: INFO: Pod "pod-projected-secrets-217ee361-2b0c-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 4.990849ms
Feb  7 19:11:13.325: INFO: Pod "pod-projected-secrets-217ee361-2b0c-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009482067s
STEP: Saw pod success
Feb  7 19:11:13.326: INFO: Pod "pod-projected-secrets-217ee361-2b0c-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 19:11:13.332: INFO: Trying to get logs from node conformance0 pod pod-projected-secrets-217ee361-2b0c-11e9-90f5-5e78944a5b53 container secret-volume-test: <nil>
STEP: delete the pod
Feb  7 19:11:13.362: INFO: Waiting for pod pod-projected-secrets-217ee361-2b0c-11e9-90f5-5e78944a5b53 to disappear
Feb  7 19:11:13.374: INFO: Pod pod-projected-secrets-217ee361-2b0c-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:11:13.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8xt4v" for this suite.
Feb  7 19:11:19.394: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:11:19.470: INFO: namespace: e2e-tests-projected-8xt4v, resource: bindings, ignored listing per whitelist
Feb  7 19:11:19.562: INFO: namespace e2e-tests-projected-8xt4v deletion completed in 6.18295601s

• [SLOW TEST:8.361 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:11:19.563: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-267af022-2b0c-11e9-90f5-5e78944a5b53
STEP: Creating a pod to test consume configMaps
Feb  7 19:11:19.694: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-267bfaf5-2b0c-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-projected-65x2p" to be "success or failure"
Feb  7 19:11:19.700: INFO: Pod "pod-projected-configmaps-267bfaf5-2b0c-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 6.100684ms
Feb  7 19:11:21.704: INFO: Pod "pod-projected-configmaps-267bfaf5-2b0c-11e9-90f5-5e78944a5b53": Phase="Running", Reason="", readiness=true. Elapsed: 2.010813519s
Feb  7 19:11:23.708: INFO: Pod "pod-projected-configmaps-267bfaf5-2b0c-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014757393s
STEP: Saw pod success
Feb  7 19:11:23.709: INFO: Pod "pod-projected-configmaps-267bfaf5-2b0c-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 19:11:23.714: INFO: Trying to get logs from node conformance0 pod pod-projected-configmaps-267bfaf5-2b0c-11e9-90f5-5e78944a5b53 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  7 19:11:23.759: INFO: Waiting for pod pod-projected-configmaps-267bfaf5-2b0c-11e9-90f5-5e78944a5b53 to disappear
Feb  7 19:11:23.772: INFO: Pod pod-projected-configmaps-267bfaf5-2b0c-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:11:23.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-65x2p" for this suite.
Feb  7 19:11:29.801: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:11:29.945: INFO: namespace: e2e-tests-projected-65x2p, resource: bindings, ignored listing per whitelist
Feb  7 19:11:29.956: INFO: namespace e2e-tests-projected-65x2p deletion completed in 6.171685716s

• [SLOW TEST:10.392 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:11:29.957: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:11:36.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-4nlvq" for this suite.
Feb  7 19:11:42.243: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:11:42.298: INFO: namespace: e2e-tests-namespaces-4nlvq, resource: bindings, ignored listing per whitelist
Feb  7 19:11:42.383: INFO: namespace e2e-tests-namespaces-4nlvq deletion completed in 6.154837847s
STEP: Destroying namespace "e2e-tests-nsdeletetest-bsngd" for this suite.
Feb  7 19:11:42.388: INFO: Namespace e2e-tests-nsdeletetest-bsngd was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-n5bjs" for this suite.
Feb  7 19:11:48.404: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:11:48.543: INFO: namespace: e2e-tests-nsdeletetest-n5bjs, resource: bindings, ignored listing per whitelist
Feb  7 19:11:48.553: INFO: namespace e2e-tests-nsdeletetest-n5bjs deletion completed in 6.16526293s

• [SLOW TEST:18.597 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:11:48.554: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-37c3d490-2b0c-11e9-90f5-5e78944a5b53
STEP: Creating a pod to test consume secrets
Feb  7 19:11:48.687: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-37c4ce75-2b0c-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-projected-jg6pn" to be "success or failure"
Feb  7 19:11:48.701: INFO: Pod "pod-projected-secrets-37c4ce75-2b0c-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 13.542262ms
Feb  7 19:11:50.705: INFO: Pod "pod-projected-secrets-37c4ce75-2b0c-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017995711s
STEP: Saw pod success
Feb  7 19:11:50.705: INFO: Pod "pod-projected-secrets-37c4ce75-2b0c-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 19:11:50.711: INFO: Trying to get logs from node conformance0 pod pod-projected-secrets-37c4ce75-2b0c-11e9-90f5-5e78944a5b53 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb  7 19:11:50.776: INFO: Waiting for pod pod-projected-secrets-37c4ce75-2b0c-11e9-90f5-5e78944a5b53 to disappear
Feb  7 19:11:50.798: INFO: Pod pod-projected-secrets-37c4ce75-2b0c-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:11:50.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jg6pn" for this suite.
Feb  7 19:11:56.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:11:56.934: INFO: namespace: e2e-tests-projected-jg6pn, resource: bindings, ignored listing per whitelist
Feb  7 19:11:57.003: INFO: namespace e2e-tests-projected-jg6pn deletion completed in 6.196310694s

• [SLOW TEST:8.449 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:11:57.005: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-l9w5
STEP: Creating a pod to test atomic-volume-subpath
Feb  7 19:11:57.171: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-l9w5" in namespace "e2e-tests-subpath-rnk62" to be "success or failure"
Feb  7 19:11:57.185: INFO: Pod "pod-subpath-test-projected-l9w5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.222431ms
Feb  7 19:11:59.205: INFO: Pod "pod-subpath-test-projected-l9w5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034363041s
Feb  7 19:12:01.210: INFO: Pod "pod-subpath-test-projected-l9w5": Phase="Running", Reason="", readiness=false. Elapsed: 4.039364682s
Feb  7 19:12:03.215: INFO: Pod "pod-subpath-test-projected-l9w5": Phase="Running", Reason="", readiness=false. Elapsed: 6.043884998s
Feb  7 19:12:05.219: INFO: Pod "pod-subpath-test-projected-l9w5": Phase="Running", Reason="", readiness=false. Elapsed: 8.048694742s
Feb  7 19:12:07.233: INFO: Pod "pod-subpath-test-projected-l9w5": Phase="Running", Reason="", readiness=false. Elapsed: 10.062593317s
Feb  7 19:12:09.238: INFO: Pod "pod-subpath-test-projected-l9w5": Phase="Running", Reason="", readiness=false. Elapsed: 12.06715673s
Feb  7 19:12:11.292: INFO: Pod "pod-subpath-test-projected-l9w5": Phase="Running", Reason="", readiness=false. Elapsed: 14.121588389s
Feb  7 19:12:13.303: INFO: Pod "pod-subpath-test-projected-l9w5": Phase="Running", Reason="", readiness=false. Elapsed: 16.132609583s
Feb  7 19:12:15.358: INFO: Pod "pod-subpath-test-projected-l9w5": Phase="Running", Reason="", readiness=false. Elapsed: 18.18755395s
Feb  7 19:12:17.363: INFO: Pod "pod-subpath-test-projected-l9w5": Phase="Running", Reason="", readiness=false. Elapsed: 20.192071743s
Feb  7 19:12:19.367: INFO: Pod "pod-subpath-test-projected-l9w5": Phase="Running", Reason="", readiness=false. Elapsed: 22.196732837s
Feb  7 19:12:21.372: INFO: Pod "pod-subpath-test-projected-l9w5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.201381931s
STEP: Saw pod success
Feb  7 19:12:21.372: INFO: Pod "pod-subpath-test-projected-l9w5" satisfied condition "success or failure"
Feb  7 19:12:21.379: INFO: Trying to get logs from node conformance0 pod pod-subpath-test-projected-l9w5 container test-container-subpath-projected-l9w5: <nil>
STEP: delete the pod
Feb  7 19:12:21.431: INFO: Waiting for pod pod-subpath-test-projected-l9w5 to disappear
Feb  7 19:12:21.437: INFO: Pod pod-subpath-test-projected-l9w5 no longer exists
STEP: Deleting pod pod-subpath-test-projected-l9w5
Feb  7 19:12:21.437: INFO: Deleting pod "pod-subpath-test-projected-l9w5" in namespace "e2e-tests-subpath-rnk62"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:12:21.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-rnk62" for this suite.
Feb  7 19:12:27.494: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:12:27.643: INFO: namespace: e2e-tests-subpath-rnk62, resource: bindings, ignored listing per whitelist
Feb  7 19:12:27.654: INFO: namespace e2e-tests-subpath-rnk62 deletion completed in 6.195780062s

• [SLOW TEST:30.649 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:12:27.655: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb  7 19:12:27.822: INFO: Waiting up to 5m0s for pod "pod-4f14e431-2b0c-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-emptydir-p4frd" to be "success or failure"
Feb  7 19:12:27.853: INFO: Pod "pod-4f14e431-2b0c-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 30.875914ms
Feb  7 19:12:29.857: INFO: Pod "pod-4f14e431-2b0c-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.035157804s
STEP: Saw pod success
Feb  7 19:12:29.857: INFO: Pod "pod-4f14e431-2b0c-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 19:12:29.860: INFO: Trying to get logs from node conformance0 pod pod-4f14e431-2b0c-11e9-90f5-5e78944a5b53 container test-container: <nil>
STEP: delete the pod
Feb  7 19:12:29.909: INFO: Waiting for pod pod-4f14e431-2b0c-11e9-90f5-5e78944a5b53 to disappear
Feb  7 19:12:29.920: INFO: Pod pod-4f14e431-2b0c-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:12:29.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-p4frd" for this suite.
Feb  7 19:12:35.974: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:12:36.015: INFO: namespace: e2e-tests-emptydir-p4frd, resource: bindings, ignored listing per whitelist
Feb  7 19:12:36.121: INFO: namespace e2e-tests-emptydir-p4frd deletion completed in 6.179557194s

• [SLOW TEST:8.466 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:12:36.121: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-5424d77e-2b0c-11e9-90f5-5e78944a5b53
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:12:40.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-bkxm6" for this suite.
Feb  7 19:13:10.389: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:13:10.560: INFO: namespace: e2e-tests-configmap-bkxm6, resource: bindings, ignored listing per whitelist
Feb  7 19:13:10.570: INFO: namespace e2e-tests-configmap-bkxm6 deletion completed in 30.196935076s

• [SLOW TEST:34.448 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:13:10.570: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Feb  7 19:13:10.680: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-206495916 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:13:10.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-p2rkm" for this suite.
Feb  7 19:13:16.827: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:13:16.879: INFO: namespace: e2e-tests-kubectl-p2rkm, resource: bindings, ignored listing per whitelist
Feb  7 19:13:16.970: INFO: namespace e2e-tests-kubectl-p2rkm deletion completed in 6.159299911s

• [SLOW TEST:6.400 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:13:16.971: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Feb  7 19:13:17.074: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 create -f - --namespace=e2e-tests-kubectl-qbj9r'
Feb  7 19:13:17.467: INFO: stderr: ""
Feb  7 19:13:17.467: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb  7 19:13:18.473: INFO: Selector matched 1 pods for map[app:redis]
Feb  7 19:13:18.473: INFO: Found 0 / 1
Feb  7 19:13:19.472: INFO: Selector matched 1 pods for map[app:redis]
Feb  7 19:13:19.473: INFO: Found 1 / 1
Feb  7 19:13:19.473: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Feb  7 19:13:19.479: INFO: Selector matched 1 pods for map[app:redis]
Feb  7 19:13:19.479: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb  7 19:13:19.479: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 patch pod redis-master-9wlfh --namespace=e2e-tests-kubectl-qbj9r -p {"metadata":{"annotations":{"x":"y"}}}'
Feb  7 19:13:19.640: INFO: stderr: ""
Feb  7 19:13:19.640: INFO: stdout: "pod/redis-master-9wlfh patched\n"
STEP: checking annotations
Feb  7 19:13:19.648: INFO: Selector matched 1 pods for map[app:redis]
Feb  7 19:13:19.648: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:13:19.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-qbj9r" for this suite.
Feb  7 19:13:41.690: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:13:41.792: INFO: namespace: e2e-tests-kubectl-qbj9r, resource: bindings, ignored listing per whitelist
Feb  7 19:13:41.832: INFO: namespace e2e-tests-kubectl-qbj9r deletion completed in 22.167414184s

• [SLOW TEST:24.862 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:13:41.833: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb  7 19:13:41.964: INFO: Waiting up to 5m0s for pod "pod-7b487523-2b0c-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-emptydir-hwz2m" to be "success or failure"
Feb  7 19:13:41.968: INFO: Pod "pod-7b487523-2b0c-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 4.375487ms
Feb  7 19:13:43.972: INFO: Pod "pod-7b487523-2b0c-11e9-90f5-5e78944a5b53": Phase="Running", Reason="", readiness=true. Elapsed: 2.008238766s
Feb  7 19:13:45.976: INFO: Pod "pod-7b487523-2b0c-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012823136s
STEP: Saw pod success
Feb  7 19:13:45.976: INFO: Pod "pod-7b487523-2b0c-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 19:13:45.981: INFO: Trying to get logs from node conformance0 pod pod-7b487523-2b0c-11e9-90f5-5e78944a5b53 container test-container: <nil>
STEP: delete the pod
Feb  7 19:13:46.019: INFO: Waiting for pod pod-7b487523-2b0c-11e9-90f5-5e78944a5b53 to disappear
Feb  7 19:13:46.033: INFO: Pod pod-7b487523-2b0c-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:13:46.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-hwz2m" for this suite.
Feb  7 19:13:52.060: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:13:52.213: INFO: namespace: e2e-tests-emptydir-hwz2m, resource: bindings, ignored listing per whitelist
Feb  7 19:13:52.227: INFO: namespace e2e-tests-emptydir-hwz2m deletion completed in 6.186985356s

• [SLOW TEST:10.395 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:13:52.229: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb  7 19:13:52.381: INFO: Waiting up to 5m0s for pod "downward-api-817eedc1-2b0c-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-downward-api-dmxwm" to be "success or failure"
Feb  7 19:13:52.395: INFO: Pod "downward-api-817eedc1-2b0c-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 13.613488ms
Feb  7 19:13:54.406: INFO: Pod "downward-api-817eedc1-2b0c-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024813852s
Feb  7 19:13:56.410: INFO: Pod "downward-api-817eedc1-2b0c-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028867101s
STEP: Saw pod success
Feb  7 19:13:56.410: INFO: Pod "downward-api-817eedc1-2b0c-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 19:13:56.415: INFO: Trying to get logs from node conformance0 pod downward-api-817eedc1-2b0c-11e9-90f5-5e78944a5b53 container dapi-container: <nil>
STEP: delete the pod
Feb  7 19:13:56.460: INFO: Waiting for pod downward-api-817eedc1-2b0c-11e9-90f5-5e78944a5b53 to disappear
Feb  7 19:13:56.473: INFO: Pod downward-api-817eedc1-2b0c-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:13:56.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-dmxwm" for this suite.
Feb  7 19:14:02.499: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:14:02.557: INFO: namespace: e2e-tests-downward-api-dmxwm, resource: bindings, ignored listing per whitelist
Feb  7 19:14:02.687: INFO: namespace e2e-tests-downward-api-dmxwm deletion completed in 6.206091648s

• [SLOW TEST:10.458 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:14:02.689: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  7 19:14:02.944: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"87c05c26-2b0c-11e9-a946-ceb99be2323d", Controller:(*bool)(0xc0022e91d6), BlockOwnerDeletion:(*bool)(0xc0022e91d7)}}
Feb  7 19:14:02.984: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"87bd6c69-2b0c-11e9-a946-ceb99be2323d", Controller:(*bool)(0xc0022e93b2), BlockOwnerDeletion:(*bool)(0xc0022e93b3)}}
Feb  7 19:14:03.015: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"87bef8c2-2b0c-11e9-a946-ceb99be2323d", Controller:(*bool)(0xc002581466), BlockOwnerDeletion:(*bool)(0xc002581467)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:14:08.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-bldxc" for this suite.
Feb  7 19:14:14.071: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:14:14.187: INFO: namespace: e2e-tests-gc-bldxc, resource: bindings, ignored listing per whitelist
Feb  7 19:14:14.237: INFO: namespace e2e-tests-gc-bldxc deletion completed in 6.182204996s

• [SLOW TEST:11.548 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:14:14.237: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb  7 19:14:14.335: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-xtlg5'
Feb  7 19:14:14.499: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb  7 19:14:14.499: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Feb  7 19:14:14.516: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-xtlg5'
Feb  7 19:14:14.709: INFO: stderr: ""
Feb  7 19:14:14.709: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:14:14.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xtlg5" for this suite.
Feb  7 19:14:20.744: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:14:20.885: INFO: namespace: e2e-tests-kubectl-xtlg5, resource: bindings, ignored listing per whitelist
Feb  7 19:14:20.919: INFO: namespace e2e-tests-kubectl-xtlg5 deletion completed in 6.203331774s

• [SLOW TEST:6.682 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:14:20.920: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Feb  7 19:14:27.154: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rg7r8 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  7 19:14:27.154: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
Feb  7 19:14:27.277: INFO: Exec stderr: ""
Feb  7 19:14:27.277: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rg7r8 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  7 19:14:27.277: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
Feb  7 19:14:27.424: INFO: Exec stderr: ""
Feb  7 19:14:27.424: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rg7r8 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  7 19:14:27.424: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
Feb  7 19:14:27.557: INFO: Exec stderr: ""
Feb  7 19:14:27.557: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rg7r8 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  7 19:14:27.557: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
Feb  7 19:14:27.674: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Feb  7 19:14:27.674: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rg7r8 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  7 19:14:27.674: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
Feb  7 19:14:27.793: INFO: Exec stderr: ""
Feb  7 19:14:27.793: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rg7r8 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  7 19:14:27.793: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
Feb  7 19:14:27.917: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Feb  7 19:14:27.917: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rg7r8 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  7 19:14:27.917: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
Feb  7 19:14:28.027: INFO: Exec stderr: ""
Feb  7 19:14:28.027: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rg7r8 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  7 19:14:28.027: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
Feb  7 19:14:28.164: INFO: Exec stderr: ""
Feb  7 19:14:28.164: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rg7r8 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  7 19:14:28.164: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
Feb  7 19:14:28.292: INFO: Exec stderr: ""
Feb  7 19:14:28.292: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rg7r8 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  7 19:14:28.292: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
Feb  7 19:14:28.451: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:14:28.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-rg7r8" for this suite.
Feb  7 19:15:10.476: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:15:10.534: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-rg7r8, resource: bindings, ignored listing per whitelist
Feb  7 19:15:10.624: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-rg7r8 deletion completed in 42.165422498s

• [SLOW TEST:49.704 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:15:10.625: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-b03a281a-2b0c-11e9-90f5-5e78944a5b53
STEP: Creating a pod to test consume configMaps
Feb  7 19:15:10.802: INFO: Waiting up to 5m0s for pod "pod-configmaps-b03baafe-2b0c-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-configmap-5s9kv" to be "success or failure"
Feb  7 19:15:10.816: INFO: Pod "pod-configmaps-b03baafe-2b0c-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 13.890178ms
Feb  7 19:15:12.823: INFO: Pod "pod-configmaps-b03baafe-2b0c-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020468136s
STEP: Saw pod success
Feb  7 19:15:12.823: INFO: Pod "pod-configmaps-b03baafe-2b0c-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 19:15:12.828: INFO: Trying to get logs from node conformance0 pod pod-configmaps-b03baafe-2b0c-11e9-90f5-5e78944a5b53 container configmap-volume-test: <nil>
STEP: delete the pod
Feb  7 19:15:12.861: INFO: Waiting for pod pod-configmaps-b03baafe-2b0c-11e9-90f5-5e78944a5b53 to disappear
Feb  7 19:15:12.873: INFO: Pod pod-configmaps-b03baafe-2b0c-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:15:12.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-5s9kv" for this suite.
Feb  7 19:15:18.896: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:15:19.006: INFO: namespace: e2e-tests-configmap-5s9kv, resource: bindings, ignored listing per whitelist
Feb  7 19:15:19.059: INFO: namespace e2e-tests-configmap-5s9kv deletion completed in 6.179983632s

• [SLOW TEST:8.434 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:15:19.060: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Feb  7 19:15:19.270: INFO: Waiting up to 5m0s for pod "var-expansion-b546f366-2b0c-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-var-expansion-d44t4" to be "success or failure"
Feb  7 19:15:19.280: INFO: Pod "var-expansion-b546f366-2b0c-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 9.884362ms
Feb  7 19:15:21.285: INFO: Pod "var-expansion-b546f366-2b0c-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014789383s
STEP: Saw pod success
Feb  7 19:15:21.285: INFO: Pod "var-expansion-b546f366-2b0c-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 19:15:21.290: INFO: Trying to get logs from node conformance0 pod var-expansion-b546f366-2b0c-11e9-90f5-5e78944a5b53 container dapi-container: <nil>
STEP: delete the pod
Feb  7 19:15:21.320: INFO: Waiting for pod var-expansion-b546f366-2b0c-11e9-90f5-5e78944a5b53 to disappear
Feb  7 19:15:21.332: INFO: Pod var-expansion-b546f366-2b0c-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:15:21.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-d44t4" for this suite.
Feb  7 19:15:27.371: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:15:27.428: INFO: namespace: e2e-tests-var-expansion-d44t4, resource: bindings, ignored listing per whitelist
Feb  7 19:15:27.523: INFO: namespace e2e-tests-var-expansion-d44t4 deletion completed in 6.184982682s

• [SLOW TEST:8.463 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:15:27.524: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-ba4ec61d-2b0c-11e9-90f5-5e78944a5b53
STEP: Creating secret with name s-test-opt-upd-ba4ec6b8-2b0c-11e9-90f5-5e78944a5b53
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-ba4ec61d-2b0c-11e9-90f5-5e78944a5b53
STEP: Updating secret s-test-opt-upd-ba4ec6b8-2b0c-11e9-90f5-5e78944a5b53
STEP: Creating secret with name s-test-opt-create-ba4ec70e-2b0c-11e9-90f5-5e78944a5b53
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:15:31.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-b9fnq" for this suite.
Feb  7 19:15:53.878: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:15:53.970: INFO: namespace: e2e-tests-projected-b9fnq, resource: bindings, ignored listing per whitelist
Feb  7 19:15:54.032: INFO: namespace e2e-tests-projected-b9fnq deletion completed in 22.17346784s

• [SLOW TEST:26.508 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:15:54.033: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb  7 19:15:54.161: INFO: Waiting up to 5m0s for pod "pod-ca1585f1-2b0c-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-emptydir-nw945" to be "success or failure"
Feb  7 19:15:54.173: INFO: Pod "pod-ca1585f1-2b0c-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 11.663588ms
Feb  7 19:15:56.177: INFO: Pod "pod-ca1585f1-2b0c-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015653133s
STEP: Saw pod success
Feb  7 19:15:56.177: INFO: Pod "pod-ca1585f1-2b0c-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 19:15:56.186: INFO: Trying to get logs from node conformance0 pod pod-ca1585f1-2b0c-11e9-90f5-5e78944a5b53 container test-container: <nil>
STEP: delete the pod
Feb  7 19:15:56.260: INFO: Waiting for pod pod-ca1585f1-2b0c-11e9-90f5-5e78944a5b53 to disappear
Feb  7 19:15:56.266: INFO: Pod pod-ca1585f1-2b0c-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:15:56.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-nw945" for this suite.
Feb  7 19:16:02.289: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:16:02.417: INFO: namespace: e2e-tests-emptydir-nw945, resource: bindings, ignored listing per whitelist
Feb  7 19:16:02.448: INFO: namespace e2e-tests-emptydir-nw945 deletion completed in 6.174170992s

• [SLOW TEST:8.416 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:16:02.449: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-cf174b2c-2b0c-11e9-90f5-5e78944a5b53
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-cf174b2c-2b0c-11e9-90f5-5e78944a5b53
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:16:06.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wcc42" for this suite.
Feb  7 19:16:28.657: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:16:28.797: INFO: namespace: e2e-tests-projected-wcc42, resource: bindings, ignored listing per whitelist
Feb  7 19:16:28.835: INFO: namespace e2e-tests-projected-wcc42 deletion completed in 22.193299134s

• [SLOW TEST:26.386 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:16:28.836: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Feb  7 19:16:28.958: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Feb  7 19:16:28.958: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 create -f - --namespace=e2e-tests-kubectl-mvj6l'
Feb  7 19:16:29.511: INFO: stderr: ""
Feb  7 19:16:29.511: INFO: stdout: "service/redis-slave created\n"
Feb  7 19:16:29.511: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Feb  7 19:16:29.511: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 create -f - --namespace=e2e-tests-kubectl-mvj6l'
Feb  7 19:16:29.910: INFO: stderr: ""
Feb  7 19:16:29.910: INFO: stdout: "service/redis-master created\n"
Feb  7 19:16:29.910: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Feb  7 19:16:29.911: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 create -f - --namespace=e2e-tests-kubectl-mvj6l'
Feb  7 19:16:30.289: INFO: stderr: ""
Feb  7 19:16:30.290: INFO: stdout: "service/frontend created\n"
Feb  7 19:16:30.290: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Feb  7 19:16:30.291: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 create -f - --namespace=e2e-tests-kubectl-mvj6l'
Feb  7 19:16:30.705: INFO: stderr: ""
Feb  7 19:16:30.705: INFO: stdout: "deployment.extensions/frontend created\n"
Feb  7 19:16:30.706: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Feb  7 19:16:30.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 create -f - --namespace=e2e-tests-kubectl-mvj6l'
Feb  7 19:16:31.234: INFO: stderr: ""
Feb  7 19:16:31.234: INFO: stdout: "deployment.extensions/redis-master created\n"
Feb  7 19:16:31.234: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Feb  7 19:16:31.234: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 create -f - --namespace=e2e-tests-kubectl-mvj6l'
Feb  7 19:16:31.798: INFO: stderr: ""
Feb  7 19:16:31.798: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Feb  7 19:16:31.798: INFO: Waiting for all frontend pods to be Running.
Feb  7 19:17:01.850: INFO: Waiting for frontend to serve content.
Feb  7 19:17:04.874: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'No route to host [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('No route to hos...', 113)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\StreamCo in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Feb  7 19:17:09.903: INFO: Trying to add a new entry to the guestbook.
Feb  7 19:17:09.924: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Feb  7 19:17:09.952: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-mvj6l'
Feb  7 19:17:10.288: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  7 19:17:10.288: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Feb  7 19:17:10.288: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-mvj6l'
Feb  7 19:17:10.575: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  7 19:17:10.575: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb  7 19:17:10.575: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-mvj6l'
Feb  7 19:17:11.348: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  7 19:17:11.348: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb  7 19:17:11.348: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-mvj6l'
Feb  7 19:17:11.987: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  7 19:17:11.987: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb  7 19:17:11.987: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-mvj6l'
Feb  7 19:17:12.599: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  7 19:17:12.599: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb  7 19:17:12.599: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-mvj6l'
Feb  7 19:17:13.263: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  7 19:17:13.263: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:17:13.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-mvj6l" for this suite.
Feb  7 19:17:53.430: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:17:53.485: INFO: namespace: e2e-tests-kubectl-mvj6l, resource: bindings, ignored listing per whitelist
Feb  7 19:17:53.580: INFO: namespace e2e-tests-kubectl-mvj6l deletion completed in 40.291032459s

• [SLOW TEST:84.744 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:17:53.581: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb  7 19:17:53.694: INFO: PodSpec: initContainers in spec.initContainers
Feb  7 19:18:35.465: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-1156322f-2b0d-11e9-90f5-5e78944a5b53", GenerateName:"", Namespace:"e2e-tests-init-container-z22wc", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-z22wc/pods/pod-init-1156322f-2b0d-11e9-90f5-5e78944a5b53", UID:"1156fbed-2b0d-11e9-a946-ceb99be2323d", ResourceVersion:"9965", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63685163873, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"694173738"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-cn4mm", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001d347c0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-cn4mm", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-cn4mm", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-cn4mm", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc002581c68), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"conformance0", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc000cb90e0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002581d00)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002581d20)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc002581d28), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc002581d2c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685163873, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685163873, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685163873, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685163873, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.10.1.212", PodIP:"10.244.0.242", StartTime:(*v1.Time)(0xc001629960), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0009cc150)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0009cc1c0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://d1bca08f538e7566e422fd9ede615f086c0708a399dad21679d24fb674c7d00d"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0016299a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001629980), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:18:35.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-z22wc" for this suite.
Feb  7 19:18:57.495: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:18:57.630: INFO: namespace: e2e-tests-init-container-z22wc, resource: bindings, ignored listing per whitelist
Feb  7 19:18:57.651: INFO: namespace e2e-tests-init-container-z22wc deletion completed in 22.179929604s

• [SLOW TEST:64.071 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:18:57.652: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Feb  7 19:18:58.132: INFO: Pod name wrapped-volume-race-37bc0521-2b0d-11e9-90f5-5e78944a5b53: Found 0 pods out of 5
Feb  7 19:19:03.142: INFO: Pod name wrapped-volume-race-37bc0521-2b0d-11e9-90f5-5e78944a5b53: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-37bc0521-2b0d-11e9-90f5-5e78944a5b53 in namespace e2e-tests-emptydir-wrapper-k5njv, will wait for the garbage collector to delete the pods
Feb  7 19:19:15.273: INFO: Deleting ReplicationController wrapped-volume-race-37bc0521-2b0d-11e9-90f5-5e78944a5b53 took: 11.282172ms
Feb  7 19:19:15.473: INFO: Terminating ReplicationController wrapped-volume-race-37bc0521-2b0d-11e9-90f5-5e78944a5b53 pods took: 200.370903ms
STEP: Creating RC which spawns configmap-volume pods
Feb  7 19:19:59.201: INFO: Pod name wrapped-volume-race-5c20f4d0-2b0d-11e9-90f5-5e78944a5b53: Found 0 pods out of 5
Feb  7 19:20:04.209: INFO: Pod name wrapped-volume-race-5c20f4d0-2b0d-11e9-90f5-5e78944a5b53: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-5c20f4d0-2b0d-11e9-90f5-5e78944a5b53 in namespace e2e-tests-emptydir-wrapper-k5njv, will wait for the garbage collector to delete the pods
Feb  7 19:20:16.314: INFO: Deleting ReplicationController wrapped-volume-race-5c20f4d0-2b0d-11e9-90f5-5e78944a5b53 took: 10.831955ms
Feb  7 19:20:16.515: INFO: Terminating ReplicationController wrapped-volume-race-5c20f4d0-2b0d-11e9-90f5-5e78944a5b53 pods took: 200.385902ms
STEP: Creating RC which spawns configmap-volume pods
Feb  7 19:20:59.844: INFO: Pod name wrapped-volume-race-804614dd-2b0d-11e9-90f5-5e78944a5b53: Found 0 pods out of 5
Feb  7 19:21:04.853: INFO: Pod name wrapped-volume-race-804614dd-2b0d-11e9-90f5-5e78944a5b53: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-804614dd-2b0d-11e9-90f5-5e78944a5b53 in namespace e2e-tests-emptydir-wrapper-k5njv, will wait for the garbage collector to delete the pods
Feb  7 19:21:16.955: INFO: Deleting ReplicationController wrapped-volume-race-804614dd-2b0d-11e9-90f5-5e78944a5b53 took: 9.648219ms
Feb  7 19:21:17.155: INFO: Terminating ReplicationController wrapped-volume-race-804614dd-2b0d-11e9-90f5-5e78944a5b53 pods took: 200.363081ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:22:00.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-k5njv" for this suite.
Feb  7 19:22:08.332: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:22:08.416: INFO: namespace: e2e-tests-emptydir-wrapper-k5njv, resource: bindings, ignored listing per whitelist
Feb  7 19:22:08.485: INFO: namespace e2e-tests-emptydir-wrapper-k5njv deletion completed in 8.169582904s

• [SLOW TEST:190.833 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:22:08.486: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  7 19:22:08.614: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a9453d97-2b0d-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-projected-pkzn7" to be "success or failure"
Feb  7 19:22:08.619: INFO: Pod "downwardapi-volume-a9453d97-2b0d-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 4.965767ms
Feb  7 19:22:10.624: INFO: Pod "downwardapi-volume-a9453d97-2b0d-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009658165s
STEP: Saw pod success
Feb  7 19:22:10.624: INFO: Pod "downwardapi-volume-a9453d97-2b0d-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 19:22:10.630: INFO: Trying to get logs from node conformance0 pod downwardapi-volume-a9453d97-2b0d-11e9-90f5-5e78944a5b53 container client-container: <nil>
STEP: delete the pod
Feb  7 19:22:10.674: INFO: Waiting for pod downwardapi-volume-a9453d97-2b0d-11e9-90f5-5e78944a5b53 to disappear
Feb  7 19:22:10.679: INFO: Pod downwardapi-volume-a9453d97-2b0d-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:22:10.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pkzn7" for this suite.
Feb  7 19:22:16.702: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:22:16.842: INFO: namespace: e2e-tests-projected-pkzn7, resource: bindings, ignored listing per whitelist
Feb  7 19:22:16.876: INFO: namespace e2e-tests-projected-pkzn7 deletion completed in 6.193427777s

• [SLOW TEST:8.391 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:22:16.877: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Feb  7 19:22:17.034: INFO: Waiting up to 5m0s for pod "var-expansion-ae4af090-2b0d-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-var-expansion-qqslt" to be "success or failure"
Feb  7 19:22:17.050: INFO: Pod "var-expansion-ae4af090-2b0d-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 16.60144ms
Feb  7 19:22:19.055: INFO: Pod "var-expansion-ae4af090-2b0d-11e9-90f5-5e78944a5b53": Phase="Running", Reason="", readiness=true. Elapsed: 2.021507016s
Feb  7 19:22:21.061: INFO: Pod "var-expansion-ae4af090-2b0d-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026851597s
STEP: Saw pod success
Feb  7 19:22:21.061: INFO: Pod "var-expansion-ae4af090-2b0d-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 19:22:21.066: INFO: Trying to get logs from node conformance0 pod var-expansion-ae4af090-2b0d-11e9-90f5-5e78944a5b53 container dapi-container: <nil>
STEP: delete the pod
Feb  7 19:22:21.122: INFO: Waiting for pod var-expansion-ae4af090-2b0d-11e9-90f5-5e78944a5b53 to disappear
Feb  7 19:22:21.128: INFO: Pod var-expansion-ae4af090-2b0d-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:22:21.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-qqslt" for this suite.
Feb  7 19:22:27.151: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:22:27.296: INFO: namespace: e2e-tests-var-expansion-qqslt, resource: bindings, ignored listing per whitelist
Feb  7 19:22:27.310: INFO: namespace e2e-tests-var-expansion-qqslt deletion completed in 6.174378427s

• [SLOW TEST:10.433 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:22:27.311: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-b47d4dfa-2b0d-11e9-90f5-5e78944a5b53
STEP: Creating a pod to test consume configMaps
Feb  7 19:22:27.438: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b47e663d-2b0d-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-projected-wq9zj" to be "success or failure"
Feb  7 19:22:27.443: INFO: Pod "pod-projected-configmaps-b47e663d-2b0d-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 4.626302ms
Feb  7 19:22:29.447: INFO: Pod "pod-projected-configmaps-b47e663d-2b0d-11e9-90f5-5e78944a5b53": Phase="Running", Reason="", readiness=true. Elapsed: 2.009117395s
Feb  7 19:22:31.452: INFO: Pod "pod-projected-configmaps-b47e663d-2b0d-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013368982s
STEP: Saw pod success
Feb  7 19:22:31.452: INFO: Pod "pod-projected-configmaps-b47e663d-2b0d-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 19:22:31.456: INFO: Trying to get logs from node conformance0 pod pod-projected-configmaps-b47e663d-2b0d-11e9-90f5-5e78944a5b53 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  7 19:22:31.491: INFO: Waiting for pod pod-projected-configmaps-b47e663d-2b0d-11e9-90f5-5e78944a5b53 to disappear
Feb  7 19:22:31.498: INFO: Pod pod-projected-configmaps-b47e663d-2b0d-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:22:31.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wq9zj" for this suite.
Feb  7 19:22:37.517: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:22:37.651: INFO: namespace: e2e-tests-projected-wq9zj, resource: bindings, ignored listing per whitelist
Feb  7 19:22:37.676: INFO: namespace e2e-tests-projected-wq9zj deletion completed in 6.173335547s

• [SLOW TEST:10.365 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:22:37.676: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  7 19:22:37.804: INFO: Waiting up to 5m0s for pod "downwardapi-volume-baabac65-2b0d-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-downward-api-k2hxp" to be "success or failure"
Feb  7 19:22:37.809: INFO: Pod "downwardapi-volume-baabac65-2b0d-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 5.316496ms
Feb  7 19:22:39.813: INFO: Pod "downwardapi-volume-baabac65-2b0d-11e9-90f5-5e78944a5b53": Phase="Running", Reason="", readiness=true. Elapsed: 2.0093098s
Feb  7 19:22:41.818: INFO: Pod "downwardapi-volume-baabac65-2b0d-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013578216s
STEP: Saw pod success
Feb  7 19:22:41.818: INFO: Pod "downwardapi-volume-baabac65-2b0d-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 19:22:41.823: INFO: Trying to get logs from node conformance0 pod downwardapi-volume-baabac65-2b0d-11e9-90f5-5e78944a5b53 container client-container: <nil>
STEP: delete the pod
Feb  7 19:22:41.867: INFO: Waiting for pod downwardapi-volume-baabac65-2b0d-11e9-90f5-5e78944a5b53 to disappear
Feb  7 19:22:41.878: INFO: Pod downwardapi-volume-baabac65-2b0d-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:22:41.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-k2hxp" for this suite.
Feb  7 19:22:47.908: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:22:48.064: INFO: namespace: e2e-tests-downward-api-k2hxp, resource: bindings, ignored listing per whitelist
Feb  7 19:22:48.080: INFO: namespace e2e-tests-downward-api-k2hxp deletion completed in 6.192832829s

• [SLOW TEST:10.404 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:22:48.081: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-c0e182ff-2b0d-11e9-90f5-5e78944a5b53
STEP: Creating secret with name secret-projected-all-test-volume-c0e182a6-2b0d-11e9-90f5-5e78944a5b53
STEP: Creating a pod to test Check all projections for projected volume plugin
Feb  7 19:22:48.236: INFO: Waiting up to 5m0s for pod "projected-volume-c0e1822c-2b0d-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-projected-cn9tw" to be "success or failure"
Feb  7 19:22:48.269: INFO: Pod "projected-volume-c0e1822c-2b0d-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 32.880333ms
Feb  7 19:22:50.291: INFO: Pod "projected-volume-c0e1822c-2b0d-11e9-90f5-5e78944a5b53": Phase="Running", Reason="", readiness=true. Elapsed: 2.054555716s
Feb  7 19:22:52.296: INFO: Pod "projected-volume-c0e1822c-2b0d-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.059940169s
STEP: Saw pod success
Feb  7 19:22:52.296: INFO: Pod "projected-volume-c0e1822c-2b0d-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 19:22:52.304: INFO: Trying to get logs from node conformance0 pod projected-volume-c0e1822c-2b0d-11e9-90f5-5e78944a5b53 container projected-all-volume-test: <nil>
STEP: delete the pod
Feb  7 19:22:52.345: INFO: Waiting for pod projected-volume-c0e1822c-2b0d-11e9-90f5-5e78944a5b53 to disappear
Feb  7 19:22:52.352: INFO: Pod projected-volume-c0e1822c-2b0d-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:22:52.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-cn9tw" for this suite.
Feb  7 19:22:58.377: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:22:58.459: INFO: namespace: e2e-tests-projected-cn9tw, resource: bindings, ignored listing per whitelist
Feb  7 19:22:58.521: INFO: namespace e2e-tests-projected-cn9tw deletion completed in 6.161278165s

• [SLOW TEST:10.440 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:22:58.522: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-dhlgk/configmap-test-c719038d-2b0d-11e9-90f5-5e78944a5b53
STEP: Creating a pod to test consume configMaps
Feb  7 19:22:58.658: INFO: Waiting up to 5m0s for pod "pod-configmaps-c719f66d-2b0d-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-configmap-dhlgk" to be "success or failure"
Feb  7 19:22:58.683: INFO: Pod "pod-configmaps-c719f66d-2b0d-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 24.630733ms
Feb  7 19:23:00.691: INFO: Pod "pod-configmaps-c719f66d-2b0d-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.032718104s
STEP: Saw pod success
Feb  7 19:23:00.691: INFO: Pod "pod-configmaps-c719f66d-2b0d-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 19:23:00.695: INFO: Trying to get logs from node conformance0 pod pod-configmaps-c719f66d-2b0d-11e9-90f5-5e78944a5b53 container env-test: <nil>
STEP: delete the pod
Feb  7 19:23:00.741: INFO: Waiting for pod pod-configmaps-c719f66d-2b0d-11e9-90f5-5e78944a5b53 to disappear
Feb  7 19:23:00.755: INFO: Pod pod-configmaps-c719f66d-2b0d-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:23:00.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-dhlgk" for this suite.
Feb  7 19:23:06.820: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:23:06.883: INFO: namespace: e2e-tests-configmap-dhlgk, resource: bindings, ignored listing per whitelist
Feb  7 19:23:06.967: INFO: namespace e2e-tests-configmap-dhlgk deletion completed in 6.195129383s

• [SLOW TEST:8.446 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:23:06.968: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  7 19:23:07.139: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cc27ef97-2b0d-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-projected-qrnvx" to be "success or failure"
Feb  7 19:23:07.150: INFO: Pod "downwardapi-volume-cc27ef97-2b0d-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 10.801055ms
Feb  7 19:23:09.160: INFO: Pod "downwardapi-volume-cc27ef97-2b0d-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021449252s
STEP: Saw pod success
Feb  7 19:23:09.160: INFO: Pod "downwardapi-volume-cc27ef97-2b0d-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 19:23:09.165: INFO: Trying to get logs from node conformance0 pod downwardapi-volume-cc27ef97-2b0d-11e9-90f5-5e78944a5b53 container client-container: <nil>
STEP: delete the pod
Feb  7 19:23:09.227: INFO: Waiting for pod downwardapi-volume-cc27ef97-2b0d-11e9-90f5-5e78944a5b53 to disappear
Feb  7 19:23:09.237: INFO: Pod downwardapi-volume-cc27ef97-2b0d-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:23:09.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qrnvx" for this suite.
Feb  7 19:23:15.265: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:23:15.373: INFO: namespace: e2e-tests-projected-qrnvx, resource: bindings, ignored listing per whitelist
Feb  7 19:23:15.414: INFO: namespace e2e-tests-projected-qrnvx deletion completed in 6.167780617s

• [SLOW TEST:8.447 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:23:15.416: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  7 19:23:15.562: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d12c5182-2b0d-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-projected-c5zhf" to be "success or failure"
Feb  7 19:23:15.574: INFO: Pod "downwardapi-volume-d12c5182-2b0d-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 12.144909ms
Feb  7 19:23:17.579: INFO: Pod "downwardapi-volume-d12c5182-2b0d-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01673772s
STEP: Saw pod success
Feb  7 19:23:17.579: INFO: Pod "downwardapi-volume-d12c5182-2b0d-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 19:23:17.583: INFO: Trying to get logs from node conformance0 pod downwardapi-volume-d12c5182-2b0d-11e9-90f5-5e78944a5b53 container client-container: <nil>
STEP: delete the pod
Feb  7 19:23:17.625: INFO: Waiting for pod downwardapi-volume-d12c5182-2b0d-11e9-90f5-5e78944a5b53 to disappear
Feb  7 19:23:17.639: INFO: Pod downwardapi-volume-d12c5182-2b0d-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:23:17.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-c5zhf" for this suite.
Feb  7 19:23:23.694: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:23:23.832: INFO: namespace: e2e-tests-projected-c5zhf, resource: bindings, ignored listing per whitelist
Feb  7 19:23:23.908: INFO: namespace e2e-tests-projected-c5zhf deletion completed in 6.234674261s

• [SLOW TEST:8.492 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:23:23.909: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0207 19:24:04.130869      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb  7 19:24:04.130: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:24:04.131: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-6nc75" for this suite.
Feb  7 19:24:14.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:24:14.242: INFO: namespace: e2e-tests-gc-6nc75, resource: bindings, ignored listing per whitelist
Feb  7 19:24:14.346: INFO: namespace e2e-tests-gc-6nc75 deletion completed in 10.210915808s

• [SLOW TEST:50.438 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:24:14.347: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1052
STEP: creating the pod
Feb  7 19:24:14.490: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 create -f - --namespace=e2e-tests-kubectl-sdgbc'
Feb  7 19:24:14.895: INFO: stderr: ""
Feb  7 19:24:14.895: INFO: stdout: "pod/pause created\n"
Feb  7 19:24:14.895: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Feb  7 19:24:14.895: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-sdgbc" to be "running and ready"
Feb  7 19:24:14.907: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 11.958025ms
Feb  7 19:24:16.914: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.01827318s
Feb  7 19:24:16.914: INFO: Pod "pause" satisfied condition "running and ready"
Feb  7 19:24:16.914: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Feb  7 19:24:16.914: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-sdgbc'
Feb  7 19:24:17.080: INFO: stderr: ""
Feb  7 19:24:17.080: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Feb  7 19:24:17.080: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 get pod pause -L testing-label --namespace=e2e-tests-kubectl-sdgbc'
Feb  7 19:24:17.223: INFO: stderr: ""
Feb  7 19:24:17.223: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Feb  7 19:24:17.224: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 label pods pause testing-label- --namespace=e2e-tests-kubectl-sdgbc'
Feb  7 19:24:17.391: INFO: stderr: ""
Feb  7 19:24:17.391: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Feb  7 19:24:17.391: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 get pod pause -L testing-label --namespace=e2e-tests-kubectl-sdgbc'
Feb  7 19:24:17.554: INFO: stderr: ""
Feb  7 19:24:17.554: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1059
STEP: using delete to clean up resources
Feb  7 19:24:17.554: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-sdgbc'
Feb  7 19:24:17.745: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  7 19:24:17.745: INFO: stdout: "pod \"pause\" force deleted\n"
Feb  7 19:24:17.745: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-sdgbc'
Feb  7 19:24:18.006: INFO: stderr: "No resources found.\n"
Feb  7 19:24:18.006: INFO: stdout: ""
Feb  7 19:24:18.006: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 get pods -l name=pause --namespace=e2e-tests-kubectl-sdgbc -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb  7 19:24:18.187: INFO: stderr: ""
Feb  7 19:24:18.188: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:24:18.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-sdgbc" for this suite.
Feb  7 19:24:24.217: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:24:24.266: INFO: namespace: e2e-tests-kubectl-sdgbc, resource: bindings, ignored listing per whitelist
Feb  7 19:24:24.354: INFO: namespace e2e-tests-kubectl-sdgbc deletion completed in 6.155918104s

• [SLOW TEST:10.008 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:24:24.356: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  7 19:24:24.467: INFO: Pod name rollover-pod: Found 0 pods out of 1
Feb  7 19:24:29.471: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb  7 19:24:29.471: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Feb  7 19:24:31.476: INFO: Creating deployment "test-rollover-deployment"
Feb  7 19:24:31.488: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Feb  7 19:24:33.500: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Feb  7 19:24:33.510: INFO: Ensure that both replica sets have 1 created replica
Feb  7 19:24:33.517: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Feb  7 19:24:33.527: INFO: Updating deployment test-rollover-deployment
Feb  7 19:24:33.527: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Feb  7 19:24:35.538: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Feb  7 19:24:35.549: INFO: Make sure deployment "test-rollover-deployment" is complete
Feb  7 19:24:35.562: INFO: all replica sets need to contain the pod-template-hash label
Feb  7 19:24:35.562: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685164271, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685164271, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685164274, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685164271, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  7 19:24:37.572: INFO: all replica sets need to contain the pod-template-hash label
Feb  7 19:24:37.572: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685164271, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685164271, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685164274, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685164271, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  7 19:24:39.572: INFO: all replica sets need to contain the pod-template-hash label
Feb  7 19:24:39.572: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685164271, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685164271, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685164274, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685164271, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  7 19:24:41.571: INFO: all replica sets need to contain the pod-template-hash label
Feb  7 19:24:41.572: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685164271, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685164271, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685164274, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685164271, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  7 19:24:43.572: INFO: all replica sets need to contain the pod-template-hash label
Feb  7 19:24:43.572: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685164271, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685164271, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685164274, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685164271, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  7 19:24:45.572: INFO: 
Feb  7 19:24:45.572: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb  7 19:24:45.585: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-lg6s2,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-lg6s2/deployments/test-rollover-deployment,UID:fe6f59ba-2b0d-11e9-a946-ceb99be2323d,ResourceVersion:11447,Generation:2,CreationTimestamp:2019-02-07 19:24:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-02-07 19:24:31 +0000 UTC 2019-02-07 19:24:31 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-02-07 19:24:45 +0000 UTC 2019-02-07 19:24:31 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-6b7f9d6597" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb  7 19:24:45.592: INFO: New ReplicaSet "test-rollover-deployment-6b7f9d6597" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597,GenerateName:,Namespace:e2e-tests-deployment-lg6s2,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-lg6s2/replicasets/test-rollover-deployment-6b7f9d6597,UID:ffa89a77-2b0d-11e9-a946-ceb99be2323d,ResourceVersion:11438,Generation:2,CreationTimestamp:2019-02-07 19:24:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment fe6f59ba-2b0d-11e9-a946-ceb99be2323d 0xc001eb1567 0xc001eb1568}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb  7 19:24:45.592: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Feb  7 19:24:45.593: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-lg6s2,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-lg6s2/replicasets/test-rollover-controller,UID:fa3f8162-2b0d-11e9-a946-ceb99be2323d,ResourceVersion:11446,Generation:2,CreationTimestamp:2019-02-07 19:24:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment fe6f59ba-2b0d-11e9-a946-ceb99be2323d 0xc001eb1357 0xc001eb1358}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb  7 19:24:45.593: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6586df867b,GenerateName:,Namespace:e2e-tests-deployment-lg6s2,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-lg6s2/replicasets/test-rollover-deployment-6586df867b,UID:fe7512d0-2b0d-11e9-a946-ceb99be2323d,ResourceVersion:11417,Generation:2,CreationTimestamp:2019-02-07 19:24:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment fe6f59ba-2b0d-11e9-a946-ceb99be2323d 0xc001eb1417 0xc001eb1418}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb  7 19:24:45.598: INFO: Pod "test-rollover-deployment-6b7f9d6597-gczmm" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597-gczmm,GenerateName:test-rollover-deployment-6b7f9d6597-,Namespace:e2e-tests-deployment-lg6s2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lg6s2/pods/test-rollover-deployment-6b7f9d6597-gczmm,UID:ffbbd9bd-2b0d-11e9-a946-ceb99be2323d,ResourceVersion:11431,Generation:0,CreationTimestamp:2019-02-07 19:24:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-6b7f9d6597 ffa89a77-2b0d-11e9-a946-ceb99be2323d 0xc00237a3d7 0xc00237a3d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sgmf5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sgmf5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-sgmf5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00237a5e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00237a600}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:24:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:24:34 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:24:34 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:24:33 +0000 UTC  }],Message:,Reason:,HostIP:10.10.1.212,PodIP:10.244.0.32,StartTime:2019-02-07 19:24:33 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-02-07 19:24:34 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://3f48258409e41b2709ff57a8c296b711b224b3061761d12c68ad3aafed2a3134}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:24:45.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-lg6s2" for this suite.
Feb  7 19:24:53.624: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:24:53.659: INFO: namespace: e2e-tests-deployment-lg6s2, resource: bindings, ignored listing per whitelist
Feb  7 19:24:53.749: INFO: namespace e2e-tests-deployment-lg6s2 deletion completed in 8.148029287s

• [SLOW TEST:29.394 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:24:53.749: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0207 19:25:24.415114      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb  7 19:25:24.415: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:25:24.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-72b6s" for this suite.
Feb  7 19:25:30.435: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:25:30.566: INFO: namespace: e2e-tests-gc-72b6s, resource: bindings, ignored listing per whitelist
Feb  7 19:25:30.605: INFO: namespace e2e-tests-gc-72b6s deletion completed in 6.185528648s

• [SLOW TEST:36.856 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:25:30.605: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-21bf4e0e-2b0e-11e9-90f5-5e78944a5b53
STEP: Creating a pod to test consume secrets
Feb  7 19:25:30.777: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-21c178b5-2b0e-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-projected-fpxxc" to be "success or failure"
Feb  7 19:25:30.797: INFO: Pod "pod-projected-secrets-21c178b5-2b0e-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 19.848741ms
Feb  7 19:25:32.802: INFO: Pod "pod-projected-secrets-21c178b5-2b0e-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02429152s
STEP: Saw pod success
Feb  7 19:25:32.802: INFO: Pod "pod-projected-secrets-21c178b5-2b0e-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 19:25:32.805: INFO: Trying to get logs from node conformance0 pod pod-projected-secrets-21c178b5-2b0e-11e9-90f5-5e78944a5b53 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb  7 19:25:32.876: INFO: Waiting for pod pod-projected-secrets-21c178b5-2b0e-11e9-90f5-5e78944a5b53 to disappear
Feb  7 19:25:32.886: INFO: Pod pod-projected-secrets-21c178b5-2b0e-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:25:32.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fpxxc" for this suite.
Feb  7 19:25:38.921: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:25:39.062: INFO: namespace: e2e-tests-projected-fpxxc, resource: bindings, ignored listing per whitelist
Feb  7 19:25:39.074: INFO: namespace e2e-tests-projected-fpxxc deletion completed in 6.169955953s

• [SLOW TEST:8.468 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:25:39.074: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-26ca309d-2b0e-11e9-90f5-5e78944a5b53
STEP: Creating configMap with name cm-test-opt-upd-26ca3135-2b0e-11e9-90f5-5e78944a5b53
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-26ca309d-2b0e-11e9-90f5-5e78944a5b53
STEP: Updating configmap cm-test-opt-upd-26ca3135-2b0e-11e9-90f5-5e78944a5b53
STEP: Creating configMap with name cm-test-opt-create-26ca3184-2b0e-11e9-90f5-5e78944a5b53
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:27:05.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4qvkb" for this suite.
Feb  7 19:27:30.008: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:27:30.038: INFO: namespace: e2e-tests-projected-4qvkb, resource: bindings, ignored listing per whitelist
Feb  7 19:27:30.147: INFO: namespace e2e-tests-projected-4qvkb deletion completed in 24.154602332s

• [SLOW TEST:111.073 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:27:30.147: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-nqkz5
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-nqkz5 to expose endpoints map[]
Feb  7 19:27:30.318: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-nqkz5 exposes endpoints map[] (18.731243ms elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-nqkz5
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-nqkz5 to expose endpoints map[pod1:[100]]
Feb  7 19:27:32.373: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-nqkz5 exposes endpoints map[pod1:[100]] (2.037755795s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-nqkz5
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-nqkz5 to expose endpoints map[pod1:[100] pod2:[101]]
Feb  7 19:27:34.457: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-nqkz5 exposes endpoints map[pod1:[100] pod2:[101]] (2.077808074s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-nqkz5
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-nqkz5 to expose endpoints map[pod2:[101]]
Feb  7 19:27:35.528: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-nqkz5 exposes endpoints map[pod2:[101]] (1.0610168s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-nqkz5
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-nqkz5 to expose endpoints map[]
Feb  7 19:27:36.560: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-nqkz5 exposes endpoints map[] (1.022953603s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:27:36.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-nqkz5" for this suite.
Feb  7 19:27:54.631: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:27:54.813: INFO: namespace: e2e-tests-services-nqkz5, resource: bindings, ignored listing per whitelist
Feb  7 19:27:54.842: INFO: namespace e2e-tests-services-nqkz5 deletion completed in 18.237247944s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:24.696 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:27:54.843: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Feb  7 19:27:54.983: INFO: Waiting up to 5m0s for pod "client-containers-77b94072-2b0e-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-containers-dr4zq" to be "success or failure"
Feb  7 19:27:55.009: INFO: Pod "client-containers-77b94072-2b0e-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 26.629003ms
Feb  7 19:27:57.015: INFO: Pod "client-containers-77b94072-2b0e-11e9-90f5-5e78944a5b53": Phase="Running", Reason="", readiness=true. Elapsed: 2.031990022s
Feb  7 19:27:59.019: INFO: Pod "client-containers-77b94072-2b0e-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036177341s
STEP: Saw pod success
Feb  7 19:27:59.019: INFO: Pod "client-containers-77b94072-2b0e-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 19:27:59.026: INFO: Trying to get logs from node conformance0 pod client-containers-77b94072-2b0e-11e9-90f5-5e78944a5b53 container test-container: <nil>
STEP: delete the pod
Feb  7 19:27:59.060: INFO: Waiting for pod client-containers-77b94072-2b0e-11e9-90f5-5e78944a5b53 to disappear
Feb  7 19:27:59.067: INFO: Pod client-containers-77b94072-2b0e-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:27:59.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-dr4zq" for this suite.
Feb  7 19:28:05.094: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:28:05.231: INFO: namespace: e2e-tests-containers-dr4zq, resource: bindings, ignored listing per whitelist
Feb  7 19:28:05.260: INFO: namespace e2e-tests-containers-dr4zq deletion completed in 6.183643653s

• [SLOW TEST:10.417 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:28:05.262: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-7defcd57-2b0e-11e9-90f5-5e78944a5b53
Feb  7 19:28:05.403: INFO: Pod name my-hostname-basic-7defcd57-2b0e-11e9-90f5-5e78944a5b53: Found 0 pods out of 1
Feb  7 19:28:10.408: INFO: Pod name my-hostname-basic-7defcd57-2b0e-11e9-90f5-5e78944a5b53: Found 1 pods out of 1
Feb  7 19:28:10.408: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-7defcd57-2b0e-11e9-90f5-5e78944a5b53" are running
Feb  7 19:28:10.413: INFO: Pod "my-hostname-basic-7defcd57-2b0e-11e9-90f5-5e78944a5b53-qt7dn" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-07 19:28:05 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-07 19:28:06 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-07 19:28:06 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-07 19:28:05 +0000 UTC Reason: Message:}])
Feb  7 19:28:10.413: INFO: Trying to dial the pod
Feb  7 19:28:15.430: INFO: Controller my-hostname-basic-7defcd57-2b0e-11e9-90f5-5e78944a5b53: Got expected result from replica 1 [my-hostname-basic-7defcd57-2b0e-11e9-90f5-5e78944a5b53-qt7dn]: "my-hostname-basic-7defcd57-2b0e-11e9-90f5-5e78944a5b53-qt7dn", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:28:15.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-cp896" for this suite.
Feb  7 19:28:21.458: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:28:21.587: INFO: namespace: e2e-tests-replication-controller-cp896, resource: bindings, ignored listing per whitelist
Feb  7 19:28:21.639: INFO: namespace e2e-tests-replication-controller-cp896 deletion completed in 6.200811474s

• [SLOW TEST:16.377 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:28:21.639: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-zsdz8
Feb  7 19:28:23.785: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-zsdz8
STEP: checking the pod's current state and verifying that restartCount is present
Feb  7 19:28:23.791: INFO: Initial restart count of pod liveness-http is 0
Feb  7 19:28:41.836: INFO: Restart count of pod e2e-tests-container-probe-zsdz8/liveness-http is now 1 (18.045518047s elapsed)
Feb  7 19:29:01.885: INFO: Restart count of pod e2e-tests-container-probe-zsdz8/liveness-http is now 2 (38.093835186s elapsed)
Feb  7 19:29:23.956: INFO: Restart count of pod e2e-tests-container-probe-zsdz8/liveness-http is now 3 (1m0.165085797s elapsed)
Feb  7 19:29:41.998: INFO: Restart count of pod e2e-tests-container-probe-zsdz8/liveness-http is now 4 (1m18.206830564s elapsed)
Feb  7 19:30:44.139: INFO: Restart count of pod e2e-tests-container-probe-zsdz8/liveness-http is now 5 (2m20.348157608s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:30:44.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-zsdz8" for this suite.
Feb  7 19:30:50.201: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:30:50.251: INFO: namespace: e2e-tests-container-probe-zsdz8, resource: bindings, ignored listing per whitelist
Feb  7 19:30:50.358: INFO: namespace e2e-tests-container-probe-zsdz8 deletion completed in 6.177526202s

• [SLOW TEST:148.719 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:30:50.358: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb  7 19:30:50.491: INFO: Waiting up to 5m0s for pod "downward-api-e05636d9-2b0e-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-downward-api-fchz2" to be "success or failure"
Feb  7 19:30:50.501: INFO: Pod "downward-api-e05636d9-2b0e-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 10.145438ms
Feb  7 19:30:52.506: INFO: Pod "downward-api-e05636d9-2b0e-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015297894s
Feb  7 19:30:54.511: INFO: Pod "downward-api-e05636d9-2b0e-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020028644s
STEP: Saw pod success
Feb  7 19:30:54.511: INFO: Pod "downward-api-e05636d9-2b0e-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 19:30:54.517: INFO: Trying to get logs from node conformance0 pod downward-api-e05636d9-2b0e-11e9-90f5-5e78944a5b53 container dapi-container: <nil>
STEP: delete the pod
Feb  7 19:30:54.563: INFO: Waiting for pod downward-api-e05636d9-2b0e-11e9-90f5-5e78944a5b53 to disappear
Feb  7 19:30:54.578: INFO: Pod downward-api-e05636d9-2b0e-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:30:54.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-fchz2" for this suite.
Feb  7 19:31:00.601: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:31:00.765: INFO: namespace: e2e-tests-downward-api-fchz2, resource: bindings, ignored listing per whitelist
Feb  7 19:31:00.765: INFO: namespace e2e-tests-downward-api-fchz2 deletion completed in 6.181299597s

• [SLOW TEST:10.407 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:31:00.765: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-e6939c20-2b0e-11e9-90f5-5e78944a5b53
STEP: Creating a pod to test consume configMaps
Feb  7 19:31:00.976: INFO: Waiting up to 5m0s for pod "pod-configmaps-e694c97b-2b0e-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-configmap-77m94" to be "success or failure"
Feb  7 19:31:01.015: INFO: Pod "pod-configmaps-e694c97b-2b0e-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 38.63193ms
Feb  7 19:31:03.020: INFO: Pod "pod-configmaps-e694c97b-2b0e-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043381847s
Feb  7 19:31:05.024: INFO: Pod "pod-configmaps-e694c97b-2b0e-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048036048s
STEP: Saw pod success
Feb  7 19:31:05.024: INFO: Pod "pod-configmaps-e694c97b-2b0e-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 19:31:05.031: INFO: Trying to get logs from node conformance0 pod pod-configmaps-e694c97b-2b0e-11e9-90f5-5e78944a5b53 container configmap-volume-test: <nil>
STEP: delete the pod
Feb  7 19:31:05.093: INFO: Waiting for pod pod-configmaps-e694c97b-2b0e-11e9-90f5-5e78944a5b53 to disappear
Feb  7 19:31:05.099: INFO: Pod pod-configmaps-e694c97b-2b0e-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:31:05.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-77m94" for this suite.
Feb  7 19:31:11.123: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:31:11.274: INFO: namespace: e2e-tests-configmap-77m94, resource: bindings, ignored listing per whitelist
Feb  7 19:31:11.311: INFO: namespace e2e-tests-configmap-77m94 deletion completed in 6.204862537s

• [SLOW TEST:10.546 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:31:11.312: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-ecd47d34-2b0e-11e9-90f5-5e78944a5b53
STEP: Creating a pod to test consume configMaps
Feb  7 19:31:11.468: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ecd69008-2b0e-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-projected-dzjnj" to be "success or failure"
Feb  7 19:31:11.475: INFO: Pod "pod-projected-configmaps-ecd69008-2b0e-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 7.282832ms
Feb  7 19:31:13.502: INFO: Pod "pod-projected-configmaps-ecd69008-2b0e-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.033565728s
STEP: Saw pod success
Feb  7 19:31:13.502: INFO: Pod "pod-projected-configmaps-ecd69008-2b0e-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 19:31:13.506: INFO: Trying to get logs from node conformance0 pod pod-projected-configmaps-ecd69008-2b0e-11e9-90f5-5e78944a5b53 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  7 19:31:13.555: INFO: Waiting for pod pod-projected-configmaps-ecd69008-2b0e-11e9-90f5-5e78944a5b53 to disappear
Feb  7 19:31:13.564: INFO: Pod pod-projected-configmaps-ecd69008-2b0e-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:31:13.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dzjnj" for this suite.
Feb  7 19:31:19.593: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:31:19.728: INFO: namespace: e2e-tests-projected-dzjnj, resource: bindings, ignored listing per whitelist
Feb  7 19:31:19.757: INFO: namespace e2e-tests-projected-dzjnj deletion completed in 6.181653976s

• [SLOW TEST:8.445 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:31:19.758: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb  7 19:31:19.913: INFO: Number of nodes with available pods: 0
Feb  7 19:31:19.914: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:31:20.931: INFO: Number of nodes with available pods: 0
Feb  7 19:31:20.931: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:31:21.934: INFO: Number of nodes with available pods: 0
Feb  7 19:31:21.934: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:31:22.927: INFO: Number of nodes with available pods: 1
Feb  7 19:31:22.927: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Feb  7 19:31:22.991: INFO: Number of nodes with available pods: 0
Feb  7 19:31:22.991: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:31:24.002: INFO: Number of nodes with available pods: 0
Feb  7 19:31:24.003: INFO: Node conformance0 is running more than one daemon pod
Feb  7 19:31:25.006: INFO: Number of nodes with available pods: 1
Feb  7 19:31:25.006: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-gs5qk, will wait for the garbage collector to delete the pods
Feb  7 19:31:25.091: INFO: Deleting DaemonSet.extensions daemon-set took: 20.021722ms
Feb  7 19:31:25.192: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.338403ms
Feb  7 19:32:08.799: INFO: Number of nodes with available pods: 0
Feb  7 19:32:08.799: INFO: Number of running nodes: 0, number of available pods: 0
Feb  7 19:32:08.803: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-gs5qk/daemonsets","resourceVersion":"12047"},"items":null}

Feb  7 19:32:08.808: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-gs5qk/pods","resourceVersion":"12047"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:32:08.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-gs5qk" for this suite.
Feb  7 19:32:14.843: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:32:14.981: INFO: namespace: e2e-tests-daemonsets-gs5qk, resource: bindings, ignored listing per whitelist
Feb  7 19:32:15.010: INFO: namespace e2e-tests-daemonsets-gs5qk deletion completed in 6.186599383s

• [SLOW TEST:55.252 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:32:15.010: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Feb  7 19:32:15.664: INFO: created pod pod-service-account-defaultsa
Feb  7 19:32:15.664: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Feb  7 19:32:15.674: INFO: created pod pod-service-account-mountsa
Feb  7 19:32:15.674: INFO: pod pod-service-account-mountsa service account token volume mount: true
Feb  7 19:32:15.713: INFO: created pod pod-service-account-nomountsa
Feb  7 19:32:15.713: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Feb  7 19:32:15.938: INFO: created pod pod-service-account-defaultsa-mountspec
Feb  7 19:32:15.938: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Feb  7 19:32:16.010: INFO: created pod pod-service-account-mountsa-mountspec
Feb  7 19:32:16.010: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Feb  7 19:32:16.111: INFO: created pod pod-service-account-nomountsa-mountspec
Feb  7 19:32:16.111: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Feb  7 19:32:16.174: INFO: created pod pod-service-account-defaultsa-nomountspec
Feb  7 19:32:16.174: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Feb  7 19:32:16.218: INFO: created pod pod-service-account-mountsa-nomountspec
Feb  7 19:32:16.218: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Feb  7 19:32:16.366: INFO: created pod pod-service-account-nomountsa-nomountspec
Feb  7 19:32:16.366: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:32:16.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-dcjs5" for this suite.
Feb  7 19:32:40.528: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:32:40.651: INFO: namespace: e2e-tests-svcaccounts-dcjs5, resource: bindings, ignored listing per whitelist
Feb  7 19:32:40.697: INFO: namespace e2e-tests-svcaccounts-dcjs5 deletion completed in 24.225686586s

• [SLOW TEST:25.687 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:32:40.698: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Feb  7 19:32:41.375: INFO: Waiting up to 5m0s for pod "pod-service-account-226d0bcb-2b0f-11e9-90f5-5e78944a5b53-24l2l" in namespace "e2e-tests-svcaccounts-jf4jm" to be "success or failure"
Feb  7 19:32:41.390: INFO: Pod "pod-service-account-226d0bcb-2b0f-11e9-90f5-5e78944a5b53-24l2l": Phase="Pending", Reason="", readiness=false. Elapsed: 14.262082ms
Feb  7 19:32:43.395: INFO: Pod "pod-service-account-226d0bcb-2b0f-11e9-90f5-5e78944a5b53-24l2l": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019187402s
STEP: Saw pod success
Feb  7 19:32:43.395: INFO: Pod "pod-service-account-226d0bcb-2b0f-11e9-90f5-5e78944a5b53-24l2l" satisfied condition "success or failure"
Feb  7 19:32:43.399: INFO: Trying to get logs from node conformance0 pod pod-service-account-226d0bcb-2b0f-11e9-90f5-5e78944a5b53-24l2l container token-test: <nil>
STEP: delete the pod
Feb  7 19:32:43.445: INFO: Waiting for pod pod-service-account-226d0bcb-2b0f-11e9-90f5-5e78944a5b53-24l2l to disappear
Feb  7 19:32:43.458: INFO: Pod pod-service-account-226d0bcb-2b0f-11e9-90f5-5e78944a5b53-24l2l no longer exists
STEP: Creating a pod to test consume service account root CA
Feb  7 19:32:43.491: INFO: Waiting up to 5m0s for pod "pod-service-account-226d0bcb-2b0f-11e9-90f5-5e78944a5b53-nqgzz" in namespace "e2e-tests-svcaccounts-jf4jm" to be "success or failure"
Feb  7 19:32:43.525: INFO: Pod "pod-service-account-226d0bcb-2b0f-11e9-90f5-5e78944a5b53-nqgzz": Phase="Pending", Reason="", readiness=false. Elapsed: 34.089925ms
Feb  7 19:32:45.533: INFO: Pod "pod-service-account-226d0bcb-2b0f-11e9-90f5-5e78944a5b53-nqgzz": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041611477s
Feb  7 19:32:47.538: INFO: Pod "pod-service-account-226d0bcb-2b0f-11e9-90f5-5e78944a5b53-nqgzz": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.046593406s
STEP: Saw pod success
Feb  7 19:32:47.538: INFO: Pod "pod-service-account-226d0bcb-2b0f-11e9-90f5-5e78944a5b53-nqgzz" satisfied condition "success or failure"
Feb  7 19:32:47.542: INFO: Trying to get logs from node conformance0 pod pod-service-account-226d0bcb-2b0f-11e9-90f5-5e78944a5b53-nqgzz container root-ca-test: <nil>
STEP: delete the pod
Feb  7 19:32:47.581: INFO: Waiting for pod pod-service-account-226d0bcb-2b0f-11e9-90f5-5e78944a5b53-nqgzz to disappear
Feb  7 19:32:47.593: INFO: Pod pod-service-account-226d0bcb-2b0f-11e9-90f5-5e78944a5b53-nqgzz no longer exists
STEP: Creating a pod to test consume service account namespace
Feb  7 19:32:47.617: INFO: Waiting up to 5m0s for pod "pod-service-account-226d0bcb-2b0f-11e9-90f5-5e78944a5b53-xq9rc" in namespace "e2e-tests-svcaccounts-jf4jm" to be "success or failure"
Feb  7 19:32:47.631: INFO: Pod "pod-service-account-226d0bcb-2b0f-11e9-90f5-5e78944a5b53-xq9rc": Phase="Pending", Reason="", readiness=false. Elapsed: 14.472257ms
Feb  7 19:32:49.636: INFO: Pod "pod-service-account-226d0bcb-2b0f-11e9-90f5-5e78944a5b53-xq9rc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019310349s
Feb  7 19:32:51.641: INFO: Pod "pod-service-account-226d0bcb-2b0f-11e9-90f5-5e78944a5b53-xq9rc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024312455s
STEP: Saw pod success
Feb  7 19:32:51.641: INFO: Pod "pod-service-account-226d0bcb-2b0f-11e9-90f5-5e78944a5b53-xq9rc" satisfied condition "success or failure"
Feb  7 19:32:51.647: INFO: Trying to get logs from node conformance0 pod pod-service-account-226d0bcb-2b0f-11e9-90f5-5e78944a5b53-xq9rc container namespace-test: <nil>
STEP: delete the pod
Feb  7 19:32:51.690: INFO: Waiting for pod pod-service-account-226d0bcb-2b0f-11e9-90f5-5e78944a5b53-xq9rc to disappear
Feb  7 19:32:51.695: INFO: Pod pod-service-account-226d0bcb-2b0f-11e9-90f5-5e78944a5b53-xq9rc no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:32:51.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-jf4jm" for this suite.
Feb  7 19:32:57.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:32:57.859: INFO: namespace: e2e-tests-svcaccounts-jf4jm, resource: bindings, ignored listing per whitelist
Feb  7 19:32:57.870: INFO: namespace e2e-tests-svcaccounts-jf4jm deletion completed in 6.168470413s

• [SLOW TEST:17.172 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:32:57.871: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:33:00.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-lktcg" for this suite.
Feb  7 19:33:40.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:33:40.155: INFO: namespace: e2e-tests-kubelet-test-lktcg, resource: bindings, ignored listing per whitelist
Feb  7 19:33:40.217: INFO: namespace e2e-tests-kubelet-test-lktcg deletion completed in 40.187859081s

• [SLOW TEST:42.346 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:33:40.217: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-45940192-2b0f-11e9-90f5-5e78944a5b53
STEP: Creating a pod to test consume secrets
Feb  7 19:33:40.400: INFO: Waiting up to 5m0s for pod "pod-secrets-459cd833-2b0f-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-secrets-mjsts" to be "success or failure"
Feb  7 19:33:40.403: INFO: Pod "pod-secrets-459cd833-2b0f-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 2.893946ms
Feb  7 19:33:42.408: INFO: Pod "pod-secrets-459cd833-2b0f-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007244406s
STEP: Saw pod success
Feb  7 19:33:42.408: INFO: Pod "pod-secrets-459cd833-2b0f-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 19:33:42.413: INFO: Trying to get logs from node conformance0 pod pod-secrets-459cd833-2b0f-11e9-90f5-5e78944a5b53 container secret-volume-test: <nil>
STEP: delete the pod
Feb  7 19:33:42.464: INFO: Waiting for pod pod-secrets-459cd833-2b0f-11e9-90f5-5e78944a5b53 to disappear
Feb  7 19:33:42.469: INFO: Pod pod-secrets-459cd833-2b0f-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:33:42.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-mjsts" for this suite.
Feb  7 19:33:48.493: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:33:48.530: INFO: namespace: e2e-tests-secrets-mjsts, resource: bindings, ignored listing per whitelist
Feb  7 19:33:48.668: INFO: namespace e2e-tests-secrets-mjsts deletion completed in 6.193028349s
STEP: Destroying namespace "e2e-tests-secret-namespace-w6sfm" for this suite.
Feb  7 19:33:54.687: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:33:54.783: INFO: namespace: e2e-tests-secret-namespace-w6sfm, resource: bindings, ignored listing per whitelist
Feb  7 19:33:54.862: INFO: namespace e2e-tests-secret-namespace-w6sfm deletion completed in 6.193817798s

• [SLOW TEST:14.644 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:33:54.865: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  7 19:33:55.021: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4e5273fd-2b0f-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-downward-api-njgxb" to be "success or failure"
Feb  7 19:33:55.027: INFO: Pod "downwardapi-volume-4e5273fd-2b0f-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 6.420748ms
Feb  7 19:33:57.033: INFO: Pod "downwardapi-volume-4e5273fd-2b0f-11e9-90f5-5e78944a5b53": Phase="Running", Reason="", readiness=true. Elapsed: 2.01188184s
Feb  7 19:33:59.037: INFO: Pod "downwardapi-volume-4e5273fd-2b0f-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016255443s
STEP: Saw pod success
Feb  7 19:33:59.037: INFO: Pod "downwardapi-volume-4e5273fd-2b0f-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 19:33:59.043: INFO: Trying to get logs from node conformance0 pod downwardapi-volume-4e5273fd-2b0f-11e9-90f5-5e78944a5b53 container client-container: <nil>
STEP: delete the pod
Feb  7 19:33:59.091: INFO: Waiting for pod downwardapi-volume-4e5273fd-2b0f-11e9-90f5-5e78944a5b53 to disappear
Feb  7 19:33:59.096: INFO: Pod downwardapi-volume-4e5273fd-2b0f-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:33:59.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-njgxb" for this suite.
Feb  7 19:34:05.121: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:34:05.227: INFO: namespace: e2e-tests-downward-api-njgxb, resource: bindings, ignored listing per whitelist
Feb  7 19:34:05.281: INFO: namespace e2e-tests-downward-api-njgxb deletion completed in 6.17576176s

• [SLOW TEST:10.417 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:34:05.282: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-zzjnv
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-zzjnv
STEP: Deleting pre-stop pod
Feb  7 19:34:18.493: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:34:18.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-zzjnv" for this suite.
Feb  7 19:34:58.572: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:34:58.616: INFO: namespace: e2e-tests-prestop-zzjnv, resource: bindings, ignored listing per whitelist
Feb  7 19:34:58.726: INFO: namespace e2e-tests-prestop-zzjnv deletion completed in 40.189383544s

• [SLOW TEST:53.444 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:34:58.726: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  7 19:34:58.858: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:35:03.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-qhsjs" for this suite.
Feb  7 19:35:49.033: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:35:49.072: INFO: namespace: e2e-tests-pods-qhsjs, resource: bindings, ignored listing per whitelist
Feb  7 19:35:49.214: INFO: namespace e2e-tests-pods-qhsjs deletion completed in 46.199757248s

• [SLOW TEST:50.488 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:35:49.215: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
Feb  7 19:35:58.645: INFO: error from create uninitialized namespace: Internal error occurred: object deleted while waiting for creation
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:36:15.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-lb9tf" for this suite.
Feb  7 19:36:21.510: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:36:21.620: INFO: namespace: e2e-tests-namespaces-lb9tf, resource: bindings, ignored listing per whitelist
Feb  7 19:36:21.668: INFO: namespace e2e-tests-namespaces-lb9tf deletion completed in 6.173265223s
STEP: Destroying namespace "e2e-tests-nsdeletetest-rhs7q" for this suite.
Feb  7 19:36:21.673: INFO: Namespace e2e-tests-nsdeletetest-rhs7q was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-k9qww" for this suite.
Feb  7 19:36:27.693: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:36:27.864: INFO: namespace: e2e-tests-nsdeletetest-k9qww, resource: bindings, ignored listing per whitelist
Feb  7 19:36:27.869: INFO: namespace e2e-tests-nsdeletetest-k9qww deletion completed in 6.19509334s

• [SLOW TEST:38.654 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:36:27.869: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb  7 19:36:27.977: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-nmwqf'
Feb  7 19:36:28.400: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb  7 19:36:28.400: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1404
Feb  7 19:36:32.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-nmwqf'
Feb  7 19:36:32.599: INFO: stderr: ""
Feb  7 19:36:32.599: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:36:32.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-nmwqf" for this suite.
Feb  7 19:36:38.635: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:36:38.761: INFO: namespace: e2e-tests-kubectl-nmwqf, resource: bindings, ignored listing per whitelist
Feb  7 19:36:38.826: INFO: namespace e2e-tests-kubectl-nmwqf deletion completed in 6.219443688s

• [SLOW TEST:10.956 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:36:38.827: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  7 19:36:38.942: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 version --client'
Feb  7 19:36:39.043: INFO: stderr: ""
Feb  7 19:36:39.043: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Feb  7 19:36:39.046: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 create -f - --namespace=e2e-tests-kubectl-mfrjd'
Feb  7 19:36:39.447: INFO: stderr: ""
Feb  7 19:36:39.448: INFO: stdout: "replicationcontroller/redis-master created\n"
Feb  7 19:36:39.448: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 create -f - --namespace=e2e-tests-kubectl-mfrjd'
Feb  7 19:36:39.974: INFO: stderr: ""
Feb  7 19:36:39.974: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb  7 19:36:40.983: INFO: Selector matched 1 pods for map[app:redis]
Feb  7 19:36:40.983: INFO: Found 0 / 1
Feb  7 19:36:41.979: INFO: Selector matched 1 pods for map[app:redis]
Feb  7 19:36:41.979: INFO: Found 1 / 1
Feb  7 19:36:41.979: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb  7 19:36:41.985: INFO: Selector matched 1 pods for map[app:redis]
Feb  7 19:36:41.985: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb  7 19:36:41.985: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 describe pod redis-master-6vv99 --namespace=e2e-tests-kubectl-mfrjd'
Feb  7 19:36:42.184: INFO: stderr: ""
Feb  7 19:36:42.184: INFO: stdout: "Name:               redis-master-6vv99\nNamespace:          e2e-tests-kubectl-mfrjd\nPriority:           0\nPriorityClassName:  <none>\nNode:               conformance0/10.10.1.212\nStart Time:         Thu, 07 Feb 2019 19:36:39 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.244.0.67\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://fdf0bc7a3c58d3077caead8cf1e4da3e59c5ecc89e6f913a75778bfefdee0a5c\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Thu, 07 Feb 2019 19:36:40 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-wtq7q (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-wtq7q:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-wtq7q\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                   Message\n  ----    ------     ----  ----                   -------\n  Normal  Scheduled  3s    default-scheduler      Successfully assigned e2e-tests-kubectl-mfrjd/redis-master-6vv99 to conformance0\n  Normal  Pulled     2s    kubelet, conformance0  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, conformance0  Created container\n  Normal  Started    2s    kubelet, conformance0  Started container\n"
Feb  7 19:36:42.184: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 describe rc redis-master --namespace=e2e-tests-kubectl-mfrjd'
Feb  7 19:36:42.378: INFO: stderr: ""
Feb  7 19:36:42.378: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-mfrjd\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-6vv99\n"
Feb  7 19:36:42.378: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 describe service redis-master --namespace=e2e-tests-kubectl-mfrjd'
Feb  7 19:36:42.549: INFO: stderr: ""
Feb  7 19:36:42.549: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-mfrjd\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.10.213.63\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.244.0.67:6379\nSession Affinity:  None\nEvents:            <none>\n"
Feb  7 19:36:42.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 describe node conformance0'
Feb  7 19:36:42.793: INFO: stderr: ""
Feb  7 19:36:42.793: INFO: stdout: "Name:               conformance0\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/hostname=conformance0\n                    nirmata.io/cluster.name=conformancetest\n                    nirmata.io/cluster.role=control-plane\n                    node-role.kubernetes.io/master=\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"2e:61:82:2f:bf:78\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 10.10.1.212\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Thu, 07 Feb 2019 17:57:14 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Thu, 07 Feb 2019 19:36:36 +0000   Thu, 07 Feb 2019 17:57:01 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Thu, 07 Feb 2019 19:36:36 +0000   Thu, 07 Feb 2019 17:57:01 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Thu, 07 Feb 2019 19:36:36 +0000   Thu, 07 Feb 2019 17:57:01 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Thu, 07 Feb 2019 19:36:36 +0000   Thu, 07 Feb 2019 17:59:05 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  10.10.1.212\n  Hostname:    conformance0\nCapacity:\n cpu:                2\n ephemeral-storage:  31166436Ki\n hugepages-2Mi:      0\n memory:             8149868Ki\n pods:               110\nAllocatable:\n cpu:                2\n ephemeral-storage:  28722987371\n hugepages-2Mi:      0\n memory:             8047468Ki\n pods:               110\nSystem Info:\n Machine ID:                 cf9039846e817bf110c3933d5c3e0c56\n System UUID:                EB0EE6DC-ED5B-CF59-01CC-0B8140179331\n Boot ID:                    db42c2bc-612c-41da-90f2-8f62df9b3198\n Kernel Version:             4.4.0-131-generic\n OS Image:                   Debian GNU/Linux 9 (stretch)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://17.6.0\n Kubelet Version:            v1.13.3\n Kube-Proxy Version:         v1.13.3\nPodCIDR:                     10.244.0.0/24\nNon-terminated Pods:         (11 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  e2e-tests-kubectl-mfrjd    redis-master-6vv99                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         3s\n  heptio-sonobuoy            sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         85m\n  heptio-sonobuoy            sonobuoy-e2e-job-946df599e97f4154                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         85m\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-0f8450d3236a4290-khwsz    0 (0%)        0 (0%)      0 (0%)           0 (0%)         85m\n  ingress-haproxy            haproxy-ingress-6cd7fb8fc-bswfw                            0 (0%)        0 (0%)      0 (0%)           0 (0%)         97m\n  ingress-haproxy            ingress-default-backend-55c6dddf9b-bsb5j                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         97m\n  kube-system                kube-dns-6fbf99bd5-vln22                                   260m (13%)    0 (0%)      110Mi (1%)       170Mi (2%)     97m\n  kube-system                kube-flannel-ds-l2rpk                                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         97m\n  kube-system                metrics-server-58fd5b7956-55hhh                            0 (0%)        0 (0%)      0 (0%)           0 (0%)         97m\n  nirmata                    nirmata-cni-installer-548lz                                0 (0%)        0 (0%)      0 (0%)           0 (0%)         97m\n  nirmata                    nirmata-kube-controller-7bc4774558-hdvmg                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         97m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                260m (13%)  0 (0%)\n  memory             110Mi (1%)  170Mi (2%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:              <none>\n"
Feb  7 19:36:42.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 describe namespace e2e-tests-kubectl-mfrjd'
Feb  7 19:36:42.981: INFO: stderr: ""
Feb  7 19:36:42.981: INFO: stdout: "Name:         e2e-tests-kubectl-mfrjd\nLabels:       e2e-framework=kubectl\n              e2e-run=de71a073-2b03-11e9-90f5-5e78944a5b53\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:36:42.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-mfrjd" for this suite.
Feb  7 19:37:07.001: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:37:07.069: INFO: namespace: e2e-tests-kubectl-mfrjd, resource: bindings, ignored listing per whitelist
Feb  7 19:37:07.166: INFO: namespace e2e-tests-kubectl-mfrjd deletion completed in 24.180380264s

• [SLOW TEST:28.339 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:37:07.167: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-bd675 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-bd675;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-bd675 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-bd675;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-bd675.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-bd675.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-bd675.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-bd675.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-bd675.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-bd675.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-bd675.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-bd675.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-bd675.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-bd675.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-bd675.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-bd675.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-bd675.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 121.106.10.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.10.106.121_udp@PTR;check="$$(dig +tcp +noall +answer +search 121.106.10.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.10.106.121_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-bd675 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-bd675;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-bd675 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-bd675;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-bd675.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-bd675.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-bd675.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-bd675.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-bd675.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-bd675.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-bd675.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-bd675.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-bd675.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-bd675.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-bd675.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-bd675.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-bd675.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 121.106.10.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.10.106.121_udp@PTR;check="$$(dig +tcp +noall +answer +search 121.106.10.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.10.106.121_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb  7 19:37:11.546: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-bd675/dns-test-c0f4202a-2b0f-11e9-90f5-5e78944a5b53: the server could not find the requested resource (get pods dns-test-c0f4202a-2b0f-11e9-90f5-5e78944a5b53)
Feb  7 19:37:11.555: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-bd675/dns-test-c0f4202a-2b0f-11e9-90f5-5e78944a5b53: the server could not find the requested resource (get pods dns-test-c0f4202a-2b0f-11e9-90f5-5e78944a5b53)
Feb  7 19:37:11.561: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-bd675 from pod e2e-tests-dns-bd675/dns-test-c0f4202a-2b0f-11e9-90f5-5e78944a5b53: the server could not find the requested resource (get pods dns-test-c0f4202a-2b0f-11e9-90f5-5e78944a5b53)
Feb  7 19:37:11.573: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-bd675 from pod e2e-tests-dns-bd675/dns-test-c0f4202a-2b0f-11e9-90f5-5e78944a5b53: the server could not find the requested resource (get pods dns-test-c0f4202a-2b0f-11e9-90f5-5e78944a5b53)
Feb  7 19:37:11.581: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-bd675.svc from pod e2e-tests-dns-bd675/dns-test-c0f4202a-2b0f-11e9-90f5-5e78944a5b53: the server could not find the requested resource (get pods dns-test-c0f4202a-2b0f-11e9-90f5-5e78944a5b53)
Feb  7 19:37:11.591: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-bd675.svc from pod e2e-tests-dns-bd675/dns-test-c0f4202a-2b0f-11e9-90f5-5e78944a5b53: the server could not find the requested resource (get pods dns-test-c0f4202a-2b0f-11e9-90f5-5e78944a5b53)
Feb  7 19:37:11.600: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-bd675.svc from pod e2e-tests-dns-bd675/dns-test-c0f4202a-2b0f-11e9-90f5-5e78944a5b53: the server could not find the requested resource (get pods dns-test-c0f4202a-2b0f-11e9-90f5-5e78944a5b53)
Feb  7 19:37:11.607: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-bd675.svc from pod e2e-tests-dns-bd675/dns-test-c0f4202a-2b0f-11e9-90f5-5e78944a5b53: the server could not find the requested resource (get pods dns-test-c0f4202a-2b0f-11e9-90f5-5e78944a5b53)
Feb  7 19:37:11.657: INFO: Lookups using e2e-tests-dns-bd675/dns-test-c0f4202a-2b0f-11e9-90f5-5e78944a5b53 failed for: [jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-bd675 jessie_tcp@dns-test-service.e2e-tests-dns-bd675 jessie_udp@dns-test-service.e2e-tests-dns-bd675.svc jessie_tcp@dns-test-service.e2e-tests-dns-bd675.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-bd675.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-bd675.svc]

Feb  7 19:37:17.096: INFO: DNS probes using e2e-tests-dns-bd675/dns-test-c0f4202a-2b0f-11e9-90f5-5e78944a5b53 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:37:17.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-bd675" for this suite.
Feb  7 19:37:23.499: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:37:23.569: INFO: namespace: e2e-tests-dns-bd675, resource: bindings, ignored listing per whitelist
Feb  7 19:37:23.667: INFO: namespace e2e-tests-dns-bd675 deletion completed in 6.228570539s

• [SLOW TEST:16.501 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:37:23.668: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  7 19:37:49.871: INFO: Container started at 2019-02-07 19:37:24 +0000 UTC, pod became ready at 2019-02-07 19:37:48 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:37:49.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-dwxbn" for this suite.
Feb  7 19:38:11.896: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:38:11.924: INFO: namespace: e2e-tests-container-probe-dwxbn, resource: bindings, ignored listing per whitelist
Feb  7 19:38:12.043: INFO: namespace e2e-tests-container-probe-dwxbn deletion completed in 22.165815472s

• [SLOW TEST:48.375 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:38:12.044: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Feb  7 19:38:12.155: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb  7 19:38:12.166: INFO: Waiting for terminating namespaces to be deleted...
Feb  7 19:38:12.170: INFO: 
Logging pods the kubelet thinks is on node conformance0 before test
Feb  7 19:38:12.179: INFO: kube-flannel-ds-l2rpk from kube-system started at 2019-02-07 17:58:51 +0000 UTC (1 container statuses recorded)
Feb  7 19:38:12.179: INFO: 	Container kube-flannel ready: true, restart count 0
Feb  7 19:38:12.179: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-07 18:11:07 +0000 UTC (1 container statuses recorded)
Feb  7 19:38:12.179: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb  7 19:38:12.179: INFO: ingress-default-backend-55c6dddf9b-bsb5j from ingress-haproxy started at 2019-02-07 17:59:13 +0000 UTC (1 container statuses recorded)
Feb  7 19:38:12.180: INFO: 	Container ingress-default-backend ready: true, restart count 0
Feb  7 19:38:12.180: INFO: sonobuoy-systemd-logs-daemon-set-0f8450d3236a4290-khwsz from heptio-sonobuoy started at 2019-02-07 18:11:13 +0000 UTC (2 container statuses recorded)
Feb  7 19:38:12.180: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Feb  7 19:38:12.180: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb  7 19:38:12.180: INFO: kube-dns-6fbf99bd5-vln22 from kube-system started at 2019-02-07 17:59:05 +0000 UTC (3 container statuses recorded)
Feb  7 19:38:12.180: INFO: 	Container dnsmasq ready: true, restart count 0
Feb  7 19:38:12.180: INFO: 	Container kubedns ready: true, restart count 0
Feb  7 19:38:12.180: INFO: 	Container sidecar ready: true, restart count 0
Feb  7 19:38:12.180: INFO: nirmata-cni-installer-548lz from nirmata started at 2019-02-07 17:59:05 +0000 UTC (1 container statuses recorded)
Feb  7 19:38:12.180: INFO: 	Container install-cni ready: true, restart count 0
Feb  7 19:38:12.180: INFO: haproxy-ingress-6cd7fb8fc-bswfw from ingress-haproxy started at 2019-02-07 17:59:13 +0000 UTC (1 container statuses recorded)
Feb  7 19:38:12.180: INFO: 	Container haproxy-ingress ready: true, restart count 0
Feb  7 19:38:12.180: INFO: metrics-server-58fd5b7956-55hhh from kube-system started at 2019-02-07 17:59:35 +0000 UTC (1 container statuses recorded)
Feb  7 19:38:12.180: INFO: 	Container metrics-server ready: true, restart count 0
Feb  7 19:38:12.180: INFO: nirmata-kube-controller-7bc4774558-hdvmg from nirmata started at 2019-02-07 17:59:05 +0000 UTC (1 container statuses recorded)
Feb  7 19:38:12.180: INFO: 	Container nirmata-kube-controller ready: true, restart count 0
Feb  7 19:38:12.180: INFO: sonobuoy-e2e-job-946df599e97f4154 from heptio-sonobuoy started at 2019-02-07 18:11:13 +0000 UTC (2 container statuses recorded)
Feb  7 19:38:12.180: INFO: 	Container e2e ready: true, restart count 0
Feb  7 19:38:12.180: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15812c26dca33e85], Reason = [FailedScheduling], Message = [0/1 nodes are available: 1 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:38:13.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-vxgs7" for this suite.
Feb  7 19:38:19.248: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:38:19.289: INFO: namespace: e2e-tests-sched-pred-vxgs7, resource: bindings, ignored listing per whitelist
Feb  7 19:38:19.407: INFO: namespace e2e-tests-sched-pred-vxgs7 deletion completed in 6.178780175s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.364 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:38:19.408: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Feb  7 19:38:19.515: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 create -f - --namespace=e2e-tests-kubectl-9tfzx'
Feb  7 19:38:19.972: INFO: stderr: ""
Feb  7 19:38:19.972: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb  7 19:38:19.973: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-9tfzx'
Feb  7 19:38:20.214: INFO: stderr: ""
Feb  7 19:38:20.214: INFO: stdout: "update-demo-nautilus-59rqq update-demo-nautilus-dk987 "
Feb  7 19:38:20.214: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 get pods update-demo-nautilus-59rqq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9tfzx'
Feb  7 19:38:20.393: INFO: stderr: ""
Feb  7 19:38:20.393: INFO: stdout: ""
Feb  7 19:38:20.393: INFO: update-demo-nautilus-59rqq is created but not running
Feb  7 19:38:25.393: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-9tfzx'
Feb  7 19:38:25.551: INFO: stderr: ""
Feb  7 19:38:25.551: INFO: stdout: "update-demo-nautilus-59rqq update-demo-nautilus-dk987 "
Feb  7 19:38:25.551: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 get pods update-demo-nautilus-59rqq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9tfzx'
Feb  7 19:38:25.700: INFO: stderr: ""
Feb  7 19:38:25.700: INFO: stdout: "true"
Feb  7 19:38:25.700: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 get pods update-demo-nautilus-59rqq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9tfzx'
Feb  7 19:38:25.846: INFO: stderr: ""
Feb  7 19:38:25.847: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  7 19:38:25.847: INFO: validating pod update-demo-nautilus-59rqq
Feb  7 19:38:25.856: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  7 19:38:25.856: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  7 19:38:25.856: INFO: update-demo-nautilus-59rqq is verified up and running
Feb  7 19:38:25.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 get pods update-demo-nautilus-dk987 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9tfzx'
Feb  7 19:38:26.023: INFO: stderr: ""
Feb  7 19:38:26.023: INFO: stdout: "true"
Feb  7 19:38:26.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 get pods update-demo-nautilus-dk987 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9tfzx'
Feb  7 19:38:26.187: INFO: stderr: ""
Feb  7 19:38:26.187: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  7 19:38:26.187: INFO: validating pod update-demo-nautilus-dk987
Feb  7 19:38:26.196: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  7 19:38:26.196: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  7 19:38:26.196: INFO: update-demo-nautilus-dk987 is verified up and running
STEP: rolling-update to new replication controller
Feb  7 19:38:26.203: INFO: scanned /root for discovery docs: <nil>
Feb  7 19:38:26.203: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-9tfzx'
Feb  7 19:38:49.083: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb  7 19:38:49.083: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb  7 19:38:49.083: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-9tfzx'
Feb  7 19:38:49.295: INFO: stderr: ""
Feb  7 19:38:49.295: INFO: stdout: "update-demo-kitten-r2pxs update-demo-kitten-r45dh "
Feb  7 19:38:49.295: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 get pods update-demo-kitten-r2pxs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9tfzx'
Feb  7 19:38:49.454: INFO: stderr: ""
Feb  7 19:38:49.455: INFO: stdout: "true"
Feb  7 19:38:49.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 get pods update-demo-kitten-r2pxs -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9tfzx'
Feb  7 19:38:49.611: INFO: stderr: ""
Feb  7 19:38:49.611: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb  7 19:38:49.611: INFO: validating pod update-demo-kitten-r2pxs
Feb  7 19:38:49.620: INFO: got data: {
  "image": "kitten.jpg"
}

Feb  7 19:38:49.621: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb  7 19:38:49.621: INFO: update-demo-kitten-r2pxs is verified up and running
Feb  7 19:38:49.621: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 get pods update-demo-kitten-r45dh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9tfzx'
Feb  7 19:38:49.773: INFO: stderr: ""
Feb  7 19:38:49.773: INFO: stdout: "true"
Feb  7 19:38:49.773: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 get pods update-demo-kitten-r45dh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9tfzx'
Feb  7 19:38:49.934: INFO: stderr: ""
Feb  7 19:38:49.934: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb  7 19:38:49.934: INFO: validating pod update-demo-kitten-r45dh
Feb  7 19:38:49.942: INFO: got data: {
  "image": "kitten.jpg"
}

Feb  7 19:38:49.942: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb  7 19:38:49.942: INFO: update-demo-kitten-r45dh is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:38:49.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9tfzx" for this suite.
Feb  7 19:39:13.965: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:39:14.101: INFO: namespace: e2e-tests-kubectl-9tfzx, resource: bindings, ignored listing per whitelist
Feb  7 19:39:14.110: INFO: namespace e2e-tests-kubectl-9tfzx deletion completed in 24.161987785s

• [SLOW TEST:54.702 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:39:14.111: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-0c95b02c-2b10-11e9-90f5-5e78944a5b53
STEP: Creating a pod to test consume secrets
Feb  7 19:39:14.239: INFO: Waiting up to 5m0s for pod "pod-secrets-0c96a968-2b10-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-secrets-q8hg2" to be "success or failure"
Feb  7 19:39:14.262: INFO: Pod "pod-secrets-0c96a968-2b10-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 23.056879ms
Feb  7 19:39:16.267: INFO: Pod "pod-secrets-0c96a968-2b10-11e9-90f5-5e78944a5b53": Phase="Running", Reason="", readiness=true. Elapsed: 2.028000992s
Feb  7 19:39:18.294: INFO: Pod "pod-secrets-0c96a968-2b10-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.055742806s
STEP: Saw pod success
Feb  7 19:39:18.295: INFO: Pod "pod-secrets-0c96a968-2b10-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 19:39:18.301: INFO: Trying to get logs from node conformance0 pod pod-secrets-0c96a968-2b10-11e9-90f5-5e78944a5b53 container secret-env-test: <nil>
STEP: delete the pod
Feb  7 19:39:18.370: INFO: Waiting for pod pod-secrets-0c96a968-2b10-11e9-90f5-5e78944a5b53 to disappear
Feb  7 19:39:18.378: INFO: Pod pod-secrets-0c96a968-2b10-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:39:18.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-q8hg2" for this suite.
Feb  7 19:39:24.403: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:39:24.531: INFO: namespace: e2e-tests-secrets-q8hg2, resource: bindings, ignored listing per whitelist
Feb  7 19:39:24.551: INFO: namespace e2e-tests-secrets-q8hg2 deletion completed in 6.167435262s

• [SLOW TEST:10.440 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:39:24.551: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  7 19:39:24.697: INFO: Waiting up to 5m0s for pod "downwardapi-volume-12d21e43-2b10-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-downward-api-hl5sx" to be "success or failure"
Feb  7 19:39:24.709: INFO: Pod "downwardapi-volume-12d21e43-2b10-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 12.652471ms
Feb  7 19:39:26.716: INFO: Pod "downwardapi-volume-12d21e43-2b10-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019522608s
Feb  7 19:39:28.723: INFO: Pod "downwardapi-volume-12d21e43-2b10-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026384879s
STEP: Saw pod success
Feb  7 19:39:28.723: INFO: Pod "downwardapi-volume-12d21e43-2b10-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 19:39:28.729: INFO: Trying to get logs from node conformance0 pod downwardapi-volume-12d21e43-2b10-11e9-90f5-5e78944a5b53 container client-container: <nil>
STEP: delete the pod
Feb  7 19:39:28.774: INFO: Waiting for pod downwardapi-volume-12d21e43-2b10-11e9-90f5-5e78944a5b53 to disappear
Feb  7 19:39:28.794: INFO: Pod downwardapi-volume-12d21e43-2b10-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:39:28.794: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-hl5sx" for this suite.
Feb  7 19:39:34.823: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:39:34.963: INFO: namespace: e2e-tests-downward-api-hl5sx, resource: bindings, ignored listing per whitelist
Feb  7 19:39:34.983: INFO: namespace e2e-tests-downward-api-hl5sx deletion completed in 6.176029817s

• [SLOW TEST:10.432 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:39:34.984: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0207 19:39:45.130694      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb  7 19:39:45.130: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:39:45.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-rk7bl" for this suite.
Feb  7 19:39:51.151: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:39:51.231: INFO: namespace: e2e-tests-gc-rk7bl, resource: bindings, ignored listing per whitelist
Feb  7 19:39:51.300: INFO: namespace e2e-tests-gc-rk7bl deletion completed in 6.164151301s

• [SLOW TEST:16.316 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:39:51.301: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb  7 19:39:51.414: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-nlrc7'
Feb  7 19:39:51.577: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb  7 19:39:51.577: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Feb  7 19:39:53.592: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-qg9j6]
Feb  7 19:39:53.592: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-qg9j6" in namespace "e2e-tests-kubectl-nlrc7" to be "running and ready"
Feb  7 19:39:53.597: INFO: Pod "e2e-test-nginx-rc-qg9j6": Phase="Running", Reason="", readiness=true. Elapsed: 5.013873ms
Feb  7 19:39:53.597: INFO: Pod "e2e-test-nginx-rc-qg9j6" satisfied condition "running and ready"
Feb  7 19:39:53.597: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-qg9j6]
Feb  7 19:39:53.597: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-nlrc7'
Feb  7 19:39:53.801: INFO: stderr: ""
Feb  7 19:39:53.801: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1303
Feb  7 19:39:53.801: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-nlrc7'
Feb  7 19:39:53.997: INFO: stderr: ""
Feb  7 19:39:53.997: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:39:53.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-nlrc7" for this suite.
Feb  7 19:40:00.034: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:40:00.135: INFO: namespace: e2e-tests-kubectl-nlrc7, resource: bindings, ignored listing per whitelist
Feb  7 19:40:00.192: INFO: namespace e2e-tests-kubectl-nlrc7 deletion completed in 6.176182874s

• [SLOW TEST:8.891 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:40:00.193: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb  7 19:40:00.308: INFO: Waiting up to 5m0s for pod "pod-280d3c9e-2b10-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-emptydir-h7vjk" to be "success or failure"
Feb  7 19:40:00.323: INFO: Pod "pod-280d3c9e-2b10-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 15.027876ms
Feb  7 19:40:02.330: INFO: Pod "pod-280d3c9e-2b10-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021994469s
STEP: Saw pod success
Feb  7 19:40:02.330: INFO: Pod "pod-280d3c9e-2b10-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 19:40:02.335: INFO: Trying to get logs from node conformance0 pod pod-280d3c9e-2b10-11e9-90f5-5e78944a5b53 container test-container: <nil>
STEP: delete the pod
Feb  7 19:40:02.382: INFO: Waiting for pod pod-280d3c9e-2b10-11e9-90f5-5e78944a5b53 to disappear
Feb  7 19:40:02.393: INFO: Pod pod-280d3c9e-2b10-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:40:02.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-h7vjk" for this suite.
Feb  7 19:40:08.427: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:40:08.519: INFO: namespace: e2e-tests-emptydir-h7vjk, resource: bindings, ignored listing per whitelist
Feb  7 19:40:08.570: INFO: namespace e2e-tests-emptydir-h7vjk deletion completed in 6.166802976s

• [SLOW TEST:8.377 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:40:08.572: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-mv6kp
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-mv6kp
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-mv6kp
Feb  7 19:40:08.764: INFO: Found 0 stateful pods, waiting for 1
Feb  7 19:40:18.770: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Feb  7 19:40:18.777: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 exec --namespace=e2e-tests-statefulset-mv6kp ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  7 19:40:19.039: INFO: stderr: ""
Feb  7 19:40:19.039: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  7 19:40:19.039: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  7 19:40:19.043: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb  7 19:40:29.051: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb  7 19:40:29.051: INFO: Waiting for statefulset status.replicas updated to 0
Feb  7 19:40:29.078: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Feb  7 19:40:29.078: INFO: ss-0  conformance0  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:08 +0000 UTC  }]
Feb  7 19:40:29.078: INFO: 
Feb  7 19:40:29.079: INFO: StatefulSet ss has not reached scale 3, at 1
Feb  7 19:40:30.087: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.990311289s
Feb  7 19:40:31.093: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.981609887s
Feb  7 19:40:32.099: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.975817807s
Feb  7 19:40:33.106: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.96980594s
Feb  7 19:40:34.112: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.962922939s
Feb  7 19:40:35.118: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.957284062s
Feb  7 19:40:36.122: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.951304751s
Feb  7 19:40:37.128: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.946375513s
Feb  7 19:40:38.134: INFO: Verifying statefulset ss doesn't scale past 3 for another 940.691372ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-mv6kp
Feb  7 19:40:39.140: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 exec --namespace=e2e-tests-statefulset-mv6kp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  7 19:40:39.409: INFO: stderr: ""
Feb  7 19:40:39.409: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  7 19:40:39.409: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  7 19:40:39.409: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 exec --namespace=e2e-tests-statefulset-mv6kp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  7 19:40:39.707: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Feb  7 19:40:39.707: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  7 19:40:39.707: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  7 19:40:39.707: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 exec --namespace=e2e-tests-statefulset-mv6kp ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  7 19:40:40.035: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Feb  7 19:40:40.035: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  7 19:40:40.035: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  7 19:40:40.041: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb  7 19:40:40.041: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb  7 19:40:40.041: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Feb  7 19:40:40.046: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 exec --namespace=e2e-tests-statefulset-mv6kp ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  7 19:40:40.309: INFO: stderr: ""
Feb  7 19:40:40.309: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  7 19:40:40.309: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  7 19:40:40.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 exec --namespace=e2e-tests-statefulset-mv6kp ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  7 19:40:40.565: INFO: stderr: ""
Feb  7 19:40:40.565: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  7 19:40:40.565: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  7 19:40:40.565: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 exec --namespace=e2e-tests-statefulset-mv6kp ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  7 19:40:40.916: INFO: stderr: ""
Feb  7 19:40:40.916: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  7 19:40:40.916: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  7 19:40:40.916: INFO: Waiting for statefulset status.replicas updated to 0
Feb  7 19:40:40.930: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Feb  7 19:40:50.942: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb  7 19:40:50.942: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb  7 19:40:50.942: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb  7 19:40:50.962: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Feb  7 19:40:50.962: INFO: ss-0  conformance0  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:08 +0000 UTC  }]
Feb  7 19:40:50.962: INFO: ss-1  conformance0  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:29 +0000 UTC  }]
Feb  7 19:40:50.962: INFO: ss-2  conformance0  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:29 +0000 UTC  }]
Feb  7 19:40:50.962: INFO: 
Feb  7 19:40:50.962: INFO: StatefulSet ss has not reached scale 0, at 3
Feb  7 19:40:51.969: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Feb  7 19:40:51.969: INFO: ss-0  conformance0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:08 +0000 UTC  }]
Feb  7 19:40:51.969: INFO: ss-1  conformance0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:29 +0000 UTC  }]
Feb  7 19:40:51.969: INFO: ss-2  conformance0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:29 +0000 UTC  }]
Feb  7 19:40:51.969: INFO: 
Feb  7 19:40:51.969: INFO: StatefulSet ss has not reached scale 0, at 3
Feb  7 19:40:52.975: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Feb  7 19:40:52.976: INFO: ss-0  conformance0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:08 +0000 UTC  }]
Feb  7 19:40:52.976: INFO: ss-1  conformance0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:29 +0000 UTC  }]
Feb  7 19:40:52.976: INFO: ss-2  conformance0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:29 +0000 UTC  }]
Feb  7 19:40:52.976: INFO: 
Feb  7 19:40:52.976: INFO: StatefulSet ss has not reached scale 0, at 3
Feb  7 19:40:53.981: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Feb  7 19:40:53.981: INFO: ss-2  conformance0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:29 +0000 UTC  }]
Feb  7 19:40:53.981: INFO: 
Feb  7 19:40:53.981: INFO: StatefulSet ss has not reached scale 0, at 1
Feb  7 19:40:54.987: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Feb  7 19:40:54.988: INFO: ss-2  conformance0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:29 +0000 UTC  }]
Feb  7 19:40:54.988: INFO: 
Feb  7 19:40:54.988: INFO: StatefulSet ss has not reached scale 0, at 1
Feb  7 19:40:55.993: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Feb  7 19:40:55.993: INFO: ss-2  conformance0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:29 +0000 UTC  }]
Feb  7 19:40:55.993: INFO: 
Feb  7 19:40:55.993: INFO: StatefulSet ss has not reached scale 0, at 1
Feb  7 19:40:56.998: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Feb  7 19:40:56.998: INFO: ss-2  conformance0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:29 +0000 UTC  }]
Feb  7 19:40:56.998: INFO: 
Feb  7 19:40:56.999: INFO: StatefulSet ss has not reached scale 0, at 1
Feb  7 19:40:58.009: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Feb  7 19:40:58.009: INFO: ss-2  conformance0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-07 19:40:29 +0000 UTC  }]
Feb  7 19:40:58.009: INFO: 
Feb  7 19:40:58.009: INFO: StatefulSet ss has not reached scale 0, at 1
Feb  7 19:40:59.018: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.947144454s
Feb  7 19:41:00.022: INFO: Verifying statefulset ss doesn't scale past 0 for another 938.737183ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-mv6kp
Feb  7 19:41:01.029: INFO: Scaling statefulset ss to 0
Feb  7 19:41:01.047: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb  7 19:41:01.051: INFO: Deleting all statefulset in ns e2e-tests-statefulset-mv6kp
Feb  7 19:41:01.056: INFO: Scaling statefulset ss to 0
Feb  7 19:41:01.067: INFO: Waiting for statefulset status.replicas updated to 0
Feb  7 19:41:01.072: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:41:01.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-mv6kp" for this suite.
Feb  7 19:41:07.114: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:41:07.201: INFO: namespace: e2e-tests-statefulset-mv6kp, resource: bindings, ignored listing per whitelist
Feb  7 19:41:07.280: INFO: namespace e2e-tests-statefulset-mv6kp deletion completed in 6.184751574s

• [SLOW TEST:58.709 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:41:07.281: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  7 19:41:07.400: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:41:09.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-sxht8" for this suite.
Feb  7 19:41:49.483: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:41:49.564: INFO: namespace: e2e-tests-pods-sxht8, resource: bindings, ignored listing per whitelist
Feb  7 19:41:49.629: INFO: namespace e2e-tests-pods-sxht8 deletion completed in 40.162820647s

• [SLOW TEST:42.348 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:41:49.630: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb  7 19:41:52.310: INFO: Successfully updated pod "annotationupdate69496d6a-2b10-11e9-90f5-5e78944a5b53"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:41:56.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-j8jx4" for this suite.
Feb  7 19:42:18.379: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:42:18.454: INFO: namespace: e2e-tests-projected-j8jx4, resource: bindings, ignored listing per whitelist
Feb  7 19:42:18.552: INFO: namespace e2e-tests-projected-j8jx4 deletion completed in 22.190171753s

• [SLOW TEST:28.922 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:42:18.553: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-x55b9/secret-test-7a86a4d9-2b10-11e9-90f5-5e78944a5b53
STEP: Creating a pod to test consume secrets
Feb  7 19:42:18.684: INFO: Waiting up to 5m0s for pod "pod-configmaps-7a87ae26-2b10-11e9-90f5-5e78944a5b53" in namespace "e2e-tests-secrets-x55b9" to be "success or failure"
Feb  7 19:42:18.707: INFO: Pod "pod-configmaps-7a87ae26-2b10-11e9-90f5-5e78944a5b53": Phase="Pending", Reason="", readiness=false. Elapsed: 22.925869ms
Feb  7 19:42:20.712: INFO: Pod "pod-configmaps-7a87ae26-2b10-11e9-90f5-5e78944a5b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028507118s
STEP: Saw pod success
Feb  7 19:42:20.712: INFO: Pod "pod-configmaps-7a87ae26-2b10-11e9-90f5-5e78944a5b53" satisfied condition "success or failure"
Feb  7 19:42:20.718: INFO: Trying to get logs from node conformance0 pod pod-configmaps-7a87ae26-2b10-11e9-90f5-5e78944a5b53 container env-test: <nil>
STEP: delete the pod
Feb  7 19:42:20.806: INFO: Waiting for pod pod-configmaps-7a87ae26-2b10-11e9-90f5-5e78944a5b53 to disappear
Feb  7 19:42:20.858: INFO: Pod pod-configmaps-7a87ae26-2b10-11e9-90f5-5e78944a5b53 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:42:20.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-x55b9" for this suite.
Feb  7 19:42:26.911: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:42:26.965: INFO: namespace: e2e-tests-secrets-x55b9, resource: bindings, ignored listing per whitelist
Feb  7 19:42:27.133: INFO: namespace e2e-tests-secrets-x55b9 deletion completed in 6.254459142s

• [SLOW TEST:8.580 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  7 19:42:27.133: INFO: >>> kubeConfig: /tmp/kubeconfig-206495916
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Feb  7 19:42:27.301: INFO: namespace e2e-tests-kubectl-8cc4d
Feb  7 19:42:27.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 create -f - --namespace=e2e-tests-kubectl-8cc4d'
Feb  7 19:42:27.658: INFO: stderr: ""
Feb  7 19:42:27.658: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb  7 19:42:28.662: INFO: Selector matched 1 pods for map[app:redis]
Feb  7 19:42:28.663: INFO: Found 0 / 1
Feb  7 19:42:29.663: INFO: Selector matched 1 pods for map[app:redis]
Feb  7 19:42:29.663: INFO: Found 0 / 1
Feb  7 19:42:30.663: INFO: Selector matched 1 pods for map[app:redis]
Feb  7 19:42:30.663: INFO: Found 1 / 1
Feb  7 19:42:30.663: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb  7 19:42:30.670: INFO: Selector matched 1 pods for map[app:redis]
Feb  7 19:42:30.670: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb  7 19:42:30.670: INFO: wait on redis-master startup in e2e-tests-kubectl-8cc4d 
Feb  7 19:42:30.670: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 logs redis-master-grqk2 redis-master --namespace=e2e-tests-kubectl-8cc4d'
Feb  7 19:42:30.876: INFO: stderr: ""
Feb  7 19:42:30.876: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 07 Feb 19:42:29.696 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 07 Feb 19:42:29.696 # Server started, Redis version 3.2.12\n1:M 07 Feb 19:42:29.696 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 07 Feb 19:42:29.696 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Feb  7 19:42:30.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-8cc4d'
Feb  7 19:42:31.099: INFO: stderr: ""
Feb  7 19:42:31.099: INFO: stdout: "service/rm2 exposed\n"
Feb  7 19:42:31.108: INFO: Service rm2 in namespace e2e-tests-kubectl-8cc4d found.
STEP: exposing service
Feb  7 19:42:33.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-206495916 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-8cc4d'
Feb  7 19:42:33.296: INFO: stderr: ""
Feb  7 19:42:33.296: INFO: stdout: "service/rm3 exposed\n"
Feb  7 19:42:33.314: INFO: Service rm3 in namespace e2e-tests-kubectl-8cc4d found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  7 19:42:35.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-8cc4d" for this suite.
Feb  7 19:42:53.340: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  7 19:42:53.489: INFO: namespace: e2e-tests-kubectl-8cc4d, resource: bindings, ignored listing per whitelist
Feb  7 19:42:53.550: INFO: namespace e2e-tests-kubectl-8cc4d deletion completed in 18.224310732s

• [SLOW TEST:26.417 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SFeb  7 19:42:53.551: INFO: Running AfterSuite actions on all nodes
Feb  7 19:42:53.551: INFO: Running AfterSuite actions on node 1
Feb  7 19:42:53.551: INFO: Skipping dumping logs from cluster

Ran 200 of 1946 Specs in 5448.734 seconds
SUCCESS! -- 200 Passed | 0 Failed | 0 Pending | 1746 Skipped PASS

Ginkgo ran 1 suite in 1h30m50.857477717s
Test Suite Passed
