I0731 06:08:42.673974      18 test_context.go:358] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-864115849
I0731 06:08:42.674081      18 e2e.go:224] Starting e2e run "a5580c68-b359-11e9-990e-fe448544ce72" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1564553321 - Will randomize all specs
Will run 201 of 1946 specs

Jul 31 06:08:42.892: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
Jul 31 06:08:42.894: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Jul 31 06:08:42.906: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Jul 31 06:08:42.931: INFO: 13 / 13 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Jul 31 06:08:42.931: INFO: expected 3 pod replicas in namespace 'kube-system', 3 are Running and Ready.
Jul 31 06:08:42.931: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Jul 31 06:08:42.939: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds' (0 seconds elapsed)
Jul 31 06:08:42.939: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Jul 31 06:08:42.939: INFO: e2e test version: v1.13.0
Jul 31 06:08:42.940: INFO: kube-apiserver version: v1.13.5+1.2.2.el7
S
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:08:42.941: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename gc
Jul 31 06:08:43.005: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Jul 31 06:08:44.037: INFO: MetricsGrabber failed grab metrics. Skipping metrics gathering.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:08:44.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-fpdpg" for this suite.
Jul 31 06:08:50.048: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:08:50.103: INFO: namespace: e2e-tests-gc-fpdpg, resource: bindings, ignored listing per whitelist
Jul 31 06:08:50.118: INFO: namespace e2e-tests-gc-fpdpg deletion completed in 6.078181421s

• [SLOW TEST:7.178 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:08:50.119: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jul 31 06:08:50.176: INFO: Waiting up to 5m0s for pod "downwardapi-volume-aa46772e-b359-11e9-990e-fe448544ce72" in namespace "e2e-tests-projected-dk96q" to be "success or failure"
Jul 31 06:08:50.178: INFO: Pod "downwardapi-volume-aa46772e-b359-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 1.997838ms
Jul 31 06:08:52.181: INFO: Pod "downwardapi-volume-aa46772e-b359-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004983611s
Jul 31 06:08:54.184: INFO: Pod "downwardapi-volume-aa46772e-b359-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007831913s
Jul 31 06:08:56.187: INFO: Pod "downwardapi-volume-aa46772e-b359-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.011103445s
STEP: Saw pod success
Jul 31 06:08:56.187: INFO: Pod "downwardapi-volume-aa46772e-b359-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 06:08:56.189: INFO: Trying to get logs from node shushsha-k8s-worker2 pod downwardapi-volume-aa46772e-b359-11e9-990e-fe448544ce72 container client-container: <nil>
STEP: delete the pod
Jul 31 06:08:56.213: INFO: Waiting for pod downwardapi-volume-aa46772e-b359-11e9-990e-fe448544ce72 to disappear
Jul 31 06:08:56.215: INFO: Pod downwardapi-volume-aa46772e-b359-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:08:56.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dk96q" for this suite.
Jul 31 06:09:02.225: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:09:02.250: INFO: namespace: e2e-tests-projected-dk96q, resource: bindings, ignored listing per whitelist
Jul 31 06:09:02.294: INFO: namespace e2e-tests-projected-dk96q deletion completed in 6.076919632s

• [SLOW TEST:12.176 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:09:02.294: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jul 31 06:09:02.364: INFO: (0) /api/v1/nodes/shushsha-k8s-worker1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 12.888979ms)
Jul 31 06:09:02.368: INFO: (1) /api/v1/nodes/shushsha-k8s-worker1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.094779ms)
Jul 31 06:09:02.371: INFO: (2) /api/v1/nodes/shushsha-k8s-worker1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.906386ms)
Jul 31 06:09:02.373: INFO: (3) /api/v1/nodes/shushsha-k8s-worker1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.678892ms)
Jul 31 06:09:02.376: INFO: (4) /api/v1/nodes/shushsha-k8s-worker1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.53356ms)
Jul 31 06:09:02.379: INFO: (5) /api/v1/nodes/shushsha-k8s-worker1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.886376ms)
Jul 31 06:09:02.381: INFO: (6) /api/v1/nodes/shushsha-k8s-worker1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.699865ms)
Jul 31 06:09:02.384: INFO: (7) /api/v1/nodes/shushsha-k8s-worker1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.727334ms)
Jul 31 06:09:02.387: INFO: (8) /api/v1/nodes/shushsha-k8s-worker1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.831275ms)
Jul 31 06:09:02.391: INFO: (9) /api/v1/nodes/shushsha-k8s-worker1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.157061ms)
Jul 31 06:09:02.394: INFO: (10) /api/v1/nodes/shushsha-k8s-worker1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.625266ms)
Jul 31 06:09:02.397: INFO: (11) /api/v1/nodes/shushsha-k8s-worker1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.559855ms)
Jul 31 06:09:02.399: INFO: (12) /api/v1/nodes/shushsha-k8s-worker1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.631258ms)
Jul 31 06:09:02.402: INFO: (13) /api/v1/nodes/shushsha-k8s-worker1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.856554ms)
Jul 31 06:09:02.405: INFO: (14) /api/v1/nodes/shushsha-k8s-worker1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.702085ms)
Jul 31 06:09:02.408: INFO: (15) /api/v1/nodes/shushsha-k8s-worker1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.68824ms)
Jul 31 06:09:02.410: INFO: (16) /api/v1/nodes/shushsha-k8s-worker1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.677455ms)
Jul 31 06:09:02.413: INFO: (17) /api/v1/nodes/shushsha-k8s-worker1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.542689ms)
Jul 31 06:09:02.416: INFO: (18) /api/v1/nodes/shushsha-k8s-worker1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.647837ms)
Jul 31 06:09:02.418: INFO: (19) /api/v1/nodes/shushsha-k8s-worker1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.698174ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:09:02.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-vd8mx" for this suite.
Jul 31 06:09:08.429: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:09:08.466: INFO: namespace: e2e-tests-proxy-vd8mx, resource: bindings, ignored listing per whitelist
Jul 31 06:09:08.496: INFO: namespace e2e-tests-proxy-vd8mx deletion completed in 6.074781843s

• [SLOW TEST:6.201 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:09:08.496: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-b53a273f-b359-11e9-990e-fe448544ce72
STEP: Creating a pod to test consume configMaps
Jul 31 06:09:08.552: INFO: Waiting up to 5m0s for pod "pod-configmaps-b53a80c2-b359-11e9-990e-fe448544ce72" in namespace "e2e-tests-configmap-29bkj" to be "success or failure"
Jul 31 06:09:08.555: INFO: Pod "pod-configmaps-b53a80c2-b359-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 3.031788ms
Jul 31 06:09:10.558: INFO: Pod "pod-configmaps-b53a80c2-b359-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006106964s
Jul 31 06:09:12.561: INFO: Pod "pod-configmaps-b53a80c2-b359-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009040378s
Jul 31 06:09:14.564: INFO: Pod "pod-configmaps-b53a80c2-b359-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.01211608s
STEP: Saw pod success
Jul 31 06:09:14.564: INFO: Pod "pod-configmaps-b53a80c2-b359-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 06:09:14.567: INFO: Trying to get logs from node shushsha-k8s-worker1 pod pod-configmaps-b53a80c2-b359-11e9-990e-fe448544ce72 container configmap-volume-test: <nil>
STEP: delete the pod
Jul 31 06:09:14.581: INFO: Waiting for pod pod-configmaps-b53a80c2-b359-11e9-990e-fe448544ce72 to disappear
Jul 31 06:09:14.583: INFO: Pod pod-configmaps-b53a80c2-b359-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:09:14.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-29bkj" for this suite.
Jul 31 06:09:20.593: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:09:20.656: INFO: namespace: e2e-tests-configmap-29bkj, resource: bindings, ignored listing per whitelist
Jul 31 06:09:20.661: INFO: namespace e2e-tests-configmap-29bkj deletion completed in 6.075888965s

• [SLOW TEST:12.165 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:09:20.662: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-bc7c6b72-b359-11e9-990e-fe448544ce72
STEP: Creating a pod to test consume secrets
Jul 31 06:09:20.731: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-bc7ccccb-b359-11e9-990e-fe448544ce72" in namespace "e2e-tests-projected-b7m5g" to be "success or failure"
Jul 31 06:09:20.733: INFO: Pod "pod-projected-secrets-bc7ccccb-b359-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 1.827348ms
Jul 31 06:09:22.736: INFO: Pod "pod-projected-secrets-bc7ccccb-b359-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00507849s
Jul 31 06:09:24.739: INFO: Pod "pod-projected-secrets-bc7ccccb-b359-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007876042s
STEP: Saw pod success
Jul 31 06:09:24.739: INFO: Pod "pod-projected-secrets-bc7ccccb-b359-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 06:09:24.741: INFO: Trying to get logs from node shushsha-k8s-worker2 pod pod-projected-secrets-bc7ccccb-b359-11e9-990e-fe448544ce72 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jul 31 06:09:24.755: INFO: Waiting for pod pod-projected-secrets-bc7ccccb-b359-11e9-990e-fe448544ce72 to disappear
Jul 31 06:09:24.757: INFO: Pod pod-projected-secrets-bc7ccccb-b359-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:09:24.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-b7m5g" for this suite.
Jul 31 06:09:30.768: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:09:30.826: INFO: namespace: e2e-tests-projected-b7m5g, resource: bindings, ignored listing per whitelist
Jul 31 06:09:30.841: INFO: namespace e2e-tests-projected-b7m5g deletion completed in 6.081739914s

• [SLOW TEST:10.180 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:09:30.842: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Jul 31 06:09:42.930: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jul 31 06:09:42.933: INFO: Pod pod-with-poststart-http-hook still exists
Jul 31 06:09:44.933: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jul 31 06:09:44.936: INFO: Pod pod-with-poststart-http-hook still exists
Jul 31 06:09:46.933: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jul 31 06:09:46.936: INFO: Pod pod-with-poststart-http-hook still exists
Jul 31 06:09:48.933: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jul 31 06:09:48.937: INFO: Pod pod-with-poststart-http-hook still exists
Jul 31 06:09:50.933: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jul 31 06:09:50.937: INFO: Pod pod-with-poststart-http-hook still exists
Jul 31 06:09:52.933: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jul 31 06:09:52.936: INFO: Pod pod-with-poststart-http-hook still exists
Jul 31 06:09:54.933: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jul 31 06:09:54.936: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:09:54.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-zxrrt" for this suite.
Jul 31 06:10:16.947: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:10:16.960: INFO: namespace: e2e-tests-container-lifecycle-hook-zxrrt, resource: bindings, ignored listing per whitelist
Jul 31 06:10:17.016: INFO: namespace e2e-tests-container-lifecycle-hook-zxrrt deletion completed in 22.077010268s

• [SLOW TEST:46.174 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:10:17.016: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jul 31 06:10:17.084: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 06:10:17.086: INFO: Number of nodes with available pods: 0
Jul 31 06:10:17.086: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 06:10:18.089: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 06:10:18.092: INFO: Number of nodes with available pods: 0
Jul 31 06:10:18.092: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 06:10:19.089: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 06:10:19.092: INFO: Number of nodes with available pods: 0
Jul 31 06:10:19.092: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 06:10:20.089: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 06:10:20.092: INFO: Number of nodes with available pods: 0
Jul 31 06:10:20.092: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 06:10:21.089: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 06:10:21.091: INFO: Number of nodes with available pods: 0
Jul 31 06:10:21.092: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 06:10:22.089: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 06:10:22.091: INFO: Number of nodes with available pods: 0
Jul 31 06:10:22.091: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 06:10:23.089: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 06:10:23.092: INFO: Number of nodes with available pods: 2
Jul 31 06:10:23.092: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Jul 31 06:10:23.103: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 06:10:23.105: INFO: Number of nodes with available pods: 1
Jul 31 06:10:23.105: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 06:10:24.108: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 06:10:24.111: INFO: Number of nodes with available pods: 1
Jul 31 06:10:24.111: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 06:10:25.108: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 06:10:25.110: INFO: Number of nodes with available pods: 1
Jul 31 06:10:25.110: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 06:10:26.109: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 06:10:26.111: INFO: Number of nodes with available pods: 1
Jul 31 06:10:26.111: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 06:10:27.108: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 06:10:27.111: INFO: Number of nodes with available pods: 1
Jul 31 06:10:27.111: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 06:10:28.109: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 06:10:28.111: INFO: Number of nodes with available pods: 1
Jul 31 06:10:28.111: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 06:10:29.109: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 06:10:29.111: INFO: Number of nodes with available pods: 1
Jul 31 06:10:29.111: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 06:10:30.109: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 06:10:30.111: INFO: Number of nodes with available pods: 1
Jul 31 06:10:30.111: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 06:10:31.108: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 06:10:31.111: INFO: Number of nodes with available pods: 1
Jul 31 06:10:31.111: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 06:10:32.108: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 06:10:32.111: INFO: Number of nodes with available pods: 1
Jul 31 06:10:32.111: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 06:10:33.109: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 06:10:33.111: INFO: Number of nodes with available pods: 1
Jul 31 06:10:33.111: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 06:10:34.108: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 06:10:34.111: INFO: Number of nodes with available pods: 1
Jul 31 06:10:34.111: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 06:10:35.109: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 06:10:35.111: INFO: Number of nodes with available pods: 1
Jul 31 06:10:35.111: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 06:10:36.109: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 06:10:36.111: INFO: Number of nodes with available pods: 1
Jul 31 06:10:36.111: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 06:10:37.109: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 06:10:37.111: INFO: Number of nodes with available pods: 1
Jul 31 06:10:37.111: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 06:10:38.109: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 06:10:38.111: INFO: Number of nodes with available pods: 1
Jul 31 06:10:38.111: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 06:10:39.109: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 06:10:39.111: INFO: Number of nodes with available pods: 1
Jul 31 06:10:39.111: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 06:10:40.108: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 06:10:40.111: INFO: Number of nodes with available pods: 1
Jul 31 06:10:40.111: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 06:10:41.109: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 06:10:41.111: INFO: Number of nodes with available pods: 1
Jul 31 06:10:41.111: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 06:10:42.108: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 06:10:42.111: INFO: Number of nodes with available pods: 1
Jul 31 06:10:42.111: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 06:10:43.109: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 06:10:43.111: INFO: Number of nodes with available pods: 1
Jul 31 06:10:43.112: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 06:10:44.108: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 06:10:44.110: INFO: Number of nodes with available pods: 1
Jul 31 06:10:44.110: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 06:10:45.109: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 06:10:45.111: INFO: Number of nodes with available pods: 1
Jul 31 06:10:45.111: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 06:10:46.109: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 06:10:46.111: INFO: Number of nodes with available pods: 1
Jul 31 06:10:46.111: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 06:10:47.108: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 06:10:47.111: INFO: Number of nodes with available pods: 1
Jul 31 06:10:47.111: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 06:10:48.109: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 06:10:48.111: INFO: Number of nodes with available pods: 1
Jul 31 06:10:48.111: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 06:10:49.109: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 06:10:49.111: INFO: Number of nodes with available pods: 1
Jul 31 06:10:49.111: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 06:10:50.109: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 06:10:50.111: INFO: Number of nodes with available pods: 1
Jul 31 06:10:50.111: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 06:10:51.109: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 06:10:51.112: INFO: Number of nodes with available pods: 1
Jul 31 06:10:51.112: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 06:10:52.109: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 06:10:52.111: INFO: Number of nodes with available pods: 1
Jul 31 06:10:52.111: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 06:10:53.109: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 06:10:53.111: INFO: Number of nodes with available pods: 1
Jul 31 06:10:53.111: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 06:10:54.108: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 06:10:54.111: INFO: Number of nodes with available pods: 1
Jul 31 06:10:54.111: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 06:10:55.108: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 06:10:55.111: INFO: Number of nodes with available pods: 1
Jul 31 06:10:55.111: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 06:10:56.109: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 06:10:56.111: INFO: Number of nodes with available pods: 1
Jul 31 06:10:56.111: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 06:10:57.109: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 06:10:57.111: INFO: Number of nodes with available pods: 1
Jul 31 06:10:57.111: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 06:10:58.109: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 06:10:58.111: INFO: Number of nodes with available pods: 1
Jul 31 06:10:58.111: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 06:10:59.109: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 06:10:59.111: INFO: Number of nodes with available pods: 2
Jul 31 06:10:59.111: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-zn7rn, will wait for the garbage collector to delete the pods
Jul 31 06:10:59.170: INFO: Deleting DaemonSet.extensions daemon-set took: 4.676486ms
Jul 31 06:10:59.271: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.276507ms
Jul 31 06:11:42.773: INFO: Number of nodes with available pods: 0
Jul 31 06:11:42.773: INFO: Number of running nodes: 0, number of available pods: 0
Jul 31 06:11:42.779: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-zn7rn/daemonsets","resourceVersion":"1643"},"items":null}

Jul 31 06:11:42.781: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-zn7rn/pods","resourceVersion":"1643"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:11:42.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-zn7rn" for this suite.
Jul 31 06:11:48.798: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:11:48.835: INFO: namespace: e2e-tests-daemonsets-zn7rn, resource: bindings, ignored listing per whitelist
Jul 31 06:11:48.866: INFO: namespace e2e-tests-daemonsets-zn7rn deletion completed in 6.076534523s

• [SLOW TEST:91.851 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:11:48.867: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-tmszt
Jul 31 06:11:54.929: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-tmszt
STEP: checking the pod's current state and verifying that restartCount is present
Jul 31 06:11:54.931: INFO: Initial restart count of pod liveness-exec is 0
Jul 31 06:12:43.004: INFO: Restart count of pod e2e-tests-container-probe-tmszt/liveness-exec is now 1 (48.07356206s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:12:43.010: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-tmszt" for this suite.
Jul 31 06:12:49.021: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:12:49.080: INFO: namespace: e2e-tests-container-probe-tmszt, resource: bindings, ignored listing per whitelist
Jul 31 06:12:49.089: INFO: namespace e2e-tests-container-probe-tmszt deletion completed in 6.075599809s

• [SLOW TEST:60.222 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:12:49.089: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Jul 31 06:12:49.152: INFO: Waiting up to 5m0s for pod "client-containers-38b75527-b35a-11e9-990e-fe448544ce72" in namespace "e2e-tests-containers-nrt7x" to be "success or failure"
Jul 31 06:12:49.154: INFO: Pod "client-containers-38b75527-b35a-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.511242ms
Jul 31 06:12:51.160: INFO: Pod "client-containers-38b75527-b35a-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007816556s
Jul 31 06:12:53.163: INFO: Pod "client-containers-38b75527-b35a-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011582532s
Jul 31 06:12:55.167: INFO: Pod "client-containers-38b75527-b35a-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.014743531s
STEP: Saw pod success
Jul 31 06:12:55.167: INFO: Pod "client-containers-38b75527-b35a-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 06:12:55.169: INFO: Trying to get logs from node shushsha-k8s-worker2 pod client-containers-38b75527-b35a-11e9-990e-fe448544ce72 container test-container: <nil>
STEP: delete the pod
Jul 31 06:12:55.182: INFO: Waiting for pod client-containers-38b75527-b35a-11e9-990e-fe448544ce72 to disappear
Jul 31 06:12:55.191: INFO: Pod client-containers-38b75527-b35a-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:12:55.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-nrt7x" for this suite.
Jul 31 06:13:01.202: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:13:01.223: INFO: namespace: e2e-tests-containers-nrt7x, resource: bindings, ignored listing per whitelist
Jul 31 06:13:01.272: INFO: namespace e2e-tests-containers-nrt7x deletion completed in 6.07854024s

• [SLOW TEST:12.183 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:13:01.272: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-h6n7d
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-h6n7d to expose endpoints map[]
Jul 31 06:13:01.335: INFO: Get endpoints failed (2.436524ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Jul 31 06:13:02.338: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-h6n7d exposes endpoints map[] (1.005197787s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-h6n7d
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-h6n7d to expose endpoints map[pod1:[80]]
Jul 31 06:13:06.367: INFO: Unexpected endpoints: found map[], expected map[pod1:[80]] (4.024774397s elapsed, will retry)
Jul 31 06:13:08.381: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-h6n7d exposes endpoints map[pod1:[80]] (6.038982139s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-h6n7d
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-h6n7d to expose endpoints map[pod1:[80] pod2:[80]]
Jul 31 06:13:10.407: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-h6n7d exposes endpoints map[pod1:[80] pod2:[80]] (2.021839429s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-h6n7d
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-h6n7d to expose endpoints map[pod2:[80]]
Jul 31 06:13:11.422: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-h6n7d exposes endpoints map[pod2:[80]] (1.010493096s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-h6n7d
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-h6n7d to expose endpoints map[]
Jul 31 06:13:12.430: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-h6n7d exposes endpoints map[] (1.004534287s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:13:12.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-h6n7d" for this suite.
Jul 31 06:13:34.455: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:13:34.526: INFO: namespace: e2e-tests-services-h6n7d, resource: bindings, ignored listing per whitelist
Jul 31 06:13:34.526: INFO: namespace e2e-tests-services-h6n7d deletion completed in 22.080324297s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:33.254 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:13:34.526: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jul 31 06:13:34.581: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-xvph5'
Jul 31 06:13:34.793: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jul 31 06:13:34.793: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Jul 31 06:13:34.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-xvph5'
Jul 31 06:13:34.884: INFO: stderr: ""
Jul 31 06:13:34.884: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:13:34.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xvph5" for this suite.
Jul 31 06:13:56.897: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:13:56.910: INFO: namespace: e2e-tests-kubectl-xvph5, resource: bindings, ignored listing per whitelist
Jul 31 06:13:56.965: INFO: namespace e2e-tests-kubectl-xvph5 deletion completed in 22.078011972s

• [SLOW TEST:22.439 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:13:56.965: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-612bc7ed-b35a-11e9-990e-fe448544ce72
STEP: Creating a pod to test consume secrets
Jul 31 06:13:57.045: INFO: Waiting up to 5m0s for pod "pod-secrets-612effe0-b35a-11e9-990e-fe448544ce72" in namespace "e2e-tests-secrets-222q2" to be "success or failure"
Jul 31 06:13:57.047: INFO: Pod "pod-secrets-612effe0-b35a-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029654ms
Jul 31 06:13:59.049: INFO: Pod "pod-secrets-612effe0-b35a-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004618404s
STEP: Saw pod success
Jul 31 06:13:59.049: INFO: Pod "pod-secrets-612effe0-b35a-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 06:13:59.052: INFO: Trying to get logs from node shushsha-k8s-worker1 pod pod-secrets-612effe0-b35a-11e9-990e-fe448544ce72 container secret-volume-test: <nil>
STEP: delete the pod
Jul 31 06:13:59.065: INFO: Waiting for pod pod-secrets-612effe0-b35a-11e9-990e-fe448544ce72 to disappear
Jul 31 06:13:59.067: INFO: Pod pod-secrets-612effe0-b35a-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:13:59.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-222q2" for this suite.
Jul 31 06:14:05.079: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:14:05.099: INFO: namespace: e2e-tests-secrets-222q2, resource: bindings, ignored listing per whitelist
Jul 31 06:14:05.147: INFO: namespace e2e-tests-secrets-222q2 deletion completed in 6.077598638s
STEP: Destroying namespace "e2e-tests-secret-namespace-cnjlt" for this suite.
Jul 31 06:14:11.156: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:14:11.196: INFO: namespace: e2e-tests-secret-namespace-cnjlt, resource: bindings, ignored listing per whitelist
Jul 31 06:14:11.231: INFO: namespace e2e-tests-secret-namespace-cnjlt deletion completed in 6.083899466s

• [SLOW TEST:14.266 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:14:11.232: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jul 31 06:14:11.286: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 version'
Jul 31 06:14:11.353: INFO: stderr: ""
Jul 31 06:14:11.353: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.5+1.2.2.el7\", GitCommit:\"067c6116d2598861bd31a0609b34599a68b14f89\", GitTreeState:\"archive\", BuildDate:\"2019-05-23T19:33:18Z\", GoVersion:\"go1.11.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:14:11.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-jn5jx" for this suite.
Jul 31 06:14:17.364: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:14:17.423: INFO: namespace: e2e-tests-kubectl-jn5jx, resource: bindings, ignored listing per whitelist
Jul 31 06:14:17.431: INFO: namespace e2e-tests-kubectl-jn5jx deletion completed in 6.074890806s

• [SLOW TEST:6.199 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:14:17.431: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jul 31 06:14:17.489: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6d5e7e83-b35a-11e9-990e-fe448544ce72" in namespace "e2e-tests-downward-api-9zfpw" to be "success or failure"
Jul 31 06:14:17.491: INFO: Pod "downwardapi-volume-6d5e7e83-b35a-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.258329ms
Jul 31 06:14:19.494: INFO: Pod "downwardapi-volume-6d5e7e83-b35a-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005354785s
STEP: Saw pod success
Jul 31 06:14:19.494: INFO: Pod "downwardapi-volume-6d5e7e83-b35a-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 06:14:19.496: INFO: Trying to get logs from node shushsha-k8s-worker1 pod downwardapi-volume-6d5e7e83-b35a-11e9-990e-fe448544ce72 container client-container: <nil>
STEP: delete the pod
Jul 31 06:14:19.512: INFO: Waiting for pod downwardapi-volume-6d5e7e83-b35a-11e9-990e-fe448544ce72 to disappear
Jul 31 06:14:19.513: INFO: Pod downwardapi-volume-6d5e7e83-b35a-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:14:19.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-9zfpw" for this suite.
Jul 31 06:14:25.524: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:14:25.581: INFO: namespace: e2e-tests-downward-api-9zfpw, resource: bindings, ignored listing per whitelist
Jul 31 06:14:25.592: INFO: namespace e2e-tests-downward-api-9zfpw deletion completed in 6.076413712s

• [SLOW TEST:8.161 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:14:25.592: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Jul 31 06:14:37.680: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 31 06:14:37.683: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 31 06:14:39.683: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 31 06:14:39.686: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 31 06:14:41.683: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 31 06:14:41.686: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 31 06:14:43.683: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 31 06:14:43.686: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 31 06:14:45.683: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 31 06:14:45.686: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 31 06:14:47.683: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 31 06:14:47.686: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 31 06:14:49.683: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 31 06:14:49.686: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 31 06:14:51.683: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 31 06:14:51.686: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 31 06:14:53.683: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 31 06:14:53.686: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 31 06:14:55.683: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 31 06:14:55.686: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 31 06:14:57.683: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 31 06:14:57.686: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 31 06:14:59.683: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 31 06:14:59.686: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 31 06:15:01.683: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 31 06:15:01.686: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 31 06:15:03.683: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 31 06:15:03.686: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:15:03.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-d4qwl" for this suite.
Jul 31 06:15:25.697: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:15:25.754: INFO: namespace: e2e-tests-container-lifecycle-hook-d4qwl, resource: bindings, ignored listing per whitelist
Jul 31 06:15:25.768: INFO: namespace e2e-tests-container-lifecycle-hook-d4qwl deletion completed in 22.079244251s

• [SLOW TEST:60.175 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:15:25.768: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jul 31 06:15:25.855: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"961c23f9-b35a-11e9-ac6f-000017003e78", Controller:(*bool)(0xc001a592ba), BlockOwnerDeletion:(*bool)(0xc001a592bb)}}
Jul 31 06:15:25.859: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"961aa97c-b35a-11e9-ac6f-000017003e78", Controller:(*bool)(0xc000cf2982), BlockOwnerDeletion:(*bool)(0xc000cf2983)}}
Jul 31 06:15:25.862: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"961b54d0-b35a-11e9-ac6f-000017003e78", Controller:(*bool)(0xc001a594fa), BlockOwnerDeletion:(*bool)(0xc001a594fb)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:15:30.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-xp4bs" for this suite.
Jul 31 06:15:36.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:15:36.939: INFO: namespace: e2e-tests-gc-xp4bs, resource: bindings, ignored listing per whitelist
Jul 31 06:15:36.949: INFO: namespace e2e-tests-gc-xp4bs deletion completed in 6.078756181s

• [SLOW TEST:11.181 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:15:36.949: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Jul 31 06:15:37.011: INFO: Waiting up to 5m0s for pod "pod-9cc4b551-b35a-11e9-990e-fe448544ce72" in namespace "e2e-tests-emptydir-6c4sn" to be "success or failure"
Jul 31 06:15:37.014: INFO: Pod "pod-9cc4b551-b35a-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.825792ms
Jul 31 06:15:39.017: INFO: Pod "pod-9cc4b551-b35a-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005186608s
STEP: Saw pod success
Jul 31 06:15:39.017: INFO: Pod "pod-9cc4b551-b35a-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 06:15:39.019: INFO: Trying to get logs from node shushsha-k8s-worker1 pod pod-9cc4b551-b35a-11e9-990e-fe448544ce72 container test-container: <nil>
STEP: delete the pod
Jul 31 06:15:39.031: INFO: Waiting for pod pod-9cc4b551-b35a-11e9-990e-fe448544ce72 to disappear
Jul 31 06:15:39.033: INFO: Pod pod-9cc4b551-b35a-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:15:39.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-6c4sn" for this suite.
Jul 31 06:15:45.047: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:15:45.105: INFO: namespace: e2e-tests-emptydir-6c4sn, resource: bindings, ignored listing per whitelist
Jul 31 06:15:45.116: INFO: namespace e2e-tests-emptydir-6c4sn deletion completed in 6.080545443s

• [SLOW TEST:8.167 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:15:45.116: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jul 31 06:15:45.176: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a1a27b9f-b35a-11e9-990e-fe448544ce72" in namespace "e2e-tests-projected-k2mcj" to be "success or failure"
Jul 31 06:15:45.180: INFO: Pod "downwardapi-volume-a1a27b9f-b35a-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 3.367405ms
Jul 31 06:15:47.182: INFO: Pod "downwardapi-volume-a1a27b9f-b35a-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005996392s
Jul 31 06:15:49.185: INFO: Pod "downwardapi-volume-a1a27b9f-b35a-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008817186s
STEP: Saw pod success
Jul 31 06:15:49.185: INFO: Pod "downwardapi-volume-a1a27b9f-b35a-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 06:15:49.187: INFO: Trying to get logs from node shushsha-k8s-worker2 pod downwardapi-volume-a1a27b9f-b35a-11e9-990e-fe448544ce72 container client-container: <nil>
STEP: delete the pod
Jul 31 06:15:49.200: INFO: Waiting for pod downwardapi-volume-a1a27b9f-b35a-11e9-990e-fe448544ce72 to disappear
Jul 31 06:15:49.203: INFO: Pod downwardapi-volume-a1a27b9f-b35a-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:15:49.203: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-k2mcj" for this suite.
Jul 31 06:15:55.214: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:15:55.230: INFO: namespace: e2e-tests-projected-k2mcj, resource: bindings, ignored listing per whitelist
Jul 31 06:15:55.282: INFO: namespace e2e-tests-projected-k2mcj deletion completed in 6.076215424s

• [SLOW TEST:10.166 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:15:55.283: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jul 31 06:15:55.337: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:15:57.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-m68cr" for this suite.
Jul 31 06:16:47.458: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:16:47.503: INFO: namespace: e2e-tests-pods-m68cr, resource: bindings, ignored listing per whitelist
Jul 31 06:16:47.524: INFO: namespace e2e-tests-pods-m68cr deletion completed in 50.075108635s

• [SLOW TEST:52.242 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:16:47.524: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jul 31 06:16:47.583: INFO: Waiting up to 5m0s for pod "pod-c6d50de2-b35a-11e9-990e-fe448544ce72" in namespace "e2e-tests-emptydir-j4bz7" to be "success or failure"
Jul 31 06:16:47.585: INFO: Pod "pod-c6d50de2-b35a-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.241761ms
Jul 31 06:16:49.588: INFO: Pod "pod-c6d50de2-b35a-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005351414s
Jul 31 06:16:51.592: INFO: Pod "pod-c6d50de2-b35a-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008705941s
Jul 31 06:16:53.595: INFO: Pod "pod-c6d50de2-b35a-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.011971887s
STEP: Saw pod success
Jul 31 06:16:53.595: INFO: Pod "pod-c6d50de2-b35a-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 06:16:53.597: INFO: Trying to get logs from node shushsha-k8s-worker2 pod pod-c6d50de2-b35a-11e9-990e-fe448544ce72 container test-container: <nil>
STEP: delete the pod
Jul 31 06:16:53.610: INFO: Waiting for pod pod-c6d50de2-b35a-11e9-990e-fe448544ce72 to disappear
Jul 31 06:16:53.612: INFO: Pod pod-c6d50de2-b35a-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:16:53.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-j4bz7" for this suite.
Jul 31 06:16:59.623: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:16:59.690: INFO: namespace: e2e-tests-emptydir-j4bz7, resource: bindings, ignored listing per whitelist
Jul 31 06:16:59.692: INFO: namespace e2e-tests-emptydir-j4bz7 deletion completed in 6.076941877s

• [SLOW TEST:12.167 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:16:59.692: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Jul 31 06:16:59.747: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Jul 31 06:16:59.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 create -f - --namespace=e2e-tests-kubectl-t89kr'
Jul 31 06:16:59.989: INFO: stderr: ""
Jul 31 06:16:59.989: INFO: stdout: "service/redis-slave created\n"
Jul 31 06:16:59.990: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Jul 31 06:16:59.990: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 create -f - --namespace=e2e-tests-kubectl-t89kr'
Jul 31 06:17:00.182: INFO: stderr: ""
Jul 31 06:17:00.182: INFO: stdout: "service/redis-master created\n"
Jul 31 06:17:00.182: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Jul 31 06:17:00.182: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 create -f - --namespace=e2e-tests-kubectl-t89kr'
Jul 31 06:17:00.365: INFO: stderr: ""
Jul 31 06:17:00.365: INFO: stdout: "service/frontend created\n"
Jul 31 06:17:00.366: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Jul 31 06:17:00.366: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 create -f - --namespace=e2e-tests-kubectl-t89kr'
Jul 31 06:17:00.548: INFO: stderr: ""
Jul 31 06:17:00.548: INFO: stdout: "deployment.extensions/frontend created\n"
Jul 31 06:17:00.548: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Jul 31 06:17:00.548: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 create -f - --namespace=e2e-tests-kubectl-t89kr'
Jul 31 06:17:00.713: INFO: stderr: ""
Jul 31 06:17:00.713: INFO: stdout: "deployment.extensions/redis-master created\n"
Jul 31 06:17:00.713: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Jul 31 06:17:00.713: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 create -f - --namespace=e2e-tests-kubectl-t89kr'
Jul 31 06:17:00.892: INFO: stderr: ""
Jul 31 06:17:00.892: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Jul 31 06:17:00.892: INFO: Waiting for all frontend pods to be Running.
Jul 31 06:17:30.943: INFO: Waiting for frontend to serve content.
Jul 31 06:17:30.962: INFO: Trying to add a new entry to the guestbook.
Jul 31 06:17:30.975: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Jul 31 06:17:30.985: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-t89kr'
Jul 31 06:17:31.123: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 31 06:17:31.123: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Jul 31 06:17:31.123: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-t89kr'
Jul 31 06:17:31.268: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 31 06:17:31.268: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Jul 31 06:17:31.268: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-t89kr'
Jul 31 06:17:31.402: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 31 06:17:31.402: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Jul 31 06:17:31.402: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-t89kr'
Jul 31 06:17:31.529: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 31 06:17:31.529: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Jul 31 06:17:31.530: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-t89kr'
Jul 31 06:17:31.658: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 31 06:17:31.658: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Jul 31 06:17:31.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-t89kr'
Jul 31 06:17:31.820: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 31 06:17:31.820: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:17:31.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-t89kr" for this suite.
Jul 31 06:18:13.844: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:18:13.901: INFO: namespace: e2e-tests-kubectl-t89kr, resource: bindings, ignored listing per whitelist
Jul 31 06:18:13.914: INFO: namespace e2e-tests-kubectl-t89kr deletion completed in 42.089991678s

• [SLOW TEST:74.222 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:18:13.914: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jul 31 06:18:39.985: INFO: Container started at 2019-07-31 06:18:18 +0000 UTC, pod became ready at 2019-07-31 06:18:39 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:18:39.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-5vljj" for this suite.
Jul 31 06:19:01.996: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:19:02.036: INFO: namespace: e2e-tests-container-probe-5vljj, resource: bindings, ignored listing per whitelist
Jul 31 06:19:02.064: INFO: namespace e2e-tests-container-probe-5vljj deletion completed in 22.076109494s

• [SLOW TEST:48.150 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:19:02.064: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Jul 31 06:19:12.139: INFO: MetricsGrabber failed grab metrics. Skipping metrics gathering.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:19:12.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-gllpp" for this suite.
Jul 31 06:19:18.150: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:19:18.160: INFO: namespace: e2e-tests-gc-gllpp, resource: bindings, ignored listing per whitelist
Jul 31 06:19:18.217: INFO: namespace e2e-tests-gc-gllpp deletion completed in 6.075710406s

• [SLOW TEST:16.153 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:19:18.217: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-44qvx
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-44qvx
STEP: Deleting pre-stop pod
Jul 31 06:19:31.301: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:19:31.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-44qvx" for this suite.
Jul 31 06:20:09.316: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:20:09.356: INFO: namespace: e2e-tests-prestop-44qvx, resource: bindings, ignored listing per whitelist
Jul 31 06:20:09.386: INFO: namespace e2e-tests-prestop-44qvx deletion completed in 38.077984088s

• [SLOW TEST:51.169 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:20:09.386: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Jul 31 06:20:09.446: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jul 31 06:20:09.452: INFO: Waiting for terminating namespaces to be deleted...
Jul 31 06:20:09.454: INFO: 
Logging pods the kubelet thinks is on node shushsha-k8s-worker1 before test
Jul 31 06:20:09.460: INFO: kube-proxy-7z76l from kube-system started at 2019-07-31 06:05:42 +0000 UTC (1 container statuses recorded)
Jul 31 06:20:09.460: INFO: 	Container kube-proxy ready: true, restart count 0
Jul 31 06:20:09.460: INFO: kube-flannel-ds-9jt4h from kube-system started at 2019-07-31 06:05:43 +0000 UTC (1 container statuses recorded)
Jul 31 06:20:09.460: INFO: 	Container kube-flannel ready: true, restart count 0
Jul 31 06:20:09.460: INFO: sonobuoy from heptio-sonobuoy started at 2019-07-31 06:07:48 +0000 UTC (1 container statuses recorded)
Jul 31 06:20:09.460: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jul 31 06:20:09.460: INFO: sonobuoy-systemd-logs-daemon-set-e7f83d409c1d4c2e-fn8j6 from heptio-sonobuoy started at 2019-07-31 06:07:55 +0000 UTC (2 container statuses recorded)
Jul 31 06:20:09.460: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jul 31 06:20:09.460: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul 31 06:20:09.460: INFO: nginx-7cdbd8cdc9-gpjlv from default started at 2019-07-31 06:08:14 +0000 UTC (1 container statuses recorded)
Jul 31 06:20:09.460: INFO: 	Container nginx ready: true, restart count 0
Jul 31 06:20:09.460: INFO: 
Logging pods the kubelet thinks is on node shushsha-k8s-worker2 before test
Jul 31 06:20:09.466: INFO: kube-flannel-ds-flmdc from kube-system started at 2019-07-31 06:05:45 +0000 UTC (1 container statuses recorded)
Jul 31 06:20:09.466: INFO: 	Container kube-flannel ready: true, restart count 0
Jul 31 06:20:09.466: INFO: kube-proxy-2wjnv from kube-system started at 2019-07-31 06:05:45 +0000 UTC (1 container statuses recorded)
Jul 31 06:20:09.466: INFO: 	Container kube-proxy ready: true, restart count 0
Jul 31 06:20:09.466: INFO: sonobuoy-e2e-job-35084b16218148db from heptio-sonobuoy started at 2019-07-31 06:07:55 +0000 UTC (2 container statuses recorded)
Jul 31 06:20:09.466: INFO: 	Container e2e ready: true, restart count 0
Jul 31 06:20:09.466: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul 31 06:20:09.466: INFO: sonobuoy-systemd-logs-daemon-set-e7f83d409c1d4c2e-qgszv from heptio-sonobuoy started at 2019-07-31 06:07:55 +0000 UTC (2 container statuses recorded)
Jul 31 06:20:09.466: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jul 31 06:20:09.466: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-405e8c93-b35b-11e9-990e-fe448544ce72 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-405e8c93-b35b-11e9-990e-fe448544ce72 off the node shushsha-k8s-worker2
STEP: verifying the node doesn't have the label kubernetes.io/e2e-405e8c93-b35b-11e9-990e-fe448544ce72
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:20:13.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-cx5kz" for this suite.
Jul 31 06:20:25.522: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:20:25.553: INFO: namespace: e2e-tests-sched-pred-cx5kz, resource: bindings, ignored listing per whitelist
Jul 31 06:20:25.591: INFO: namespace e2e-tests-sched-pred-cx5kz deletion completed in 12.0757793s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:16.205 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:20:25.591: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-vb7c
STEP: Creating a pod to test atomic-volume-subpath
Jul 31 06:20:25.656: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-vb7c" in namespace "e2e-tests-subpath-sd6pw" to be "success or failure"
Jul 31 06:20:25.658: INFO: Pod "pod-subpath-test-secret-vb7c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.075897ms
Jul 31 06:20:27.661: INFO: Pod "pod-subpath-test-secret-vb7c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004739756s
Jul 31 06:20:29.664: INFO: Pod "pod-subpath-test-secret-vb7c": Phase="Running", Reason="", readiness=false. Elapsed: 4.00781857s
Jul 31 06:20:31.667: INFO: Pod "pod-subpath-test-secret-vb7c": Phase="Running", Reason="", readiness=false. Elapsed: 6.010990669s
Jul 31 06:20:33.670: INFO: Pod "pod-subpath-test-secret-vb7c": Phase="Running", Reason="", readiness=false. Elapsed: 8.014351504s
Jul 31 06:20:35.673: INFO: Pod "pod-subpath-test-secret-vb7c": Phase="Running", Reason="", readiness=false. Elapsed: 10.017238821s
Jul 31 06:20:37.676: INFO: Pod "pod-subpath-test-secret-vb7c": Phase="Running", Reason="", readiness=false. Elapsed: 12.020277684s
Jul 31 06:20:39.679: INFO: Pod "pod-subpath-test-secret-vb7c": Phase="Running", Reason="", readiness=false. Elapsed: 14.023635244s
Jul 31 06:20:41.682: INFO: Pod "pod-subpath-test-secret-vb7c": Phase="Running", Reason="", readiness=false. Elapsed: 16.02664305s
Jul 31 06:20:43.685: INFO: Pod "pod-subpath-test-secret-vb7c": Phase="Running", Reason="", readiness=false. Elapsed: 18.029505761s
Jul 31 06:20:45.688: INFO: Pod "pod-subpath-test-secret-vb7c": Phase="Running", Reason="", readiness=false. Elapsed: 20.032387883s
Jul 31 06:20:47.691: INFO: Pod "pod-subpath-test-secret-vb7c": Phase="Running", Reason="", readiness=false. Elapsed: 22.035467973s
Jul 31 06:20:49.695: INFO: Pod "pod-subpath-test-secret-vb7c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.038842873s
STEP: Saw pod success
Jul 31 06:20:49.695: INFO: Pod "pod-subpath-test-secret-vb7c" satisfied condition "success or failure"
Jul 31 06:20:49.697: INFO: Trying to get logs from node shushsha-k8s-worker1 pod pod-subpath-test-secret-vb7c container test-container-subpath-secret-vb7c: <nil>
STEP: delete the pod
Jul 31 06:20:49.712: INFO: Waiting for pod pod-subpath-test-secret-vb7c to disappear
Jul 31 06:20:49.714: INFO: Pod pod-subpath-test-secret-vb7c no longer exists
STEP: Deleting pod pod-subpath-test-secret-vb7c
Jul 31 06:20:49.714: INFO: Deleting pod "pod-subpath-test-secret-vb7c" in namespace "e2e-tests-subpath-sd6pw"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:20:49.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-sd6pw" for this suite.
Jul 31 06:20:55.726: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:20:55.769: INFO: namespace: e2e-tests-subpath-sd6pw, resource: bindings, ignored listing per whitelist
Jul 31 06:20:55.799: INFO: namespace e2e-tests-subpath-sd6pw deletion completed in 6.080512738s

• [SLOW TEST:30.208 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:20:55.800: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-xk492/configmap-test-5ad283fd-b35b-11e9-990e-fe448544ce72
STEP: Creating a pod to test consume configMaps
Jul 31 06:20:55.871: INFO: Waiting up to 5m0s for pod "pod-configmaps-5ad2dffb-b35b-11e9-990e-fe448544ce72" in namespace "e2e-tests-configmap-xk492" to be "success or failure"
Jul 31 06:20:55.873: INFO: Pod "pod-configmaps-5ad2dffb-b35b-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.118364ms
Jul 31 06:20:57.876: INFO: Pod "pod-configmaps-5ad2dffb-b35b-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005223566s
Jul 31 06:20:59.879: INFO: Pod "pod-configmaps-5ad2dffb-b35b-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008196447s
Jul 31 06:21:01.882: INFO: Pod "pod-configmaps-5ad2dffb-b35b-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 6.011029031s
Jul 31 06:21:03.885: INFO: Pod "pod-configmaps-5ad2dffb-b35b-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.014276932s
STEP: Saw pod success
Jul 31 06:21:03.886: INFO: Pod "pod-configmaps-5ad2dffb-b35b-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 06:21:03.888: INFO: Trying to get logs from node shushsha-k8s-worker2 pod pod-configmaps-5ad2dffb-b35b-11e9-990e-fe448544ce72 container env-test: <nil>
STEP: delete the pod
Jul 31 06:21:03.902: INFO: Waiting for pod pod-configmaps-5ad2dffb-b35b-11e9-990e-fe448544ce72 to disappear
Jul 31 06:21:03.905: INFO: Pod pod-configmaps-5ad2dffb-b35b-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:21:03.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-xk492" for this suite.
Jul 31 06:21:09.918: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:21:09.952: INFO: namespace: e2e-tests-configmap-xk492, resource: bindings, ignored listing per whitelist
Jul 31 06:21:09.991: INFO: namespace e2e-tests-configmap-xk492 deletion completed in 6.083121828s

• [SLOW TEST:14.192 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:21:09.991: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jul 31 06:21:10.053: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6346bee2-b35b-11e9-990e-fe448544ce72" in namespace "e2e-tests-downward-api-nmvds" to be "success or failure"
Jul 31 06:21:10.057: INFO: Pod "downwardapi-volume-6346bee2-b35b-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 3.493292ms
Jul 31 06:21:12.060: INFO: Pod "downwardapi-volume-6346bee2-b35b-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007151592s
STEP: Saw pod success
Jul 31 06:21:12.060: INFO: Pod "downwardapi-volume-6346bee2-b35b-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 06:21:12.063: INFO: Trying to get logs from node shushsha-k8s-worker1 pod downwardapi-volume-6346bee2-b35b-11e9-990e-fe448544ce72 container client-container: <nil>
STEP: delete the pod
Jul 31 06:21:12.078: INFO: Waiting for pod downwardapi-volume-6346bee2-b35b-11e9-990e-fe448544ce72 to disappear
Jul 31 06:21:12.080: INFO: Pod downwardapi-volume-6346bee2-b35b-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:21:12.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-nmvds" for this suite.
Jul 31 06:21:18.092: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:21:18.132: INFO: namespace: e2e-tests-downward-api-nmvds, resource: bindings, ignored listing per whitelist
Jul 31 06:21:18.165: INFO: namespace e2e-tests-downward-api-nmvds deletion completed in 6.082397995s

• [SLOW TEST:8.174 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:21:18.165: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Jul 31 06:21:43.251: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:21:44.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-cpxz7" for this suite.
Jul 31 06:22:06.274: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:22:06.314: INFO: namespace: e2e-tests-replicaset-cpxz7, resource: bindings, ignored listing per whitelist
Jul 31 06:22:06.344: INFO: namespace e2e-tests-replicaset-cpxz7 deletion completed in 22.077598477s

• [SLOW TEST:48.178 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:22:06.344: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jul 31 06:22:06.403: INFO: Waiting up to 5m0s for pod "downwardapi-volume-84dd3862-b35b-11e9-990e-fe448544ce72" in namespace "e2e-tests-projected-t2scx" to be "success or failure"
Jul 31 06:22:06.406: INFO: Pod "downwardapi-volume-84dd3862-b35b-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.266288ms
Jul 31 06:22:08.409: INFO: Pod "downwardapi-volume-84dd3862-b35b-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005510573s
STEP: Saw pod success
Jul 31 06:22:08.409: INFO: Pod "downwardapi-volume-84dd3862-b35b-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 06:22:08.411: INFO: Trying to get logs from node shushsha-k8s-worker2 pod downwardapi-volume-84dd3862-b35b-11e9-990e-fe448544ce72 container client-container: <nil>
STEP: delete the pod
Jul 31 06:22:08.425: INFO: Waiting for pod downwardapi-volume-84dd3862-b35b-11e9-990e-fe448544ce72 to disappear
Jul 31 06:22:08.427: INFO: Pod downwardapi-volume-84dd3862-b35b-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:22:08.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-t2scx" for this suite.
Jul 31 06:22:14.438: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:22:14.504: INFO: namespace: e2e-tests-projected-t2scx, resource: bindings, ignored listing per whitelist
Jul 31 06:22:14.504: INFO: namespace e2e-tests-projected-t2scx deletion completed in 6.074222921s

• [SLOW TEST:8.160 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:22:14.504: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jul 31 06:22:14.560: INFO: Waiting up to 5m0s for pod "downward-api-89b9cd9a-b35b-11e9-990e-fe448544ce72" in namespace "e2e-tests-downward-api-wbhch" to be "success or failure"
Jul 31 06:22:14.563: INFO: Pod "downward-api-89b9cd9a-b35b-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.315265ms
Jul 31 06:22:16.566: INFO: Pod "downward-api-89b9cd9a-b35b-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005224184s
Jul 31 06:22:18.569: INFO: Pod "downward-api-89b9cd9a-b35b-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008524862s
STEP: Saw pod success
Jul 31 06:22:18.569: INFO: Pod "downward-api-89b9cd9a-b35b-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 06:22:18.571: INFO: Trying to get logs from node shushsha-k8s-worker1 pod downward-api-89b9cd9a-b35b-11e9-990e-fe448544ce72 container dapi-container: <nil>
STEP: delete the pod
Jul 31 06:22:18.583: INFO: Waiting for pod downward-api-89b9cd9a-b35b-11e9-990e-fe448544ce72 to disappear
Jul 31 06:22:18.585: INFO: Pod downward-api-89b9cd9a-b35b-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:22:18.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-wbhch" for this suite.
Jul 31 06:22:24.595: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:22:24.658: INFO: namespace: e2e-tests-downward-api-wbhch, resource: bindings, ignored listing per whitelist
Jul 31 06:22:24.662: INFO: namespace e2e-tests-downward-api-wbhch deletion completed in 6.074138172s

• [SLOW TEST:10.158 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:22:24.662: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-8fc7f16c-b35b-11e9-990e-fe448544ce72
STEP: Creating a pod to test consume configMaps
Jul 31 06:22:24.721: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8fc84a77-b35b-11e9-990e-fe448544ce72" in namespace "e2e-tests-projected-k44nm" to be "success or failure"
Jul 31 06:22:24.724: INFO: Pod "pod-projected-configmaps-8fc84a77-b35b-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.265709ms
Jul 31 06:22:26.727: INFO: Pod "pod-projected-configmaps-8fc84a77-b35b-11e9-990e-fe448544ce72": Phase="Running", Reason="", readiness=true. Elapsed: 2.005497487s
Jul 31 06:22:28.730: INFO: Pod "pod-projected-configmaps-8fc84a77-b35b-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008997567s
STEP: Saw pod success
Jul 31 06:22:28.730: INFO: Pod "pod-projected-configmaps-8fc84a77-b35b-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 06:22:28.733: INFO: Trying to get logs from node shushsha-k8s-worker2 pod pod-projected-configmaps-8fc84a77-b35b-11e9-990e-fe448544ce72 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jul 31 06:22:28.750: INFO: Waiting for pod pod-projected-configmaps-8fc84a77-b35b-11e9-990e-fe448544ce72 to disappear
Jul 31 06:22:28.753: INFO: Pod pod-projected-configmaps-8fc84a77-b35b-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:22:28.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-k44nm" for this suite.
Jul 31 06:22:34.768: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:22:34.807: INFO: namespace: e2e-tests-projected-k44nm, resource: bindings, ignored listing per whitelist
Jul 31 06:22:34.837: INFO: namespace e2e-tests-projected-k44nm deletion completed in 6.08066054s

• [SLOW TEST:10.175 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:22:34.838: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jul 31 06:22:39.413: INFO: Successfully updated pod "pod-update-95d8eecf-b35b-11e9-990e-fe448544ce72"
STEP: verifying the updated pod is in kubernetes
Jul 31 06:22:39.417: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:22:39.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-hr6mt" for this suite.
Jul 31 06:23:01.428: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:23:01.447: INFO: namespace: e2e-tests-pods-hr6mt, resource: bindings, ignored listing per whitelist
Jul 31 06:23:01.499: INFO: namespace e2e-tests-pods-hr6mt deletion completed in 22.078657311s

• [SLOW TEST:26.661 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:23:01.499: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Jul 31 06:23:01.561: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-864115849 proxy --unix-socket=/tmp/kubectl-proxy-unix849703508/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:23:01.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-m49b4" for this suite.
Jul 31 06:23:07.635: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:23:07.662: INFO: namespace: e2e-tests-kubectl-m49b4, resource: bindings, ignored listing per whitelist
Jul 31 06:23:07.705: INFO: namespace e2e-tests-kubectl-m49b4 deletion completed in 6.077690903s

• [SLOW TEST:6.206 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:23:07.706: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Jul 31 06:23:09.769: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-a96f7d6b-b35b-11e9-990e-fe448544ce72,GenerateName:,Namespace:e2e-tests-events-kmf55,SelfLink:/api/v1/namespaces/e2e-tests-events-kmf55/pods/send-events-a96f7d6b-b35b-11e9-990e-fe448544ce72,UID:a96fdd48-b35b-11e9-ac6f-000017003e78,ResourceVersion:3660,Generation:0,CreationTimestamp:2019-07-31 06:23:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 756281595,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-gmffq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-gmffq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-gmffq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shushsha-k8s-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c49dd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c49df0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:23:07 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:23:09 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:23:09 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:23:07 +0000 UTC  }],Message:,Reason:,HostIP:100.100.230.39,PodIP:10.244.2.25,StartTime:2019-07-31 06:23:07 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-07-31 06:23:08 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://9088edbe097b8c9124338bfadaea1407417bf24613fed97bed87bf02aad37967}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Jul 31 06:23:11.773: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Jul 31 06:23:13.777: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:23:13.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-kmf55" for this suite.
Jul 31 06:23:55.791: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:23:55.828: INFO: namespace: e2e-tests-events-kmf55, resource: bindings, ignored listing per whitelist
Jul 31 06:23:55.862: INFO: namespace e2e-tests-events-kmf55 deletion completed in 42.078549579s

• [SLOW TEST:48.156 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:23:55.862: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jul 31 06:23:55.930: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c62535b6-b35b-11e9-990e-fe448544ce72" in namespace "e2e-tests-projected-btrxz" to be "success or failure"
Jul 31 06:23:55.932: INFO: Pod "downwardapi-volume-c62535b6-b35b-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.568948ms
Jul 31 06:23:57.935: INFO: Pod "downwardapi-volume-c62535b6-b35b-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005488948s
STEP: Saw pod success
Jul 31 06:23:57.935: INFO: Pod "downwardapi-volume-c62535b6-b35b-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 06:23:57.937: INFO: Trying to get logs from node shushsha-k8s-worker1 pod downwardapi-volume-c62535b6-b35b-11e9-990e-fe448544ce72 container client-container: <nil>
STEP: delete the pod
Jul 31 06:23:57.956: INFO: Waiting for pod downwardapi-volume-c62535b6-b35b-11e9-990e-fe448544ce72 to disappear
Jul 31 06:23:57.958: INFO: Pod downwardapi-volume-c62535b6-b35b-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:23:57.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-btrxz" for this suite.
Jul 31 06:24:03.968: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:24:04.035: INFO: namespace: e2e-tests-projected-btrxz, resource: bindings, ignored listing per whitelist
Jul 31 06:24:04.041: INFO: namespace e2e-tests-projected-btrxz deletion completed in 6.080673792s

• [SLOW TEST:8.178 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:24:04.041: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-75g4
STEP: Creating a pod to test atomic-volume-subpath
Jul 31 06:24:04.101: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-75g4" in namespace "e2e-tests-subpath-x8kk6" to be "success or failure"
Jul 31 06:24:04.105: INFO: Pod "pod-subpath-test-configmap-75g4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009294ms
Jul 31 06:24:06.108: INFO: Pod "pod-subpath-test-configmap-75g4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006569278s
Jul 31 06:24:08.110: INFO: Pod "pod-subpath-test-configmap-75g4": Phase="Running", Reason="", readiness=false. Elapsed: 4.00927611s
Jul 31 06:24:10.113: INFO: Pod "pod-subpath-test-configmap-75g4": Phase="Running", Reason="", readiness=false. Elapsed: 6.01191455s
Jul 31 06:24:12.116: INFO: Pod "pod-subpath-test-configmap-75g4": Phase="Running", Reason="", readiness=false. Elapsed: 8.014630582s
Jul 31 06:24:14.118: INFO: Pod "pod-subpath-test-configmap-75g4": Phase="Running", Reason="", readiness=false. Elapsed: 10.017296884s
Jul 31 06:24:16.121: INFO: Pod "pod-subpath-test-configmap-75g4": Phase="Running", Reason="", readiness=false. Elapsed: 12.019798499s
Jul 31 06:24:18.123: INFO: Pod "pod-subpath-test-configmap-75g4": Phase="Running", Reason="", readiness=false. Elapsed: 14.022395004s
Jul 31 06:24:20.126: INFO: Pod "pod-subpath-test-configmap-75g4": Phase="Running", Reason="", readiness=false. Elapsed: 16.025183248s
Jul 31 06:24:22.129: INFO: Pod "pod-subpath-test-configmap-75g4": Phase="Running", Reason="", readiness=false. Elapsed: 18.027727867s
Jul 31 06:24:24.131: INFO: Pod "pod-subpath-test-configmap-75g4": Phase="Running", Reason="", readiness=false. Elapsed: 20.030344177s
Jul 31 06:24:26.137: INFO: Pod "pod-subpath-test-configmap-75g4": Phase="Running", Reason="", readiness=false. Elapsed: 22.035609359s
Jul 31 06:24:28.139: INFO: Pod "pod-subpath-test-configmap-75g4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.038350954s
STEP: Saw pod success
Jul 31 06:24:28.139: INFO: Pod "pod-subpath-test-configmap-75g4" satisfied condition "success or failure"
Jul 31 06:24:28.141: INFO: Trying to get logs from node shushsha-k8s-worker2 pod pod-subpath-test-configmap-75g4 container test-container-subpath-configmap-75g4: <nil>
STEP: delete the pod
Jul 31 06:24:28.156: INFO: Waiting for pod pod-subpath-test-configmap-75g4 to disappear
Jul 31 06:24:28.158: INFO: Pod pod-subpath-test-configmap-75g4 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-75g4
Jul 31 06:24:28.158: INFO: Deleting pod "pod-subpath-test-configmap-75g4" in namespace "e2e-tests-subpath-x8kk6"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:24:28.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-x8kk6" for this suite.
Jul 31 06:24:34.171: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:24:34.232: INFO: namespace: e2e-tests-subpath-x8kk6, resource: bindings, ignored listing per whitelist
Jul 31 06:24:34.238: INFO: namespace e2e-tests-subpath-x8kk6 deletion completed in 6.075070523s

• [SLOW TEST:30.197 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:24:34.238: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:24:34.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-ltx9b" for this suite.
Jul 31 06:24:40.307: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:24:40.339: INFO: namespace: e2e-tests-services-ltx9b, resource: bindings, ignored listing per whitelist
Jul 31 06:24:40.375: INFO: namespace e2e-tests-services-ltx9b deletion completed in 6.075280139s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:6.137 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:24:40.375: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jul 31 06:24:40.424: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Jul 31 06:24:40.430: INFO: Pod name sample-pod: Found 0 pods out of 1
Jul 31 06:24:45.433: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jul 31 06:24:45.433: INFO: Creating deployment "test-rolling-update-deployment"
Jul 31 06:24:45.437: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Jul 31 06:24:45.441: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Jul 31 06:24:47.447: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Jul 31 06:24:47.449: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700151085, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700151085, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700151085, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700151085, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-68b55d7bc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 31 06:24:49.452: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jul 31 06:24:49.459: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-grs4f,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-grs4f/deployments/test-rolling-update-deployment,UID:e3a80c14-b35b-11e9-ac6f-000017003e78,ResourceVersion:3930,Generation:1,CreationTimestamp:2019-07-31 06:24:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-07-31 06:24:45 +0000 UTC 2019-07-31 06:24:45 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-07-31 06:24:47 +0000 UTC 2019-07-31 06:24:45 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-68b55d7bc6" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Jul 31 06:24:49.462: INFO: New ReplicaSet "test-rolling-update-deployment-68b55d7bc6" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6,GenerateName:,Namespace:e2e-tests-deployment-grs4f,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-grs4f/replicasets/test-rolling-update-deployment-68b55d7bc6,UID:e3aa3390-b35b-11e9-ac6f-000017003e78,ResourceVersion:3921,Generation:1,CreationTimestamp:2019-07-31 06:24:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment e3a80c14-b35b-11e9-ac6f-000017003e78 0xc0021919f7 0xc0021919f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jul 31 06:24:49.462: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Jul 31 06:24:49.462: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-grs4f,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-grs4f/replicasets/test-rolling-update-controller,UID:e0abbbdb-b35b-11e9-ac6f-000017003e78,ResourceVersion:3929,Generation:2,CreationTimestamp:2019-07-31 06:24:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment e3a80c14-b35b-11e9-ac6f-000017003e78 0xc00219190f 0xc002191920}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jul 31 06:24:49.464: INFO: Pod "test-rolling-update-deployment-68b55d7bc6-gc575" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6-gc575,GenerateName:test-rolling-update-deployment-68b55d7bc6-,Namespace:e2e-tests-deployment-grs4f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-grs4f/pods/test-rolling-update-deployment-68b55d7bc6-gc575,UID:e3aa9edd-b35b-11e9-ac6f-000017003e78,ResourceVersion:3920,Generation:0,CreationTimestamp:2019-07-31 06:24:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-68b55d7bc6 e3aa3390-b35b-11e9-ac6f-000017003e78 0xc001fec487 0xc001fec488}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-g7nrf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-g7nrf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-g7nrf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shushsha-k8s-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001fec4f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001fec510}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:24:45 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:24:47 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:24:47 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:24:45 +0000 UTC  }],Message:,Reason:,HostIP:100.100.230.39,PodIP:10.244.2.27,StartTime:2019-07-31 06:24:45 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-07-31 06:24:46 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://1fa9231fb683e9e10dd304353395bd5df7eaac08a23d6b3c3bb4a19fccb2bf03}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:24:49.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-grs4f" for this suite.
Jul 31 06:24:55.475: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:24:55.515: INFO: namespace: e2e-tests-deployment-grs4f, resource: bindings, ignored listing per whitelist
Jul 31 06:24:55.544: INFO: namespace e2e-tests-deployment-grs4f deletion completed in 6.077226299s

• [SLOW TEST:15.169 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:24:55.545: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Jul 31 06:24:55.603: INFO: Waiting up to 5m0s for pod "pod-e9b71302-b35b-11e9-990e-fe448544ce72" in namespace "e2e-tests-emptydir-c5vlc" to be "success or failure"
Jul 31 06:24:55.605: INFO: Pod "pod-e9b71302-b35b-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 1.987925ms
Jul 31 06:24:57.608: INFO: Pod "pod-e9b71302-b35b-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005070914s
Jul 31 06:24:59.611: INFO: Pod "pod-e9b71302-b35b-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 4.00744764s
Jul 31 06:25:01.614: INFO: Pod "pod-e9b71302-b35b-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.010623746s
STEP: Saw pod success
Jul 31 06:25:01.614: INFO: Pod "pod-e9b71302-b35b-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 06:25:01.616: INFO: Trying to get logs from node shushsha-k8s-worker1 pod pod-e9b71302-b35b-11e9-990e-fe448544ce72 container test-container: <nil>
STEP: delete the pod
Jul 31 06:25:01.629: INFO: Waiting for pod pod-e9b71302-b35b-11e9-990e-fe448544ce72 to disappear
Jul 31 06:25:01.631: INFO: Pod pod-e9b71302-b35b-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:25:01.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-c5vlc" for this suite.
Jul 31 06:25:07.642: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:25:07.690: INFO: namespace: e2e-tests-emptydir-c5vlc, resource: bindings, ignored listing per whitelist
Jul 31 06:25:07.711: INFO: namespace e2e-tests-emptydir-c5vlc deletion completed in 6.077349838s

• [SLOW TEST:12.167 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:25:07.711: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Jul 31 06:25:07.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 cluster-info'
Jul 31 06:25:07.952: INFO: stderr: ""
Jul 31 06:25:07.952: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:25:07.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-pjpf7" for this suite.
Jul 31 06:25:13.963: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:25:13.982: INFO: namespace: e2e-tests-kubectl-pjpf7, resource: bindings, ignored listing per whitelist
Jul 31 06:25:14.030: INFO: namespace e2e-tests-kubectl-pjpf7 deletion completed in 6.074716054s

• [SLOW TEST:6.319 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:25:14.031: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jul 31 06:25:14.087: INFO: Waiting up to 5m0s for pod "pod-f4bb5f79-b35b-11e9-990e-fe448544ce72" in namespace "e2e-tests-emptydir-7kcqj" to be "success or failure"
Jul 31 06:25:14.090: INFO: Pod "pod-f4bb5f79-b35b-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.346262ms
Jul 31 06:25:16.092: INFO: Pod "pod-f4bb5f79-b35b-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004636341s
STEP: Saw pod success
Jul 31 06:25:16.092: INFO: Pod "pod-f4bb5f79-b35b-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 06:25:16.094: INFO: Trying to get logs from node shushsha-k8s-worker2 pod pod-f4bb5f79-b35b-11e9-990e-fe448544ce72 container test-container: <nil>
STEP: delete the pod
Jul 31 06:25:16.110: INFO: Waiting for pod pod-f4bb5f79-b35b-11e9-990e-fe448544ce72 to disappear
Jul 31 06:25:16.113: INFO: Pod pod-f4bb5f79-b35b-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:25:16.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-7kcqj" for this suite.
Jul 31 06:25:22.123: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:25:22.176: INFO: namespace: e2e-tests-emptydir-7kcqj, resource: bindings, ignored listing per whitelist
Jul 31 06:25:22.191: INFO: namespace e2e-tests-emptydir-7kcqj deletion completed in 6.074994964s

• [SLOW TEST:8.160 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:25:22.191: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jul 31 06:25:22.245: INFO: Creating deployment "nginx-deployment"
Jul 31 06:25:22.247: INFO: Waiting for observed generation 1
Jul 31 06:25:24.252: INFO: Waiting for all required pods to come up
Jul 31 06:25:24.256: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Jul 31 06:25:28.264: INFO: Waiting for deployment "nginx-deployment" to complete
Jul 31 06:25:28.268: INFO: Updating deployment "nginx-deployment" with a non-existent image
Jul 31 06:25:28.273: INFO: Updating deployment nginx-deployment
Jul 31 06:25:28.273: INFO: Waiting for observed generation 2
Jul 31 06:25:30.280: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Jul 31 06:25:30.283: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Jul 31 06:25:30.284: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Jul 31 06:25:30.291: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Jul 31 06:25:30.291: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Jul 31 06:25:30.293: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Jul 31 06:25:30.297: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Jul 31 06:25:30.297: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Jul 31 06:25:30.302: INFO: Updating deployment nginx-deployment
Jul 31 06:25:30.302: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Jul 31 06:25:30.312: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Jul 31 06:25:30.323: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jul 31 06:25:32.345: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-lhg48,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-lhg48/deployments/nginx-deployment,UID:f998f8dc-b35b-11e9-ac6f-000017003e78,ResourceVersion:4330,Generation:3,CreationTimestamp:2019-07-31 06:25:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-07-31 06:25:30 +0000 UTC 2019-07-31 06:25:30 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-07-31 06:25:30 +0000 UTC 2019-07-31 06:25:22 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-65bbdb5f8" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Jul 31 06:25:32.348: INFO: New ReplicaSet "nginx-deployment-65bbdb5f8" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8,GenerateName:,Namespace:e2e-tests-deployment-lhg48,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-lhg48/replicasets/nginx-deployment-65bbdb5f8,UID:fd30d1ce-b35b-11e9-ac6f-000017003e78,ResourceVersion:4323,Generation:3,CreationTimestamp:2019-07-31 06:25:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment f998f8dc-b35b-11e9-ac6f-000017003e78 0xc002000c77 0xc002000c78}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jul 31 06:25:32.348: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Jul 31 06:25:32.348: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965,GenerateName:,Namespace:e2e-tests-deployment-lhg48,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-lhg48/replicasets/nginx-deployment-555b55d965,UID:f99a01c6-b35b-11e9-ac6f-000017003e78,ResourceVersion:4321,Generation:3,CreationTimestamp:2019-07-31 06:25:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment f998f8dc-b35b-11e9-ac6f-000017003e78 0xc002000bb7 0xc002000bb8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Jul 31 06:25:32.353: INFO: Pod "nginx-deployment-555b55d965-2j2kt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-2j2kt,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-lhg48,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lhg48/pods/nginx-deployment-555b55d965-2j2kt,UID:fe6d3b2c-b35b-11e9-ac6f-000017003e78,ResourceVersion:4307,Generation:0,CreationTimestamp:2019-07-31 06:25:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f99a01c6-b35b-11e9-ac6f-000017003e78 0xc0020015e0 0xc0020015e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9s8gr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9s8gr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9s8gr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shushsha-k8s-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002001640} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002001660}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 06:25:32.353: INFO: Pod "nginx-deployment-555b55d965-4b2s8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-4b2s8,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-lhg48,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lhg48/pods/nginx-deployment-555b55d965-4b2s8,UID:fe671256-b35b-11e9-ac6f-000017003e78,ResourceVersion:4285,Generation:0,CreationTimestamp:2019-07-31 06:25:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f99a01c6-b35b-11e9-ac6f-000017003e78 0xc0020016e0 0xc0020016e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9s8gr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9s8gr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9s8gr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shushsha-k8s-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002001740} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002001760}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC  }],Message:,Reason:,HostIP:100.100.230.39,PodIP:,StartTime:2019-07-31 06:25:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 06:25:32.353: INFO: Pod "nginx-deployment-555b55d965-4vvkx" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-4vvkx,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-lhg48,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lhg48/pods/nginx-deployment-555b55d965-4vvkx,UID:f9a3c88b-b35b-11e9-ac6f-000017003e78,ResourceVersion:4171,Generation:0,CreationTimestamp:2019-07-31 06:25:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f99a01c6-b35b-11e9-ac6f-000017003e78 0xc002001817 0xc002001818}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9s8gr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9s8gr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9s8gr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shushsha-k8s-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002001880} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020018a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:24 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:24 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:22 +0000 UTC  }],Message:,Reason:,HostIP:100.100.230.39,PodIP:10.244.2.30,StartTime:2019-07-31 06:25:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-07-31 06:25:23 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://8faf695039b4bdbd405a63145d99d347951ebffe6a689ac9e3f40d0b38101e6e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 06:25:32.354: INFO: Pod "nginx-deployment-555b55d965-6v5ch" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-6v5ch,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-lhg48,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lhg48/pods/nginx-deployment-555b55d965-6v5ch,UID:f9a3fea8-b35b-11e9-ac6f-000017003e78,ResourceVersion:4158,Generation:0,CreationTimestamp:2019-07-31 06:25:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f99a01c6-b35b-11e9-ac6f-000017003e78 0xc002001960 0xc002001961}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9s8gr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9s8gr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9s8gr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shushsha-k8s-worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020019c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020019e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:24 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:24 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:22 +0000 UTC  }],Message:,Reason:,HostIP:100.100.230.30,PodIP:10.244.1.30,StartTime:2019-07-31 06:25:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-07-31 06:25:23 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://9527d28ff74c5f9e1afc560639d6772db8adfcee3957eb241510956f68ebe826}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 06:25:32.354: INFO: Pod "nginx-deployment-555b55d965-8p656" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-8p656,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-lhg48,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lhg48/pods/nginx-deployment-555b55d965-8p656,UID:fe6d50a0-b35b-11e9-ac6f-000017003e78,ResourceVersion:4306,Generation:0,CreationTimestamp:2019-07-31 06:25:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f99a01c6-b35b-11e9-ac6f-000017003e78 0xc002001aa0 0xc002001aa1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9s8gr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9s8gr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9s8gr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shushsha-k8s-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002001b10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002001b30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 06:25:32.354: INFO: Pod "nginx-deployment-555b55d965-8z5t4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-8z5t4,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-lhg48,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lhg48/pods/nginx-deployment-555b55d965-8z5t4,UID:fe6d1b59-b35b-11e9-ac6f-000017003e78,ResourceVersion:4368,Generation:0,CreationTimestamp:2019-07-31 06:25:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f99a01c6-b35b-11e9-ac6f-000017003e78 0xc002001ba0 0xc002001ba1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9s8gr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9s8gr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9s8gr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shushsha-k8s-worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002001c00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002001c20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC  }],Message:,Reason:,HostIP:100.100.230.30,PodIP:,StartTime:2019-07-31 06:25:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 06:25:32.354: INFO: Pod "nginx-deployment-555b55d965-9dhh9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-9dhh9,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-lhg48,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lhg48/pods/nginx-deployment-555b55d965-9dhh9,UID:fe6a011d-b35b-11e9-ac6f-000017003e78,ResourceVersion:4349,Generation:0,CreationTimestamp:2019-07-31 06:25:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f99a01c6-b35b-11e9-ac6f-000017003e78 0xc002001ce7 0xc002001ce8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9s8gr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9s8gr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9s8gr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shushsha-k8s-worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002001d50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002001d70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC  }],Message:,Reason:,HostIP:100.100.230.30,PodIP:,StartTime:2019-07-31 06:25:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 06:25:32.355: INFO: Pod "nginx-deployment-555b55d965-g97g9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-g97g9,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-lhg48,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lhg48/pods/nginx-deployment-555b55d965-g97g9,UID:f9a1dfd0-b35b-11e9-ac6f-000017003e78,ResourceVersion:4168,Generation:0,CreationTimestamp:2019-07-31 06:25:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f99a01c6-b35b-11e9-ac6f-000017003e78 0xc002001e37 0xc002001e38}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9s8gr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9s8gr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9s8gr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shushsha-k8s-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002001ea0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002001ec0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:24 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:24 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:22 +0000 UTC  }],Message:,Reason:,HostIP:100.100.230.39,PodIP:10.244.2.29,StartTime:2019-07-31 06:25:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-07-31 06:25:23 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://d7e8b8015396889926e0434647925cd525d34ab7cdbd7da33de8c57987a9d5a3}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 06:25:32.355: INFO: Pod "nginx-deployment-555b55d965-h6r68" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-h6r68,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-lhg48,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lhg48/pods/nginx-deployment-555b55d965-h6r68,UID:fe6d4a83-b35b-11e9-ac6f-000017003e78,ResourceVersion:4310,Generation:0,CreationTimestamp:2019-07-31 06:25:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f99a01c6-b35b-11e9-ac6f-000017003e78 0xc002001f80 0xc002001f81}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9s8gr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9s8gr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9s8gr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shushsha-k8s-worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002001ff0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00207a050}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 06:25:32.355: INFO: Pod "nginx-deployment-555b55d965-kcn5h" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-kcn5h,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-lhg48,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lhg48/pods/nginx-deployment-555b55d965-kcn5h,UID:f9a052d2-b35b-11e9-ac6f-000017003e78,ResourceVersion:4174,Generation:0,CreationTimestamp:2019-07-31 06:25:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f99a01c6-b35b-11e9-ac6f-000017003e78 0xc00207a0c0 0xc00207a0c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9s8gr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9s8gr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9s8gr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shushsha-k8s-worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00207a120} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00207a140}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:24 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:24 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:22 +0000 UTC  }],Message:,Reason:,HostIP:100.100.230.30,PodIP:10.244.1.29,StartTime:2019-07-31 06:25:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-07-31 06:25:23 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://d64fb987d61cb71527212b3c1061706225c2cba3d9cce57b0383333063aa7981}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 06:25:32.355: INFO: Pod "nginx-deployment-555b55d965-mh4lc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-mh4lc,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-lhg48,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lhg48/pods/nginx-deployment-555b55d965-mh4lc,UID:fe6d45c2-b35b-11e9-ac6f-000017003e78,ResourceVersion:4374,Generation:0,CreationTimestamp:2019-07-31 06:25:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f99a01c6-b35b-11e9-ac6f-000017003e78 0xc00207a230 0xc00207a231}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9s8gr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9s8gr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9s8gr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shushsha-k8s-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00207a290} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00207a2b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC  }],Message:,Reason:,HostIP:100.100.230.39,PodIP:,StartTime:2019-07-31 06:25:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 06:25:32.356: INFO: Pod "nginx-deployment-555b55d965-n5l4l" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-n5l4l,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-lhg48,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lhg48/pods/nginx-deployment-555b55d965-n5l4l,UID:fe69fd13-b35b-11e9-ac6f-000017003e78,ResourceVersion:4337,Generation:0,CreationTimestamp:2019-07-31 06:25:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f99a01c6-b35b-11e9-ac6f-000017003e78 0xc00207a367 0xc00207a368}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9s8gr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9s8gr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9s8gr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shushsha-k8s-worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00207a440} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00207a460}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC  }],Message:,Reason:,HostIP:100.100.230.30,PodIP:,StartTime:2019-07-31 06:25:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 06:25:32.356: INFO: Pod "nginx-deployment-555b55d965-n6f2v" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-n6f2v,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-lhg48,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lhg48/pods/nginx-deployment-555b55d965-n6f2v,UID:f9a60d12-b35b-11e9-ac6f-000017003e78,ResourceVersion:4155,Generation:0,CreationTimestamp:2019-07-31 06:25:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f99a01c6-b35b-11e9-ac6f-000017003e78 0xc00207a517 0xc00207a518}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9s8gr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9s8gr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9s8gr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shushsha-k8s-worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00207a580} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00207a5a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:24 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:24 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:22 +0000 UTC  }],Message:,Reason:,HostIP:100.100.230.30,PodIP:10.244.1.31,StartTime:2019-07-31 06:25:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-07-31 06:25:23 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://434d94a00f030c31ef83745346e8b0aa2e9aa1821caced0620b48ad7a88bb248}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 06:25:32.356: INFO: Pod "nginx-deployment-555b55d965-pfz87" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-pfz87,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-lhg48,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lhg48/pods/nginx-deployment-555b55d965-pfz87,UID:fe69ff24-b35b-11e9-ac6f-000017003e78,ResourceVersion:4354,Generation:0,CreationTimestamp:2019-07-31 06:25:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f99a01c6-b35b-11e9-ac6f-000017003e78 0xc00207a710 0xc00207a711}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9s8gr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9s8gr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9s8gr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shushsha-k8s-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00207a770} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00207a790}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC  }],Message:,Reason:,HostIP:100.100.230.39,PodIP:,StartTime:2019-07-31 06:25:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 06:25:32.356: INFO: Pod "nginx-deployment-555b55d965-ph965" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-ph965,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-lhg48,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lhg48/pods/nginx-deployment-555b55d965-ph965,UID:fe6a08c0-b35b-11e9-ac6f-000017003e78,ResourceVersion:4319,Generation:0,CreationTimestamp:2019-07-31 06:25:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f99a01c6-b35b-11e9-ac6f-000017003e78 0xc00207a847 0xc00207a848}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9s8gr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9s8gr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9s8gr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shushsha-k8s-worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00207a9f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00207aa10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC  }],Message:,Reason:,HostIP:100.100.230.30,PodIP:,StartTime:2019-07-31 06:25:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 06:25:32.357: INFO: Pod "nginx-deployment-555b55d965-qnskt" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-qnskt,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-lhg48,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lhg48/pods/nginx-deployment-555b55d965-qnskt,UID:f9a3f0e5-b35b-11e9-ac6f-000017003e78,ResourceVersion:4177,Generation:0,CreationTimestamp:2019-07-31 06:25:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f99a01c6-b35b-11e9-ac6f-000017003e78 0xc00207aac7 0xc00207aac8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9s8gr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9s8gr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9s8gr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shushsha-k8s-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00207ab50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00207ac10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:24 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:24 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:22 +0000 UTC  }],Message:,Reason:,HostIP:100.100.230.39,PodIP:10.244.2.32,StartTime:2019-07-31 06:25:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-07-31 06:25:24 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://0e8ae6531ec9ff8719e7eae2ba235b84343419a6633b8d014cce5171ed90ca4f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 06:25:32.357: INFO: Pod "nginx-deployment-555b55d965-rhjvg" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-rhjvg,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-lhg48,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lhg48/pods/nginx-deployment-555b55d965-rhjvg,UID:f9a2243a-b35b-11e9-ac6f-000017003e78,ResourceVersion:4180,Generation:0,CreationTimestamp:2019-07-31 06:25:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f99a01c6-b35b-11e9-ac6f-000017003e78 0xc00207acd0 0xc00207acd1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9s8gr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9s8gr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9s8gr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shushsha-k8s-worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00207ad30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00207ad50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:24 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:24 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:22 +0000 UTC  }],Message:,Reason:,HostIP:100.100.230.30,PodIP:10.244.1.32,StartTime:2019-07-31 06:25:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-07-31 06:25:23 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://c6bfbd59327eb5832d68f4e084f92e4becfa0725cf610f101d99f7afa0c68298}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 06:25:32.357: INFO: Pod "nginx-deployment-555b55d965-tsz2r" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-tsz2r,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-lhg48,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lhg48/pods/nginx-deployment-555b55d965-tsz2r,UID:f9a612af-b35b-11e9-ac6f-000017003e78,ResourceVersion:4183,Generation:0,CreationTimestamp:2019-07-31 06:25:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f99a01c6-b35b-11e9-ac6f-000017003e78 0xc00207ae10 0xc00207ae11}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9s8gr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9s8gr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9s8gr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shushsha-k8s-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00207ae70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00207ae90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:24 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:24 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:22 +0000 UTC  }],Message:,Reason:,HostIP:100.100.230.39,PodIP:10.244.2.31,StartTime:2019-07-31 06:25:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-07-31 06:25:24 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://47ef22f906aab5feac62dd65b1f57f9882764f31a8320e0f69b29c3c7b4f1c65}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 06:25:32.357: INFO: Pod "nginx-deployment-555b55d965-w8sz9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-w8sz9,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-lhg48,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lhg48/pods/nginx-deployment-555b55d965-w8sz9,UID:fe6856ee-b35b-11e9-ac6f-000017003e78,ResourceVersion:4317,Generation:0,CreationTimestamp:2019-07-31 06:25:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f99a01c6-b35b-11e9-ac6f-000017003e78 0xc00207af50 0xc00207af51}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9s8gr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9s8gr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9s8gr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shushsha-k8s-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00207afb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00207afd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC  }],Message:,Reason:,HostIP:100.100.230.39,PodIP:,StartTime:2019-07-31 06:25:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 06:25:32.357: INFO: Pod "nginx-deployment-555b55d965-zf5d7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-zf5d7,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-lhg48,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lhg48/pods/nginx-deployment-555b55d965-zf5d7,UID:fe684006-b35b-11e9-ac6f-000017003e78,ResourceVersion:4295,Generation:0,CreationTimestamp:2019-07-31 06:25:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f99a01c6-b35b-11e9-ac6f-000017003e78 0xc00207b087 0xc00207b088}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9s8gr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9s8gr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9s8gr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shushsha-k8s-worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00207b0f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00207b110}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC  }],Message:,Reason:,HostIP:100.100.230.30,PodIP:,StartTime:2019-07-31 06:25:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 06:25:32.358: INFO: Pod "nginx-deployment-65bbdb5f8-4qfwq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-4qfwq,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-lhg48,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lhg48/pods/nginx-deployment-65bbdb5f8-4qfwq,UID:fe6daf09-b35b-11e9-ac6f-000017003e78,ResourceVersion:4313,Generation:0,CreationTimestamp:2019-07-31 06:25:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 fd30d1ce-b35b-11e9-ac6f-000017003e78 0xc00207b1c0 0xc00207b1c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9s8gr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9s8gr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9s8gr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shushsha-k8s-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00207b230} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00207b250}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 06:25:32.358: INFO: Pod "nginx-deployment-65bbdb5f8-5p67w" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-5p67w,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-lhg48,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lhg48/pods/nginx-deployment-65bbdb5f8-5p67w,UID:fe69e322-b35b-11e9-ac6f-000017003e78,ResourceVersion:4339,Generation:0,CreationTimestamp:2019-07-31 06:25:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 fd30d1ce-b35b-11e9-ac6f-000017003e78 0xc00207b2c0 0xc00207b2c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9s8gr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9s8gr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9s8gr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shushsha-k8s-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00207b340} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00207b360}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC  }],Message:,Reason:,HostIP:100.100.230.39,PodIP:,StartTime:2019-07-31 06:25:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 06:25:32.358: INFO: Pod "nginx-deployment-65bbdb5f8-b58ch" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-b58ch,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-lhg48,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lhg48/pods/nginx-deployment-65bbdb5f8-b58ch,UID:fe6d913d-b35b-11e9-ac6f-000017003e78,ResourceVersion:4309,Generation:0,CreationTimestamp:2019-07-31 06:25:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 fd30d1ce-b35b-11e9-ac6f-000017003e78 0xc00207b420 0xc00207b421}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9s8gr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9s8gr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9s8gr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shushsha-k8s-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00207b490} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00207b4b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 06:25:32.358: INFO: Pod "nginx-deployment-65bbdb5f8-dcfgb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-dcfgb,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-lhg48,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lhg48/pods/nginx-deployment-65bbdb5f8-dcfgb,UID:fd31e7d6-b35b-11e9-ac6f-000017003e78,ResourceVersion:4220,Generation:0,CreationTimestamp:2019-07-31 06:25:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 fd30d1ce-b35b-11e9-ac6f-000017003e78 0xc00207b520 0xc00207b521}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9s8gr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9s8gr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9s8gr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shushsha-k8s-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00207b590} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00207b5b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:28 +0000 UTC  }],Message:,Reason:,HostIP:100.100.230.39,PodIP:,StartTime:2019-07-31 06:25:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 06:25:32.358: INFO: Pod "nginx-deployment-65bbdb5f8-f4452" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-f4452,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-lhg48,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lhg48/pods/nginx-deployment-65bbdb5f8-f4452,UID:fd38c22f-b35b-11e9-ac6f-000017003e78,ResourceVersion:4240,Generation:0,CreationTimestamp:2019-07-31 06:25:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 fd30d1ce-b35b-11e9-ac6f-000017003e78 0xc00207b670 0xc00207b671}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9s8gr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9s8gr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9s8gr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shushsha-k8s-worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00207b6e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00207b700}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:28 +0000 UTC  }],Message:,Reason:,HostIP:100.100.230.30,PodIP:,StartTime:2019-07-31 06:25:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 06:25:32.359: INFO: Pod "nginx-deployment-65bbdb5f8-fcpwr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-fcpwr,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-lhg48,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lhg48/pods/nginx-deployment-65bbdb5f8-fcpwr,UID:fd313801-b35b-11e9-ac6f-000017003e78,ResourceVersion:4217,Generation:0,CreationTimestamp:2019-07-31 06:25:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 fd30d1ce-b35b-11e9-ac6f-000017003e78 0xc00207b7c0 0xc00207b7c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9s8gr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9s8gr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9s8gr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shushsha-k8s-worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00207b830} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00207b850}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:28 +0000 UTC  }],Message:,Reason:,HostIP:100.100.230.30,PodIP:,StartTime:2019-07-31 06:25:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 06:25:32.359: INFO: Pod "nginx-deployment-65bbdb5f8-hr8m9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-hr8m9,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-lhg48,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lhg48/pods/nginx-deployment-65bbdb5f8-hr8m9,UID:fd31fa72-b35b-11e9-ac6f-000017003e78,ResourceVersion:4226,Generation:0,CreationTimestamp:2019-07-31 06:25:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 fd30d1ce-b35b-11e9-ac6f-000017003e78 0xc00207b910 0xc00207b911}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9s8gr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9s8gr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9s8gr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shushsha-k8s-worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00207b980} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00207b9a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:28 +0000 UTC  }],Message:,Reason:,HostIP:100.100.230.30,PodIP:,StartTime:2019-07-31 06:25:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 06:25:32.359: INFO: Pod "nginx-deployment-65bbdb5f8-l9n9n" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-l9n9n,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-lhg48,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lhg48/pods/nginx-deployment-65bbdb5f8-l9n9n,UID:fe6dc386-b35b-11e9-ac6f-000017003e78,ResourceVersion:4312,Generation:0,CreationTimestamp:2019-07-31 06:25:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 fd30d1ce-b35b-11e9-ac6f-000017003e78 0xc00207ba60 0xc00207ba61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9s8gr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9s8gr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9s8gr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shushsha-k8s-worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00207bad0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00207baf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 06:25:32.359: INFO: Pod "nginx-deployment-65bbdb5f8-lflfk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-lflfk,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-lhg48,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lhg48/pods/nginx-deployment-65bbdb5f8-lflfk,UID:fd3816d9-b35b-11e9-ac6f-000017003e78,ResourceVersion:4242,Generation:0,CreationTimestamp:2019-07-31 06:25:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 fd30d1ce-b35b-11e9-ac6f-000017003e78 0xc00207bb60 0xc00207bb61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9s8gr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9s8gr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9s8gr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shushsha-k8s-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00207bbd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00207bbf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:28 +0000 UTC  }],Message:,Reason:,HostIP:100.100.230.39,PodIP:,StartTime:2019-07-31 06:25:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 06:25:32.360: INFO: Pod "nginx-deployment-65bbdb5f8-qqrls" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-qqrls,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-lhg48,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lhg48/pods/nginx-deployment-65bbdb5f8-qqrls,UID:fe686242-b35b-11e9-ac6f-000017003e78,ResourceVersion:4335,Generation:0,CreationTimestamp:2019-07-31 06:25:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 fd30d1ce-b35b-11e9-ac6f-000017003e78 0xc00207bcb0 0xc00207bcb1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9s8gr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9s8gr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9s8gr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shushsha-k8s-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00207bd20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00207bd40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC  }],Message:,Reason:,HostIP:100.100.230.39,PodIP:,StartTime:2019-07-31 06:25:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 06:25:32.360: INFO: Pod "nginx-deployment-65bbdb5f8-qs4gk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-qs4gk,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-lhg48,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lhg48/pods/nginx-deployment-65bbdb5f8-qs4gk,UID:fe6da5ce-b35b-11e9-ac6f-000017003e78,ResourceVersion:4308,Generation:0,CreationTimestamp:2019-07-31 06:25:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 fd30d1ce-b35b-11e9-ac6f-000017003e78 0xc00207be00 0xc00207be01}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9s8gr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9s8gr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9s8gr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shushsha-k8s-worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00207be70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00207be90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 06:25:32.360: INFO: Pod "nginx-deployment-65bbdb5f8-t7cn7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-t7cn7,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-lhg48,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lhg48/pods/nginx-deployment-65bbdb5f8-t7cn7,UID:fe69b02b-b35b-11e9-ac6f-000017003e78,ResourceVersion:4329,Generation:0,CreationTimestamp:2019-07-31 06:25:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 fd30d1ce-b35b-11e9-ac6f-000017003e78 0xc00207bf00 0xc00207bf01}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9s8gr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9s8gr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9s8gr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shushsha-k8s-worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00207bf70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00207bf90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC  }],Message:,Reason:,HostIP:100.100.230.30,PodIP:,StartTime:2019-07-31 06:25:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 31 06:25:32.360: INFO: Pod "nginx-deployment-65bbdb5f8-z4gk8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-z4gk8,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-lhg48,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lhg48/pods/nginx-deployment-65bbdb5f8-z4gk8,UID:fe71c1af-b35b-11e9-ac6f-000017003e78,ResourceVersion:4320,Generation:0,CreationTimestamp:2019-07-31 06:25:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 fd30d1ce-b35b-11e9-ac6f-000017003e78 0xc00208a050 0xc00208a051}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9s8gr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9s8gr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9s8gr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shushsha-k8s-worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00208a0c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00208a120}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 06:25:30 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:25:32.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-lhg48" for this suite.
Jul 31 06:25:38.371: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:25:38.526: INFO: namespace: e2e-tests-deployment-lhg48, resource: bindings, ignored listing per whitelist
Jul 31 06:25:38.547: INFO: namespace e2e-tests-deployment-lhg48 deletion completed in 6.18385651s

• [SLOW TEST:16.356 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:25:38.548: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Jul 31 06:25:46.652: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:26:10.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-b9sdj" for this suite.
Jul 31 06:26:16.697: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:26:16.755: INFO: namespace: e2e-tests-namespaces-b9sdj, resource: bindings, ignored listing per whitelist
Jul 31 06:26:16.766: INFO: namespace e2e-tests-namespaces-b9sdj deletion completed in 6.077270311s
STEP: Destroying namespace "e2e-tests-nsdeletetest-gshxh" for this suite.
Jul 31 06:26:16.767: INFO: Namespace e2e-tests-nsdeletetest-gshxh was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-mpz7x" for this suite.
Jul 31 06:26:22.776: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:26:22.785: INFO: namespace: e2e-tests-nsdeletetest-mpz7x, resource: bindings, ignored listing per whitelist
Jul 31 06:26:22.847: INFO: namespace e2e-tests-nsdeletetest-mpz7x deletion completed in 6.07989288s

• [SLOW TEST:44.300 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:26:22.848: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Jul 31 06:26:22.908: INFO: Pod name pod-release: Found 0 pods out of 1
Jul 31 06:26:27.911: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:26:28.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-ttcwj" for this suite.
Jul 31 06:26:34.932: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:26:34.939: INFO: namespace: e2e-tests-replication-controller-ttcwj, resource: bindings, ignored listing per whitelist
Jul 31 06:26:35.001: INFO: namespace e2e-tests-replication-controller-ttcwj deletion completed in 6.076689157s

• [SLOW TEST:12.153 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:26:35.001: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Jul 31 06:26:35.059: INFO: Waiting up to 5m0s for pod "pod-24fec031-b35c-11e9-990e-fe448544ce72" in namespace "e2e-tests-emptydir-s7855" to be "success or failure"
Jul 31 06:26:35.062: INFO: Pod "pod-24fec031-b35c-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 3.160228ms
Jul 31 06:26:37.065: INFO: Pod "pod-24fec031-b35c-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006256921s
STEP: Saw pod success
Jul 31 06:26:37.065: INFO: Pod "pod-24fec031-b35c-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 06:26:37.067: INFO: Trying to get logs from node shushsha-k8s-worker2 pod pod-24fec031-b35c-11e9-990e-fe448544ce72 container test-container: <nil>
STEP: delete the pod
Jul 31 06:26:37.082: INFO: Waiting for pod pod-24fec031-b35c-11e9-990e-fe448544ce72 to disappear
Jul 31 06:26:37.084: INFO: Pod pod-24fec031-b35c-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:26:37.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-s7855" for this suite.
Jul 31 06:26:43.095: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:26:43.124: INFO: namespace: e2e-tests-emptydir-s7855, resource: bindings, ignored listing per whitelist
Jul 31 06:26:43.163: INFO: namespace e2e-tests-emptydir-s7855 deletion completed in 6.075605195s

• [SLOW TEST:8.161 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:26:43.163: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Jul 31 06:26:47.232: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wxsm9 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 31 06:26:47.232: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
Jul 31 06:26:47.328: INFO: Exec stderr: ""
Jul 31 06:26:47.328: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wxsm9 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 31 06:26:47.328: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
Jul 31 06:26:47.428: INFO: Exec stderr: ""
Jul 31 06:26:47.428: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wxsm9 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 31 06:26:47.428: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
Jul 31 06:26:47.529: INFO: Exec stderr: ""
Jul 31 06:26:47.529: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wxsm9 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 31 06:26:47.529: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
Jul 31 06:26:47.629: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Jul 31 06:26:47.629: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wxsm9 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 31 06:26:47.629: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
Jul 31 06:26:47.740: INFO: Exec stderr: ""
Jul 31 06:26:47.740: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wxsm9 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 31 06:26:47.740: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
Jul 31 06:26:47.840: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Jul 31 06:26:47.840: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wxsm9 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 31 06:26:47.840: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
Jul 31 06:26:47.963: INFO: Exec stderr: ""
Jul 31 06:26:47.963: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wxsm9 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 31 06:26:47.963: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
Jul 31 06:26:48.086: INFO: Exec stderr: ""
Jul 31 06:26:48.086: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wxsm9 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 31 06:26:48.086: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
Jul 31 06:26:48.209: INFO: Exec stderr: ""
Jul 31 06:26:48.209: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wxsm9 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 31 06:26:48.209: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
Jul 31 06:26:48.325: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:26:48.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-wxsm9" for this suite.
Jul 31 06:27:26.335: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:27:26.383: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-wxsm9, resource: bindings, ignored listing per whitelist
Jul 31 06:27:26.405: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-wxsm9 deletion completed in 38.077157128s

• [SLOW TEST:43.242 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:27:26.405: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jul 31 06:27:26.466: INFO: Waiting up to 5m0s for pod "downwardapi-volume-43a2d3e5-b35c-11e9-990e-fe448544ce72" in namespace "e2e-tests-downward-api-ntn2p" to be "success or failure"
Jul 31 06:27:26.468: INFO: Pod "downwardapi-volume-43a2d3e5-b35c-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.145472ms
Jul 31 06:27:28.471: INFO: Pod "downwardapi-volume-43a2d3e5-b35c-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004919182s
Jul 31 06:27:30.474: INFO: Pod "downwardapi-volume-43a2d3e5-b35c-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007754723s
STEP: Saw pod success
Jul 31 06:27:30.474: INFO: Pod "downwardapi-volume-43a2d3e5-b35c-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 06:27:30.477: INFO: Trying to get logs from node shushsha-k8s-worker2 pod downwardapi-volume-43a2d3e5-b35c-11e9-990e-fe448544ce72 container client-container: <nil>
STEP: delete the pod
Jul 31 06:27:30.490: INFO: Waiting for pod downwardapi-volume-43a2d3e5-b35c-11e9-990e-fe448544ce72 to disappear
Jul 31 06:27:30.492: INFO: Pod downwardapi-volume-43a2d3e5-b35c-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:27:30.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-ntn2p" for this suite.
Jul 31 06:27:36.503: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:27:36.568: INFO: namespace: e2e-tests-downward-api-ntn2p, resource: bindings, ignored listing per whitelist
Jul 31 06:27:36.573: INFO: namespace e2e-tests-downward-api-ntn2p deletion completed in 6.077854233s

• [SLOW TEST:10.167 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:27:36.573: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:27:58.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-runtime-jfpbn" for this suite.
Jul 31 06:28:04.777: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:28:04.835: INFO: namespace: e2e-tests-container-runtime-jfpbn, resource: bindings, ignored listing per whitelist
Jul 31 06:28:04.849: INFO: namespace e2e-tests-container-runtime-jfpbn deletion completed in 6.081998143s

• [SLOW TEST:28.277 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  blackbox test
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:28:04.850: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-5a8e48a9-b35c-11e9-990e-fe448544ce72
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:28:06.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-9dbnh" for this suite.
Jul 31 06:28:28.958: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:28:29.019: INFO: namespace: e2e-tests-configmap-9dbnh, resource: bindings, ignored listing per whitelist
Jul 31 06:28:29.027: INFO: namespace e2e-tests-configmap-9dbnh deletion completed in 22.080774189s

• [SLOW TEST:24.177 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:28:29.027: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-68f5c5f5-b35c-11e9-990e-fe448544ce72
STEP: Creating a pod to test consume configMaps
Jul 31 06:28:29.088: INFO: Waiting up to 5m0s for pod "pod-configmaps-68f62dbe-b35c-11e9-990e-fe448544ce72" in namespace "e2e-tests-configmap-92fs5" to be "success or failure"
Jul 31 06:28:29.092: INFO: Pod "pod-configmaps-68f62dbe-b35c-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 3.888184ms
Jul 31 06:28:31.095: INFO: Pod "pod-configmaps-68f62dbe-b35c-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006982199s
STEP: Saw pod success
Jul 31 06:28:31.095: INFO: Pod "pod-configmaps-68f62dbe-b35c-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 06:28:31.098: INFO: Trying to get logs from node shushsha-k8s-worker2 pod pod-configmaps-68f62dbe-b35c-11e9-990e-fe448544ce72 container configmap-volume-test: <nil>
STEP: delete the pod
Jul 31 06:28:31.112: INFO: Waiting for pod pod-configmaps-68f62dbe-b35c-11e9-990e-fe448544ce72 to disappear
Jul 31 06:28:31.115: INFO: Pod pod-configmaps-68f62dbe-b35c-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:28:31.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-92fs5" for this suite.
Jul 31 06:28:37.126: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:28:37.187: INFO: namespace: e2e-tests-configmap-92fs5, resource: bindings, ignored listing per whitelist
Jul 31 06:28:37.193: INFO: namespace e2e-tests-configmap-92fs5 deletion completed in 6.075400455s

• [SLOW TEST:8.166 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:28:37.194: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-cwx5p in namespace e2e-tests-proxy-wtkdc
I0731 06:28:37.256948      18 runners.go:184] Created replication controller with name: proxy-service-cwx5p, namespace: e2e-tests-proxy-wtkdc, replica count: 1
I0731 06:28:38.307442      18 runners.go:184] proxy-service-cwx5p Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0731 06:28:39.307713      18 runners.go:184] proxy-service-cwx5p Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0731 06:28:40.307963      18 runners.go:184] proxy-service-cwx5p Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0731 06:28:41.308242      18 runners.go:184] proxy-service-cwx5p Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0731 06:28:42.308558      18 runners.go:184] proxy-service-cwx5p Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0731 06:28:43.308855      18 runners.go:184] proxy-service-cwx5p Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0731 06:28:44.309118      18 runners.go:184] proxy-service-cwx5p Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0731 06:28:45.309389      18 runners.go:184] proxy-service-cwx5p Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0731 06:28:46.309654      18 runners.go:184] proxy-service-cwx5p Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0731 06:28:47.309901      18 runners.go:184] proxy-service-cwx5p Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0731 06:28:48.310195      18 runners.go:184] proxy-service-cwx5p Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0731 06:28:49.310455      18 runners.go:184] proxy-service-cwx5p Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0731 06:28:50.310728      18 runners.go:184] proxy-service-cwx5p Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jul 31 06:28:50.313: INFO: setup took 13.067835237s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Jul 31 06:28:50.328: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:1080/proxy/... (200; 15.117123ms)
Jul 31 06:28:50.328: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:1080/proxy/rewri... (200; 15.056279ms)
Jul 31 06:28:50.330: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb/proxy/rewriteme"... (200; 16.585217ms)
Jul 31 06:28:50.333: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/proxy-service-cwx5p:portname2/proxy/: bar (200; 19.327697ms)
Jul 31 06:28:50.333: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:162/proxy/: bar (200; 19.660515ms)
Jul 31 06:28:50.333: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/http:proxy-service-cwx5p:portname2/proxy/: bar (200; 19.815065ms)
Jul 31 06:28:50.333: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:160/proxy/: foo (200; 19.753205ms)
Jul 31 06:28:50.333: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/proxy-service-cwx5p:portname1/proxy/: foo (200; 19.931629ms)
Jul 31 06:28:50.333: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/http:proxy-service-cwx5p:portname1/proxy/: foo (200; 19.901275ms)
Jul 31 06:28:50.333: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:160/proxy/: foo (200; 19.857922ms)
Jul 31 06:28:50.333: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:162/proxy/: bar (200; 19.92007ms)
Jul 31 06:28:50.334: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/https:proxy-service-cwx5p:tlsportname1/proxy/: tls baz (200; 20.937066ms)
Jul 31 06:28:50.334: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:462/proxy/: tls qux (200; 21.163683ms)
Jul 31 06:28:50.335: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:443/proxy/... (200; 21.629921ms)
Jul 31 06:28:50.335: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/https:proxy-service-cwx5p:tlsportname2/proxy/: tls qux (200; 21.372375ms)
Jul 31 06:28:50.336: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:460/proxy/: tls baz (200; 23.189796ms)
Jul 31 06:28:50.341: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:162/proxy/: bar (200; 4.519981ms)
Jul 31 06:28:50.342: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:462/proxy/: tls qux (200; 5.758875ms)
Jul 31 06:28:50.345: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/proxy-service-cwx5p:portname1/proxy/: foo (200; 8.559637ms)
Jul 31 06:28:50.345: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:160/proxy/: foo (200; 8.831356ms)
Jul 31 06:28:50.345: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb/proxy/rewriteme"... (200; 8.750869ms)
Jul 31 06:28:50.345: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:443/proxy/... (200; 9.070692ms)
Jul 31 06:28:50.345: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/https:proxy-service-cwx5p:tlsportname1/proxy/: tls baz (200; 9.00478ms)
Jul 31 06:28:50.345: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/http:proxy-service-cwx5p:portname2/proxy/: bar (200; 9.148296ms)
Jul 31 06:28:50.346: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/http:proxy-service-cwx5p:portname1/proxy/: foo (200; 8.976314ms)
Jul 31 06:28:50.346: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/proxy-service-cwx5p:portname2/proxy/: bar (200; 9.425288ms)
Jul 31 06:28:50.346: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:460/proxy/: tls baz (200; 9.112035ms)
Jul 31 06:28:50.346: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:1080/proxy/... (200; 8.993949ms)
Jul 31 06:28:50.346: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:1080/proxy/rewri... (200; 9.275291ms)
Jul 31 06:28:50.346: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:160/proxy/: foo (200; 9.310137ms)
Jul 31 06:28:50.346: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:162/proxy/: bar (200; 9.209618ms)
Jul 31 06:28:50.346: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/https:proxy-service-cwx5p:tlsportname2/proxy/: tls qux (200; 9.781367ms)
Jul 31 06:28:50.349: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:443/proxy/... (200; 2.745915ms)
Jul 31 06:28:50.353: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:162/proxy/: bar (200; 4.609715ms)
Jul 31 06:28:50.353: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:1080/proxy/rewri... (200; 4.75843ms)
Jul 31 06:28:50.353: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:1080/proxy/... (200; 6.192986ms)
Jul 31 06:28:50.354: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:460/proxy/: tls baz (200; 6.973345ms)
Jul 31 06:28:50.354: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:462/proxy/: tls qux (200; 5.981867ms)
Jul 31 06:28:50.354: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:162/proxy/: bar (200; 6.711872ms)
Jul 31 06:28:50.354: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb/proxy/rewriteme"... (200; 6.299075ms)
Jul 31 06:28:50.354: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:160/proxy/: foo (200; 7.85957ms)
Jul 31 06:28:50.355: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:160/proxy/: foo (200; 6.852633ms)
Jul 31 06:28:50.356: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/proxy-service-cwx5p:portname2/proxy/: bar (200; 8.235554ms)
Jul 31 06:28:50.356: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/https:proxy-service-cwx5p:tlsportname2/proxy/: tls qux (200; 7.867679ms)
Jul 31 06:28:50.356: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/https:proxy-service-cwx5p:tlsportname1/proxy/: tls baz (200; 8.542674ms)
Jul 31 06:28:50.356: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/proxy-service-cwx5p:portname1/proxy/: foo (200; 9.228937ms)
Jul 31 06:28:50.356: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/http:proxy-service-cwx5p:portname2/proxy/: bar (200; 8.97072ms)
Jul 31 06:28:50.356: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/http:proxy-service-cwx5p:portname1/proxy/: foo (200; 9.373368ms)
Jul 31 06:28:50.360: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:462/proxy/: tls qux (200; 3.472517ms)
Jul 31 06:28:50.360: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:162/proxy/: bar (200; 3.581915ms)
Jul 31 06:28:50.360: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:460/proxy/: tls baz (200; 3.872719ms)
Jul 31 06:28:50.365: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/http:proxy-service-cwx5p:portname1/proxy/: foo (200; 8.098303ms)
Jul 31 06:28:50.365: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/proxy-service-cwx5p:portname1/proxy/: foo (200; 8.749731ms)
Jul 31 06:28:50.365: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:443/proxy/... (200; 8.834439ms)
Jul 31 06:28:50.366: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:160/proxy/: foo (200; 9.119113ms)
Jul 31 06:28:50.366: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/proxy-service-cwx5p:portname2/proxy/: bar (200; 9.309469ms)
Jul 31 06:28:50.366: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/https:proxy-service-cwx5p:tlsportname1/proxy/: tls baz (200; 9.476998ms)
Jul 31 06:28:50.366: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb/proxy/rewriteme"... (200; 9.335979ms)
Jul 31 06:28:50.366: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/https:proxy-service-cwx5p:tlsportname2/proxy/: tls qux (200; 9.310502ms)
Jul 31 06:28:50.366: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:1080/proxy/... (200; 9.556801ms)
Jul 31 06:28:50.366: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:162/proxy/: bar (200; 9.600058ms)
Jul 31 06:28:50.366: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:160/proxy/: foo (200; 9.843536ms)
Jul 31 06:28:50.366: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:1080/proxy/rewri... (200; 9.749323ms)
Jul 31 06:28:50.368: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/http:proxy-service-cwx5p:portname2/proxy/: bar (200; 11.036617ms)
Jul 31 06:28:50.371: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:160/proxy/: foo (200; 3.203594ms)
Jul 31 06:28:50.371: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:160/proxy/: foo (200; 3.501042ms)
Jul 31 06:28:50.378: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:462/proxy/: tls qux (200; 10.453423ms)
Jul 31 06:28:50.414: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/https:proxy-service-cwx5p:tlsportname1/proxy/: tls baz (200; 46.5761ms)
Jul 31 06:28:50.414: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/proxy-service-cwx5p:portname1/proxy/: foo (200; 46.397836ms)
Jul 31 06:28:50.415: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/http:proxy-service-cwx5p:portname2/proxy/: bar (200; 46.863069ms)
Jul 31 06:28:50.415: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:1080/proxy/rewri... (200; 47.116551ms)
Jul 31 06:28:50.415: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:443/proxy/... (200; 47.448739ms)
Jul 31 06:28:50.416: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:1080/proxy/... (200; 47.644994ms)
Jul 31 06:28:50.416: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:460/proxy/: tls baz (200; 47.61856ms)
Jul 31 06:28:50.416: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:162/proxy/: bar (200; 47.764111ms)
Jul 31 06:28:50.418: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:162/proxy/: bar (200; 50.115153ms)
Jul 31 06:28:50.422: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb/proxy/rewriteme"... (200; 53.849461ms)
Jul 31 06:28:50.422: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/proxy-service-cwx5p:portname2/proxy/: bar (200; 53.773313ms)
Jul 31 06:28:50.422: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/https:proxy-service-cwx5p:tlsportname2/proxy/: tls qux (200; 53.753352ms)
Jul 31 06:28:50.422: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/http:proxy-service-cwx5p:portname1/proxy/: foo (200; 53.874015ms)
Jul 31 06:28:50.426: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:1080/proxy/... (200; 3.797148ms)
Jul 31 06:28:50.427: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:162/proxy/: bar (200; 4.536207ms)
Jul 31 06:28:50.429: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:162/proxy/: bar (200; 6.160948ms)
Jul 31 06:28:50.429: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:1080/proxy/rewri... (200; 6.189149ms)
Jul 31 06:28:50.430: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:160/proxy/: foo (200; 6.471393ms)
Jul 31 06:28:50.430: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:460/proxy/: tls baz (200; 6.974996ms)
Jul 31 06:28:50.430: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/proxy-service-cwx5p:portname1/proxy/: foo (200; 6.924897ms)
Jul 31 06:28:50.430: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:443/proxy/... (200; 6.410687ms)
Jul 31 06:28:50.430: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb/proxy/rewriteme"... (200; 7.674607ms)
Jul 31 06:28:50.430: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:462/proxy/: tls qux (200; 6.993778ms)
Jul 31 06:28:50.431: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:160/proxy/: foo (200; 8.743241ms)
Jul 31 06:28:50.435: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/proxy-service-cwx5p:portname2/proxy/: bar (200; 11.608503ms)
Jul 31 06:28:50.435: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/http:proxy-service-cwx5p:portname1/proxy/: foo (200; 12.386963ms)
Jul 31 06:28:50.435: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/https:proxy-service-cwx5p:tlsportname1/proxy/: tls baz (200; 12.162026ms)
Jul 31 06:28:50.435: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/http:proxy-service-cwx5p:portname2/proxy/: bar (200; 12.675999ms)
Jul 31 06:28:50.435: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/https:proxy-service-cwx5p:tlsportname2/proxy/: tls qux (200; 12.142567ms)
Jul 31 06:28:50.441: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:443/proxy/... (200; 5.469837ms)
Jul 31 06:28:50.442: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:162/proxy/: bar (200; 6.408014ms)
Jul 31 06:28:50.442: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:160/proxy/: foo (200; 7.128191ms)
Jul 31 06:28:50.443: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:1080/proxy/... (200; 7.111715ms)
Jul 31 06:28:50.443: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:162/proxy/: bar (200; 6.820827ms)
Jul 31 06:28:50.443: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb/proxy/rewriteme"... (200; 7.516273ms)
Jul 31 06:28:50.443: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:160/proxy/: foo (200; 7.497432ms)
Jul 31 06:28:50.443: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:1080/proxy/rewri... (200; 7.389516ms)
Jul 31 06:28:50.443: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:462/proxy/: tls qux (200; 7.483042ms)
Jul 31 06:28:50.444: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:460/proxy/: tls baz (200; 8.305389ms)
Jul 31 06:28:50.446: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/proxy-service-cwx5p:portname2/proxy/: bar (200; 10.035181ms)
Jul 31 06:28:50.446: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/https:proxy-service-cwx5p:tlsportname1/proxy/: tls baz (200; 10.036425ms)
Jul 31 06:28:50.446: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/http:proxy-service-cwx5p:portname2/proxy/: bar (200; 10.166819ms)
Jul 31 06:28:50.446: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/https:proxy-service-cwx5p:tlsportname2/proxy/: tls qux (200; 9.964701ms)
Jul 31 06:28:50.446: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/http:proxy-service-cwx5p:portname1/proxy/: foo (200; 10.218907ms)
Jul 31 06:28:50.446: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/proxy-service-cwx5p:portname1/proxy/: foo (200; 10.29938ms)
Jul 31 06:28:50.455: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:1080/proxy/rewri... (200; 8.376739ms)
Jul 31 06:28:50.455: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:460/proxy/: tls baz (200; 8.383289ms)
Jul 31 06:28:50.455: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:162/proxy/: bar (200; 9.016284ms)
Jul 31 06:28:50.456: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb/proxy/rewriteme"... (200; 10.033014ms)
Jul 31 06:28:50.456: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:443/proxy/... (200; 10.571227ms)
Jul 31 06:28:50.457: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:1080/proxy/... (200; 10.498407ms)
Jul 31 06:28:50.457: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:162/proxy/: bar (200; 11.010733ms)
Jul 31 06:28:50.457: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:462/proxy/: tls qux (200; 10.865222ms)
Jul 31 06:28:50.457: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:160/proxy/: foo (200; 10.712722ms)
Jul 31 06:28:50.457: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:160/proxy/: foo (200; 11.072845ms)
Jul 31 06:28:50.459: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/proxy-service-cwx5p:portname2/proxy/: bar (200; 12.765887ms)
Jul 31 06:28:50.459: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/proxy-service-cwx5p:portname1/proxy/: foo (200; 12.964059ms)
Jul 31 06:28:50.459: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/https:proxy-service-cwx5p:tlsportname1/proxy/: tls baz (200; 13.405718ms)
Jul 31 06:28:50.459: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/http:proxy-service-cwx5p:portname2/proxy/: bar (200; 12.917189ms)
Jul 31 06:28:50.459: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/https:proxy-service-cwx5p:tlsportname2/proxy/: tls qux (200; 13.456311ms)
Jul 31 06:28:50.460: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/http:proxy-service-cwx5p:portname1/proxy/: foo (200; 13.234018ms)
Jul 31 06:28:50.464: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:460/proxy/: tls baz (200; 3.915321ms)
Jul 31 06:28:50.466: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/proxy-service-cwx5p:portname2/proxy/: bar (200; 6.265401ms)
Jul 31 06:28:50.470: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/http:proxy-service-cwx5p:portname1/proxy/: foo (200; 9.350867ms)
Jul 31 06:28:50.470: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:443/proxy/... (200; 9.508883ms)
Jul 31 06:28:50.470: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:160/proxy/: foo (200; 9.139155ms)
Jul 31 06:28:50.471: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/https:proxy-service-cwx5p:tlsportname1/proxy/: tls baz (200; 10.911022ms)
Jul 31 06:28:50.471: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/https:proxy-service-cwx5p:tlsportname2/proxy/: tls qux (200; 11.277263ms)
Jul 31 06:28:50.472: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:462/proxy/: tls qux (200; 11.132344ms)
Jul 31 06:28:50.472: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:162/proxy/: bar (200; 11.442391ms)
Jul 31 06:28:50.472: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/proxy-service-cwx5p:portname1/proxy/: foo (200; 10.74775ms)
Jul 31 06:28:50.472: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb/proxy/rewriteme"... (200; 11.179113ms)
Jul 31 06:28:50.472: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:160/proxy/: foo (200; 11.506987ms)
Jul 31 06:28:50.472: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:1080/proxy/... (200; 10.960106ms)
Jul 31 06:28:50.472: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:162/proxy/: bar (200; 11.469543ms)
Jul 31 06:28:50.472: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:1080/proxy/rewri... (200; 11.586307ms)
Jul 31 06:28:50.472: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/http:proxy-service-cwx5p:portname2/proxy/: bar (200; 11.222509ms)
Jul 31 06:28:50.476: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:162/proxy/: bar (200; 4.022707ms)
Jul 31 06:28:50.481: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/http:proxy-service-cwx5p:portname2/proxy/: bar (200; 7.602733ms)
Jul 31 06:28:50.481: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:160/proxy/: foo (200; 7.968704ms)
Jul 31 06:28:50.482: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:160/proxy/: foo (200; 9.656273ms)
Jul 31 06:28:50.482: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:460/proxy/: tls baz (200; 8.692527ms)
Jul 31 06:28:50.482: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:443/proxy/... (200; 9.281968ms)
Jul 31 06:28:50.482: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/proxy-service-cwx5p:portname1/proxy/: foo (200; 9.212307ms)
Jul 31 06:28:50.482: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:1080/proxy/... (200; 8.98074ms)
Jul 31 06:28:50.482: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/https:proxy-service-cwx5p:tlsportname2/proxy/: tls qux (200; 9.963345ms)
Jul 31 06:28:50.483: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/https:proxy-service-cwx5p:tlsportname1/proxy/: tls baz (200; 8.781126ms)
Jul 31 06:28:50.483: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/proxy-service-cwx5p:portname2/proxy/: bar (200; 8.942271ms)
Jul 31 06:28:50.483: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:1080/proxy/rewri... (200; 9.785227ms)
Jul 31 06:28:50.483: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb/proxy/rewriteme"... (200; 9.908428ms)
Jul 31 06:28:50.483: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:462/proxy/: tls qux (200; 10.061272ms)
Jul 31 06:28:50.483: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/http:proxy-service-cwx5p:portname1/proxy/: foo (200; 9.52451ms)
Jul 31 06:28:50.483: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:162/proxy/: bar (200; 9.884897ms)
Jul 31 06:28:50.487: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:462/proxy/: tls qux (200; 4.325748ms)
Jul 31 06:28:50.492: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/https:proxy-service-cwx5p:tlsportname1/proxy/: tls baz (200; 8.191631ms)
Jul 31 06:28:50.493: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/http:proxy-service-cwx5p:portname2/proxy/: bar (200; 9.073383ms)
Jul 31 06:28:50.493: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:443/proxy/... (200; 9.39603ms)
Jul 31 06:28:50.493: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/proxy-service-cwx5p:portname1/proxy/: foo (200; 9.780683ms)
Jul 31 06:28:50.493: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/http:proxy-service-cwx5p:portname1/proxy/: foo (200; 9.706454ms)
Jul 31 06:28:50.493: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/proxy-service-cwx5p:portname2/proxy/: bar (200; 9.45071ms)
Jul 31 06:28:50.493: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/https:proxy-service-cwx5p:tlsportname2/proxy/: tls qux (200; 9.136916ms)
Jul 31 06:28:50.493: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:460/proxy/: tls baz (200; 9.587293ms)
Jul 31 06:28:50.494: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:160/proxy/: foo (200; 9.304417ms)
Jul 31 06:28:50.494: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:162/proxy/: bar (200; 9.541111ms)
Jul 31 06:28:50.494: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb/proxy/rewriteme"... (200; 11.015792ms)
Jul 31 06:28:50.494: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:1080/proxy/... (200; 10.469834ms)
Jul 31 06:28:50.494: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:160/proxy/: foo (200; 10.388957ms)
Jul 31 06:28:50.494: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:162/proxy/: bar (200; 11.016513ms)
Jul 31 06:28:50.495: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:1080/proxy/rewri... (200; 11.381321ms)
Jul 31 06:28:50.501: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:1080/proxy/rewri... (200; 5.951702ms)
Jul 31 06:28:50.501: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:1080/proxy/... (200; 6.293105ms)
Jul 31 06:28:50.501: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:462/proxy/: tls qux (200; 6.661258ms)
Jul 31 06:28:50.501: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb/proxy/rewriteme"... (200; 6.591461ms)
Jul 31 06:28:50.502: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:162/proxy/: bar (200; 6.865776ms)
Jul 31 06:28:50.502: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:160/proxy/: foo (200; 6.896048ms)
Jul 31 06:28:50.502: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:460/proxy/: tls baz (200; 6.957314ms)
Jul 31 06:28:50.502: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:160/proxy/: foo (200; 7.183455ms)
Jul 31 06:28:50.502: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:162/proxy/: bar (200; 7.069379ms)
Jul 31 06:28:50.502: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:443/proxy/... (200; 7.441495ms)
Jul 31 06:28:50.504: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/http:proxy-service-cwx5p:portname1/proxy/: foo (200; 8.716563ms)
Jul 31 06:28:50.504: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/http:proxy-service-cwx5p:portname2/proxy/: bar (200; 8.840337ms)
Jul 31 06:28:50.504: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/proxy-service-cwx5p:portname2/proxy/: bar (200; 9.26018ms)
Jul 31 06:28:50.505: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/https:proxy-service-cwx5p:tlsportname2/proxy/: tls qux (200; 9.861087ms)
Jul 31 06:28:50.505: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/proxy-service-cwx5p:portname1/proxy/: foo (200; 9.580829ms)
Jul 31 06:28:50.506: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/https:proxy-service-cwx5p:tlsportname1/proxy/: tls baz (200; 10.891124ms)
Jul 31 06:28:50.511: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:160/proxy/: foo (200; 5.564381ms)
Jul 31 06:28:50.511: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:162/proxy/: bar (200; 5.142038ms)
Jul 31 06:28:50.512: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:462/proxy/: tls qux (200; 6.019428ms)
Jul 31 06:28:50.513: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:443/proxy/... (200; 6.589316ms)
Jul 31 06:28:50.513: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/proxy-service-cwx5p:portname1/proxy/: foo (200; 6.536143ms)
Jul 31 06:28:50.513: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:162/proxy/: bar (200; 6.853955ms)
Jul 31 06:28:50.513: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:1080/proxy/rewri... (200; 7.048531ms)
Jul 31 06:28:50.513: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:160/proxy/: foo (200; 7.014171ms)
Jul 31 06:28:50.513: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb/proxy/rewriteme"... (200; 7.023943ms)
Jul 31 06:28:50.513: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:460/proxy/: tls baz (200; 7.343376ms)
Jul 31 06:28:50.514: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:1080/proxy/... (200; 7.806991ms)
Jul 31 06:28:50.516: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/http:proxy-service-cwx5p:portname2/proxy/: bar (200; 9.875751ms)
Jul 31 06:28:50.516: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/https:proxy-service-cwx5p:tlsportname1/proxy/: tls baz (200; 9.741742ms)
Jul 31 06:28:50.516: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/https:proxy-service-cwx5p:tlsportname2/proxy/: tls qux (200; 9.740536ms)
Jul 31 06:28:50.516: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/proxy-service-cwx5p:portname2/proxy/: bar (200; 9.922418ms)
Jul 31 06:28:50.516: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/http:proxy-service-cwx5p:portname1/proxy/: foo (200; 9.803222ms)
Jul 31 06:28:50.522: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:160/proxy/: foo (200; 5.731429ms)
Jul 31 06:28:50.522: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:460/proxy/: tls baz (200; 5.559981ms)
Jul 31 06:28:50.522: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb/proxy/rewriteme"... (200; 5.80546ms)
Jul 31 06:28:50.522: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:1080/proxy/... (200; 5.903349ms)
Jul 31 06:28:50.522: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:160/proxy/: foo (200; 6.430075ms)
Jul 31 06:28:50.522: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:162/proxy/: bar (200; 6.458491ms)
Jul 31 06:28:50.525: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:443/proxy/... (200; 8.240481ms)
Jul 31 06:28:50.525: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:162/proxy/: bar (200; 8.565882ms)
Jul 31 06:28:50.525: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/http:proxy-service-cwx5p:portname1/proxy/: foo (200; 8.989289ms)
Jul 31 06:28:50.525: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/https:proxy-service-cwx5p:tlsportname2/proxy/: tls qux (200; 9.341725ms)
Jul 31 06:28:50.526: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:1080/proxy/rewri... (200; 9.602118ms)
Jul 31 06:28:50.526: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/https:proxy-service-cwx5p:tlsportname1/proxy/: tls baz (200; 9.661711ms)
Jul 31 06:28:50.526: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/http:proxy-service-cwx5p:portname2/proxy/: bar (200; 9.925109ms)
Jul 31 06:28:50.526: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:462/proxy/: tls qux (200; 9.893684ms)
Jul 31 06:28:50.526: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/proxy-service-cwx5p:portname1/proxy/: foo (200; 9.8541ms)
Jul 31 06:28:50.526: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/proxy-service-cwx5p:portname2/proxy/: bar (200; 9.915246ms)
Jul 31 06:28:50.529: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:462/proxy/: tls qux (200; 3.091574ms)
Jul 31 06:28:50.530: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb/proxy/rewriteme"... (200; 2.960185ms)
Jul 31 06:28:50.538: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/proxy-service-cwx5p:portname2/proxy/: bar (200; 10.747423ms)
Jul 31 06:28:50.538: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:460/proxy/: tls baz (200; 10.671546ms)
Jul 31 06:28:50.538: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:1080/proxy/rewri... (200; 11.787874ms)
Jul 31 06:28:50.539: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/https:proxy-service-cwx5p:tlsportname1/proxy/: tls baz (200; 11.313465ms)
Jul 31 06:28:50.539: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/https:proxy-service-cwx5p:tlsportname2/proxy/: tls qux (200; 11.231887ms)
Jul 31 06:28:50.539: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:160/proxy/: foo (200; 11.604565ms)
Jul 31 06:28:50.539: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:162/proxy/: bar (200; 12.105824ms)
Jul 31 06:28:50.539: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:1080/proxy/... (200; 11.830476ms)
Jul 31 06:28:50.539: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:443/proxy/... (200; 12.446988ms)
Jul 31 06:28:50.539: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/http:proxy-service-cwx5p:portname1/proxy/: foo (200; 12.015956ms)
Jul 31 06:28:50.539: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:160/proxy/: foo (200; 12.133741ms)
Jul 31 06:28:50.540: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:162/proxy/: bar (200; 12.970233ms)
Jul 31 06:28:50.540: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/proxy-service-cwx5p:portname1/proxy/: foo (200; 12.750388ms)
Jul 31 06:28:50.541: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/http:proxy-service-cwx5p:portname2/proxy/: bar (200; 13.412401ms)
Jul 31 06:28:50.543: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:460/proxy/: tls baz (200; 2.373766ms)
Jul 31 06:28:50.549: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb/proxy/rewriteme"... (200; 7.913933ms)
Jul 31 06:28:50.550: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:162/proxy/: bar (200; 8.336966ms)
Jul 31 06:28:50.550: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:1080/proxy/rewri... (200; 8.475723ms)
Jul 31 06:28:50.550: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:160/proxy/: foo (200; 8.784024ms)
Jul 31 06:28:50.550: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/https:proxy-service-cwx5p:tlsportname1/proxy/: tls baz (200; 9.1132ms)
Jul 31 06:28:50.551: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:443/proxy/... (200; 9.397948ms)
Jul 31 06:28:50.551: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:160/proxy/: foo (200; 9.182988ms)
Jul 31 06:28:50.551: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:462/proxy/: tls qux (200; 9.544433ms)
Jul 31 06:28:50.551: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/http:proxy-service-cwx5p:portname1/proxy/: foo (200; 9.51257ms)
Jul 31 06:28:50.551: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/http:proxy-service-cwx5p:portname2/proxy/: bar (200; 9.557855ms)
Jul 31 06:28:50.551: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/https:proxy-service-cwx5p:tlsportname2/proxy/: tls qux (200; 9.603549ms)
Jul 31 06:28:50.551: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/proxy-service-cwx5p:portname2/proxy/: bar (200; 9.79529ms)
Jul 31 06:28:50.551: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/proxy-service-cwx5p:portname1/proxy/: foo (200; 9.560415ms)
Jul 31 06:28:50.551: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:1080/proxy/... (200; 9.757042ms)
Jul 31 06:28:50.552: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:162/proxy/: bar (200; 10.771694ms)
Jul 31 06:28:50.555: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:162/proxy/: bar (200; 2.573773ms)
Jul 31 06:28:50.555: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:162/proxy/: bar (200; 3.286636ms)
Jul 31 06:28:50.560: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb/proxy/rewriteme"... (200; 7.315009ms)
Jul 31 06:28:50.560: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:443/proxy/... (200; 7.904739ms)
Jul 31 06:28:50.561: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:160/proxy/: foo (200; 7.782946ms)
Jul 31 06:28:50.560: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:1080/proxy/... (200; 7.848754ms)
Jul 31 06:28:50.561: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/https:proxy-service-cwx5p:tlsportname1/proxy/: tls baz (200; 7.779778ms)
Jul 31 06:28:50.561: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:460/proxy/: tls baz (200; 8.121749ms)
Jul 31 06:28:50.561: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:160/proxy/: foo (200; 8.217012ms)
Jul 31 06:28:50.561: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/http:proxy-service-cwx5p:portname1/proxy/: foo (200; 8.371172ms)
Jul 31 06:28:50.561: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:462/proxy/: tls qux (200; 8.038279ms)
Jul 31 06:28:50.562: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:1080/proxy/rewri... (200; 8.890497ms)
Jul 31 06:28:50.562: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/proxy-service-cwx5p:portname2/proxy/: bar (200; 9.520025ms)
Jul 31 06:28:50.562: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/http:proxy-service-cwx5p:portname2/proxy/: bar (200; 9.764498ms)
Jul 31 06:28:50.562: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/https:proxy-service-cwx5p:tlsportname2/proxy/: tls qux (200; 10.168483ms)
Jul 31 06:28:50.562: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/proxy-service-cwx5p:portname1/proxy/: foo (200; 9.895658ms)
Jul 31 06:28:50.570: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:162/proxy/: bar (200; 7.64455ms)
Jul 31 06:28:50.570: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/http:proxy-service-cwx5p:portname1/proxy/: foo (200; 7.261254ms)
Jul 31 06:28:50.570: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/http:proxy-service-cwx5p:portname2/proxy/: bar (200; 7.336006ms)
Jul 31 06:28:50.571: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/https:proxy-service-cwx5p:tlsportname1/proxy/: tls baz (200; 6.48874ms)
Jul 31 06:28:50.571: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/proxy-service-cwx5p:portname1/proxy/: foo (200; 7.925467ms)
Jul 31 06:28:50.571: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:462/proxy/: tls qux (200; 8.194199ms)
Jul 31 06:28:50.571: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:162/proxy/: bar (200; 8.34005ms)
Jul 31 06:28:50.571: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/proxy-service-cwx5p:portname2/proxy/: bar (200; 7.944997ms)
Jul 31 06:28:50.571: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/https:proxy-service-cwx5p:tlsportname2/proxy/: tls qux (200; 8.312949ms)
Jul 31 06:28:50.572: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:160/proxy/: foo (200; 8.4589ms)
Jul 31 06:28:50.572: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb/proxy/rewriteme"... (200; 8.71379ms)
Jul 31 06:28:50.572: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:443/proxy/... (200; 8.777465ms)
Jul 31 06:28:50.572: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:160/proxy/: foo (200; 8.83062ms)
Jul 31 06:28:50.572: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:1080/proxy/... (200; 8.616692ms)
Jul 31 06:28:50.572: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:460/proxy/: tls baz (200; 8.791467ms)
Jul 31 06:28:50.572: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:1080/proxy/rewri... (200; 9.283354ms)
Jul 31 06:28:50.578: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:443/proxy/... (200; 5.213178ms)
Jul 31 06:28:50.580: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:160/proxy/: foo (200; 7.742307ms)
Jul 31 06:28:50.581: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:162/proxy/: bar (200; 8.176761ms)
Jul 31 06:28:50.581: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:1080/proxy/rewri... (200; 8.754395ms)
Jul 31 06:28:50.581: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:1080/proxy/... (200; 8.83866ms)
Jul 31 06:28:50.582: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:460/proxy/: tls baz (200; 8.765842ms)
Jul 31 06:28:50.582: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:462/proxy/: tls qux (200; 8.78382ms)
Jul 31 06:28:50.582: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb/proxy/rewriteme"... (200; 8.840059ms)
Jul 31 06:28:50.582: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:162/proxy/: bar (200; 9.260571ms)
Jul 31 06:28:50.583: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/http:proxy-service-cwx5p:portname1/proxy/: foo (200; 10.248212ms)
Jul 31 06:28:50.583: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/http:proxy-service-cwx5p:portname2/proxy/: bar (200; 10.112132ms)
Jul 31 06:28:50.583: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/https:proxy-service-cwx5p:tlsportname1/proxy/: tls baz (200; 10.02448ms)
Jul 31 06:28:50.583: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/https:proxy-service-cwx5p:tlsportname2/proxy/: tls qux (200; 10.078372ms)
Jul 31 06:28:50.583: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:160/proxy/: foo (200; 9.9638ms)
Jul 31 06:28:50.584: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/proxy-service-cwx5p:portname1/proxy/: foo (200; 11.737023ms)
Jul 31 06:28:50.585: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/proxy-service-cwx5p:portname2/proxy/: bar (200; 12.336667ms)
Jul 31 06:28:50.589: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:460/proxy/: tls baz (200; 4.379019ms)
Jul 31 06:28:50.590: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:160/proxy/: foo (200; 4.294277ms)
Jul 31 06:28:50.592: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:462/proxy/: tls qux (200; 6.768937ms)
Jul 31 06:28:50.592: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:162/proxy/: bar (200; 6.614148ms)
Jul 31 06:28:50.593: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb/proxy/rewriteme"... (200; 7.298406ms)
Jul 31 06:28:50.593: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/http:proxy-service-cwx5p:portname1/proxy/: foo (200; 8.016511ms)
Jul 31 06:28:50.593: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:1080/proxy/... (200; 7.831093ms)
Jul 31 06:28:50.593: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:160/proxy/: foo (200; 8.076686ms)
Jul 31 06:28:50.594: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/http:proxy-service-cwx5p-ljnmb:162/proxy/: bar (200; 8.655968ms)
Jul 31 06:28:50.594: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/proxy-service-cwx5p-ljnmb:1080/proxy/rewri... (200; 8.784343ms)
Jul 31 06:28:50.594: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/https:proxy-service-cwx5p:tlsportname1/proxy/: tls baz (200; 8.640546ms)
Jul 31 06:28:50.594: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-wtkdc/pods/https:proxy-service-cwx5p-ljnmb:443/proxy/... (200; 9.204577ms)
Jul 31 06:28:50.596: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/proxy-service-cwx5p:portname2/proxy/: bar (200; 10.778551ms)
Jul 31 06:28:50.596: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/http:proxy-service-cwx5p:portname2/proxy/: bar (200; 10.803655ms)
Jul 31 06:28:50.596: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/https:proxy-service-cwx5p:tlsportname2/proxy/: tls qux (200; 11.023264ms)
Jul 31 06:28:50.596: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-wtkdc/services/proxy-service-cwx5p:portname1/proxy/: foo (200; 11.110526ms)
STEP: deleting ReplicationController proxy-service-cwx5p in namespace e2e-tests-proxy-wtkdc, will wait for the garbage collector to delete the pods
Jul 31 06:28:50.653: INFO: Deleting ReplicationController proxy-service-cwx5p took: 4.573591ms
Jul 31 06:28:50.754: INFO: Terminating ReplicationController proxy-service-cwx5p pods took: 100.194989ms
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:29:02.754: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-wtkdc" for this suite.
Jul 31 06:29:08.765: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:29:08.820: INFO: namespace: e2e-tests-proxy-wtkdc, resource: bindings, ignored listing per whitelist
Jul 31 06:29:08.834: INFO: namespace e2e-tests-proxy-wtkdc deletion completed in 6.077291652s

• [SLOW TEST:31.641 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:29:08.835: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-ztk7n.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-ztk7n.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-ztk7n.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-ztk7n.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-ztk7n.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-ztk7n.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jul 31 06:29:36.967: INFO: DNS probes using e2e-tests-dns-ztk7n/dns-test-80b07362-b35c-11e9-990e-fe448544ce72 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:29:36.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-ztk7n" for this suite.
Jul 31 06:29:42.985: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:29:42.998: INFO: namespace: e2e-tests-dns-ztk7n, resource: bindings, ignored listing per whitelist
Jul 31 06:29:43.051: INFO: namespace e2e-tests-dns-ztk7n deletion completed in 6.073314701s

• [SLOW TEST:34.216 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:29:43.051: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jul 31 06:29:43.104: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-7w8qc'
Jul 31 06:29:43.204: INFO: stderr: ""
Jul 31 06:29:43.204: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Jul 31 06:29:48.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-7w8qc -o json'
Jul 31 06:29:48.325: INFO: stderr: ""
Jul 31 06:29:48.325: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-07-31T06:29:43Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-7w8qc\",\n        \"resourceVersion\": \"5413\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-7w8qc/pods/e2e-test-nginx-pod\",\n        \"uid\": \"952293f5-b35c-11e9-ac6f-000017003e78\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-2sjgs\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"shushsha-k8s-worker1\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-2sjgs\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-2sjgs\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-07-31T06:29:43Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-07-31T06:29:44Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-07-31T06:29:44Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-07-31T06:29:43Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://249f39ad0164d3ebc086a3ff78d4d1070424985c8977ff9ce7092473b344e985\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-07-31T06:29:44Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"100.100.230.30\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.244.1.53\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-07-31T06:29:43Z\"\n    }\n}\n"
STEP: replace the image in the pod
Jul 31 06:29:48.326: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 replace -f - --namespace=e2e-tests-kubectl-7w8qc'
Jul 31 06:29:48.544: INFO: stderr: ""
Jul 31 06:29:48.545: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
Jul 31 06:29:48.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-7w8qc'
Jul 31 06:29:52.705: INFO: stderr: ""
Jul 31 06:29:52.705: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:29:52.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-7w8qc" for this suite.
Jul 31 06:29:58.718: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:29:58.774: INFO: namespace: e2e-tests-kubectl-7w8qc, resource: bindings, ignored listing per whitelist
Jul 31 06:29:58.801: INFO: namespace e2e-tests-kubectl-7w8qc deletion completed in 6.092971931s

• [SLOW TEST:15.750 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:29:58.801: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jul 31 06:30:01.390: INFO: Successfully updated pod "annotationupdate9e791c0a-b35c-11e9-990e-fe448544ce72"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:30:03.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5hrqr" for this suite.
Jul 31 06:30:25.418: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:30:25.468: INFO: namespace: e2e-tests-projected-5hrqr, resource: bindings, ignored listing per whitelist
Jul 31 06:30:25.486: INFO: namespace e2e-tests-projected-5hrqr deletion completed in 22.077336682s

• [SLOW TEST:26.686 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:30:25.487: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Jul 31 06:30:25.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 --namespace=e2e-tests-kubectl-tqp94 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Jul 31 06:30:26.894: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Jul 31 06:30:26.894: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:30:28.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-tqp94" for this suite.
Jul 31 06:30:34.909: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:30:34.927: INFO: namespace: e2e-tests-kubectl-tqp94, resource: bindings, ignored listing per whitelist
Jul 31 06:30:34.978: INFO: namespace e2e-tests-kubectl-tqp94 deletion completed in 6.076967011s

• [SLOW TEST:9.492 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:30:34.979: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1527
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jul 31 06:30:35.028: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-4fqzl'
Jul 31 06:30:35.110: INFO: stderr: ""
Jul 31 06:30:35.110: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1532
Jul 31 06:30:35.113: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-4fqzl'
Jul 31 06:30:44.844: INFO: stderr: ""
Jul 31 06:30:44.844: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:30:44.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-4fqzl" for this suite.
Jul 31 06:30:50.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:30:50.919: INFO: namespace: e2e-tests-kubectl-4fqzl, resource: bindings, ignored listing per whitelist
Jul 31 06:30:50.923: INFO: namespace e2e-tests-kubectl-4fqzl deletion completed in 6.076704494s

• [SLOW TEST:15.945 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:30:50.924: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-z5xlm
I0731 06:30:50.979590      18 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-z5xlm, replica count: 1
I0731 06:30:52.030065      18 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0731 06:30:53.030348      18 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jul 31 06:30:53.137: INFO: Created: latency-svc-kk7pq
Jul 31 06:30:53.146: INFO: Got endpoints: latency-svc-kk7pq [15.488685ms]
Jul 31 06:30:53.154: INFO: Created: latency-svc-krvvl
Jul 31 06:30:53.158: INFO: Got endpoints: latency-svc-krvvl [11.826074ms]
Jul 31 06:30:53.164: INFO: Created: latency-svc-gn547
Jul 31 06:30:53.169: INFO: Got endpoints: latency-svc-gn547 [21.668243ms]
Jul 31 06:30:53.173: INFO: Created: latency-svc-tmxfk
Jul 31 06:30:53.175: INFO: Got endpoints: latency-svc-tmxfk [27.79654ms]
Jul 31 06:30:53.184: INFO: Created: latency-svc-q6bqv
Jul 31 06:30:53.189: INFO: Got endpoints: latency-svc-q6bqv [19.510686ms]
Jul 31 06:30:53.195: INFO: Created: latency-svc-5qptr
Jul 31 06:30:53.198: INFO: Got endpoints: latency-svc-5qptr [51.132523ms]
Jul 31 06:30:53.205: INFO: Created: latency-svc-wvm4z
Jul 31 06:30:53.207: INFO: Got endpoints: latency-svc-wvm4z [59.730434ms]
Jul 31 06:30:53.217: INFO: Created: latency-svc-hqnm5
Jul 31 06:30:53.220: INFO: Got endpoints: latency-svc-hqnm5 [72.957211ms]
Jul 31 06:30:53.235: INFO: Created: latency-svc-jjvsg
Jul 31 06:30:53.237: INFO: Got endpoints: latency-svc-jjvsg [89.396075ms]
Jul 31 06:30:53.243: INFO: Created: latency-svc-dnchp
Jul 31 06:30:53.245: INFO: Got endpoints: latency-svc-dnchp [96.779173ms]
Jul 31 06:30:53.256: INFO: Created: latency-svc-4fr4n
Jul 31 06:30:53.258: INFO: Got endpoints: latency-svc-4fr4n [110.312279ms]
Jul 31 06:30:53.268: INFO: Created: latency-svc-kcq2g
Jul 31 06:30:53.281: INFO: Got endpoints: latency-svc-kcq2g [132.941298ms]
Jul 31 06:30:53.283: INFO: Created: latency-svc-t8ztn
Jul 31 06:30:53.289: INFO: Got endpoints: latency-svc-t8ztn [143.135097ms]
Jul 31 06:30:53.300: INFO: Created: latency-svc-hf6nn
Jul 31 06:30:53.300: INFO: Got endpoints: latency-svc-hf6nn [152.208243ms]
Jul 31 06:30:53.305: INFO: Created: latency-svc-lntcp
Jul 31 06:30:53.308: INFO: Got endpoints: latency-svc-lntcp [160.65041ms]
Jul 31 06:30:53.314: INFO: Created: latency-svc-9t74m
Jul 31 06:30:53.317: INFO: Got endpoints: latency-svc-9t74m [169.244053ms]
Jul 31 06:30:53.325: INFO: Created: latency-svc-78fr5
Jul 31 06:30:53.329: INFO: Got endpoints: latency-svc-78fr5 [181.20883ms]
Jul 31 06:30:53.336: INFO: Created: latency-svc-s6j88
Jul 31 06:30:53.341: INFO: Got endpoints: latency-svc-s6j88 [182.975749ms]
Jul 31 06:30:53.347: INFO: Created: latency-svc-26x5g
Jul 31 06:30:53.351: INFO: Got endpoints: latency-svc-26x5g [175.781076ms]
Jul 31 06:30:53.365: INFO: Created: latency-svc-xvswd
Jul 31 06:30:53.370: INFO: Got endpoints: latency-svc-xvswd [180.992391ms]
Jul 31 06:30:53.375: INFO: Created: latency-svc-8z9fk
Jul 31 06:30:53.379: INFO: Got endpoints: latency-svc-8z9fk [181.214814ms]
Jul 31 06:30:53.393: INFO: Created: latency-svc-qqswr
Jul 31 06:30:53.397: INFO: Got endpoints: latency-svc-qqswr [190.012264ms]
Jul 31 06:30:53.405: INFO: Created: latency-svc-f6ngb
Jul 31 06:30:53.410: INFO: Got endpoints: latency-svc-f6ngb [189.403182ms]
Jul 31 06:30:53.413: INFO: Created: latency-svc-qb7fv
Jul 31 06:30:53.417: INFO: Got endpoints: latency-svc-qb7fv [179.855639ms]
Jul 31 06:30:53.424: INFO: Created: latency-svc-whx69
Jul 31 06:30:53.426: INFO: Got endpoints: latency-svc-whx69 [181.789758ms]
Jul 31 06:30:53.433: INFO: Created: latency-svc-ldhsn
Jul 31 06:30:53.435: INFO: Got endpoints: latency-svc-ldhsn [177.391714ms]
Jul 31 06:30:53.446: INFO: Created: latency-svc-9b8qj
Jul 31 06:30:53.448: INFO: Got endpoints: latency-svc-9b8qj [167.850796ms]
Jul 31 06:30:53.460: INFO: Created: latency-svc-8f48q
Jul 31 06:30:53.460: INFO: Got endpoints: latency-svc-8f48q [170.416488ms]
Jul 31 06:30:53.466: INFO: Created: latency-svc-stfhr
Jul 31 06:30:53.469: INFO: Got endpoints: latency-svc-stfhr [169.141154ms]
Jul 31 06:30:53.479: INFO: Created: latency-svc-8ff6x
Jul 31 06:30:53.483: INFO: Got endpoints: latency-svc-8ff6x [174.226434ms]
Jul 31 06:30:53.491: INFO: Created: latency-svc-h9mmr
Jul 31 06:30:53.518: INFO: Got endpoints: latency-svc-h9mmr [201.57516ms]
Jul 31 06:30:53.555: INFO: Created: latency-svc-t2vfb
Jul 31 06:30:53.567: INFO: Got endpoints: latency-svc-t2vfb [238.104346ms]
Jul 31 06:30:53.575: INFO: Created: latency-svc-mgrpb
Jul 31 06:30:53.575: INFO: Got endpoints: latency-svc-mgrpb [234.625035ms]
Jul 31 06:30:53.581: INFO: Created: latency-svc-sbch2
Jul 31 06:30:53.584: INFO: Got endpoints: latency-svc-sbch2 [232.200166ms]
Jul 31 06:30:53.588: INFO: Created: latency-svc-nmpfn
Jul 31 06:30:53.594: INFO: Got endpoints: latency-svc-nmpfn [224.348685ms]
Jul 31 06:30:53.597: INFO: Created: latency-svc-d2xd5
Jul 31 06:30:53.601: INFO: Got endpoints: latency-svc-d2xd5 [222.373449ms]
Jul 31 06:30:53.608: INFO: Created: latency-svc-dv649
Jul 31 06:30:53.612: INFO: Got endpoints: latency-svc-dv649 [215.088579ms]
Jul 31 06:30:53.626: INFO: Created: latency-svc-655mx
Jul 31 06:30:53.633: INFO: Got endpoints: latency-svc-655mx [223.76385ms]
Jul 31 06:30:53.642: INFO: Created: latency-svc-tdz6r
Jul 31 06:30:53.642: INFO: Got endpoints: latency-svc-tdz6r [225.165962ms]
Jul 31 06:30:53.650: INFO: Created: latency-svc-4z4wd
Jul 31 06:30:53.652: INFO: Got endpoints: latency-svc-4z4wd [226.003921ms]
Jul 31 06:30:53.662: INFO: Created: latency-svc-qdhbs
Jul 31 06:30:53.685: INFO: Created: latency-svc-7pxgm
Jul 31 06:30:53.692: INFO: Got endpoints: latency-svc-qdhbs [256.343498ms]
Jul 31 06:30:53.696: INFO: Created: latency-svc-tvnrw
Jul 31 06:30:53.705: INFO: Created: latency-svc-4t2cr
Jul 31 06:30:53.717: INFO: Created: latency-svc-dtdx9
Jul 31 06:30:53.744: INFO: Got endpoints: latency-svc-7pxgm [295.120599ms]
Jul 31 06:30:53.744: INFO: Created: latency-svc-nc9pv
Jul 31 06:30:53.754: INFO: Created: latency-svc-zswf4
Jul 31 06:30:53.763: INFO: Created: latency-svc-nf2gc
Jul 31 06:30:53.770: INFO: Created: latency-svc-frjfz
Jul 31 06:30:53.780: INFO: Created: latency-svc-rqd8p
Jul 31 06:30:53.787: INFO: Created: latency-svc-llkmf
Jul 31 06:30:53.793: INFO: Got endpoints: latency-svc-tvnrw [333.512664ms]
Jul 31 06:30:53.794: INFO: Created: latency-svc-6b7qr
Jul 31 06:30:53.803: INFO: Created: latency-svc-jwkh6
Jul 31 06:30:53.810: INFO: Created: latency-svc-9n778
Jul 31 06:30:53.817: INFO: Created: latency-svc-6zs9g
Jul 31 06:30:53.825: INFO: Created: latency-svc-g2rc6
Jul 31 06:30:53.856: INFO: Created: latency-svc-b2jph
Jul 31 06:30:53.858: INFO: Got endpoints: latency-svc-4t2cr [388.370659ms]
Jul 31 06:30:53.861: INFO: Created: latency-svc-wczll
Jul 31 06:30:53.871: INFO: Created: latency-svc-hxwk5
Jul 31 06:30:53.891: INFO: Got endpoints: latency-svc-dtdx9 [408.054364ms]
Jul 31 06:30:53.901: INFO: Created: latency-svc-cmwq6
Jul 31 06:30:53.941: INFO: Got endpoints: latency-svc-nc9pv [422.038682ms]
Jul 31 06:30:53.951: INFO: Created: latency-svc-sm7tg
Jul 31 06:30:53.991: INFO: Got endpoints: latency-svc-zswf4 [424.311319ms]
Jul 31 06:30:54.007: INFO: Created: latency-svc-8dmch
Jul 31 06:30:54.041: INFO: Got endpoints: latency-svc-nf2gc [465.106139ms]
Jul 31 06:30:54.050: INFO: Created: latency-svc-29tb6
Jul 31 06:30:54.091: INFO: Got endpoints: latency-svc-frjfz [507.045972ms]
Jul 31 06:30:54.100: INFO: Created: latency-svc-ds586
Jul 31 06:30:54.141: INFO: Got endpoints: latency-svc-rqd8p [547.132932ms]
Jul 31 06:30:54.152: INFO: Created: latency-svc-29sb5
Jul 31 06:30:54.191: INFO: Got endpoints: latency-svc-llkmf [589.978289ms]
Jul 31 06:30:54.202: INFO: Created: latency-svc-xw2tm
Jul 31 06:30:54.241: INFO: Got endpoints: latency-svc-6b7qr [628.479651ms]
Jul 31 06:30:54.249: INFO: Created: latency-svc-vlqk4
Jul 31 06:30:54.291: INFO: Got endpoints: latency-svc-jwkh6 [657.074977ms]
Jul 31 06:30:54.302: INFO: Created: latency-svc-65pgk
Jul 31 06:30:54.341: INFO: Got endpoints: latency-svc-9n778 [698.764896ms]
Jul 31 06:30:54.350: INFO: Created: latency-svc-6j8v8
Jul 31 06:30:54.391: INFO: Got endpoints: latency-svc-6zs9g [738.834979ms]
Jul 31 06:30:54.401: INFO: Created: latency-svc-hngtb
Jul 31 06:30:54.441: INFO: Got endpoints: latency-svc-g2rc6 [749.614663ms]
Jul 31 06:30:54.454: INFO: Created: latency-svc-8g9km
Jul 31 06:30:54.491: INFO: Got endpoints: latency-svc-b2jph [747.31869ms]
Jul 31 06:30:54.504: INFO: Created: latency-svc-gtcqk
Jul 31 06:30:54.541: INFO: Got endpoints: latency-svc-wczll [747.15479ms]
Jul 31 06:30:54.552: INFO: Created: latency-svc-7wfpk
Jul 31 06:30:54.594: INFO: Got endpoints: latency-svc-hxwk5 [735.857975ms]
Jul 31 06:30:54.609: INFO: Created: latency-svc-wb99b
Jul 31 06:30:54.641: INFO: Got endpoints: latency-svc-cmwq6 [749.988681ms]
Jul 31 06:30:54.652: INFO: Created: latency-svc-nfnwt
Jul 31 06:30:54.691: INFO: Got endpoints: latency-svc-sm7tg [749.923811ms]
Jul 31 06:30:54.708: INFO: Created: latency-svc-2lwjb
Jul 31 06:30:54.741: INFO: Got endpoints: latency-svc-8dmch [749.540411ms]
Jul 31 06:30:54.754: INFO: Created: latency-svc-hj8ld
Jul 31 06:30:54.791: INFO: Got endpoints: latency-svc-29tb6 [750.699535ms]
Jul 31 06:30:54.800: INFO: Created: latency-svc-zjt88
Jul 31 06:30:54.841: INFO: Got endpoints: latency-svc-ds586 [750.087139ms]
Jul 31 06:30:54.853: INFO: Created: latency-svc-l4zgm
Jul 31 06:30:54.892: INFO: Got endpoints: latency-svc-29sb5 [750.883858ms]
Jul 31 06:30:54.904: INFO: Created: latency-svc-jbgn7
Jul 31 06:30:54.941: INFO: Got endpoints: latency-svc-xw2tm [749.535644ms]
Jul 31 06:30:54.953: INFO: Created: latency-svc-5h9nf
Jul 31 06:30:54.991: INFO: Got endpoints: latency-svc-vlqk4 [750.473203ms]
Jul 31 06:30:55.004: INFO: Created: latency-svc-std8t
Jul 31 06:30:55.042: INFO: Got endpoints: latency-svc-65pgk [750.890586ms]
Jul 31 06:30:55.055: INFO: Created: latency-svc-xxfsd
Jul 31 06:30:55.091: INFO: Got endpoints: latency-svc-6j8v8 [750.233482ms]
Jul 31 06:30:55.103: INFO: Created: latency-svc-nfp5l
Jul 31 06:30:55.141: INFO: Got endpoints: latency-svc-hngtb [749.807162ms]
Jul 31 06:30:55.155: INFO: Created: latency-svc-rwp4k
Jul 31 06:30:55.191: INFO: Got endpoints: latency-svc-8g9km [749.476579ms]
Jul 31 06:30:55.203: INFO: Created: latency-svc-cvn5h
Jul 31 06:30:55.241: INFO: Got endpoints: latency-svc-gtcqk [750.096401ms]
Jul 31 06:30:55.251: INFO: Created: latency-svc-jj5h8
Jul 31 06:30:55.291: INFO: Got endpoints: latency-svc-7wfpk [750.316687ms]
Jul 31 06:30:55.304: INFO: Created: latency-svc-5djfs
Jul 31 06:30:55.342: INFO: Got endpoints: latency-svc-wb99b [748.131157ms]
Jul 31 06:30:55.393: INFO: Created: latency-svc-ns888
Jul 31 06:30:55.404: INFO: Got endpoints: latency-svc-nfnwt [763.132739ms]
Jul 31 06:30:55.419: INFO: Created: latency-svc-28wpq
Jul 31 06:30:55.441: INFO: Got endpoints: latency-svc-2lwjb [750.822711ms]
Jul 31 06:30:55.461: INFO: Created: latency-svc-w2796
Jul 31 06:30:55.491: INFO: Got endpoints: latency-svc-hj8ld [749.961933ms]
Jul 31 06:30:55.500: INFO: Created: latency-svc-dg7vv
Jul 31 06:30:55.541: INFO: Got endpoints: latency-svc-zjt88 [749.172944ms]
Jul 31 06:30:55.557: INFO: Created: latency-svc-drl5b
Jul 31 06:30:55.592: INFO: Got endpoints: latency-svc-l4zgm [750.606173ms]
Jul 31 06:30:55.601: INFO: Created: latency-svc-fwrsj
Jul 31 06:30:55.642: INFO: Got endpoints: latency-svc-jbgn7 [749.285398ms]
Jul 31 06:30:55.666: INFO: Created: latency-svc-rrd5j
Jul 31 06:30:55.691: INFO: Got endpoints: latency-svc-5h9nf [749.79518ms]
Jul 31 06:30:55.703: INFO: Created: latency-svc-rvv6z
Jul 31 06:30:55.740: INFO: Got endpoints: latency-svc-std8t [749.216656ms]
Jul 31 06:30:55.775: INFO: Created: latency-svc-4zhh5
Jul 31 06:30:55.791: INFO: Got endpoints: latency-svc-xxfsd [749.235119ms]
Jul 31 06:30:55.806: INFO: Created: latency-svc-l9dlk
Jul 31 06:30:55.842: INFO: Got endpoints: latency-svc-nfp5l [750.948352ms]
Jul 31 06:30:55.856: INFO: Created: latency-svc-ccdpf
Jul 31 06:30:55.891: INFO: Got endpoints: latency-svc-rwp4k [749.897434ms]
Jul 31 06:30:55.904: INFO: Created: latency-svc-7tfj6
Jul 31 06:30:55.941: INFO: Got endpoints: latency-svc-cvn5h [749.742417ms]
Jul 31 06:30:55.953: INFO: Created: latency-svc-gmn87
Jul 31 06:30:55.991: INFO: Got endpoints: latency-svc-jj5h8 [749.550805ms]
Jul 31 06:30:56.001: INFO: Created: latency-svc-5whqb
Jul 31 06:30:56.041: INFO: Got endpoints: latency-svc-5djfs [750.100717ms]
Jul 31 06:30:56.056: INFO: Created: latency-svc-nlfhq
Jul 31 06:30:56.092: INFO: Got endpoints: latency-svc-ns888 [750.244895ms]
Jul 31 06:30:56.104: INFO: Created: latency-svc-tnkdc
Jul 31 06:30:56.142: INFO: Got endpoints: latency-svc-28wpq [737.874928ms]
Jul 31 06:30:56.156: INFO: Created: latency-svc-84jb8
Jul 31 06:30:56.191: INFO: Got endpoints: latency-svc-w2796 [749.736408ms]
Jul 31 06:30:56.203: INFO: Created: latency-svc-kchph
Jul 31 06:30:56.241: INFO: Got endpoints: latency-svc-dg7vv [749.569905ms]
Jul 31 06:30:56.257: INFO: Created: latency-svc-jwh72
Jul 31 06:30:56.291: INFO: Got endpoints: latency-svc-drl5b [749.959101ms]
Jul 31 06:30:56.313: INFO: Created: latency-svc-2wsbl
Jul 31 06:30:56.341: INFO: Got endpoints: latency-svc-fwrsj [749.117309ms]
Jul 31 06:30:56.354: INFO: Created: latency-svc-dsfnv
Jul 31 06:30:56.391: INFO: Got endpoints: latency-svc-rrd5j [749.358786ms]
Jul 31 06:30:56.400: INFO: Created: latency-svc-5wqrt
Jul 31 06:30:56.441: INFO: Got endpoints: latency-svc-rvv6z [750.24957ms]
Jul 31 06:30:56.452: INFO: Created: latency-svc-ghjp9
Jul 31 06:30:56.491: INFO: Got endpoints: latency-svc-4zhh5 [750.733781ms]
Jul 31 06:30:56.501: INFO: Created: latency-svc-8qrzx
Jul 31 06:30:56.541: INFO: Got endpoints: latency-svc-l9dlk [750.33688ms]
Jul 31 06:30:56.554: INFO: Created: latency-svc-jp6vb
Jul 31 06:30:56.591: INFO: Got endpoints: latency-svc-ccdpf [749.434521ms]
Jul 31 06:30:56.600: INFO: Created: latency-svc-ph4l6
Jul 31 06:30:56.641: INFO: Got endpoints: latency-svc-7tfj6 [749.401034ms]
Jul 31 06:30:56.650: INFO: Created: latency-svc-7pnpk
Jul 31 06:30:56.691: INFO: Got endpoints: latency-svc-gmn87 [750.592632ms]
Jul 31 06:30:56.701: INFO: Created: latency-svc-tn2sd
Jul 31 06:30:56.741: INFO: Got endpoints: latency-svc-5whqb [750.020761ms]
Jul 31 06:30:56.750: INFO: Created: latency-svc-dm2g6
Jul 31 06:30:56.791: INFO: Got endpoints: latency-svc-nlfhq [749.644599ms]
Jul 31 06:30:56.804: INFO: Created: latency-svc-9g6n5
Jul 31 06:30:56.841: INFO: Got endpoints: latency-svc-tnkdc [748.796513ms]
Jul 31 06:30:56.850: INFO: Created: latency-svc-bhfwn
Jul 31 06:30:56.891: INFO: Got endpoints: latency-svc-84jb8 [749.004176ms]
Jul 31 06:30:56.903: INFO: Created: latency-svc-5zfnq
Jul 31 06:30:56.941: INFO: Got endpoints: latency-svc-kchph [749.80322ms]
Jul 31 06:30:56.955: INFO: Created: latency-svc-xqplp
Jul 31 06:30:56.991: INFO: Got endpoints: latency-svc-jwh72 [750.100281ms]
Jul 31 06:30:57.001: INFO: Created: latency-svc-sgwch
Jul 31 06:30:57.041: INFO: Got endpoints: latency-svc-2wsbl [750.761953ms]
Jul 31 06:30:57.060: INFO: Created: latency-svc-87zgk
Jul 31 06:30:57.091: INFO: Got endpoints: latency-svc-dsfnv [749.984873ms]
Jul 31 06:30:57.102: INFO: Created: latency-svc-vbfx2
Jul 31 06:30:57.141: INFO: Got endpoints: latency-svc-5wqrt [749.473562ms]
Jul 31 06:30:57.160: INFO: Created: latency-svc-ptbfp
Jul 31 06:30:57.190: INFO: Got endpoints: latency-svc-ghjp9 [749.088342ms]
Jul 31 06:30:57.199: INFO: Created: latency-svc-fqpd8
Jul 31 06:30:57.244: INFO: Got endpoints: latency-svc-8qrzx [752.528219ms]
Jul 31 06:30:57.254: INFO: Created: latency-svc-jcdn8
Jul 31 06:30:57.291: INFO: Got endpoints: latency-svc-jp6vb [749.370639ms]
Jul 31 06:30:57.300: INFO: Created: latency-svc-ncrvz
Jul 31 06:30:57.340: INFO: Got endpoints: latency-svc-ph4l6 [748.772103ms]
Jul 31 06:30:57.350: INFO: Created: latency-svc-ln9wz
Jul 31 06:30:57.391: INFO: Got endpoints: latency-svc-7pnpk [750.569425ms]
Jul 31 06:30:57.402: INFO: Created: latency-svc-qqpkt
Jul 31 06:30:57.441: INFO: Got endpoints: latency-svc-tn2sd [749.562613ms]
Jul 31 06:30:57.456: INFO: Created: latency-svc-jjz4f
Jul 31 06:30:57.492: INFO: Got endpoints: latency-svc-dm2g6 [750.607706ms]
Jul 31 06:30:57.500: INFO: Created: latency-svc-ls2n4
Jul 31 06:30:57.541: INFO: Got endpoints: latency-svc-9g6n5 [750.021254ms]
Jul 31 06:30:57.561: INFO: Created: latency-svc-xm95p
Jul 31 06:30:57.591: INFO: Got endpoints: latency-svc-bhfwn [750.205519ms]
Jul 31 06:30:57.601: INFO: Created: latency-svc-x28wk
Jul 31 06:30:57.641: INFO: Got endpoints: latency-svc-5zfnq [749.591844ms]
Jul 31 06:30:57.652: INFO: Created: latency-svc-f7ntc
Jul 31 06:30:57.691: INFO: Got endpoints: latency-svc-xqplp [749.477385ms]
Jul 31 06:30:57.710: INFO: Created: latency-svc-v7mlb
Jul 31 06:30:57.741: INFO: Got endpoints: latency-svc-sgwch [750.271528ms]
Jul 31 06:30:57.753: INFO: Created: latency-svc-dml4c
Jul 31 06:30:57.791: INFO: Got endpoints: latency-svc-87zgk [749.503599ms]
Jul 31 06:30:57.803: INFO: Created: latency-svc-kkvbq
Jul 31 06:30:57.842: INFO: Got endpoints: latency-svc-vbfx2 [750.901216ms]
Jul 31 06:30:57.856: INFO: Created: latency-svc-sdmpw
Jul 31 06:30:57.891: INFO: Got endpoints: latency-svc-ptbfp [750.242337ms]
Jul 31 06:30:57.904: INFO: Created: latency-svc-gvfv2
Jul 31 06:30:57.941: INFO: Got endpoints: latency-svc-fqpd8 [750.749396ms]
Jul 31 06:30:57.951: INFO: Created: latency-svc-sprbm
Jul 31 06:30:57.991: INFO: Got endpoints: latency-svc-jcdn8 [747.479832ms]
Jul 31 06:30:58.003: INFO: Created: latency-svc-sb6sn
Jul 31 06:30:58.041: INFO: Got endpoints: latency-svc-ncrvz [749.756746ms]
Jul 31 06:30:58.056: INFO: Created: latency-svc-ntws2
Jul 31 06:30:58.091: INFO: Got endpoints: latency-svc-ln9wz [750.616262ms]
Jul 31 06:30:58.101: INFO: Created: latency-svc-shf9f
Jul 31 06:30:58.141: INFO: Got endpoints: latency-svc-qqpkt [749.206259ms]
Jul 31 06:30:58.191: INFO: Created: latency-svc-4rx2f
Jul 31 06:30:58.194: INFO: Got endpoints: latency-svc-jjz4f [752.696395ms]
Jul 31 06:30:58.205: INFO: Created: latency-svc-lxmp7
Jul 31 06:30:58.241: INFO: Got endpoints: latency-svc-ls2n4 [749.454634ms]
Jul 31 06:30:58.250: INFO: Created: latency-svc-4w9cj
Jul 31 06:30:58.296: INFO: Got endpoints: latency-svc-xm95p [755.278645ms]
Jul 31 06:30:58.306: INFO: Created: latency-svc-98sdz
Jul 31 06:30:58.341: INFO: Got endpoints: latency-svc-x28wk [749.200418ms]
Jul 31 06:30:58.349: INFO: Created: latency-svc-242xz
Jul 31 06:30:58.391: INFO: Got endpoints: latency-svc-f7ntc [750.187371ms]
Jul 31 06:30:58.403: INFO: Created: latency-svc-mknm4
Jul 31 06:30:58.441: INFO: Got endpoints: latency-svc-v7mlb [749.676113ms]
Jul 31 06:30:58.451: INFO: Created: latency-svc-sd74v
Jul 31 06:30:58.491: INFO: Got endpoints: latency-svc-dml4c [749.664061ms]
Jul 31 06:30:58.499: INFO: Created: latency-svc-srtlp
Jul 31 06:30:58.541: INFO: Got endpoints: latency-svc-kkvbq [749.736378ms]
Jul 31 06:30:58.550: INFO: Created: latency-svc-lwmk7
Jul 31 06:30:58.591: INFO: Got endpoints: latency-svc-sdmpw [749.037324ms]
Jul 31 06:30:58.603: INFO: Created: latency-svc-g5bhv
Jul 31 06:30:58.642: INFO: Got endpoints: latency-svc-gvfv2 [751.103501ms]
Jul 31 06:30:58.655: INFO: Created: latency-svc-tjbgk
Jul 31 06:30:58.692: INFO: Got endpoints: latency-svc-sprbm [750.96425ms]
Jul 31 06:30:58.704: INFO: Created: latency-svc-swp72
Jul 31 06:30:58.741: INFO: Got endpoints: latency-svc-sb6sn [749.421602ms]
Jul 31 06:30:58.753: INFO: Created: latency-svc-tzfgv
Jul 31 06:30:58.793: INFO: Got endpoints: latency-svc-ntws2 [752.598494ms]
Jul 31 06:30:58.805: INFO: Created: latency-svc-qnns9
Jul 31 06:30:58.841: INFO: Got endpoints: latency-svc-shf9f [749.762416ms]
Jul 31 06:30:58.850: INFO: Created: latency-svc-h9bjr
Jul 31 06:30:58.891: INFO: Got endpoints: latency-svc-4rx2f [750.37481ms]
Jul 31 06:30:58.901: INFO: Created: latency-svc-8nm9x
Jul 31 06:30:58.940: INFO: Got endpoints: latency-svc-lxmp7 [746.741581ms]
Jul 31 06:30:58.951: INFO: Created: latency-svc-947mq
Jul 31 06:30:58.991: INFO: Got endpoints: latency-svc-4w9cj [749.494183ms]
Jul 31 06:30:59.001: INFO: Created: latency-svc-2qljv
Jul 31 06:30:59.041: INFO: Got endpoints: latency-svc-98sdz [744.234197ms]
Jul 31 06:30:59.056: INFO: Created: latency-svc-mfxwf
Jul 31 06:30:59.091: INFO: Got endpoints: latency-svc-242xz [750.190217ms]
Jul 31 06:30:59.106: INFO: Created: latency-svc-lrmnf
Jul 31 06:30:59.141: INFO: Got endpoints: latency-svc-mknm4 [749.839635ms]
Jul 31 06:30:59.150: INFO: Created: latency-svc-vh6d5
Jul 31 06:30:59.191: INFO: Got endpoints: latency-svc-sd74v [750.304689ms]
Jul 31 06:30:59.200: INFO: Created: latency-svc-tqm7c
Jul 31 06:30:59.241: INFO: Got endpoints: latency-svc-srtlp [749.702662ms]
Jul 31 06:30:59.251: INFO: Created: latency-svc-bk2qn
Jul 31 06:30:59.291: INFO: Got endpoints: latency-svc-lwmk7 [749.691088ms]
Jul 31 06:30:59.299: INFO: Created: latency-svc-jk99x
Jul 31 06:30:59.343: INFO: Got endpoints: latency-svc-g5bhv [752.01321ms]
Jul 31 06:30:59.355: INFO: Created: latency-svc-8m7v2
Jul 31 06:30:59.391: INFO: Got endpoints: latency-svc-tjbgk [748.730632ms]
Jul 31 06:30:59.402: INFO: Created: latency-svc-gwcfh
Jul 31 06:30:59.442: INFO: Got endpoints: latency-svc-swp72 [749.288805ms]
Jul 31 06:30:59.454: INFO: Created: latency-svc-d4h8v
Jul 31 06:30:59.491: INFO: Got endpoints: latency-svc-tzfgv [750.206804ms]
Jul 31 06:30:59.501: INFO: Created: latency-svc-kwlq7
Jul 31 06:30:59.541: INFO: Got endpoints: latency-svc-qnns9 [747.420823ms]
Jul 31 06:30:59.554: INFO: Created: latency-svc-mmrl2
Jul 31 06:30:59.591: INFO: Got endpoints: latency-svc-h9bjr [750.312494ms]
Jul 31 06:30:59.603: INFO: Created: latency-svc-s9dmg
Jul 31 06:30:59.642: INFO: Got endpoints: latency-svc-8nm9x [750.595482ms]
Jul 31 06:30:59.657: INFO: Created: latency-svc-f9kwt
Jul 31 06:30:59.691: INFO: Got endpoints: latency-svc-947mq [750.190643ms]
Jul 31 06:30:59.702: INFO: Created: latency-svc-82cmf
Jul 31 06:30:59.741: INFO: Got endpoints: latency-svc-2qljv [750.195526ms]
Jul 31 06:30:59.751: INFO: Created: latency-svc-5ghnf
Jul 31 06:30:59.791: INFO: Got endpoints: latency-svc-mfxwf [750.120762ms]
Jul 31 06:30:59.802: INFO: Created: latency-svc-qkg2v
Jul 31 06:30:59.841: INFO: Got endpoints: latency-svc-lrmnf [750.391065ms]
Jul 31 06:30:59.853: INFO: Created: latency-svc-8db77
Jul 31 06:30:59.892: INFO: Got endpoints: latency-svc-vh6d5 [750.516608ms]
Jul 31 06:30:59.901: INFO: Created: latency-svc-95dzk
Jul 31 06:30:59.941: INFO: Got endpoints: latency-svc-tqm7c [749.987573ms]
Jul 31 06:30:59.951: INFO: Created: latency-svc-6jg2k
Jul 31 06:30:59.991: INFO: Got endpoints: latency-svc-bk2qn [749.981485ms]
Jul 31 06:31:00.002: INFO: Created: latency-svc-7fgwm
Jul 31 06:31:00.041: INFO: Got endpoints: latency-svc-jk99x [750.282163ms]
Jul 31 06:31:00.064: INFO: Created: latency-svc-dskzq
Jul 31 06:31:00.091: INFO: Got endpoints: latency-svc-8m7v2 [747.554811ms]
Jul 31 06:31:00.101: INFO: Created: latency-svc-d6c46
Jul 31 06:31:00.141: INFO: Got endpoints: latency-svc-gwcfh [749.540426ms]
Jul 31 06:31:00.149: INFO: Created: latency-svc-g5gxk
Jul 31 06:31:00.192: INFO: Got endpoints: latency-svc-d4h8v [750.066683ms]
Jul 31 06:31:00.201: INFO: Created: latency-svc-6zt45
Jul 31 06:31:00.241: INFO: Got endpoints: latency-svc-kwlq7 [749.773184ms]
Jul 31 06:31:00.252: INFO: Created: latency-svc-dwd78
Jul 31 06:31:00.291: INFO: Got endpoints: latency-svc-mmrl2 [750.112486ms]
Jul 31 06:31:00.300: INFO: Created: latency-svc-74nqw
Jul 31 06:31:00.340: INFO: Got endpoints: latency-svc-s9dmg [748.98751ms]
Jul 31 06:31:00.353: INFO: Created: latency-svc-jvzpb
Jul 31 06:31:00.391: INFO: Got endpoints: latency-svc-f9kwt [749.187705ms]
Jul 31 06:31:00.401: INFO: Created: latency-svc-7nnz2
Jul 31 06:31:00.441: INFO: Got endpoints: latency-svc-82cmf [750.430723ms]
Jul 31 06:31:00.451: INFO: Created: latency-svc-m8pk6
Jul 31 06:31:00.492: INFO: Got endpoints: latency-svc-5ghnf [750.328063ms]
Jul 31 06:31:00.503: INFO: Created: latency-svc-g5l8t
Jul 31 06:31:00.541: INFO: Got endpoints: latency-svc-qkg2v [749.7502ms]
Jul 31 06:31:00.550: INFO: Created: latency-svc-r575g
Jul 31 06:31:00.592: INFO: Got endpoints: latency-svc-8db77 [750.156738ms]
Jul 31 06:31:00.602: INFO: Created: latency-svc-7xmkt
Jul 31 06:31:00.641: INFO: Got endpoints: latency-svc-95dzk [749.382981ms]
Jul 31 06:31:00.653: INFO: Created: latency-svc-g8dz6
Jul 31 06:31:00.691: INFO: Got endpoints: latency-svc-6jg2k [749.870858ms]
Jul 31 06:31:00.703: INFO: Created: latency-svc-plfg5
Jul 31 06:31:00.741: INFO: Got endpoints: latency-svc-7fgwm [749.85792ms]
Jul 31 06:31:00.750: INFO: Created: latency-svc-h9qpv
Jul 31 06:31:00.791: INFO: Got endpoints: latency-svc-dskzq [749.581028ms]
Jul 31 06:31:00.801: INFO: Created: latency-svc-g5jwb
Jul 31 06:31:00.841: INFO: Got endpoints: latency-svc-d6c46 [750.482574ms]
Jul 31 06:31:00.851: INFO: Created: latency-svc-tszq9
Jul 31 06:31:00.891: INFO: Got endpoints: latency-svc-g5gxk [750.39554ms]
Jul 31 06:31:00.900: INFO: Created: latency-svc-ggfxz
Jul 31 06:31:00.941: INFO: Got endpoints: latency-svc-6zt45 [749.434275ms]
Jul 31 06:31:00.952: INFO: Created: latency-svc-cjt2p
Jul 31 06:31:00.992: INFO: Got endpoints: latency-svc-dwd78 [750.425981ms]
Jul 31 06:31:01.041: INFO: Got endpoints: latency-svc-74nqw [749.665853ms]
Jul 31 06:31:01.091: INFO: Got endpoints: latency-svc-jvzpb [750.438775ms]
Jul 31 06:31:01.141: INFO: Got endpoints: latency-svc-7nnz2 [749.525197ms]
Jul 31 06:31:01.191: INFO: Got endpoints: latency-svc-m8pk6 [749.409362ms]
Jul 31 06:31:01.241: INFO: Got endpoints: latency-svc-g5l8t [749.406863ms]
Jul 31 06:31:01.291: INFO: Got endpoints: latency-svc-r575g [750.134488ms]
Jul 31 06:31:01.341: INFO: Got endpoints: latency-svc-7xmkt [749.068672ms]
Jul 31 06:31:01.391: INFO: Got endpoints: latency-svc-g8dz6 [750.192763ms]
Jul 31 06:31:01.441: INFO: Got endpoints: latency-svc-plfg5 [749.86165ms]
Jul 31 06:31:01.492: INFO: Got endpoints: latency-svc-h9qpv [750.316234ms]
Jul 31 06:31:01.541: INFO: Got endpoints: latency-svc-g5jwb [750.18917ms]
Jul 31 06:31:01.599: INFO: Got endpoints: latency-svc-tszq9 [757.593123ms]
Jul 31 06:31:01.655: INFO: Got endpoints: latency-svc-ggfxz [763.469507ms]
Jul 31 06:31:01.691: INFO: Got endpoints: latency-svc-cjt2p [749.927577ms]
Jul 31 06:31:01.691: INFO: Latencies: [11.826074ms 19.510686ms 21.668243ms 27.79654ms 51.132523ms 59.730434ms 72.957211ms 89.396075ms 96.779173ms 110.312279ms 132.941298ms 143.135097ms 152.208243ms 160.65041ms 167.850796ms 169.141154ms 169.244053ms 170.416488ms 174.226434ms 175.781076ms 177.391714ms 179.855639ms 180.992391ms 181.20883ms 181.214814ms 181.789758ms 182.975749ms 189.403182ms 190.012264ms 201.57516ms 215.088579ms 222.373449ms 223.76385ms 224.348685ms 225.165962ms 226.003921ms 232.200166ms 234.625035ms 238.104346ms 256.343498ms 295.120599ms 333.512664ms 388.370659ms 408.054364ms 422.038682ms 424.311319ms 465.106139ms 507.045972ms 547.132932ms 589.978289ms 628.479651ms 657.074977ms 698.764896ms 735.857975ms 737.874928ms 738.834979ms 744.234197ms 746.741581ms 747.15479ms 747.31869ms 747.420823ms 747.479832ms 747.554811ms 748.131157ms 748.730632ms 748.772103ms 748.796513ms 748.98751ms 749.004176ms 749.037324ms 749.068672ms 749.088342ms 749.117309ms 749.172944ms 749.187705ms 749.200418ms 749.206259ms 749.216656ms 749.235119ms 749.285398ms 749.288805ms 749.358786ms 749.370639ms 749.382981ms 749.401034ms 749.406863ms 749.409362ms 749.421602ms 749.434275ms 749.434521ms 749.454634ms 749.473562ms 749.476579ms 749.477385ms 749.494183ms 749.503599ms 749.525197ms 749.535644ms 749.540411ms 749.540426ms 749.550805ms 749.562613ms 749.569905ms 749.581028ms 749.591844ms 749.614663ms 749.644599ms 749.664061ms 749.665853ms 749.676113ms 749.691088ms 749.702662ms 749.736378ms 749.736408ms 749.742417ms 749.7502ms 749.756746ms 749.762416ms 749.773184ms 749.79518ms 749.80322ms 749.807162ms 749.839635ms 749.85792ms 749.86165ms 749.870858ms 749.897434ms 749.923811ms 749.927577ms 749.959101ms 749.961933ms 749.981485ms 749.984873ms 749.987573ms 749.988681ms 750.020761ms 750.021254ms 750.066683ms 750.087139ms 750.096401ms 750.100281ms 750.100717ms 750.112486ms 750.120762ms 750.134488ms 750.156738ms 750.187371ms 750.18917ms 750.190217ms 750.190643ms 750.192763ms 750.195526ms 750.205519ms 750.206804ms 750.233482ms 750.242337ms 750.244895ms 750.24957ms 750.271528ms 750.282163ms 750.304689ms 750.312494ms 750.316234ms 750.316687ms 750.328063ms 750.33688ms 750.37481ms 750.391065ms 750.39554ms 750.425981ms 750.430723ms 750.438775ms 750.473203ms 750.482574ms 750.516608ms 750.569425ms 750.592632ms 750.595482ms 750.606173ms 750.607706ms 750.616262ms 750.699535ms 750.733781ms 750.749396ms 750.761953ms 750.822711ms 750.883858ms 750.890586ms 750.901216ms 750.948352ms 750.96425ms 751.103501ms 752.01321ms 752.528219ms 752.598494ms 752.696395ms 755.278645ms 757.593123ms 763.132739ms 763.469507ms]
Jul 31 06:31:01.692: INFO: 50 %ile: 749.550805ms
Jul 31 06:31:01.692: INFO: 90 %ile: 750.616262ms
Jul 31 06:31:01.692: INFO: 99 %ile: 763.132739ms
Jul 31 06:31:01.692: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:31:01.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-z5xlm" for this suite.
Jul 31 06:31:33.705: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:31:33.713: INFO: namespace: e2e-tests-svc-latency-z5xlm, resource: bindings, ignored listing per whitelist
Jul 31 06:31:33.771: INFO: namespace e2e-tests-svc-latency-z5xlm deletion completed in 32.075659342s

• [SLOW TEST:42.848 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:31:33.772: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:32:33.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-xbldb" for this suite.
Jul 31 06:32:55.847: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:32:55.877: INFO: namespace: e2e-tests-container-probe-xbldb, resource: bindings, ignored listing per whitelist
Jul 31 06:32:55.918: INFO: namespace e2e-tests-container-probe-xbldb deletion completed in 22.080913869s

• [SLOW TEST:82.146 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:32:55.918: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-080a3ac2-b35d-11e9-990e-fe448544ce72
STEP: Creating a pod to test consume configMaps
Jul 31 06:32:55.979: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-080a96fa-b35d-11e9-990e-fe448544ce72" in namespace "e2e-tests-projected-kcms5" to be "success or failure"
Jul 31 06:32:55.981: INFO: Pod "pod-projected-configmaps-080a96fa-b35d-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 1.836715ms
Jul 31 06:32:57.984: INFO: Pod "pod-projected-configmaps-080a96fa-b35d-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005082608s
STEP: Saw pod success
Jul 31 06:32:57.984: INFO: Pod "pod-projected-configmaps-080a96fa-b35d-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 06:32:57.986: INFO: Trying to get logs from node shushsha-k8s-worker1 pod pod-projected-configmaps-080a96fa-b35d-11e9-990e-fe448544ce72 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jul 31 06:32:57.999: INFO: Waiting for pod pod-projected-configmaps-080a96fa-b35d-11e9-990e-fe448544ce72 to disappear
Jul 31 06:32:58.001: INFO: Pod pod-projected-configmaps-080a96fa-b35d-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:32:58.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-kcms5" for this suite.
Jul 31 06:33:04.013: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:33:04.051: INFO: namespace: e2e-tests-projected-kcms5, resource: bindings, ignored listing per whitelist
Jul 31 06:33:04.080: INFO: namespace e2e-tests-projected-kcms5 deletion completed in 6.075976098s

• [SLOW TEST:8.162 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:33:04.080: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jul 31 06:33:04.139: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0ce78e40-b35d-11e9-990e-fe448544ce72" in namespace "e2e-tests-downward-api-p22xz" to be "success or failure"
Jul 31 06:33:04.141: INFO: Pod "downwardapi-volume-0ce78e40-b35d-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.331686ms
Jul 31 06:33:06.144: INFO: Pod "downwardapi-volume-0ce78e40-b35d-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005289513s
STEP: Saw pod success
Jul 31 06:33:06.144: INFO: Pod "downwardapi-volume-0ce78e40-b35d-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 06:33:06.146: INFO: Trying to get logs from node shushsha-k8s-worker2 pod downwardapi-volume-0ce78e40-b35d-11e9-990e-fe448544ce72 container client-container: <nil>
STEP: delete the pod
Jul 31 06:33:06.162: INFO: Waiting for pod downwardapi-volume-0ce78e40-b35d-11e9-990e-fe448544ce72 to disappear
Jul 31 06:33:06.164: INFO: Pod downwardapi-volume-0ce78e40-b35d-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:33:06.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-p22xz" for this suite.
Jul 31 06:33:12.176: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:33:12.206: INFO: namespace: e2e-tests-downward-api-p22xz, resource: bindings, ignored listing per whitelist
Jul 31 06:33:12.242: INFO: namespace e2e-tests-downward-api-p22xz deletion completed in 6.075521097s

• [SLOW TEST:8.162 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:33:12.242: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Jul 31 06:33:12.301: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-779p2" to be "success or failure"
Jul 31 06:33:12.304: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.375464ms
Jul 31 06:33:14.306: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005103573s
STEP: Saw pod success
Jul 31 06:33:14.307: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Jul 31 06:33:14.309: INFO: Trying to get logs from node shushsha-k8s-worker1 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Jul 31 06:33:14.323: INFO: Waiting for pod pod-host-path-test to disappear
Jul 31 06:33:14.325: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:33:14.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-779p2" for this suite.
Jul 31 06:33:20.335: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:33:20.347: INFO: namespace: e2e-tests-hostpath-779p2, resource: bindings, ignored listing per whitelist
Jul 31 06:33:20.403: INFO: namespace e2e-tests-hostpath-779p2 deletion completed in 6.075713513s

• [SLOW TEST:8.161 seconds]
[sig-storage] HostPath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:33:20.404: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-16a2282d-b35d-11e9-990e-fe448544ce72
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-16a2282d-b35d-11e9-990e-fe448544ce72
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:33:24.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6x5md" for this suite.
Jul 31 06:33:46.510: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:33:46.520: INFO: namespace: e2e-tests-projected-6x5md, resource: bindings, ignored listing per whitelist
Jul 31 06:33:46.600: INFO: namespace e2e-tests-projected-6x5md deletion completed in 22.102338277s

• [SLOW TEST:26.197 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:33:46.600: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-26406f71-b35d-11e9-990e-fe448544ce72
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-26406f71-b35d-11e9-990e-fe448544ce72
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:33:52.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-fnmhc" for this suite.
Jul 31 06:34:14.719: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:34:14.736: INFO: namespace: e2e-tests-configmap-fnmhc, resource: bindings, ignored listing per whitelist
Jul 31 06:34:14.788: INFO: namespace e2e-tests-configmap-fnmhc deletion completed in 22.075949416s

• [SLOW TEST:28.187 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:34:14.788: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:34:16.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-zgg7d" for this suite.
Jul 31 06:34:22.886: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:34:22.939: INFO: namespace: e2e-tests-emptydir-wrapper-zgg7d, resource: bindings, ignored listing per whitelist
Jul 31 06:34:22.953: INFO: namespace e2e-tests-emptydir-wrapper-zgg7d deletion completed in 6.076291591s

• [SLOW TEST:8.165 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:34:22.953: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Jul 31 06:34:23.005: INFO: namespace e2e-tests-kubectl-d2psm
Jul 31 06:34:23.005: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 create -f - --namespace=e2e-tests-kubectl-d2psm'
Jul 31 06:34:23.207: INFO: stderr: ""
Jul 31 06:34:23.207: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Jul 31 06:34:24.211: INFO: Selector matched 1 pods for map[app:redis]
Jul 31 06:34:24.211: INFO: Found 0 / 1
Jul 31 06:34:25.210: INFO: Selector matched 1 pods for map[app:redis]
Jul 31 06:34:25.210: INFO: Found 0 / 1
Jul 31 06:34:26.210: INFO: Selector matched 1 pods for map[app:redis]
Jul 31 06:34:26.211: INFO: Found 0 / 1
Jul 31 06:34:27.211: INFO: Selector matched 1 pods for map[app:redis]
Jul 31 06:34:27.211: INFO: Found 0 / 1
Jul 31 06:34:28.210: INFO: Selector matched 1 pods for map[app:redis]
Jul 31 06:34:28.210: INFO: Found 1 / 1
Jul 31 06:34:28.210: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jul 31 06:34:28.213: INFO: Selector matched 1 pods for map[app:redis]
Jul 31 06:34:28.213: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jul 31 06:34:28.213: INFO: wait on redis-master startup in e2e-tests-kubectl-d2psm 
Jul 31 06:34:28.213: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 logs redis-master-nnhss redis-master --namespace=e2e-tests-kubectl-d2psm'
Jul 31 06:34:28.296: INFO: stderr: ""
Jul 31 06:34:28.296: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 31 Jul 06:34:27.617 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 31 Jul 06:34:27.617 # Server started, Redis version 3.2.12\n1:M 31 Jul 06:34:27.617 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 31 Jul 06:34:27.617 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Jul 31 06:34:28.296: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-d2psm'
Jul 31 06:34:28.387: INFO: stderr: ""
Jul 31 06:34:28.387: INFO: stdout: "service/rm2 exposed\n"
Jul 31 06:34:28.389: INFO: Service rm2 in namespace e2e-tests-kubectl-d2psm found.
STEP: exposing service
Jul 31 06:34:30.394: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-d2psm'
Jul 31 06:34:30.479: INFO: stderr: ""
Jul 31 06:34:30.479: INFO: stdout: "service/rm3 exposed\n"
Jul 31 06:34:30.485: INFO: Service rm3 in namespace e2e-tests-kubectl-d2psm found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:34:32.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-d2psm" for this suite.
Jul 31 06:34:54.501: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:34:54.546: INFO: namespace: e2e-tests-kubectl-d2psm, resource: bindings, ignored listing per whitelist
Jul 31 06:34:54.569: INFO: namespace e2e-tests-kubectl-d2psm deletion completed in 22.075648005s

• [SLOW TEST:31.616 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:34:54.569: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-4ec322cc-b35d-11e9-990e-fe448544ce72
STEP: Creating secret with name s-test-opt-upd-4ec3232f-b35d-11e9-990e-fe448544ce72
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-4ec322cc-b35d-11e9-990e-fe448544ce72
STEP: Updating secret s-test-opt-upd-4ec3232f-b35d-11e9-990e-fe448544ce72
STEP: Creating secret with name s-test-opt-create-4ec32369-b35d-11e9-990e-fe448544ce72
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:34:58.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-8w79l" for this suite.
Jul 31 06:35:20.711: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:35:20.775: INFO: namespace: e2e-tests-secrets-8w79l, resource: bindings, ignored listing per whitelist
Jul 31 06:35:20.778: INFO: namespace e2e-tests-secrets-8w79l deletion completed in 22.07581172s

• [SLOW TEST:26.209 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:35:20.779: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-vmsvm
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jul 31 06:35:20.837: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jul 31 06:35:44.893: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.61:8080/dial?request=hostName&protocol=udp&host=10.244.1.60&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-vmsvm PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 31 06:35:44.893: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
Jul 31 06:35:45.023: INFO: Waiting for endpoints: map[]
Jul 31 06:35:45.030: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.61:8080/dial?request=hostName&protocol=udp&host=10.244.2.61&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-vmsvm PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 31 06:35:45.030: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
Jul 31 06:35:45.155: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:35:45.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-vmsvm" for this suite.
Jul 31 06:36:07.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:36:07.212: INFO: namespace: e2e-tests-pod-network-test-vmsvm, resource: bindings, ignored listing per whitelist
Jul 31 06:36:07.245: INFO: namespace e2e-tests-pod-network-test-vmsvm deletion completed in 22.087403761s

• [SLOW TEST:46.466 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:36:07.246: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1358
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jul 31 06:36:07.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-dggck'
Jul 31 06:36:07.513: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jul 31 06:36:07.513: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Jul 31 06:36:07.519: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Jul 31 06:36:07.523: INFO: scanned /root for discovery docs: <nil>
Jul 31 06:36:07.523: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-dggck'
Jul 31 06:36:23.266: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Jul 31 06:36:23.266: INFO: stdout: "Created e2e-test-nginx-rc-a0f998de9e04077df9662d60b36b2802\nScaling up e2e-test-nginx-rc-a0f998de9e04077df9662d60b36b2802 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-a0f998de9e04077df9662d60b36b2802 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-a0f998de9e04077df9662d60b36b2802 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Jul 31 06:36:23.266: INFO: stdout: "Created e2e-test-nginx-rc-a0f998de9e04077df9662d60b36b2802\nScaling up e2e-test-nginx-rc-a0f998de9e04077df9662d60b36b2802 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-a0f998de9e04077df9662d60b36b2802 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-a0f998de9e04077df9662d60b36b2802 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Jul 31 06:36:23.266: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-dggck'
Jul 31 06:36:23.342: INFO: stderr: ""
Jul 31 06:36:23.342: INFO: stdout: "e2e-test-nginx-rc-a0f998de9e04077df9662d60b36b2802-clxhf "
Jul 31 06:36:23.342: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 get pods e2e-test-nginx-rc-a0f998de9e04077df9662d60b36b2802-clxhf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dggck'
Jul 31 06:36:23.416: INFO: stderr: ""
Jul 31 06:36:23.416: INFO: stdout: "true"
Jul 31 06:36:23.416: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 get pods e2e-test-nginx-rc-a0f998de9e04077df9662d60b36b2802-clxhf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dggck'
Jul 31 06:36:23.486: INFO: stderr: ""
Jul 31 06:36:23.486: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Jul 31 06:36:23.486: INFO: e2e-test-nginx-rc-a0f998de9e04077df9662d60b36b2802-clxhf is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1364
Jul 31 06:36:23.486: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-dggck'
Jul 31 06:36:23.565: INFO: stderr: ""
Jul 31 06:36:23.565: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:36:23.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-dggck" for this suite.
Jul 31 06:36:45.579: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:36:45.617: INFO: namespace: e2e-tests-kubectl-dggck, resource: bindings, ignored listing per whitelist
Jul 31 06:36:45.646: INFO: namespace e2e-tests-kubectl-dggck deletion completed in 22.076578733s

• [SLOW TEST:38.400 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:36:45.646: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jul 31 06:36:45.701: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:36:49.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-2w7g2" for this suite.
Jul 31 06:37:11.838: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:37:11.888: INFO: namespace: e2e-tests-init-container-2w7g2, resource: bindings, ignored listing per whitelist
Jul 31 06:37:11.906: INFO: namespace e2e-tests-init-container-2w7g2 deletion completed in 22.078925695s

• [SLOW TEST:26.260 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:37:11.906: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-a09ee8fb-b35d-11e9-990e-fe448544ce72
STEP: Creating a pod to test consume secrets
Jul 31 06:37:11.967: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a09f4139-b35d-11e9-990e-fe448544ce72" in namespace "e2e-tests-projected-zs6hf" to be "success or failure"
Jul 31 06:37:11.969: INFO: Pod "pod-projected-secrets-a09f4139-b35d-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.105699ms
Jul 31 06:37:13.972: INFO: Pod "pod-projected-secrets-a09f4139-b35d-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004971746s
STEP: Saw pod success
Jul 31 06:37:13.972: INFO: Pod "pod-projected-secrets-a09f4139-b35d-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 06:37:13.974: INFO: Trying to get logs from node shushsha-k8s-worker2 pod pod-projected-secrets-a09f4139-b35d-11e9-990e-fe448544ce72 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jul 31 06:37:13.989: INFO: Waiting for pod pod-projected-secrets-a09f4139-b35d-11e9-990e-fe448544ce72 to disappear
Jul 31 06:37:13.991: INFO: Pod pod-projected-secrets-a09f4139-b35d-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:37:13.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zs6hf" for this suite.
Jul 31 06:37:20.002: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:37:20.016: INFO: namespace: e2e-tests-projected-zs6hf, resource: bindings, ignored listing per whitelist
Jul 31 06:37:20.077: INFO: namespace e2e-tests-projected-zs6hf deletion completed in 6.083436171s

• [SLOW TEST:8.171 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:37:20.078: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Jul 31 06:37:20.132: INFO: Waiting up to 5m0s for pod "client-containers-a57d3b4f-b35d-11e9-990e-fe448544ce72" in namespace "e2e-tests-containers-pwm85" to be "success or failure"
Jul 31 06:37:20.136: INFO: Pod "client-containers-a57d3b4f-b35d-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 3.384764ms
Jul 31 06:37:22.138: INFO: Pod "client-containers-a57d3b4f-b35d-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005937804s
Jul 31 06:37:24.141: INFO: Pod "client-containers-a57d3b4f-b35d-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008853836s
Jul 31 06:37:26.144: INFO: Pod "client-containers-a57d3b4f-b35d-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.011394389s
STEP: Saw pod success
Jul 31 06:37:26.144: INFO: Pod "client-containers-a57d3b4f-b35d-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 06:37:26.146: INFO: Trying to get logs from node shushsha-k8s-worker1 pod client-containers-a57d3b4f-b35d-11e9-990e-fe448544ce72 container test-container: <nil>
STEP: delete the pod
Jul 31 06:37:26.160: INFO: Waiting for pod client-containers-a57d3b4f-b35d-11e9-990e-fe448544ce72 to disappear
Jul 31 06:37:26.162: INFO: Pod client-containers-a57d3b4f-b35d-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:37:26.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-pwm85" for this suite.
Jul 31 06:37:32.173: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:37:32.230: INFO: namespace: e2e-tests-containers-pwm85, resource: bindings, ignored listing per whitelist
Jul 31 06:37:32.239: INFO: namespace e2e-tests-containers-pwm85 deletion completed in 6.074827755s

• [SLOW TEST:12.161 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:37:32.240: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jul 31 06:37:32.297: INFO: Waiting up to 5m0s for pod "downward-api-acbd63f2-b35d-11e9-990e-fe448544ce72" in namespace "e2e-tests-downward-api-gwkz5" to be "success or failure"
Jul 31 06:37:32.300: INFO: Pod "downward-api-acbd63f2-b35d-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.049496ms
Jul 31 06:37:34.302: INFO: Pod "downward-api-acbd63f2-b35d-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004428457s
STEP: Saw pod success
Jul 31 06:37:34.302: INFO: Pod "downward-api-acbd63f2-b35d-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 06:37:34.304: INFO: Trying to get logs from node shushsha-k8s-worker2 pod downward-api-acbd63f2-b35d-11e9-990e-fe448544ce72 container dapi-container: <nil>
STEP: delete the pod
Jul 31 06:37:34.317: INFO: Waiting for pod downward-api-acbd63f2-b35d-11e9-990e-fe448544ce72 to disappear
Jul 31 06:37:34.319: INFO: Pod downward-api-acbd63f2-b35d-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:37:34.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-gwkz5" for this suite.
Jul 31 06:37:40.331: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:37:40.390: INFO: namespace: e2e-tests-downward-api-gwkz5, resource: bindings, ignored listing per whitelist
Jul 31 06:37:40.401: INFO: namespace e2e-tests-downward-api-gwkz5 deletion completed in 6.078930115s

• [SLOW TEST:8.161 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:37:40.401: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Jul 31 06:37:40.455: INFO: Waiting up to 5m0s for pod "pod-b19a407e-b35d-11e9-990e-fe448544ce72" in namespace "e2e-tests-emptydir-dvg9q" to be "success or failure"
Jul 31 06:37:40.459: INFO: Pod "pod-b19a407e-b35d-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 3.462441ms
Jul 31 06:37:42.462: INFO: Pod "pod-b19a407e-b35d-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006101193s
STEP: Saw pod success
Jul 31 06:37:42.462: INFO: Pod "pod-b19a407e-b35d-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 06:37:42.464: INFO: Trying to get logs from node shushsha-k8s-worker1 pod pod-b19a407e-b35d-11e9-990e-fe448544ce72 container test-container: <nil>
STEP: delete the pod
Jul 31 06:37:42.476: INFO: Waiting for pod pod-b19a407e-b35d-11e9-990e-fe448544ce72 to disappear
Jul 31 06:37:42.478: INFO: Pod pod-b19a407e-b35d-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:37:42.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-dvg9q" for this suite.
Jul 31 06:37:48.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:37:48.543: INFO: namespace: e2e-tests-emptydir-dvg9q, resource: bindings, ignored listing per whitelist
Jul 31 06:37:48.558: INFO: namespace e2e-tests-emptydir-dvg9q deletion completed in 6.07769887s

• [SLOW TEST:8.157 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:37:48.558: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Jul 31 06:38:28.636: INFO: MetricsGrabber failed grab metrics. Skipping metrics gathering.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:38:28.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-znttq" for this suite.
Jul 31 06:38:34.649: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:38:34.692: INFO: namespace: e2e-tests-gc-znttq, resource: bindings, ignored listing per whitelist
Jul 31 06:38:34.718: INFO: namespace e2e-tests-gc-znttq deletion completed in 6.079696187s

• [SLOW TEST:46.160 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:38:34.718: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-v4txv
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-v4txv
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-v4txv
Jul 31 06:38:34.785: INFO: Found 0 stateful pods, waiting for 1
Jul 31 06:38:44.789: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Jul 31 06:38:44.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 exec --namespace=e2e-tests-statefulset-v4txv ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul 31 06:38:45.001: INFO: stderr: ""
Jul 31 06:38:45.001: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul 31 06:38:45.001: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jul 31 06:38:45.003: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jul 31 06:38:55.006: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jul 31 06:38:55.006: INFO: Waiting for statefulset status.replicas updated to 0
Jul 31 06:38:55.018: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999519s
Jul 31 06:38:56.021: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.995342831s
Jul 31 06:38:57.024: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.99157304s
Jul 31 06:38:58.028: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.988468011s
Jul 31 06:38:59.031: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.984950526s
Jul 31 06:39:00.035: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.981451422s
Jul 31 06:39:01.038: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.978284205s
Jul 31 06:39:02.041: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.974784613s
Jul 31 06:39:03.045: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.971689225s
Jul 31 06:39:04.048: INFO: Verifying statefulset ss doesn't scale past 1 for another 968.210417ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-v4txv
Jul 31 06:39:05.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 exec --namespace=e2e-tests-statefulset-v4txv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 31 06:39:05.237: INFO: stderr: ""
Jul 31 06:39:05.237: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jul 31 06:39:05.237: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jul 31 06:39:05.239: INFO: Found 1 stateful pods, waiting for 3
Jul 31 06:39:15.243: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jul 31 06:39:15.243: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jul 31 06:39:15.243: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Jul 31 06:39:15.248: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 exec --namespace=e2e-tests-statefulset-v4txv ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul 31 06:39:15.437: INFO: stderr: ""
Jul 31 06:39:15.437: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul 31 06:39:15.437: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jul 31 06:39:15.437: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 exec --namespace=e2e-tests-statefulset-v4txv ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul 31 06:39:15.629: INFO: stderr: ""
Jul 31 06:39:15.629: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul 31 06:39:15.629: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jul 31 06:39:15.629: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 exec --namespace=e2e-tests-statefulset-v4txv ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul 31 06:39:15.830: INFO: stderr: ""
Jul 31 06:39:15.830: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul 31 06:39:15.830: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jul 31 06:39:15.830: INFO: Waiting for statefulset status.replicas updated to 0
Jul 31 06:39:15.833: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Jul 31 06:39:25.839: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jul 31 06:39:25.839: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jul 31 06:39:25.839: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jul 31 06:39:25.849: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999738s
Jul 31 06:39:26.853: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995577303s
Jul 31 06:39:27.856: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.991684606s
Jul 31 06:39:28.860: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.988267908s
Jul 31 06:39:29.863: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.984697136s
Jul 31 06:39:30.866: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.981402582s
Jul 31 06:39:31.870: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.977940667s
Jul 31 06:39:32.873: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.97465153s
Jul 31 06:39:33.877: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.971448235s
Jul 31 06:39:34.880: INFO: Verifying statefulset ss doesn't scale past 3 for another 967.847293ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-v4txv
Jul 31 06:39:35.883: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 exec --namespace=e2e-tests-statefulset-v4txv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 31 06:39:36.072: INFO: stderr: ""
Jul 31 06:39:36.072: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jul 31 06:39:36.072: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jul 31 06:39:36.072: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 exec --namespace=e2e-tests-statefulset-v4txv ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 31 06:39:36.260: INFO: stderr: ""
Jul 31 06:39:36.260: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jul 31 06:39:36.260: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jul 31 06:39:36.260: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 exec --namespace=e2e-tests-statefulset-v4txv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 31 06:39:36.455: INFO: stderr: ""
Jul 31 06:39:36.455: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jul 31 06:39:36.455: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jul 31 06:39:36.455: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jul 31 06:39:56.468: INFO: Deleting all statefulset in ns e2e-tests-statefulset-v4txv
Jul 31 06:39:56.471: INFO: Scaling statefulset ss to 0
Jul 31 06:39:56.477: INFO: Waiting for statefulset status.replicas updated to 0
Jul 31 06:39:56.479: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:39:56.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-v4txv" for this suite.
Jul 31 06:40:02.499: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:40:02.506: INFO: namespace: e2e-tests-statefulset-v4txv, resource: bindings, ignored listing per whitelist
Jul 31 06:40:02.570: INFO: namespace e2e-tests-statefulset-v4txv deletion completed in 6.079145989s

• [SLOW TEST:87.851 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:40:02.570: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jul 31 06:40:02.629: INFO: Waiting up to 5m0s for pod "downwardapi-volume-065828c1-b35e-11e9-990e-fe448544ce72" in namespace "e2e-tests-downward-api-v6tm4" to be "success or failure"
Jul 31 06:40:02.631: INFO: Pod "downwardapi-volume-065828c1-b35e-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.072647ms
Jul 31 06:40:04.634: INFO: Pod "downwardapi-volume-065828c1-b35e-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004834033s
STEP: Saw pod success
Jul 31 06:40:04.634: INFO: Pod "downwardapi-volume-065828c1-b35e-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 06:40:04.636: INFO: Trying to get logs from node shushsha-k8s-worker1 pod downwardapi-volume-065828c1-b35e-11e9-990e-fe448544ce72 container client-container: <nil>
STEP: delete the pod
Jul 31 06:40:04.650: INFO: Waiting for pod downwardapi-volume-065828c1-b35e-11e9-990e-fe448544ce72 to disappear
Jul 31 06:40:04.652: INFO: Pod downwardapi-volume-065828c1-b35e-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:40:04.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-v6tm4" for this suite.
Jul 31 06:40:10.662: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:40:10.689: INFO: namespace: e2e-tests-downward-api-v6tm4, resource: bindings, ignored listing per whitelist
Jul 31 06:40:10.734: INFO: namespace e2e-tests-downward-api-v6tm4 deletion completed in 6.078581481s

• [SLOW TEST:8.164 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:40:10.734: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jul 31 06:40:10.791: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0b358480-b35e-11e9-990e-fe448544ce72" in namespace "e2e-tests-downward-api-q6wqn" to be "success or failure"
Jul 31 06:40:10.793: INFO: Pod "downwardapi-volume-0b358480-b35e-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.563167ms
Jul 31 06:40:12.796: INFO: Pod "downwardapi-volume-0b358480-b35e-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005072011s
STEP: Saw pod success
Jul 31 06:40:12.796: INFO: Pod "downwardapi-volume-0b358480-b35e-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 06:40:12.798: INFO: Trying to get logs from node shushsha-k8s-worker1 pod downwardapi-volume-0b358480-b35e-11e9-990e-fe448544ce72 container client-container: <nil>
STEP: delete the pod
Jul 31 06:40:12.811: INFO: Waiting for pod downwardapi-volume-0b358480-b35e-11e9-990e-fe448544ce72 to disappear
Jul 31 06:40:12.813: INFO: Pod downwardapi-volume-0b358480-b35e-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:40:12.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-q6wqn" for this suite.
Jul 31 06:40:18.823: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:40:18.900: INFO: namespace: e2e-tests-downward-api-q6wqn, resource: bindings, ignored listing per whitelist
Jul 31 06:40:18.906: INFO: namespace e2e-tests-downward-api-q6wqn deletion completed in 6.090897389s

• [SLOW TEST:8.172 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:40:18.907: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-1015badc-b35e-11e9-990e-fe448544ce72
STEP: Creating configMap with name cm-test-opt-upd-1015bb17-b35e-11e9-990e-fe448544ce72
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-1015badc-b35e-11e9-990e-fe448544ce72
STEP: Updating configmap cm-test-opt-upd-1015bb17-b35e-11e9-990e-fe448544ce72
STEP: Creating configMap with name cm-test-opt-create-1015bb2d-b35e-11e9-990e-fe448544ce72
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:40:23.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6rdl5" for this suite.
Jul 31 06:40:45.051: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:40:45.113: INFO: namespace: e2e-tests-projected-6rdl5, resource: bindings, ignored listing per whitelist
Jul 31 06:40:45.125: INFO: namespace e2e-tests-projected-6rdl5 deletion completed in 22.082178572s

• [SLOW TEST:26.219 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:40:45.126: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jul 31 06:40:47.708: INFO: Successfully updated pod "annotationupdate1fb5a189-b35e-11e9-990e-fe448544ce72"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:40:51.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-f6259" for this suite.
Jul 31 06:41:13.744: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:41:13.752: INFO: namespace: e2e-tests-downward-api-f6259, resource: bindings, ignored listing per whitelist
Jul 31 06:41:13.813: INFO: namespace e2e-tests-downward-api-f6259 deletion completed in 22.077697108s

• [SLOW TEST:28.688 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:41:13.814: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jul 31 06:41:13.879: INFO: Waiting up to 5m0s for pod "downward-api-30cfdbf6-b35e-11e9-990e-fe448544ce72" in namespace "e2e-tests-downward-api-j4hnd" to be "success or failure"
Jul 31 06:41:13.881: INFO: Pod "downward-api-30cfdbf6-b35e-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.075501ms
Jul 31 06:41:15.884: INFO: Pod "downward-api-30cfdbf6-b35e-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005032157s
STEP: Saw pod success
Jul 31 06:41:15.884: INFO: Pod "downward-api-30cfdbf6-b35e-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 06:41:15.886: INFO: Trying to get logs from node shushsha-k8s-worker1 pod downward-api-30cfdbf6-b35e-11e9-990e-fe448544ce72 container dapi-container: <nil>
STEP: delete the pod
Jul 31 06:41:15.902: INFO: Waiting for pod downward-api-30cfdbf6-b35e-11e9-990e-fe448544ce72 to disappear
Jul 31 06:41:15.904: INFO: Pod downward-api-30cfdbf6-b35e-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:41:15.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-j4hnd" for this suite.
Jul 31 06:41:21.915: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:41:21.961: INFO: namespace: e2e-tests-downward-api-j4hnd, resource: bindings, ignored listing per whitelist
Jul 31 06:41:21.984: INFO: namespace e2e-tests-downward-api-j4hnd deletion completed in 6.0775501s

• [SLOW TEST:8.171 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:41:21.985: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Jul 31 06:41:22.038: INFO: Waiting up to 5m0s for pod "pod-35ad08eb-b35e-11e9-990e-fe448544ce72" in namespace "e2e-tests-emptydir-rk8sq" to be "success or failure"
Jul 31 06:41:22.040: INFO: Pod "pod-35ad08eb-b35e-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 1.982574ms
Jul 31 06:41:24.043: INFO: Pod "pod-35ad08eb-b35e-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00477476s
STEP: Saw pod success
Jul 31 06:41:24.043: INFO: Pod "pod-35ad08eb-b35e-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 06:41:24.045: INFO: Trying to get logs from node shushsha-k8s-worker2 pod pod-35ad08eb-b35e-11e9-990e-fe448544ce72 container test-container: <nil>
STEP: delete the pod
Jul 31 06:41:24.059: INFO: Waiting for pod pod-35ad08eb-b35e-11e9-990e-fe448544ce72 to disappear
Jul 31 06:41:24.062: INFO: Pod pod-35ad08eb-b35e-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:41:24.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-rk8sq" for this suite.
Jul 31 06:41:30.073: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:41:30.126: INFO: namespace: e2e-tests-emptydir-rk8sq, resource: bindings, ignored listing per whitelist
Jul 31 06:41:30.150: INFO: namespace e2e-tests-emptydir-rk8sq deletion completed in 6.08528467s

• [SLOW TEST:8.165 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:41:30.150: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-3a8b9262-b35e-11e9-990e-fe448544ce72
STEP: Creating a pod to test consume configMaps
Jul 31 06:41:30.209: INFO: Waiting up to 5m0s for pod "pod-configmaps-3a8bedde-b35e-11e9-990e-fe448544ce72" in namespace "e2e-tests-configmap-5zrv7" to be "success or failure"
Jul 31 06:41:30.211: INFO: Pod "pod-configmaps-3a8bedde-b35e-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043668ms
Jul 31 06:41:32.214: INFO: Pod "pod-configmaps-3a8bedde-b35e-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004992756s
STEP: Saw pod success
Jul 31 06:41:32.214: INFO: Pod "pod-configmaps-3a8bedde-b35e-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 06:41:32.217: INFO: Trying to get logs from node shushsha-k8s-worker1 pod pod-configmaps-3a8bedde-b35e-11e9-990e-fe448544ce72 container configmap-volume-test: <nil>
STEP: delete the pod
Jul 31 06:41:32.230: INFO: Waiting for pod pod-configmaps-3a8bedde-b35e-11e9-990e-fe448544ce72 to disappear
Jul 31 06:41:32.232: INFO: Pod pod-configmaps-3a8bedde-b35e-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:41:32.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-5zrv7" for this suite.
Jul 31 06:41:38.243: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:41:38.277: INFO: namespace: e2e-tests-configmap-5zrv7, resource: bindings, ignored listing per whitelist
Jul 31 06:41:38.315: INFO: namespace e2e-tests-configmap-5zrv7 deletion completed in 6.080351019s

• [SLOW TEST:8.165 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:41:38.315: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jul 31 06:41:38.367: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 version --client'
Jul 31 06:41:38.422: INFO: stderr: ""
Jul 31 06:41:38.422: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Jul 31 06:41:38.424: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 create -f - --namespace=e2e-tests-kubectl-pkfn9'
Jul 31 06:41:38.640: INFO: stderr: ""
Jul 31 06:41:38.640: INFO: stdout: "replicationcontroller/redis-master created\n"
Jul 31 06:41:38.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 create -f - --namespace=e2e-tests-kubectl-pkfn9'
Jul 31 06:41:38.816: INFO: stderr: ""
Jul 31 06:41:38.816: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Jul 31 06:41:39.820: INFO: Selector matched 1 pods for map[app:redis]
Jul 31 06:41:39.820: INFO: Found 0 / 1
Jul 31 06:41:40.819: INFO: Selector matched 1 pods for map[app:redis]
Jul 31 06:41:40.819: INFO: Found 1 / 1
Jul 31 06:41:40.819: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jul 31 06:41:40.822: INFO: Selector matched 1 pods for map[app:redis]
Jul 31 06:41:40.822: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jul 31 06:41:40.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 describe pod redis-master-f9z9j --namespace=e2e-tests-kubectl-pkfn9'
Jul 31 06:41:40.910: INFO: stderr: ""
Jul 31 06:41:40.910: INFO: stdout: "Name:               redis-master-f9z9j\nNamespace:          e2e-tests-kubectl-pkfn9\nPriority:           0\nPriorityClassName:  <none>\nNode:               shushsha-k8s-worker2/100.100.230.39\nStart Time:         Wed, 31 Jul 2019 06:41:38 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.244.2.74\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://f7de779bad0b16bed9a73591673498172ad3fea1cf602a3f13b887c278f554b6\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 31 Jul 2019 06:41:39 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-m6mzr (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-m6mzr:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-m6mzr\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                           Message\n  ----    ------     ----  ----                           -------\n  Normal  Scheduled  2s    default-scheduler              Successfully assigned e2e-tests-kubectl-pkfn9/redis-master-f9z9j to shushsha-k8s-worker2\n  Normal  Pulled     1s    kubelet, shushsha-k8s-worker2  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, shushsha-k8s-worker2  Created container\n  Normal  Started    1s    kubelet, shushsha-k8s-worker2  Started container\n"
Jul 31 06:41:40.910: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 describe rc redis-master --namespace=e2e-tests-kubectl-pkfn9'
Jul 31 06:41:40.999: INFO: stderr: ""
Jul 31 06:41:40.999: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-pkfn9\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-f9z9j\n"
Jul 31 06:41:40.999: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 describe service redis-master --namespace=e2e-tests-kubectl-pkfn9'
Jul 31 06:41:41.083: INFO: stderr: ""
Jul 31 06:41:41.084: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-pkfn9\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.102.99.73\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.244.2.74:6379\nSession Affinity:  None\nEvents:            <none>\n"
Jul 31 06:41:41.086: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 describe node shushsha-k8s-master'
Jul 31 06:41:41.179: INFO: stderr: ""
Jul 31 06:41:41.179: INFO: stdout: "Name:               shushsha-k8s-master\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/hostname=shushsha-k8s-master\n                    node-role.kubernetes.io/master=\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"5a:d8:15:ec:a9:57\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 100.100.230.26\n                    kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Wed, 31 Jul 2019 06:02:48 +0000\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Wed, 31 Jul 2019 06:41:40 +0000   Wed, 31 Jul 2019 06:02:40 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Wed, 31 Jul 2019 06:41:40 +0000   Wed, 31 Jul 2019 06:02:40 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Wed, 31 Jul 2019 06:41:40 +0000   Wed, 31 Jul 2019 06:02:40 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Wed, 31 Jul 2019 06:41:40 +0000   Wed, 31 Jul 2019 06:03:38 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  100.100.230.26\n  Hostname:    shushsha-k8s-master\nCapacity:\n cpu:                4\n ephemeral-storage:  40223552Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             14083440Ki\n pods:               110\nAllocatable:\n cpu:                4\n ephemeral-storage:  37070025462\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             13981040Ki\n pods:               110\nSystem Info:\n Machine ID:                 7204624677024a07a0e0a96893be1088\n System UUID:                56BBBBEB-4942-4F15-9421-0A7A42209154\n Boot ID:                    f33e18b5-cc56-4c99-bc80-cacfc15aab19\n Kernel Version:             4.14.35-1902.3.1.el7uek.x86_64\n OS Image:                   Oracle Linux Server 7.6\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.9.1\n Kubelet Version:            v1.13.5+1.2.2.el7\n Kube-Proxy Version:         v1.13.5+1.2.2.el7\nPodCIDR:                     10.244.0.0/24\nNon-terminated Pods:         (10 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-e7f83d409c1d4c2e-nzmb4    0 (0%)        0 (0%)      0 (0%)           0 (0%)         33m\n  kube-system                coredns-588cfdbddf-gc2v7                                   100m (2%)     0 (0%)      70Mi (0%)        170Mi (1%)     38m\n  kube-system                coredns-588cfdbddf-gxdbz                                   100m (2%)     0 (0%)      70Mi (0%)        170Mi (1%)     38m\n  kube-system                etcd-shushsha-k8s-master                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         37m\n  kube-system                kube-apiserver-shushsha-k8s-master                         250m (6%)     0 (0%)      0 (0%)           0 (0%)         37m\n  kube-system                kube-controller-manager-shushsha-k8s-master                200m (5%)     0 (0%)      0 (0%)           0 (0%)         37m\n  kube-system                kube-flannel-ds-wmmhn                                      100m (2%)     100m (2%)   100Mi (0%)       100Mi (0%)     38m\n  kube-system                kube-proxy-9ffhc                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         38m\n  kube-system                kube-scheduler-shushsha-k8s-master                         100m (2%)     0 (0%)      0 (0%)           0 (0%)         37m\n  kube-system                kubernetes-dashboard-7d84d6db5c-5plwx                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         38m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                850m (21%)  100m (2%)\n  memory             240Mi (1%)  440Mi (3%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:\n  Type    Reason                   Age                From                             Message\n  ----    ------                   ----               ----                             -------\n  Normal  Starting                 39m                kubelet, shushsha-k8s-master     Starting kubelet.\n  Normal  NodeHasSufficientMemory  39m (x8 over 39m)  kubelet, shushsha-k8s-master     Node shushsha-k8s-master status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    39m (x7 over 39m)  kubelet, shushsha-k8s-master     Node shushsha-k8s-master status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     39m (x8 over 39m)  kubelet, shushsha-k8s-master     Node shushsha-k8s-master status is now: NodeHasSufficientPID\n  Normal  NodeAllocatableEnforced  39m                kubelet, shushsha-k8s-master     Updated Node Allocatable limit across pods\n  Normal  Starting                 38m                kube-proxy, shushsha-k8s-master  Starting kube-proxy.\n"
Jul 31 06:41:41.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 describe namespace e2e-tests-kubectl-pkfn9'
Jul 31 06:41:41.258: INFO: stderr: ""
Jul 31 06:41:41.258: INFO: stdout: "Name:         e2e-tests-kubectl-pkfn9\nLabels:       e2e-framework=kubectl\n              e2e-run=a5580c68-b359-11e9-990e-fe448544ce72\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:41:41.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-pkfn9" for this suite.
Jul 31 06:42:03.270: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:42:03.304: INFO: namespace: e2e-tests-kubectl-pkfn9, resource: bindings, ignored listing per whitelist
Jul 31 06:42:03.338: INFO: namespace e2e-tests-kubectl-pkfn9 deletion completed in 22.076912779s

• [SLOW TEST:25.023 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:42:03.339: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-4e540892-b35e-11e9-990e-fe448544ce72
STEP: Creating a pod to test consume configMaps
Jul 31 06:42:03.401: INFO: Waiting up to 5m0s for pod "pod-configmaps-4e547145-b35e-11e9-990e-fe448544ce72" in namespace "e2e-tests-configmap-bgfn2" to be "success or failure"
Jul 31 06:42:03.405: INFO: Pod "pod-configmaps-4e547145-b35e-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 3.542515ms
Jul 31 06:42:05.408: INFO: Pod "pod-configmaps-4e547145-b35e-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006476606s
STEP: Saw pod success
Jul 31 06:42:05.408: INFO: Pod "pod-configmaps-4e547145-b35e-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 06:42:05.410: INFO: Trying to get logs from node shushsha-k8s-worker1 pod pod-configmaps-4e547145-b35e-11e9-990e-fe448544ce72 container configmap-volume-test: <nil>
STEP: delete the pod
Jul 31 06:42:05.423: INFO: Waiting for pod pod-configmaps-4e547145-b35e-11e9-990e-fe448544ce72 to disappear
Jul 31 06:42:05.425: INFO: Pod pod-configmaps-4e547145-b35e-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:42:05.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-bgfn2" for this suite.
Jul 31 06:42:11.439: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:42:11.491: INFO: namespace: e2e-tests-configmap-bgfn2, resource: bindings, ignored listing per whitelist
Jul 31 06:42:11.506: INFO: namespace e2e-tests-configmap-bgfn2 deletion completed in 6.078471253s

• [SLOW TEST:8.167 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:42:11.506: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:42:16.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-4lvz5" for this suite.
Jul 31 06:42:38.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:42:38.620: INFO: namespace: e2e-tests-replication-controller-4lvz5, resource: bindings, ignored listing per whitelist
Jul 31 06:42:38.658: INFO: namespace e2e-tests-replication-controller-4lvz5 deletion completed in 22.079333805s

• [SLOW TEST:27.152 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:42:38.658: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-nx9j5/configmap-test-6362d710-b35e-11e9-990e-fe448544ce72
STEP: Creating a pod to test consume configMaps
Jul 31 06:42:38.730: INFO: Waiting up to 5m0s for pod "pod-configmaps-63634878-b35e-11e9-990e-fe448544ce72" in namespace "e2e-tests-configmap-nx9j5" to be "success or failure"
Jul 31 06:42:38.732: INFO: Pod "pod-configmaps-63634878-b35e-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 1.984286ms
Jul 31 06:42:40.735: INFO: Pod "pod-configmaps-63634878-b35e-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005486041s
STEP: Saw pod success
Jul 31 06:42:40.735: INFO: Pod "pod-configmaps-63634878-b35e-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 06:42:40.737: INFO: Trying to get logs from node shushsha-k8s-worker1 pod pod-configmaps-63634878-b35e-11e9-990e-fe448544ce72 container env-test: <nil>
STEP: delete the pod
Jul 31 06:42:40.751: INFO: Waiting for pod pod-configmaps-63634878-b35e-11e9-990e-fe448544ce72 to disappear
Jul 31 06:42:40.753: INFO: Pod pod-configmaps-63634878-b35e-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:42:40.754: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-nx9j5" for this suite.
Jul 31 06:42:46.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:42:46.813: INFO: namespace: e2e-tests-configmap-nx9j5, resource: bindings, ignored listing per whitelist
Jul 31 06:42:46.832: INFO: namespace e2e-tests-configmap-nx9j5 deletion completed in 6.075632266s

• [SLOW TEST:8.174 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:42:46.833: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-68406d38-b35e-11e9-990e-fe448544ce72
STEP: Creating a pod to test consume configMaps
Jul 31 06:42:46.892: INFO: Waiting up to 5m0s for pod "pod-configmaps-6840d254-b35e-11e9-990e-fe448544ce72" in namespace "e2e-tests-configmap-lbp24" to be "success or failure"
Jul 31 06:42:46.895: INFO: Pod "pod-configmaps-6840d254-b35e-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.991568ms
Jul 31 06:42:48.898: INFO: Pod "pod-configmaps-6840d254-b35e-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005812369s
STEP: Saw pod success
Jul 31 06:42:48.898: INFO: Pod "pod-configmaps-6840d254-b35e-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 06:42:48.900: INFO: Trying to get logs from node shushsha-k8s-worker2 pod pod-configmaps-6840d254-b35e-11e9-990e-fe448544ce72 container configmap-volume-test: <nil>
STEP: delete the pod
Jul 31 06:42:48.913: INFO: Waiting for pod pod-configmaps-6840d254-b35e-11e9-990e-fe448544ce72 to disappear
Jul 31 06:42:48.915: INFO: Pod pod-configmaps-6840d254-b35e-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:42:48.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-lbp24" for this suite.
Jul 31 06:42:54.927: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:42:54.942: INFO: namespace: e2e-tests-configmap-lbp24, resource: bindings, ignored listing per whitelist
Jul 31 06:42:54.994: INFO: namespace e2e-tests-configmap-lbp24 deletion completed in 6.075219191s

• [SLOW TEST:8.161 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:42:54.994: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Jul 31 06:42:55.049: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-864115849 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:42:55.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-zsv5p" for this suite.
Jul 31 06:43:01.122: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:43:01.184: INFO: namespace: e2e-tests-kubectl-zsv5p, resource: bindings, ignored listing per whitelist
Jul 31 06:43:01.191: INFO: namespace e2e-tests-kubectl-zsv5p deletion completed in 6.076476774s

• [SLOW TEST:6.197 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:43:01.192: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jul 31 06:43:01.243: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-b7tjj'
Jul 31 06:43:01.319: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jul 31 06:43:01.319: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1268
Jul 31 06:43:03.326: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-b7tjj'
Jul 31 06:43:03.401: INFO: stderr: ""
Jul 31 06:43:03.401: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:43:03.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-b7tjj" for this suite.
Jul 31 06:43:09.413: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:43:09.466: INFO: namespace: e2e-tests-kubectl-b7tjj, resource: bindings, ignored listing per whitelist
Jul 31 06:43:09.482: INFO: namespace e2e-tests-kubectl-b7tjj deletion completed in 6.078000152s

• [SLOW TEST:8.290 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:43:09.482: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Jul 31 06:43:09.537: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 create -f - --namespace=e2e-tests-kubectl-9bs7c'
Jul 31 06:43:09.704: INFO: stderr: ""
Jul 31 06:43:09.704: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jul 31 06:43:09.704: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-9bs7c'
Jul 31 06:43:09.785: INFO: stderr: ""
Jul 31 06:43:09.785: INFO: stdout: "update-demo-nautilus-nckb5 update-demo-nautilus-s68gd "
Jul 31 06:43:09.785: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 get pods update-demo-nautilus-nckb5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9bs7c'
Jul 31 06:43:09.858: INFO: stderr: ""
Jul 31 06:43:09.858: INFO: stdout: ""
Jul 31 06:43:09.858: INFO: update-demo-nautilus-nckb5 is created but not running
Jul 31 06:43:14.859: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-9bs7c'
Jul 31 06:43:14.936: INFO: stderr: ""
Jul 31 06:43:14.936: INFO: stdout: "update-demo-nautilus-nckb5 update-demo-nautilus-s68gd "
Jul 31 06:43:14.936: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 get pods update-demo-nautilus-nckb5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9bs7c'
Jul 31 06:43:15.008: INFO: stderr: ""
Jul 31 06:43:15.008: INFO: stdout: "true"
Jul 31 06:43:15.008: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 get pods update-demo-nautilus-nckb5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9bs7c'
Jul 31 06:43:15.081: INFO: stderr: ""
Jul 31 06:43:15.081: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jul 31 06:43:15.081: INFO: validating pod update-demo-nautilus-nckb5
Jul 31 06:43:15.085: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 31 06:43:15.085: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 31 06:43:15.085: INFO: update-demo-nautilus-nckb5 is verified up and running
Jul 31 06:43:15.085: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 get pods update-demo-nautilus-s68gd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9bs7c'
Jul 31 06:43:15.158: INFO: stderr: ""
Jul 31 06:43:15.158: INFO: stdout: "true"
Jul 31 06:43:15.158: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 get pods update-demo-nautilus-s68gd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9bs7c'
Jul 31 06:43:15.228: INFO: stderr: ""
Jul 31 06:43:15.228: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jul 31 06:43:15.228: INFO: validating pod update-demo-nautilus-s68gd
Jul 31 06:43:15.232: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 31 06:43:15.232: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 31 06:43:15.232: INFO: update-demo-nautilus-s68gd is verified up and running
STEP: scaling down the replication controller
Jul 31 06:43:15.234: INFO: scanned /root for discovery docs: <nil>
Jul 31 06:43:15.234: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-9bs7c'
Jul 31 06:43:16.332: INFO: stderr: ""
Jul 31 06:43:16.332: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jul 31 06:43:16.332: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-9bs7c'
Jul 31 06:43:16.407: INFO: stderr: ""
Jul 31 06:43:16.407: INFO: stdout: "update-demo-nautilus-nckb5 update-demo-nautilus-s68gd "
STEP: Replicas for name=update-demo: expected=1 actual=2
Jul 31 06:43:21.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-9bs7c'
Jul 31 06:43:21.485: INFO: stderr: ""
Jul 31 06:43:21.485: INFO: stdout: "update-demo-nautilus-nckb5 update-demo-nautilus-s68gd "
STEP: Replicas for name=update-demo: expected=1 actual=2
Jul 31 06:43:26.486: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-9bs7c'
Jul 31 06:43:26.561: INFO: stderr: ""
Jul 31 06:43:26.561: INFO: stdout: "update-demo-nautilus-s68gd "
Jul 31 06:43:26.561: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 get pods update-demo-nautilus-s68gd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9bs7c'
Jul 31 06:43:26.631: INFO: stderr: ""
Jul 31 06:43:26.631: INFO: stdout: "true"
Jul 31 06:43:26.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 get pods update-demo-nautilus-s68gd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9bs7c'
Jul 31 06:43:26.702: INFO: stderr: ""
Jul 31 06:43:26.702: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jul 31 06:43:26.702: INFO: validating pod update-demo-nautilus-s68gd
Jul 31 06:43:26.706: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 31 06:43:26.706: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 31 06:43:26.706: INFO: update-demo-nautilus-s68gd is verified up and running
STEP: scaling up the replication controller
Jul 31 06:43:26.707: INFO: scanned /root for discovery docs: <nil>
Jul 31 06:43:26.707: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-9bs7c'
Jul 31 06:43:27.801: INFO: stderr: ""
Jul 31 06:43:27.801: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jul 31 06:43:27.801: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-9bs7c'
Jul 31 06:43:27.876: INFO: stderr: ""
Jul 31 06:43:27.876: INFO: stdout: "update-demo-nautilus-s68gd update-demo-nautilus-t25b5 "
Jul 31 06:43:27.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 get pods update-demo-nautilus-s68gd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9bs7c'
Jul 31 06:43:27.947: INFO: stderr: ""
Jul 31 06:43:27.947: INFO: stdout: "true"
Jul 31 06:43:27.948: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 get pods update-demo-nautilus-s68gd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9bs7c'
Jul 31 06:43:28.019: INFO: stderr: ""
Jul 31 06:43:28.019: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jul 31 06:43:28.019: INFO: validating pod update-demo-nautilus-s68gd
Jul 31 06:43:28.022: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 31 06:43:28.022: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 31 06:43:28.022: INFO: update-demo-nautilus-s68gd is verified up and running
Jul 31 06:43:28.022: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 get pods update-demo-nautilus-t25b5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9bs7c'
Jul 31 06:43:28.100: INFO: stderr: ""
Jul 31 06:43:28.100: INFO: stdout: ""
Jul 31 06:43:28.100: INFO: update-demo-nautilus-t25b5 is created but not running
Jul 31 06:43:33.101: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-9bs7c'
Jul 31 06:43:33.175: INFO: stderr: ""
Jul 31 06:43:33.175: INFO: stdout: "update-demo-nautilus-s68gd update-demo-nautilus-t25b5 "
Jul 31 06:43:33.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 get pods update-demo-nautilus-s68gd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9bs7c'
Jul 31 06:43:33.246: INFO: stderr: ""
Jul 31 06:43:33.246: INFO: stdout: "true"
Jul 31 06:43:33.246: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 get pods update-demo-nautilus-s68gd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9bs7c'
Jul 31 06:43:33.316: INFO: stderr: ""
Jul 31 06:43:33.316: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jul 31 06:43:33.316: INFO: validating pod update-demo-nautilus-s68gd
Jul 31 06:43:33.319: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 31 06:43:33.319: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 31 06:43:33.319: INFO: update-demo-nautilus-s68gd is verified up and running
Jul 31 06:43:33.319: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 get pods update-demo-nautilus-t25b5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9bs7c'
Jul 31 06:43:33.390: INFO: stderr: ""
Jul 31 06:43:33.391: INFO: stdout: "true"
Jul 31 06:43:33.391: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 get pods update-demo-nautilus-t25b5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9bs7c'
Jul 31 06:43:33.462: INFO: stderr: ""
Jul 31 06:43:33.462: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jul 31 06:43:33.462: INFO: validating pod update-demo-nautilus-t25b5
Jul 31 06:43:33.465: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 31 06:43:33.465: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 31 06:43:33.465: INFO: update-demo-nautilus-t25b5 is verified up and running
STEP: using delete to clean up resources
Jul 31 06:43:33.466: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-9bs7c'
Jul 31 06:43:33.538: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 31 06:43:33.538: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jul 31 06:43:33.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-9bs7c'
Jul 31 06:43:33.645: INFO: stderr: "No resources found.\n"
Jul 31 06:43:33.646: INFO: stdout: ""
Jul 31 06:43:33.646: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 get pods -l name=update-demo --namespace=e2e-tests-kubectl-9bs7c -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jul 31 06:43:33.746: INFO: stderr: ""
Jul 31 06:43:33.746: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:43:33.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9bs7c" for this suite.
Jul 31 06:43:55.757: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:43:55.822: INFO: namespace: e2e-tests-kubectl-9bs7c, resource: bindings, ignored listing per whitelist
Jul 31 06:43:55.828: INFO: namespace e2e-tests-kubectl-9bs7c deletion completed in 22.079425535s

• [SLOW TEST:46.346 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:43:55.828: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-9thm2
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Jul 31 06:43:55.895: INFO: Found 0 stateful pods, waiting for 3
Jul 31 06:44:05.899: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jul 31 06:44:05.899: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jul 31 06:44:05.899: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Jul 31 06:44:05.906: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 exec --namespace=e2e-tests-statefulset-9thm2 ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul 31 06:44:06.125: INFO: stderr: ""
Jul 31 06:44:06.125: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul 31 06:44:06.125: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Jul 31 06:44:16.151: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Jul 31 06:44:26.167: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 exec --namespace=e2e-tests-statefulset-9thm2 ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 31 06:44:26.380: INFO: stderr: ""
Jul 31 06:44:26.380: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jul 31 06:44:26.380: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jul 31 06:44:26.403: INFO: Waiting for StatefulSet e2e-tests-statefulset-9thm2/ss2 to complete update
Jul 31 06:44:26.403: INFO: Waiting for Pod e2e-tests-statefulset-9thm2/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Jul 31 06:44:26.403: INFO: Waiting for Pod e2e-tests-statefulset-9thm2/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Jul 31 06:44:26.403: INFO: Waiting for Pod e2e-tests-statefulset-9thm2/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Jul 31 06:44:36.408: INFO: Waiting for StatefulSet e2e-tests-statefulset-9thm2/ss2 to complete update
Jul 31 06:44:36.408: INFO: Waiting for Pod e2e-tests-statefulset-9thm2/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Jul 31 06:44:36.408: INFO: Waiting for Pod e2e-tests-statefulset-9thm2/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Jul 31 06:44:46.408: INFO: Waiting for StatefulSet e2e-tests-statefulset-9thm2/ss2 to complete update
Jul 31 06:44:46.408: INFO: Waiting for Pod e2e-tests-statefulset-9thm2/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Jul 31 06:44:56.414: INFO: Waiting for StatefulSet e2e-tests-statefulset-9thm2/ss2 to complete update
Jul 31 06:44:56.414: INFO: Waiting for Pod e2e-tests-statefulset-9thm2/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Jul 31 06:45:06.409: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 exec --namespace=e2e-tests-statefulset-9thm2 ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul 31 06:45:06.583: INFO: stderr: ""
Jul 31 06:45:06.583: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul 31 06:45:06.583: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jul 31 06:45:16.609: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Jul 31 06:45:26.632: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 exec --namespace=e2e-tests-statefulset-9thm2 ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 31 06:45:26.806: INFO: stderr: ""
Jul 31 06:45:26.806: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jul 31 06:45:26.806: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jul 31 06:45:36.820: INFO: Waiting for StatefulSet e2e-tests-statefulset-9thm2/ss2 to complete update
Jul 31 06:45:36.820: INFO: Waiting for Pod e2e-tests-statefulset-9thm2/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Jul 31 06:45:36.820: INFO: Waiting for Pod e2e-tests-statefulset-9thm2/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Jul 31 06:45:46.827: INFO: Waiting for StatefulSet e2e-tests-statefulset-9thm2/ss2 to complete update
Jul 31 06:45:46.827: INFO: Waiting for Pod e2e-tests-statefulset-9thm2/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Jul 31 06:45:56.826: INFO: Waiting for StatefulSet e2e-tests-statefulset-9thm2/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jul 31 06:46:06.827: INFO: Deleting all statefulset in ns e2e-tests-statefulset-9thm2
Jul 31 06:46:06.829: INFO: Scaling statefulset ss2 to 0
Jul 31 06:46:16.840: INFO: Waiting for statefulset status.replicas updated to 0
Jul 31 06:46:16.842: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:46:16.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-9thm2" for this suite.
Jul 31 06:46:22.865: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:46:22.875: INFO: namespace: e2e-tests-statefulset-9thm2, resource: bindings, ignored listing per whitelist
Jul 31 06:46:22.933: INFO: namespace e2e-tests-statefulset-9thm2 deletion completed in 6.078772238s

• [SLOW TEST:147.105 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:46:22.933: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Jul 31 06:46:22.988: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jul 31 06:46:22.993: INFO: Waiting for terminating namespaces to be deleted...
Jul 31 06:46:22.995: INFO: 
Logging pods the kubelet thinks is on node shushsha-k8s-worker1 before test
Jul 31 06:46:23.001: INFO: nginx-7cdbd8cdc9-gpjlv from default started at 2019-07-31 06:08:14 +0000 UTC (1 container statuses recorded)
Jul 31 06:46:23.001: INFO: 	Container nginx ready: true, restart count 0
Jul 31 06:46:23.001: INFO: kube-proxy-7z76l from kube-system started at 2019-07-31 06:05:42 +0000 UTC (1 container statuses recorded)
Jul 31 06:46:23.001: INFO: 	Container kube-proxy ready: true, restart count 0
Jul 31 06:46:23.001: INFO: sonobuoy-systemd-logs-daemon-set-e7f83d409c1d4c2e-fn8j6 from heptio-sonobuoy started at 2019-07-31 06:07:55 +0000 UTC (2 container statuses recorded)
Jul 31 06:46:23.001: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jul 31 06:46:23.001: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul 31 06:46:23.001: INFO: kube-flannel-ds-9jt4h from kube-system started at 2019-07-31 06:05:43 +0000 UTC (1 container statuses recorded)
Jul 31 06:46:23.001: INFO: 	Container kube-flannel ready: true, restart count 0
Jul 31 06:46:23.001: INFO: sonobuoy from heptio-sonobuoy started at 2019-07-31 06:07:48 +0000 UTC (1 container statuses recorded)
Jul 31 06:46:23.001: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jul 31 06:46:23.001: INFO: 
Logging pods the kubelet thinks is on node shushsha-k8s-worker2 before test
Jul 31 06:46:23.007: INFO: kube-flannel-ds-flmdc from kube-system started at 2019-07-31 06:05:45 +0000 UTC (1 container statuses recorded)
Jul 31 06:46:23.007: INFO: 	Container kube-flannel ready: true, restart count 0
Jul 31 06:46:23.007: INFO: kube-proxy-2wjnv from kube-system started at 2019-07-31 06:05:45 +0000 UTC (1 container statuses recorded)
Jul 31 06:46:23.007: INFO: 	Container kube-proxy ready: true, restart count 0
Jul 31 06:46:23.007: INFO: sonobuoy-systemd-logs-daemon-set-e7f83d409c1d4c2e-qgszv from heptio-sonobuoy started at 2019-07-31 06:07:55 +0000 UTC (2 container statuses recorded)
Jul 31 06:46:23.007: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jul 31 06:46:23.007: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul 31 06:46:23.007: INFO: sonobuoy-e2e-job-35084b16218148db from heptio-sonobuoy started at 2019-07-31 06:07:55 +0000 UTC (2 container statuses recorded)
Jul 31 06:46:23.007: INFO: 	Container e2e ready: true, restart count 0
Jul 31 06:46:23.007: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node shushsha-k8s-worker1
STEP: verifying the node has the label node shushsha-k8s-worker2
Jul 31 06:46:23.029: INFO: Pod nginx-7cdbd8cdc9-gpjlv requesting resource cpu=0m on Node shushsha-k8s-worker1
Jul 31 06:46:23.029: INFO: Pod sonobuoy requesting resource cpu=0m on Node shushsha-k8s-worker1
Jul 31 06:46:23.029: INFO: Pod sonobuoy-e2e-job-35084b16218148db requesting resource cpu=0m on Node shushsha-k8s-worker2
Jul 31 06:46:23.029: INFO: Pod sonobuoy-systemd-logs-daemon-set-e7f83d409c1d4c2e-fn8j6 requesting resource cpu=0m on Node shushsha-k8s-worker1
Jul 31 06:46:23.029: INFO: Pod sonobuoy-systemd-logs-daemon-set-e7f83d409c1d4c2e-qgszv requesting resource cpu=0m on Node shushsha-k8s-worker2
Jul 31 06:46:23.029: INFO: Pod kube-flannel-ds-9jt4h requesting resource cpu=100m on Node shushsha-k8s-worker1
Jul 31 06:46:23.029: INFO: Pod kube-flannel-ds-flmdc requesting resource cpu=100m on Node shushsha-k8s-worker2
Jul 31 06:46:23.029: INFO: Pod kube-proxy-2wjnv requesting resource cpu=0m on Node shushsha-k8s-worker2
Jul 31 06:46:23.029: INFO: Pod kube-proxy-7z76l requesting resource cpu=0m on Node shushsha-k8s-worker1
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e9155d1d-b35e-11e9-990e-fe448544ce72.15b66b036e693de8], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-sv6d6/filler-pod-e9155d1d-b35e-11e9-990e-fe448544ce72 to shushsha-k8s-worker1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e9155d1d-b35e-11e9-990e-fe448544ce72.15b66b03a1da7412], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e9155d1d-b35e-11e9-990e-fe448544ce72.15b66b03a405ff27], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e9155d1d-b35e-11e9-990e-fe448544ce72.15b66b03aad45d8d], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e91667b6-b35e-11e9-990e-fe448544ce72.15b66b036ec58989], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-sv6d6/filler-pod-e91667b6-b35e-11e9-990e-fe448544ce72 to shushsha-k8s-worker2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e91667b6-b35e-11e9-990e-fe448544ce72.15b66b03a748674e], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e91667b6-b35e-11e9-990e-fe448544ce72.15b66b03aa3f2b64], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e91667b6-b35e-11e9-990e-fe448544ce72.15b66b03b580e763], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15b66b045de1b0c4], Reason = [FailedScheduling], Message = [0/3 nodes are available: 1 node(s) had taints that the pod didn't tolerate, 2 Insufficient cpu.]
STEP: removing the label node off the node shushsha-k8s-worker1
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node shushsha-k8s-worker2
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:46:28.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-sv6d6" for this suite.
Jul 31 06:46:34.097: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:46:34.122: INFO: namespace: e2e-tests-sched-pred-sv6d6, resource: bindings, ignored listing per whitelist
Jul 31 06:46:34.166: INFO: namespace e2e-tests-sched-pred-sv6d6 deletion completed in 6.079100913s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:11.233 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:46:34.166: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jul 31 06:46:34.227: INFO: Waiting up to 5m0s for pod "pod-efc15113-b35e-11e9-990e-fe448544ce72" in namespace "e2e-tests-emptydir-hbpj5" to be "success or failure"
Jul 31 06:46:34.229: INFO: Pod "pod-efc15113-b35e-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.142005ms
Jul 31 06:46:36.232: INFO: Pod "pod-efc15113-b35e-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004838503s
STEP: Saw pod success
Jul 31 06:46:36.232: INFO: Pod "pod-efc15113-b35e-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 06:46:36.234: INFO: Trying to get logs from node shushsha-k8s-worker2 pod pod-efc15113-b35e-11e9-990e-fe448544ce72 container test-container: <nil>
STEP: delete the pod
Jul 31 06:46:36.248: INFO: Waiting for pod pod-efc15113-b35e-11e9-990e-fe448544ce72 to disappear
Jul 31 06:46:36.250: INFO: Pod pod-efc15113-b35e-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:46:36.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-hbpj5" for this suite.
Jul 31 06:46:42.261: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:46:42.310: INFO: namespace: e2e-tests-emptydir-hbpj5, resource: bindings, ignored listing per whitelist
Jul 31 06:46:42.329: INFO: namespace e2e-tests-emptydir-hbpj5 deletion completed in 6.075975374s

• [SLOW TEST:8.163 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:46:42.330: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-bzrs
STEP: Creating a pod to test atomic-volume-subpath
Jul 31 06:46:42.393: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-bzrs" in namespace "e2e-tests-subpath-bb8dg" to be "success or failure"
Jul 31 06:46:42.396: INFO: Pod "pod-subpath-test-projected-bzrs": Phase="Pending", Reason="", readiness=false. Elapsed: 2.218674ms
Jul 31 06:46:44.399: INFO: Pod "pod-subpath-test-projected-bzrs": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005049382s
Jul 31 06:46:46.401: INFO: Pod "pod-subpath-test-projected-bzrs": Phase="Running", Reason="", readiness=false. Elapsed: 4.008014806s
Jul 31 06:46:48.404: INFO: Pod "pod-subpath-test-projected-bzrs": Phase="Running", Reason="", readiness=false. Elapsed: 6.010946147s
Jul 31 06:46:50.407: INFO: Pod "pod-subpath-test-projected-bzrs": Phase="Running", Reason="", readiness=false. Elapsed: 8.013454959s
Jul 31 06:46:52.410: INFO: Pod "pod-subpath-test-projected-bzrs": Phase="Running", Reason="", readiness=false. Elapsed: 10.016753252s
Jul 31 06:46:54.413: INFO: Pod "pod-subpath-test-projected-bzrs": Phase="Running", Reason="", readiness=false. Elapsed: 12.019898465s
Jul 31 06:46:56.422: INFO: Pod "pod-subpath-test-projected-bzrs": Phase="Running", Reason="", readiness=false. Elapsed: 14.028347484s
Jul 31 06:46:58.425: INFO: Pod "pod-subpath-test-projected-bzrs": Phase="Running", Reason="", readiness=false. Elapsed: 16.031907076s
Jul 31 06:47:00.429: INFO: Pod "pod-subpath-test-projected-bzrs": Phase="Running", Reason="", readiness=false. Elapsed: 18.035026371s
Jul 31 06:47:02.431: INFO: Pod "pod-subpath-test-projected-bzrs": Phase="Running", Reason="", readiness=false. Elapsed: 20.038021709s
Jul 31 06:47:04.434: INFO: Pod "pod-subpath-test-projected-bzrs": Phase="Running", Reason="", readiness=false. Elapsed: 22.040955772s
Jul 31 06:47:06.437: INFO: Pod "pod-subpath-test-projected-bzrs": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.043996388s
STEP: Saw pod success
Jul 31 06:47:06.438: INFO: Pod "pod-subpath-test-projected-bzrs" satisfied condition "success or failure"
Jul 31 06:47:06.440: INFO: Trying to get logs from node shushsha-k8s-worker1 pod pod-subpath-test-projected-bzrs container test-container-subpath-projected-bzrs: <nil>
STEP: delete the pod
Jul 31 06:47:06.455: INFO: Waiting for pod pod-subpath-test-projected-bzrs to disappear
Jul 31 06:47:06.457: INFO: Pod pod-subpath-test-projected-bzrs no longer exists
STEP: Deleting pod pod-subpath-test-projected-bzrs
Jul 31 06:47:06.457: INFO: Deleting pod "pod-subpath-test-projected-bzrs" in namespace "e2e-tests-subpath-bb8dg"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:47:06.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-bb8dg" for this suite.
Jul 31 06:47:12.469: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:47:12.530: INFO: namespace: e2e-tests-subpath-bb8dg, resource: bindings, ignored listing per whitelist
Jul 31 06:47:12.543: INFO: namespace e2e-tests-subpath-bb8dg deletion completed in 6.081149173s

• [SLOW TEST:30.213 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:47:12.543: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-06a0d41a-b35f-11e9-990e-fe448544ce72
STEP: Creating a pod to test consume secrets
Jul 31 06:47:12.605: INFO: Waiting up to 5m0s for pod "pod-secrets-06a12f1a-b35f-11e9-990e-fe448544ce72" in namespace "e2e-tests-secrets-tnbt2" to be "success or failure"
Jul 31 06:47:12.608: INFO: Pod "pod-secrets-06a12f1a-b35f-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.791628ms
Jul 31 06:47:14.611: INFO: Pod "pod-secrets-06a12f1a-b35f-11e9-990e-fe448544ce72": Phase="Running", Reason="", readiness=true. Elapsed: 2.006195509s
Jul 31 06:47:16.614: INFO: Pod "pod-secrets-06a12f1a-b35f-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009272521s
STEP: Saw pod success
Jul 31 06:47:16.614: INFO: Pod "pod-secrets-06a12f1a-b35f-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 06:47:16.617: INFO: Trying to get logs from node shushsha-k8s-worker2 pod pod-secrets-06a12f1a-b35f-11e9-990e-fe448544ce72 container secret-volume-test: <nil>
STEP: delete the pod
Jul 31 06:47:16.631: INFO: Waiting for pod pod-secrets-06a12f1a-b35f-11e9-990e-fe448544ce72 to disappear
Jul 31 06:47:16.633: INFO: Pod pod-secrets-06a12f1a-b35f-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:47:16.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-tnbt2" for this suite.
Jul 31 06:47:22.644: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:47:22.699: INFO: namespace: e2e-tests-secrets-tnbt2, resource: bindings, ignored listing per whitelist
Jul 31 06:47:22.712: INFO: namespace e2e-tests-secrets-tnbt2 deletion completed in 6.076816172s

• [SLOW TEST:10.169 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:47:22.713: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-j4rfs
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jul 31 06:47:22.767: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jul 31 06:47:40.818: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.2.85:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-j4rfs PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 31 06:47:40.818: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
Jul 31 06:47:40.944: INFO: Found all expected endpoints: [netserver-0]
Jul 31 06:47:40.946: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.1.89:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-j4rfs PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 31 06:47:40.946: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
Jul 31 06:47:41.072: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:47:41.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-j4rfs" for this suite.
Jul 31 06:48:03.084: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:48:03.112: INFO: namespace: e2e-tests-pod-network-test-j4rfs, resource: bindings, ignored listing per whitelist
Jul 31 06:48:03.151: INFO: namespace e2e-tests-pod-network-test-j4rfs deletion completed in 22.075861811s

• [SLOW TEST:40.439 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:48:03.151: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-24cb33ed-b35f-11e9-990e-fe448544ce72
STEP: Creating a pod to test consume secrets
Jul 31 06:48:03.213: INFO: Waiting up to 5m0s for pod "pod-secrets-24cb93e0-b35f-11e9-990e-fe448544ce72" in namespace "e2e-tests-secrets-7fq5v" to be "success or failure"
Jul 31 06:48:03.216: INFO: Pod "pod-secrets-24cb93e0-b35f-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.069143ms
Jul 31 06:48:05.218: INFO: Pod "pod-secrets-24cb93e0-b35f-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004759631s
STEP: Saw pod success
Jul 31 06:48:05.218: INFO: Pod "pod-secrets-24cb93e0-b35f-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 06:48:05.220: INFO: Trying to get logs from node shushsha-k8s-worker1 pod pod-secrets-24cb93e0-b35f-11e9-990e-fe448544ce72 container secret-volume-test: <nil>
STEP: delete the pod
Jul 31 06:48:05.233: INFO: Waiting for pod pod-secrets-24cb93e0-b35f-11e9-990e-fe448544ce72 to disappear
Jul 31 06:48:05.235: INFO: Pod pod-secrets-24cb93e0-b35f-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:48:05.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-7fq5v" for this suite.
Jul 31 06:48:11.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:48:11.306: INFO: namespace: e2e-tests-secrets-7fq5v, resource: bindings, ignored listing per whitelist
Jul 31 06:48:11.313: INFO: namespace e2e-tests-secrets-7fq5v deletion completed in 6.075472681s

• [SLOW TEST:8.162 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:48:11.313: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-5n7sn
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jul 31 06:48:11.366: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jul 31 06:48:35.412: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.244.2.86 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-5n7sn PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 31 06:48:35.412: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
Jul 31 06:48:36.508: INFO: Found all expected endpoints: [netserver-0]
Jul 31 06:48:36.510: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.244.1.92 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-5n7sn PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 31 06:48:36.511: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
Jul 31 06:48:37.610: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:48:37.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-5n7sn" for this suite.
Jul 31 06:48:59.622: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:48:59.681: INFO: namespace: e2e-tests-pod-network-test-5n7sn, resource: bindings, ignored listing per whitelist
Jul 31 06:48:59.690: INFO: namespace e2e-tests-pod-network-test-5n7sn deletion completed in 22.076684433s

• [SLOW TEST:48.377 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:48:59.691: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1052
STEP: creating the pod
Jul 31 06:48:59.746: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 create -f - --namespace=e2e-tests-kubectl-drqwj'
Jul 31 06:49:00.046: INFO: stderr: ""
Jul 31 06:49:00.046: INFO: stdout: "pod/pause created\n"
Jul 31 06:49:00.046: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Jul 31 06:49:00.046: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-drqwj" to be "running and ready"
Jul 31 06:49:00.048: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.102203ms
Jul 31 06:49:02.053: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.006642873s
Jul 31 06:49:02.053: INFO: Pod "pause" satisfied condition "running and ready"
Jul 31 06:49:02.053: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Jul 31 06:49:02.053: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-drqwj'
Jul 31 06:49:02.132: INFO: stderr: ""
Jul 31 06:49:02.132: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Jul 31 06:49:02.132: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 get pod pause -L testing-label --namespace=e2e-tests-kubectl-drqwj'
Jul 31 06:49:02.204: INFO: stderr: ""
Jul 31 06:49:02.204: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Jul 31 06:49:02.204: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 label pods pause testing-label- --namespace=e2e-tests-kubectl-drqwj'
Jul 31 06:49:02.281: INFO: stderr: ""
Jul 31 06:49:02.281: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Jul 31 06:49:02.281: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 get pod pause -L testing-label --namespace=e2e-tests-kubectl-drqwj'
Jul 31 06:49:02.353: INFO: stderr: ""
Jul 31 06:49:02.353: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1059
STEP: using delete to clean up resources
Jul 31 06:49:02.353: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-drqwj'
Jul 31 06:49:02.426: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 31 06:49:02.426: INFO: stdout: "pod \"pause\" force deleted\n"
Jul 31 06:49:02.426: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-drqwj'
Jul 31 06:49:02.501: INFO: stderr: "No resources found.\n"
Jul 31 06:49:02.501: INFO: stdout: ""
Jul 31 06:49:02.501: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 get pods -l name=pause --namespace=e2e-tests-kubectl-drqwj -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jul 31 06:49:02.574: INFO: stderr: ""
Jul 31 06:49:02.574: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:49:02.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-drqwj" for this suite.
Jul 31 06:49:08.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:49:08.643: INFO: namespace: e2e-tests-kubectl-drqwj, resource: bindings, ignored listing per whitelist
Jul 31 06:49:08.657: INFO: namespace e2e-tests-kubectl-drqwj deletion completed in 6.079340093s

• [SLOW TEST:8.966 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:49:08.657: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Jul 31 06:49:09.234: INFO: created pod pod-service-account-defaultsa
Jul 31 06:49:09.234: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Jul 31 06:49:09.237: INFO: created pod pod-service-account-mountsa
Jul 31 06:49:09.237: INFO: pod pod-service-account-mountsa service account token volume mount: true
Jul 31 06:49:09.243: INFO: created pod pod-service-account-nomountsa
Jul 31 06:49:09.243: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Jul 31 06:49:09.247: INFO: created pod pod-service-account-defaultsa-mountspec
Jul 31 06:49:09.247: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Jul 31 06:49:09.254: INFO: created pod pod-service-account-mountsa-mountspec
Jul 31 06:49:09.254: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Jul 31 06:49:09.259: INFO: created pod pod-service-account-nomountsa-mountspec
Jul 31 06:49:09.259: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Jul 31 06:49:09.263: INFO: created pod pod-service-account-defaultsa-nomountspec
Jul 31 06:49:09.263: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Jul 31 06:49:09.269: INFO: created pod pod-service-account-mountsa-nomountspec
Jul 31 06:49:09.269: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Jul 31 06:49:09.276: INFO: created pod pod-service-account-nomountsa-nomountspec
Jul 31 06:49:09.276: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:49:09.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-8c2q9" for this suite.
Jul 31 06:49:15.296: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:49:15.354: INFO: namespace: e2e-tests-svcaccounts-8c2q9, resource: bindings, ignored listing per whitelist
Jul 31 06:49:15.364: INFO: namespace e2e-tests-svcaccounts-8c2q9 deletion completed in 6.080000292s

• [SLOW TEST:6.707 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:49:15.364: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-4fd5a376-b35f-11e9-990e-fe448544ce72
STEP: Creating a pod to test consume secrets
Jul 31 06:49:15.424: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4fd60047-b35f-11e9-990e-fe448544ce72" in namespace "e2e-tests-projected-9d5hp" to be "success or failure"
Jul 31 06:49:15.426: INFO: Pod "pod-projected-secrets-4fd60047-b35f-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.502629ms
Jul 31 06:49:17.430: INFO: Pod "pod-projected-secrets-4fd60047-b35f-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005640784s
STEP: Saw pod success
Jul 31 06:49:17.430: INFO: Pod "pod-projected-secrets-4fd60047-b35f-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 06:49:17.432: INFO: Trying to get logs from node shushsha-k8s-worker2 pod pod-projected-secrets-4fd60047-b35f-11e9-990e-fe448544ce72 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jul 31 06:49:17.454: INFO: Waiting for pod pod-projected-secrets-4fd60047-b35f-11e9-990e-fe448544ce72 to disappear
Jul 31 06:49:17.456: INFO: Pod pod-projected-secrets-4fd60047-b35f-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:49:17.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9d5hp" for this suite.
Jul 31 06:49:23.468: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:49:23.507: INFO: namespace: e2e-tests-projected-9d5hp, resource: bindings, ignored listing per whitelist
Jul 31 06:49:23.537: INFO: namespace e2e-tests-projected-9d5hp deletion completed in 6.077752978s

• [SLOW TEST:8.173 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:49:23.538: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jul 31 06:49:23.592: INFO: Waiting up to 5m0s for pod "downwardapi-volume-54b43c2f-b35f-11e9-990e-fe448544ce72" in namespace "e2e-tests-projected-92xwj" to be "success or failure"
Jul 31 06:49:23.595: INFO: Pod "downwardapi-volume-54b43c2f-b35f-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 3.052834ms
Jul 31 06:49:25.598: INFO: Pod "downwardapi-volume-54b43c2f-b35f-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005587706s
STEP: Saw pod success
Jul 31 06:49:25.598: INFO: Pod "downwardapi-volume-54b43c2f-b35f-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 06:49:25.600: INFO: Trying to get logs from node shushsha-k8s-worker1 pod downwardapi-volume-54b43c2f-b35f-11e9-990e-fe448544ce72 container client-container: <nil>
STEP: delete the pod
Jul 31 06:49:25.613: INFO: Waiting for pod downwardapi-volume-54b43c2f-b35f-11e9-990e-fe448544ce72 to disappear
Jul 31 06:49:25.615: INFO: Pod downwardapi-volume-54b43c2f-b35f-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:49:25.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-92xwj" for this suite.
Jul 31 06:49:31.626: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:49:31.669: INFO: namespace: e2e-tests-projected-92xwj, resource: bindings, ignored listing per whitelist
Jul 31 06:49:31.694: INFO: namespace e2e-tests-projected-92xwj deletion completed in 6.075607143s

• [SLOW TEST:8.156 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:49:31.694: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Jul 31 06:49:31.748: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 api-versions'
Jul 31 06:49:31.817: INFO: stderr: ""
Jul 31 06:49:31.817: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:49:31.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-vnn9j" for this suite.
Jul 31 06:49:37.828: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:49:37.850: INFO: namespace: e2e-tests-kubectl-vnn9j, resource: bindings, ignored listing per whitelist
Jul 31 06:49:37.900: INFO: namespace e2e-tests-kubectl-vnn9j deletion completed in 6.079888619s

• [SLOW TEST:6.207 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:49:37.901: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jul 31 06:49:37.952: INFO: PodSpec: initContainers in spec.initContainers
Jul 31 06:50:21.484: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-5d442609-b35f-11e9-990e-fe448544ce72", GenerateName:"", Namespace:"e2e-tests-init-container-frxv2", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-frxv2/pods/pod-init-5d442609-b35f-11e9-990e-fe448544ce72", UID:"5d448092-b35f-11e9-ac6f-000017003e78", ResourceVersion:"10784", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63700152577, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"952314743"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-6tkfr", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0027053c0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-6tkfr", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-6tkfr", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-6tkfr", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0021f6618), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"shushsha-k8s-worker2", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002449ce0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0021f6690)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0021f66b0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0021f66b8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0021f66bc)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700152577, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700152577, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700152577, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700152577, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"100.100.230.39", PodIP:"10.244.2.94", StartTime:(*v1.Time)(0xc001fb3d20), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0027f2a10)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0027f2a80)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://6ae9e59391a82c436d5507491ebb31496cb72eae69b2e94750880bd2a79916f2"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001fb3d60), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001fb3d40), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:50:21.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-frxv2" for this suite.
Jul 31 06:50:43.497: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:50:43.538: INFO: namespace: e2e-tests-init-container-frxv2, resource: bindings, ignored listing per whitelist
Jul 31 06:50:43.565: INFO: namespace e2e-tests-init-container-frxv2 deletion completed in 22.077428034s

• [SLOW TEST:65.665 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:50:43.566: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-8468950e-b35f-11e9-990e-fe448544ce72
STEP: Creating secret with name s-test-opt-upd-8468954d-b35f-11e9-990e-fe448544ce72
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-8468950e-b35f-11e9-990e-fe448544ce72
STEP: Updating secret s-test-opt-upd-8468954d-b35f-11e9-990e-fe448544ce72
STEP: Creating secret with name s-test-opt-create-84689564-b35f-11e9-990e-fe448544ce72
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:52:16.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jmk9b" for this suite.
Jul 31 06:52:38.120: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:52:38.131: INFO: namespace: e2e-tests-projected-jmk9b, resource: bindings, ignored listing per whitelist
Jul 31 06:52:38.189: INFO: namespace e2e-tests-projected-jmk9b deletion completed in 22.076518227s

• [SLOW TEST:114.623 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:52:38.189: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Jul 31 06:52:38.260: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-zmv4n,SelfLink:/api/v1/namespaces/e2e-tests-watch-zmv4n/configmaps/e2e-watch-test-resource-version,UID:c8ba9aa6-b35f-11e9-ac6f-000017003e78,ResourceVersion:11041,Generation:0,CreationTimestamp:2019-07-31 06:52:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jul 31 06:52:38.260: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-zmv4n,SelfLink:/api/v1/namespaces/e2e-tests-watch-zmv4n/configmaps/e2e-watch-test-resource-version,UID:c8ba9aa6-b35f-11e9-ac6f-000017003e78,ResourceVersion:11042,Generation:0,CreationTimestamp:2019-07-31 06:52:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:52:38.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-zmv4n" for this suite.
Jul 31 06:52:44.271: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:52:44.300: INFO: namespace: e2e-tests-watch-zmv4n, resource: bindings, ignored listing per whitelist
Jul 31 06:52:44.339: INFO: namespace e2e-tests-watch-zmv4n deletion completed in 6.076310868s

• [SLOW TEST:6.150 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:52:44.339: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jul 31 06:52:44.390: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:52:47.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-dbq5l" for this suite.
Jul 31 06:52:53.890: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:52:53.901: INFO: namespace: e2e-tests-init-container-dbq5l, resource: bindings, ignored listing per whitelist
Jul 31 06:52:53.959: INFO: namespace e2e-tests-init-container-dbq5l deletion completed in 6.080385809s

• [SLOW TEST:9.619 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:52:53.959: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jul 31 06:52:54.017: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d2209d01-b35f-11e9-990e-fe448544ce72" in namespace "e2e-tests-projected-tvp7q" to be "success or failure"
Jul 31 06:52:54.019: INFO: Pod "downwardapi-volume-d2209d01-b35f-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.504979ms
Jul 31 06:52:56.022: INFO: Pod "downwardapi-volume-d2209d01-b35f-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005354898s
STEP: Saw pod success
Jul 31 06:52:56.022: INFO: Pod "downwardapi-volume-d2209d01-b35f-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 06:52:56.024: INFO: Trying to get logs from node shushsha-k8s-worker1 pod downwardapi-volume-d2209d01-b35f-11e9-990e-fe448544ce72 container client-container: <nil>
STEP: delete the pod
Jul 31 06:52:56.038: INFO: Waiting for pod downwardapi-volume-d2209d01-b35f-11e9-990e-fe448544ce72 to disappear
Jul 31 06:52:56.040: INFO: Pod downwardapi-volume-d2209d01-b35f-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:52:56.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-tvp7q" for this suite.
Jul 31 06:53:02.051: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:53:02.110: INFO: namespace: e2e-tests-projected-tvp7q, resource: bindings, ignored listing per whitelist
Jul 31 06:53:02.119: INFO: namespace e2e-tests-projected-tvp7q deletion completed in 6.076012555s

• [SLOW TEST:8.160 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:53:02.119: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jul 31 06:53:02.174: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d6fd4a42-b35f-11e9-990e-fe448544ce72" in namespace "e2e-tests-projected-prr8w" to be "success or failure"
Jul 31 06:53:02.177: INFO: Pod "downwardapi-volume-d6fd4a42-b35f-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.536907ms
Jul 31 06:53:04.180: INFO: Pod "downwardapi-volume-d6fd4a42-b35f-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005507122s
STEP: Saw pod success
Jul 31 06:53:04.180: INFO: Pod "downwardapi-volume-d6fd4a42-b35f-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 06:53:04.182: INFO: Trying to get logs from node shushsha-k8s-worker2 pod downwardapi-volume-d6fd4a42-b35f-11e9-990e-fe448544ce72 container client-container: <nil>
STEP: delete the pod
Jul 31 06:53:04.195: INFO: Waiting for pod downwardapi-volume-d6fd4a42-b35f-11e9-990e-fe448544ce72 to disappear
Jul 31 06:53:04.197: INFO: Pod downwardapi-volume-d6fd4a42-b35f-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:53:04.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-prr8w" for this suite.
Jul 31 06:53:10.209: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:53:10.225: INFO: namespace: e2e-tests-projected-prr8w, resource: bindings, ignored listing per whitelist
Jul 31 06:53:10.277: INFO: namespace e2e-tests-projected-prr8w deletion completed in 6.076664832s

• [SLOW TEST:8.158 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:53:10.277: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jul 31 06:53:10.382: INFO: Waiting up to 5m0s for pod "downward-api-dbe1b1bd-b35f-11e9-990e-fe448544ce72" in namespace "e2e-tests-downward-api-gvt66" to be "success or failure"
Jul 31 06:53:10.384: INFO: Pod "downward-api-dbe1b1bd-b35f-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 1.892872ms
Jul 31 06:53:12.386: INFO: Pod "downward-api-dbe1b1bd-b35f-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004750919s
STEP: Saw pod success
Jul 31 06:53:12.386: INFO: Pod "downward-api-dbe1b1bd-b35f-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 06:53:12.389: INFO: Trying to get logs from node shushsha-k8s-worker1 pod downward-api-dbe1b1bd-b35f-11e9-990e-fe448544ce72 container dapi-container: <nil>
STEP: delete the pod
Jul 31 06:53:12.401: INFO: Waiting for pod downward-api-dbe1b1bd-b35f-11e9-990e-fe448544ce72 to disappear
Jul 31 06:53:12.403: INFO: Pod downward-api-dbe1b1bd-b35f-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:53:12.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-gvt66" for this suite.
Jul 31 06:53:18.413: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:53:18.442: INFO: namespace: e2e-tests-downward-api-gvt66, resource: bindings, ignored listing per whitelist
Jul 31 06:53:18.483: INFO: namespace e2e-tests-downward-api-gvt66 deletion completed in 6.07691389s

• [SLOW TEST:8.206 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:53:18.483: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jul 31 06:53:21.051: INFO: Successfully updated pod "pod-update-activedeadlineseconds-e0be1bf0-b35f-11e9-990e-fe448544ce72"
Jul 31 06:53:21.052: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-e0be1bf0-b35f-11e9-990e-fe448544ce72" in namespace "e2e-tests-pods-vrh9r" to be "terminated due to deadline exceeded"
Jul 31 06:53:21.054: INFO: Pod "pod-update-activedeadlineseconds-e0be1bf0-b35f-11e9-990e-fe448544ce72": Phase="Running", Reason="", readiness=true. Elapsed: 1.871841ms
Jul 31 06:53:23.056: INFO: Pod "pod-update-activedeadlineseconds-e0be1bf0-b35f-11e9-990e-fe448544ce72": Phase="Running", Reason="", readiness=true. Elapsed: 2.004359442s
Jul 31 06:53:25.059: INFO: Pod "pod-update-activedeadlineseconds-e0be1bf0-b35f-11e9-990e-fe448544ce72": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.007116524s
Jul 31 06:53:25.059: INFO: Pod "pod-update-activedeadlineseconds-e0be1bf0-b35f-11e9-990e-fe448544ce72" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:53:25.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-vrh9r" for this suite.
Jul 31 06:53:31.069: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:53:31.116: INFO: namespace: e2e-tests-pods-vrh9r, resource: bindings, ignored listing per whitelist
Jul 31 06:53:31.140: INFO: namespace e2e-tests-pods-vrh9r deletion completed in 6.077817555s

• [SLOW TEST:12.657 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:53:31.140: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Jul 31 06:53:31.197: INFO: Waiting up to 5m0s for pod "pod-e849d993-b35f-11e9-990e-fe448544ce72" in namespace "e2e-tests-emptydir-6cp8v" to be "success or failure"
Jul 31 06:53:31.199: INFO: Pod "pod-e849d993-b35f-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.59481ms
Jul 31 06:53:33.202: INFO: Pod "pod-e849d993-b35f-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005389296s
STEP: Saw pod success
Jul 31 06:53:33.202: INFO: Pod "pod-e849d993-b35f-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 06:53:33.204: INFO: Trying to get logs from node shushsha-k8s-worker1 pod pod-e849d993-b35f-11e9-990e-fe448544ce72 container test-container: <nil>
STEP: delete the pod
Jul 31 06:53:33.217: INFO: Waiting for pod pod-e849d993-b35f-11e9-990e-fe448544ce72 to disappear
Jul 31 06:53:33.219: INFO: Pod pod-e849d993-b35f-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:53:33.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-6cp8v" for this suite.
Jul 31 06:53:39.230: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:53:39.248: INFO: namespace: e2e-tests-emptydir-6cp8v, resource: bindings, ignored listing per whitelist
Jul 31 06:53:39.300: INFO: namespace e2e-tests-emptydir-6cp8v deletion completed in 6.078854821s

• [SLOW TEST:8.160 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:53:39.300: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jul 31 06:53:39.359: INFO: Waiting up to 5m0s for pod "downward-api-ed271fe4-b35f-11e9-990e-fe448544ce72" in namespace "e2e-tests-downward-api-gmzsk" to be "success or failure"
Jul 31 06:53:39.360: INFO: Pod "downward-api-ed271fe4-b35f-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 1.725427ms
Jul 31 06:53:41.363: INFO: Pod "downward-api-ed271fe4-b35f-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004611322s
STEP: Saw pod success
Jul 31 06:53:41.363: INFO: Pod "downward-api-ed271fe4-b35f-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 06:53:41.365: INFO: Trying to get logs from node shushsha-k8s-worker2 pod downward-api-ed271fe4-b35f-11e9-990e-fe448544ce72 container dapi-container: <nil>
STEP: delete the pod
Jul 31 06:53:41.379: INFO: Waiting for pod downward-api-ed271fe4-b35f-11e9-990e-fe448544ce72 to disappear
Jul 31 06:53:41.381: INFO: Pod downward-api-ed271fe4-b35f-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:53:41.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-gmzsk" for this suite.
Jul 31 06:53:47.393: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:53:47.409: INFO: namespace: e2e-tests-downward-api-gmzsk, resource: bindings, ignored listing per whitelist
Jul 31 06:53:47.459: INFO: namespace e2e-tests-downward-api-gmzsk deletion completed in 6.074910472s

• [SLOW TEST:8.159 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:53:47.460: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-f2043b1b-b35f-11e9-990e-fe448544ce72
STEP: Creating a pod to test consume secrets
Jul 31 06:53:47.520: INFO: Waiting up to 5m0s for pod "pod-secrets-f204a4f4-b35f-11e9-990e-fe448544ce72" in namespace "e2e-tests-secrets-nfn8f" to be "success or failure"
Jul 31 06:53:47.522: INFO: Pod "pod-secrets-f204a4f4-b35f-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.208609ms
Jul 31 06:53:49.525: INFO: Pod "pod-secrets-f204a4f4-b35f-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004822303s
STEP: Saw pod success
Jul 31 06:53:49.525: INFO: Pod "pod-secrets-f204a4f4-b35f-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 06:53:49.527: INFO: Trying to get logs from node shushsha-k8s-worker1 pod pod-secrets-f204a4f4-b35f-11e9-990e-fe448544ce72 container secret-volume-test: <nil>
STEP: delete the pod
Jul 31 06:53:49.540: INFO: Waiting for pod pod-secrets-f204a4f4-b35f-11e9-990e-fe448544ce72 to disappear
Jul 31 06:53:49.542: INFO: Pod pod-secrets-f204a4f4-b35f-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:53:49.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-nfn8f" for this suite.
Jul 31 06:53:55.556: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:53:55.581: INFO: namespace: e2e-tests-secrets-nfn8f, resource: bindings, ignored listing per whitelist
Jul 31 06:53:55.625: INFO: namespace e2e-tests-secrets-nfn8f deletion completed in 6.077546444s

• [SLOW TEST:8.165 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:53:55.625: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-t8vt
STEP: Creating a pod to test atomic-volume-subpath
Jul 31 06:53:55.684: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-t8vt" in namespace "e2e-tests-subpath-dg2md" to be "success or failure"
Jul 31 06:53:55.686: INFO: Pod "pod-subpath-test-configmap-t8vt": Phase="Pending", Reason="", readiness=false. Elapsed: 1.893604ms
Jul 31 06:53:57.690: INFO: Pod "pod-subpath-test-configmap-t8vt": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005272534s
Jul 31 06:53:59.693: INFO: Pod "pod-subpath-test-configmap-t8vt": Phase="Running", Reason="", readiness=false. Elapsed: 4.008763821s
Jul 31 06:54:01.696: INFO: Pod "pod-subpath-test-configmap-t8vt": Phase="Running", Reason="", readiness=false. Elapsed: 6.012037128s
Jul 31 06:54:03.700: INFO: Pod "pod-subpath-test-configmap-t8vt": Phase="Running", Reason="", readiness=false. Elapsed: 8.015340045s
Jul 31 06:54:05.703: INFO: Pod "pod-subpath-test-configmap-t8vt": Phase="Running", Reason="", readiness=false. Elapsed: 10.01854343s
Jul 31 06:54:07.706: INFO: Pod "pod-subpath-test-configmap-t8vt": Phase="Running", Reason="", readiness=false. Elapsed: 12.021859036s
Jul 31 06:54:09.710: INFO: Pod "pod-subpath-test-configmap-t8vt": Phase="Running", Reason="", readiness=false. Elapsed: 14.025126919s
Jul 31 06:54:11.713: INFO: Pod "pod-subpath-test-configmap-t8vt": Phase="Running", Reason="", readiness=false. Elapsed: 16.028243981s
Jul 31 06:54:13.717: INFO: Pod "pod-subpath-test-configmap-t8vt": Phase="Running", Reason="", readiness=false. Elapsed: 18.032463804s
Jul 31 06:54:15.720: INFO: Pod "pod-subpath-test-configmap-t8vt": Phase="Running", Reason="", readiness=false. Elapsed: 20.035949046s
Jul 31 06:54:17.724: INFO: Pod "pod-subpath-test-configmap-t8vt": Phase="Running", Reason="", readiness=false. Elapsed: 22.039152356s
Jul 31 06:54:19.727: INFO: Pod "pod-subpath-test-configmap-t8vt": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.042648859s
STEP: Saw pod success
Jul 31 06:54:19.727: INFO: Pod "pod-subpath-test-configmap-t8vt" satisfied condition "success or failure"
Jul 31 06:54:19.729: INFO: Trying to get logs from node shushsha-k8s-worker2 pod pod-subpath-test-configmap-t8vt container test-container-subpath-configmap-t8vt: <nil>
STEP: delete the pod
Jul 31 06:54:19.746: INFO: Waiting for pod pod-subpath-test-configmap-t8vt to disappear
Jul 31 06:54:19.748: INFO: Pod pod-subpath-test-configmap-t8vt no longer exists
STEP: Deleting pod pod-subpath-test-configmap-t8vt
Jul 31 06:54:19.748: INFO: Deleting pod "pod-subpath-test-configmap-t8vt" in namespace "e2e-tests-subpath-dg2md"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:54:19.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-dg2md" for this suite.
Jul 31 06:54:25.760: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:54:25.823: INFO: namespace: e2e-tests-subpath-dg2md, resource: bindings, ignored listing per whitelist
Jul 31 06:54:25.832: INFO: namespace e2e-tests-subpath-dg2md deletion completed in 6.079763872s

• [SLOW TEST:30.207 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:54:25.833: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Jul 31 06:54:25.897: INFO: Waiting up to 5m0s for pod "pod-08e467a9-b360-11e9-990e-fe448544ce72" in namespace "e2e-tests-emptydir-ls6b4" to be "success or failure"
Jul 31 06:54:25.899: INFO: Pod "pod-08e467a9-b360-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.612664ms
Jul 31 06:54:27.902: INFO: Pod "pod-08e467a9-b360-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005030836s
STEP: Saw pod success
Jul 31 06:54:27.902: INFO: Pod "pod-08e467a9-b360-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 06:54:27.904: INFO: Trying to get logs from node shushsha-k8s-worker1 pod pod-08e467a9-b360-11e9-990e-fe448544ce72 container test-container: <nil>
STEP: delete the pod
Jul 31 06:54:27.916: INFO: Waiting for pod pod-08e467a9-b360-11e9-990e-fe448544ce72 to disappear
Jul 31 06:54:27.918: INFO: Pod pod-08e467a9-b360-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:54:27.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-ls6b4" for this suite.
Jul 31 06:54:33.929: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:54:33.943: INFO: namespace: e2e-tests-emptydir-ls6b4, resource: bindings, ignored listing per whitelist
Jul 31 06:54:33.996: INFO: namespace e2e-tests-emptydir-ls6b4 deletion completed in 6.075491931s

• [SLOW TEST:8.163 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:54:33.996: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-0dc09177-b360-11e9-990e-fe448544ce72
STEP: Creating a pod to test consume configMaps
Jul 31 06:54:34.053: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0dc0e833-b360-11e9-990e-fe448544ce72" in namespace "e2e-tests-projected-wpkzk" to be "success or failure"
Jul 31 06:54:34.059: INFO: Pod "pod-projected-configmaps-0dc0e833-b360-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 5.437863ms
Jul 31 06:54:36.061: INFO: Pod "pod-projected-configmaps-0dc0e833-b360-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008255207s
Jul 31 06:54:38.064: INFO: Pod "pod-projected-configmaps-0dc0e833-b360-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010775977s
STEP: Saw pod success
Jul 31 06:54:38.064: INFO: Pod "pod-projected-configmaps-0dc0e833-b360-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 06:54:38.066: INFO: Trying to get logs from node shushsha-k8s-worker2 pod pod-projected-configmaps-0dc0e833-b360-11e9-990e-fe448544ce72 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jul 31 06:54:38.080: INFO: Waiting for pod pod-projected-configmaps-0dc0e833-b360-11e9-990e-fe448544ce72 to disappear
Jul 31 06:54:38.083: INFO: Pod pod-projected-configmaps-0dc0e833-b360-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:54:38.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wpkzk" for this suite.
Jul 31 06:54:44.094: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:54:44.144: INFO: namespace: e2e-tests-projected-wpkzk, resource: bindings, ignored listing per whitelist
Jul 31 06:54:44.161: INFO: namespace e2e-tests-projected-wpkzk deletion completed in 6.074017822s

• [SLOW TEST:10.164 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:54:44.161: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Jul 31 06:54:50.239: INFO: MetricsGrabber failed grab metrics. Skipping metrics gathering.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:54:50.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-mvpbj" for this suite.
Jul 31 06:54:56.250: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:54:56.272: INFO: namespace: e2e-tests-gc-mvpbj, resource: bindings, ignored listing per whitelist
Jul 31 06:54:56.319: INFO: namespace e2e-tests-gc-mvpbj deletion completed in 6.076842179s

• [SLOW TEST:12.157 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:54:56.319: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-1b0facef-b360-11e9-990e-fe448544ce72
STEP: Creating a pod to test consume secrets
Jul 31 06:54:56.382: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1b1009d2-b360-11e9-990e-fe448544ce72" in namespace "e2e-tests-projected-tjdw2" to be "success or failure"
Jul 31 06:54:56.384: INFO: Pod "pod-projected-secrets-1b1009d2-b360-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 1.952989ms
Jul 31 06:54:58.387: INFO: Pod "pod-projected-secrets-1b1009d2-b360-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005093559s
STEP: Saw pod success
Jul 31 06:54:58.387: INFO: Pod "pod-projected-secrets-1b1009d2-b360-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 06:54:58.389: INFO: Trying to get logs from node shushsha-k8s-worker1 pod pod-projected-secrets-1b1009d2-b360-11e9-990e-fe448544ce72 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jul 31 06:54:58.403: INFO: Waiting for pod pod-projected-secrets-1b1009d2-b360-11e9-990e-fe448544ce72 to disappear
Jul 31 06:54:58.405: INFO: Pod pod-projected-secrets-1b1009d2-b360-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:54:58.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-tjdw2" for this suite.
Jul 31 06:55:04.415: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:55:04.428: INFO: namespace: e2e-tests-projected-tjdw2, resource: bindings, ignored listing per whitelist
Jul 31 06:55:04.484: INFO: namespace e2e-tests-projected-tjdw2 deletion completed in 6.076533858s

• [SLOW TEST:8.165 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:55:04.484: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:55:06.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-hnsvj" for this suite.
Jul 31 06:55:56.565: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:55:56.596: INFO: namespace: e2e-tests-kubelet-test-hnsvj, resource: bindings, ignored listing per whitelist
Jul 31 06:55:56.638: INFO: namespace e2e-tests-kubelet-test-hnsvj deletion completed in 50.081589298s

• [SLOW TEST:52.154 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:55:56.639: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jul 31 06:55:56.703: INFO: (0) /api/v1/nodes/shushsha-k8s-worker1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.926094ms)
Jul 31 06:55:56.706: INFO: (1) /api/v1/nodes/shushsha-k8s-worker1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.802463ms)
Jul 31 06:55:56.709: INFO: (2) /api/v1/nodes/shushsha-k8s-worker1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.958617ms)
Jul 31 06:55:56.712: INFO: (3) /api/v1/nodes/shushsha-k8s-worker1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.037963ms)
Jul 31 06:55:56.715: INFO: (4) /api/v1/nodes/shushsha-k8s-worker1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.863089ms)
Jul 31 06:55:56.717: INFO: (5) /api/v1/nodes/shushsha-k8s-worker1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.851749ms)
Jul 31 06:55:56.720: INFO: (6) /api/v1/nodes/shushsha-k8s-worker1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.965635ms)
Jul 31 06:55:56.723: INFO: (7) /api/v1/nodes/shushsha-k8s-worker1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.974446ms)
Jul 31 06:55:56.727: INFO: (8) /api/v1/nodes/shushsha-k8s-worker1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.048924ms)
Jul 31 06:55:56.730: INFO: (9) /api/v1/nodes/shushsha-k8s-worker1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.994286ms)
Jul 31 06:55:56.732: INFO: (10) /api/v1/nodes/shushsha-k8s-worker1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.750288ms)
Jul 31 06:55:56.735: INFO: (11) /api/v1/nodes/shushsha-k8s-worker1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.881334ms)
Jul 31 06:55:56.738: INFO: (12) /api/v1/nodes/shushsha-k8s-worker1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.82014ms)
Jul 31 06:55:56.741: INFO: (13) /api/v1/nodes/shushsha-k8s-worker1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.8598ms)
Jul 31 06:55:56.744: INFO: (14) /api/v1/nodes/shushsha-k8s-worker1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.710719ms)
Jul 31 06:55:56.747: INFO: (15) /api/v1/nodes/shushsha-k8s-worker1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.746614ms)
Jul 31 06:55:56.749: INFO: (16) /api/v1/nodes/shushsha-k8s-worker1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.666061ms)
Jul 31 06:55:56.752: INFO: (17) /api/v1/nodes/shushsha-k8s-worker1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.996499ms)
Jul 31 06:55:56.755: INFO: (18) /api/v1/nodes/shushsha-k8s-worker1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.973204ms)
Jul 31 06:55:56.758: INFO: (19) /api/v1/nodes/shushsha-k8s-worker1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.888751ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:55:56.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-vdxg8" for this suite.
Jul 31 06:56:02.769: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:56:02.825: INFO: namespace: e2e-tests-proxy-vdxg8, resource: bindings, ignored listing per whitelist
Jul 31 06:56:02.842: INFO: namespace e2e-tests-proxy-vdxg8 deletion completed in 6.081282355s

• [SLOW TEST:6.204 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:56:02.843: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Jul 31 06:56:04.916: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-42b602d2-b360-11e9-990e-fe448544ce72", GenerateName:"", Namespace:"e2e-tests-pods-5hpw8", SelfLink:"/api/v1/namespaces/e2e-tests-pods-5hpw8/pods/pod-submit-remove-42b602d2-b360-11e9-990e-fe448544ce72", UID:"42b6dbd7-b360-11e9-ac6f-000017003e78", ResourceVersion:"11923", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63700152962, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"896770281"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-kf587", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0026a2b00), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-kf587", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0022fa5a8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"shushsha-k8s-worker1", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002d1a1e0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0022fa5e0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0022fa600)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0022fa608), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0022fa60c)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700152962, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700152964, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700152964, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700152962, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"100.100.230.30", PodIP:"10.244.1.110", StartTime:(*v1.Time)(0xc002d188a0), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc002d188c0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7", ContainerID:"docker://20f4c1438cd0e2307664562831bd30ce91aa3ac3636c992b8aa498ba0819091d"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:56:12.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-5hpw8" for this suite.
Jul 31 06:56:18.727: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:56:18.774: INFO: namespace: e2e-tests-pods-5hpw8, resource: bindings, ignored listing per whitelist
Jul 31 06:56:18.803: INFO: namespace e2e-tests-pods-5hpw8 deletion completed in 6.085334341s

• [SLOW TEST:15.961 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:56:18.804: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:56:20.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-lkf9q" for this suite.
Jul 31 06:56:58.894: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:56:58.958: INFO: namespace: e2e-tests-kubelet-test-lkf9q, resource: bindings, ignored listing per whitelist
Jul 31 06:56:58.964: INFO: namespace e2e-tests-kubelet-test-lkf9q deletion completed in 38.078457561s

• [SLOW TEST:40.160 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:56:58.964: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:57:05.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-8zcjc" for this suite.
Jul 31 06:57:11.080: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:57:11.139: INFO: namespace: e2e-tests-namespaces-8zcjc, resource: bindings, ignored listing per whitelist
Jul 31 06:57:11.149: INFO: namespace e2e-tests-namespaces-8zcjc deletion completed in 6.076914502s
STEP: Destroying namespace "e2e-tests-nsdeletetest-z6zdr" for this suite.
Jul 31 06:57:11.151: INFO: Namespace e2e-tests-nsdeletetest-z6zdr was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-89ffd" for this suite.
Jul 31 06:57:17.159: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:57:17.214: INFO: namespace: e2e-tests-nsdeletetest-89ffd, resource: bindings, ignored listing per whitelist
Jul 31 06:57:17.227: INFO: namespace e2e-tests-nsdeletetest-89ffd deletion completed in 6.075975823s

• [SLOW TEST:18.263 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:57:17.227: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-wqzwb
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jul 31 06:57:17.282: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jul 31 06:57:35.331: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.112:8080/dial?request=hostName&protocol=http&host=10.244.2.109&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-wqzwb PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 31 06:57:35.331: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
Jul 31 06:57:35.458: INFO: Waiting for endpoints: map[]
Jul 31 06:57:35.460: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.112:8080/dial?request=hostName&protocol=http&host=10.244.1.111&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-wqzwb PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 31 06:57:35.460: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
Jul 31 06:57:35.584: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:57:35.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-wqzwb" for this suite.
Jul 31 06:57:57.595: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:57:57.628: INFO: namespace: e2e-tests-pod-network-test-wqzwb, resource: bindings, ignored listing per whitelist
Jul 31 06:57:57.670: INFO: namespace e2e-tests-pod-network-test-wqzwb deletion completed in 22.083064855s

• [SLOW TEST:40.443 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:57:57.671: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Jul 31 06:57:57.733: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-fwd4f,SelfLink:/api/v1/namespaces/e2e-tests-watch-fwd4f/configmaps/e2e-watch-test-watch-closed,UID:8727cddf-b360-11e9-ac6f-000017003e78,ResourceVersion:12228,Generation:0,CreationTimestamp:2019-07-31 06:57:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jul 31 06:57:57.733: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-fwd4f,SelfLink:/api/v1/namespaces/e2e-tests-watch-fwd4f/configmaps/e2e-watch-test-watch-closed,UID:8727cddf-b360-11e9-ac6f-000017003e78,ResourceVersion:12229,Generation:0,CreationTimestamp:2019-07-31 06:57:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Jul 31 06:57:57.743: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-fwd4f,SelfLink:/api/v1/namespaces/e2e-tests-watch-fwd4f/configmaps/e2e-watch-test-watch-closed,UID:8727cddf-b360-11e9-ac6f-000017003e78,ResourceVersion:12230,Generation:0,CreationTimestamp:2019-07-31 06:57:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jul 31 06:57:57.743: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-fwd4f,SelfLink:/api/v1/namespaces/e2e-tests-watch-fwd4f/configmaps/e2e-watch-test-watch-closed,UID:8727cddf-b360-11e9-ac6f-000017003e78,ResourceVersion:12231,Generation:0,CreationTimestamp:2019-07-31 06:57:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:57:57.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-fwd4f" for this suite.
Jul 31 06:58:03.753: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:58:03.817: INFO: namespace: e2e-tests-watch-fwd4f, resource: bindings, ignored listing per whitelist
Jul 31 06:58:03.823: INFO: namespace e2e-tests-watch-fwd4f deletion completed in 6.077069081s

• [SLOW TEST:6.152 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:58:03.823: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Jul 31 06:58:03.890: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-vw47s,SelfLink:/api/v1/namespaces/e2e-tests-watch-vw47s/configmaps/e2e-watch-test-label-changed,UID:8ad2aa9e-b360-11e9-ac6f-000017003e78,ResourceVersion:12250,Generation:0,CreationTimestamp:2019-07-31 06:58:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jul 31 06:58:03.891: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-vw47s,SelfLink:/api/v1/namespaces/e2e-tests-watch-vw47s/configmaps/e2e-watch-test-label-changed,UID:8ad2aa9e-b360-11e9-ac6f-000017003e78,ResourceVersion:12251,Generation:0,CreationTimestamp:2019-07-31 06:58:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Jul 31 06:58:03.891: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-vw47s,SelfLink:/api/v1/namespaces/e2e-tests-watch-vw47s/configmaps/e2e-watch-test-label-changed,UID:8ad2aa9e-b360-11e9-ac6f-000017003e78,ResourceVersion:12252,Generation:0,CreationTimestamp:2019-07-31 06:58:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Jul 31 06:58:13.909: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-vw47s,SelfLink:/api/v1/namespaces/e2e-tests-watch-vw47s/configmaps/e2e-watch-test-label-changed,UID:8ad2aa9e-b360-11e9-ac6f-000017003e78,ResourceVersion:12268,Generation:0,CreationTimestamp:2019-07-31 06:58:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jul 31 06:58:13.909: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-vw47s,SelfLink:/api/v1/namespaces/e2e-tests-watch-vw47s/configmaps/e2e-watch-test-label-changed,UID:8ad2aa9e-b360-11e9-ac6f-000017003e78,ResourceVersion:12269,Generation:0,CreationTimestamp:2019-07-31 06:58:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Jul 31 06:58:13.909: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-vw47s,SelfLink:/api/v1/namespaces/e2e-tests-watch-vw47s/configmaps/e2e-watch-test-label-changed,UID:8ad2aa9e-b360-11e9-ac6f-000017003e78,ResourceVersion:12270,Generation:0,CreationTimestamp:2019-07-31 06:58:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 06:58:13.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-vw47s" for this suite.
Jul 31 06:58:19.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 06:58:19.986: INFO: namespace: e2e-tests-watch-vw47s, resource: bindings, ignored listing per whitelist
Jul 31 06:58:19.990: INFO: namespace e2e-tests-watch-vw47s deletion completed in 6.078699706s

• [SLOW TEST:16.168 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 06:58:19.991: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-4kxdq
Jul 31 06:58:22.054: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-4kxdq
STEP: checking the pod's current state and verifying that restartCount is present
Jul 31 06:58:22.056: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:02:22.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-4kxdq" for this suite.
Jul 31 07:02:28.435: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:02:28.493: INFO: namespace: e2e-tests-container-probe-4kxdq, resource: bindings, ignored listing per whitelist
Jul 31 07:02:28.505: INFO: namespace e2e-tests-container-probe-4kxdq deletion completed in 6.077315278s

• [SLOW TEST:248.515 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:02:28.506: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1134
STEP: creating an rc
Jul 31 07:02:28.559: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 create -f - --namespace=e2e-tests-kubectl-2ldhq'
Jul 31 07:02:28.858: INFO: stderr: ""
Jul 31 07:02:28.859: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Jul 31 07:02:29.862: INFO: Selector matched 1 pods for map[app:redis]
Jul 31 07:02:29.862: INFO: Found 0 / 1
Jul 31 07:02:30.861: INFO: Selector matched 1 pods for map[app:redis]
Jul 31 07:02:30.862: INFO: Found 1 / 1
Jul 31 07:02:30.862: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jul 31 07:02:30.864: INFO: Selector matched 1 pods for map[app:redis]
Jul 31 07:02:30.864: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Jul 31 07:02:30.864: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 logs redis-master-f2krj redis-master --namespace=e2e-tests-kubectl-2ldhq'
Jul 31 07:02:30.949: INFO: stderr: ""
Jul 31 07:02:30.949: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 31 Jul 07:02:29.899 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 31 Jul 07:02:29.899 # Server started, Redis version 3.2.12\n1:M 31 Jul 07:02:29.900 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 31 Jul 07:02:29.900 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Jul 31 07:02:30.949: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 log redis-master-f2krj redis-master --namespace=e2e-tests-kubectl-2ldhq --tail=1'
Jul 31 07:02:31.036: INFO: stderr: ""
Jul 31 07:02:31.036: INFO: stdout: "1:M 31 Jul 07:02:29.900 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Jul 31 07:02:31.036: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 log redis-master-f2krj redis-master --namespace=e2e-tests-kubectl-2ldhq --limit-bytes=1'
Jul 31 07:02:31.120: INFO: stderr: ""
Jul 31 07:02:31.120: INFO: stdout: " "
STEP: exposing timestamps
Jul 31 07:02:31.120: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 log redis-master-f2krj redis-master --namespace=e2e-tests-kubectl-2ldhq --tail=1 --timestamps'
Jul 31 07:02:31.204: INFO: stderr: ""
Jul 31 07:02:31.204: INFO: stdout: "2019-07-31T07:02:29.900681943Z 1:M 31 Jul 07:02:29.900 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Jul 31 07:02:33.704: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 log redis-master-f2krj redis-master --namespace=e2e-tests-kubectl-2ldhq --since=1s'
Jul 31 07:02:33.789: INFO: stderr: ""
Jul 31 07:02:33.789: INFO: stdout: ""
Jul 31 07:02:33.789: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 log redis-master-f2krj redis-master --namespace=e2e-tests-kubectl-2ldhq --since=24h'
Jul 31 07:02:33.874: INFO: stderr: ""
Jul 31 07:02:33.874: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 31 Jul 07:02:29.899 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 31 Jul 07:02:29.899 # Server started, Redis version 3.2.12\n1:M 31 Jul 07:02:29.900 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 31 Jul 07:02:29.900 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1140
STEP: using delete to clean up resources
Jul 31 07:02:33.874: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-2ldhq'
Jul 31 07:02:33.947: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 31 07:02:33.947: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Jul 31 07:02:33.947: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-2ldhq'
Jul 31 07:02:34.030: INFO: stderr: "No resources found.\n"
Jul 31 07:02:34.030: INFO: stdout: ""
Jul 31 07:02:34.030: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 get pods -l name=nginx --namespace=e2e-tests-kubectl-2ldhq -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jul 31 07:02:34.131: INFO: stderr: ""
Jul 31 07:02:34.131: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:02:34.131: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2ldhq" for this suite.
Jul 31 07:02:56.143: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:02:56.172: INFO: namespace: e2e-tests-kubectl-2ldhq, resource: bindings, ignored listing per whitelist
Jul 31 07:02:56.217: INFO: namespace e2e-tests-kubectl-2ldhq deletion completed in 22.081347053s

• [SLOW TEST:27.711 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:02:56.217: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-391b3474-b361-11e9-990e-fe448544ce72
STEP: Creating a pod to test consume configMaps
Jul 31 07:02:56.286: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-391b927a-b361-11e9-990e-fe448544ce72" in namespace "e2e-tests-projected-47cgz" to be "success or failure"
Jul 31 07:02:56.288: INFO: Pod "pod-projected-configmaps-391b927a-b361-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.262074ms
Jul 31 07:02:58.291: INFO: Pod "pod-projected-configmaps-391b927a-b361-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005050298s
STEP: Saw pod success
Jul 31 07:02:58.291: INFO: Pod "pod-projected-configmaps-391b927a-b361-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 07:02:58.293: INFO: Trying to get logs from node shushsha-k8s-worker1 pod pod-projected-configmaps-391b927a-b361-11e9-990e-fe448544ce72 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jul 31 07:02:58.307: INFO: Waiting for pod pod-projected-configmaps-391b927a-b361-11e9-990e-fe448544ce72 to disappear
Jul 31 07:02:58.309: INFO: Pod pod-projected-configmaps-391b927a-b361-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:02:58.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-47cgz" for this suite.
Jul 31 07:03:04.322: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:03:04.348: INFO: namespace: e2e-tests-projected-47cgz, resource: bindings, ignored listing per whitelist
Jul 31 07:03:04.401: INFO: namespace e2e-tests-projected-47cgz deletion completed in 6.088138434s

• [SLOW TEST:8.184 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:03:04.402: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jul 31 07:03:06.986: INFO: Successfully updated pod "labelsupdate3dfb5f83-b361-11e9-990e-fe448544ce72"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:03:09.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-xsh5h" for this suite.
Jul 31 07:03:31.014: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:03:31.067: INFO: namespace: e2e-tests-downward-api-xsh5h, resource: bindings, ignored listing per whitelist
Jul 31 07:03:31.088: INFO: namespace e2e-tests-downward-api-xsh5h deletion completed in 22.081914761s

• [SLOW TEST:26.686 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:03:31.088: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Jul 31 07:04:01.673: INFO: MetricsGrabber failed grab metrics. Skipping metrics gathering.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:04:01.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-fqzwn" for this suite.
Jul 31 07:04:07.685: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:04:07.738: INFO: namespace: e2e-tests-gc-fqzwn, resource: bindings, ignored listing per whitelist
Jul 31 07:04:07.757: INFO: namespace e2e-tests-gc-fqzwn deletion completed in 6.080967676s

• [SLOW TEST:36.669 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:04:07.758: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jul 31 07:04:07.819: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-4vjxt'
Jul 31 07:04:07.904: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jul 31 07:04:07.904: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Jul 31 07:04:07.913: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-r4lq4]
Jul 31 07:04:07.913: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-r4lq4" in namespace "e2e-tests-kubectl-4vjxt" to be "running and ready"
Jul 31 07:04:07.916: INFO: Pod "e2e-test-nginx-rc-r4lq4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.763136ms
Jul 31 07:04:09.918: INFO: Pod "e2e-test-nginx-rc-r4lq4": Phase="Running", Reason="", readiness=true. Elapsed: 2.005675049s
Jul 31 07:04:09.919: INFO: Pod "e2e-test-nginx-rc-r4lq4" satisfied condition "running and ready"
Jul 31 07:04:09.919: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-r4lq4]
Jul 31 07:04:09.919: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-4vjxt'
Jul 31 07:04:10.109: INFO: stderr: ""
Jul 31 07:04:10.109: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1303
Jul 31 07:04:10.109: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-4vjxt'
Jul 31 07:04:10.199: INFO: stderr: ""
Jul 31 07:04:10.199: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:04:10.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-4vjxt" for this suite.
Jul 31 07:04:32.211: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:04:32.240: INFO: namespace: e2e-tests-kubectl-4vjxt, resource: bindings, ignored listing per whitelist
Jul 31 07:04:32.285: INFO: namespace e2e-tests-kubectl-4vjxt deletion completed in 22.081824931s

• [SLOW TEST:24.527 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:04:32.285: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:04:34.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-wwfgr" for this suite.
Jul 31 07:05:12.380: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:05:12.396: INFO: namespace: e2e-tests-kubelet-test-wwfgr, resource: bindings, ignored listing per whitelist
Jul 31 07:05:12.453: INFO: namespace e2e-tests-kubelet-test-wwfgr deletion completed in 38.080880544s

• [SLOW TEST:40.167 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a read only busybox container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:186
    should not write to root filesystem [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:05:12.453: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jul 31 07:05:12.522: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Jul 31 07:05:17.525: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jul 31 07:05:17.526: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jul 31 07:05:17.540: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-lbdcb,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-lbdcb/deployments/test-cleanup-deployment,UID:8d4c6a6c-b361-11e9-ac6f-000017003e78,ResourceVersion:13115,Generation:1,CreationTimestamp:2019-07-31 07:05:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Jul 31 07:05:17.543: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Jul 31 07:05:17.543: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Jul 31 07:05:17.543: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:e2e-tests-deployment-lbdcb,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-lbdcb/replicasets/test-cleanup-controller,UID:8a4f829d-b361-11e9-ac6f-000017003e78,ResourceVersion:13116,Generation:1,CreationTimestamp:2019-07-31 07:05:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 8d4c6a6c-b361-11e9-ac6f-000017003e78 0xc001a08c27 0xc001a08c28}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jul 31 07:05:17.548: INFO: Pod "test-cleanup-controller-v5jvn" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-v5jvn,GenerateName:test-cleanup-controller-,Namespace:e2e-tests-deployment-lbdcb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lbdcb/pods/test-cleanup-controller-v5jvn,UID:8a50b836-b361-11e9-ac6f-000017003e78,ResourceVersion:13108,Generation:0,CreationTimestamp:2019-07-31 07:05:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller 8a4f829d-b361-11e9-ac6f-000017003e78 0xc001a09777 0xc001a09778}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-2rn8s {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2rn8s,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-2rn8s true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shushsha-k8s-worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a098e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a09900}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 07:05:12 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 07:05:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 07:05:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 07:05:12 +0000 UTC  }],Message:,Reason:,HostIP:100.100.230.30,PodIP:10.244.1.117,StartTime:2019-07-31 07:05:12 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-07-31 07:05:13 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://ad1fad8848672b6bcebedd5863d69a7eb35ff20a343e25db8796f8b11dd58f05}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:05:17.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-lbdcb" for this suite.
Jul 31 07:05:23.569: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:05:23.625: INFO: namespace: e2e-tests-deployment-lbdcb, resource: bindings, ignored listing per whitelist
Jul 31 07:05:23.641: INFO: namespace e2e-tests-deployment-lbdcb deletion completed in 6.081721159s

• [SLOW TEST:11.187 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:05:23.641: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:05:27.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-d2l4p" for this suite.
Jul 31 07:05:33.718: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:05:33.765: INFO: namespace: e2e-tests-kubelet-test-d2l4p, resource: bindings, ignored listing per whitelist
Jul 31 07:05:33.794: INFO: namespace e2e-tests-kubelet-test-d2l4p deletion completed in 6.0838062s

• [SLOW TEST:10.153 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:05:33.794: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Jul 31 07:05:33.870: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-k88c4,SelfLink:/api/v1/namespaces/e2e-tests-watch-k88c4/configmaps/e2e-watch-test-configmap-a,UID:97096cfe-b361-11e9-ac6f-000017003e78,ResourceVersion:13208,Generation:0,CreationTimestamp:2019-07-31 07:05:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jul 31 07:05:33.870: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-k88c4,SelfLink:/api/v1/namespaces/e2e-tests-watch-k88c4/configmaps/e2e-watch-test-configmap-a,UID:97096cfe-b361-11e9-ac6f-000017003e78,ResourceVersion:13208,Generation:0,CreationTimestamp:2019-07-31 07:05:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Jul 31 07:05:43.877: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-k88c4,SelfLink:/api/v1/namespaces/e2e-tests-watch-k88c4/configmaps/e2e-watch-test-configmap-a,UID:97096cfe-b361-11e9-ac6f-000017003e78,ResourceVersion:13223,Generation:0,CreationTimestamp:2019-07-31 07:05:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Jul 31 07:05:43.877: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-k88c4,SelfLink:/api/v1/namespaces/e2e-tests-watch-k88c4/configmaps/e2e-watch-test-configmap-a,UID:97096cfe-b361-11e9-ac6f-000017003e78,ResourceVersion:13223,Generation:0,CreationTimestamp:2019-07-31 07:05:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Jul 31 07:05:53.883: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-k88c4,SelfLink:/api/v1/namespaces/e2e-tests-watch-k88c4/configmaps/e2e-watch-test-configmap-a,UID:97096cfe-b361-11e9-ac6f-000017003e78,ResourceVersion:13238,Generation:0,CreationTimestamp:2019-07-31 07:05:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jul 31 07:05:53.884: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-k88c4,SelfLink:/api/v1/namespaces/e2e-tests-watch-k88c4/configmaps/e2e-watch-test-configmap-a,UID:97096cfe-b361-11e9-ac6f-000017003e78,ResourceVersion:13238,Generation:0,CreationTimestamp:2019-07-31 07:05:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Jul 31 07:06:03.889: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-k88c4,SelfLink:/api/v1/namespaces/e2e-tests-watch-k88c4/configmaps/e2e-watch-test-configmap-a,UID:97096cfe-b361-11e9-ac6f-000017003e78,ResourceVersion:13253,Generation:0,CreationTimestamp:2019-07-31 07:05:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jul 31 07:06:03.889: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-k88c4,SelfLink:/api/v1/namespaces/e2e-tests-watch-k88c4/configmaps/e2e-watch-test-configmap-a,UID:97096cfe-b361-11e9-ac6f-000017003e78,ResourceVersion:13253,Generation:0,CreationTimestamp:2019-07-31 07:05:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Jul 31 07:06:13.895: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-k88c4,SelfLink:/api/v1/namespaces/e2e-tests-watch-k88c4/configmaps/e2e-watch-test-configmap-b,UID:aee44ce7-b361-11e9-ac6f-000017003e78,ResourceVersion:13268,Generation:0,CreationTimestamp:2019-07-31 07:06:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jul 31 07:06:13.895: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-k88c4,SelfLink:/api/v1/namespaces/e2e-tests-watch-k88c4/configmaps/e2e-watch-test-configmap-b,UID:aee44ce7-b361-11e9-ac6f-000017003e78,ResourceVersion:13268,Generation:0,CreationTimestamp:2019-07-31 07:06:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Jul 31 07:06:23.901: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-k88c4,SelfLink:/api/v1/namespaces/e2e-tests-watch-k88c4/configmaps/e2e-watch-test-configmap-b,UID:aee44ce7-b361-11e9-ac6f-000017003e78,ResourceVersion:13283,Generation:0,CreationTimestamp:2019-07-31 07:06:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jul 31 07:06:23.901: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-k88c4,SelfLink:/api/v1/namespaces/e2e-tests-watch-k88c4/configmaps/e2e-watch-test-configmap-b,UID:aee44ce7-b361-11e9-ac6f-000017003e78,ResourceVersion:13283,Generation:0,CreationTimestamp:2019-07-31 07:06:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:06:33.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-k88c4" for this suite.
Jul 31 07:06:39.914: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:06:39.941: INFO: namespace: e2e-tests-watch-k88c4, resource: bindings, ignored listing per whitelist
Jul 31 07:06:39.989: INFO: namespace e2e-tests-watch-k88c4 deletion completed in 6.08328961s

• [SLOW TEST:66.195 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:06:39.989: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Jul 31 07:06:40.051: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jul 31 07:06:40.057: INFO: Waiting for terminating namespaces to be deleted...
Jul 31 07:06:40.059: INFO: 
Logging pods the kubelet thinks is on node shushsha-k8s-worker1 before test
Jul 31 07:06:40.064: INFO: kube-flannel-ds-9jt4h from kube-system started at 2019-07-31 06:05:43 +0000 UTC (1 container statuses recorded)
Jul 31 07:06:40.064: INFO: 	Container kube-flannel ready: true, restart count 0
Jul 31 07:06:40.064: INFO: sonobuoy from heptio-sonobuoy started at 2019-07-31 06:07:48 +0000 UTC (1 container statuses recorded)
Jul 31 07:06:40.064: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jul 31 07:06:40.064: INFO: nginx-7cdbd8cdc9-gpjlv from default started at 2019-07-31 06:08:14 +0000 UTC (1 container statuses recorded)
Jul 31 07:06:40.064: INFO: 	Container nginx ready: true, restart count 0
Jul 31 07:06:40.064: INFO: kube-proxy-7z76l from kube-system started at 2019-07-31 06:05:42 +0000 UTC (1 container statuses recorded)
Jul 31 07:06:40.064: INFO: 	Container kube-proxy ready: true, restart count 0
Jul 31 07:06:40.064: INFO: sonobuoy-systemd-logs-daemon-set-e7f83d409c1d4c2e-fn8j6 from heptio-sonobuoy started at 2019-07-31 06:07:55 +0000 UTC (2 container statuses recorded)
Jul 31 07:06:40.064: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jul 31 07:06:40.064: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul 31 07:06:40.064: INFO: 
Logging pods the kubelet thinks is on node shushsha-k8s-worker2 before test
Jul 31 07:06:40.070: INFO: sonobuoy-e2e-job-35084b16218148db from heptio-sonobuoy started at 2019-07-31 06:07:55 +0000 UTC (2 container statuses recorded)
Jul 31 07:06:40.070: INFO: 	Container e2e ready: true, restart count 0
Jul 31 07:06:40.070: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul 31 07:06:40.070: INFO: kube-flannel-ds-flmdc from kube-system started at 2019-07-31 06:05:45 +0000 UTC (1 container statuses recorded)
Jul 31 07:06:40.070: INFO: 	Container kube-flannel ready: true, restart count 0
Jul 31 07:06:40.070: INFO: kube-proxy-2wjnv from kube-system started at 2019-07-31 06:05:45 +0000 UTC (1 container statuses recorded)
Jul 31 07:06:40.070: INFO: 	Container kube-proxy ready: true, restart count 0
Jul 31 07:06:40.070: INFO: sonobuoy-systemd-logs-daemon-set-e7f83d409c1d4c2e-qgszv from heptio-sonobuoy started at 2019-07-31 06:07:55 +0000 UTC (2 container statuses recorded)
Jul 31 07:06:40.070: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jul 31 07:06:40.070: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15b66c1ecbd46ead], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:06:41.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-8l7c8" for this suite.
Jul 31 07:06:47.097: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:06:47.158: INFO: namespace: e2e-tests-sched-pred-8l7c8, resource: bindings, ignored listing per whitelist
Jul 31 07:06:47.173: INFO: namespace e2e-tests-sched-pred-8l7c8 deletion completed in 6.084157332s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.184 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:06:47.174: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-c2c3d8bf-b361-11e9-990e-fe448544ce72
STEP: Creating a pod to test consume secrets
Jul 31 07:06:47.239: INFO: Waiting up to 5m0s for pod "pod-secrets-c2c43d52-b361-11e9-990e-fe448544ce72" in namespace "e2e-tests-secrets-czkqv" to be "success or failure"
Jul 31 07:06:47.243: INFO: Pod "pod-secrets-c2c43d52-b361-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 3.437353ms
Jul 31 07:06:49.245: INFO: Pod "pod-secrets-c2c43d52-b361-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005974655s
Jul 31 07:06:51.248: INFO: Pod "pod-secrets-c2c43d52-b361-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008750084s
STEP: Saw pod success
Jul 31 07:06:51.248: INFO: Pod "pod-secrets-c2c43d52-b361-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 07:06:51.250: INFO: Trying to get logs from node shushsha-k8s-worker2 pod pod-secrets-c2c43d52-b361-11e9-990e-fe448544ce72 container secret-volume-test: <nil>
STEP: delete the pod
Jul 31 07:06:51.264: INFO: Waiting for pod pod-secrets-c2c43d52-b361-11e9-990e-fe448544ce72 to disappear
Jul 31 07:06:51.266: INFO: Pod pod-secrets-c2c43d52-b361-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:06:51.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-czkqv" for this suite.
Jul 31 07:06:57.277: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:06:57.335: INFO: namespace: e2e-tests-secrets-czkqv, resource: bindings, ignored listing per whitelist
Jul 31 07:06:57.353: INFO: namespace e2e-tests-secrets-czkqv deletion completed in 6.083551839s

• [SLOW TEST:10.179 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:06:57.354: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jul 31 07:06:57.421: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c8d5d7af-b361-11e9-990e-fe448544ce72" in namespace "e2e-tests-projected-fgrt8" to be "success or failure"
Jul 31 07:06:57.424: INFO: Pod "downwardapi-volume-c8d5d7af-b361-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 3.536398ms
Jul 31 07:06:59.427: INFO: Pod "downwardapi-volume-c8d5d7af-b361-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006328207s
STEP: Saw pod success
Jul 31 07:06:59.427: INFO: Pod "downwardapi-volume-c8d5d7af-b361-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 07:06:59.429: INFO: Trying to get logs from node shushsha-k8s-worker1 pod downwardapi-volume-c8d5d7af-b361-11e9-990e-fe448544ce72 container client-container: <nil>
STEP: delete the pod
Jul 31 07:06:59.443: INFO: Waiting for pod downwardapi-volume-c8d5d7af-b361-11e9-990e-fe448544ce72 to disappear
Jul 31 07:06:59.445: INFO: Pod downwardapi-volume-c8d5d7af-b361-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:06:59.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fgrt8" for this suite.
Jul 31 07:07:05.456: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:07:05.514: INFO: namespace: e2e-tests-projected-fgrt8, resource: bindings, ignored listing per whitelist
Jul 31 07:07:05.530: INFO: namespace e2e-tests-projected-fgrt8 deletion completed in 6.08251428s

• [SLOW TEST:8.177 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:07:05.531: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-rrfxt
Jul 31 07:07:11.598: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-rrfxt
STEP: checking the pod's current state and verifying that restartCount is present
Jul 31 07:07:11.600: INFO: Initial restart count of pod liveness-http is 0
Jul 31 07:07:33.636: INFO: Restart count of pod e2e-tests-container-probe-rrfxt/liveness-http is now 1 (22.035902554s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:07:33.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-rrfxt" for this suite.
Jul 31 07:07:39.653: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:07:39.678: INFO: namespace: e2e-tests-container-probe-rrfxt, resource: bindings, ignored listing per whitelist
Jul 31 07:07:39.726: INFO: namespace e2e-tests-container-probe-rrfxt deletion completed in 6.080799052s

• [SLOW TEST:34.195 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:07:39.727: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-e216cb48-b361-11e9-990e-fe448544ce72
STEP: Creating a pod to test consume configMaps
Jul 31 07:07:39.792: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e2172f3e-b361-11e9-990e-fe448544ce72" in namespace "e2e-tests-projected-8zstz" to be "success or failure"
Jul 31 07:07:39.794: INFO: Pod "pod-projected-configmaps-e2172f3e-b361-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.137775ms
Jul 31 07:07:41.797: INFO: Pod "pod-projected-configmaps-e2172f3e-b361-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005036975s
STEP: Saw pod success
Jul 31 07:07:41.797: INFO: Pod "pod-projected-configmaps-e2172f3e-b361-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 07:07:41.800: INFO: Trying to get logs from node shushsha-k8s-worker1 pod pod-projected-configmaps-e2172f3e-b361-11e9-990e-fe448544ce72 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jul 31 07:07:41.819: INFO: Waiting for pod pod-projected-configmaps-e2172f3e-b361-11e9-990e-fe448544ce72 to disappear
Jul 31 07:07:41.823: INFO: Pod pod-projected-configmaps-e2172f3e-b361-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:07:41.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8zstz" for this suite.
Jul 31 07:07:47.839: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:07:47.868: INFO: namespace: e2e-tests-projected-8zstz, resource: bindings, ignored listing per whitelist
Jul 31 07:07:47.914: INFO: namespace e2e-tests-projected-8zstz deletion completed in 6.088370542s

• [SLOW TEST:8.188 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:07:47.915: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Jul 31 07:07:49.986: INFO: Pod pod-hostip-e6f7e7c0-b361-11e9-990e-fe448544ce72 has hostIP: 100.100.230.39
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:07:49.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-4bhng" for this suite.
Jul 31 07:08:11.996: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:08:12.045: INFO: namespace: e2e-tests-pods-4bhng, resource: bindings, ignored listing per whitelist
Jul 31 07:08:12.076: INFO: namespace e2e-tests-pods-4bhng deletion completed in 22.087695127s

• [SLOW TEST:24.162 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:08:12.077: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jul 31 07:08:12.140: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f55f0fad-b361-11e9-990e-fe448544ce72" in namespace "e2e-tests-downward-api-skx2k" to be "success or failure"
Jul 31 07:08:12.143: INFO: Pod "downwardapi-volume-f55f0fad-b361-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 3.380323ms
Jul 31 07:08:14.146: INFO: Pod "downwardapi-volume-f55f0fad-b361-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00594193s
STEP: Saw pod success
Jul 31 07:08:14.146: INFO: Pod "downwardapi-volume-f55f0fad-b361-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 07:08:14.148: INFO: Trying to get logs from node shushsha-k8s-worker1 pod downwardapi-volume-f55f0fad-b361-11e9-990e-fe448544ce72 container client-container: <nil>
STEP: delete the pod
Jul 31 07:08:14.163: INFO: Waiting for pod downwardapi-volume-f55f0fad-b361-11e9-990e-fe448544ce72 to disappear
Jul 31 07:08:14.165: INFO: Pod downwardapi-volume-f55f0fad-b361-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:08:14.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-skx2k" for this suite.
Jul 31 07:08:20.177: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:08:20.228: INFO: namespace: e2e-tests-downward-api-skx2k, resource: bindings, ignored listing per whitelist
Jul 31 07:08:20.251: INFO: namespace e2e-tests-downward-api-skx2k deletion completed in 6.083589033s

• [SLOW TEST:8.175 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:08:20.252: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-zgqf9
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Jul 31 07:08:20.315: INFO: Found 0 stateful pods, waiting for 3
Jul 31 07:08:30.319: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jul 31 07:08:30.319: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jul 31 07:08:30.319: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Jul 31 07:08:30.342: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Jul 31 07:08:40.370: INFO: Updating stateful set ss2
Jul 31 07:08:40.375: INFO: Waiting for Pod e2e-tests-statefulset-zgqf9/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Jul 31 07:08:50.423: INFO: Found 2 stateful pods, waiting for 3
Jul 31 07:09:00.427: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jul 31 07:09:00.427: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jul 31 07:09:00.427: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Jul 31 07:09:00.448: INFO: Updating stateful set ss2
Jul 31 07:09:00.454: INFO: Waiting for Pod e2e-tests-statefulset-zgqf9/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Jul 31 07:09:10.460: INFO: Waiting for Pod e2e-tests-statefulset-zgqf9/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Jul 31 07:09:20.475: INFO: Updating stateful set ss2
Jul 31 07:09:20.481: INFO: Waiting for StatefulSet e2e-tests-statefulset-zgqf9/ss2 to complete update
Jul 31 07:09:20.481: INFO: Waiting for Pod e2e-tests-statefulset-zgqf9/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jul 31 07:09:30.487: INFO: Deleting all statefulset in ns e2e-tests-statefulset-zgqf9
Jul 31 07:09:30.489: INFO: Scaling statefulset ss2 to 0
Jul 31 07:10:10.500: INFO: Waiting for statefulset status.replicas updated to 0
Jul 31 07:10:10.503: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:10:10.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-zgqf9" for this suite.
Jul 31 07:10:16.533: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:10:16.606: INFO: namespace: e2e-tests-statefulset-zgqf9, resource: bindings, ignored listing per whitelist
Jul 31 07:10:16.614: INFO: namespace e2e-tests-statefulset-zgqf9 deletion completed in 6.091358759s

• [SLOW TEST:116.362 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:10:16.615: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jul 31 07:10:16.680: INFO: Creating deployment "test-recreate-deployment"
Jul 31 07:10:16.682: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Jul 31 07:10:16.687: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Jul 31 07:10:18.701: INFO: Waiting deployment "test-recreate-deployment" to complete
Jul 31 07:10:18.704: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Jul 31 07:10:18.710: INFO: Updating deployment test-recreate-deployment
Jul 31 07:10:18.710: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jul 31 07:10:18.765: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-mtxlg,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-mtxlg/deployments/test-recreate-deployment,UID:3f9b1fff-b362-11e9-ac6f-000017003e78,ResourceVersion:14141,Generation:2,CreationTimestamp:2019-07-31 07:10:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-07-31 07:10:18 +0000 UTC 2019-07-31 07:10:18 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-07-31 07:10:18 +0000 UTC 2019-07-31 07:10:16 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-697fbf54bf" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Jul 31 07:10:18.768: INFO: New ReplicaSet "test-recreate-deployment-697fbf54bf" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf,GenerateName:,Namespace:e2e-tests-deployment-mtxlg,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-mtxlg/replicasets/test-recreate-deployment-697fbf54bf,UID:40d43900-b362-11e9-ac6f-000017003e78,ResourceVersion:14138,Generation:1,CreationTimestamp:2019-07-31 07:10:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 3f9b1fff-b362-11e9-ac6f-000017003e78 0xc0029c9b17 0xc0029c9b18}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jul 31 07:10:18.768: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Jul 31 07:10:18.769: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5dfdcc846d,GenerateName:,Namespace:e2e-tests-deployment-mtxlg,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-mtxlg/replicasets/test-recreate-deployment-5dfdcc846d,UID:3f9c1ef0-b362-11e9-ac6f-000017003e78,ResourceVersion:14129,Generation:2,CreationTimestamp:2019-07-31 07:10:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 3f9b1fff-b362-11e9-ac6f-000017003e78 0xc0029c9997 0xc0029c9998}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jul 31 07:10:18.774: INFO: Pod "test-recreate-deployment-697fbf54bf-6xbtm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf-6xbtm,GenerateName:test-recreate-deployment-697fbf54bf-,Namespace:e2e-tests-deployment-mtxlg,SelfLink:/api/v1/namespaces/e2e-tests-deployment-mtxlg/pods/test-recreate-deployment-697fbf54bf-6xbtm,UID:40d4a8d5-b362-11e9-ac6f-000017003e78,ResourceVersion:14140,Generation:0,CreationTimestamp:2019-07-31 07:10:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-697fbf54bf 40d43900-b362-11e9-ac6f-000017003e78 0xc002acaef7 0xc002acaef8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hw6pp {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hw6pp,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-hw6pp true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shushsha-k8s-worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002acaf60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002acaf80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 07:10:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 07:10:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 07:10:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 07:10:18 +0000 UTC  }],Message:,Reason:,HostIP:100.100.230.30,PodIP:,StartTime:2019-07-31 07:10:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:10:18.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-mtxlg" for this suite.
Jul 31 07:10:24.786: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:10:24.845: INFO: namespace: e2e-tests-deployment-mtxlg, resource: bindings, ignored listing per whitelist
Jul 31 07:10:24.862: INFO: namespace e2e-tests-deployment-mtxlg deletion completed in 6.084365429s

• [SLOW TEST:8.247 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:10:24.862: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Jul 31 07:10:25.114: INFO: Pod name wrapped-volume-race-4497b7ed-b362-11e9-990e-fe448544ce72: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-4497b7ed-b362-11e9-990e-fe448544ce72 in namespace e2e-tests-emptydir-wrapper-5qd99, will wait for the garbage collector to delete the pods
Jul 31 07:12:13.237: INFO: Deleting ReplicationController wrapped-volume-race-4497b7ed-b362-11e9-990e-fe448544ce72 took: 5.570874ms
Jul 31 07:12:13.337: INFO: Terminating ReplicationController wrapped-volume-race-4497b7ed-b362-11e9-990e-fe448544ce72 pods took: 100.22112ms
STEP: Creating RC which spawns configmap-volume pods
Jul 31 07:12:53.750: INFO: Pod name wrapped-volume-race-9d381802-b362-11e9-990e-fe448544ce72: Found 0 pods out of 5
Jul 31 07:12:58.757: INFO: Pod name wrapped-volume-race-9d381802-b362-11e9-990e-fe448544ce72: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-9d381802-b362-11e9-990e-fe448544ce72 in namespace e2e-tests-emptydir-wrapper-5qd99, will wait for the garbage collector to delete the pods
Jul 31 07:14:44.832: INFO: Deleting ReplicationController wrapped-volume-race-9d381802-b362-11e9-990e-fe448544ce72 took: 5.938616ms
Jul 31 07:14:44.933: INFO: Terminating ReplicationController wrapped-volume-race-9d381802-b362-11e9-990e-fe448544ce72 pods took: 100.283911ms
STEP: Creating RC which spawns configmap-volume pods
Jul 31 07:15:22.744: INFO: Pod name wrapped-volume-race-f60707ef-b362-11e9-990e-fe448544ce72: Found 0 pods out of 5
Jul 31 07:15:27.749: INFO: Pod name wrapped-volume-race-f60707ef-b362-11e9-990e-fe448544ce72: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-f60707ef-b362-11e9-990e-fe448544ce72 in namespace e2e-tests-emptydir-wrapper-5qd99, will wait for the garbage collector to delete the pods
Jul 31 07:17:13.838: INFO: Deleting ReplicationController wrapped-volume-race-f60707ef-b362-11e9-990e-fe448544ce72 took: 10.375303ms
Jul 31 07:17:13.938: INFO: Terminating ReplicationController wrapped-volume-race-f60707ef-b362-11e9-990e-fe448544ce72 pods took: 100.313373ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:17:52.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-5qd99" for this suite.
Jul 31 07:17:59.001: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:17:59.073: INFO: namespace: e2e-tests-emptydir-wrapper-5qd99, resource: bindings, ignored listing per whitelist
Jul 31 07:17:59.075: INFO: namespace e2e-tests-emptydir-wrapper-5qd99 deletion completed in 6.081719155s

• [SLOW TEST:454.213 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:17:59.075: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-533fd405-b363-11e9-990e-fe448544ce72
Jul 31 07:17:59.138: INFO: Pod name my-hostname-basic-533fd405-b363-11e9-990e-fe448544ce72: Found 0 pods out of 1
Jul 31 07:18:04.141: INFO: Pod name my-hostname-basic-533fd405-b363-11e9-990e-fe448544ce72: Found 1 pods out of 1
Jul 31 07:18:04.141: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-533fd405-b363-11e9-990e-fe448544ce72" are running
Jul 31 07:18:04.144: INFO: Pod "my-hostname-basic-533fd405-b363-11e9-990e-fe448544ce72-657fj" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-07-31 07:17:59 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-07-31 07:18:01 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-07-31 07:18:01 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-07-31 07:17:59 +0000 UTC Reason: Message:}])
Jul 31 07:18:04.144: INFO: Trying to dial the pod
Jul 31 07:18:09.153: INFO: Controller my-hostname-basic-533fd405-b363-11e9-990e-fe448544ce72: Got expected result from replica 1 [my-hostname-basic-533fd405-b363-11e9-990e-fe448544ce72-657fj]: "my-hostname-basic-533fd405-b363-11e9-990e-fe448544ce72-657fj", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:18:09.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-59n5h" for this suite.
Jul 31 07:18:15.164: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:18:15.188: INFO: namespace: e2e-tests-replication-controller-59n5h, resource: bindings, ignored listing per whitelist
Jul 31 07:18:15.235: INFO: namespace e2e-tests-replication-controller-59n5h deletion completed in 6.07977027s

• [SLOW TEST:16.160 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:18:15.236: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jul 31 07:18:15.302: INFO: Pod name rollover-pod: Found 0 pods out of 1
Jul 31 07:18:20.306: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jul 31 07:18:20.306: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Jul 31 07:18:22.309: INFO: Creating deployment "test-rollover-deployment"
Jul 31 07:18:22.315: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Jul 31 07:18:24.320: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Jul 31 07:18:24.325: INFO: Ensure that both replica sets have 1 created replica
Jul 31 07:18:24.330: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Jul 31 07:18:24.336: INFO: Updating deployment test-rollover-deployment
Jul 31 07:18:24.336: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Jul 31 07:18:26.341: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Jul 31 07:18:26.346: INFO: Make sure deployment "test-rollover-deployment" is complete
Jul 31 07:18:26.351: INFO: all replica sets need to contain the pod-template-hash label
Jul 31 07:18:26.351: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700154302, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700154302, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700154304, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700154302, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 31 07:18:28.356: INFO: all replica sets need to contain the pod-template-hash label
Jul 31 07:18:28.356: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700154302, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700154302, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700154306, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700154302, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 31 07:18:30.357: INFO: all replica sets need to contain the pod-template-hash label
Jul 31 07:18:30.357: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700154302, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700154302, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700154306, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700154302, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 31 07:18:32.357: INFO: all replica sets need to contain the pod-template-hash label
Jul 31 07:18:32.357: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700154302, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700154302, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700154306, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700154302, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 31 07:18:34.357: INFO: all replica sets need to contain the pod-template-hash label
Jul 31 07:18:34.357: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700154302, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700154302, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700154306, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700154302, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 31 07:18:36.357: INFO: all replica sets need to contain the pod-template-hash label
Jul 31 07:18:36.357: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700154302, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700154302, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700154306, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700154302, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 31 07:18:38.357: INFO: 
Jul 31 07:18:38.357: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jul 31 07:18:38.364: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-2g97p,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-2g97p/deployments/test-rollover-deployment,UID:611055f1-b363-11e9-ac6f-000017003e78,ResourceVersion:15419,Generation:2,CreationTimestamp:2019-07-31 07:18:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-07-31 07:18:22 +0000 UTC 2019-07-31 07:18:22 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-07-31 07:18:36 +0000 UTC 2019-07-31 07:18:22 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-6b7f9d6597" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Jul 31 07:18:38.366: INFO: New ReplicaSet "test-rollover-deployment-6b7f9d6597" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597,GenerateName:,Namespace:e2e-tests-deployment-2g97p,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-2g97p/replicasets/test-rollover-deployment-6b7f9d6597,UID:624575dc-b363-11e9-ac6f-000017003e78,ResourceVersion:15410,Generation:2,CreationTimestamp:2019-07-31 07:18:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 611055f1-b363-11e9-ac6f-000017003e78 0xc0018bc2b7 0xc0018bc2b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jul 31 07:18:38.366: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Jul 31 07:18:38.367: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-2g97p,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-2g97p/replicasets/test-rollover-controller,UID:5ce24c32-b363-11e9-ac6f-000017003e78,ResourceVersion:15418,Generation:2,CreationTimestamp:2019-07-31 07:18:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 611055f1-b363-11e9-ac6f-000017003e78 0xc001865fd7 0xc001865fd8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jul 31 07:18:38.367: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6586df867b,GenerateName:,Namespace:e2e-tests-deployment-2g97p,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-2g97p/replicasets/test-rollover-deployment-6586df867b,UID:611230a3-b363-11e9-ac6f-000017003e78,ResourceVersion:15380,Generation:2,CreationTimestamp:2019-07-31 07:18:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 611055f1-b363-11e9-ac6f-000017003e78 0xc0018bc137 0xc0018bc138}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jul 31 07:18:38.370: INFO: Pod "test-rollover-deployment-6b7f9d6597-c2nj2" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597-c2nj2,GenerateName:test-rollover-deployment-6b7f9d6597-,Namespace:e2e-tests-deployment-2g97p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2g97p/pods/test-rollover-deployment-6b7f9d6597-c2nj2,UID:6248a8a8-b363-11e9-ac6f-000017003e78,ResourceVersion:15393,Generation:0,CreationTimestamp:2019-07-31 07:18:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-6b7f9d6597 624575dc-b363-11e9-ac6f-000017003e78 0xc0016e22c7 0xc0016e22c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qrkvz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qrkvz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-qrkvz true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shushsha-k8s-worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0016e2330} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0016e2390}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 07:18:24 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 07:18:26 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 07:18:26 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 07:18:24 +0000 UTC  }],Message:,Reason:,HostIP:100.100.230.30,PodIP:10.244.1.143,StartTime:2019-07-31 07:18:24 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-07-31 07:18:25 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://28739887e74650f19c0cab767d0d7c5db96ced6b5246059a841c79875801a6cc}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:18:38.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-2g97p" for this suite.
Jul 31 07:18:44.381: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:18:44.416: INFO: namespace: e2e-tests-deployment-2g97p, resource: bindings, ignored listing per whitelist
Jul 31 07:18:44.453: INFO: namespace e2e-tests-deployment-2g97p deletion completed in 6.080345637s

• [SLOW TEST:29.217 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:18:44.454: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jul 31 07:18:44.519: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6e4c8800-b363-11e9-990e-fe448544ce72" in namespace "e2e-tests-projected-9sfll" to be "success or failure"
Jul 31 07:18:44.522: INFO: Pod "downwardapi-volume-6e4c8800-b363-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.182247ms
Jul 31 07:18:46.525: INFO: Pod "downwardapi-volume-6e4c8800-b363-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005026312s
STEP: Saw pod success
Jul 31 07:18:46.525: INFO: Pod "downwardapi-volume-6e4c8800-b363-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 07:18:46.527: INFO: Trying to get logs from node shushsha-k8s-worker2 pod downwardapi-volume-6e4c8800-b363-11e9-990e-fe448544ce72 container client-container: <nil>
STEP: delete the pod
Jul 31 07:18:46.542: INFO: Waiting for pod downwardapi-volume-6e4c8800-b363-11e9-990e-fe448544ce72 to disappear
Jul 31 07:18:46.544: INFO: Pod downwardapi-volume-6e4c8800-b363-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:18:46.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9sfll" for this suite.
Jul 31 07:18:52.557: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:18:52.632: INFO: namespace: e2e-tests-projected-9sfll, resource: bindings, ignored listing per whitelist
Jul 31 07:18:52.633: INFO: namespace e2e-tests-projected-9sfll deletion completed in 6.085143475s

• [SLOW TEST:8.179 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:18:52.633: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jul 31 07:18:52.698: INFO: Waiting up to 5m0s for pod "pod-732c0741-b363-11e9-990e-fe448544ce72" in namespace "e2e-tests-emptydir-9fngj" to be "success or failure"
Jul 31 07:18:52.702: INFO: Pod "pod-732c0741-b363-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 3.708734ms
Jul 31 07:18:54.704: INFO: Pod "pod-732c0741-b363-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006563966s
STEP: Saw pod success
Jul 31 07:18:54.705: INFO: Pod "pod-732c0741-b363-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 07:18:54.708: INFO: Trying to get logs from node shushsha-k8s-worker1 pod pod-732c0741-b363-11e9-990e-fe448544ce72 container test-container: <nil>
STEP: delete the pod
Jul 31 07:18:54.724: INFO: Waiting for pod pod-732c0741-b363-11e9-990e-fe448544ce72 to disappear
Jul 31 07:18:54.726: INFO: Pod pod-732c0741-b363-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:18:54.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-9fngj" for this suite.
Jul 31 07:19:00.737: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:19:00.784: INFO: namespace: e2e-tests-emptydir-9fngj, resource: bindings, ignored listing per whitelist
Jul 31 07:19:00.812: INFO: namespace e2e-tests-emptydir-9fngj deletion completed in 6.083701123s

• [SLOW TEST:8.179 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:19:00.813: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Jul 31 07:19:10.923: INFO: MetricsGrabber failed grab metrics. Skipping metrics gathering.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:19:10.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-zdf92" for this suite.
Jul 31 07:19:16.934: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:19:16.950: INFO: namespace: e2e-tests-gc-zdf92, resource: bindings, ignored listing per whitelist
Jul 31 07:19:17.007: INFO: namespace e2e-tests-gc-zdf92 deletion completed in 6.081109141s

• [SLOW TEST:16.194 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:19:17.007: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-qkb6x
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-qkb6x to expose endpoints map[]
Jul 31 07:19:17.076: INFO: Get endpoints failed (2.841111ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Jul 31 07:19:18.079: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-qkb6x exposes endpoints map[] (1.005411306s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-qkb6x
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-qkb6x to expose endpoints map[pod1:[100]]
Jul 31 07:19:20.099: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-qkb6x exposes endpoints map[pod1:[100]] (2.015235277s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-qkb6x
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-qkb6x to expose endpoints map[pod1:[100] pod2:[101]]
Jul 31 07:19:22.126: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-qkb6x exposes endpoints map[pod1:[100] pod2:[101]] (2.024805788s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-qkb6x
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-qkb6x to expose endpoints map[pod2:[101]]
Jul 31 07:19:23.142: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-qkb6x exposes endpoints map[pod2:[101]] (1.012147999s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-qkb6x
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-qkb6x to expose endpoints map[]
Jul 31 07:19:24.150: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-qkb6x exposes endpoints map[] (1.004829128s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:19:24.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-qkb6x" for this suite.
Jul 31 07:19:46.179: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:19:46.244: INFO: namespace: e2e-tests-services-qkb6x, resource: bindings, ignored listing per whitelist
Jul 31 07:19:46.255: INFO: namespace e2e-tests-services-qkb6x deletion completed in 22.086748014s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:29.247 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:19:46.255: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jul 31 07:19:50.338: INFO: Waiting up to 5m0s for pod "client-envvars-9587c217-b363-11e9-990e-fe448544ce72" in namespace "e2e-tests-pods-lm5c5" to be "success or failure"
Jul 31 07:19:50.341: INFO: Pod "client-envvars-9587c217-b363-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 3.095154ms
Jul 31 07:19:52.344: INFO: Pod "client-envvars-9587c217-b363-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006031213s
STEP: Saw pod success
Jul 31 07:19:52.344: INFO: Pod "client-envvars-9587c217-b363-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 07:19:52.347: INFO: Trying to get logs from node shushsha-k8s-worker1 pod client-envvars-9587c217-b363-11e9-990e-fe448544ce72 container env3cont: <nil>
STEP: delete the pod
Jul 31 07:19:52.360: INFO: Waiting for pod client-envvars-9587c217-b363-11e9-990e-fe448544ce72 to disappear
Jul 31 07:19:52.362: INFO: Pod client-envvars-9587c217-b363-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:19:52.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-lm5c5" for this suite.
Jul 31 07:20:30.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:20:30.418: INFO: namespace: e2e-tests-pods-lm5c5, resource: bindings, ignored listing per whitelist
Jul 31 07:20:30.446: INFO: namespace e2e-tests-pods-lm5c5 deletion completed in 38.080305079s

• [SLOW TEST:44.191 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:20:30.446: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-ad79af85-b363-11e9-990e-fe448544ce72
STEP: Creating a pod to test consume secrets
Jul 31 07:20:30.514: INFO: Waiting up to 5m0s for pod "pod-secrets-ad7a10d0-b363-11e9-990e-fe448544ce72" in namespace "e2e-tests-secrets-69b9t" to be "success or failure"
Jul 31 07:20:30.517: INFO: Pod "pod-secrets-ad7a10d0-b363-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.807625ms
Jul 31 07:20:32.520: INFO: Pod "pod-secrets-ad7a10d0-b363-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005593726s
STEP: Saw pod success
Jul 31 07:20:32.520: INFO: Pod "pod-secrets-ad7a10d0-b363-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 07:20:32.522: INFO: Trying to get logs from node shushsha-k8s-worker2 pod pod-secrets-ad7a10d0-b363-11e9-990e-fe448544ce72 container secret-volume-test: <nil>
STEP: delete the pod
Jul 31 07:20:32.536: INFO: Waiting for pod pod-secrets-ad7a10d0-b363-11e9-990e-fe448544ce72 to disappear
Jul 31 07:20:32.538: INFO: Pod pod-secrets-ad7a10d0-b363-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:20:32.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-69b9t" for this suite.
Jul 31 07:20:38.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:20:38.597: INFO: namespace: e2e-tests-secrets-69b9t, resource: bindings, ignored listing per whitelist
Jul 31 07:20:38.630: INFO: namespace e2e-tests-secrets-69b9t deletion completed in 6.089173577s

• [SLOW TEST:8.184 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:20:38.631: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-b25b9673-b363-11e9-990e-fe448544ce72
STEP: Creating a pod to test consume configMaps
Jul 31 07:20:38.708: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b25c0663-b363-11e9-990e-fe448544ce72" in namespace "e2e-tests-projected-9jnhx" to be "success or failure"
Jul 31 07:20:38.710: INFO: Pod "pod-projected-configmaps-b25c0663-b363-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.072902ms
Jul 31 07:20:40.713: INFO: Pod "pod-projected-configmaps-b25c0663-b363-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005261602s
STEP: Saw pod success
Jul 31 07:20:40.713: INFO: Pod "pod-projected-configmaps-b25c0663-b363-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 07:20:40.716: INFO: Trying to get logs from node shushsha-k8s-worker1 pod pod-projected-configmaps-b25c0663-b363-11e9-990e-fe448544ce72 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jul 31 07:20:40.731: INFO: Waiting for pod pod-projected-configmaps-b25c0663-b363-11e9-990e-fe448544ce72 to disappear
Jul 31 07:20:40.733: INFO: Pod pod-projected-configmaps-b25c0663-b363-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:20:40.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9jnhx" for this suite.
Jul 31 07:20:46.744: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:20:46.786: INFO: namespace: e2e-tests-projected-9jnhx, resource: bindings, ignored listing per whitelist
Jul 31 07:20:46.819: INFO: namespace e2e-tests-projected-9jnhx deletion completed in 6.083007376s

• [SLOW TEST:8.188 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:20:46.819: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Jul 31 07:20:46.886: INFO: Waiting up to 5m0s for pod "pod-b73c3b2e-b363-11e9-990e-fe448544ce72" in namespace "e2e-tests-emptydir-6sgst" to be "success or failure"
Jul 31 07:20:46.889: INFO: Pod "pod-b73c3b2e-b363-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.53489ms
Jul 31 07:20:48.891: INFO: Pod "pod-b73c3b2e-b363-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005132032s
STEP: Saw pod success
Jul 31 07:20:48.891: INFO: Pod "pod-b73c3b2e-b363-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 07:20:48.894: INFO: Trying to get logs from node shushsha-k8s-worker2 pod pod-b73c3b2e-b363-11e9-990e-fe448544ce72 container test-container: <nil>
STEP: delete the pod
Jul 31 07:20:48.907: INFO: Waiting for pod pod-b73c3b2e-b363-11e9-990e-fe448544ce72 to disappear
Jul 31 07:20:48.910: INFO: Pod pod-b73c3b2e-b363-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:20:48.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-6sgst" for this suite.
Jul 31 07:20:54.923: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:20:54.960: INFO: namespace: e2e-tests-emptydir-6sgst, resource: bindings, ignored listing per whitelist
Jul 31 07:20:54.997: INFO: namespace e2e-tests-emptydir-6sgst deletion completed in 6.08314172s

• [SLOW TEST:8.178 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:20:54.997: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jul 31 07:20:57.582: INFO: Successfully updated pod "labelsupdatebc1b75f4-b363-11e9-990e-fe448544ce72"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:20:59.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hkq68" for this suite.
Jul 31 07:21:21.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:21:21.625: INFO: namespace: e2e-tests-projected-hkq68, resource: bindings, ignored listing per whitelist
Jul 31 07:21:21.683: INFO: namespace e2e-tests-projected-hkq68 deletion completed in 22.081044956s

• [SLOW TEST:26.687 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:21:21.684: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-cc047984-b363-11e9-990e-fe448544ce72
STEP: Creating a pod to test consume secrets
Jul 31 07:21:21.756: INFO: Waiting up to 5m0s for pod "pod-secrets-cc04fc9d-b363-11e9-990e-fe448544ce72" in namespace "e2e-tests-secrets-ck627" to be "success or failure"
Jul 31 07:21:21.760: INFO: Pod "pod-secrets-cc04fc9d-b363-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 3.672521ms
Jul 31 07:21:23.765: INFO: Pod "pod-secrets-cc04fc9d-b363-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008877541s
STEP: Saw pod success
Jul 31 07:21:23.765: INFO: Pod "pod-secrets-cc04fc9d-b363-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 07:21:23.768: INFO: Trying to get logs from node shushsha-k8s-worker2 pod pod-secrets-cc04fc9d-b363-11e9-990e-fe448544ce72 container secret-volume-test: <nil>
STEP: delete the pod
Jul 31 07:21:23.789: INFO: Waiting for pod pod-secrets-cc04fc9d-b363-11e9-990e-fe448544ce72 to disappear
Jul 31 07:21:23.791: INFO: Pod pod-secrets-cc04fc9d-b363-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:21:23.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-ck627" for this suite.
Jul 31 07:21:29.802: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:21:29.872: INFO: namespace: e2e-tests-secrets-ck627, resource: bindings, ignored listing per whitelist
Jul 31 07:21:29.876: INFO: namespace e2e-tests-secrets-ck627 deletion completed in 6.081708098s

• [SLOW TEST:8.192 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:21:29.876: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-d0e5de0b-b363-11e9-990e-fe448544ce72
STEP: Creating secret with name secret-projected-all-test-volume-d0e5ddf7-b363-11e9-990e-fe448544ce72
STEP: Creating a pod to test Check all projections for projected volume plugin
Jul 31 07:21:29.946: INFO: Waiting up to 5m0s for pod "projected-volume-d0e5ddb9-b363-11e9-990e-fe448544ce72" in namespace "e2e-tests-projected-948sf" to be "success or failure"
Jul 31 07:21:29.948: INFO: Pod "projected-volume-d0e5ddb9-b363-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.402605ms
Jul 31 07:21:31.951: INFO: Pod "projected-volume-d0e5ddb9-b363-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005356485s
STEP: Saw pod success
Jul 31 07:21:31.951: INFO: Pod "projected-volume-d0e5ddb9-b363-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 07:21:31.954: INFO: Trying to get logs from node shushsha-k8s-worker1 pod projected-volume-d0e5ddb9-b363-11e9-990e-fe448544ce72 container projected-all-volume-test: <nil>
STEP: delete the pod
Jul 31 07:21:31.966: INFO: Waiting for pod projected-volume-d0e5ddb9-b363-11e9-990e-fe448544ce72 to disappear
Jul 31 07:21:31.968: INFO: Pod projected-volume-d0e5ddb9-b363-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:21:31.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-948sf" for this suite.
Jul 31 07:21:37.979: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:21:38.033: INFO: namespace: e2e-tests-projected-948sf, resource: bindings, ignored listing per whitelist
Jul 31 07:21:38.055: INFO: namespace e2e-tests-projected-948sf deletion completed in 6.084188977s

• [SLOW TEST:8.180 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:21:38.056: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jul 31 07:21:38.127: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:21:40.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-s5jfz" for this suite.
Jul 31 07:22:18.164: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:22:18.180: INFO: namespace: e2e-tests-pods-s5jfz, resource: bindings, ignored listing per whitelist
Jul 31 07:22:18.233: INFO: namespace e2e-tests-pods-s5jfz deletion completed in 38.077074962s

• [SLOW TEST:40.178 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:22:18.233: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Jul 31 07:22:18.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 create -f - --namespace=e2e-tests-kubectl-nddpg'
Jul 31 07:22:18.649: INFO: stderr: ""
Jul 31 07:22:18.649: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jul 31 07:22:18.649: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-nddpg'
Jul 31 07:22:18.750: INFO: stderr: ""
Jul 31 07:22:18.750: INFO: stdout: "update-demo-nautilus-2qtlc update-demo-nautilus-swpbz "
Jul 31 07:22:18.750: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 get pods update-demo-nautilus-2qtlc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nddpg'
Jul 31 07:22:18.832: INFO: stderr: ""
Jul 31 07:22:18.832: INFO: stdout: ""
Jul 31 07:22:18.832: INFO: update-demo-nautilus-2qtlc is created but not running
Jul 31 07:22:23.832: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-nddpg'
Jul 31 07:22:23.915: INFO: stderr: ""
Jul 31 07:22:23.915: INFO: stdout: "update-demo-nautilus-2qtlc update-demo-nautilus-swpbz "
Jul 31 07:22:23.915: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 get pods update-demo-nautilus-2qtlc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nddpg'
Jul 31 07:22:24.025: INFO: stderr: ""
Jul 31 07:22:24.025: INFO: stdout: "true"
Jul 31 07:22:24.025: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 get pods update-demo-nautilus-2qtlc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nddpg'
Jul 31 07:22:24.118: INFO: stderr: ""
Jul 31 07:22:24.118: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jul 31 07:22:24.118: INFO: validating pod update-demo-nautilus-2qtlc
Jul 31 07:22:24.122: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 31 07:22:24.122: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 31 07:22:24.122: INFO: update-demo-nautilus-2qtlc is verified up and running
Jul 31 07:22:24.122: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 get pods update-demo-nautilus-swpbz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nddpg'
Jul 31 07:22:24.238: INFO: stderr: ""
Jul 31 07:22:24.238: INFO: stdout: "true"
Jul 31 07:22:24.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 get pods update-demo-nautilus-swpbz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nddpg'
Jul 31 07:22:24.321: INFO: stderr: ""
Jul 31 07:22:24.321: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jul 31 07:22:24.321: INFO: validating pod update-demo-nautilus-swpbz
Jul 31 07:22:24.325: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 31 07:22:24.325: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 31 07:22:24.325: INFO: update-demo-nautilus-swpbz is verified up and running
STEP: using delete to clean up resources
Jul 31 07:22:24.325: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-nddpg'
Jul 31 07:22:24.416: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 31 07:22:24.416: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jul 31 07:22:24.416: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-nddpg'
Jul 31 07:22:24.545: INFO: stderr: "No resources found.\n"
Jul 31 07:22:24.545: INFO: stdout: ""
Jul 31 07:22:24.546: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 get pods -l name=update-demo --namespace=e2e-tests-kubectl-nddpg -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jul 31 07:22:24.699: INFO: stderr: ""
Jul 31 07:22:24.699: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:22:24.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-nddpg" for this suite.
Jul 31 07:22:46.710: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:22:46.726: INFO: namespace: e2e-tests-kubectl-nddpg, resource: bindings, ignored listing per whitelist
Jul 31 07:22:46.826: INFO: namespace e2e-tests-kubectl-nddpg deletion completed in 22.123534264s

• [SLOW TEST:28.592 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:22:46.826: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-fec40460-b363-11e9-990e-fe448544ce72
STEP: Creating a pod to test consume configMaps
Jul 31 07:22:46.897: INFO: Waiting up to 5m0s for pod "pod-configmaps-fec46ec0-b363-11e9-990e-fe448544ce72" in namespace "e2e-tests-configmap-kqmsv" to be "success or failure"
Jul 31 07:22:46.900: INFO: Pod "pod-configmaps-fec46ec0-b363-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 3.0068ms
Jul 31 07:22:48.904: INFO: Pod "pod-configmaps-fec46ec0-b363-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006189523s
STEP: Saw pod success
Jul 31 07:22:48.904: INFO: Pod "pod-configmaps-fec46ec0-b363-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 07:22:48.906: INFO: Trying to get logs from node shushsha-k8s-worker1 pod pod-configmaps-fec46ec0-b363-11e9-990e-fe448544ce72 container configmap-volume-test: <nil>
STEP: delete the pod
Jul 31 07:22:48.919: INFO: Waiting for pod pod-configmaps-fec46ec0-b363-11e9-990e-fe448544ce72 to disappear
Jul 31 07:22:48.922: INFO: Pod pod-configmaps-fec46ec0-b363-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:22:48.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-kqmsv" for this suite.
Jul 31 07:22:54.937: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:22:55.012: INFO: namespace: e2e-tests-configmap-kqmsv, resource: bindings, ignored listing per whitelist
Jul 31 07:22:55.012: INFO: namespace e2e-tests-configmap-kqmsv deletion completed in 6.086653696s

• [SLOW TEST:8.186 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:22:55.012: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-03a41330-b364-11e9-990e-fe448544ce72
STEP: Creating a pod to test consume configMaps
Jul 31 07:22:55.076: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-03a4745c-b364-11e9-990e-fe448544ce72" in namespace "e2e-tests-projected-dlwmx" to be "success or failure"
Jul 31 07:22:55.079: INFO: Pod "pod-projected-configmaps-03a4745c-b364-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.177153ms
Jul 31 07:22:57.081: INFO: Pod "pod-projected-configmaps-03a4745c-b364-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00502914s
STEP: Saw pod success
Jul 31 07:22:57.082: INFO: Pod "pod-projected-configmaps-03a4745c-b364-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 07:22:57.084: INFO: Trying to get logs from node shushsha-k8s-worker1 pod pod-projected-configmaps-03a4745c-b364-11e9-990e-fe448544ce72 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jul 31 07:22:57.096: INFO: Waiting for pod pod-projected-configmaps-03a4745c-b364-11e9-990e-fe448544ce72 to disappear
Jul 31 07:22:57.099: INFO: Pod pod-projected-configmaps-03a4745c-b364-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:22:57.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dlwmx" for this suite.
Jul 31 07:23:03.110: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:23:03.137: INFO: namespace: e2e-tests-projected-dlwmx, resource: bindings, ignored listing per whitelist
Jul 31 07:23:03.184: INFO: namespace e2e-tests-projected-dlwmx deletion completed in 6.082733923s

• [SLOW TEST:8.172 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:23:03.184: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jul 31 07:23:03.253: INFO: Waiting up to 5m0s for pod "pod-088405b4-b364-11e9-990e-fe448544ce72" in namespace "e2e-tests-emptydir-hmpf4" to be "success or failure"
Jul 31 07:23:03.255: INFO: Pod "pod-088405b4-b364-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.12207ms
Jul 31 07:23:05.258: INFO: Pod "pod-088405b4-b364-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005039523s
STEP: Saw pod success
Jul 31 07:23:05.258: INFO: Pod "pod-088405b4-b364-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 07:23:05.260: INFO: Trying to get logs from node shushsha-k8s-worker1 pod pod-088405b4-b364-11e9-990e-fe448544ce72 container test-container: <nil>
STEP: delete the pod
Jul 31 07:23:05.273: INFO: Waiting for pod pod-088405b4-b364-11e9-990e-fe448544ce72 to disappear
Jul 31 07:23:05.276: INFO: Pod pod-088405b4-b364-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:23:05.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-hmpf4" for this suite.
Jul 31 07:23:11.287: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:23:11.326: INFO: namespace: e2e-tests-emptydir-hmpf4, resource: bindings, ignored listing per whitelist
Jul 31 07:23:11.362: INFO: namespace e2e-tests-emptydir-hmpf4 deletion completed in 6.083673955s

• [SLOW TEST:8.178 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:23:11.363: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Jul 31 07:23:11.423: INFO: Waiting up to 5m0s for pod "var-expansion-0d62ce43-b364-11e9-990e-fe448544ce72" in namespace "e2e-tests-var-expansion-wrtsg" to be "success or failure"
Jul 31 07:23:11.426: INFO: Pod "var-expansion-0d62ce43-b364-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.536304ms
Jul 31 07:23:13.429: INFO: Pod "var-expansion-0d62ce43-b364-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005811374s
STEP: Saw pod success
Jul 31 07:23:13.429: INFO: Pod "var-expansion-0d62ce43-b364-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 07:23:13.432: INFO: Trying to get logs from node shushsha-k8s-worker2 pod var-expansion-0d62ce43-b364-11e9-990e-fe448544ce72 container dapi-container: <nil>
STEP: delete the pod
Jul 31 07:23:13.445: INFO: Waiting for pod var-expansion-0d62ce43-b364-11e9-990e-fe448544ce72 to disappear
Jul 31 07:23:13.448: INFO: Pod var-expansion-0d62ce43-b364-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:23:13.448: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-wrtsg" for this suite.
Jul 31 07:23:19.459: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:23:19.518: INFO: namespace: e2e-tests-var-expansion-wrtsg, resource: bindings, ignored listing per whitelist
Jul 31 07:23:19.537: INFO: namespace e2e-tests-var-expansion-wrtsg deletion completed in 6.086082182s

• [SLOW TEST:8.174 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:23:19.537: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jul 31 07:23:19.605: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1243349c-b364-11e9-990e-fe448544ce72" in namespace "e2e-tests-downward-api-xlth9" to be "success or failure"
Jul 31 07:23:19.609: INFO: Pod "downwardapi-volume-1243349c-b364-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 3.134607ms
Jul 31 07:23:21.611: INFO: Pod "downwardapi-volume-1243349c-b364-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006035924s
STEP: Saw pod success
Jul 31 07:23:21.611: INFO: Pod "downwardapi-volume-1243349c-b364-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 07:23:21.614: INFO: Trying to get logs from node shushsha-k8s-worker1 pod downwardapi-volume-1243349c-b364-11e9-990e-fe448544ce72 container client-container: <nil>
STEP: delete the pod
Jul 31 07:23:21.627: INFO: Waiting for pod downwardapi-volume-1243349c-b364-11e9-990e-fe448544ce72 to disappear
Jul 31 07:23:21.629: INFO: Pod downwardapi-volume-1243349c-b364-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:23:21.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-xlth9" for this suite.
Jul 31 07:23:27.640: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:23:27.671: INFO: namespace: e2e-tests-downward-api-xlth9, resource: bindings, ignored listing per whitelist
Jul 31 07:23:27.711: INFO: namespace e2e-tests-downward-api-xlth9 deletion completed in 6.07936788s

• [SLOW TEST:8.174 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:23:27.712: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:23:27.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-dfbhw" for this suite.
Jul 31 07:23:33.813: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:23:33.835: INFO: namespace: e2e-tests-kubelet-test-dfbhw, resource: bindings, ignored listing per whitelist
Jul 31 07:23:33.892: INFO: namespace e2e-tests-kubelet-test-dfbhw deletion completed in 6.087546258s

• [SLOW TEST:6.181 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:23:33.893: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Jul 31 07:23:33.960: INFO: Waiting up to 5m0s for pod "client-containers-1ad1b05f-b364-11e9-990e-fe448544ce72" in namespace "e2e-tests-containers-m57zq" to be "success or failure"
Jul 31 07:23:33.962: INFO: Pod "client-containers-1ad1b05f-b364-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.229965ms
Jul 31 07:23:35.965: INFO: Pod "client-containers-1ad1b05f-b364-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005025843s
STEP: Saw pod success
Jul 31 07:23:35.965: INFO: Pod "client-containers-1ad1b05f-b364-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 07:23:35.967: INFO: Trying to get logs from node shushsha-k8s-worker1 pod client-containers-1ad1b05f-b364-11e9-990e-fe448544ce72 container test-container: <nil>
STEP: delete the pod
Jul 31 07:23:35.980: INFO: Waiting for pod client-containers-1ad1b05f-b364-11e9-990e-fe448544ce72 to disappear
Jul 31 07:23:35.983: INFO: Pod client-containers-1ad1b05f-b364-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:23:35.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-m57zq" for this suite.
Jul 31 07:23:41.994: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:23:42.049: INFO: namespace: e2e-tests-containers-m57zq, resource: bindings, ignored listing per whitelist
Jul 31 07:23:42.067: INFO: namespace e2e-tests-containers-m57zq deletion completed in 6.081922594s

• [SLOW TEST:8.175 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:23:42.068: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Jul 31 07:23:42.133: INFO: Waiting up to 5m0s for pod "var-expansion-1fb0a2a8-b364-11e9-990e-fe448544ce72" in namespace "e2e-tests-var-expansion-w7dm8" to be "success or failure"
Jul 31 07:23:42.135: INFO: Pod "var-expansion-1fb0a2a8-b364-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.51547ms
Jul 31 07:23:44.138: INFO: Pod "var-expansion-1fb0a2a8-b364-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005169309s
STEP: Saw pod success
Jul 31 07:23:44.138: INFO: Pod "var-expansion-1fb0a2a8-b364-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 07:23:44.140: INFO: Trying to get logs from node shushsha-k8s-worker2 pod var-expansion-1fb0a2a8-b364-11e9-990e-fe448544ce72 container dapi-container: <nil>
STEP: delete the pod
Jul 31 07:23:44.154: INFO: Waiting for pod var-expansion-1fb0a2a8-b364-11e9-990e-fe448544ce72 to disappear
Jul 31 07:23:44.156: INFO: Pod var-expansion-1fb0a2a8-b364-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:23:44.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-w7dm8" for this suite.
Jul 31 07:23:50.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:23:50.206: INFO: namespace: e2e-tests-var-expansion-w7dm8, resource: bindings, ignored listing per whitelist
Jul 31 07:23:50.241: INFO: namespace e2e-tests-var-expansion-w7dm8 deletion completed in 6.081417689s

• [SLOW TEST:8.172 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:23:50.241: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Jul 31 07:23:54.349: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jul 31 07:23:54.352: INFO: Pod pod-with-prestop-http-hook still exists
Jul 31 07:23:56.352: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jul 31 07:23:56.355: INFO: Pod pod-with-prestop-http-hook still exists
Jul 31 07:23:58.352: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jul 31 07:23:58.355: INFO: Pod pod-with-prestop-http-hook still exists
Jul 31 07:24:00.352: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jul 31 07:24:00.356: INFO: Pod pod-with-prestop-http-hook still exists
Jul 31 07:24:02.352: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jul 31 07:24:02.355: INFO: Pod pod-with-prestop-http-hook still exists
Jul 31 07:24:04.352: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jul 31 07:24:04.355: INFO: Pod pod-with-prestop-http-hook still exists
Jul 31 07:24:06.353: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jul 31 07:24:06.356: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:24:06.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-j9nwk" for this suite.
Jul 31 07:24:28.375: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:24:28.416: INFO: namespace: e2e-tests-container-lifecycle-hook-j9nwk, resource: bindings, ignored listing per whitelist
Jul 31 07:24:28.452: INFO: namespace e2e-tests-container-lifecycle-hook-j9nwk deletion completed in 22.08601151s

• [SLOW TEST:38.212 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:24:28.453: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jul 31 07:24:28.530: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Jul 31 07:24:28.536: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:24:28.538: INFO: Number of nodes with available pods: 0
Jul 31 07:24:28.538: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 07:24:29.541: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:24:29.543: INFO: Number of nodes with available pods: 0
Jul 31 07:24:29.543: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 07:24:30.543: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:24:30.545: INFO: Number of nodes with available pods: 1
Jul 31 07:24:30.545: INFO: Node shushsha-k8s-worker2 is running more than one daemon pod
Jul 31 07:24:31.541: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:24:31.544: INFO: Number of nodes with available pods: 2
Jul 31 07:24:31.544: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Jul 31 07:24:31.561: INFO: Wrong image for pod: daemon-set-448wc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:31.561: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:31.565: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:24:32.568: INFO: Wrong image for pod: daemon-set-448wc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:32.568: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:32.571: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:24:33.568: INFO: Wrong image for pod: daemon-set-448wc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:33.568: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:33.571: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:24:34.568: INFO: Wrong image for pod: daemon-set-448wc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:34.568: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:34.571: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:24:35.568: INFO: Wrong image for pod: daemon-set-448wc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:35.568: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:35.571: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:24:36.568: INFO: Wrong image for pod: daemon-set-448wc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:36.568: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:36.571: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:24:37.568: INFO: Wrong image for pod: daemon-set-448wc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:37.568: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:37.571: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:24:38.568: INFO: Wrong image for pod: daemon-set-448wc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:38.568: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:38.571: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:24:39.569: INFO: Wrong image for pod: daemon-set-448wc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:39.569: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:39.571: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:24:40.568: INFO: Wrong image for pod: daemon-set-448wc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:40.568: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:40.572: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:24:41.568: INFO: Wrong image for pod: daemon-set-448wc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:41.568: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:41.571: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:24:42.568: INFO: Wrong image for pod: daemon-set-448wc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:42.568: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:42.571: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:24:43.568: INFO: Wrong image for pod: daemon-set-448wc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:43.568: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:43.571: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:24:44.568: INFO: Wrong image for pod: daemon-set-448wc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:44.568: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:44.571: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:24:45.569: INFO: Wrong image for pod: daemon-set-448wc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:45.569: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:45.571: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:24:46.568: INFO: Wrong image for pod: daemon-set-448wc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:46.568: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:46.571: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:24:47.568: INFO: Wrong image for pod: daemon-set-448wc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:47.568: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:47.571: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:24:48.568: INFO: Wrong image for pod: daemon-set-448wc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:48.568: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:48.571: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:24:49.569: INFO: Wrong image for pod: daemon-set-448wc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:49.569: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:49.572: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:24:50.568: INFO: Wrong image for pod: daemon-set-448wc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:50.568: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:50.571: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:24:51.568: INFO: Wrong image for pod: daemon-set-448wc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:51.569: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:51.572: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:24:52.568: INFO: Wrong image for pod: daemon-set-448wc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:52.568: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:52.571: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:24:53.569: INFO: Wrong image for pod: daemon-set-448wc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:53.569: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:53.572: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:24:54.568: INFO: Wrong image for pod: daemon-set-448wc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:54.568: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:54.571: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:24:55.568: INFO: Wrong image for pod: daemon-set-448wc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:55.568: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:55.571: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:24:56.568: INFO: Wrong image for pod: daemon-set-448wc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:56.568: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:56.571: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:24:57.568: INFO: Wrong image for pod: daemon-set-448wc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:57.568: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:57.571: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:24:58.568: INFO: Wrong image for pod: daemon-set-448wc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:58.568: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:58.571: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:24:59.568: INFO: Wrong image for pod: daemon-set-448wc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:59.568: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:24:59.571: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:25:00.568: INFO: Wrong image for pod: daemon-set-448wc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:25:00.568: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:25:00.571: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:25:01.569: INFO: Wrong image for pod: daemon-set-448wc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:25:01.569: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:25:01.572: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:25:02.568: INFO: Wrong image for pod: daemon-set-448wc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:25:02.568: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:25:02.571: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:25:03.569: INFO: Wrong image for pod: daemon-set-448wc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:25:03.569: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:25:03.572: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:25:04.569: INFO: Wrong image for pod: daemon-set-448wc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:25:04.569: INFO: Pod daemon-set-448wc is not available
Jul 31 07:25:04.569: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:25:04.575: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:25:05.568: INFO: Pod daemon-set-hx4pg is not available
Jul 31 07:25:05.568: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:25:05.571: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:25:06.568: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:25:06.571: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:25:07.569: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:25:07.572: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:25:08.568: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:25:08.570: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:25:09.568: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:25:09.572: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:25:10.569: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:25:10.572: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:25:11.568: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:25:11.571: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:25:12.569: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:25:12.572: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:25:13.569: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:25:13.572: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:25:14.568: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:25:14.571: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:25:15.568: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:25:15.571: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:25:16.568: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:25:16.572: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:25:17.568: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:25:17.571: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:25:18.569: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:25:18.572: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:25:19.568: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:25:19.571: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:25:20.568: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:25:20.571: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:25:21.568: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:25:21.571: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:25:22.568: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:25:22.571: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:25:23.568: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:25:23.571: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:25:24.569: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:25:24.572: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:25:25.568: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:25:25.571: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:25:26.569: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:25:26.572: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:25:27.569: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:25:27.572: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:25:28.568: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:25:28.571: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:25:29.570: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:25:29.573: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:25:30.568: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:25:30.572: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:25:31.569: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:25:31.571: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:25:32.569: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:25:32.572: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:25:33.568: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:25:33.571: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:25:34.568: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:25:34.572: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:25:35.568: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:25:35.572: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:25:36.568: INFO: Wrong image for pod: daemon-set-vxw84. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 31 07:25:36.568: INFO: Pod daemon-set-vxw84 is not available
Jul 31 07:25:36.571: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:25:37.568: INFO: Pod daemon-set-2fpm5 is not available
Jul 31 07:25:37.571: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Jul 31 07:25:37.574: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:25:37.577: INFO: Number of nodes with available pods: 1
Jul 31 07:25:37.577: INFO: Node shushsha-k8s-worker2 is running more than one daemon pod
Jul 31 07:25:38.581: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:25:38.584: INFO: Number of nodes with available pods: 1
Jul 31 07:25:38.584: INFO: Node shushsha-k8s-worker2 is running more than one daemon pod
Jul 31 07:25:39.580: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:25:39.582: INFO: Number of nodes with available pods: 2
Jul 31 07:25:39.582: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-tkjxt, will wait for the garbage collector to delete the pods
Jul 31 07:25:39.651: INFO: Deleting DaemonSet.extensions daemon-set took: 4.705115ms
Jul 31 07:25:39.751: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.300578ms
Jul 31 07:25:52.754: INFO: Number of nodes with available pods: 0
Jul 31 07:25:52.754: INFO: Number of running nodes: 0, number of available pods: 0
Jul 31 07:25:52.756: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-tkjxt/daemonsets","resourceVersion":"16979"},"items":null}

Jul 31 07:25:52.758: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-tkjxt/pods","resourceVersion":"16979"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:25:52.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-tkjxt" for this suite.
Jul 31 07:25:58.776: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:25:58.808: INFO: namespace: e2e-tests-daemonsets-tkjxt, resource: bindings, ignored listing per whitelist
Jul 31 07:25:58.850: INFO: namespace e2e-tests-daemonsets-tkjxt deletion completed in 6.082106002s

• [SLOW TEST:90.398 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:25:58.851: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jul 31 07:25:58.911: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-kggjr'
Jul 31 07:25:59.034: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jul 31 07:25:59.034: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1404
Jul 31 07:26:01.044: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-kggjr'
Jul 31 07:26:01.150: INFO: stderr: ""
Jul 31 07:26:01.150: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:26:01.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-kggjr" for this suite.
Jul 31 07:26:23.166: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:26:23.175: INFO: namespace: e2e-tests-kubectl-kggjr, resource: bindings, ignored listing per whitelist
Jul 31 07:26:23.240: INFO: namespace e2e-tests-kubectl-kggjr deletion completed in 22.085077407s

• [SLOW TEST:24.389 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:26:23.240: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-9zs2v
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-9zs2v
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-9zs2v
Jul 31 07:26:23.311: INFO: Found 0 stateful pods, waiting for 1
Jul 31 07:26:33.314: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Jul 31 07:26:33.317: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 exec --namespace=e2e-tests-statefulset-9zs2v ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul 31 07:26:33.581: INFO: stderr: ""
Jul 31 07:26:33.581: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul 31 07:26:33.581: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jul 31 07:26:33.584: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jul 31 07:26:43.587: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jul 31 07:26:43.587: INFO: Waiting for statefulset status.replicas updated to 0
Jul 31 07:26:43.598: INFO: POD   NODE                  PHASE    GRACE  CONDITIONS
Jul 31 07:26:43.598: INFO: ss-0  shushsha-k8s-worker2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 07:26:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 07:26:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 07:26:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 07:26:23 +0000 UTC  }]
Jul 31 07:26:43.598: INFO: 
Jul 31 07:26:43.598: INFO: StatefulSet ss has not reached scale 3, at 1
Jul 31 07:26:44.602: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997448244s
Jul 31 07:26:45.605: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.993066191s
Jul 31 07:26:46.609: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.989830122s
Jul 31 07:26:47.613: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.986335181s
Jul 31 07:26:48.617: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.98235765s
Jul 31 07:26:49.621: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.978528705s
Jul 31 07:26:50.624: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.974494551s
Jul 31 07:26:51.628: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.970722144s
Jul 31 07:26:52.632: INFO: Verifying statefulset ss doesn't scale past 3 for another 967.269933ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-9zs2v
Jul 31 07:26:53.636: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 exec --namespace=e2e-tests-statefulset-9zs2v ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 31 07:26:53.956: INFO: stderr: ""
Jul 31 07:26:53.956: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jul 31 07:26:53.956: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jul 31 07:26:53.956: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 exec --namespace=e2e-tests-statefulset-9zs2v ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 31 07:26:54.191: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Jul 31 07:26:54.191: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jul 31 07:26:54.191: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jul 31 07:26:54.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 exec --namespace=e2e-tests-statefulset-9zs2v ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 31 07:26:54.539: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Jul 31 07:26:54.540: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jul 31 07:26:54.540: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jul 31 07:26:54.543: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jul 31 07:26:54.543: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jul 31 07:26:54.543: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Jul 31 07:26:54.546: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 exec --namespace=e2e-tests-statefulset-9zs2v ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul 31 07:26:54.801: INFO: stderr: ""
Jul 31 07:26:54.801: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul 31 07:26:54.801: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jul 31 07:26:54.801: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 exec --namespace=e2e-tests-statefulset-9zs2v ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul 31 07:26:55.044: INFO: stderr: ""
Jul 31 07:26:55.044: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul 31 07:26:55.044: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jul 31 07:26:55.044: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 exec --namespace=e2e-tests-statefulset-9zs2v ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul 31 07:26:55.326: INFO: stderr: ""
Jul 31 07:26:55.326: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul 31 07:26:55.326: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jul 31 07:26:55.326: INFO: Waiting for statefulset status.replicas updated to 0
Jul 31 07:26:55.330: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Jul 31 07:27:05.343: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jul 31 07:27:05.343: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jul 31 07:27:05.343: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jul 31 07:27:05.354: INFO: POD   NODE                  PHASE    GRACE  CONDITIONS
Jul 31 07:27:05.354: INFO: ss-0  shushsha-k8s-worker2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 07:26:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 07:26:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 07:26:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 07:26:23 +0000 UTC  }]
Jul 31 07:27:05.354: INFO: ss-1  shushsha-k8s-worker1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 07:26:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 07:26:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 07:26:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 07:26:43 +0000 UTC  }]
Jul 31 07:27:05.354: INFO: ss-2  shushsha-k8s-worker2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 07:26:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 07:26:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 07:26:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 07:26:43 +0000 UTC  }]
Jul 31 07:27:05.354: INFO: 
Jul 31 07:27:05.354: INFO: StatefulSet ss has not reached scale 0, at 3
Jul 31 07:27:06.358: INFO: POD   NODE                  PHASE    GRACE  CONDITIONS
Jul 31 07:27:06.358: INFO: ss-0  shushsha-k8s-worker2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 07:26:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 07:26:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 07:26:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 07:26:23 +0000 UTC  }]
Jul 31 07:27:06.358: INFO: ss-1  shushsha-k8s-worker1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 07:26:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 07:26:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 07:26:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 07:26:43 +0000 UTC  }]
Jul 31 07:27:06.358: INFO: ss-2  shushsha-k8s-worker2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 07:26:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 07:26:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-31 07:26:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-31 07:26:43 +0000 UTC  }]
Jul 31 07:27:06.358: INFO: 
Jul 31 07:27:06.358: INFO: StatefulSet ss has not reached scale 0, at 3
Jul 31 07:27:07.361: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.991200437s
Jul 31 07:27:08.365: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.988042518s
Jul 31 07:27:09.367: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.984766407s
Jul 31 07:27:10.371: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.981936332s
Jul 31 07:27:11.374: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.978442399s
Jul 31 07:27:12.378: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.975219491s
Jul 31 07:27:13.381: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.971757133s
Jul 31 07:27:14.384: INFO: Verifying statefulset ss doesn't scale past 0 for another 968.439984ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-9zs2v
Jul 31 07:27:15.387: INFO: Scaling statefulset ss to 0
Jul 31 07:27:15.394: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jul 31 07:27:15.396: INFO: Deleting all statefulset in ns e2e-tests-statefulset-9zs2v
Jul 31 07:27:15.398: INFO: Scaling statefulset ss to 0
Jul 31 07:27:15.405: INFO: Waiting for statefulset status.replicas updated to 0
Jul 31 07:27:15.407: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:27:15.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-9zs2v" for this suite.
Jul 31 07:27:21.433: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:27:21.479: INFO: namespace: e2e-tests-statefulset-9zs2v, resource: bindings, ignored listing per whitelist
Jul 31 07:27:21.510: INFO: namespace e2e-tests-statefulset-9zs2v deletion completed in 6.087738504s

• [SLOW TEST:58.270 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:27:21.511: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-922wd
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-922wd
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-922wd
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-922wd
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-922wd
Jul 31 07:27:25.596: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-922wd, name: ss-0, uid: a44aebe8-b364-11e9-ac6f-000017003e78, status phase: Pending. Waiting for statefulset controller to delete.
Jul 31 07:27:25.791: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-922wd, name: ss-0, uid: a44aebe8-b364-11e9-ac6f-000017003e78, status phase: Failed. Waiting for statefulset controller to delete.
Jul 31 07:27:25.798: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-922wd, name: ss-0, uid: a44aebe8-b364-11e9-ac6f-000017003e78, status phase: Failed. Waiting for statefulset controller to delete.
Jul 31 07:27:25.801: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-922wd
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-922wd
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-922wd and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jul 31 07:27:29.822: INFO: Deleting all statefulset in ns e2e-tests-statefulset-922wd
Jul 31 07:27:29.824: INFO: Scaling statefulset ss to 0
Jul 31 07:27:39.839: INFO: Waiting for statefulset status.replicas updated to 0
Jul 31 07:27:39.842: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:27:39.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-922wd" for this suite.
Jul 31 07:27:45.865: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:27:45.888: INFO: namespace: e2e-tests-statefulset-922wd, resource: bindings, ignored listing per whitelist
Jul 31 07:27:45.940: INFO: namespace e2e-tests-statefulset-922wd deletion completed in 6.083854253s

• [SLOW TEST:24.429 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:27:45.940: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-cbxgx/secret-test-b10d307c-b364-11e9-990e-fe448544ce72
STEP: Creating a pod to test consume secrets
Jul 31 07:27:46.011: INFO: Waiting up to 5m0s for pod "pod-configmaps-b10d9767-b364-11e9-990e-fe448544ce72" in namespace "e2e-tests-secrets-cbxgx" to be "success or failure"
Jul 31 07:27:46.013: INFO: Pod "pod-configmaps-b10d9767-b364-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.087973ms
Jul 31 07:27:48.016: INFO: Pod "pod-configmaps-b10d9767-b364-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005531972s
STEP: Saw pod success
Jul 31 07:27:48.016: INFO: Pod "pod-configmaps-b10d9767-b364-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 07:27:48.019: INFO: Trying to get logs from node shushsha-k8s-worker1 pod pod-configmaps-b10d9767-b364-11e9-990e-fe448544ce72 container env-test: <nil>
STEP: delete the pod
Jul 31 07:27:48.033: INFO: Waiting for pod pod-configmaps-b10d9767-b364-11e9-990e-fe448544ce72 to disappear
Jul 31 07:27:48.035: INFO: Pod pod-configmaps-b10d9767-b364-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:27:48.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-cbxgx" for this suite.
Jul 31 07:27:54.047: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:27:54.095: INFO: namespace: e2e-tests-secrets-cbxgx, resource: bindings, ignored listing per whitelist
Jul 31 07:27:54.120: INFO: namespace e2e-tests-secrets-cbxgx deletion completed in 6.081254079s

• [SLOW TEST:8.181 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:27:54.121: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jul 31 07:27:54.177: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:27:58.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-64qf6" for this suite.
Jul 31 07:28:04.218: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:28:04.240: INFO: namespace: e2e-tests-init-container-64qf6, resource: bindings, ignored listing per whitelist
Jul 31 07:28:04.293: INFO: namespace e2e-tests-init-container-64qf6 deletion completed in 6.083861278s

• [SLOW TEST:10.173 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:28:04.294: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jul 31 07:28:04.358: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bbfd20c7-b364-11e9-990e-fe448544ce72" in namespace "e2e-tests-downward-api-jszhj" to be "success or failure"
Jul 31 07:28:04.360: INFO: Pod "downwardapi-volume-bbfd20c7-b364-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.092278ms
Jul 31 07:28:06.364: INFO: Pod "downwardapi-volume-bbfd20c7-b364-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005455416s
Jul 31 07:28:08.367: INFO: Pod "downwardapi-volume-bbfd20c7-b364-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008501663s
STEP: Saw pod success
Jul 31 07:28:08.367: INFO: Pod "downwardapi-volume-bbfd20c7-b364-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 07:28:08.369: INFO: Trying to get logs from node shushsha-k8s-worker2 pod downwardapi-volume-bbfd20c7-b364-11e9-990e-fe448544ce72 container client-container: <nil>
STEP: delete the pod
Jul 31 07:28:08.387: INFO: Waiting for pod downwardapi-volume-bbfd20c7-b364-11e9-990e-fe448544ce72 to disappear
Jul 31 07:28:08.389: INFO: Pod downwardapi-volume-bbfd20c7-b364-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:28:08.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-jszhj" for this suite.
Jul 31 07:28:14.401: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:28:14.461: INFO: namespace: e2e-tests-downward-api-jszhj, resource: bindings, ignored listing per whitelist
Jul 31 07:28:14.473: INFO: namespace e2e-tests-downward-api-jszhj deletion completed in 6.080912186s

• [SLOW TEST:10.180 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:28:14.474: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-c20efd8d-b364-11e9-990e-fe448544ce72
STEP: Creating a pod to test consume secrets
Jul 31 07:28:14.545: INFO: Waiting up to 5m0s for pod "pod-secrets-c20f6dd4-b364-11e9-990e-fe448544ce72" in namespace "e2e-tests-secrets-tqqxf" to be "success or failure"
Jul 31 07:28:14.547: INFO: Pod "pod-secrets-c20f6dd4-b364-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.23772ms
Jul 31 07:28:16.550: INFO: Pod "pod-secrets-c20f6dd4-b364-11e9-990e-fe448544ce72": Phase="Running", Reason="", readiness=true. Elapsed: 2.005612333s
Jul 31 07:28:18.553: INFO: Pod "pod-secrets-c20f6dd4-b364-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008783643s
STEP: Saw pod success
Jul 31 07:28:18.554: INFO: Pod "pod-secrets-c20f6dd4-b364-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 07:28:18.556: INFO: Trying to get logs from node shushsha-k8s-worker2 pod pod-secrets-c20f6dd4-b364-11e9-990e-fe448544ce72 container secret-env-test: <nil>
STEP: delete the pod
Jul 31 07:28:18.571: INFO: Waiting for pod pod-secrets-c20f6dd4-b364-11e9-990e-fe448544ce72 to disappear
Jul 31 07:28:18.573: INFO: Pod pod-secrets-c20f6dd4-b364-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:28:18.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-tqqxf" for this suite.
Jul 31 07:28:24.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:28:24.599: INFO: namespace: e2e-tests-secrets-tqqxf, resource: bindings, ignored listing per whitelist
Jul 31 07:28:24.658: INFO: namespace e2e-tests-secrets-tqqxf deletion completed in 6.082294349s

• [SLOW TEST:10.184 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:28:24.659: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-c820cb15-b364-11e9-990e-fe448544ce72
STEP: Creating a pod to test consume configMaps
Jul 31 07:28:24.727: INFO: Waiting up to 5m0s for pod "pod-configmaps-c82130be-b364-11e9-990e-fe448544ce72" in namespace "e2e-tests-configmap-q4pm5" to be "success or failure"
Jul 31 07:28:24.730: INFO: Pod "pod-configmaps-c82130be-b364-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.270155ms
Jul 31 07:28:26.733: INFO: Pod "pod-configmaps-c82130be-b364-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005314512s
STEP: Saw pod success
Jul 31 07:28:26.733: INFO: Pod "pod-configmaps-c82130be-b364-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 07:28:26.735: INFO: Trying to get logs from node shushsha-k8s-worker1 pod pod-configmaps-c82130be-b364-11e9-990e-fe448544ce72 container configmap-volume-test: <nil>
STEP: delete the pod
Jul 31 07:28:26.747: INFO: Waiting for pod pod-configmaps-c82130be-b364-11e9-990e-fe448544ce72 to disappear
Jul 31 07:28:26.749: INFO: Pod pod-configmaps-c82130be-b364-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:28:26.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-q4pm5" for this suite.
Jul 31 07:28:32.761: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:28:32.798: INFO: namespace: e2e-tests-configmap-q4pm5, resource: bindings, ignored listing per whitelist
Jul 31 07:28:32.843: INFO: namespace e2e-tests-configmap-q4pm5 deletion completed in 6.090040577s

• [SLOW TEST:8.184 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:28:32.843: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Jul 31 07:28:32.925: INFO: Waiting up to 5m0s for pod "var-expansion-cd041855-b364-11e9-990e-fe448544ce72" in namespace "e2e-tests-var-expansion-sfhnh" to be "success or failure"
Jul 31 07:28:32.927: INFO: Pod "var-expansion-cd041855-b364-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.346034ms
Jul 31 07:28:34.931: INFO: Pod "var-expansion-cd041855-b364-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005634563s
Jul 31 07:28:36.934: INFO: Pod "var-expansion-cd041855-b364-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008822829s
STEP: Saw pod success
Jul 31 07:28:36.934: INFO: Pod "var-expansion-cd041855-b364-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 07:28:36.936: INFO: Trying to get logs from node shushsha-k8s-worker2 pod var-expansion-cd041855-b364-11e9-990e-fe448544ce72 container dapi-container: <nil>
STEP: delete the pod
Jul 31 07:28:36.952: INFO: Waiting for pod var-expansion-cd041855-b364-11e9-990e-fe448544ce72 to disappear
Jul 31 07:28:36.955: INFO: Pod var-expansion-cd041855-b364-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:28:36.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-sfhnh" for this suite.
Jul 31 07:28:42.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:28:43.001: INFO: namespace: e2e-tests-var-expansion-sfhnh, resource: bindings, ignored listing per whitelist
Jul 31 07:28:43.049: INFO: namespace e2e-tests-var-expansion-sfhnh deletion completed in 6.090824889s

• [SLOW TEST:10.206 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:28:43.049: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Jul 31 07:28:43.110: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 create -f - --namespace=e2e-tests-kubectl-7hb49'
Jul 31 07:28:43.344: INFO: stderr: ""
Jul 31 07:28:43.344: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Jul 31 07:28:44.347: INFO: Selector matched 1 pods for map[app:redis]
Jul 31 07:28:44.347: INFO: Found 0 / 1
Jul 31 07:28:45.347: INFO: Selector matched 1 pods for map[app:redis]
Jul 31 07:28:45.347: INFO: Found 1 / 1
Jul 31 07:28:45.347: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Jul 31 07:28:45.350: INFO: Selector matched 1 pods for map[app:redis]
Jul 31 07:28:45.350: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jul 31 07:28:45.350: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 patch pod redis-master-qv7pn --namespace=e2e-tests-kubectl-7hb49 -p {"metadata":{"annotations":{"x":"y"}}}'
Jul 31 07:28:45.518: INFO: stderr: ""
Jul 31 07:28:45.518: INFO: stdout: "pod/redis-master-qv7pn patched\n"
STEP: checking annotations
Jul 31 07:28:45.521: INFO: Selector matched 1 pods for map[app:redis]
Jul 31 07:28:45.521: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:28:45.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-7hb49" for this suite.
Jul 31 07:29:07.532: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:29:07.590: INFO: namespace: e2e-tests-kubectl-7hb49, resource: bindings, ignored listing per whitelist
Jul 31 07:29:07.609: INFO: namespace e2e-tests-kubectl-7hb49 deletion completed in 22.085199811s

• [SLOW TEST:24.560 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:29:07.609: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jul 31 07:29:07.677: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:29:08.721: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-h479r" for this suite.
Jul 31 07:29:14.734: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:29:14.753: INFO: namespace: e2e-tests-custom-resource-definition-h479r, resource: bindings, ignored listing per whitelist
Jul 31 07:29:14.815: INFO: namespace e2e-tests-custom-resource-definition-h479r deletion completed in 6.090553159s

• [SLOW TEST:7.206 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:29:14.815: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Jul 31 07:29:18.902: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 31 07:29:18.905: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 31 07:29:20.905: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 31 07:29:20.908: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 31 07:29:22.905: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 31 07:29:22.908: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 31 07:29:24.905: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 31 07:29:24.908: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 31 07:29:26.905: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 31 07:29:26.908: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 31 07:29:28.905: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 31 07:29:28.908: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 31 07:29:30.905: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 31 07:29:30.908: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 31 07:29:32.905: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 31 07:29:32.909: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 31 07:29:34.905: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 31 07:29:34.909: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 31 07:29:36.905: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 31 07:29:36.908: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 31 07:29:38.905: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 31 07:29:38.908: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:29:38.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-r8bjt" for this suite.
Jul 31 07:30:00.928: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:30:00.991: INFO: namespace: e2e-tests-container-lifecycle-hook-r8bjt, resource: bindings, ignored listing per whitelist
Jul 31 07:30:01.008: INFO: namespace e2e-tests-container-lifecycle-hook-r8bjt deletion completed in 22.087748614s

• [SLOW TEST:46.192 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:30:01.008: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jul 31 07:30:01.082: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Jul 31 07:30:01.087: INFO: Number of nodes with available pods: 0
Jul 31 07:30:01.087: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Jul 31 07:30:01.100: INFO: Number of nodes with available pods: 0
Jul 31 07:30:01.100: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 07:30:02.103: INFO: Number of nodes with available pods: 0
Jul 31 07:30:02.103: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 07:30:03.104: INFO: Number of nodes with available pods: 1
Jul 31 07:30:03.104: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Jul 31 07:30:03.117: INFO: Number of nodes with available pods: 1
Jul 31 07:30:03.117: INFO: Number of running nodes: 0, number of available pods: 1
Jul 31 07:30:04.121: INFO: Number of nodes with available pods: 0
Jul 31 07:30:04.121: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Jul 31 07:30:04.127: INFO: Number of nodes with available pods: 0
Jul 31 07:30:04.127: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 07:30:05.130: INFO: Number of nodes with available pods: 0
Jul 31 07:30:05.130: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 07:30:06.130: INFO: Number of nodes with available pods: 0
Jul 31 07:30:06.130: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 07:30:07.130: INFO: Number of nodes with available pods: 0
Jul 31 07:30:07.130: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 07:30:08.130: INFO: Number of nodes with available pods: 0
Jul 31 07:30:08.130: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 07:30:09.130: INFO: Number of nodes with available pods: 0
Jul 31 07:30:09.130: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 07:30:10.130: INFO: Number of nodes with available pods: 0
Jul 31 07:30:10.130: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 07:30:11.130: INFO: Number of nodes with available pods: 0
Jul 31 07:30:11.130: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 07:30:12.130: INFO: Number of nodes with available pods: 0
Jul 31 07:30:12.130: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 07:30:13.129: INFO: Number of nodes with available pods: 0
Jul 31 07:30:13.129: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 07:30:14.130: INFO: Number of nodes with available pods: 0
Jul 31 07:30:14.130: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 07:30:15.130: INFO: Number of nodes with available pods: 0
Jul 31 07:30:15.130: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 07:30:16.130: INFO: Number of nodes with available pods: 0
Jul 31 07:30:16.130: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 07:30:17.130: INFO: Number of nodes with available pods: 0
Jul 31 07:30:17.130: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 07:30:18.130: INFO: Number of nodes with available pods: 0
Jul 31 07:30:18.130: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 07:30:19.130: INFO: Number of nodes with available pods: 0
Jul 31 07:30:19.130: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 07:30:20.130: INFO: Number of nodes with available pods: 0
Jul 31 07:30:20.130: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 07:30:21.130: INFO: Number of nodes with available pods: 0
Jul 31 07:30:21.130: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 07:30:22.130: INFO: Number of nodes with available pods: 0
Jul 31 07:30:22.130: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 07:30:23.131: INFO: Number of nodes with available pods: 0
Jul 31 07:30:23.131: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 07:30:24.130: INFO: Number of nodes with available pods: 0
Jul 31 07:30:24.130: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 07:30:25.130: INFO: Number of nodes with available pods: 0
Jul 31 07:30:25.130: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 07:30:26.130: INFO: Number of nodes with available pods: 0
Jul 31 07:30:26.130: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 07:30:27.130: INFO: Number of nodes with available pods: 0
Jul 31 07:30:27.130: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 07:30:28.130: INFO: Number of nodes with available pods: 0
Jul 31 07:30:28.130: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 07:30:29.130: INFO: Number of nodes with available pods: 0
Jul 31 07:30:29.130: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 07:30:30.130: INFO: Number of nodes with available pods: 0
Jul 31 07:30:30.130: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 07:30:31.130: INFO: Number of nodes with available pods: 0
Jul 31 07:30:31.130: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 07:30:32.130: INFO: Number of nodes with available pods: 0
Jul 31 07:30:32.130: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 07:30:33.130: INFO: Number of nodes with available pods: 0
Jul 31 07:30:33.130: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 07:30:34.130: INFO: Number of nodes with available pods: 0
Jul 31 07:30:34.130: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 07:30:35.130: INFO: Number of nodes with available pods: 0
Jul 31 07:30:35.130: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 07:30:36.130: INFO: Number of nodes with available pods: 0
Jul 31 07:30:36.130: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 07:30:37.130: INFO: Number of nodes with available pods: 0
Jul 31 07:30:37.131: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 07:30:38.130: INFO: Number of nodes with available pods: 0
Jul 31 07:30:38.130: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 07:30:39.130: INFO: Number of nodes with available pods: 0
Jul 31 07:30:39.130: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 07:30:40.130: INFO: Number of nodes with available pods: 0
Jul 31 07:30:40.130: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 07:30:41.130: INFO: Number of nodes with available pods: 0
Jul 31 07:30:41.130: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 07:30:42.130: INFO: Number of nodes with available pods: 0
Jul 31 07:30:42.130: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 07:30:43.130: INFO: Number of nodes with available pods: 0
Jul 31 07:30:43.130: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 07:30:44.130: INFO: Number of nodes with available pods: 0
Jul 31 07:30:44.130: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 07:30:45.130: INFO: Number of nodes with available pods: 1
Jul 31 07:30:45.130: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-97klp, will wait for the garbage collector to delete the pods
Jul 31 07:30:45.192: INFO: Deleting DaemonSet.extensions daemon-set took: 4.722276ms
Jul 31 07:30:45.292: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.330406ms
Jul 31 07:31:19.095: INFO: Number of nodes with available pods: 0
Jul 31 07:31:19.095: INFO: Number of running nodes: 0, number of available pods: 0
Jul 31 07:31:19.097: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-97klp/daemonsets","resourceVersion":"18122"},"items":null}

Jul 31 07:31:19.099: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-97klp/pods","resourceVersion":"18122"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:31:19.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-97klp" for this suite.
Jul 31 07:31:25.123: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:31:25.179: INFO: namespace: e2e-tests-daemonsets-97klp, resource: bindings, ignored listing per whitelist
Jul 31 07:31:25.197: INFO: namespace e2e-tests-daemonsets-97klp deletion completed in 6.083192315s

• [SLOW TEST:84.190 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:31:25.198: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jul 31 07:31:25.264: INFO: Waiting up to 5m0s for pod "pod-33bcec81-b365-11e9-990e-fe448544ce72" in namespace "e2e-tests-emptydir-gn6ch" to be "success or failure"
Jul 31 07:31:25.266: INFO: Pod "pod-33bcec81-b365-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.290569ms
Jul 31 07:31:27.269: INFO: Pod "pod-33bcec81-b365-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005319758s
STEP: Saw pod success
Jul 31 07:31:27.269: INFO: Pod "pod-33bcec81-b365-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 07:31:27.271: INFO: Trying to get logs from node shushsha-k8s-worker2 pod pod-33bcec81-b365-11e9-990e-fe448544ce72 container test-container: <nil>
STEP: delete the pod
Jul 31 07:31:27.285: INFO: Waiting for pod pod-33bcec81-b365-11e9-990e-fe448544ce72 to disappear
Jul 31 07:31:27.287: INFO: Pod pod-33bcec81-b365-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:31:27.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-gn6ch" for this suite.
Jul 31 07:31:33.299: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:31:33.362: INFO: namespace: e2e-tests-emptydir-gn6ch, resource: bindings, ignored listing per whitelist
Jul 31 07:31:33.373: INFO: namespace e2e-tests-emptydir-gn6ch deletion completed in 6.082438259s

• [SLOW TEST:8.176 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:31:33.373: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-5l5fc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-5l5fc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-5l5fc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-5l5fc;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-5l5fc.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-5l5fc.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-5l5fc.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-5l5fc.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-5l5fc.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-5l5fc.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-5l5fc.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-5l5fc.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-5l5fc.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-5l5fc.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-5l5fc.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-5l5fc.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-5l5fc.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 244.40.106.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.106.40.244_udp@PTR;check="$$(dig +tcp +noall +answer +search 244.40.106.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.106.40.244_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-5l5fc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-5l5fc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-5l5fc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-5l5fc;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-5l5fc.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-5l5fc.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-5l5fc.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-5l5fc.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-5l5fc.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-5l5fc.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-5l5fc.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-5l5fc.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-5l5fc.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-5l5fc.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-5l5fc.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-5l5fc.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-5l5fc.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 244.40.106.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.106.40.244_udp@PTR;check="$$(dig +tcp +noall +answer +search 244.40.106.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.106.40.244_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jul 31 07:31:57.505: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-5l5fc/dns-test-389ddf85-b365-11e9-990e-fe448544ce72: the server could not find the requested resource (get pods dns-test-389ddf85-b365-11e9-990e-fe448544ce72)
Jul 31 07:31:57.508: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-5l5fc/dns-test-389ddf85-b365-11e9-990e-fe448544ce72: the server could not find the requested resource (get pods dns-test-389ddf85-b365-11e9-990e-fe448544ce72)
Jul 31 07:31:57.511: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-5l5fc from pod e2e-tests-dns-5l5fc/dns-test-389ddf85-b365-11e9-990e-fe448544ce72: the server could not find the requested resource (get pods dns-test-389ddf85-b365-11e9-990e-fe448544ce72)
Jul 31 07:31:57.513: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-5l5fc from pod e2e-tests-dns-5l5fc/dns-test-389ddf85-b365-11e9-990e-fe448544ce72: the server could not find the requested resource (get pods dns-test-389ddf85-b365-11e9-990e-fe448544ce72)
Jul 31 07:31:57.516: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-5l5fc.svc from pod e2e-tests-dns-5l5fc/dns-test-389ddf85-b365-11e9-990e-fe448544ce72: the server could not find the requested resource (get pods dns-test-389ddf85-b365-11e9-990e-fe448544ce72)
Jul 31 07:31:57.519: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-5l5fc.svc from pod e2e-tests-dns-5l5fc/dns-test-389ddf85-b365-11e9-990e-fe448544ce72: the server could not find the requested resource (get pods dns-test-389ddf85-b365-11e9-990e-fe448544ce72)
Jul 31 07:31:57.522: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-5l5fc.svc from pod e2e-tests-dns-5l5fc/dns-test-389ddf85-b365-11e9-990e-fe448544ce72: the server could not find the requested resource (get pods dns-test-389ddf85-b365-11e9-990e-fe448544ce72)
Jul 31 07:31:57.524: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-5l5fc.svc from pod e2e-tests-dns-5l5fc/dns-test-389ddf85-b365-11e9-990e-fe448544ce72: the server could not find the requested resource (get pods dns-test-389ddf85-b365-11e9-990e-fe448544ce72)
Jul 31 07:31:57.541: INFO: Lookups using e2e-tests-dns-5l5fc/dns-test-389ddf85-b365-11e9-990e-fe448544ce72 failed for: [jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-5l5fc jessie_tcp@dns-test-service.e2e-tests-dns-5l5fc jessie_udp@dns-test-service.e2e-tests-dns-5l5fc.svc jessie_tcp@dns-test-service.e2e-tests-dns-5l5fc.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-5l5fc.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-5l5fc.svc]

Jul 31 07:32:02.593: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-5l5fc/dns-test-389ddf85-b365-11e9-990e-fe448544ce72: the server could not find the requested resource (get pods dns-test-389ddf85-b365-11e9-990e-fe448544ce72)
Jul 31 07:32:02.596: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-5l5fc/dns-test-389ddf85-b365-11e9-990e-fe448544ce72: the server could not find the requested resource (get pods dns-test-389ddf85-b365-11e9-990e-fe448544ce72)
Jul 31 07:32:02.598: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-5l5fc from pod e2e-tests-dns-5l5fc/dns-test-389ddf85-b365-11e9-990e-fe448544ce72: the server could not find the requested resource (get pods dns-test-389ddf85-b365-11e9-990e-fe448544ce72)
Jul 31 07:32:02.602: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-5l5fc from pod e2e-tests-dns-5l5fc/dns-test-389ddf85-b365-11e9-990e-fe448544ce72: the server could not find the requested resource (get pods dns-test-389ddf85-b365-11e9-990e-fe448544ce72)
Jul 31 07:32:02.605: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-5l5fc.svc from pod e2e-tests-dns-5l5fc/dns-test-389ddf85-b365-11e9-990e-fe448544ce72: the server could not find the requested resource (get pods dns-test-389ddf85-b365-11e9-990e-fe448544ce72)
Jul 31 07:32:02.607: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-5l5fc.svc from pod e2e-tests-dns-5l5fc/dns-test-389ddf85-b365-11e9-990e-fe448544ce72: the server could not find the requested resource (get pods dns-test-389ddf85-b365-11e9-990e-fe448544ce72)
Jul 31 07:32:02.610: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-5l5fc.svc from pod e2e-tests-dns-5l5fc/dns-test-389ddf85-b365-11e9-990e-fe448544ce72: the server could not find the requested resource (get pods dns-test-389ddf85-b365-11e9-990e-fe448544ce72)
Jul 31 07:32:02.613: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-5l5fc.svc from pod e2e-tests-dns-5l5fc/dns-test-389ddf85-b365-11e9-990e-fe448544ce72: the server could not find the requested resource (get pods dns-test-389ddf85-b365-11e9-990e-fe448544ce72)
Jul 31 07:32:02.629: INFO: Lookups using e2e-tests-dns-5l5fc/dns-test-389ddf85-b365-11e9-990e-fe448544ce72 failed for: [jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-5l5fc jessie_tcp@dns-test-service.e2e-tests-dns-5l5fc jessie_udp@dns-test-service.e2e-tests-dns-5l5fc.svc jessie_tcp@dns-test-service.e2e-tests-dns-5l5fc.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-5l5fc.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-5l5fc.svc]

Jul 31 07:32:07.584: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-5l5fc/dns-test-389ddf85-b365-11e9-990e-fe448544ce72: the server could not find the requested resource (get pods dns-test-389ddf85-b365-11e9-990e-fe448544ce72)
Jul 31 07:32:07.587: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-5l5fc/dns-test-389ddf85-b365-11e9-990e-fe448544ce72: the server could not find the requested resource (get pods dns-test-389ddf85-b365-11e9-990e-fe448544ce72)
Jul 31 07:32:07.590: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-5l5fc from pod e2e-tests-dns-5l5fc/dns-test-389ddf85-b365-11e9-990e-fe448544ce72: the server could not find the requested resource (get pods dns-test-389ddf85-b365-11e9-990e-fe448544ce72)
Jul 31 07:32:07.593: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-5l5fc from pod e2e-tests-dns-5l5fc/dns-test-389ddf85-b365-11e9-990e-fe448544ce72: the server could not find the requested resource (get pods dns-test-389ddf85-b365-11e9-990e-fe448544ce72)
Jul 31 07:32:07.595: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-5l5fc.svc from pod e2e-tests-dns-5l5fc/dns-test-389ddf85-b365-11e9-990e-fe448544ce72: the server could not find the requested resource (get pods dns-test-389ddf85-b365-11e9-990e-fe448544ce72)
Jul 31 07:32:07.598: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-5l5fc.svc from pod e2e-tests-dns-5l5fc/dns-test-389ddf85-b365-11e9-990e-fe448544ce72: the server could not find the requested resource (get pods dns-test-389ddf85-b365-11e9-990e-fe448544ce72)
Jul 31 07:32:07.601: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-5l5fc.svc from pod e2e-tests-dns-5l5fc/dns-test-389ddf85-b365-11e9-990e-fe448544ce72: the server could not find the requested resource (get pods dns-test-389ddf85-b365-11e9-990e-fe448544ce72)
Jul 31 07:32:07.604: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-5l5fc.svc from pod e2e-tests-dns-5l5fc/dns-test-389ddf85-b365-11e9-990e-fe448544ce72: the server could not find the requested resource (get pods dns-test-389ddf85-b365-11e9-990e-fe448544ce72)
Jul 31 07:32:07.620: INFO: Lookups using e2e-tests-dns-5l5fc/dns-test-389ddf85-b365-11e9-990e-fe448544ce72 failed for: [jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-5l5fc jessie_tcp@dns-test-service.e2e-tests-dns-5l5fc jessie_udp@dns-test-service.e2e-tests-dns-5l5fc.svc jessie_tcp@dns-test-service.e2e-tests-dns-5l5fc.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-5l5fc.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-5l5fc.svc]

Jul 31 07:32:12.622: INFO: DNS probes using e2e-tests-dns-5l5fc/dns-test-389ddf85-b365-11e9-990e-fe448544ce72 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:32:12.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-5l5fc" for this suite.
Jul 31 07:32:18.689: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:32:18.734: INFO: namespace: e2e-tests-dns-5l5fc, resource: bindings, ignored listing per whitelist
Jul 31 07:32:18.774: INFO: namespace e2e-tests-dns-5l5fc deletion completed in 6.095316199s

• [SLOW TEST:45.401 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:32:18.774: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Jul 31 07:32:18.839: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 create -f - --namespace=e2e-tests-kubectl-j9z4x'
Jul 31 07:32:19.188: INFO: stderr: ""
Jul 31 07:32:19.188: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jul 31 07:32:19.188: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-j9z4x'
Jul 31 07:32:19.371: INFO: stderr: ""
Jul 31 07:32:19.371: INFO: stdout: "update-demo-nautilus-bd9s6 update-demo-nautilus-dkktn "
Jul 31 07:32:19.372: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 get pods update-demo-nautilus-bd9s6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-j9z4x'
Jul 31 07:32:19.514: INFO: stderr: ""
Jul 31 07:32:19.514: INFO: stdout: ""
Jul 31 07:32:19.514: INFO: update-demo-nautilus-bd9s6 is created but not running
Jul 31 07:32:24.514: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-j9z4x'
Jul 31 07:32:24.638: INFO: stderr: ""
Jul 31 07:32:24.638: INFO: stdout: "update-demo-nautilus-bd9s6 update-demo-nautilus-dkktn "
Jul 31 07:32:24.638: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 get pods update-demo-nautilus-bd9s6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-j9z4x'
Jul 31 07:32:24.736: INFO: stderr: ""
Jul 31 07:32:24.736: INFO: stdout: "true"
Jul 31 07:32:24.736: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 get pods update-demo-nautilus-bd9s6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-j9z4x'
Jul 31 07:32:24.850: INFO: stderr: ""
Jul 31 07:32:24.850: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jul 31 07:32:24.850: INFO: validating pod update-demo-nautilus-bd9s6
Jul 31 07:32:24.855: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 31 07:32:24.855: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 31 07:32:24.855: INFO: update-demo-nautilus-bd9s6 is verified up and running
Jul 31 07:32:24.855: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 get pods update-demo-nautilus-dkktn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-j9z4x'
Jul 31 07:32:24.992: INFO: stderr: ""
Jul 31 07:32:24.992: INFO: stdout: "true"
Jul 31 07:32:24.992: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 get pods update-demo-nautilus-dkktn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-j9z4x'
Jul 31 07:32:25.107: INFO: stderr: ""
Jul 31 07:32:25.107: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jul 31 07:32:25.107: INFO: validating pod update-demo-nautilus-dkktn
Jul 31 07:32:25.112: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 31 07:32:25.112: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 31 07:32:25.112: INFO: update-demo-nautilus-dkktn is verified up and running
STEP: rolling-update to new replication controller
Jul 31 07:32:25.114: INFO: scanned /root for discovery docs: <nil>
Jul 31 07:32:25.114: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-j9z4x'
Jul 31 07:32:50.576: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Jul 31 07:32:50.576: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jul 31 07:32:50.576: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-j9z4x'
Jul 31 07:32:50.719: INFO: stderr: ""
Jul 31 07:32:50.719: INFO: stdout: "update-demo-kitten-6lnq7 update-demo-kitten-gvpst "
Jul 31 07:32:50.719: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 get pods update-demo-kitten-6lnq7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-j9z4x'
Jul 31 07:32:50.883: INFO: stderr: ""
Jul 31 07:32:50.883: INFO: stdout: "true"
Jul 31 07:32:50.884: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 get pods update-demo-kitten-6lnq7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-j9z4x'
Jul 31 07:32:51.026: INFO: stderr: ""
Jul 31 07:32:51.026: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Jul 31 07:32:51.026: INFO: validating pod update-demo-kitten-6lnq7
Jul 31 07:32:51.030: INFO: got data: {
  "image": "kitten.jpg"
}

Jul 31 07:32:51.031: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Jul 31 07:32:51.031: INFO: update-demo-kitten-6lnq7 is verified up and running
Jul 31 07:32:51.031: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 get pods update-demo-kitten-gvpst -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-j9z4x'
Jul 31 07:32:51.133: INFO: stderr: ""
Jul 31 07:32:51.133: INFO: stdout: "true"
Jul 31 07:32:51.133: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-864115849 get pods update-demo-kitten-gvpst -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-j9z4x'
Jul 31 07:32:51.230: INFO: stderr: ""
Jul 31 07:32:51.230: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Jul 31 07:32:51.230: INFO: validating pod update-demo-kitten-gvpst
Jul 31 07:32:51.234: INFO: got data: {
  "image": "kitten.jpg"
}

Jul 31 07:32:51.234: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Jul 31 07:32:51.234: INFO: update-demo-kitten-gvpst is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:32:51.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-j9z4x" for this suite.
Jul 31 07:33:13.246: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:33:13.270: INFO: namespace: e2e-tests-kubectl-j9z4x, resource: bindings, ignored listing per whitelist
Jul 31 07:33:13.330: INFO: namespace e2e-tests-kubectl-j9z4x deletion completed in 22.092795953s

• [SLOW TEST:54.556 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:33:13.331: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Jul 31 07:33:13.901: INFO: Waiting up to 5m0s for pod "pod-service-account-747d8c53-b365-11e9-990e-fe448544ce72-xnxjb" in namespace "e2e-tests-svcaccounts-xxwsl" to be "success or failure"
Jul 31 07:33:13.903: INFO: Pod "pod-service-account-747d8c53-b365-11e9-990e-fe448544ce72-xnxjb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.590431ms
Jul 31 07:33:15.906: INFO: Pod "pod-service-account-747d8c53-b365-11e9-990e-fe448544ce72-xnxjb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005489234s
STEP: Saw pod success
Jul 31 07:33:15.906: INFO: Pod "pod-service-account-747d8c53-b365-11e9-990e-fe448544ce72-xnxjb" satisfied condition "success or failure"
Jul 31 07:33:15.909: INFO: Trying to get logs from node shushsha-k8s-worker2 pod pod-service-account-747d8c53-b365-11e9-990e-fe448544ce72-xnxjb container token-test: <nil>
STEP: delete the pod
Jul 31 07:33:15.925: INFO: Waiting for pod pod-service-account-747d8c53-b365-11e9-990e-fe448544ce72-xnxjb to disappear
Jul 31 07:33:15.927: INFO: Pod pod-service-account-747d8c53-b365-11e9-990e-fe448544ce72-xnxjb no longer exists
STEP: Creating a pod to test consume service account root CA
Jul 31 07:33:15.930: INFO: Waiting up to 5m0s for pod "pod-service-account-747d8c53-b365-11e9-990e-fe448544ce72-4cvgv" in namespace "e2e-tests-svcaccounts-xxwsl" to be "success or failure"
Jul 31 07:33:15.933: INFO: Pod "pod-service-account-747d8c53-b365-11e9-990e-fe448544ce72-4cvgv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.344386ms
Jul 31 07:33:17.936: INFO: Pod "pod-service-account-747d8c53-b365-11e9-990e-fe448544ce72-4cvgv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005622909s
STEP: Saw pod success
Jul 31 07:33:17.936: INFO: Pod "pod-service-account-747d8c53-b365-11e9-990e-fe448544ce72-4cvgv" satisfied condition "success or failure"
Jul 31 07:33:17.938: INFO: Trying to get logs from node shushsha-k8s-worker1 pod pod-service-account-747d8c53-b365-11e9-990e-fe448544ce72-4cvgv container root-ca-test: <nil>
STEP: delete the pod
Jul 31 07:33:17.953: INFO: Waiting for pod pod-service-account-747d8c53-b365-11e9-990e-fe448544ce72-4cvgv to disappear
Jul 31 07:33:17.955: INFO: Pod pod-service-account-747d8c53-b365-11e9-990e-fe448544ce72-4cvgv no longer exists
STEP: Creating a pod to test consume service account namespace
Jul 31 07:33:17.958: INFO: Waiting up to 5m0s for pod "pod-service-account-747d8c53-b365-11e9-990e-fe448544ce72-bzvjk" in namespace "e2e-tests-svcaccounts-xxwsl" to be "success or failure"
Jul 31 07:33:17.960: INFO: Pod "pod-service-account-747d8c53-b365-11e9-990e-fe448544ce72-bzvjk": Phase="Pending", Reason="", readiness=false. Elapsed: 2.257599ms
Jul 31 07:33:19.963: INFO: Pod "pod-service-account-747d8c53-b365-11e9-990e-fe448544ce72-bzvjk": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005373929s
Jul 31 07:33:21.967: INFO: Pod "pod-service-account-747d8c53-b365-11e9-990e-fe448544ce72-bzvjk": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008594758s
STEP: Saw pod success
Jul 31 07:33:21.967: INFO: Pod "pod-service-account-747d8c53-b365-11e9-990e-fe448544ce72-bzvjk" satisfied condition "success or failure"
Jul 31 07:33:21.969: INFO: Trying to get logs from node shushsha-k8s-worker2 pod pod-service-account-747d8c53-b365-11e9-990e-fe448544ce72-bzvjk container namespace-test: <nil>
STEP: delete the pod
Jul 31 07:33:21.984: INFO: Waiting for pod pod-service-account-747d8c53-b365-11e9-990e-fe448544ce72-bzvjk to disappear
Jul 31 07:33:21.986: INFO: Pod pod-service-account-747d8c53-b365-11e9-990e-fe448544ce72-bzvjk no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:33:21.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-xxwsl" for this suite.
Jul 31 07:33:27.997: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:33:28.119: INFO: namespace: e2e-tests-svcaccounts-xxwsl, resource: bindings, ignored listing per whitelist
Jul 31 07:33:28.127: INFO: namespace e2e-tests-svcaccounts-xxwsl deletion completed in 6.137712363s

• [SLOW TEST:14.796 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:33:28.127: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jul 31 07:33:28.210: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:33:28.214: INFO: Number of nodes with available pods: 0
Jul 31 07:33:28.214: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 07:33:29.218: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:33:29.220: INFO: Number of nodes with available pods: 0
Jul 31 07:33:29.220: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 07:33:30.218: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:33:30.221: INFO: Number of nodes with available pods: 1
Jul 31 07:33:30.221: INFO: Node shushsha-k8s-worker2 is running more than one daemon pod
Jul 31 07:33:31.218: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:33:31.221: INFO: Number of nodes with available pods: 2
Jul 31 07:33:31.221: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Jul 31 07:33:31.233: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:33:31.238: INFO: Number of nodes with available pods: 1
Jul 31 07:33:31.238: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 07:33:32.241: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:33:32.244: INFO: Number of nodes with available pods: 1
Jul 31 07:33:32.244: INFO: Node shushsha-k8s-worker1 is running more than one daemon pod
Jul 31 07:33:33.241: INFO: DaemonSet pods can't tolerate node shushsha-k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 31 07:33:33.244: INFO: Number of nodes with available pods: 2
Jul 31 07:33:33.244: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-9vc2v, will wait for the garbage collector to delete the pods
Jul 31 07:33:33.306: INFO: Deleting DaemonSet.extensions daemon-set took: 5.730315ms
Jul 31 07:33:33.406: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.259009ms
Jul 31 07:34:14.909: INFO: Number of nodes with available pods: 0
Jul 31 07:34:14.909: INFO: Number of running nodes: 0, number of available pods: 0
Jul 31 07:34:14.911: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-9vc2v/daemonsets","resourceVersion":"18743"},"items":null}

Jul 31 07:34:14.914: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-9vc2v/pods","resourceVersion":"18743"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:34:14.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-9vc2v" for this suite.
Jul 31 07:34:20.933: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:34:20.952: INFO: namespace: e2e-tests-daemonsets-9vc2v, resource: bindings, ignored listing per whitelist
Jul 31 07:34:21.009: INFO: namespace e2e-tests-daemonsets-9vc2v deletion completed in 6.084672139s

• [SLOW TEST:52.882 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:34:21.009: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jul 31 07:34:21.071: INFO: Creating ReplicaSet my-hostname-basic-9c879422-b365-11e9-990e-fe448544ce72
Jul 31 07:34:21.077: INFO: Pod name my-hostname-basic-9c879422-b365-11e9-990e-fe448544ce72: Found 0 pods out of 1
Jul 31 07:34:26.080: INFO: Pod name my-hostname-basic-9c879422-b365-11e9-990e-fe448544ce72: Found 1 pods out of 1
Jul 31 07:34:26.080: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-9c879422-b365-11e9-990e-fe448544ce72" is running
Jul 31 07:34:26.084: INFO: Pod "my-hostname-basic-9c879422-b365-11e9-990e-fe448544ce72-n2ksj" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-07-31 07:34:21 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-07-31 07:34:22 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-07-31 07:34:22 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-07-31 07:34:21 +0000 UTC Reason: Message:}])
Jul 31 07:34:26.084: INFO: Trying to dial the pod
Jul 31 07:34:31.093: INFO: Controller my-hostname-basic-9c879422-b365-11e9-990e-fe448544ce72: Got expected result from replica 1 [my-hostname-basic-9c879422-b365-11e9-990e-fe448544ce72-n2ksj]: "my-hostname-basic-9c879422-b365-11e9-990e-fe448544ce72-n2ksj", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:34:31.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-25qw5" for this suite.
Jul 31 07:34:37.105: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:34:37.135: INFO: namespace: e2e-tests-replicaset-25qw5, resource: bindings, ignored listing per whitelist
Jul 31 07:34:37.181: INFO: namespace e2e-tests-replicaset-25qw5 deletion completed in 6.085189747s

• [SLOW TEST:16.172 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:34:37.182: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jul 31 07:34:37.257: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
Jul 31 07:34:37.263: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-hfrwm/daemonsets","resourceVersion":"18836"},"items":null}

Jul 31 07:34:37.266: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-hfrwm/pods","resourceVersion":"18836"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:34:37.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-hfrwm" for this suite.
Jul 31 07:34:43.286: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:34:43.340: INFO: namespace: e2e-tests-daemonsets-hfrwm, resource: bindings, ignored listing per whitelist
Jul 31 07:34:43.374: INFO: namespace e2e-tests-daemonsets-hfrwm deletion completed in 6.095568127s

S [SKIPPING] [6.193 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Jul 31 07:34:37.257: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:34:43.375: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:34:43.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-fz865" for this suite.
Jul 31 07:35:05.457: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:35:05.514: INFO: namespace: e2e-tests-pods-fz865, resource: bindings, ignored listing per whitelist
Jul 31 07:35:05.533: INFO: namespace e2e-tests-pods-fz865 deletion completed in 22.084672256s

• [SLOW TEST:22.158 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:35:05.533: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Jul 31 07:35:05.601: INFO: Waiting up to 5m0s for pod "client-containers-b711c406-b365-11e9-990e-fe448544ce72" in namespace "e2e-tests-containers-f69xg" to be "success or failure"
Jul 31 07:35:05.604: INFO: Pod "client-containers-b711c406-b365-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.127339ms
Jul 31 07:35:07.607: INFO: Pod "client-containers-b711c406-b365-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005320038s
STEP: Saw pod success
Jul 31 07:35:07.607: INFO: Pod "client-containers-b711c406-b365-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 07:35:07.609: INFO: Trying to get logs from node shushsha-k8s-worker1 pod client-containers-b711c406-b365-11e9-990e-fe448544ce72 container test-container: <nil>
STEP: delete the pod
Jul 31 07:35:07.625: INFO: Waiting for pod client-containers-b711c406-b365-11e9-990e-fe448544ce72 to disappear
Jul 31 07:35:07.627: INFO: Pod client-containers-b711c406-b365-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:35:07.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-f69xg" for this suite.
Jul 31 07:35:13.638: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:35:13.679: INFO: namespace: e2e-tests-containers-f69xg, resource: bindings, ignored listing per whitelist
Jul 31 07:35:13.715: INFO: namespace e2e-tests-containers-f69xg deletion completed in 6.084689845s

• [SLOW TEST:8.182 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:35:13.716: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-2jrv
STEP: Creating a pod to test atomic-volume-subpath
Jul 31 07:35:13.788: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-2jrv" in namespace "e2e-tests-subpath-cjcmj" to be "success or failure"
Jul 31 07:35:13.791: INFO: Pod "pod-subpath-test-downwardapi-2jrv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.53432ms
Jul 31 07:35:15.794: INFO: Pod "pod-subpath-test-downwardapi-2jrv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006107149s
Jul 31 07:35:17.797: INFO: Pod "pod-subpath-test-downwardapi-2jrv": Phase="Running", Reason="", readiness=false. Elapsed: 4.009279379s
Jul 31 07:35:19.801: INFO: Pod "pod-subpath-test-downwardapi-2jrv": Phase="Running", Reason="", readiness=false. Elapsed: 6.012580938s
Jul 31 07:35:21.804: INFO: Pod "pod-subpath-test-downwardapi-2jrv": Phase="Running", Reason="", readiness=false. Elapsed: 8.015743288s
Jul 31 07:35:23.807: INFO: Pod "pod-subpath-test-downwardapi-2jrv": Phase="Running", Reason="", readiness=false. Elapsed: 10.019188421s
Jul 31 07:35:25.811: INFO: Pod "pod-subpath-test-downwardapi-2jrv": Phase="Running", Reason="", readiness=false. Elapsed: 12.022468948s
Jul 31 07:35:27.813: INFO: Pod "pod-subpath-test-downwardapi-2jrv": Phase="Running", Reason="", readiness=false. Elapsed: 14.025412038s
Jul 31 07:35:29.817: INFO: Pod "pod-subpath-test-downwardapi-2jrv": Phase="Running", Reason="", readiness=false. Elapsed: 16.02878243s
Jul 31 07:35:31.820: INFO: Pod "pod-subpath-test-downwardapi-2jrv": Phase="Running", Reason="", readiness=false. Elapsed: 18.031907697s
Jul 31 07:35:33.823: INFO: Pod "pod-subpath-test-downwardapi-2jrv": Phase="Running", Reason="", readiness=false. Elapsed: 20.034989876s
Jul 31 07:35:35.827: INFO: Pod "pod-subpath-test-downwardapi-2jrv": Phase="Running", Reason="", readiness=false. Elapsed: 22.038467772s
Jul 31 07:35:37.830: INFO: Pod "pod-subpath-test-downwardapi-2jrv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.04166581s
STEP: Saw pod success
Jul 31 07:35:37.830: INFO: Pod "pod-subpath-test-downwardapi-2jrv" satisfied condition "success or failure"
Jul 31 07:35:37.832: INFO: Trying to get logs from node shushsha-k8s-worker2 pod pod-subpath-test-downwardapi-2jrv container test-container-subpath-downwardapi-2jrv: <nil>
STEP: delete the pod
Jul 31 07:35:37.852: INFO: Waiting for pod pod-subpath-test-downwardapi-2jrv to disappear
Jul 31 07:35:37.856: INFO: Pod pod-subpath-test-downwardapi-2jrv no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-2jrv
Jul 31 07:35:37.856: INFO: Deleting pod "pod-subpath-test-downwardapi-2jrv" in namespace "e2e-tests-subpath-cjcmj"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:35:37.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-cjcmj" for this suite.
Jul 31 07:35:43.872: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:35:43.888: INFO: namespace: e2e-tests-subpath-cjcmj, resource: bindings, ignored listing per whitelist
Jul 31 07:35:43.950: INFO: namespace e2e-tests-subpath-cjcmj deletion completed in 6.087974111s

• [SLOW TEST:30.234 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:35:43.950: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-mz8nd
Jul 31 07:35:52.025: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-mz8nd
STEP: checking the pod's current state and verifying that restartCount is present
Jul 31 07:35:52.027: INFO: Initial restart count of pod liveness-http is 0
Jul 31 07:36:10.058: INFO: Restart count of pod e2e-tests-container-probe-mz8nd/liveness-http is now 1 (18.030414933s elapsed)
Jul 31 07:36:32.093: INFO: Restart count of pod e2e-tests-container-probe-mz8nd/liveness-http is now 2 (40.065717036s elapsed)
Jul 31 07:36:52.142: INFO: Restart count of pod e2e-tests-container-probe-mz8nd/liveness-http is now 3 (1m0.114840575s elapsed)
Jul 31 07:37:12.174: INFO: Restart count of pod e2e-tests-container-probe-mz8nd/liveness-http is now 4 (1m20.146590208s elapsed)
Jul 31 07:38:12.270: INFO: Restart count of pod e2e-tests-container-probe-mz8nd/liveness-http is now 5 (2m20.242250521s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:38:12.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-mz8nd" for this suite.
Jul 31 07:38:18.290: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:38:18.330: INFO: namespace: e2e-tests-container-probe-mz8nd, resource: bindings, ignored listing per whitelist
Jul 31 07:38:18.366: INFO: namespace e2e-tests-container-probe-mz8nd deletion completed in 6.085870454s

• [SLOW TEST:154.416 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:38:18.366: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-4ht8f
Jul 31 07:38:22.442: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-4ht8f
STEP: checking the pod's current state and verifying that restartCount is present
Jul 31 07:38:22.444: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:42:22.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-4ht8f" for this suite.
Jul 31 07:42:28.893: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:42:28.926: INFO: namespace: e2e-tests-container-probe-4ht8f, resource: bindings, ignored listing per whitelist
Jul 31 07:42:28.968: INFO: namespace e2e-tests-container-probe-4ht8f deletion completed in 6.082661813s

• [SLOW TEST:250.602 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:42:28.969: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-bf60a282-b366-11e9-990e-fe448544ce72
STEP: Creating a pod to test consume secrets
Jul 31 07:42:29.040: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-bf610353-b366-11e9-990e-fe448544ce72" in namespace "e2e-tests-projected-876hv" to be "success or failure"
Jul 31 07:42:29.042: INFO: Pod "pod-projected-secrets-bf610353-b366-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.742717ms
Jul 31 07:42:31.045: INFO: Pod "pod-projected-secrets-bf610353-b366-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005280007s
STEP: Saw pod success
Jul 31 07:42:31.045: INFO: Pod "pod-projected-secrets-bf610353-b366-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 07:42:31.047: INFO: Trying to get logs from node shushsha-k8s-worker1 pod pod-projected-secrets-bf610353-b366-11e9-990e-fe448544ce72 container secret-volume-test: <nil>
STEP: delete the pod
Jul 31 07:42:31.063: INFO: Waiting for pod pod-projected-secrets-bf610353-b366-11e9-990e-fe448544ce72 to disappear
Jul 31 07:42:31.065: INFO: Pod pod-projected-secrets-bf610353-b366-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:42:31.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-876hv" for this suite.
Jul 31 07:42:37.084: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:42:37.157: INFO: namespace: e2e-tests-projected-876hv, resource: bindings, ignored listing per whitelist
Jul 31 07:42:37.167: INFO: namespace e2e-tests-projected-876hv deletion completed in 6.098747219s

• [SLOW TEST:8.199 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:42:37.168: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-c443fddf-b366-11e9-990e-fe448544ce72
STEP: Creating configMap with name cm-test-opt-upd-c443fe57-b366-11e9-990e-fe448544ce72
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-c443fddf-b366-11e9-990e-fe448544ce72
STEP: Updating configmap cm-test-opt-upd-c443fe57-b366-11e9-990e-fe448544ce72
STEP: Creating configMap with name cm-test-opt-create-c443feb9-b366-11e9-990e-fe448544ce72
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:44:03.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-wfskc" for this suite.
Jul 31 07:44:25.825: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:44:25.835: INFO: namespace: e2e-tests-configmap-wfskc, resource: bindings, ignored listing per whitelist
Jul 31 07:44:25.907: INFO: namespace e2e-tests-configmap-wfskc deletion completed in 22.090843569s

• [SLOW TEST:108.739 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 31 07:44:25.907: INFO: >>> kubeConfig: /tmp/kubeconfig-864115849
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-05141f21-b367-11e9-990e-fe448544ce72
STEP: Creating a pod to test consume secrets
Jul 31 07:44:25.979: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-051495db-b367-11e9-990e-fe448544ce72" in namespace "e2e-tests-projected-9f882" to be "success or failure"
Jul 31 07:44:25.981: INFO: Pod "pod-projected-secrets-051495db-b367-11e9-990e-fe448544ce72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.361855ms
Jul 31 07:44:27.985: INFO: Pod "pod-projected-secrets-051495db-b367-11e9-990e-fe448544ce72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006391947s
STEP: Saw pod success
Jul 31 07:44:27.985: INFO: Pod "pod-projected-secrets-051495db-b367-11e9-990e-fe448544ce72" satisfied condition "success or failure"
Jul 31 07:44:27.988: INFO: Trying to get logs from node shushsha-k8s-worker1 pod pod-projected-secrets-051495db-b367-11e9-990e-fe448544ce72 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jul 31 07:44:28.002: INFO: Waiting for pod pod-projected-secrets-051495db-b367-11e9-990e-fe448544ce72 to disappear
Jul 31 07:44:28.004: INFO: Pod pod-projected-secrets-051495db-b367-11e9-990e-fe448544ce72 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 31 07:44:28.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9f882" for this suite.
Jul 31 07:44:34.016: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 31 07:44:34.051: INFO: namespace: e2e-tests-projected-9f882, resource: bindings, ignored listing per whitelist
Jul 31 07:44:34.094: INFO: namespace e2e-tests-projected-9f882 deletion completed in 6.086570237s

• [SLOW TEST:8.187 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSJul 31 07:44:34.094: INFO: Running AfterSuite actions on all nodes
Jul 31 07:44:34.094: INFO: Running AfterSuite actions on node 1
Jul 31 07:44:34.094: INFO: Skipping dumping logs from cluster

Ran 200 of 1946 Specs in 5751.203 seconds
SUCCESS! -- 200 Passed | 0 Failed | 0 Pending | 1746 Skipped PASS

Ginkgo ran 1 suite in 1h35m52.343722028s
Test Suite Passed
