I0903 15:21:05.061440      16 test_context.go:358] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-043111098
I0903 15:21:05.061602      16 e2e.go:224] Starting e2e run "715463bb-ce5e-11e9-a956-0a580af40009" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1567524063 - Will randomize all specs
Will run 201 of 1946 specs

Sep  3 15:21:05.434: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
Sep  3 15:21:05.439: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Sep  3 15:21:05.494: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Sep  3 15:21:05.609: INFO: 7 / 7 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Sep  3 15:21:05.609: INFO: expected 4 pod replicas in namespace 'kube-system', 4 are Running and Ready.
Sep  3 15:21:05.609: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Sep  3 15:21:05.640: INFO: 1 / 1 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds' (0 seconds elapsed)
Sep  3 15:21:05.640: INFO: 1 / 1 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Sep  3 15:21:05.640: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-gpu-device-plugin' (0 seconds elapsed)
Sep  3 15:21:05.640: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-gpu-device-plugin-1-8' (0 seconds elapsed)
Sep  3 15:21:05.640: INFO: e2e test version: v1.13.0
Sep  3 15:21:05.645: INFO: kube-apiserver version: v1.13.5-5+270f968ee96a91
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:21:05.645: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename gc
Sep  3 15:21:05.880: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  3 15:21:05.970: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"72c45658-ce5e-11e9-9b93-0a580aed0c4f", Controller:(*bool)(0xc00119590a), BlockOwnerDeletion:(*bool)(0xc00119590b)}}
Sep  3 15:21:06.001: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"72c261e3-ce5e-11e9-9b93-0a580aed0c4f", Controller:(*bool)(0xc000c3cfba), BlockOwnerDeletion:(*bool)(0xc000c3cfbb)}}
Sep  3 15:21:06.030: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"72c35bf5-ce5e-11e9-9b93-0a580aed0c4f", Controller:(*bool)(0xc001195b52), BlockOwnerDeletion:(*bool)(0xc001195b53)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:21:11.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-sq9kj" for this suite.
Sep  3 15:21:17.172: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:21:17.808: INFO: namespace: e2e-tests-gc-sq9kj, resource: bindings, ignored listing per whitelist
Sep  3 15:21:18.002: INFO: namespace e2e-tests-gc-sq9kj deletion completed in 6.902465389s

• [SLOW TEST:12.357 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:21:18.002: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Sep  3 15:21:18.133: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:21:24.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-xgbfj" for this suite.
Sep  3 15:21:30.641: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:21:31.300: INFO: namespace: e2e-tests-init-container-xgbfj, resource: bindings, ignored listing per whitelist
Sep  3 15:21:31.546: INFO: namespace e2e-tests-init-container-xgbfj deletion completed in 6.975704867s

• [SLOW TEST:13.543 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:21:31.547: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-mm2fs
I0903 15:21:31.919519      16 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-mm2fs, replica count: 1
I0903 15:21:32.969927      16 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0903 15:21:33.970202      16 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep  3 15:21:34.111: INFO: Created: latency-svc-8blmf
Sep  3 15:21:34.118: INFO: Got endpoints: latency-svc-8blmf [47.382439ms]
Sep  3 15:21:34.131: INFO: Created: latency-svc-f6g8t
Sep  3 15:21:34.138: INFO: Created: latency-svc-v9x4m
Sep  3 15:21:34.142: INFO: Got endpoints: latency-svc-f6g8t [23.971134ms]
Sep  3 15:21:34.144: INFO: Got endpoints: latency-svc-v9x4m [24.978691ms]
Sep  3 15:21:34.146: INFO: Created: latency-svc-htpvx
Sep  3 15:21:34.152: INFO: Got endpoints: latency-svc-htpvx [32.86204ms]
Sep  3 15:21:34.153: INFO: Created: latency-svc-4n565
Sep  3 15:21:34.159: INFO: Got endpoints: latency-svc-4n565 [40.086888ms]
Sep  3 15:21:34.163: INFO: Created: latency-svc-b8vhl
Sep  3 15:21:34.166: INFO: Got endpoints: latency-svc-b8vhl [46.80723ms]
Sep  3 15:21:34.167: INFO: Created: latency-svc-ltzz2
Sep  3 15:21:34.173: INFO: Got endpoints: latency-svc-ltzz2 [53.225797ms]
Sep  3 15:21:34.177: INFO: Created: latency-svc-nqd57
Sep  3 15:21:34.180: INFO: Got endpoints: latency-svc-nqd57 [60.122282ms]
Sep  3 15:21:34.181: INFO: Created: latency-svc-nmjsd
Sep  3 15:21:34.186: INFO: Got endpoints: latency-svc-nmjsd [66.571833ms]
Sep  3 15:21:34.191: INFO: Created: latency-svc-jdjf9
Sep  3 15:21:34.193: INFO: Got endpoints: latency-svc-jdjf9 [72.762175ms]
Sep  3 15:21:34.195: INFO: Created: latency-svc-j96bl
Sep  3 15:21:34.204: INFO: Created: latency-svc-b78zl
Sep  3 15:21:34.204: INFO: Got endpoints: latency-svc-j96bl [84.239756ms]
Sep  3 15:21:34.209: INFO: Created: latency-svc-4r6lr
Sep  3 15:21:34.209: INFO: Got endpoints: latency-svc-b78zl [89.26458ms]
Sep  3 15:21:34.232: INFO: Created: latency-svc-hgrjx
Sep  3 15:21:34.233: INFO: Created: latency-svc-d6zqx
Sep  3 15:21:34.235: INFO: Got endpoints: latency-svc-d6zqx [114.76037ms]
Sep  3 15:21:34.236: INFO: Got endpoints: latency-svc-4r6lr [116.211592ms]
Sep  3 15:21:34.238: INFO: Created: latency-svc-d5x9m
Sep  3 15:21:34.238: INFO: Got endpoints: latency-svc-d5x9m [118.230313ms]
Sep  3 15:21:34.240: INFO: Created: latency-svc-ds6qb
Sep  3 15:21:34.242: INFO: Got endpoints: latency-svc-ds6qb [99.568662ms]
Sep  3 15:21:34.243: INFO: Created: latency-svc-r7vp4
Sep  3 15:21:34.244: INFO: Got endpoints: latency-svc-hgrjx [123.914565ms]
Sep  3 15:21:34.248: INFO: Created: latency-svc-4wdhs
Sep  3 15:21:34.250: INFO: Got endpoints: latency-svc-r7vp4 [105.451538ms]
Sep  3 15:21:34.255: INFO: Got endpoints: latency-svc-4wdhs [103.129712ms]
Sep  3 15:21:34.256: INFO: Created: latency-svc-qtxmw
Sep  3 15:21:34.263: INFO: Created: latency-svc-lscdb
Sep  3 15:21:34.263: INFO: Got endpoints: latency-svc-qtxmw [103.223106ms]
Sep  3 15:21:34.268: INFO: Got endpoints: latency-svc-lscdb [101.730039ms]
Sep  3 15:21:34.271: INFO: Created: latency-svc-l7bk7
Sep  3 15:21:34.276: INFO: Got endpoints: latency-svc-l7bk7 [102.70034ms]
Sep  3 15:21:34.276: INFO: Created: latency-svc-llh7v
Sep  3 15:21:34.281: INFO: Got endpoints: latency-svc-llh7v [101.334253ms]
Sep  3 15:21:34.282: INFO: Created: latency-svc-8c26q
Sep  3 15:21:34.288: INFO: Got endpoints: latency-svc-8c26q [101.715068ms]
Sep  3 15:21:34.289: INFO: Created: latency-svc-fdqmb
Sep  3 15:21:34.295: INFO: Created: latency-svc-6tb2t
Sep  3 15:21:34.295: INFO: Got endpoints: latency-svc-fdqmb [102.9605ms]
Sep  3 15:21:34.301: INFO: Got endpoints: latency-svc-6tb2t [97.220123ms]
Sep  3 15:21:34.303: INFO: Created: latency-svc-p56s5
Sep  3 15:21:34.308: INFO: Got endpoints: latency-svc-p56s5 [99.170622ms]
Sep  3 15:21:34.312: INFO: Created: latency-svc-nvqwn
Sep  3 15:21:34.318: INFO: Got endpoints: latency-svc-nvqwn [83.084515ms]
Sep  3 15:21:34.318: INFO: Created: latency-svc-psn7q
Sep  3 15:21:34.326: INFO: Created: latency-svc-2lkfx
Sep  3 15:21:34.326: INFO: Got endpoints: latency-svc-psn7q [89.661178ms]
Sep  3 15:21:34.331: INFO: Got endpoints: latency-svc-2lkfx [92.130942ms]
Sep  3 15:21:34.332: INFO: Created: latency-svc-wdq5v
Sep  3 15:21:34.338: INFO: Created: latency-svc-9g7rk
Sep  3 15:21:34.338: INFO: Got endpoints: latency-svc-wdq5v [93.417266ms]
Sep  3 15:21:34.343: INFO: Got endpoints: latency-svc-9g7rk [101.372206ms]
Sep  3 15:21:34.345: INFO: Created: latency-svc-5c288
Sep  3 15:21:34.350: INFO: Got endpoints: latency-svc-5c288 [100.495164ms]
Sep  3 15:21:34.352: INFO: Created: latency-svc-2qgdv
Sep  3 15:21:34.357: INFO: Got endpoints: latency-svc-2qgdv [101.856389ms]
Sep  3 15:21:34.358: INFO: Created: latency-svc-gqfn8
Sep  3 15:21:34.364: INFO: Created: latency-svc-5c46m
Sep  3 15:21:34.367: INFO: Got endpoints: latency-svc-gqfn8 [104.274223ms]
Sep  3 15:21:34.370: INFO: Created: latency-svc-vwttx
Sep  3 15:21:34.377: INFO: Created: latency-svc-2tg64
Sep  3 15:21:34.385: INFO: Created: latency-svc-hvdkp
Sep  3 15:21:34.390: INFO: Created: latency-svc-58dft
Sep  3 15:21:34.396: INFO: Created: latency-svc-7qht2
Sep  3 15:21:34.403: INFO: Created: latency-svc-ddpbx
Sep  3 15:21:34.412: INFO: Created: latency-svc-4vzfb
Sep  3 15:21:34.417: INFO: Created: latency-svc-b644p
Sep  3 15:21:34.417: INFO: Got endpoints: latency-svc-5c46m [149.363991ms]
Sep  3 15:21:34.423: INFO: Created: latency-svc-7zhbd
Sep  3 15:21:34.430: INFO: Created: latency-svc-plw78
Sep  3 15:21:34.435: INFO: Created: latency-svc-vlfbd
Sep  3 15:21:34.442: INFO: Created: latency-svc-298g6
Sep  3 15:21:34.451: INFO: Created: latency-svc-5fccp
Sep  3 15:21:34.459: INFO: Created: latency-svc-w2wtl
Sep  3 15:21:34.464: INFO: Created: latency-svc-7dc4b
Sep  3 15:21:34.466: INFO: Got endpoints: latency-svc-vwttx [190.343889ms]
Sep  3 15:21:34.479: INFO: Created: latency-svc-5dsq4
Sep  3 15:21:34.516: INFO: Got endpoints: latency-svc-2tg64 [234.987745ms]
Sep  3 15:21:34.532: INFO: Created: latency-svc-gc42n
Sep  3 15:21:34.567: INFO: Got endpoints: latency-svc-hvdkp [278.681947ms]
Sep  3 15:21:34.581: INFO: Created: latency-svc-kpkhc
Sep  3 15:21:34.619: INFO: Got endpoints: latency-svc-58dft [323.260097ms]
Sep  3 15:21:34.632: INFO: Created: latency-svc-bc6f7
Sep  3 15:21:34.667: INFO: Got endpoints: latency-svc-7qht2 [365.654632ms]
Sep  3 15:21:34.681: INFO: Created: latency-svc-lmzx2
Sep  3 15:21:34.717: INFO: Got endpoints: latency-svc-ddpbx [408.513924ms]
Sep  3 15:21:34.730: INFO: Created: latency-svc-wpxcm
Sep  3 15:21:34.768: INFO: Got endpoints: latency-svc-4vzfb [449.802127ms]
Sep  3 15:21:34.783: INFO: Created: latency-svc-j9dqb
Sep  3 15:21:34.817: INFO: Got endpoints: latency-svc-b644p [490.97557ms]
Sep  3 15:21:34.847: INFO: Created: latency-svc-r5n7s
Sep  3 15:21:34.869: INFO: Got endpoints: latency-svc-7zhbd [537.377781ms]
Sep  3 15:21:34.882: INFO: Created: latency-svc-pm2x7
Sep  3 15:21:34.918: INFO: Got endpoints: latency-svc-plw78 [579.686349ms]
Sep  3 15:21:34.935: INFO: Created: latency-svc-f9qrs
Sep  3 15:21:34.967: INFO: Got endpoints: latency-svc-vlfbd [623.518143ms]
Sep  3 15:21:34.981: INFO: Created: latency-svc-mkq59
Sep  3 15:21:35.017: INFO: Got endpoints: latency-svc-298g6 [665.286907ms]
Sep  3 15:21:35.031: INFO: Created: latency-svc-l7dcz
Sep  3 15:21:35.067: INFO: Got endpoints: latency-svc-5fccp [710.412233ms]
Sep  3 15:21:35.082: INFO: Created: latency-svc-jl5l9
Sep  3 15:21:35.117: INFO: Got endpoints: latency-svc-w2wtl [749.456445ms]
Sep  3 15:21:35.132: INFO: Created: latency-svc-hmrk2
Sep  3 15:21:35.187: INFO: Got endpoints: latency-svc-7dc4b [769.624136ms]
Sep  3 15:21:35.201: INFO: Created: latency-svc-xmrzd
Sep  3 15:21:35.217: INFO: Got endpoints: latency-svc-5dsq4 [750.299439ms]
Sep  3 15:21:35.231: INFO: Created: latency-svc-k9bdt
Sep  3 15:21:35.267: INFO: Got endpoints: latency-svc-gc42n [750.388762ms]
Sep  3 15:21:35.282: INFO: Created: latency-svc-9jpbn
Sep  3 15:21:35.317: INFO: Got endpoints: latency-svc-kpkhc [749.437807ms]
Sep  3 15:21:35.330: INFO: Created: latency-svc-tc6wr
Sep  3 15:21:35.367: INFO: Got endpoints: latency-svc-bc6f7 [748.551268ms]
Sep  3 15:21:35.386: INFO: Created: latency-svc-zxpp7
Sep  3 15:21:35.417: INFO: Got endpoints: latency-svc-lmzx2 [749.99238ms]
Sep  3 15:21:35.446: INFO: Created: latency-svc-pb2wj
Sep  3 15:21:35.469: INFO: Got endpoints: latency-svc-wpxcm [751.493912ms]
Sep  3 15:21:35.482: INFO: Created: latency-svc-4787w
Sep  3 15:21:35.517: INFO: Got endpoints: latency-svc-j9dqb [747.206083ms]
Sep  3 15:21:35.531: INFO: Created: latency-svc-ctdf5
Sep  3 15:21:35.568: INFO: Got endpoints: latency-svc-r5n7s [750.472194ms]
Sep  3 15:21:35.583: INFO: Created: latency-svc-lpv94
Sep  3 15:21:35.617: INFO: Got endpoints: latency-svc-pm2x7 [748.26766ms]
Sep  3 15:21:35.631: INFO: Created: latency-svc-49ntp
Sep  3 15:21:35.667: INFO: Got endpoints: latency-svc-f9qrs [749.30454ms]
Sep  3 15:21:35.683: INFO: Created: latency-svc-dhhxd
Sep  3 15:21:35.717: INFO: Got endpoints: latency-svc-mkq59 [749.608683ms]
Sep  3 15:21:35.731: INFO: Created: latency-svc-8gccw
Sep  3 15:21:35.767: INFO: Got endpoints: latency-svc-l7dcz [750.66726ms]
Sep  3 15:21:35.781: INFO: Created: latency-svc-9ckgv
Sep  3 15:21:35.817: INFO: Got endpoints: latency-svc-jl5l9 [749.451782ms]
Sep  3 15:21:35.830: INFO: Created: latency-svc-sjxl8
Sep  3 15:21:35.867: INFO: Got endpoints: latency-svc-hmrk2 [749.566678ms]
Sep  3 15:21:35.880: INFO: Created: latency-svc-jw9tw
Sep  3 15:21:35.918: INFO: Got endpoints: latency-svc-xmrzd [730.344407ms]
Sep  3 15:21:35.930: INFO: Created: latency-svc-sjz2p
Sep  3 15:21:35.967: INFO: Got endpoints: latency-svc-k9bdt [749.928607ms]
Sep  3 15:21:35.980: INFO: Created: latency-svc-t4mwk
Sep  3 15:21:36.017: INFO: Got endpoints: latency-svc-9jpbn [749.449663ms]
Sep  3 15:21:36.032: INFO: Created: latency-svc-ksjrk
Sep  3 15:21:36.068: INFO: Got endpoints: latency-svc-tc6wr [750.949158ms]
Sep  3 15:21:36.082: INFO: Created: latency-svc-4wx77
Sep  3 15:21:36.117: INFO: Got endpoints: latency-svc-zxpp7 [749.480114ms]
Sep  3 15:21:36.131: INFO: Created: latency-svc-pkhcn
Sep  3 15:21:36.168: INFO: Got endpoints: latency-svc-pb2wj [750.584577ms]
Sep  3 15:21:36.183: INFO: Created: latency-svc-625sl
Sep  3 15:21:36.217: INFO: Got endpoints: latency-svc-4787w [748.27108ms]
Sep  3 15:21:36.230: INFO: Created: latency-svc-467s8
Sep  3 15:21:36.267: INFO: Got endpoints: latency-svc-ctdf5 [750.184796ms]
Sep  3 15:21:36.282: INFO: Created: latency-svc-vsjh5
Sep  3 15:21:36.317: INFO: Got endpoints: latency-svc-lpv94 [749.28477ms]
Sep  3 15:21:36.332: INFO: Created: latency-svc-tn6h8
Sep  3 15:21:36.367: INFO: Got endpoints: latency-svc-49ntp [749.607262ms]
Sep  3 15:21:36.382: INFO: Created: latency-svc-xr9sp
Sep  3 15:21:36.417: INFO: Got endpoints: latency-svc-dhhxd [749.24656ms]
Sep  3 15:21:36.432: INFO: Created: latency-svc-klxrf
Sep  3 15:21:36.468: INFO: Got endpoints: latency-svc-8gccw [751.002396ms]
Sep  3 15:21:36.481: INFO: Created: latency-svc-xlhjv
Sep  3 15:21:36.518: INFO: Got endpoints: latency-svc-9ckgv [750.966824ms]
Sep  3 15:21:36.532: INFO: Created: latency-svc-zx67b
Sep  3 15:21:36.569: INFO: Got endpoints: latency-svc-sjxl8 [751.494697ms]
Sep  3 15:21:36.583: INFO: Created: latency-svc-k56b4
Sep  3 15:21:36.617: INFO: Got endpoints: latency-svc-jw9tw [750.59046ms]
Sep  3 15:21:36.631: INFO: Created: latency-svc-hv5df
Sep  3 15:21:36.667: INFO: Got endpoints: latency-svc-sjz2p [749.841032ms]
Sep  3 15:21:36.683: INFO: Created: latency-svc-rvp8s
Sep  3 15:21:36.717: INFO: Got endpoints: latency-svc-t4mwk [749.757291ms]
Sep  3 15:21:36.730: INFO: Created: latency-svc-llq76
Sep  3 15:21:36.784: INFO: Got endpoints: latency-svc-ksjrk [766.718981ms]
Sep  3 15:21:36.802: INFO: Created: latency-svc-qnk4q
Sep  3 15:21:36.817: INFO: Got endpoints: latency-svc-4wx77 [749.307321ms]
Sep  3 15:21:36.831: INFO: Created: latency-svc-9rtfl
Sep  3 15:21:36.868: INFO: Got endpoints: latency-svc-pkhcn [751.019565ms]
Sep  3 15:21:36.882: INFO: Created: latency-svc-wsssx
Sep  3 15:21:36.917: INFO: Got endpoints: latency-svc-625sl [748.971809ms]
Sep  3 15:21:36.932: INFO: Created: latency-svc-qkhjw
Sep  3 15:21:36.967: INFO: Got endpoints: latency-svc-467s8 [750.12215ms]
Sep  3 15:21:36.981: INFO: Created: latency-svc-rww24
Sep  3 15:21:37.018: INFO: Got endpoints: latency-svc-vsjh5 [750.299472ms]
Sep  3 15:21:37.032: INFO: Created: latency-svc-pzffx
Sep  3 15:21:37.068: INFO: Got endpoints: latency-svc-tn6h8 [750.496043ms]
Sep  3 15:21:37.083: INFO: Created: latency-svc-tcfg6
Sep  3 15:21:37.118: INFO: Got endpoints: latency-svc-xr9sp [749.69981ms]
Sep  3 15:21:37.132: INFO: Created: latency-svc-rsq2q
Sep  3 15:21:37.168: INFO: Got endpoints: latency-svc-klxrf [750.653684ms]
Sep  3 15:21:37.181: INFO: Created: latency-svc-lj9lk
Sep  3 15:21:37.242: INFO: Got endpoints: latency-svc-xlhjv [773.565849ms]
Sep  3 15:21:37.256: INFO: Created: latency-svc-d2tps
Sep  3 15:21:37.269: INFO: Got endpoints: latency-svc-zx67b [750.447359ms]
Sep  3 15:21:37.282: INFO: Created: latency-svc-zshrp
Sep  3 15:21:37.317: INFO: Got endpoints: latency-svc-k56b4 [748.443307ms]
Sep  3 15:21:37.333: INFO: Created: latency-svc-ll85c
Sep  3 15:21:37.377: INFO: Got endpoints: latency-svc-hv5df [759.282216ms]
Sep  3 15:21:37.395: INFO: Created: latency-svc-ptzwg
Sep  3 15:21:37.417: INFO: Got endpoints: latency-svc-rvp8s [749.119715ms]
Sep  3 15:21:37.432: INFO: Created: latency-svc-mpgtr
Sep  3 15:21:37.468: INFO: Got endpoints: latency-svc-llq76 [750.812186ms]
Sep  3 15:21:37.491: INFO: Created: latency-svc-bzr6c
Sep  3 15:21:37.518: INFO: Got endpoints: latency-svc-qnk4q [733.030294ms]
Sep  3 15:21:37.531: INFO: Created: latency-svc-njwds
Sep  3 15:21:37.568: INFO: Got endpoints: latency-svc-9rtfl [750.475863ms]
Sep  3 15:21:37.583: INFO: Created: latency-svc-5vxnt
Sep  3 15:21:37.617: INFO: Got endpoints: latency-svc-wsssx [748.942236ms]
Sep  3 15:21:37.633: INFO: Created: latency-svc-t2prf
Sep  3 15:21:37.667: INFO: Got endpoints: latency-svc-qkhjw [749.593525ms]
Sep  3 15:21:37.683: INFO: Created: latency-svc-cfjxh
Sep  3 15:21:37.718: INFO: Got endpoints: latency-svc-rww24 [751.342413ms]
Sep  3 15:21:37.732: INFO: Created: latency-svc-hs5t9
Sep  3 15:21:37.770: INFO: Got endpoints: latency-svc-pzffx [752.126164ms]
Sep  3 15:21:37.785: INFO: Created: latency-svc-6ngqw
Sep  3 15:21:37.819: INFO: Got endpoints: latency-svc-tcfg6 [750.840703ms]
Sep  3 15:21:37.832: INFO: Created: latency-svc-hqf9l
Sep  3 15:21:37.868: INFO: Got endpoints: latency-svc-rsq2q [750.146959ms]
Sep  3 15:21:37.881: INFO: Created: latency-svc-hqxpm
Sep  3 15:21:37.917: INFO: Got endpoints: latency-svc-lj9lk [749.278812ms]
Sep  3 15:21:37.935: INFO: Created: latency-svc-r5zxr
Sep  3 15:21:37.968: INFO: Got endpoints: latency-svc-d2tps [725.978313ms]
Sep  3 15:21:37.992: INFO: Created: latency-svc-xkmms
Sep  3 15:21:38.017: INFO: Got endpoints: latency-svc-zshrp [747.671234ms]
Sep  3 15:21:38.032: INFO: Created: latency-svc-fgslv
Sep  3 15:21:38.067: INFO: Got endpoints: latency-svc-ll85c [749.2746ms]
Sep  3 15:21:38.081: INFO: Created: latency-svc-cll8g
Sep  3 15:21:38.117: INFO: Got endpoints: latency-svc-ptzwg [739.521575ms]
Sep  3 15:21:38.142: INFO: Created: latency-svc-l7flh
Sep  3 15:21:38.168: INFO: Got endpoints: latency-svc-mpgtr [750.953312ms]
Sep  3 15:21:38.182: INFO: Created: latency-svc-627pf
Sep  3 15:21:38.217: INFO: Got endpoints: latency-svc-bzr6c [748.903474ms]
Sep  3 15:21:38.231: INFO: Created: latency-svc-4drhg
Sep  3 15:21:38.268: INFO: Got endpoints: latency-svc-njwds [750.189372ms]
Sep  3 15:21:38.281: INFO: Created: latency-svc-lcdbc
Sep  3 15:21:38.317: INFO: Got endpoints: latency-svc-5vxnt [748.614446ms]
Sep  3 15:21:38.331: INFO: Created: latency-svc-w57st
Sep  3 15:21:38.367: INFO: Got endpoints: latency-svc-t2prf [749.456092ms]
Sep  3 15:21:38.381: INFO: Created: latency-svc-xld6l
Sep  3 15:21:38.417: INFO: Got endpoints: latency-svc-cfjxh [749.96179ms]
Sep  3 15:21:38.431: INFO: Created: latency-svc-xvkz4
Sep  3 15:21:38.467: INFO: Got endpoints: latency-svc-hs5t9 [748.981533ms]
Sep  3 15:21:38.481: INFO: Created: latency-svc-jb2sp
Sep  3 15:21:38.522: INFO: Got endpoints: latency-svc-6ngqw [752.131973ms]
Sep  3 15:21:38.535: INFO: Created: latency-svc-7v2jf
Sep  3 15:21:38.567: INFO: Got endpoints: latency-svc-hqf9l [747.891089ms]
Sep  3 15:21:38.580: INFO: Created: latency-svc-f5mnn
Sep  3 15:21:38.617: INFO: Got endpoints: latency-svc-hqxpm [749.25924ms]
Sep  3 15:21:38.631: INFO: Created: latency-svc-92vq9
Sep  3 15:21:38.668: INFO: Got endpoints: latency-svc-r5zxr [749.989816ms]
Sep  3 15:21:38.688: INFO: Created: latency-svc-sg6nv
Sep  3 15:21:38.717: INFO: Got endpoints: latency-svc-xkmms [749.23365ms]
Sep  3 15:21:38.733: INFO: Created: latency-svc-tplz9
Sep  3 15:21:38.767: INFO: Got endpoints: latency-svc-fgslv [749.969239ms]
Sep  3 15:21:38.781: INFO: Created: latency-svc-dxphk
Sep  3 15:21:38.817: INFO: Got endpoints: latency-svc-cll8g [749.320755ms]
Sep  3 15:21:38.832: INFO: Created: latency-svc-p7c4f
Sep  3 15:21:38.867: INFO: Got endpoints: latency-svc-l7flh [750.176346ms]
Sep  3 15:21:38.880: INFO: Created: latency-svc-n2lfc
Sep  3 15:21:38.917: INFO: Got endpoints: latency-svc-627pf [748.533354ms]
Sep  3 15:21:38.949: INFO: Created: latency-svc-xrmzz
Sep  3 15:21:38.967: INFO: Got endpoints: latency-svc-4drhg [750.117811ms]
Sep  3 15:21:38.982: INFO: Created: latency-svc-4ppwj
Sep  3 15:21:39.017: INFO: Got endpoints: latency-svc-lcdbc [749.526105ms]
Sep  3 15:21:39.031: INFO: Created: latency-svc-kjxjx
Sep  3 15:21:39.067: INFO: Got endpoints: latency-svc-w57st [750.078426ms]
Sep  3 15:21:39.081: INFO: Created: latency-svc-v5trn
Sep  3 15:21:39.117: INFO: Got endpoints: latency-svc-xld6l [750.405959ms]
Sep  3 15:21:39.131: INFO: Created: latency-svc-nz8cf
Sep  3 15:21:39.167: INFO: Got endpoints: latency-svc-xvkz4 [749.6549ms]
Sep  3 15:21:39.181: INFO: Created: latency-svc-ntph5
Sep  3 15:21:39.236: INFO: Got endpoints: latency-svc-jb2sp [768.688477ms]
Sep  3 15:21:39.251: INFO: Created: latency-svc-8w5p9
Sep  3 15:21:39.287: INFO: Got endpoints: latency-svc-7v2jf [765.031797ms]
Sep  3 15:21:39.300: INFO: Created: latency-svc-vhzt4
Sep  3 15:21:39.317: INFO: Got endpoints: latency-svc-f5mnn [749.878573ms]
Sep  3 15:21:39.330: INFO: Created: latency-svc-5fg5p
Sep  3 15:21:39.367: INFO: Got endpoints: latency-svc-92vq9 [749.902136ms]
Sep  3 15:21:39.380: INFO: Created: latency-svc-btbrn
Sep  3 15:21:39.417: INFO: Got endpoints: latency-svc-sg6nv [748.917788ms]
Sep  3 15:21:39.431: INFO: Created: latency-svc-qmspn
Sep  3 15:21:39.467: INFO: Got endpoints: latency-svc-tplz9 [749.707692ms]
Sep  3 15:21:39.481: INFO: Created: latency-svc-tr4z9
Sep  3 15:21:39.517: INFO: Got endpoints: latency-svc-dxphk [749.546427ms]
Sep  3 15:21:39.539: INFO: Created: latency-svc-t7nsj
Sep  3 15:21:39.567: INFO: Got endpoints: latency-svc-p7c4f [749.750362ms]
Sep  3 15:21:39.581: INFO: Created: latency-svc-ljrqq
Sep  3 15:21:39.618: INFO: Got endpoints: latency-svc-n2lfc [751.040546ms]
Sep  3 15:21:39.631: INFO: Created: latency-svc-7qqj6
Sep  3 15:21:39.670: INFO: Got endpoints: latency-svc-xrmzz [752.217248ms]
Sep  3 15:21:39.683: INFO: Created: latency-svc-6tx2j
Sep  3 15:21:39.717: INFO: Got endpoints: latency-svc-4ppwj [749.544096ms]
Sep  3 15:21:39.730: INFO: Created: latency-svc-g4cvr
Sep  3 15:21:39.767: INFO: Got endpoints: latency-svc-kjxjx [749.673699ms]
Sep  3 15:21:39.781: INFO: Created: latency-svc-gp6n8
Sep  3 15:21:39.818: INFO: Got endpoints: latency-svc-v5trn [750.306476ms]
Sep  3 15:21:39.837: INFO: Created: latency-svc-qbgcp
Sep  3 15:21:39.868: INFO: Got endpoints: latency-svc-nz8cf [750.014467ms]
Sep  3 15:21:39.883: INFO: Created: latency-svc-9pwbf
Sep  3 15:21:39.917: INFO: Got endpoints: latency-svc-ntph5 [749.583509ms]
Sep  3 15:21:39.930: INFO: Created: latency-svc-jx9vj
Sep  3 15:21:39.968: INFO: Got endpoints: latency-svc-8w5p9 [731.48437ms]
Sep  3 15:21:39.982: INFO: Created: latency-svc-nb8zr
Sep  3 15:21:40.017: INFO: Got endpoints: latency-svc-vhzt4 [730.032233ms]
Sep  3 15:21:40.030: INFO: Created: latency-svc-cwc7h
Sep  3 15:21:40.082: INFO: Got endpoints: latency-svc-5fg5p [765.06168ms]
Sep  3 15:21:40.096: INFO: Created: latency-svc-jfr6p
Sep  3 15:21:40.117: INFO: Got endpoints: latency-svc-btbrn [749.291081ms]
Sep  3 15:21:40.129: INFO: Created: latency-svc-fzsw8
Sep  3 15:21:40.166: INFO: Got endpoints: latency-svc-qmspn [749.017648ms]
Sep  3 15:21:40.179: INFO: Created: latency-svc-447gn
Sep  3 15:21:40.217: INFO: Got endpoints: latency-svc-tr4z9 [749.119109ms]
Sep  3 15:21:40.230: INFO: Created: latency-svc-s4gll
Sep  3 15:21:40.267: INFO: Got endpoints: latency-svc-t7nsj [750.132179ms]
Sep  3 15:21:40.282: INFO: Created: latency-svc-5b4jb
Sep  3 15:21:40.317: INFO: Got endpoints: latency-svc-ljrqq [749.525206ms]
Sep  3 15:21:40.330: INFO: Created: latency-svc-vcrlw
Sep  3 15:21:40.367: INFO: Got endpoints: latency-svc-7qqj6 [748.820749ms]
Sep  3 15:21:40.381: INFO: Created: latency-svc-lhqzw
Sep  3 15:21:40.417: INFO: Got endpoints: latency-svc-6tx2j [747.263666ms]
Sep  3 15:21:40.433: INFO: Created: latency-svc-87zb4
Sep  3 15:21:40.467: INFO: Got endpoints: latency-svc-g4cvr [749.731573ms]
Sep  3 15:21:40.482: INFO: Created: latency-svc-zhwpk
Sep  3 15:21:40.517: INFO: Got endpoints: latency-svc-gp6n8 [749.226712ms]
Sep  3 15:21:40.530: INFO: Created: latency-svc-nxnjz
Sep  3 15:21:40.567: INFO: Got endpoints: latency-svc-qbgcp [749.331629ms]
Sep  3 15:21:40.581: INFO: Created: latency-svc-8zm72
Sep  3 15:21:40.617: INFO: Got endpoints: latency-svc-9pwbf [749.447768ms]
Sep  3 15:21:40.633: INFO: Created: latency-svc-vb9l8
Sep  3 15:21:40.668: INFO: Got endpoints: latency-svc-jx9vj [750.728786ms]
Sep  3 15:21:40.681: INFO: Created: latency-svc-pbk5d
Sep  3 15:21:40.717: INFO: Got endpoints: latency-svc-nb8zr [748.678059ms]
Sep  3 15:21:40.731: INFO: Created: latency-svc-z692t
Sep  3 15:21:40.768: INFO: Got endpoints: latency-svc-cwc7h [750.524293ms]
Sep  3 15:21:40.781: INFO: Created: latency-svc-9vzvx
Sep  3 15:21:40.817: INFO: Got endpoints: latency-svc-jfr6p [734.52801ms]
Sep  3 15:21:40.830: INFO: Created: latency-svc-gsb4q
Sep  3 15:21:40.867: INFO: Got endpoints: latency-svc-fzsw8 [750.395666ms]
Sep  3 15:21:40.880: INFO: Created: latency-svc-kkn4l
Sep  3 15:21:40.917: INFO: Got endpoints: latency-svc-447gn [751.002435ms]
Sep  3 15:21:40.931: INFO: Created: latency-svc-5m9wb
Sep  3 15:21:40.967: INFO: Got endpoints: latency-svc-s4gll [750.600546ms]
Sep  3 15:21:40.996: INFO: Created: latency-svc-rrj2v
Sep  3 15:21:41.017: INFO: Got endpoints: latency-svc-5b4jb [749.475515ms]
Sep  3 15:21:41.030: INFO: Created: latency-svc-2chq2
Sep  3 15:21:41.067: INFO: Got endpoints: latency-svc-vcrlw [750.408104ms]
Sep  3 15:21:41.080: INFO: Created: latency-svc-vksbk
Sep  3 15:21:41.117: INFO: Got endpoints: latency-svc-lhqzw [750.04708ms]
Sep  3 15:21:41.131: INFO: Created: latency-svc-nqrgl
Sep  3 15:21:41.167: INFO: Got endpoints: latency-svc-87zb4 [750.410271ms]
Sep  3 15:21:41.180: INFO: Created: latency-svc-btxmj
Sep  3 15:21:41.217: INFO: Got endpoints: latency-svc-zhwpk [750.459576ms]
Sep  3 15:21:41.230: INFO: Created: latency-svc-475lj
Sep  3 15:21:41.285: INFO: Got endpoints: latency-svc-nxnjz [767.935349ms]
Sep  3 15:21:41.298: INFO: Created: latency-svc-5l9dn
Sep  3 15:21:41.339: INFO: Got endpoints: latency-svc-8zm72 [771.083399ms]
Sep  3 15:21:41.352: INFO: Created: latency-svc-hlsj7
Sep  3 15:21:41.367: INFO: Got endpoints: latency-svc-vb9l8 [748.864987ms]
Sep  3 15:21:41.380: INFO: Created: latency-svc-rqvp8
Sep  3 15:21:41.419: INFO: Got endpoints: latency-svc-pbk5d [751.148326ms]
Sep  3 15:21:41.432: INFO: Created: latency-svc-hc466
Sep  3 15:21:41.467: INFO: Got endpoints: latency-svc-z692t [749.565153ms]
Sep  3 15:21:41.479: INFO: Created: latency-svc-vp85c
Sep  3 15:21:41.517: INFO: Got endpoints: latency-svc-9vzvx [748.855602ms]
Sep  3 15:21:41.530: INFO: Created: latency-svc-ztsz5
Sep  3 15:21:41.567: INFO: Got endpoints: latency-svc-gsb4q [750.046938ms]
Sep  3 15:21:41.596: INFO: Created: latency-svc-s9rqp
Sep  3 15:21:41.617: INFO: Got endpoints: latency-svc-kkn4l [749.27079ms]
Sep  3 15:21:41.632: INFO: Created: latency-svc-525pb
Sep  3 15:21:41.667: INFO: Got endpoints: latency-svc-5m9wb [749.21168ms]
Sep  3 15:21:41.680: INFO: Created: latency-svc-7xh67
Sep  3 15:21:41.717: INFO: Got endpoints: latency-svc-rrj2v [749.60882ms]
Sep  3 15:21:41.730: INFO: Created: latency-svc-8rtct
Sep  3 15:21:41.767: INFO: Got endpoints: latency-svc-2chq2 [749.844968ms]
Sep  3 15:21:41.780: INFO: Created: latency-svc-jf2p7
Sep  3 15:21:41.817: INFO: Got endpoints: latency-svc-vksbk [749.905728ms]
Sep  3 15:21:41.830: INFO: Created: latency-svc-nf2lg
Sep  3 15:21:41.867: INFO: Got endpoints: latency-svc-nqrgl [749.879076ms]
Sep  3 15:21:41.880: INFO: Created: latency-svc-pvjw9
Sep  3 15:21:41.917: INFO: Got endpoints: latency-svc-btxmj [749.807161ms]
Sep  3 15:21:41.932: INFO: Created: latency-svc-zkknh
Sep  3 15:21:41.967: INFO: Got endpoints: latency-svc-475lj [749.591232ms]
Sep  3 15:21:42.020: INFO: Got endpoints: latency-svc-5l9dn [735.230172ms]
Sep  3 15:21:42.068: INFO: Got endpoints: latency-svc-hlsj7 [729.18322ms]
Sep  3 15:21:42.862: INFO: Got endpoints: latency-svc-rqvp8 [1.495113114s]
Sep  3 15:21:43.040: INFO: Got endpoints: latency-svc-ztsz5 [1.523585117s]
Sep  3 15:21:43.041: INFO: Got endpoints: latency-svc-s9rqp [1.473766379s]
Sep  3 15:21:43.041: INFO: Got endpoints: latency-svc-525pb [1.424332298s]
Sep  3 15:21:43.041: INFO: Got endpoints: latency-svc-hc466 [1.62189236s]
Sep  3 15:21:43.041: INFO: Got endpoints: latency-svc-vp85c [1.574445272s]
Sep  3 15:21:43.048: INFO: Got endpoints: latency-svc-8rtct [1.330566212s]
Sep  3 15:21:43.049: INFO: Got endpoints: latency-svc-7xh67 [1.382109327s]
Sep  3 15:21:43.049: INFO: Got endpoints: latency-svc-nf2lg [1.23131991s]
Sep  3 15:21:43.049: INFO: Got endpoints: latency-svc-jf2p7 [1.281926925s]
Sep  3 15:21:43.049: INFO: Got endpoints: latency-svc-pvjw9 [1.181835325s]
Sep  3 15:21:43.053: INFO: Got endpoints: latency-svc-zkknh [1.136068455s]
Sep  3 15:21:43.053: INFO: Latencies: [23.971134ms 24.978691ms 32.86204ms 40.086888ms 46.80723ms 53.225797ms 60.122282ms 66.571833ms 72.762175ms 83.084515ms 84.239756ms 89.26458ms 89.661178ms 92.130942ms 93.417266ms 97.220123ms 99.170622ms 99.568662ms 100.495164ms 101.334253ms 101.372206ms 101.715068ms 101.730039ms 101.856389ms 102.70034ms 102.9605ms 103.129712ms 103.223106ms 104.274223ms 105.451538ms 114.76037ms 116.211592ms 118.230313ms 123.914565ms 149.363991ms 190.343889ms 234.987745ms 278.681947ms 323.260097ms 365.654632ms 408.513924ms 449.802127ms 490.97557ms 537.377781ms 579.686349ms 623.518143ms 665.286907ms 710.412233ms 725.978313ms 729.18322ms 730.032233ms 730.344407ms 731.48437ms 733.030294ms 734.52801ms 735.230172ms 739.521575ms 747.206083ms 747.263666ms 747.671234ms 747.891089ms 748.26766ms 748.27108ms 748.443307ms 748.533354ms 748.551268ms 748.614446ms 748.678059ms 748.820749ms 748.855602ms 748.864987ms 748.903474ms 748.917788ms 748.942236ms 748.971809ms 748.981533ms 749.017648ms 749.119109ms 749.119715ms 749.21168ms 749.226712ms 749.23365ms 749.24656ms 749.25924ms 749.27079ms 749.2746ms 749.278812ms 749.28477ms 749.291081ms 749.30454ms 749.307321ms 749.320755ms 749.331629ms 749.437807ms 749.447768ms 749.449663ms 749.451782ms 749.456092ms 749.456445ms 749.475515ms 749.480114ms 749.525206ms 749.526105ms 749.544096ms 749.546427ms 749.565153ms 749.566678ms 749.583509ms 749.591232ms 749.593525ms 749.607262ms 749.608683ms 749.60882ms 749.6549ms 749.673699ms 749.69981ms 749.707692ms 749.731573ms 749.750362ms 749.757291ms 749.807161ms 749.841032ms 749.844968ms 749.878573ms 749.879076ms 749.902136ms 749.905728ms 749.928607ms 749.96179ms 749.969239ms 749.989816ms 749.99238ms 750.014467ms 750.046938ms 750.04708ms 750.078426ms 750.117811ms 750.12215ms 750.132179ms 750.146959ms 750.176346ms 750.184796ms 750.189372ms 750.299439ms 750.299472ms 750.306476ms 750.388762ms 750.395666ms 750.405959ms 750.408104ms 750.410271ms 750.447359ms 750.459576ms 750.472194ms 750.475863ms 750.496043ms 750.524293ms 750.584577ms 750.59046ms 750.600546ms 750.653684ms 750.66726ms 750.728786ms 750.812186ms 750.840703ms 750.949158ms 750.953312ms 750.966824ms 751.002396ms 751.002435ms 751.019565ms 751.040546ms 751.148326ms 751.342413ms 751.493912ms 751.494697ms 752.126164ms 752.131973ms 752.217248ms 759.282216ms 765.031797ms 765.06168ms 766.718981ms 767.935349ms 768.688477ms 769.624136ms 771.083399ms 773.565849ms 1.136068455s 1.181835325s 1.23131991s 1.281926925s 1.330566212s 1.382109327s 1.424332298s 1.473766379s 1.495113114s 1.523585117s 1.574445272s 1.62189236s]
Sep  3 15:21:43.053: INFO: 50 %ile: 749.480114ms
Sep  3 15:21:43.053: INFO: 90 %ile: 765.031797ms
Sep  3 15:21:43.053: INFO: 99 %ile: 1.574445272s
Sep  3 15:21:43.053: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:21:43.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-mm2fs" for this suite.
Sep  3 15:21:55.130: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:21:55.141: INFO: namespace: e2e-tests-svc-latency-mm2fs, resource: bindings, ignored listing per whitelist
Sep  3 15:21:56.002: INFO: namespace e2e-tests-svc-latency-mm2fs deletion completed in 12.93962647s

• [SLOW TEST:24.455 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:21:56.002: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Sep  3 15:21:56.165: INFO: Waiting up to 5m0s for pod "pod-90b210f9-ce5e-11e9-a956-0a580af40009" in namespace "e2e-tests-emptydir-r2xzg" to be "success or failure"
Sep  3 15:21:56.193: INFO: Pod "pod-90b210f9-ce5e-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 27.481898ms
Sep  3 15:21:58.199: INFO: Pod "pod-90b210f9-ce5e-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033623606s
Sep  3 15:22:00.211: INFO: Pod "pod-90b210f9-ce5e-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.046025519s
STEP: Saw pod success
Sep  3 15:22:00.211: INFO: Pod "pod-90b210f9-ce5e-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 15:22:00.216: INFO: Trying to get logs from node 10.0.10.2 pod pod-90b210f9-ce5e-11e9-a956-0a580af40009 container test-container: <nil>
STEP: delete the pod
Sep  3 15:22:00.383: INFO: Waiting for pod pod-90b210f9-ce5e-11e9-a956-0a580af40009 to disappear
Sep  3 15:22:00.413: INFO: Pod pod-90b210f9-ce5e-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:22:00.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-r2xzg" for this suite.
Sep  3 15:22:06.531: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:22:06.795: INFO: namespace: e2e-tests-emptydir-r2xzg, resource: bindings, ignored listing per whitelist
Sep  3 15:22:07.385: INFO: namespace e2e-tests-emptydir-r2xzg deletion completed in 6.966898339s

• [SLOW TEST:11.383 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:22:07.386: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Sep  3 15:22:07.555: INFO: Waiting up to 5m0s for pod "downwardapi-volume-977c1836-ce5e-11e9-a956-0a580af40009" in namespace "e2e-tests-downward-api-58wns" to be "success or failure"
Sep  3 15:22:07.580: INFO: Pod "downwardapi-volume-977c1836-ce5e-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 25.184395ms
Sep  3 15:22:09.587: INFO: Pod "downwardapi-volume-977c1836-ce5e-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031551044s
Sep  3 15:22:11.600: INFO: Pod "downwardapi-volume-977c1836-ce5e-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044523605s
STEP: Saw pod success
Sep  3 15:22:11.600: INFO: Pod "downwardapi-volume-977c1836-ce5e-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 15:22:11.605: INFO: Trying to get logs from node 10.0.10.2 pod downwardapi-volume-977c1836-ce5e-11e9-a956-0a580af40009 container client-container: <nil>
STEP: delete the pod
Sep  3 15:22:11.960: INFO: Waiting for pod downwardapi-volume-977c1836-ce5e-11e9-a956-0a580af40009 to disappear
Sep  3 15:22:11.984: INFO: Pod downwardapi-volume-977c1836-ce5e-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:22:11.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-58wns" for this suite.
Sep  3 15:22:18.059: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:22:18.071: INFO: namespace: e2e-tests-downward-api-58wns, resource: bindings, ignored listing per whitelist
Sep  3 15:22:18.921: INFO: namespace e2e-tests-downward-api-58wns deletion completed in 6.931084538s

• [SLOW TEST:11.536 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:22:18.921: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-l2x8k
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep  3 15:22:19.056: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep  3 15:22:43.229: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.244.0.14 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-l2x8k PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  3 15:22:43.229: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
Sep  3 15:22:44.489: INFO: Found all expected endpoints: [netserver-0]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:22:44.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-l2x8k" for this suite.
Sep  3 15:23:08.569: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:23:08.618: INFO: namespace: e2e-tests-pod-network-test-l2x8k, resource: bindings, ignored listing per whitelist
Sep  3 15:23:09.424: INFO: namespace e2e-tests-pod-network-test-l2x8k deletion completed in 24.929436248s

• [SLOW TEST:50.503 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:23:09.424: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Sep  3 15:23:11.719: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:23:31.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-dtm2w" for this suite.
Sep  3 15:23:37.936: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:23:37.974: INFO: namespace: e2e-tests-namespaces-dtm2w, resource: bindings, ignored listing per whitelist
Sep  3 15:23:38.860: INFO: namespace e2e-tests-namespaces-dtm2w deletion completed in 6.986954065s
STEP: Destroying namespace "e2e-tests-nsdeletetest-bwppz" for this suite.
Sep  3 15:23:38.865: INFO: Namespace e2e-tests-nsdeletetest-bwppz was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-mjnnr" for this suite.
Sep  3 15:23:44.930: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:23:45.525: INFO: namespace: e2e-tests-nsdeletetest-mjnnr, resource: bindings, ignored listing per whitelist
Sep  3 15:23:45.882: INFO: namespace e2e-tests-nsdeletetest-mjnnr deletion completed in 7.016479181s

• [SLOW TEST:36.458 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:23:45.882: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-7n8v9
Sep  3 15:23:50.138: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-7n8v9
STEP: checking the pod's current state and verifying that restartCount is present
Sep  3 15:23:50.145: INFO: Initial restart count of pod liveness-http is 0
Sep  3 15:24:04.215: INFO: Restart count of pod e2e-tests-container-probe-7n8v9/liveness-http is now 1 (14.06987939s elapsed)
Sep  3 15:24:24.291: INFO: Restart count of pod e2e-tests-container-probe-7n8v9/liveness-http is now 2 (34.146138605s elapsed)
Sep  3 15:24:42.362: INFO: Restart count of pod e2e-tests-container-probe-7n8v9/liveness-http is now 3 (52.216866522s elapsed)
Sep  3 15:25:02.436: INFO: Restart count of pod e2e-tests-container-probe-7n8v9/liveness-http is now 4 (1m12.291075218s elapsed)
Sep  3 15:26:14.711: INFO: Restart count of pod e2e-tests-container-probe-7n8v9/liveness-http is now 5 (2m24.566569114s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:26:14.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-7n8v9" for this suite.
Sep  3 15:26:20.859: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:26:21.615: INFO: namespace: e2e-tests-container-probe-7n8v9, resource: bindings, ignored listing per whitelist
Sep  3 15:26:21.779: INFO: namespace e2e-tests-container-probe-7n8v9 deletion completed in 6.99437242s

• [SLOW TEST:155.897 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:26:21.780: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Sep  3 15:26:22.014: INFO: Waiting up to 5m0s for pod "pod-2f276028-ce5f-11e9-a956-0a580af40009" in namespace "e2e-tests-emptydir-mkqst" to be "success or failure"
Sep  3 15:26:22.044: INFO: Pod "pod-2f276028-ce5f-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 29.430875ms
Sep  3 15:26:24.057: INFO: Pod "pod-2f276028-ce5f-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.042617585s
STEP: Saw pod success
Sep  3 15:26:24.057: INFO: Pod "pod-2f276028-ce5f-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 15:26:24.062: INFO: Trying to get logs from node 10.0.10.2 pod pod-2f276028-ce5f-11e9-a956-0a580af40009 container test-container: <nil>
STEP: delete the pod
Sep  3 15:26:24.133: INFO: Waiting for pod pod-2f276028-ce5f-11e9-a956-0a580af40009 to disappear
Sep  3 15:26:24.158: INFO: Pod pod-2f276028-ce5f-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:26:24.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-mkqst" for this suite.
Sep  3 15:26:30.224: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:26:30.590: INFO: namespace: e2e-tests-emptydir-mkqst, resource: bindings, ignored listing per whitelist
Sep  3 15:26:31.262: INFO: namespace e2e-tests-emptydir-mkqst deletion completed in 7.097970311s

• [SLOW TEST:9.482 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:26:31.262: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:27:31.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-85csw" for this suite.
Sep  3 15:27:55.505: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:27:55.984: INFO: namespace: e2e-tests-container-probe-85csw, resource: bindings, ignored listing per whitelist
Sep  3 15:27:56.412: INFO: namespace e2e-tests-container-probe-85csw deletion completed in 24.981441077s

• [SLOW TEST:85.150 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:27:56.412: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Sep  3 15:27:57.124: INFO: Waiting up to 5m0s for pod "downward-api-67d82046-ce5f-11e9-a956-0a580af40009" in namespace "e2e-tests-downward-api-28l8l" to be "success or failure"
Sep  3 15:27:57.149: INFO: Pod "downward-api-67d82046-ce5f-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 25.47485ms
Sep  3 15:27:59.162: INFO: Pod "downward-api-67d82046-ce5f-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.038217243s
STEP: Saw pod success
Sep  3 15:27:59.162: INFO: Pod "downward-api-67d82046-ce5f-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 15:27:59.167: INFO: Trying to get logs from node 10.0.10.2 pod downward-api-67d82046-ce5f-11e9-a956-0a580af40009 container dapi-container: <nil>
STEP: delete the pod
Sep  3 15:27:59.243: INFO: Waiting for pod downward-api-67d82046-ce5f-11e9-a956-0a580af40009 to disappear
Sep  3 15:27:59.268: INFO: Pod downward-api-67d82046-ce5f-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:27:59.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-28l8l" for this suite.
Sep  3 15:28:05.333: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:28:06.118: INFO: namespace: e2e-tests-downward-api-28l8l, resource: bindings, ignored listing per whitelist
Sep  3 15:28:06.255: INFO: namespace e2e-tests-downward-api-28l8l deletion completed in 6.98093151s

• [SLOW TEST:9.842 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:28:06.255: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Sep  3 15:28:06.449: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-f9fgj" to be "success or failure"
Sep  3 15:28:06.476: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 26.778354ms
Sep  3 15:28:08.481: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032608786s
Sep  3 15:28:10.517: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.068346563s
STEP: Saw pod success
Sep  3 15:28:10.517: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Sep  3 15:28:10.524: INFO: Trying to get logs from node 10.0.10.2 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Sep  3 15:28:10.600: INFO: Waiting for pod pod-host-path-test to disappear
Sep  3 15:28:10.626: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:28:10.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-f9fgj" for this suite.
Sep  3 15:28:16.741: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:28:17.397: INFO: namespace: e2e-tests-hostpath-f9fgj, resource: bindings, ignored listing per whitelist
Sep  3 15:28:17.844: INFO: namespace e2e-tests-hostpath-f9fgj deletion completed in 7.212404759s

• [SLOW TEST:11.589 seconds]
[sig-storage] HostPath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:28:17.844: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-9pmq2
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-9pmq2 to expose endpoints map[]
Sep  3 15:28:18.036: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-9pmq2 exposes endpoints map[] (25.913382ms elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-9pmq2
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-9pmq2 to expose endpoints map[pod1:[100]]
Sep  3 15:28:20.127: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-9pmq2 exposes endpoints map[pod1:[100]] (2.05731885s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-9pmq2
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-9pmq2 to expose endpoints map[pod1:[100] pod2:[101]]
Sep  3 15:28:21.201: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-9pmq2 exposes endpoints map[pod1:[100] pod2:[101]] (1.06706132s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-9pmq2
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-9pmq2 to expose endpoints map[pod2:[101]]
Sep  3 15:28:22.255: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-9pmq2 exposes endpoints map[pod2:[101]] (1.022662649s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-9pmq2
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-9pmq2 to expose endpoints map[]
Sep  3 15:28:23.301: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-9pmq2 exposes endpoints map[] (1.013055727s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:28:23.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-9pmq2" for this suite.
Sep  3 15:28:47.441: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:28:48.145: INFO: namespace: e2e-tests-services-9pmq2, resource: bindings, ignored listing per whitelist
Sep  3 15:28:48.357: INFO: namespace e2e-tests-services-9pmq2 deletion completed in 24.983326711s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:30.513 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:28:48.357: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Sep  3 15:28:54.776: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep  3 15:28:54.807: INFO: Pod pod-with-poststart-http-hook still exists
Sep  3 15:28:56.807: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep  3 15:28:56.813: INFO: Pod pod-with-poststart-http-hook still exists
Sep  3 15:28:58.807: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep  3 15:28:58.813: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:28:58.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-hwff8" for this suite.
Sep  3 15:29:20.875: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:29:21.376: INFO: namespace: e2e-tests-container-lifecycle-hook-hwff8, resource: bindings, ignored listing per whitelist
Sep  3 15:29:21.716: INFO: namespace e2e-tests-container-lifecycle-hook-hwff8 deletion completed in 22.898008387s

• [SLOW TEST:33.359 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:29:21.717: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0903 15:30:02.014844      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep  3 15:30:02.014: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:30:02.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-7jjzn" for this suite.
Sep  3 15:30:10.093: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:30:10.496: INFO: namespace: e2e-tests-gc-7jjzn, resource: bindings, ignored listing per whitelist
Sep  3 15:30:10.923: INFO: namespace e2e-tests-gc-7jjzn deletion completed in 8.901605257s

• [SLOW TEST:49.206 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:30:10.923: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: Gathering metrics
W0903 15:30:11.200709      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep  3 15:30:11.200: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:30:11.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-fqp2h" for this suite.
Sep  3 15:30:17.263: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:30:17.650: INFO: namespace: e2e-tests-gc-fqp2h, resource: bindings, ignored listing per whitelist
Sep  3 15:30:18.201: INFO: namespace e2e-tests-gc-fqp2h deletion completed in 6.995421766s

• [SLOW TEST:7.278 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:30:18.201: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Sep  3 15:30:18.397: INFO: Waiting up to 5m0s for pod "client-containers-bc0c9c86-ce5f-11e9-a956-0a580af40009" in namespace "e2e-tests-containers-g2hwt" to be "success or failure"
Sep  3 15:30:18.421: INFO: Pod "client-containers-bc0c9c86-ce5f-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 23.550511ms
Sep  3 15:30:20.427: INFO: Pod "client-containers-bc0c9c86-ce5f-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029631124s
Sep  3 15:30:22.433: INFO: Pod "client-containers-bc0c9c86-ce5f-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035723522s
STEP: Saw pod success
Sep  3 15:30:22.433: INFO: Pod "client-containers-bc0c9c86-ce5f-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 15:30:22.438: INFO: Trying to get logs from node 10.0.10.2 pod client-containers-bc0c9c86-ce5f-11e9-a956-0a580af40009 container test-container: <nil>
STEP: delete the pod
Sep  3 15:30:22.513: INFO: Waiting for pod client-containers-bc0c9c86-ce5f-11e9-a956-0a580af40009 to disappear
Sep  3 15:30:22.538: INFO: Pod client-containers-bc0c9c86-ce5f-11e9-a956-0a580af40009 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:30:22.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-g2hwt" for this suite.
Sep  3 15:30:28.606: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:30:28.922: INFO: namespace: e2e-tests-containers-g2hwt, resource: bindings, ignored listing per whitelist
Sep  3 15:30:29.536: INFO: namespace e2e-tests-containers-g2hwt deletion completed in 6.991929117s

• [SLOW TEST:11.335 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:30:29.537: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  3 15:30:33.806: INFO: Waiting up to 5m0s for pod "client-envvars-c53f9296-ce5f-11e9-a956-0a580af40009" in namespace "e2e-tests-pods-z4dt8" to be "success or failure"
Sep  3 15:30:33.842: INFO: Pod "client-envvars-c53f9296-ce5f-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 35.668416ms
Sep  3 15:30:35.855: INFO: Pod "client-envvars-c53f9296-ce5f-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.048444995s
STEP: Saw pod success
Sep  3 15:30:35.855: INFO: Pod "client-envvars-c53f9296-ce5f-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 15:30:35.860: INFO: Trying to get logs from node 10.0.10.2 pod client-envvars-c53f9296-ce5f-11e9-a956-0a580af40009 container env3cont: <nil>
STEP: delete the pod
Sep  3 15:30:35.990: INFO: Waiting for pod client-envvars-c53f9296-ce5f-11e9-a956-0a580af40009 to disappear
Sep  3 15:30:36.029: INFO: Pod client-envvars-c53f9296-ce5f-11e9-a956-0a580af40009 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:30:36.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-z4dt8" for this suite.
Sep  3 15:31:22.113: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:31:22.253: INFO: namespace: e2e-tests-pods-z4dt8, resource: bindings, ignored listing per whitelist
Sep  3 15:31:22.927: INFO: namespace e2e-tests-pods-z4dt8 deletion completed in 46.891618806s

• [SLOW TEST:53.390 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:31:22.928: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-e29eda46-ce5f-11e9-a956-0a580af40009
STEP: Creating a pod to test consume secrets
Sep  3 15:31:23.133: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e2a2ad96-ce5f-11e9-a956-0a580af40009" in namespace "e2e-tests-projected-wzp7c" to be "success or failure"
Sep  3 15:31:23.160: INFO: Pod "pod-projected-secrets-e2a2ad96-ce5f-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 26.654048ms
Sep  3 15:31:25.166: INFO: Pod "pod-projected-secrets-e2a2ad96-ce5f-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.032560339s
STEP: Saw pod success
Sep  3 15:31:25.166: INFO: Pod "pod-projected-secrets-e2a2ad96-ce5f-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 15:31:25.171: INFO: Trying to get logs from node 10.0.10.2 pod pod-projected-secrets-e2a2ad96-ce5f-11e9-a956-0a580af40009 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep  3 15:31:25.283: INFO: Waiting for pod pod-projected-secrets-e2a2ad96-ce5f-11e9-a956-0a580af40009 to disappear
Sep  3 15:31:25.307: INFO: Pod pod-projected-secrets-e2a2ad96-ce5f-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:31:25.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wzp7c" for this suite.
Sep  3 15:31:31.402: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:31:32.181: INFO: namespace: e2e-tests-projected-wzp7c, resource: bindings, ignored listing per whitelist
Sep  3 15:31:32.255: INFO: namespace e2e-tests-projected-wzp7c deletion completed in 6.91809886s

• [SLOW TEST:9.327 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:31:32.256: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-e82add8b-ce5f-11e9-a956-0a580af40009
STEP: Creating a pod to test consume secrets
Sep  3 15:31:32.442: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e82ec790-ce5f-11e9-a956-0a580af40009" in namespace "e2e-tests-projected-7z78f" to be "success or failure"
Sep  3 15:31:32.468: INFO: Pod "pod-projected-secrets-e82ec790-ce5f-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 25.987378ms
Sep  3 15:31:34.475: INFO: Pod "pod-projected-secrets-e82ec790-ce5f-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.032436651s
STEP: Saw pod success
Sep  3 15:31:34.475: INFO: Pod "pod-projected-secrets-e82ec790-ce5f-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 15:31:34.481: INFO: Trying to get logs from node 10.0.10.2 pod pod-projected-secrets-e82ec790-ce5f-11e9-a956-0a580af40009 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep  3 15:31:34.559: INFO: Waiting for pod pod-projected-secrets-e82ec790-ce5f-11e9-a956-0a580af40009 to disappear
Sep  3 15:31:34.584: INFO: Pod pod-projected-secrets-e82ec790-ce5f-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:31:34.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7z78f" for this suite.
Sep  3 15:31:40.649: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:31:41.261: INFO: namespace: e2e-tests-projected-7z78f, resource: bindings, ignored listing per whitelist
Sep  3 15:31:41.501: INFO: namespace e2e-tests-projected-7z78f deletion completed in 6.911256912s

• [SLOW TEST:9.245 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:31:41.501: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  3 15:31:41.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 version'
Sep  3 15:31:41.736: INFO: stderr: ""
Sep  3 15:31:41.736: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"13+\", GitVersion:\"v1.13.5-5+270f968ee96a91\", GitCommit:\"270f968ee96a9166c3dee050b3f45d213e49a1d5\", GitTreeState:\"clean\", BuildDate:\"2019-07-25T04:08:14Z\", GoVersion:\"go1.11.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:31:41.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-z6wdv" for this suite.
Sep  3 15:31:47.812: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:31:48.041: INFO: namespace: e2e-tests-kubectl-z6wdv, resource: bindings, ignored listing per whitelist
Sep  3 15:31:48.723: INFO: namespace e2e-tests-kubectl-z6wdv deletion completed in 6.980084427s

• [SLOW TEST:7.222 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:31:48.723: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Sep  3 15:31:55.007: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep  3 15:31:55.041: INFO: Pod pod-with-prestop-http-hook still exists
Sep  3 15:31:57.041: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep  3 15:31:57.047: INFO: Pod pod-with-prestop-http-hook still exists
Sep  3 15:31:59.041: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep  3 15:31:59.048: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:31:59.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-xwdqj" for this suite.
Sep  3 15:32:21.158: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:32:21.767: INFO: namespace: e2e-tests-container-lifecycle-hook-xwdqj, resource: bindings, ignored listing per whitelist
Sep  3 15:32:22.073: INFO: namespace e2e-tests-container-lifecycle-hook-xwdqj deletion completed in 22.978986072s

• [SLOW TEST:33.350 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:32:22.074: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Sep  3 15:32:22.204: INFO: PodSpec: initContainers in spec.initContainers
Sep  3 15:33:08.110: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-05dccb1b-ce60-11e9-a956-0a580af40009", GenerateName:"", Namespace:"e2e-tests-init-container-hdz2d", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-hdz2d/pods/pod-init-05dccb1b-ce60-11e9-a956-0a580af40009", UID:"05e09a38-ce60-11e9-9b93-0a580aed0c4f", ResourceVersion:"616363", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63703121542, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"204911653"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-7s78f", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001005140), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-7s78f", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-7s78f", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}, "cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-7s78f", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc000c14b18), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10.0.10.2", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001595b00), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc000c14bb0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc000c14bd0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc000c14bd8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc000c14bdc)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703121542, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703121542, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703121542, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703121542, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.0.10.2", PodIP:"10.244.0.44", StartTime:(*v1.Time)(0xc000f71ce0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00035f260)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00035f2d0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://8f2c806eab576e800085e629706e2f40ab026569d0919bca3c3c1837cc3fb24d"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc000f71d20), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc000f71d00), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:33:08.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-hdz2d" for this suite.
Sep  3 15:33:32.189: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:33:32.488: INFO: namespace: e2e-tests-init-container-hdz2d, resource: bindings, ignored listing per whitelist
Sep  3 15:33:33.187: INFO: namespace e2e-tests-init-container-hdz2d deletion completed in 25.06286988s

• [SLOW TEST:71.113 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:33:33.187: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-304063c7-ce60-11e9-a956-0a580af40009
STEP: Creating a pod to test consume configMaps
Sep  3 15:33:33.386: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-3044c77d-ce60-11e9-a956-0a580af40009" in namespace "e2e-tests-projected-fgm5z" to be "success or failure"
Sep  3 15:33:33.413: INFO: Pod "pod-projected-configmaps-3044c77d-ce60-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 26.136156ms
Sep  3 15:33:35.419: INFO: Pod "pod-projected-configmaps-3044c77d-ce60-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.03258951s
STEP: Saw pod success
Sep  3 15:33:35.419: INFO: Pod "pod-projected-configmaps-3044c77d-ce60-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 15:33:35.424: INFO: Trying to get logs from node 10.0.10.2 pod pod-projected-configmaps-3044c77d-ce60-11e9-a956-0a580af40009 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  3 15:33:35.501: INFO: Waiting for pod pod-projected-configmaps-3044c77d-ce60-11e9-a956-0a580af40009 to disappear
Sep  3 15:33:35.528: INFO: Pod pod-projected-configmaps-3044c77d-ce60-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:33:35.529: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fgm5z" for this suite.
Sep  3 15:33:41.607: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:33:41.907: INFO: namespace: e2e-tests-projected-fgm5z, resource: bindings, ignored listing per whitelist
Sep  3 15:33:42.559: INFO: namespace e2e-tests-projected-fgm5z deletion completed in 7.025881479s

• [SLOW TEST:9.373 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:33:42.560: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Sep  3 15:33:42.738: INFO: Waiting up to 5m0s for pod "var-expansion-35d86afb-ce60-11e9-a956-0a580af40009" in namespace "e2e-tests-var-expansion-ldk6w" to be "success or failure"
Sep  3 15:33:42.767: INFO: Pod "var-expansion-35d86afb-ce60-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 28.790613ms
Sep  3 15:33:44.773: INFO: Pod "var-expansion-35d86afb-ce60-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.034964942s
STEP: Saw pod success
Sep  3 15:33:44.773: INFO: Pod "var-expansion-35d86afb-ce60-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 15:33:44.779: INFO: Trying to get logs from node 10.0.10.2 pod var-expansion-35d86afb-ce60-11e9-a956-0a580af40009 container dapi-container: <nil>
STEP: delete the pod
Sep  3 15:33:44.852: INFO: Waiting for pod var-expansion-35d86afb-ce60-11e9-a956-0a580af40009 to disappear
Sep  3 15:33:44.887: INFO: Pod var-expansion-35d86afb-ce60-11e9-a956-0a580af40009 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:33:44.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-ldk6w" for this suite.
Sep  3 15:33:50.956: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:33:51.213: INFO: namespace: e2e-tests-var-expansion-ldk6w, resource: bindings, ignored listing per whitelist
Sep  3 15:33:51.860: INFO: namespace e2e-tests-var-expansion-ldk6w deletion completed in 6.967252597s

• [SLOW TEST:9.300 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:33:51.861: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Sep  3 15:33:52.033: INFO: Waiting up to 5m0s for pod "pod-3b6238bc-ce60-11e9-a956-0a580af40009" in namespace "e2e-tests-emptydir-jfcjr" to be "success or failure"
Sep  3 15:33:52.060: INFO: Pod "pod-3b6238bc-ce60-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 27.529715ms
Sep  3 15:33:54.067: INFO: Pod "pod-3b6238bc-ce60-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.034509192s
STEP: Saw pod success
Sep  3 15:33:54.067: INFO: Pod "pod-3b6238bc-ce60-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 15:33:54.073: INFO: Trying to get logs from node 10.0.10.2 pod pod-3b6238bc-ce60-11e9-a956-0a580af40009 container test-container: <nil>
STEP: delete the pod
Sep  3 15:33:54.148: INFO: Waiting for pod pod-3b6238bc-ce60-11e9-a956-0a580af40009 to disappear
Sep  3 15:33:54.195: INFO: Pod pod-3b6238bc-ce60-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:33:54.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-jfcjr" for this suite.
Sep  3 15:34:00.265: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:34:01.097: INFO: namespace: e2e-tests-emptydir-jfcjr, resource: bindings, ignored listing per whitelist
Sep  3 15:34:01.286: INFO: namespace e2e-tests-emptydir-jfcjr deletion completed in 7.085023879s

• [SLOW TEST:9.425 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:34:01.286: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:34:25.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-runtime-fqghn" for this suite.
Sep  3 15:34:32.009: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:34:32.288: INFO: namespace: e2e-tests-container-runtime-fqghn, resource: bindings, ignored listing per whitelist
Sep  3 15:34:32.900: INFO: namespace e2e-tests-container-runtime-fqghn deletion completed in 6.9591657s

• [SLOW TEST:31.614 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  blackbox test
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:34:32.900: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Sep  3 15:34:33.034: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-043111098 proxy --unix-socket=/tmp/kubectl-proxy-unix035221713/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:34:33.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-j78mw" for this suite.
Sep  3 15:34:39.177: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:34:39.581: INFO: namespace: e2e-tests-kubectl-j78mw, resource: bindings, ignored listing per whitelist
Sep  3 15:34:40.316: INFO: namespace e2e-tests-kubectl-j78mw deletion completed in 7.201516886s

• [SLOW TEST:7.416 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:34:40.317: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Sep  3 15:34:40.573: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-gf8sj,SelfLink:/api/v1/namespaces/e2e-tests-watch-gf8sj/configmaps/e2e-watch-test-label-changed,UID:584b5b36-ce60-11e9-9b93-0a580aed0c4f,ResourceVersion:616712,Generation:0,CreationTimestamp:2019-09-03 15:34:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep  3 15:34:40.574: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-gf8sj,SelfLink:/api/v1/namespaces/e2e-tests-watch-gf8sj/configmaps/e2e-watch-test-label-changed,UID:584b5b36-ce60-11e9-9b93-0a580aed0c4f,ResourceVersion:616713,Generation:0,CreationTimestamp:2019-09-03 15:34:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Sep  3 15:34:40.574: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-gf8sj,SelfLink:/api/v1/namespaces/e2e-tests-watch-gf8sj/configmaps/e2e-watch-test-label-changed,UID:584b5b36-ce60-11e9-9b93-0a580aed0c4f,ResourceVersion:616714,Generation:0,CreationTimestamp:2019-09-03 15:34:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Sep  3 15:34:50.646: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-gf8sj,SelfLink:/api/v1/namespaces/e2e-tests-watch-gf8sj/configmaps/e2e-watch-test-label-changed,UID:584b5b36-ce60-11e9-9b93-0a580aed0c4f,ResourceVersion:616735,Generation:0,CreationTimestamp:2019-09-03 15:34:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep  3 15:34:50.647: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-gf8sj,SelfLink:/api/v1/namespaces/e2e-tests-watch-gf8sj/configmaps/e2e-watch-test-label-changed,UID:584b5b36-ce60-11e9-9b93-0a580aed0c4f,ResourceVersion:616736,Generation:0,CreationTimestamp:2019-09-03 15:34:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Sep  3 15:34:50.647: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-gf8sj,SelfLink:/api/v1/namespaces/e2e-tests-watch-gf8sj/configmaps/e2e-watch-test-label-changed,UID:584b5b36-ce60-11e9-9b93-0a580aed0c4f,ResourceVersion:616737,Generation:0,CreationTimestamp:2019-09-03 15:34:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:34:50.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-gf8sj" for this suite.
Sep  3 15:34:56.715: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:34:57.394: INFO: namespace: e2e-tests-watch-gf8sj, resource: bindings, ignored listing per whitelist
Sep  3 15:34:57.621: INFO: namespace e2e-tests-watch-gf8sj deletion completed in 6.968420017s

• [SLOW TEST:17.304 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:34:57.622: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  3 15:34:57.776: INFO: Creating deployment "nginx-deployment"
Sep  3 15:34:57.801: INFO: Waiting for observed generation 1
Sep  3 15:34:59.831: INFO: Waiting for all required pods to come up
Sep  3 15:34:59.855: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Sep  3 15:35:11.894: INFO: Waiting for deployment "nginx-deployment" to complete
Sep  3 15:35:11.941: INFO: Updating deployment "nginx-deployment" with a non-existent image
Sep  3 15:35:11.985: INFO: Updating deployment nginx-deployment
Sep  3 15:35:11.985: INFO: Waiting for observed generation 2
Sep  3 15:35:14.025: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Sep  3 15:35:14.068: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Sep  3 15:35:14.074: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Sep  3 15:35:14.090: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Sep  3 15:35:14.090: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Sep  3 15:35:14.116: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Sep  3 15:35:14.127: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Sep  3 15:35:14.127: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Sep  3 15:35:14.139: INFO: Updating deployment nginx-deployment
Sep  3 15:35:14.139: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Sep  3 15:35:14.150: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Sep  3 15:35:14.155: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Sep  3 15:35:14.191: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-qvdtd,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-qvdtd/deployments/nginx-deployment,UID:629a4dd0-ce60-11e9-9b93-0a580aed0c4f,ResourceVersion:616986,Generation:3,CreationTimestamp:2019-09-03 15:34:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Progressing True 2019-09-03 15:35:12 +0000 UTC 2019-09-03 15:34:57 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-65bbdb5f8" is progressing.} {Available False 2019-09-03 15:35:14 +0000 UTC 2019-09-03 15:35:14 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}],ReadyReplicas:8,CollisionCount:nil,},}

Sep  3 15:35:14.198: INFO: New ReplicaSet "nginx-deployment-65bbdb5f8" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8,GenerateName:,Namespace:e2e-tests-deployment-qvdtd,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-qvdtd/replicasets/nginx-deployment-65bbdb5f8,UID:6b0f8478-ce60-11e9-9b93-0a580aed0c4f,ResourceVersion:616969,Generation:3,CreationTimestamp:2019-09-03 15:35:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 629a4dd0-ce60-11e9-9b93-0a580aed0c4f 0xc00117f527 0xc00117f528}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep  3 15:35:14.198: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Sep  3 15:35:14.198: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965,GenerateName:,Namespace:e2e-tests-deployment-qvdtd,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-qvdtd/replicasets/nginx-deployment-555b55d965,UID:629b96c0-ce60-11e9-9b93-0a580aed0c4f,ResourceVersion:617013,Generation:3,CreationTimestamp:2019-09-03 15:34:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 629a4dd0-ce60-11e9-9b93-0a580aed0c4f 0xc00117f1b7 0xc00117f1b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Sep  3 15:35:14.208: INFO: Pod "nginx-deployment-555b55d965-442vq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-442vq,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qvdtd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qvdtd/pods/nginx-deployment-555b55d965-442vq,UID:6c5d4381-ce60-11e9-9b93-0a580aed0c4f,ResourceVersion:617012,Generation:0,CreationTimestamp:2019-09-03 15:35:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 629b96c0-ce60-11e9-9b93-0a580aed0c4f 0xc000b54a67 0xc000b54a68}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-w4gns {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-w4gns,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-w4gns true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000b54c40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000b54dd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:14 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  3 15:35:14.208: INFO: Pod "nginx-deployment-555b55d965-4rcpj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-4rcpj,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qvdtd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qvdtd/pods/nginx-deployment-555b55d965-4rcpj,UID:6c5d52bc-ce60-11e9-9b93-0a580aed0c4f,ResourceVersion:617018,Generation:0,CreationTimestamp:2019-09-03 15:35:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 629b96c0-ce60-11e9-9b93-0a580aed0c4f 0xc000b54e40 0xc000b54e41}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-w4gns {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-w4gns,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-w4gns true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000b54f40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000b54f70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:14 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  3 15:35:14.209: INFO: Pod "nginx-deployment-555b55d965-7kznr" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-7kznr,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qvdtd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qvdtd/pods/nginx-deployment-555b55d965-7kznr,UID:62a10098-ce60-11e9-9b93-0a580aed0c4f,ResourceVersion:616897,Generation:0,CreationTimestamp:2019-09-03 15:34:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 629b96c0-ce60-11e9-9b93-0a580aed0c4f 0xc000b55750 0xc000b55751}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-w4gns {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-w4gns,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-w4gns true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000b55850} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000b55870}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:34:57 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:04 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:04 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:34:57 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.2,PodIP:10.244.0.58,StartTime:2019-09-03 15:34:57 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-03 15:35:03 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://2a22f17dbf890bbc23a23a6579977a8419db5707cc03152bc122b00c9ccf79c0}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  3 15:35:14.209: INFO: Pod "nginx-deployment-555b55d965-8f82g" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-8f82g,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qvdtd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qvdtd/pods/nginx-deployment-555b55d965-8f82g,UID:6c5bec2b-ce60-11e9-9b93-0a580aed0c4f,ResourceVersion:617000,Generation:0,CreationTimestamp:2019-09-03 15:35:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 629b96c0-ce60-11e9-9b93-0a580aed0c4f 0xc000b55940 0xc000b55941}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-w4gns {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-w4gns,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-w4gns true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000b55c30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000b55c50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:14 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  3 15:35:14.209: INFO: Pod "nginx-deployment-555b55d965-9ps82" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-9ps82,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qvdtd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qvdtd/pods/nginx-deployment-555b55d965-9ps82,UID:6c5bd41a-ce60-11e9-9b93-0a580aed0c4f,ResourceVersion:616992,Generation:0,CreationTimestamp:2019-09-03 15:35:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 629b96c0-ce60-11e9-9b93-0a580aed0c4f 0xc000b55cc0 0xc000b55cc1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-w4gns {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-w4gns,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-w4gns true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000b55d30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000b55d50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:14 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  3 15:35:14.210: INFO: Pod "nginx-deployment-555b55d965-b4v5s" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-b4v5s,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qvdtd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qvdtd/pods/nginx-deployment-555b55d965-b4v5s,UID:6c5d2765-ce60-11e9-9b93-0a580aed0c4f,ResourceVersion:617008,Generation:0,CreationTimestamp:2019-09-03 15:35:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 629b96c0-ce60-11e9-9b93-0a580aed0c4f 0xc000b55e60 0xc000b55e61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-w4gns {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-w4gns,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-w4gns true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000b55ed0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000b55ef0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:14 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  3 15:35:14.210: INFO: Pod "nginx-deployment-555b55d965-b8qxw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-b8qxw,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qvdtd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qvdtd/pods/nginx-deployment-555b55d965-b8qxw,UID:629fbb72-ce60-11e9-9b93-0a580aed0c4f,ResourceVersion:616852,Generation:0,CreationTimestamp:2019-09-03 15:34:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 629b96c0-ce60-11e9-9b93-0a580aed0c4f 0xc000b55f60 0xc000b55f61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-w4gns {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-w4gns,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-w4gns true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000b55fd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000b55ff0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:34:57 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:00 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:34:57 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.2,PodIP:10.244.0.52,StartTime:2019-09-03 15:34:57 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-03 15:35:00 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://308b20f35351de67be3fbce5d396fc64305d4a5f3951a7f436d239a7e5b68388}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  3 15:35:14.210: INFO: Pod "nginx-deployment-555b55d965-c4b2h" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-c4b2h,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qvdtd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qvdtd/pods/nginx-deployment-555b55d965-c4b2h,UID:6c5d3f23-ce60-11e9-9b93-0a580aed0c4f,ResourceVersion:617011,Generation:0,CreationTimestamp:2019-09-03 15:35:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 629b96c0-ce60-11e9-9b93-0a580aed0c4f 0xc00167eb50 0xc00167eb51}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-w4gns {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-w4gns,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-w4gns true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00167ebc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00167ebe0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:14 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  3 15:35:14.210: INFO: Pod "nginx-deployment-555b55d965-cmp97" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-cmp97,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qvdtd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qvdtd/pods/nginx-deployment-555b55d965-cmp97,UID:6c5d4d2a-ce60-11e9-9b93-0a580aed0c4f,ResourceVersion:617019,Generation:0,CreationTimestamp:2019-09-03 15:35:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 629b96c0-ce60-11e9-9b93-0a580aed0c4f 0xc00167fa90 0xc00167fa91}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-w4gns {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-w4gns,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-w4gns true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00167fb90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00167fbb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:14 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  3 15:35:14.211: INFO: Pod "nginx-deployment-555b55d965-d77c7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-d77c7,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qvdtd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qvdtd/pods/nginx-deployment-555b55d965-d77c7,UID:6c595e5b-ce60-11e9-9b93-0a580aed0c4f,ResourceVersion:616975,Generation:0,CreationTimestamp:2019-09-03 15:35:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 629b96c0-ce60-11e9-9b93-0a580aed0c4f 0xc00167fc80 0xc00167fc81}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-w4gns {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-w4gns,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-w4gns true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00167fdf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0014e4310}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:14 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  3 15:35:14.211: INFO: Pod "nginx-deployment-555b55d965-flwrh" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-flwrh,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qvdtd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qvdtd/pods/nginx-deployment-555b55d965-flwrh,UID:629e8e1e-ce60-11e9-9b93-0a580aed0c4f,ResourceVersion:616879,Generation:0,CreationTimestamp:2019-09-03 15:34:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 629b96c0-ce60-11e9-9b93-0a580aed0c4f 0xc0014e4380 0xc0014e4381}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-w4gns {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-w4gns,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-w4gns true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0014e43f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0014e4410}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:34:57 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:02 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:02 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:34:57 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.2,PodIP:10.244.0.55,StartTime:2019-09-03 15:34:57 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-03 15:35:01 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://85ce8508606caea3f6f324e26905668cfb4501c3c9fee53d91117e01f4ac7c07}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  3 15:35:14.211: INFO: Pod "nginx-deployment-555b55d965-g9pgg" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-g9pgg,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qvdtd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qvdtd/pods/nginx-deployment-555b55d965-g9pgg,UID:629fc8c9-ce60-11e9-9b93-0a580aed0c4f,ResourceVersion:616869,Generation:0,CreationTimestamp:2019-09-03 15:34:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 629b96c0-ce60-11e9-9b93-0a580aed0c4f 0xc0014e4780 0xc0014e4781}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-w4gns {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-w4gns,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-w4gns true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0014e47f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0014e4810}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:34:57 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:01 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:01 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:34:57 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.2,PodIP:10.244.0.53,StartTime:2019-09-03 15:34:57 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-03 15:35:00 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://8125606c6b5bf18093f93bc27632d957a584b26ab0ba49079f3af4a29c8abe1c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  3 15:35:14.211: INFO: Pod "nginx-deployment-555b55d965-jnvsb" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-jnvsb,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qvdtd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qvdtd/pods/nginx-deployment-555b55d965-jnvsb,UID:629e92ad-ce60-11e9-9b93-0a580aed0c4f,ResourceVersion:616884,Generation:0,CreationTimestamp:2019-09-03 15:34:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 629b96c0-ce60-11e9-9b93-0a580aed0c4f 0xc0014e48d0 0xc0014e48d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-w4gns {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-w4gns,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-w4gns true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0014e4ae0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0014e4b00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:34:57 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:03 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:03 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:34:57 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.2,PodIP:10.244.0.59,StartTime:2019-09-03 15:34:57 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-03 15:35:03 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://8d3a1293beb66011ee7d3714ccc5646c598e83b299ef12aa7b5d9461fcd1897c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  3 15:35:14.212: INFO: Pod "nginx-deployment-555b55d965-kljh5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-kljh5,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qvdtd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qvdtd/pods/nginx-deployment-555b55d965-kljh5,UID:6c5a829c-ce60-11e9-9b93-0a580aed0c4f,ResourceVersion:616977,Generation:0,CreationTimestamp:2019-09-03 15:35:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 629b96c0-ce60-11e9-9b93-0a580aed0c4f 0xc0014e4c50 0xc0014e4c51}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-w4gns {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-w4gns,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-w4gns true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0014e4d40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0014e4d60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:14 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  3 15:35:14.212: INFO: Pod "nginx-deployment-555b55d965-krrbg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-krrbg,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qvdtd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qvdtd/pods/nginx-deployment-555b55d965-krrbg,UID:6c5bcb1a-ce60-11e9-9b93-0a580aed0c4f,ResourceVersion:616990,Generation:0,CreationTimestamp:2019-09-03 15:35:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 629b96c0-ce60-11e9-9b93-0a580aed0c4f 0xc0014e4dd0 0xc0014e4dd1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-w4gns {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-w4gns,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-w4gns true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0014e4ed0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0014e4f20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:14 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  3 15:35:14.212: INFO: Pod "nginx-deployment-555b55d965-l7csh" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-l7csh,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qvdtd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qvdtd/pods/nginx-deployment-555b55d965-l7csh,UID:629d8345-ce60-11e9-9b93-0a580aed0c4f,ResourceVersion:616863,Generation:0,CreationTimestamp:2019-09-03 15:34:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 629b96c0-ce60-11e9-9b93-0a580aed0c4f 0xc0014e5030 0xc0014e5031}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-w4gns {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-w4gns,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-w4gns true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0014e5100} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0014e5170}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:34:57 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:00 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:34:57 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.2,PodIP:10.244.0.51,StartTime:2019-09-03 15:34:57 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-03 15:34:59 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://467d763fe0af71f06d3f3a5e2380f1bebac152e49a8981c86f378513f16e0a11}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  3 15:35:14.212: INFO: Pod "nginx-deployment-555b55d965-rdvjr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-rdvjr,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qvdtd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qvdtd/pods/nginx-deployment-555b55d965-rdvjr,UID:6c5a85e5-ce60-11e9-9b93-0a580aed0c4f,ResourceVersion:616978,Generation:0,CreationTimestamp:2019-09-03 15:35:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 629b96c0-ce60-11e9-9b93-0a580aed0c4f 0xc0014e5230 0xc0014e5231}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-w4gns {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-w4gns,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-w4gns true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0014e5420} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0014e5440}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:14 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  3 15:35:14.213: INFO: Pod "nginx-deployment-555b55d965-shbh8" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-shbh8,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qvdtd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qvdtd/pods/nginx-deployment-555b55d965-shbh8,UID:629fb54c-ce60-11e9-9b93-0a580aed0c4f,ResourceVersion:616874,Generation:0,CreationTimestamp:2019-09-03 15:34:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 629b96c0-ce60-11e9-9b93-0a580aed0c4f 0xc0014e5510 0xc0014e5511}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-w4gns {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-w4gns,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-w4gns true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0014e55b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0014e55d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:34:57 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:01 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:01 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:34:57 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.2,PodIP:10.244.0.54,StartTime:2019-09-03 15:34:57 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-03 15:35:01 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://1ac1798262c2a2ba862501820f510d3be8e21c57460d71f4d48670522dbbe33b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  3 15:35:14.213: INFO: Pod "nginx-deployment-555b55d965-v7qc2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-v7qc2,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qvdtd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qvdtd/pods/nginx-deployment-555b55d965-v7qc2,UID:6c5bdbe2-ce60-11e9-9b93-0a580aed0c4f,ResourceVersion:616995,Generation:0,CreationTimestamp:2019-09-03 15:35:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 629b96c0-ce60-11e9-9b93-0a580aed0c4f 0xc0014e5700 0xc0014e5701}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-w4gns {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-w4gns,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-w4gns true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0014e58e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0014e5900}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:14 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  3 15:35:14.213: INFO: Pod "nginx-deployment-555b55d965-vv2kg" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-vv2kg,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qvdtd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qvdtd/pods/nginx-deployment-555b55d965-vv2kg,UID:62a10880-ce60-11e9-9b93-0a580aed0c4f,ResourceVersion:616892,Generation:0,CreationTimestamp:2019-09-03 15:34:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 629b96c0-ce60-11e9-9b93-0a580aed0c4f 0xc0014e59f0 0xc0014e59f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-w4gns {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-w4gns,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-w4gns true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0014e5b80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0014e5bc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:34:57 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:04 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:04 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:34:57 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.2,PodIP:10.244.0.57,StartTime:2019-09-03 15:34:57 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-03 15:35:03 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://21cd41ceecda8961d9e480052f665dd60d6f7ce242e8c39dc0777b48f946f60a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  3 15:35:14.213: INFO: Pod "nginx-deployment-65bbdb5f8-4kwts" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-4kwts,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-qvdtd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qvdtd/pods/nginx-deployment-65bbdb5f8-4kwts,UID:6b15f49c-ce60-11e9-9b93-0a580aed0c4f,ResourceVersion:616951,Generation:0,CreationTimestamp:2019-09-03 15:35:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 6b0f8478-ce60-11e9-9b93-0a580aed0c4f 0xc0014e5cd0 0xc0014e5cd1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-w4gns {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-w4gns,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-w4gns true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0014e5ef0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0014e5f20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:12 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.2,PodIP:,StartTime:2019-09-03 15:35:12 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  3 15:35:14.213: INFO: Pod "nginx-deployment-65bbdb5f8-csnnw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-csnnw,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-qvdtd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qvdtd/pods/nginx-deployment-65bbdb5f8-csnnw,UID:6b1a883a-ce60-11e9-9b93-0a580aed0c4f,ResourceVersion:616953,Generation:0,CreationTimestamp:2019-09-03 15:35:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 6b0f8478-ce60-11e9-9b93-0a580aed0c4f 0xc001630030 0xc001630031}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-w4gns {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-w4gns,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-w4gns true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0016300c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001630120}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:12 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.2,PodIP:,StartTime:2019-09-03 15:35:12 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  3 15:35:14.214: INFO: Pod "nginx-deployment-65bbdb5f8-jqlgg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-jqlgg,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-qvdtd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qvdtd/pods/nginx-deployment-65bbdb5f8-jqlgg,UID:6b1605ad-ce60-11e9-9b93-0a580aed0c4f,ResourceVersion:616952,Generation:0,CreationTimestamp:2019-09-03 15:35:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 6b0f8478-ce60-11e9-9b93-0a580aed0c4f 0xc0016303e0 0xc0016303e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-w4gns {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-w4gns,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-w4gns true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001630600} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001630650}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:12 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.2,PodIP:,StartTime:2019-09-03 15:35:12 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  3 15:35:14.214: INFO: Pod "nginx-deployment-65bbdb5f8-kk8dc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-kk8dc,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-qvdtd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qvdtd/pods/nginx-deployment-65bbdb5f8-kk8dc,UID:6b14b9d2-ce60-11e9-9b93-0a580aed0c4f,ResourceVersion:616931,Generation:0,CreationTimestamp:2019-09-03 15:35:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 6b0f8478-ce60-11e9-9b93-0a580aed0c4f 0xc001630710 0xc001630711}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-w4gns {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-w4gns,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-w4gns true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0016307d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0016307f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:12 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.2,PodIP:,StartTime:2019-09-03 15:35:12 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  3 15:35:14.214: INFO: Pod "nginx-deployment-65bbdb5f8-l4n8j" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-l4n8j,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-qvdtd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qvdtd/pods/nginx-deployment-65bbdb5f8-l4n8j,UID:6c5d5590-ce60-11e9-9b93-0a580aed0c4f,ResourceVersion:617016,Generation:0,CreationTimestamp:2019-09-03 15:35:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 6b0f8478-ce60-11e9-9b93-0a580aed0c4f 0xc001630920 0xc001630921}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-w4gns {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-w4gns,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-w4gns true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001630a20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001630a40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:14 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  3 15:35:14.214: INFO: Pod "nginx-deployment-65bbdb5f8-lvvgf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-lvvgf,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-qvdtd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qvdtd/pods/nginx-deployment-65bbdb5f8-lvvgf,UID:6c5be42d-ce60-11e9-9b93-0a580aed0c4f,ResourceVersion:616991,Generation:0,CreationTimestamp:2019-09-03 15:35:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 6b0f8478-ce60-11e9-9b93-0a580aed0c4f 0xc001630ab0 0xc001630ab1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-w4gns {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-w4gns,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-w4gns true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001630ce0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001630d00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:14 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  3 15:35:14.214: INFO: Pod "nginx-deployment-65bbdb5f8-pmcj5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-pmcj5,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-qvdtd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qvdtd/pods/nginx-deployment-65bbdb5f8-pmcj5,UID:6c5be4c2-ce60-11e9-9b93-0a580aed0c4f,ResourceVersion:616996,Generation:0,CreationTimestamp:2019-09-03 15:35:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 6b0f8478-ce60-11e9-9b93-0a580aed0c4f 0xc001630d80 0xc001630d81}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-w4gns {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-w4gns,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-w4gns true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001631110} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001631130}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:14 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  3 15:35:14.214: INFO: Pod "nginx-deployment-65bbdb5f8-rtq9f" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-rtq9f,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-qvdtd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qvdtd/pods/nginx-deployment-65bbdb5f8-rtq9f,UID:6c5ea399-ce60-11e9-9b93-0a580aed0c4f,ResourceVersion:617021,Generation:0,CreationTimestamp:2019-09-03 15:35:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 6b0f8478-ce60-11e9-9b93-0a580aed0c4f 0xc001631df0 0xc001631df1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-w4gns {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-w4gns,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-w4gns true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001631e70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001631e90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:14 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  3 15:35:14.215: INFO: Pod "nginx-deployment-65bbdb5f8-txnsh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-txnsh,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-qvdtd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qvdtd/pods/nginx-deployment-65bbdb5f8-txnsh,UID:6c5d26e0-ce60-11e9-9b93-0a580aed0c4f,ResourceVersion:617007,Generation:0,CreationTimestamp:2019-09-03 15:35:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 6b0f8478-ce60-11e9-9b93-0a580aed0c4f 0xc001631f00 0xc001631f01}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-w4gns {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-w4gns,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-w4gns true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000e581c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e581f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:14 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  3 15:35:14.215: INFO: Pod "nginx-deployment-65bbdb5f8-vbfr6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-vbfr6,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-qvdtd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qvdtd/pods/nginx-deployment-65bbdb5f8-vbfr6,UID:6c5d32ab-ce60-11e9-9b93-0a580aed0c4f,ResourceVersion:617009,Generation:0,CreationTimestamp:2019-09-03 15:35:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 6b0f8478-ce60-11e9-9b93-0a580aed0c4f 0xc000e582d0 0xc000e582d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-w4gns {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-w4gns,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-w4gns true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000e584f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e58510}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:14 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  3 15:35:14.215: INFO: Pod "nginx-deployment-65bbdb5f8-wp8z5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-wp8z5,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-qvdtd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qvdtd/pods/nginx-deployment-65bbdb5f8-wp8z5,UID:6b1b6270-ce60-11e9-9b93-0a580aed0c4f,ResourceVersion:616958,Generation:0,CreationTimestamp:2019-09-03 15:35:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 6b0f8478-ce60-11e9-9b93-0a580aed0c4f 0xc000e58580 0xc000e58581}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-w4gns {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-w4gns,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-w4gns true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000e587f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e58820}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:12 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.2,PodIP:,StartTime:2019-09-03 15:35:12 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  3 15:35:14.215: INFO: Pod "nginx-deployment-65bbdb5f8-xw8nk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-xw8nk,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-qvdtd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qvdtd/pods/nginx-deployment-65bbdb5f8-xw8nk,UID:6c5a8b19-ce60-11e9-9b93-0a580aed0c4f,ResourceVersion:616980,Generation:0,CreationTimestamp:2019-09-03 15:35:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 6b0f8478-ce60-11e9-9b93-0a580aed0c4f 0xc000e58a60 0xc000e58a61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-w4gns {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-w4gns,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-w4gns true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000e58d00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e58d20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:14 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  3 15:35:14.215: INFO: Pod "nginx-deployment-65bbdb5f8-znqdc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-znqdc,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-qvdtd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qvdtd/pods/nginx-deployment-65bbdb5f8-znqdc,UID:6c5d4c45-ce60-11e9-9b93-0a580aed0c4f,ResourceVersion:617017,Generation:0,CreationTimestamp:2019-09-03 15:35:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 6b0f8478-ce60-11e9-9b93-0a580aed0c4f 0xc000e58db0 0xc000e58db1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-w4gns {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-w4gns,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-w4gns true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000e58e40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e590c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:35:14 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:35:14.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-qvdtd" for this suite.
Sep  3 15:35:22.288: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:35:23.051: INFO: namespace: e2e-tests-deployment-qvdtd, resource: bindings, ignored listing per whitelist
Sep  3 15:35:23.217: INFO: namespace e2e-tests-deployment-qvdtd deletion completed in 8.996691495s

• [SLOW TEST:25.596 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:35:23.218: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Sep  3 15:35:23.396: INFO: Waiting up to 5m0s for pod "pod-71d749ab-ce60-11e9-a956-0a580af40009" in namespace "e2e-tests-emptydir-h7v6b" to be "success or failure"
Sep  3 15:35:23.428: INFO: Pod "pod-71d749ab-ce60-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 31.38176ms
Sep  3 15:35:25.434: INFO: Pod "pod-71d749ab-ce60-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037869832s
Sep  3 15:35:27.440: INFO: Pod "pod-71d749ab-ce60-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 4.04366628s
Sep  3 15:35:29.446: INFO: Pod "pod-71d749ab-ce60-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 6.049525121s
Sep  3 15:35:31.452: INFO: Pod "pod-71d749ab-ce60-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.055309157s
STEP: Saw pod success
Sep  3 15:35:31.452: INFO: Pod "pod-71d749ab-ce60-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 15:35:31.457: INFO: Trying to get logs from node 10.0.10.2 pod pod-71d749ab-ce60-11e9-a956-0a580af40009 container test-container: <nil>
STEP: delete the pod
Sep  3 15:35:31.535: INFO: Waiting for pod pod-71d749ab-ce60-11e9-a956-0a580af40009 to disappear
Sep  3 15:35:31.561: INFO: Pod pod-71d749ab-ce60-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:35:31.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-h7v6b" for this suite.
Sep  3 15:35:37.630: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:35:38.047: INFO: namespace: e2e-tests-emptydir-h7v6b, resource: bindings, ignored listing per whitelist
Sep  3 15:35:38.493: INFO: namespace e2e-tests-emptydir-h7v6b deletion completed in 6.925397759s

• [SLOW TEST:15.275 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:35:38.493: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1527
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  3 15:35:38.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-d7hmv'
Sep  3 15:35:39.005: INFO: stderr: ""
Sep  3 15:35:39.005: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1532
Sep  3 15:35:39.032: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-d7hmv'
Sep  3 15:35:49.370: INFO: stderr: ""
Sep  3 15:35:49.370: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:35:49.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-d7hmv" for this suite.
Sep  3 15:35:55.441: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:35:55.533: INFO: namespace: e2e-tests-kubectl-d7hmv, resource: bindings, ignored listing per whitelist
Sep  3 15:35:56.332: INFO: namespace e2e-tests-kubectl-d7hmv deletion completed in 6.949964428s

• [SLOW TEST:17.839 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:35:56.332: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  3 15:35:56.556: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
Sep  3 15:35:56.589: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-6lngv/daemonsets","resourceVersion":"617333"},"items":null}

Sep  3 15:35:56.615: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-6lngv/pods","resourceVersion":"617333"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:35:56.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-6lngv" for this suite.
Sep  3 15:36:02.673: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:36:03.276: INFO: namespace: e2e-tests-daemonsets-6lngv, resource: bindings, ignored listing per whitelist
Sep  3 15:36:03.542: INFO: namespace e2e-tests-daemonsets-6lngv deletion completed in 6.909198253s

S [SKIPPING] [7.209 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Sep  3 15:35:56.556: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:36:03.542: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-89ddddf4-ce60-11e9-a956-0a580af40009
STEP: Creating a pod to test consume configMaps
Sep  3 15:36:03.730: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-89e1bac0-ce60-11e9-a956-0a580af40009" in namespace "e2e-tests-projected-k8fhj" to be "success or failure"
Sep  3 15:36:03.753: INFO: Pod "pod-projected-configmaps-89e1bac0-ce60-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 23.444837ms
Sep  3 15:36:05.760: INFO: Pod "pod-projected-configmaps-89e1bac0-ce60-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030181442s
STEP: Saw pod success
Sep  3 15:36:05.760: INFO: Pod "pod-projected-configmaps-89e1bac0-ce60-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 15:36:05.765: INFO: Trying to get logs from node 10.0.10.2 pod pod-projected-configmaps-89e1bac0-ce60-11e9-a956-0a580af40009 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  3 15:36:05.886: INFO: Waiting for pod pod-projected-configmaps-89e1bac0-ce60-11e9-a956-0a580af40009 to disappear
Sep  3 15:36:05.912: INFO: Pod pod-projected-configmaps-89e1bac0-ce60-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:36:05.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-k8fhj" for this suite.
Sep  3 15:36:11.986: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:36:12.251: INFO: namespace: e2e-tests-projected-k8fhj, resource: bindings, ignored listing per whitelist
Sep  3 15:36:12.969: INFO: namespace e2e-tests-projected-k8fhj deletion completed in 7.050599672s

• [SLOW TEST:9.427 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:36:12.969: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-8f7b9d6b-ce60-11e9-a956-0a580af40009
STEP: Creating a pod to test consume configMaps
Sep  3 15:36:13.149: INFO: Waiting up to 5m0s for pod "pod-configmaps-8f7f9cda-ce60-11e9-a956-0a580af40009" in namespace "e2e-tests-configmap-7cf9m" to be "success or failure"
Sep  3 15:36:13.178: INFO: Pod "pod-configmaps-8f7f9cda-ce60-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 28.53309ms
Sep  3 15:36:15.183: INFO: Pod "pod-configmaps-8f7f9cda-ce60-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.034013944s
STEP: Saw pod success
Sep  3 15:36:15.183: INFO: Pod "pod-configmaps-8f7f9cda-ce60-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 15:36:15.188: INFO: Trying to get logs from node 10.0.10.2 pod pod-configmaps-8f7f9cda-ce60-11e9-a956-0a580af40009 container configmap-volume-test: <nil>
STEP: delete the pod
Sep  3 15:36:15.271: INFO: Waiting for pod pod-configmaps-8f7f9cda-ce60-11e9-a956-0a580af40009 to disappear
Sep  3 15:36:15.299: INFO: Pod pod-configmaps-8f7f9cda-ce60-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:36:15.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-7cf9m" for this suite.
Sep  3 15:36:21.371: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:36:21.886: INFO: namespace: e2e-tests-configmap-7cf9m, resource: bindings, ignored listing per whitelist
Sep  3 15:36:22.246: INFO: namespace e2e-tests-configmap-7cf9m deletion completed in 6.939446984s

• [SLOW TEST:9.277 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:36:22.246: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:36:24.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-dzfsb" for this suite.
Sep  3 15:37:04.621: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:37:05.284: INFO: namespace: e2e-tests-kubelet-test-dzfsb, resource: bindings, ignored listing per whitelist
Sep  3 15:37:05.558: INFO: namespace e2e-tests-kubelet-test-dzfsb deletion completed in 40.999368034s

• [SLOW TEST:43.313 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a read only busybox container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:186
    should not write to root filesystem [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:37:05.559: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Sep  3 15:37:05.745: INFO: Waiting up to 5m0s for pod "pod-aed8e75d-ce60-11e9-a956-0a580af40009" in namespace "e2e-tests-emptydir-jtf42" to be "success or failure"
Sep  3 15:37:05.773: INFO: Pod "pod-aed8e75d-ce60-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 28.033913ms
Sep  3 15:37:07.786: INFO: Pod "pod-aed8e75d-ce60-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.040431402s
STEP: Saw pod success
Sep  3 15:37:07.786: INFO: Pod "pod-aed8e75d-ce60-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 15:37:07.791: INFO: Trying to get logs from node 10.0.10.2 pod pod-aed8e75d-ce60-11e9-a956-0a580af40009 container test-container: <nil>
STEP: delete the pod
Sep  3 15:37:07.865: INFO: Waiting for pod pod-aed8e75d-ce60-11e9-a956-0a580af40009 to disappear
Sep  3 15:37:07.893: INFO: Pod pod-aed8e75d-ce60-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:37:07.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-jtf42" for this suite.
Sep  3 15:37:13.984: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:37:14.489: INFO: namespace: e2e-tests-emptydir-jtf42, resource: bindings, ignored listing per whitelist
Sep  3 15:37:14.883: INFO: namespace e2e-tests-emptydir-jtf42 deletion completed in 6.961611204s

• [SLOW TEST:9.324 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:37:14.883: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-b464b770-ce60-11e9-a956-0a580af40009
STEP: Creating secret with name s-test-opt-upd-b464b7b2-ce60-11e9-a956-0a580af40009
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-b464b770-ce60-11e9-a956-0a580af40009
STEP: Updating secret s-test-opt-upd-b464b7b2-ce60-11e9-a956-0a580af40009
STEP: Creating secret with name s-test-opt-create-b464b7ca-ce60-11e9-a956-0a580af40009
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:38:29.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dkwmk" for this suite.
Sep  3 15:38:51.256: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:38:51.976: INFO: namespace: e2e-tests-projected-dkwmk, resource: bindings, ignored listing per whitelist
Sep  3 15:38:52.151: INFO: namespace e2e-tests-projected-dkwmk deletion completed in 22.961617084s

• [SLOW TEST:97.268 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:38:52.151: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Sep  3 15:38:52.313: INFO: Waiting up to 5m0s for pod "pod-ee5e538c-ce60-11e9-a956-0a580af40009" in namespace "e2e-tests-emptydir-t68vr" to be "success or failure"
Sep  3 15:38:52.337: INFO: Pod "pod-ee5e538c-ce60-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 23.904782ms
Sep  3 15:38:54.349: INFO: Pod "pod-ee5e538c-ce60-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036554845s
Sep  3 15:38:56.355: INFO: Pod "pod-ee5e538c-ce60-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042695979s
STEP: Saw pod success
Sep  3 15:38:56.356: INFO: Pod "pod-ee5e538c-ce60-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 15:38:56.361: INFO: Trying to get logs from node 10.0.10.2 pod pod-ee5e538c-ce60-11e9-a956-0a580af40009 container test-container: <nil>
STEP: delete the pod
Sep  3 15:38:56.445: INFO: Waiting for pod pod-ee5e538c-ce60-11e9-a956-0a580af40009 to disappear
Sep  3 15:38:56.470: INFO: Pod pod-ee5e538c-ce60-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:38:56.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-t68vr" for this suite.
Sep  3 15:39:02.560: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:39:03.257: INFO: namespace: e2e-tests-emptydir-t68vr, resource: bindings, ignored listing per whitelist
Sep  3 15:39:03.383: INFO: namespace e2e-tests-emptydir-t68vr deletion completed in 6.907435669s

• [SLOW TEST:11.232 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:39:03.384: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-f50f3a2a-ce60-11e9-a956-0a580af40009
STEP: Creating a pod to test consume secrets
Sep  3 15:39:03.571: INFO: Waiting up to 5m0s for pod "pod-secrets-f51394fa-ce60-11e9-a956-0a580af40009" in namespace "e2e-tests-secrets-nvgr9" to be "success or failure"
Sep  3 15:39:03.597: INFO: Pod "pod-secrets-f51394fa-ce60-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 25.562429ms
Sep  3 15:39:05.609: INFO: Pod "pod-secrets-f51394fa-ce60-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.038407817s
STEP: Saw pod success
Sep  3 15:39:05.609: INFO: Pod "pod-secrets-f51394fa-ce60-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 15:39:05.615: INFO: Trying to get logs from node 10.0.10.2 pod pod-secrets-f51394fa-ce60-11e9-a956-0a580af40009 container secret-volume-test: <nil>
STEP: delete the pod
Sep  3 15:39:05.699: INFO: Waiting for pod pod-secrets-f51394fa-ce60-11e9-a956-0a580af40009 to disappear
Sep  3 15:39:05.729: INFO: Pod pod-secrets-f51394fa-ce60-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:39:05.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-nvgr9" for this suite.
Sep  3 15:39:11.810: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:39:12.692: INFO: namespace: e2e-tests-secrets-nvgr9, resource: bindings, ignored listing per whitelist
Sep  3 15:39:12.714: INFO: namespace e2e-tests-secrets-nvgr9 deletion completed in 6.979072311s

• [SLOW TEST:9.331 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:39:12.714: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Sep  3 15:39:12.872: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fa9f17cc-ce60-11e9-a956-0a580af40009" in namespace "e2e-tests-downward-api-95lv4" to be "success or failure"
Sep  3 15:39:12.897: INFO: Pod "downwardapi-volume-fa9f17cc-ce60-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 25.55097ms
Sep  3 15:39:14.903: INFO: Pod "downwardapi-volume-fa9f17cc-ce60-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.031703727s
STEP: Saw pod success
Sep  3 15:39:14.903: INFO: Pod "downwardapi-volume-fa9f17cc-ce60-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 15:39:14.909: INFO: Trying to get logs from node 10.0.10.2 pod downwardapi-volume-fa9f17cc-ce60-11e9-a956-0a580af40009 container client-container: <nil>
STEP: delete the pod
Sep  3 15:39:14.995: INFO: Waiting for pod downwardapi-volume-fa9f17cc-ce60-11e9-a956-0a580af40009 to disappear
Sep  3 15:39:15.022: INFO: Pod downwardapi-volume-fa9f17cc-ce60-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:39:15.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-95lv4" for this suite.
Sep  3 15:39:21.095: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:39:21.814: INFO: namespace: e2e-tests-downward-api-95lv4, resource: bindings, ignored listing per whitelist
Sep  3 15:39:21.983: INFO: namespace e2e-tests-downward-api-95lv4 deletion completed in 6.952389994s

• [SLOW TEST:9.268 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:39:21.983: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Sep  3 15:39:25.062: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-00a7c7c8-ce61-11e9-a956-0a580af40009,GenerateName:,Namespace:e2e-tests-events-nsqvp,SelfLink:/api/v1/namespaces/e2e-tests-events-nsqvp/pods/send-events-00a7c7c8-ce61-11e9-a956-0a580af40009,UID:00abc31a-ce61-11e9-9b93-0a580aed0c4f,ResourceVersion:617959,Generation:0,CreationTimestamp:2019-09-03 15:39:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 965607730,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-54cmm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-54cmm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-54cmm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d8b360} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d8b380}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:39:23 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:39:24 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:39:24 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:39:23 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.2,PodIP:10.244.0.88,StartTime:2019-09-03 15:39:23 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-09-03 15:39:23 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://715ce8f950dc5c2ec1a0a48ee2ad8e009ad02dcbf8c0b77742ccc645239d39cc}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Sep  3 15:39:27.090: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Sep  3 15:39:29.104: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:39:29.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-nsqvp" for this suite.
Sep  3 15:40:09.213: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:40:09.399: INFO: namespace: e2e-tests-events-nsqvp, resource: bindings, ignored listing per whitelist
Sep  3 15:40:10.352: INFO: namespace e2e-tests-events-nsqvp deletion completed in 41.211913837s

• [SLOW TEST:48.369 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:40:10.352: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Sep  3 15:40:10.515: INFO: Waiting up to 5m0s for pod "client-containers-1cfa877b-ce61-11e9-a956-0a580af40009" in namespace "e2e-tests-containers-gmbqn" to be "success or failure"
Sep  3 15:40:10.542: INFO: Pod "client-containers-1cfa877b-ce61-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 27.268139ms
Sep  3 15:40:12.548: INFO: Pod "client-containers-1cfa877b-ce61-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.033379329s
STEP: Saw pod success
Sep  3 15:40:12.548: INFO: Pod "client-containers-1cfa877b-ce61-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 15:40:12.553: INFO: Trying to get logs from node 10.0.10.2 pod client-containers-1cfa877b-ce61-11e9-a956-0a580af40009 container test-container: <nil>
STEP: delete the pod
Sep  3 15:40:12.633: INFO: Waiting for pod client-containers-1cfa877b-ce61-11e9-a956-0a580af40009 to disappear
Sep  3 15:40:12.662: INFO: Pod client-containers-1cfa877b-ce61-11e9-a956-0a580af40009 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:40:12.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-gmbqn" for this suite.
Sep  3 15:40:18.724: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:40:19.082: INFO: namespace: e2e-tests-containers-gmbqn, resource: bindings, ignored listing per whitelist
Sep  3 15:40:19.558: INFO: namespace e2e-tests-containers-gmbqn deletion completed in 6.88977967s

• [SLOW TEST:9.207 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:40:19.559: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Sep  3 15:40:19.738: INFO: Waiting up to 5m0s for pod "pod-2277b2e8-ce61-11e9-a956-0a580af40009" in namespace "e2e-tests-emptydir-t8h42" to be "success or failure"
Sep  3 15:40:19.765: INFO: Pod "pod-2277b2e8-ce61-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 26.932275ms
Sep  3 15:40:21.783: INFO: Pod "pod-2277b2e8-ce61-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.045076089s
STEP: Saw pod success
Sep  3 15:40:21.783: INFO: Pod "pod-2277b2e8-ce61-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 15:40:21.788: INFO: Trying to get logs from node 10.0.10.2 pod pod-2277b2e8-ce61-11e9-a956-0a580af40009 container test-container: <nil>
STEP: delete the pod
Sep  3 15:40:21.862: INFO: Waiting for pod pod-2277b2e8-ce61-11e9-a956-0a580af40009 to disappear
Sep  3 15:40:21.889: INFO: Pod pod-2277b2e8-ce61-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:40:21.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-t8h42" for this suite.
Sep  3 15:40:27.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:40:28.494: INFO: namespace: e2e-tests-emptydir-t8h42, resource: bindings, ignored listing per whitelist
Sep  3 15:40:28.771: INFO: namespace e2e-tests-emptydir-t8h42 deletion completed in 6.875189647s

• [SLOW TEST:9.212 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:40:28.771: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:40:28.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-xv568" for this suite.
Sep  3 15:40:51.032: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:40:51.360: INFO: namespace: e2e-tests-pods-xv568, resource: bindings, ignored listing per whitelist
Sep  3 15:40:51.922: INFO: namespace e2e-tests-pods-xv568 deletion completed in 22.956965678s

• [SLOW TEST:23.152 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:40:51.923: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-35c18f8d-ce61-11e9-a956-0a580af40009
STEP: Creating a pod to test consume configMaps
Sep  3 15:40:52.114: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-35c5fe9a-ce61-11e9-a956-0a580af40009" in namespace "e2e-tests-projected-n6644" to be "success or failure"
Sep  3 15:40:52.141: INFO: Pod "pod-projected-configmaps-35c5fe9a-ce61-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 26.914179ms
Sep  3 15:40:54.146: INFO: Pod "pod-projected-configmaps-35c5fe9a-ce61-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.032660383s
STEP: Saw pod success
Sep  3 15:40:54.146: INFO: Pod "pod-projected-configmaps-35c5fe9a-ce61-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 15:40:54.152: INFO: Trying to get logs from node 10.0.10.2 pod pod-projected-configmaps-35c5fe9a-ce61-11e9-a956-0a580af40009 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  3 15:40:54.288: INFO: Waiting for pod pod-projected-configmaps-35c5fe9a-ce61-11e9-a956-0a580af40009 to disappear
Sep  3 15:40:54.322: INFO: Pod pod-projected-configmaps-35c5fe9a-ce61-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:40:54.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-n6644" for this suite.
Sep  3 15:41:00.399: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:41:01.050: INFO: namespace: e2e-tests-projected-n6644, resource: bindings, ignored listing per whitelist
Sep  3 15:41:01.412: INFO: namespace e2e-tests-projected-n6644 deletion completed in 7.083874601s

• [SLOW TEST:9.489 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:41:01.412: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Sep  3 15:41:01.584: INFO: Waiting up to 5m0s for pod "var-expansion-3b6ada99-ce61-11e9-a956-0a580af40009" in namespace "e2e-tests-var-expansion-wnh5r" to be "success or failure"
Sep  3 15:41:01.612: INFO: Pod "var-expansion-3b6ada99-ce61-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 27.563605ms
Sep  3 15:41:03.618: INFO: Pod "var-expansion-3b6ada99-ce61-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033954457s
Sep  3 15:41:05.624: INFO: Pod "var-expansion-3b6ada99-ce61-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040328541s
STEP: Saw pod success
Sep  3 15:41:05.624: INFO: Pod "var-expansion-3b6ada99-ce61-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 15:41:05.630: INFO: Trying to get logs from node 10.0.10.2 pod var-expansion-3b6ada99-ce61-11e9-a956-0a580af40009 container dapi-container: <nil>
STEP: delete the pod
Sep  3 15:41:05.698: INFO: Waiting for pod var-expansion-3b6ada99-ce61-11e9-a956-0a580af40009 to disappear
Sep  3 15:41:05.723: INFO: Pod var-expansion-3b6ada99-ce61-11e9-a956-0a580af40009 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:41:05.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-wnh5r" for this suite.
Sep  3 15:41:11.795: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:41:11.806: INFO: namespace: e2e-tests-var-expansion-wnh5r, resource: bindings, ignored listing per whitelist
Sep  3 15:41:12.717: INFO: namespace e2e-tests-var-expansion-wnh5r deletion completed in 6.988042762s

• [SLOW TEST:11.305 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:41:12.717: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Sep  3 15:41:12.886: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4227618c-ce61-11e9-a956-0a580af40009" in namespace "e2e-tests-projected-4xx94" to be "success or failure"
Sep  3 15:41:12.914: INFO: Pod "downwardapi-volume-4227618c-ce61-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 27.795328ms
Sep  3 15:41:14.922: INFO: Pod "downwardapi-volume-4227618c-ce61-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.035651026s
STEP: Saw pod success
Sep  3 15:41:14.922: INFO: Pod "downwardapi-volume-4227618c-ce61-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 15:41:14.928: INFO: Trying to get logs from node 10.0.10.2 pod downwardapi-volume-4227618c-ce61-11e9-a956-0a580af40009 container client-container: <nil>
STEP: delete the pod
Sep  3 15:41:15.086: INFO: Waiting for pod downwardapi-volume-4227618c-ce61-11e9-a956-0a580af40009 to disappear
Sep  3 15:41:15.115: INFO: Pod downwardapi-volume-4227618c-ce61-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:41:15.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4xx94" for this suite.
Sep  3 15:41:21.186: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:41:21.425: INFO: namespace: e2e-tests-projected-4xx94, resource: bindings, ignored listing per whitelist
Sep  3 15:41:22.085: INFO: namespace e2e-tests-projected-4xx94 deletion completed in 6.964183073s

• [SLOW TEST:9.368 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:41:22.085: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  3 15:41:22.215: INFO: Creating deployment "test-recreate-deployment"
Sep  3 15:41:22.243: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Sep  3 15:41:22.297: INFO: Waiting deployment "test-recreate-deployment" to complete
Sep  3 15:41:22.302: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703122082, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703122082, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703122082, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703122082, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-5dfdcc846d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  3 15:41:24.308: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703122082, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703122082, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703122082, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703122082, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-5dfdcc846d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  3 15:41:26.307: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Sep  3 15:41:26.342: INFO: Updating deployment test-recreate-deployment
Sep  3 15:41:26.342: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Sep  3 15:41:26.444: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-xzlch,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-xzlch/deployments/test-recreate-deployment,UID:47bf7bc3-ce61-11e9-9b93-0a580aed0c4f,ResourceVersion:618388,Generation:2,CreationTimestamp:2019-09-03 15:41:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-09-03 15:41:26 +0000 UTC 2019-09-03 15:41:26 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-09-03 15:41:26 +0000 UTC 2019-09-03 15:41:22 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-697fbf54bf" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Sep  3 15:41:26.450: INFO: New ReplicaSet "test-recreate-deployment-697fbf54bf" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf,GenerateName:,Namespace:e2e-tests-deployment-xzlch,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-xzlch/replicasets/test-recreate-deployment-697fbf54bf,UID:4a37a327-ce61-11e9-9b93-0a580aed0c4f,ResourceVersion:618387,Generation:1,CreationTimestamp:2019-09-03 15:41:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 47bf7bc3-ce61-11e9-9b93-0a580aed0c4f 0xc00099d327 0xc00099d328}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep  3 15:41:26.450: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Sep  3 15:41:26.450: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5dfdcc846d,GenerateName:,Namespace:e2e-tests-deployment-xzlch,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-xzlch/replicasets/test-recreate-deployment-5dfdcc846d,UID:47c0b7f1-ce61-11e9-9b93-0a580aed0c4f,ResourceVersion:618377,Generation:2,CreationTimestamp:2019-09-03 15:41:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 47bf7bc3-ce61-11e9-9b93-0a580aed0c4f 0xc00099d157 0xc00099d158}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep  3 15:41:26.478: INFO: Pod "test-recreate-deployment-697fbf54bf-h5szv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf-h5szv,GenerateName:test-recreate-deployment-697fbf54bf-,Namespace:e2e-tests-deployment-xzlch,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xzlch/pods/test-recreate-deployment-697fbf54bf-h5szv,UID:4a3893fb-ce61-11e9-9b93-0a580aed0c4f,ResourceVersion:618389,Generation:0,CreationTimestamp:2019-09-03 15:41:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-697fbf54bf 4a37a327-ce61-11e9-9b93-0a580aed0c4f 0xc00099df17 0xc00099df18}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7fxfz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7fxfz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7fxfz true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001190020} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001190040}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:41:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:41:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:41:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:41:26 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.2,PodIP:,StartTime:2019-09-03 15:41:26 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:41:26.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-xzlch" for this suite.
Sep  3 15:41:32.559: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:41:33.028: INFO: namespace: e2e-tests-deployment-xzlch, resource: bindings, ignored listing per whitelist
Sep  3 15:41:33.395: INFO: namespace e2e-tests-deployment-xzlch deletion completed in 6.910312711s

• [SLOW TEST:11.309 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:41:33.395: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1358
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  3 15:41:33.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-bbltm'
Sep  3 15:41:33.661: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep  3 15:41:33.661: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: rolling-update to same image controller
Sep  3 15:41:33.714: INFO: scanned /root for discovery docs: <nil>
Sep  3 15:41:33.714: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-bbltm'
Sep  3 15:41:49.879: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Sep  3 15:41:49.879: INFO: stdout: "Created e2e-test-nginx-rc-541bb7de7e242615e5fc57ecce15e0e4\nScaling up e2e-test-nginx-rc-541bb7de7e242615e5fc57ecce15e0e4 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-541bb7de7e242615e5fc57ecce15e0e4 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-541bb7de7e242615e5fc57ecce15e0e4 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Sep  3 15:41:49.879: INFO: stdout: "Created e2e-test-nginx-rc-541bb7de7e242615e5fc57ecce15e0e4\nScaling up e2e-test-nginx-rc-541bb7de7e242615e5fc57ecce15e0e4 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-541bb7de7e242615e5fc57ecce15e0e4 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-541bb7de7e242615e5fc57ecce15e0e4 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Sep  3 15:41:49.879: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-bbltm'
Sep  3 15:41:50.001: INFO: stderr: ""
Sep  3 15:41:50.001: INFO: stdout: "e2e-test-nginx-rc-541bb7de7e242615e5fc57ecce15e0e4-66l9q "
Sep  3 15:41:50.001: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 get pods e2e-test-nginx-rc-541bb7de7e242615e5fc57ecce15e0e4-66l9q -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bbltm'
Sep  3 15:41:50.107: INFO: stderr: ""
Sep  3 15:41:50.107: INFO: stdout: "true"
Sep  3 15:41:50.107: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 get pods e2e-test-nginx-rc-541bb7de7e242615e5fc57ecce15e0e4-66l9q -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bbltm'
Sep  3 15:41:50.470: INFO: stderr: ""
Sep  3 15:41:50.471: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Sep  3 15:41:50.471: INFO: e2e-test-nginx-rc-541bb7de7e242615e5fc57ecce15e0e4-66l9q is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1364
Sep  3 15:41:50.471: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-bbltm'
Sep  3 15:41:50.572: INFO: stderr: ""
Sep  3 15:41:50.572: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:41:50.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bbltm" for this suite.
Sep  3 15:42:12.661: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:42:13.465: INFO: namespace: e2e-tests-kubectl-bbltm, resource: bindings, ignored listing per whitelist
Sep  3 15:42:13.516: INFO: namespace e2e-tests-kubectl-bbltm deletion completed in 22.938337253s

• [SLOW TEST:40.121 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:42:13.517: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  3 15:42:13.728: INFO: (0) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 36.933306ms)
Sep  3 15:42:13.737: INFO: (1) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 8.746839ms)
Sep  3 15:42:13.745: INFO: (2) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 8.911711ms)
Sep  3 15:42:13.754: INFO: (3) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 8.805509ms)
Sep  3 15:42:13.763: INFO: (4) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 9.139101ms)
Sep  3 15:42:13.772: INFO: (5) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 8.500395ms)
Sep  3 15:42:13.782: INFO: (6) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 9.518661ms)
Sep  3 15:42:13.791: INFO: (7) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 9.045425ms)
Sep  3 15:42:13.800: INFO: (8) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 9.128685ms)
Sep  3 15:42:13.809: INFO: (9) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 9.08263ms)
Sep  3 15:42:13.818: INFO: (10) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 9.069264ms)
Sep  3 15:42:13.827: INFO: (11) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 9.091028ms)
Sep  3 15:42:13.836: INFO: (12) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 8.868428ms)
Sep  3 15:42:13.845: INFO: (13) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 9.040183ms)
Sep  3 15:42:13.854: INFO: (14) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 9.012866ms)
Sep  3 15:42:13.863: INFO: (15) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 8.977505ms)
Sep  3 15:42:13.872: INFO: (16) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 8.970131ms)
Sep  3 15:42:13.883: INFO: (17) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 10.292298ms)
Sep  3 15:42:13.892: INFO: (18) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 9.039069ms)
Sep  3 15:42:13.901: INFO: (19) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 9.021143ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:42:13.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-g4dtm" for this suite.
Sep  3 15:42:19.970: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:42:20.357: INFO: namespace: e2e-tests-proxy-g4dtm, resource: bindings, ignored listing per whitelist
Sep  3 15:42:20.894: INFO: namespace e2e-tests-proxy-g4dtm deletion completed in 6.986910005s

• [SLOW TEST:7.378 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:42:20.895: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Sep  3 15:42:21.054: INFO: Waiting up to 5m0s for pod "client-containers-6ac970da-ce61-11e9-a956-0a580af40009" in namespace "e2e-tests-containers-wqzgq" to be "success or failure"
Sep  3 15:42:21.079: INFO: Pod "client-containers-6ac970da-ce61-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 24.251181ms
Sep  3 15:42:23.092: INFO: Pod "client-containers-6ac970da-ce61-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037135341s
Sep  3 15:42:25.097: INFO: Pod "client-containers-6ac970da-ce61-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042796045s
STEP: Saw pod success
Sep  3 15:42:25.097: INFO: Pod "client-containers-6ac970da-ce61-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 15:42:25.102: INFO: Trying to get logs from node 10.0.10.2 pod client-containers-6ac970da-ce61-11e9-a956-0a580af40009 container test-container: <nil>
STEP: delete the pod
Sep  3 15:42:25.198: INFO: Waiting for pod client-containers-6ac970da-ce61-11e9-a956-0a580af40009 to disappear
Sep  3 15:42:25.223: INFO: Pod client-containers-6ac970da-ce61-11e9-a956-0a580af40009 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:42:25.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-wqzgq" for this suite.
Sep  3 15:42:31.296: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:42:32.023: INFO: namespace: e2e-tests-containers-wqzgq, resource: bindings, ignored listing per whitelist
Sep  3 15:42:32.118: INFO: namespace e2e-tests-containers-wqzgq deletion completed in 6.889212081s

• [SLOW TEST:11.222 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:42:32.118: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Sep  3 15:42:32.278: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7179ef5f-ce61-11e9-a956-0a580af40009" in namespace "e2e-tests-downward-api-5sl2m" to be "success or failure"
Sep  3 15:42:32.303: INFO: Pod "downwardapi-volume-7179ef5f-ce61-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 25.890286ms
Sep  3 15:42:34.318: INFO: Pod "downwardapi-volume-7179ef5f-ce61-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.040380995s
STEP: Saw pod success
Sep  3 15:42:34.318: INFO: Pod "downwardapi-volume-7179ef5f-ce61-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 15:42:34.323: INFO: Trying to get logs from node 10.0.10.2 pod downwardapi-volume-7179ef5f-ce61-11e9-a956-0a580af40009 container client-container: <nil>
STEP: delete the pod
Sep  3 15:42:34.395: INFO: Waiting for pod downwardapi-volume-7179ef5f-ce61-11e9-a956-0a580af40009 to disappear
Sep  3 15:42:34.421: INFO: Pod downwardapi-volume-7179ef5f-ce61-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:42:34.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-5sl2m" for this suite.
Sep  3 15:42:40.488: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:42:40.499: INFO: namespace: e2e-tests-downward-api-5sl2m, resource: bindings, ignored listing per whitelist
Sep  3 15:42:41.377: INFO: namespace e2e-tests-downward-api-5sl2m deletion completed in 6.949321223s

• [SLOW TEST:9.259 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:42:41.377: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Sep  3 15:42:44.181: INFO: Successfully updated pod "labelsupdate7703615a-ce61-11e9-a956-0a580af40009"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:42:48.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4qrvj" for this suite.
Sep  3 15:43:12.299: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:43:12.939: INFO: namespace: e2e-tests-projected-4qrvj, resource: bindings, ignored listing per whitelist
Sep  3 15:43:13.161: INFO: namespace e2e-tests-projected-4qrvj deletion completed in 24.922734288s

• [SLOW TEST:31.784 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:43:13.161: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Sep  3 15:43:13.298: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 create -f - --namespace=e2e-tests-kubectl-6jrsn'
Sep  3 15:43:13.575: INFO: stderr: ""
Sep  3 15:43:13.575: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep  3 15:43:13.575: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6jrsn'
Sep  3 15:43:13.706: INFO: stderr: ""
Sep  3 15:43:13.706: INFO: stdout: "update-demo-nautilus-92wtc update-demo-nautilus-lkbxq "
Sep  3 15:43:13.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 get pods update-demo-nautilus-92wtc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6jrsn'
Sep  3 15:43:13.815: INFO: stderr: ""
Sep  3 15:43:13.815: INFO: stdout: ""
Sep  3 15:43:13.815: INFO: update-demo-nautilus-92wtc is created but not running
Sep  3 15:43:18.815: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6jrsn'
Sep  3 15:43:18.935: INFO: stderr: ""
Sep  3 15:43:18.935: INFO: stdout: "update-demo-nautilus-92wtc update-demo-nautilus-lkbxq "
Sep  3 15:43:18.936: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 get pods update-demo-nautilus-92wtc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6jrsn'
Sep  3 15:43:19.022: INFO: stderr: ""
Sep  3 15:43:19.022: INFO: stdout: "true"
Sep  3 15:43:19.022: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 get pods update-demo-nautilus-92wtc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6jrsn'
Sep  3 15:43:19.131: INFO: stderr: ""
Sep  3 15:43:19.131: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  3 15:43:19.131: INFO: validating pod update-demo-nautilus-92wtc
Sep  3 15:43:19.225: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  3 15:43:19.225: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  3 15:43:19.225: INFO: update-demo-nautilus-92wtc is verified up and running
Sep  3 15:43:19.226: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 get pods update-demo-nautilus-lkbxq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6jrsn'
Sep  3 15:43:19.326: INFO: stderr: ""
Sep  3 15:43:19.326: INFO: stdout: "true"
Sep  3 15:43:19.326: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 get pods update-demo-nautilus-lkbxq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6jrsn'
Sep  3 15:43:19.733: INFO: stderr: ""
Sep  3 15:43:19.733: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  3 15:43:19.733: INFO: validating pod update-demo-nautilus-lkbxq
Sep  3 15:43:19.840: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  3 15:43:19.840: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  3 15:43:19.840: INFO: update-demo-nautilus-lkbxq is verified up and running
STEP: scaling down the replication controller
Sep  3 15:43:19.842: INFO: scanned /root for discovery docs: <nil>
Sep  3 15:43:19.842: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-6jrsn'
Sep  3 15:43:21.034: INFO: stderr: ""
Sep  3 15:43:21.034: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep  3 15:43:21.034: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6jrsn'
Sep  3 15:43:21.175: INFO: stderr: ""
Sep  3 15:43:21.175: INFO: stdout: "update-demo-nautilus-92wtc update-demo-nautilus-lkbxq "
STEP: Replicas for name=update-demo: expected=1 actual=2
Sep  3 15:43:26.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6jrsn'
Sep  3 15:43:26.262: INFO: stderr: ""
Sep  3 15:43:26.262: INFO: stdout: "update-demo-nautilus-92wtc update-demo-nautilus-lkbxq "
STEP: Replicas for name=update-demo: expected=1 actual=2
Sep  3 15:43:31.262: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6jrsn'
Sep  3 15:43:31.385: INFO: stderr: ""
Sep  3 15:43:31.385: INFO: stdout: "update-demo-nautilus-92wtc "
Sep  3 15:43:31.385: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 get pods update-demo-nautilus-92wtc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6jrsn'
Sep  3 15:43:31.487: INFO: stderr: ""
Sep  3 15:43:31.487: INFO: stdout: "true"
Sep  3 15:43:31.488: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 get pods update-demo-nautilus-92wtc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6jrsn'
Sep  3 15:43:31.577: INFO: stderr: ""
Sep  3 15:43:31.577: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  3 15:43:31.577: INFO: validating pod update-demo-nautilus-92wtc
Sep  3 15:43:31.586: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  3 15:43:31.586: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  3 15:43:31.586: INFO: update-demo-nautilus-92wtc is verified up and running
STEP: scaling up the replication controller
Sep  3 15:43:31.587: INFO: scanned /root for discovery docs: <nil>
Sep  3 15:43:31.588: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-6jrsn'
Sep  3 15:43:32.776: INFO: stderr: ""
Sep  3 15:43:32.776: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep  3 15:43:32.776: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6jrsn'
Sep  3 15:43:32.900: INFO: stderr: ""
Sep  3 15:43:32.900: INFO: stdout: "update-demo-nautilus-92wtc update-demo-nautilus-gh4ch "
Sep  3 15:43:32.901: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 get pods update-demo-nautilus-92wtc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6jrsn'
Sep  3 15:43:32.983: INFO: stderr: ""
Sep  3 15:43:32.983: INFO: stdout: "true"
Sep  3 15:43:32.983: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 get pods update-demo-nautilus-92wtc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6jrsn'
Sep  3 15:43:33.071: INFO: stderr: ""
Sep  3 15:43:33.071: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  3 15:43:33.071: INFO: validating pod update-demo-nautilus-92wtc
Sep  3 15:43:33.080: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  3 15:43:33.080: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  3 15:43:33.080: INFO: update-demo-nautilus-92wtc is verified up and running
Sep  3 15:43:33.081: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 get pods update-demo-nautilus-gh4ch -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6jrsn'
Sep  3 15:43:33.196: INFO: stderr: ""
Sep  3 15:43:33.196: INFO: stdout: ""
Sep  3 15:43:33.196: INFO: update-demo-nautilus-gh4ch is created but not running
Sep  3 15:43:38.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6jrsn'
Sep  3 15:43:38.283: INFO: stderr: ""
Sep  3 15:43:38.283: INFO: stdout: "update-demo-nautilus-92wtc update-demo-nautilus-gh4ch "
Sep  3 15:43:38.283: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 get pods update-demo-nautilus-92wtc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6jrsn'
Sep  3 15:43:38.366: INFO: stderr: ""
Sep  3 15:43:38.366: INFO: stdout: "true"
Sep  3 15:43:38.366: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 get pods update-demo-nautilus-92wtc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6jrsn'
Sep  3 15:43:38.447: INFO: stderr: ""
Sep  3 15:43:38.447: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  3 15:43:38.447: INFO: validating pod update-demo-nautilus-92wtc
Sep  3 15:43:38.456: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  3 15:43:38.456: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  3 15:43:38.456: INFO: update-demo-nautilus-92wtc is verified up and running
Sep  3 15:43:38.456: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 get pods update-demo-nautilus-gh4ch -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6jrsn'
Sep  3 15:43:38.541: INFO: stderr: ""
Sep  3 15:43:38.541: INFO: stdout: "true"
Sep  3 15:43:38.541: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 get pods update-demo-nautilus-gh4ch -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6jrsn'
Sep  3 15:43:38.646: INFO: stderr: ""
Sep  3 15:43:38.646: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  3 15:43:38.646: INFO: validating pod update-demo-nautilus-gh4ch
Sep  3 15:43:38.852: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  3 15:43:38.852: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  3 15:43:38.852: INFO: update-demo-nautilus-gh4ch is verified up and running
STEP: using delete to clean up resources
Sep  3 15:43:38.852: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-6jrsn'
Sep  3 15:43:38.959: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  3 15:43:38.959: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Sep  3 15:43:38.959: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-6jrsn'
Sep  3 15:43:39.388: INFO: stderr: "No resources found.\n"
Sep  3 15:43:39.388: INFO: stdout: ""
Sep  3 15:43:39.388: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 get pods -l name=update-demo --namespace=e2e-tests-kubectl-6jrsn -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep  3 15:43:39.549: INFO: stderr: ""
Sep  3 15:43:39.549: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:43:39.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6jrsn" for this suite.
Sep  3 15:44:03.626: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:44:04.341: INFO: namespace: e2e-tests-kubectl-6jrsn, resource: bindings, ignored listing per whitelist
Sep  3 15:44:04.497: INFO: namespace e2e-tests-kubectl-6jrsn deletion completed in 24.941275561s

• [SLOW TEST:51.336 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:44:04.498: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  3 15:44:04.629: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:44:06.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-k8jwt" for this suite.
Sep  3 15:44:51.064: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:44:51.853: INFO: namespace: e2e-tests-pods-k8jwt, resource: bindings, ignored listing per whitelist
Sep  3 15:44:51.900: INFO: namespace e2e-tests-pods-k8jwt deletion completed in 44.90535468s

• [SLOW TEST:47.403 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:44:51.901: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-nxp74
Sep  3 15:44:54.094: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-nxp74
STEP: checking the pod's current state and verifying that restartCount is present
Sep  3 15:44:54.102: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:48:55.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-nxp74" for this suite.
Sep  3 15:49:01.383: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:49:01.914: INFO: namespace: e2e-tests-container-probe-nxp74, resource: bindings, ignored listing per whitelist
Sep  3 15:49:02.249: INFO: namespace e2e-tests-container-probe-nxp74 deletion completed in 6.936154358s

• [SLOW TEST:250.348 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:49:02.249: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Sep  3 15:49:02.428: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5a065571-ce62-11e9-a956-0a580af40009" in namespace "e2e-tests-projected-brnx7" to be "success or failure"
Sep  3 15:49:02.454: INFO: Pod "downwardapi-volume-5a065571-ce62-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 25.923868ms
Sep  3 15:49:04.468: INFO: Pod "downwardapi-volume-5a065571-ce62-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.039504909s
STEP: Saw pod success
Sep  3 15:49:04.468: INFO: Pod "downwardapi-volume-5a065571-ce62-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 15:49:04.473: INFO: Trying to get logs from node 10.0.10.2 pod downwardapi-volume-5a065571-ce62-11e9-a956-0a580af40009 container client-container: <nil>
STEP: delete the pod
Sep  3 15:49:04.554: INFO: Waiting for pod downwardapi-volume-5a065571-ce62-11e9-a956-0a580af40009 to disappear
Sep  3 15:49:04.600: INFO: Pod downwardapi-volume-5a065571-ce62-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:49:04.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-brnx7" for this suite.
Sep  3 15:49:10.668: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:49:10.790: INFO: namespace: e2e-tests-projected-brnx7, resource: bindings, ignored listing per whitelist
Sep  3 15:49:11.513: INFO: namespace e2e-tests-projected-brnx7 deletion completed in 6.905884978s

• [SLOW TEST:9.264 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:49:11.514: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  3 15:49:12.146: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:49:14.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-w9mjj" for this suite.
Sep  3 15:49:54.416: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:49:54.427: INFO: namespace: e2e-tests-pods-w9mjj, resource: bindings, ignored listing per whitelist
Sep  3 15:49:55.423: INFO: namespace e2e-tests-pods-w9mjj deletion completed in 41.067178885s

• [SLOW TEST:43.910 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:49:55.424: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Sep  3 15:49:55.602: INFO: Waiting up to 5m0s for pod "downwardapi-volume-79b7cbf5-ce62-11e9-a956-0a580af40009" in namespace "e2e-tests-projected-h57qx" to be "success or failure"
Sep  3 15:49:55.627: INFO: Pod "downwardapi-volume-79b7cbf5-ce62-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 25.316019ms
Sep  3 15:49:57.634: INFO: Pod "downwardapi-volume-79b7cbf5-ce62-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031686397s
Sep  3 15:49:59.640: INFO: Pod "downwardapi-volume-79b7cbf5-ce62-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037658828s
STEP: Saw pod success
Sep  3 15:49:59.640: INFO: Pod "downwardapi-volume-79b7cbf5-ce62-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 15:49:59.645: INFO: Trying to get logs from node 10.0.10.2 pod downwardapi-volume-79b7cbf5-ce62-11e9-a956-0a580af40009 container client-container: <nil>
STEP: delete the pod
Sep  3 15:49:59.734: INFO: Waiting for pod downwardapi-volume-79b7cbf5-ce62-11e9-a956-0a580af40009 to disappear
Sep  3 15:49:59.761: INFO: Pod downwardapi-volume-79b7cbf5-ce62-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:49:59.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-h57qx" for this suite.
Sep  3 15:50:05.829: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:50:06.612: INFO: namespace: e2e-tests-projected-h57qx, resource: bindings, ignored listing per whitelist
Sep  3 15:50:06.778: INFO: namespace e2e-tests-projected-h57qx deletion completed in 7.0049588s

• [SLOW TEST:11.354 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:50:06.779: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:50:11.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-gwvgw" for this suite.
Sep  3 15:50:17.205: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:50:17.654: INFO: namespace: e2e-tests-emptydir-wrapper-gwvgw, resource: bindings, ignored listing per whitelist
Sep  3 15:50:18.356: INFO: namespace e2e-tests-emptydir-wrapper-gwvgw deletion completed in 7.212605232s

• [SLOW TEST:11.578 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:50:18.358: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Sep  3 15:50:18.541: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8763a329-ce62-11e9-a956-0a580af40009" in namespace "e2e-tests-projected-dwbll" to be "success or failure"
Sep  3 15:50:18.570: INFO: Pod "downwardapi-volume-8763a329-ce62-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 28.703413ms
Sep  3 15:50:20.579: INFO: Pod "downwardapi-volume-8763a329-ce62-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.038263594s
STEP: Saw pod success
Sep  3 15:50:20.579: INFO: Pod "downwardapi-volume-8763a329-ce62-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 15:50:20.585: INFO: Trying to get logs from node 10.0.10.2 pod downwardapi-volume-8763a329-ce62-11e9-a956-0a580af40009 container client-container: <nil>
STEP: delete the pod
Sep  3 15:50:20.687: INFO: Waiting for pod downwardapi-volume-8763a329-ce62-11e9-a956-0a580af40009 to disappear
Sep  3 15:50:20.715: INFO: Pod downwardapi-volume-8763a329-ce62-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:50:20.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dwbll" for this suite.
Sep  3 15:50:26.793: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:50:26.805: INFO: namespace: e2e-tests-projected-dwbll, resource: bindings, ignored listing per whitelist
Sep  3 15:50:27.735: INFO: namespace e2e-tests-projected-dwbll deletion completed in 7.013874186s

• [SLOW TEST:9.377 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:50:27.735: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Sep  3 15:50:27.912: INFO: Waiting up to 5m0s for pod "downward-api-8cf9a100-ce62-11e9-a956-0a580af40009" in namespace "e2e-tests-downward-api-fbxp9" to be "success or failure"
Sep  3 15:50:27.939: INFO: Pod "downward-api-8cf9a100-ce62-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 27.668405ms
Sep  3 15:50:29.945: INFO: Pod "downward-api-8cf9a100-ce62-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.033641784s
STEP: Saw pod success
Sep  3 15:50:29.946: INFO: Pod "downward-api-8cf9a100-ce62-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 15:50:29.951: INFO: Trying to get logs from node 10.0.10.2 pod downward-api-8cf9a100-ce62-11e9-a956-0a580af40009 container dapi-container: <nil>
STEP: delete the pod
Sep  3 15:50:30.024: INFO: Waiting for pod downward-api-8cf9a100-ce62-11e9-a956-0a580af40009 to disappear
Sep  3 15:50:30.051: INFO: Pod downward-api-8cf9a100-ce62-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:50:30.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-fbxp9" for this suite.
Sep  3 15:50:36.118: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:50:36.160: INFO: namespace: e2e-tests-downward-api-fbxp9, resource: bindings, ignored listing per whitelist
Sep  3 15:50:37.061: INFO: namespace e2e-tests-downward-api-fbxp9 deletion completed in 7.004423059s

• [SLOW TEST:9.326 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:50:37.062: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Sep  3 15:50:37.260: INFO: Waiting up to 5m0s for pod "downwardapi-volume-928c1796-ce62-11e9-a956-0a580af40009" in namespace "e2e-tests-downward-api-dlbg6" to be "success or failure"
Sep  3 15:50:37.288: INFO: Pod "downwardapi-volume-928c1796-ce62-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 27.620587ms
Sep  3 15:50:39.294: INFO: Pod "downwardapi-volume-928c1796-ce62-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.033801568s
STEP: Saw pod success
Sep  3 15:50:39.294: INFO: Pod "downwardapi-volume-928c1796-ce62-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 15:50:39.300: INFO: Trying to get logs from node 10.0.10.2 pod downwardapi-volume-928c1796-ce62-11e9-a956-0a580af40009 container client-container: <nil>
STEP: delete the pod
Sep  3 15:50:39.385: INFO: Waiting for pod downwardapi-volume-928c1796-ce62-11e9-a956-0a580af40009 to disappear
Sep  3 15:50:39.429: INFO: Pod downwardapi-volume-928c1796-ce62-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:50:39.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-dlbg6" for this suite.
Sep  3 15:50:45.507: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:50:45.923: INFO: namespace: e2e-tests-downward-api-dlbg6, resource: bindings, ignored listing per whitelist
Sep  3 15:50:46.355: INFO: namespace e2e-tests-downward-api-dlbg6 deletion completed in 6.920679595s

• [SLOW TEST:9.294 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:50:46.356: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Sep  3 15:50:46.522: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9811040b-ce62-11e9-a956-0a580af40009" in namespace "e2e-tests-downward-api-8gsrj" to be "success or failure"
Sep  3 15:50:46.550: INFO: Pod "downwardapi-volume-9811040b-ce62-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 28.327775ms
Sep  3 15:50:48.563: INFO: Pod "downwardapi-volume-9811040b-ce62-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.041457588s
STEP: Saw pod success
Sep  3 15:50:48.563: INFO: Pod "downwardapi-volume-9811040b-ce62-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 15:50:48.569: INFO: Trying to get logs from node 10.0.10.2 pod downwardapi-volume-9811040b-ce62-11e9-a956-0a580af40009 container client-container: <nil>
STEP: delete the pod
Sep  3 15:50:48.635: INFO: Waiting for pod downwardapi-volume-9811040b-ce62-11e9-a956-0a580af40009 to disappear
Sep  3 15:50:48.659: INFO: Pod downwardapi-volume-9811040b-ce62-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:50:48.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-8gsrj" for this suite.
Sep  3 15:50:54.729: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:50:54.961: INFO: namespace: e2e-tests-downward-api-8gsrj, resource: bindings, ignored listing per whitelist
Sep  3 15:50:55.585: INFO: namespace e2e-tests-downward-api-8gsrj deletion completed in 6.920628272s

• [SLOW TEST:9.229 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:50:55.586: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  3 15:50:55.799: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Sep  3 15:50:55.849: INFO: Number of nodes with available pods: 0
Sep  3 15:50:55.849: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Sep  3 15:50:55.891: INFO: Number of nodes with available pods: 0
Sep  3 15:50:55.891: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 15:50:56.914: INFO: Number of nodes with available pods: 0
Sep  3 15:50:56.914: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 15:50:57.897: INFO: Number of nodes with available pods: 1
Sep  3 15:50:57.897: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Sep  3 15:50:57.943: INFO: Number of nodes with available pods: 1
Sep  3 15:50:57.943: INFO: Number of running nodes: 0, number of available pods: 1
Sep  3 15:50:58.972: INFO: Number of nodes with available pods: 0
Sep  3 15:50:58.972: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Sep  3 15:50:59.012: INFO: Number of nodes with available pods: 0
Sep  3 15:50:59.012: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 15:51:00.018: INFO: Number of nodes with available pods: 0
Sep  3 15:51:00.018: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 15:51:01.018: INFO: Number of nodes with available pods: 0
Sep  3 15:51:01.018: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 15:51:02.018: INFO: Number of nodes with available pods: 0
Sep  3 15:51:02.018: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 15:51:03.018: INFO: Number of nodes with available pods: 0
Sep  3 15:51:03.018: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 15:51:04.019: INFO: Number of nodes with available pods: 0
Sep  3 15:51:04.019: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 15:51:05.018: INFO: Number of nodes with available pods: 0
Sep  3 15:51:05.019: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 15:51:06.018: INFO: Number of nodes with available pods: 0
Sep  3 15:51:06.018: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 15:51:07.018: INFO: Number of nodes with available pods: 0
Sep  3 15:51:07.018: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 15:51:08.019: INFO: Number of nodes with available pods: 0
Sep  3 15:51:08.019: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 15:51:09.024: INFO: Number of nodes with available pods: 0
Sep  3 15:51:09.024: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 15:51:10.018: INFO: Number of nodes with available pods: 0
Sep  3 15:51:10.018: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 15:51:11.018: INFO: Number of nodes with available pods: 0
Sep  3 15:51:11.018: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 15:51:12.018: INFO: Number of nodes with available pods: 0
Sep  3 15:51:12.018: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 15:51:13.018: INFO: Number of nodes with available pods: 0
Sep  3 15:51:13.018: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 15:51:14.019: INFO: Number of nodes with available pods: 0
Sep  3 15:51:14.019: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 15:51:15.020: INFO: Number of nodes with available pods: 0
Sep  3 15:51:15.020: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 15:51:16.019: INFO: Number of nodes with available pods: 0
Sep  3 15:51:16.019: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 15:51:17.018: INFO: Number of nodes with available pods: 0
Sep  3 15:51:17.018: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 15:51:18.018: INFO: Number of nodes with available pods: 0
Sep  3 15:51:18.018: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 15:51:19.018: INFO: Number of nodes with available pods: 0
Sep  3 15:51:19.018: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 15:51:20.025: INFO: Number of nodes with available pods: 0
Sep  3 15:51:20.025: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 15:51:21.018: INFO: Number of nodes with available pods: 0
Sep  3 15:51:21.018: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 15:51:22.018: INFO: Number of nodes with available pods: 0
Sep  3 15:51:22.018: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 15:51:23.018: INFO: Number of nodes with available pods: 0
Sep  3 15:51:23.018: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 15:51:24.018: INFO: Number of nodes with available pods: 0
Sep  3 15:51:24.018: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 15:51:25.018: INFO: Number of nodes with available pods: 0
Sep  3 15:51:25.018: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 15:51:26.018: INFO: Number of nodes with available pods: 0
Sep  3 15:51:26.018: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 15:51:27.018: INFO: Number of nodes with available pods: 0
Sep  3 15:51:27.018: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 15:51:28.018: INFO: Number of nodes with available pods: 0
Sep  3 15:51:28.018: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 15:51:29.018: INFO: Number of nodes with available pods: 0
Sep  3 15:51:29.018: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 15:51:30.018: INFO: Number of nodes with available pods: 0
Sep  3 15:51:30.018: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 15:51:31.025: INFO: Number of nodes with available pods: 0
Sep  3 15:51:31.025: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 15:51:32.019: INFO: Number of nodes with available pods: 0
Sep  3 15:51:32.019: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 15:51:33.018: INFO: Number of nodes with available pods: 0
Sep  3 15:51:33.018: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 15:51:34.018: INFO: Number of nodes with available pods: 0
Sep  3 15:51:34.018: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 15:51:35.019: INFO: Number of nodes with available pods: 0
Sep  3 15:51:35.019: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 15:51:36.018: INFO: Number of nodes with available pods: 0
Sep  3 15:51:36.018: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 15:51:37.018: INFO: Number of nodes with available pods: 0
Sep  3 15:51:37.018: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 15:51:38.018: INFO: Number of nodes with available pods: 0
Sep  3 15:51:38.018: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 15:51:39.018: INFO: Number of nodes with available pods: 0
Sep  3 15:51:39.018: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 15:51:40.018: INFO: Number of nodes with available pods: 0
Sep  3 15:51:40.018: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 15:51:41.018: INFO: Number of nodes with available pods: 1
Sep  3 15:51:41.018: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-kgckh, will wait for the garbage collector to delete the pods
Sep  3 15:51:41.180: INFO: Deleting DaemonSet.extensions daemon-set took: 32.451949ms
Sep  3 15:51:41.280: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.231507ms
Sep  3 15:52:19.392: INFO: Number of nodes with available pods: 0
Sep  3 15:52:19.393: INFO: Number of running nodes: 0, number of available pods: 0
Sep  3 15:52:19.398: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-kgckh/daemonsets","resourceVersion":"620192"},"items":null}

Sep  3 15:52:19.403: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-kgckh/pods","resourceVersion":"620192"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:52:19.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-kgckh" for this suite.
Sep  3 15:52:25.476: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:52:26.028: INFO: namespace: e2e-tests-daemonsets-kgckh, resource: bindings, ignored listing per whitelist
Sep  3 15:52:26.538: INFO: namespace e2e-tests-daemonsets-kgckh deletion completed in 7.10836151s

• [SLOW TEST:90.952 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:52:26.538: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-mp2lb
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-mp2lb
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-mp2lb
Sep  3 15:52:26.773: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Sep  3 15:52:36.787: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Sep  3 15:52:36.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 exec --namespace=e2e-tests-statefulset-mp2lb ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  3 15:52:37.176: INFO: stderr: ""
Sep  3 15:52:37.176: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  3 15:52:37.176: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  3 15:52:37.182: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Sep  3 15:52:47.406: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep  3 15:52:47.407: INFO: Waiting for statefulset status.replicas updated to 0
Sep  3 15:52:47.478: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999583s
Sep  3 15:52:48.485: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.994170495s
Sep  3 15:52:49.491: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.987296086s
Sep  3 15:52:50.497: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.980954221s
Sep  3 15:52:51.505: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.974550682s
Sep  3 15:52:52.511: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.967323081s
Sep  3 15:52:53.518: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.960661165s
Sep  3 15:52:54.524: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.954127738s
Sep  3 15:52:55.530: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.947804886s
Sep  3 15:52:56.536: INFO: Verifying statefulset ss doesn't scale past 1 for another 941.712022ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-mp2lb
Sep  3 15:52:57.550: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 exec --namespace=e2e-tests-statefulset-mp2lb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  3 15:52:57.982: INFO: stderr: ""
Sep  3 15:52:57.982: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  3 15:52:57.982: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  3 15:52:57.991: INFO: Found 1 stateful pods, waiting for 3
Sep  3 15:53:08.006: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Sep  3 15:53:08.006: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Sep  3 15:53:08.006: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Sep  3 15:53:08.016: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 exec --namespace=e2e-tests-statefulset-mp2lb ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  3 15:53:08.575: INFO: stderr: ""
Sep  3 15:53:08.575: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  3 15:53:08.575: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  3 15:53:08.575: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 exec --namespace=e2e-tests-statefulset-mp2lb ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  3 15:53:08.967: INFO: stderr: ""
Sep  3 15:53:08.967: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  3 15:53:08.967: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  3 15:53:08.967: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 exec --namespace=e2e-tests-statefulset-mp2lb ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  3 15:53:09.415: INFO: stderr: ""
Sep  3 15:53:09.415: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  3 15:53:09.415: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  3 15:53:09.415: INFO: Waiting for statefulset status.replicas updated to 0
Sep  3 15:53:09.458: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Sep  3 15:53:19.476: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep  3 15:53:19.476: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Sep  3 15:53:19.476: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Sep  3 15:53:19.496: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999732s
Sep  3 15:53:20.502: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.992383003s
Sep  3 15:53:21.509: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.986016549s
Sep  3 15:53:22.515: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.979203016s
Sep  3 15:53:23.522: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.972613742s
Sep  3 15:53:24.528: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.965918062s
Sep  3 15:53:25.535: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.9597744s
Sep  3 15:53:26.541: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.953519521s
Sep  3 15:53:27.548: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.946747341s
Sep  3 15:53:28.556: INFO: Verifying statefulset ss doesn't scale past 3 for another 939.557656ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-mp2lb
Sep  3 15:53:29.570: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 exec --namespace=e2e-tests-statefulset-mp2lb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  3 15:53:29.965: INFO: stderr: ""
Sep  3 15:53:29.965: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  3 15:53:29.965: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  3 15:53:29.965: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 exec --namespace=e2e-tests-statefulset-mp2lb ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  3 15:53:30.354: INFO: stderr: ""
Sep  3 15:53:30.354: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  3 15:53:30.354: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  3 15:53:30.354: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 exec --namespace=e2e-tests-statefulset-mp2lb ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  3 15:53:30.783: INFO: stderr: ""
Sep  3 15:53:30.783: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  3 15:53:30.783: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  3 15:53:30.783: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Sep  3 15:53:50.808: INFO: Deleting all statefulset in ns e2e-tests-statefulset-mp2lb
Sep  3 15:53:50.844: INFO: Scaling statefulset ss to 0
Sep  3 15:53:50.869: INFO: Waiting for statefulset status.replicas updated to 0
Sep  3 15:53:50.874: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:53:50.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-mp2lb" for this suite.
Sep  3 15:53:57.063: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:53:57.323: INFO: namespace: e2e-tests-statefulset-mp2lb, resource: bindings, ignored listing per whitelist
Sep  3 15:53:57.913: INFO: namespace e2e-tests-statefulset-mp2lb deletion completed in 6.919446803s

• [SLOW TEST:91.375 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:53:57.913: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Sep  3 15:54:04.178: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-snn6m PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  3 15:54:04.178: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
Sep  3 15:54:04.447: INFO: Exec stderr: ""
Sep  3 15:54:04.447: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-snn6m PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  3 15:54:04.447: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
Sep  3 15:54:04.895: INFO: Exec stderr: ""
Sep  3 15:54:04.895: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-snn6m PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  3 15:54:04.895: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
Sep  3 15:54:05.139: INFO: Exec stderr: ""
Sep  3 15:54:05.140: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-snn6m PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  3 15:54:05.140: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
Sep  3 15:54:05.374: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Sep  3 15:54:05.374: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-snn6m PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  3 15:54:05.374: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
Sep  3 15:54:05.594: INFO: Exec stderr: ""
Sep  3 15:54:05.595: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-snn6m PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  3 15:54:05.595: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
Sep  3 15:54:05.806: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Sep  3 15:54:05.806: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-snn6m PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  3 15:54:05.806: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
Sep  3 15:54:06.041: INFO: Exec stderr: ""
Sep  3 15:54:06.041: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-snn6m PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  3 15:54:06.041: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
Sep  3 15:54:06.326: INFO: Exec stderr: ""
Sep  3 15:54:06.326: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-snn6m PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  3 15:54:06.326: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
Sep  3 15:54:06.650: INFO: Exec stderr: ""
Sep  3 15:54:06.650: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-snn6m PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  3 15:54:06.650: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
Sep  3 15:54:06.913: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:54:06.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-snn6m" for this suite.
Sep  3 15:54:53.005: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:54:53.221: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-snn6m, resource: bindings, ignored listing per whitelist
Sep  3 15:54:53.967: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-snn6m deletion completed in 47.028709562s

• [SLOW TEST:56.054 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:54:53.967: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-2bab42ce-ce63-11e9-a956-0a580af40009
STEP: Creating a pod to test consume configMaps
Sep  3 15:54:54.182: INFO: Waiting up to 5m0s for pod "pod-configmaps-2baf3c8e-ce63-11e9-a956-0a580af40009" in namespace "e2e-tests-configmap-b98hc" to be "success or failure"
Sep  3 15:54:54.211: INFO: Pod "pod-configmaps-2baf3c8e-ce63-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 29.332447ms
Sep  3 15:54:56.218: INFO: Pod "pod-configmaps-2baf3c8e-ce63-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.035820458s
STEP: Saw pod success
Sep  3 15:54:56.218: INFO: Pod "pod-configmaps-2baf3c8e-ce63-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 15:54:56.223: INFO: Trying to get logs from node 10.0.10.2 pod pod-configmaps-2baf3c8e-ce63-11e9-a956-0a580af40009 container configmap-volume-test: <nil>
STEP: delete the pod
Sep  3 15:54:56.388: INFO: Waiting for pod pod-configmaps-2baf3c8e-ce63-11e9-a956-0a580af40009 to disappear
Sep  3 15:54:56.415: INFO: Pod pod-configmaps-2baf3c8e-ce63-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:54:56.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-b98hc" for this suite.
Sep  3 15:55:02.486: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:55:05.045: INFO: namespace: e2e-tests-configmap-b98hc, resource: bindings, ignored listing per whitelist
Sep  3 15:55:05.073: INFO: namespace e2e-tests-configmap-b98hc deletion completed in 8.651973883s

• [SLOW TEST:11.106 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:55:05.073: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Sep  3 15:55:05.828: INFO: created pod pod-service-account-defaultsa
Sep  3 15:55:05.828: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Sep  3 15:55:05.834: INFO: created pod pod-service-account-mountsa
Sep  3 15:55:05.834: INFO: pod pod-service-account-mountsa service account token volume mount: true
Sep  3 15:55:05.841: INFO: created pod pod-service-account-nomountsa
Sep  3 15:55:05.841: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Sep  3 15:55:05.849: INFO: created pod pod-service-account-defaultsa-mountspec
Sep  3 15:55:05.849: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Sep  3 15:55:05.855: INFO: created pod pod-service-account-mountsa-mountspec
Sep  3 15:55:05.856: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Sep  3 15:55:05.863: INFO: created pod pod-service-account-nomountsa-mountspec
Sep  3 15:55:05.863: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Sep  3 15:55:05.870: INFO: created pod pod-service-account-defaultsa-nomountspec
Sep  3 15:55:05.870: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Sep  3 15:55:05.877: INFO: created pod pod-service-account-mountsa-nomountspec
Sep  3 15:55:05.877: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Sep  3 15:55:05.883: INFO: created pod pod-service-account-nomountsa-nomountspec
Sep  3 15:55:05.883: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:55:05.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-xrr7h" for this suite.
Sep  3 15:55:29.950: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:55:30.104: INFO: namespace: e2e-tests-svcaccounts-xrr7h, resource: bindings, ignored listing per whitelist
Sep  3 15:55:30.840: INFO: namespace e2e-tests-svcaccounts-xrr7h deletion completed in 24.952061087s

• [SLOW TEST:25.767 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:55:30.840: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Sep  3 15:55:33.615: INFO: Successfully updated pod "labelsupdate41a2b434-ce63-11e9-a956-0a580af40009"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:55:37.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-jnbbj" for this suite.
Sep  3 15:55:59.739: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:56:00.039: INFO: namespace: e2e-tests-downward-api-jnbbj, resource: bindings, ignored listing per whitelist
Sep  3 15:56:00.728: INFO: namespace e2e-tests-downward-api-jnbbj deletion completed in 23.055783297s

• [SLOW TEST:29.888 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:56:00.728: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0903 15:56:11.025968      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep  3 15:56:11.026: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:56:11.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-bwgmv" for this suite.
Sep  3 15:56:17.097: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:56:17.280: INFO: namespace: e2e-tests-gc-bwgmv, resource: bindings, ignored listing per whitelist
Sep  3 15:56:17.923: INFO: namespace e2e-tests-gc-bwgmv deletion completed in 6.891610824s

• [SLOW TEST:17.194 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:56:17.923: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Sep  3 15:56:20.696: INFO: Successfully updated pod "annotationupdate5db2ef95-ce63-11e9-a956-0a580af40009"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:56:24.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-w42fb" for this suite.
Sep  3 15:56:47.096: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:56:47.143: INFO: namespace: e2e-tests-projected-w42fb, resource: bindings, ignored listing per whitelist
Sep  3 15:56:48.152: INFO: namespace e2e-tests-projected-w42fb deletion completed in 23.399214797s

• [SLOW TEST:30.229 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:56:48.152: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-tntvq
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-tntvq
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-tntvq
Sep  3 15:56:48.508: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Sep  3 15:56:58.522: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Sep  3 15:56:58.528: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 exec --namespace=e2e-tests-statefulset-tntvq ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  3 15:56:58.960: INFO: stderr: ""
Sep  3 15:56:58.960: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  3 15:56:58.960: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  3 15:56:58.967: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Sep  3 15:57:08.980: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep  3 15:57:08.980: INFO: Waiting for statefulset status.replicas updated to 0
Sep  3 15:57:09.057: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Sep  3 15:57:09.057: INFO: ss-0  10.0.10.2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:56:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:56:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:56:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:56:48 +0000 UTC  }]
Sep  3 15:57:09.057: INFO: 
Sep  3 15:57:09.057: INFO: StatefulSet ss has not reached scale 3, at 1
Sep  3 15:57:10.065: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.993251132s
Sep  3 15:57:11.072: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.985267069s
Sep  3 15:57:12.079: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.978448255s
Sep  3 15:57:13.086: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.971251264s
Sep  3 15:57:14.091: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.964980575s
Sep  3 15:57:15.098: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.959076048s
Sep  3 15:57:16.120: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.95245009s
Sep  3 15:57:17.126: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.930743071s
Sep  3 15:57:18.133: INFO: Verifying statefulset ss doesn't scale past 3 for another 924.316258ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-tntvq
Sep  3 15:57:19.148: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 exec --namespace=e2e-tests-statefulset-tntvq ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  3 15:57:19.492: INFO: stderr: ""
Sep  3 15:57:19.492: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  3 15:57:19.492: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  3 15:57:19.492: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 exec --namespace=e2e-tests-statefulset-tntvq ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  3 15:57:19.896: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Sep  3 15:57:19.896: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  3 15:57:19.896: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  3 15:57:19.896: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 exec --namespace=e2e-tests-statefulset-tntvq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  3 15:57:20.289: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Sep  3 15:57:20.289: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  3 15:57:20.289: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  3 15:57:20.296: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Sep  3 15:57:20.296: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Sep  3 15:57:20.296: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Sep  3 15:57:20.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 exec --namespace=e2e-tests-statefulset-tntvq ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  3 15:57:20.687: INFO: stderr: ""
Sep  3 15:57:20.687: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  3 15:57:20.687: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  3 15:57:20.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 exec --namespace=e2e-tests-statefulset-tntvq ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  3 15:57:21.078: INFO: stderr: ""
Sep  3 15:57:21.078: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  3 15:57:21.078: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  3 15:57:21.078: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 exec --namespace=e2e-tests-statefulset-tntvq ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  3 15:57:21.493: INFO: stderr: ""
Sep  3 15:57:21.493: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  3 15:57:21.493: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  3 15:57:21.493: INFO: Waiting for statefulset status.replicas updated to 0
Sep  3 15:57:21.499: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Sep  3 15:57:31.519: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep  3 15:57:31.519: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Sep  3 15:57:31.519: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Sep  3 15:57:31.536: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Sep  3 15:57:31.536: INFO: ss-0  10.0.10.2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:56:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:57:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:57:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:56:48 +0000 UTC  }]
Sep  3 15:57:31.536: INFO: ss-1  10.0.10.2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:57:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:57:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:57:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:57:09 +0000 UTC  }]
Sep  3 15:57:31.536: INFO: ss-2  10.0.10.2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:57:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:57:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:57:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:57:09 +0000 UTC  }]
Sep  3 15:57:31.536: INFO: 
Sep  3 15:57:31.536: INFO: StatefulSet ss has not reached scale 0, at 3
Sep  3 15:57:32.542: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Sep  3 15:57:32.542: INFO: ss-0  10.0.10.2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:56:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:57:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:57:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:56:48 +0000 UTC  }]
Sep  3 15:57:32.542: INFO: ss-1  10.0.10.2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:57:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:57:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:57:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:57:09 +0000 UTC  }]
Sep  3 15:57:32.542: INFO: ss-2  10.0.10.2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:57:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:57:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:57:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:57:09 +0000 UTC  }]
Sep  3 15:57:32.542: INFO: 
Sep  3 15:57:32.542: INFO: StatefulSet ss has not reached scale 0, at 3
Sep  3 15:57:33.549: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Sep  3 15:57:33.549: INFO: ss-0  10.0.10.2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:56:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:57:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:57:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:56:48 +0000 UTC  }]
Sep  3 15:57:33.549: INFO: ss-1  10.0.10.2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:57:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:57:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:57:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:57:09 +0000 UTC  }]
Sep  3 15:57:33.549: INFO: ss-2  10.0.10.2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:57:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:57:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:57:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 15:57:09 +0000 UTC  }]
Sep  3 15:57:33.549: INFO: 
Sep  3 15:57:33.549: INFO: StatefulSet ss has not reached scale 0, at 3
Sep  3 15:57:34.555: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.981025469s
Sep  3 15:57:35.562: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.974695023s
Sep  3 15:57:36.568: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.968525514s
Sep  3 15:57:37.574: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.962142435s
Sep  3 15:57:38.580: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.956337074s
Sep  3 15:57:39.798: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.950068006s
Sep  3 15:57:40.803: INFO: Verifying statefulset ss doesn't scale past 0 for another 732.460084ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-tntvq
Sep  3 15:57:41.816: INFO: Scaling statefulset ss to 0
Sep  3 15:57:41.832: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Sep  3 15:57:41.837: INFO: Deleting all statefulset in ns e2e-tests-statefulset-tntvq
Sep  3 15:57:41.870: INFO: Scaling statefulset ss to 0
Sep  3 15:57:41.886: INFO: Waiting for statefulset status.replicas updated to 0
Sep  3 15:57:41.892: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:57:41.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-tntvq" for this suite.
Sep  3 15:57:50.026: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:57:50.085: INFO: namespace: e2e-tests-statefulset-tntvq, resource: bindings, ignored listing per whitelist
Sep  3 15:57:50.835: INFO: namespace e2e-tests-statefulset-tntvq deletion completed in 8.871022752s

• [SLOW TEST:62.683 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:57:50.836: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-95162da1-ce63-11e9-a956-0a580af40009
STEP: Creating a pod to test consume secrets
Sep  3 15:57:51.043: INFO: Waiting up to 5m0s for pod "pod-secrets-951a8b30-ce63-11e9-a956-0a580af40009" in namespace "e2e-tests-secrets-n8fc9" to be "success or failure"
Sep  3 15:57:51.070: INFO: Pod "pod-secrets-951a8b30-ce63-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 27.036485ms
Sep  3 15:57:53.083: INFO: Pod "pod-secrets-951a8b30-ce63-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.039993907s
STEP: Saw pod success
Sep  3 15:57:53.083: INFO: Pod "pod-secrets-951a8b30-ce63-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 15:57:53.089: INFO: Trying to get logs from node 10.0.10.2 pod pod-secrets-951a8b30-ce63-11e9-a956-0a580af40009 container secret-env-test: <nil>
STEP: delete the pod
Sep  3 15:57:53.155: INFO: Waiting for pod pod-secrets-951a8b30-ce63-11e9-a956-0a580af40009 to disappear
Sep  3 15:57:53.183: INFO: Pod pod-secrets-951a8b30-ce63-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:57:53.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-n8fc9" for this suite.
Sep  3 15:57:59.250: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:57:59.589: INFO: namespace: e2e-tests-secrets-n8fc9, resource: bindings, ignored listing per whitelist
Sep  3 15:58:00.177: INFO: namespace e2e-tests-secrets-n8fc9 deletion completed in 6.988962458s

• [SLOW TEST:9.342 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:58:00.177: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:58:06.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-xmrmh" for this suite.
Sep  3 15:58:12.572: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:58:13.426: INFO: namespace: e2e-tests-namespaces-xmrmh, resource: bindings, ignored listing per whitelist
Sep  3 15:58:13.496: INFO: namespace e2e-tests-namespaces-xmrmh deletion completed in 6.991322047s
STEP: Destroying namespace "e2e-tests-nsdeletetest-vhf97" for this suite.
Sep  3 15:58:13.501: INFO: Namespace e2e-tests-nsdeletetest-vhf97 was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-rngnx" for this suite.
Sep  3 15:58:19.562: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:58:19.853: INFO: namespace: e2e-tests-nsdeletetest-rngnx, resource: bindings, ignored listing per whitelist
Sep  3 15:58:20.487: INFO: namespace e2e-tests-nsdeletetest-rngnx deletion completed in 6.986340133s

• [SLOW TEST:20.310 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:58:20.488: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:58:20.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-zv4wc" for this suite.
Sep  3 15:58:32.759: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:58:32.833: INFO: namespace: e2e-tests-kubelet-test-zv4wc, resource: bindings, ignored listing per whitelist
Sep  3 15:58:33.648: INFO: namespace e2e-tests-kubelet-test-zv4wc deletion completed in 12.955436094s

• [SLOW TEST:13.160 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:58:33.648: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Sep  3 15:58:33.829: INFO: Waiting up to 5m0s for pod "pod-ae9b33f5-ce63-11e9-a956-0a580af40009" in namespace "e2e-tests-emptydir-2jdxz" to be "success or failure"
Sep  3 15:58:33.857: INFO: Pod "pod-ae9b33f5-ce63-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 28.200004ms
Sep  3 15:58:35.871: INFO: Pod "pod-ae9b33f5-ce63-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.042277773s
STEP: Saw pod success
Sep  3 15:58:35.871: INFO: Pod "pod-ae9b33f5-ce63-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 15:58:35.879: INFO: Trying to get logs from node 10.0.10.2 pod pod-ae9b33f5-ce63-11e9-a956-0a580af40009 container test-container: <nil>
STEP: delete the pod
Sep  3 15:58:35.959: INFO: Waiting for pod pod-ae9b33f5-ce63-11e9-a956-0a580af40009 to disappear
Sep  3 15:58:35.990: INFO: Pod pod-ae9b33f5-ce63-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:58:35.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-2jdxz" for this suite.
Sep  3 15:58:42.054: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:58:42.332: INFO: namespace: e2e-tests-emptydir-2jdxz, resource: bindings, ignored listing per whitelist
Sep  3 15:58:42.925: INFO: namespace e2e-tests-emptydir-2jdxz deletion completed in 6.92900896s

• [SLOW TEST:9.277 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:58:42.925: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Sep  3 15:58:43.097: INFO: Waiting up to 5m0s for pod "downward-api-b4212bea-ce63-11e9-a956-0a580af40009" in namespace "e2e-tests-downward-api-xdwx5" to be "success or failure"
Sep  3 15:58:43.125: INFO: Pod "downward-api-b4212bea-ce63-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 28.001151ms
Sep  3 15:58:45.132: INFO: Pod "downward-api-b4212bea-ce63-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.034761383s
STEP: Saw pod success
Sep  3 15:58:45.132: INFO: Pod "downward-api-b4212bea-ce63-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 15:58:45.138: INFO: Trying to get logs from node 10.0.10.2 pod downward-api-b4212bea-ce63-11e9-a956-0a580af40009 container dapi-container: <nil>
STEP: delete the pod
Sep  3 15:58:45.298: INFO: Waiting for pod downward-api-b4212bea-ce63-11e9-a956-0a580af40009 to disappear
Sep  3 15:58:45.323: INFO: Pod downward-api-b4212bea-ce63-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:58:45.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-xdwx5" for this suite.
Sep  3 15:58:51.393: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:58:52.005: INFO: namespace: e2e-tests-downward-api-xdwx5, resource: bindings, ignored listing per whitelist
Sep  3 15:58:52.319: INFO: namespace e2e-tests-downward-api-xdwx5 deletion completed in 6.990672692s

• [SLOW TEST:9.394 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:58:52.319: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Sep  3 15:58:52.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 cluster-info'
Sep  3 15:58:52.709: INFO: stderr: ""
Sep  3 15:58:52.709: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:58:52.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-dvh6b" for this suite.
Sep  3 15:58:58.789: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:58:58.878: INFO: namespace: e2e-tests-kubectl-dvh6b, resource: bindings, ignored listing per whitelist
Sep  3 15:58:59.692: INFO: namespace e2e-tests-kubectl-dvh6b deletion completed in 6.977220159s

• [SLOW TEST:7.373 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:58:59.693: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:59:10.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-bw9jg" for this suite.
Sep  3 15:59:33.061: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:59:34.037: INFO: namespace: e2e-tests-replication-controller-bw9jg, resource: bindings, ignored listing per whitelist
Sep  3 15:59:34.065: INFO: namespace e2e-tests-replication-controller-bw9jg deletion completed in 23.091564017s

• [SLOW TEST:34.372 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:59:34.066: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Sep  3 15:59:34.234: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d29c216c-ce63-11e9-a956-0a580af40009" in namespace "e2e-tests-projected-g24fs" to be "success or failure"
Sep  3 15:59:34.272: INFO: Pod "downwardapi-volume-d29c216c-ce63-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 37.282571ms
Sep  3 15:59:36.278: INFO: Pod "downwardapi-volume-d29c216c-ce63-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.04342386s
STEP: Saw pod success
Sep  3 15:59:36.278: INFO: Pod "downwardapi-volume-d29c216c-ce63-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 15:59:36.283: INFO: Trying to get logs from node 10.0.10.2 pod downwardapi-volume-d29c216c-ce63-11e9-a956-0a580af40009 container client-container: <nil>
STEP: delete the pod
Sep  3 15:59:36.388: INFO: Waiting for pod downwardapi-volume-d29c216c-ce63-11e9-a956-0a580af40009 to disappear
Sep  3 15:59:36.413: INFO: Pod downwardapi-volume-d29c216c-ce63-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:59:36.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-g24fs" for this suite.
Sep  3 15:59:42.485: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:59:43.136: INFO: namespace: e2e-tests-projected-g24fs, resource: bindings, ignored listing per whitelist
Sep  3 15:59:43.343: INFO: namespace e2e-tests-projected-g24fs deletion completed in 6.923520353s

• [SLOW TEST:9.277 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:59:43.343: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  3 15:59:43.492: INFO: Creating ReplicaSet my-hostname-basic-d82577b3-ce63-11e9-a956-0a580af40009
Sep  3 15:59:43.546: INFO: Pod name my-hostname-basic-d82577b3-ce63-11e9-a956-0a580af40009: Found 1 pods out of 1
Sep  3 15:59:43.546: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-d82577b3-ce63-11e9-a956-0a580af40009" is running
Sep  3 15:59:45.579: INFO: Pod "my-hostname-basic-d82577b3-ce63-11e9-a956-0a580af40009-28v4v" is running (conditions: [{Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-03 15:59:43 +0000 UTC Reason: Message:}])
Sep  3 15:59:45.579: INFO: Trying to dial the pod
Sep  3 15:59:50.881: INFO: Controller my-hostname-basic-d82577b3-ce63-11e9-a956-0a580af40009: Got expected result from replica 1 [my-hostname-basic-d82577b3-ce63-11e9-a956-0a580af40009-28v4v]: "my-hostname-basic-d82577b3-ce63-11e9-a956-0a580af40009-28v4v", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 15:59:50.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-xc8jg" for this suite.
Sep  3 15:59:56.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 15:59:57.458: INFO: namespace: e2e-tests-replicaset-xc8jg, resource: bindings, ignored listing per whitelist
Sep  3 15:59:57.792: INFO: namespace e2e-tests-replicaset-xc8jg deletion completed in 6.904290865s

• [SLOW TEST:14.449 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 15:59:57.792: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  3 15:59:58.000: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep  3 16:00:00.030: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Sep  3 16:00:02.058: INFO: Creating deployment "test-rollover-deployment"
Sep  3 16:00:02.113: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Sep  3 16:00:04.125: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Sep  3 16:00:04.163: INFO: Ensure that both replica sets have 1 created replica
Sep  3 16:00:04.175: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Sep  3 16:00:04.207: INFO: Updating deployment test-rollover-deployment
Sep  3 16:00:04.207: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Sep  3 16:00:06.226: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Sep  3 16:00:06.237: INFO: Make sure deployment "test-rollover-deployment" is complete
Sep  3 16:00:06.248: INFO: all replica sets need to contain the pod-template-hash label
Sep  3 16:00:06.248: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703123202, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703123202, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703123206, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703123202, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  3 16:00:08.260: INFO: all replica sets need to contain the pod-template-hash label
Sep  3 16:00:08.260: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703123202, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703123202, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703123206, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703123202, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  3 16:00:10.260: INFO: all replica sets need to contain the pod-template-hash label
Sep  3 16:00:10.260: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703123202, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703123202, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703123206, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703123202, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  3 16:00:12.260: INFO: all replica sets need to contain the pod-template-hash label
Sep  3 16:00:12.260: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703123202, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703123202, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703123206, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703123202, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  3 16:00:14.260: INFO: all replica sets need to contain the pod-template-hash label
Sep  3 16:00:14.260: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703123202, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703123202, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703123206, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703123202, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  3 16:00:16.267: INFO: 
Sep  3 16:00:16.267: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Sep  3 16:00:16.345: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-7v4cv,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-7v4cv/deployments/test-rollover-deployment,UID:e33a2f15-ce63-11e9-9b93-0a580aed0c4f,ResourceVersion:622045,Generation:2,CreationTimestamp:2019-09-03 16:00:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-09-03 16:00:02 +0000 UTC 2019-09-03 16:00:02 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-09-03 16:00:16 +0000 UTC 2019-09-03 16:00:02 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-6b7f9d6597" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Sep  3 16:00:16.352: INFO: New ReplicaSet "test-rollover-deployment-6b7f9d6597" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597,GenerateName:,Namespace:e2e-tests-deployment-7v4cv,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-7v4cv/replicasets/test-rollover-deployment-6b7f9d6597,UID:e47e8fc3-ce63-11e9-9b93-0a580aed0c4f,ResourceVersion:622036,Generation:2,CreationTimestamp:2019-09-03 16:00:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment e33a2f15-ce63-11e9-9b93-0a580aed0c4f 0xc002909577 0xc002909578}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Sep  3 16:00:16.352: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Sep  3 16:00:16.352: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-7v4cv,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-7v4cv/replicasets/test-rollover-controller,UID:e0c6f6a5-ce63-11e9-9b93-0a580aed0c4f,ResourceVersion:622044,Generation:2,CreationTimestamp:2019-09-03 15:59:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment e33a2f15-ce63-11e9-9b93-0a580aed0c4f 0xc0029093e7 0xc0029093e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep  3 16:00:16.353: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6586df867b,GenerateName:,Namespace:e2e-tests-deployment-7v4cv,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-7v4cv/replicasets/test-rollover-deployment-6586df867b,UID:e33e81e2-ce63-11e9-9b93-0a580aed0c4f,ResourceVersion:622000,Generation:2,CreationTimestamp:2019-09-03 16:00:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment e33a2f15-ce63-11e9-9b93-0a580aed0c4f 0xc0029094a7 0xc0029094a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep  3 16:00:16.359: INFO: Pod "test-rollover-deployment-6b7f9d6597-w7wcs" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597-w7wcs,GenerateName:test-rollover-deployment-6b7f9d6597-,Namespace:e2e-tests-deployment-7v4cv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7v4cv/pods/test-rollover-deployment-6b7f9d6597-w7wcs,UID:e48462d9-ce63-11e9-9b93-0a580aed0c4f,ResourceVersion:622014,Generation:0,CreationTimestamp:2019-09-03 16:00:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-6b7f9d6597 e47e8fc3-ce63-11e9-9b93-0a580aed0c4f 0xc002943427 0xc002943428}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-j74xn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j74xn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-j74xn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0029434a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0029434c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 16:00:04 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 16:00:06 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 16:00:06 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 16:00:04 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.2,PodIP:10.244.0.147,StartTime:2019-09-03 16:00:04 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-09-03 16:00:05 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://5afdf2a5e4166622a31b5f0648ee6682a489e7aa7adce6740e0a80bd8d8e8eee}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:00:16.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-7v4cv" for this suite.
Sep  3 16:00:22.426: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:00:23.022: INFO: namespace: e2e-tests-deployment-7v4cv, resource: bindings, ignored listing per whitelist
Sep  3 16:00:23.236: INFO: namespace e2e-tests-deployment-7v4cv deletion completed in 6.871724002s

• [SLOW TEST:25.444 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:00:23.237: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-dcjqc/configmap-test-efe92a3e-ce63-11e9-a956-0a580af40009
STEP: Creating a pod to test consume configMaps
Sep  3 16:00:23.419: INFO: Waiting up to 5m0s for pod "pod-configmaps-efed0e98-ce63-11e9-a956-0a580af40009" in namespace "e2e-tests-configmap-dcjqc" to be "success or failure"
Sep  3 16:00:23.448: INFO: Pod "pod-configmaps-efed0e98-ce63-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 29.067553ms
Sep  3 16:00:25.454: INFO: Pod "pod-configmaps-efed0e98-ce63-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.035476633s
STEP: Saw pod success
Sep  3 16:00:25.454: INFO: Pod "pod-configmaps-efed0e98-ce63-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 16:00:25.460: INFO: Trying to get logs from node 10.0.10.2 pod pod-configmaps-efed0e98-ce63-11e9-a956-0a580af40009 container env-test: <nil>
STEP: delete the pod
Sep  3 16:00:25.867: INFO: Waiting for pod pod-configmaps-efed0e98-ce63-11e9-a956-0a580af40009 to disappear
Sep  3 16:00:25.929: INFO: Pod pod-configmaps-efed0e98-ce63-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:00:25.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-dcjqc" for this suite.
Sep  3 16:00:31.994: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:00:32.005: INFO: namespace: e2e-tests-configmap-dcjqc, resource: bindings, ignored listing per whitelist
Sep  3 16:00:32.866: INFO: namespace e2e-tests-configmap-dcjqc deletion completed in 6.931283571s

• [SLOW TEST:9.629 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:00:32.866: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1052
STEP: creating the pod
Sep  3 16:00:32.996: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 create -f - --namespace=e2e-tests-kubectl-7vnql'
Sep  3 16:00:33.259: INFO: stderr: ""
Sep  3 16:00:33.259: INFO: stdout: "pod/pause created\n"
Sep  3 16:00:33.259: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Sep  3 16:00:33.259: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-7vnql" to be "running and ready"
Sep  3 16:00:33.285: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 25.568966ms
Sep  3 16:00:35.290: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.031272863s
Sep  3 16:00:35.290: INFO: Pod "pause" satisfied condition "running and ready"
Sep  3 16:00:35.291: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Sep  3 16:00:35.291: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-7vnql'
Sep  3 16:00:35.457: INFO: stderr: ""
Sep  3 16:00:35.457: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Sep  3 16:00:35.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 get pod pause -L testing-label --namespace=e2e-tests-kubectl-7vnql'
Sep  3 16:00:35.574: INFO: stderr: ""
Sep  3 16:00:35.574: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Sep  3 16:00:35.574: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 label pods pause testing-label- --namespace=e2e-tests-kubectl-7vnql'
Sep  3 16:00:35.702: INFO: stderr: ""
Sep  3 16:00:35.702: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Sep  3 16:00:35.702: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 get pod pause -L testing-label --namespace=e2e-tests-kubectl-7vnql'
Sep  3 16:00:35.793: INFO: stderr: ""
Sep  3 16:00:35.793: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1059
STEP: using delete to clean up resources
Sep  3 16:00:35.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-7vnql'
Sep  3 16:00:35.911: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  3 16:00:35.911: INFO: stdout: "pod \"pause\" force deleted\n"
Sep  3 16:00:35.911: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-7vnql'
Sep  3 16:00:36.168: INFO: stderr: "No resources found.\n"
Sep  3 16:00:36.168: INFO: stdout: ""
Sep  3 16:00:36.168: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 get pods -l name=pause --namespace=e2e-tests-kubectl-7vnql -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep  3 16:00:36.330: INFO: stderr: ""
Sep  3 16:00:36.330: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:00:36.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-7vnql" for this suite.
Sep  3 16:00:42.396: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:00:42.992: INFO: namespace: e2e-tests-kubectl-7vnql, resource: bindings, ignored listing per whitelist
Sep  3 16:00:43.291: INFO: namespace e2e-tests-kubectl-7vnql deletion completed in 6.95381433s

• [SLOW TEST:10.424 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:00:43.291: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Sep  3 16:00:43.526: INFO: Waiting up to 5m0s for pod "client-containers-fbe99364-ce63-11e9-a956-0a580af40009" in namespace "e2e-tests-containers-6gzl4" to be "success or failure"
Sep  3 16:00:43.613: INFO: Pod "client-containers-fbe99364-ce63-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 86.355541ms
Sep  3 16:00:45.620: INFO: Pod "client-containers-fbe99364-ce63-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.093315308s
STEP: Saw pod success
Sep  3 16:00:45.620: INFO: Pod "client-containers-fbe99364-ce63-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 16:00:45.625: INFO: Trying to get logs from node 10.0.10.2 pod client-containers-fbe99364-ce63-11e9-a956-0a580af40009 container test-container: <nil>
STEP: delete the pod
Sep  3 16:00:45.795: INFO: Waiting for pod client-containers-fbe99364-ce63-11e9-a956-0a580af40009 to disappear
Sep  3 16:00:45.820: INFO: Pod client-containers-fbe99364-ce63-11e9-a956-0a580af40009 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:00:45.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-6gzl4" for this suite.
Sep  3 16:00:51.890: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:00:52.099: INFO: namespace: e2e-tests-containers-6gzl4, resource: bindings, ignored listing per whitelist
Sep  3 16:00:52.759: INFO: namespace e2e-tests-containers-6gzl4 deletion completed in 6.932878233s

• [SLOW TEST:9.468 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:00:52.759: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Sep  3 16:00:52.931: INFO: Waiting up to 5m0s for pod "downward-api-01840a31-ce64-11e9-a956-0a580af40009" in namespace "e2e-tests-downward-api-l8gzt" to be "success or failure"
Sep  3 16:00:52.958: INFO: Pod "downward-api-01840a31-ce64-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 26.157162ms
Sep  3 16:00:54.964: INFO: Pod "downward-api-01840a31-ce64-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.032340478s
STEP: Saw pod success
Sep  3 16:00:54.964: INFO: Pod "downward-api-01840a31-ce64-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 16:00:54.970: INFO: Trying to get logs from node 10.0.10.2 pod downward-api-01840a31-ce64-11e9-a956-0a580af40009 container dapi-container: <nil>
STEP: delete the pod
Sep  3 16:00:55.057: INFO: Waiting for pod downward-api-01840a31-ce64-11e9-a956-0a580af40009 to disappear
Sep  3 16:00:55.084: INFO: Pod downward-api-01840a31-ce64-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:00:55.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-l8gzt" for this suite.
Sep  3 16:01:01.162: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:01:01.231: INFO: namespace: e2e-tests-downward-api-l8gzt, resource: bindings, ignored listing per whitelist
Sep  3 16:01:02.094: INFO: namespace e2e-tests-downward-api-l8gzt deletion completed in 7.002692497s

• [SLOW TEST:9.335 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:01:02.095: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  3 16:01:02.222: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-72whs'
Sep  3 16:01:02.341: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep  3 16:01:02.341: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Sep  3 16:01:02.368: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-72whs'
Sep  3 16:01:02.536: INFO: stderr: ""
Sep  3 16:01:02.537: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:01:02.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-72whs" for this suite.
Sep  3 16:01:24.614: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:01:25.484: INFO: namespace: e2e-tests-kubectl-72whs, resource: bindings, ignored listing per whitelist
Sep  3 16:01:25.559: INFO: namespace e2e-tests-kubectl-72whs deletion completed in 23.01702161s

• [SLOW TEST:23.465 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:01:25.560: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-15101098-ce64-11e9-a956-0a580af40009
STEP: Creating a pod to test consume configMaps
Sep  3 16:01:25.752: INFO: Waiting up to 5m0s for pod "pod-configmaps-1514360f-ce64-11e9-a956-0a580af40009" in namespace "e2e-tests-configmap-2r2xf" to be "success or failure"
Sep  3 16:01:25.981: INFO: Pod "pod-configmaps-1514360f-ce64-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 229.217065ms
Sep  3 16:01:27.987: INFO: Pod "pod-configmaps-1514360f-ce64-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.234951735s
STEP: Saw pod success
Sep  3 16:01:27.987: INFO: Pod "pod-configmaps-1514360f-ce64-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 16:01:27.992: INFO: Trying to get logs from node 10.0.10.2 pod pod-configmaps-1514360f-ce64-11e9-a956-0a580af40009 container configmap-volume-test: <nil>
STEP: delete the pod
Sep  3 16:01:28.084: INFO: Waiting for pod pod-configmaps-1514360f-ce64-11e9-a956-0a580af40009 to disappear
Sep  3 16:01:28.110: INFO: Pod pod-configmaps-1514360f-ce64-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:01:28.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-2r2xf" for this suite.
Sep  3 16:01:34.175: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:01:34.644: INFO: namespace: e2e-tests-configmap-2r2xf, resource: bindings, ignored listing per whitelist
Sep  3 16:01:34.974: INFO: namespace e2e-tests-configmap-2r2xf deletion completed in 6.857958515s

• [SLOW TEST:9.414 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:01:34.974: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:01:35.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-v5dsg" for this suite.
Sep  3 16:01:41.212: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:01:41.465: INFO: namespace: e2e-tests-services-v5dsg, resource: bindings, ignored listing per whitelist
Sep  3 16:01:42.026: INFO: namespace e2e-tests-services-v5dsg deletion completed in 6.879642378s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:7.052 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:01:42.026: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Sep  3 16:01:42.197: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1ee18990-ce64-11e9-a956-0a580af40009" in namespace "e2e-tests-downward-api-l2nt5" to be "success or failure"
Sep  3 16:01:42.223: INFO: Pod "downwardapi-volume-1ee18990-ce64-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 25.711699ms
Sep  3 16:01:44.231: INFO: Pod "downwardapi-volume-1ee18990-ce64-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.033924537s
STEP: Saw pod success
Sep  3 16:01:44.231: INFO: Pod "downwardapi-volume-1ee18990-ce64-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 16:01:44.236: INFO: Trying to get logs from node 10.0.10.2 pod downwardapi-volume-1ee18990-ce64-11e9-a956-0a580af40009 container client-container: <nil>
STEP: delete the pod
Sep  3 16:01:44.307: INFO: Waiting for pod downwardapi-volume-1ee18990-ce64-11e9-a956-0a580af40009 to disappear
Sep  3 16:01:44.333: INFO: Pod downwardapi-volume-1ee18990-ce64-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:01:44.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-l2nt5" for this suite.
Sep  3 16:01:50.413: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:01:51.238: INFO: namespace: e2e-tests-downward-api-l2nt5, resource: bindings, ignored listing per whitelist
Sep  3 16:01:51.238: INFO: namespace e2e-tests-downward-api-l2nt5 deletion completed in 6.898700677s

• [SLOW TEST:9.212 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:01:51.238: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  3 16:01:51.399: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-tr98d'
Sep  3 16:01:51.522: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep  3 16:01:51.522: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1404
Sep  3 16:01:53.575: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-tr98d'
Sep  3 16:01:53.705: INFO: stderr: ""
Sep  3 16:01:53.705: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:01:53.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-tr98d" for this suite.
Sep  3 16:02:15.768: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:02:16.359: INFO: namespace: e2e-tests-kubectl-tr98d, resource: bindings, ignored listing per whitelist
Sep  3 16:02:16.616: INFO: namespace e2e-tests-kubectl-tr98d deletion completed in 22.904068916s

• [SLOW TEST:25.378 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:02:16.616: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Sep  3 16:02:16.804: INFO: Waiting up to 5m0s for pod "downward-api-3382564c-ce64-11e9-a956-0a580af40009" in namespace "e2e-tests-downward-api-wxd89" to be "success or failure"
Sep  3 16:02:16.829: INFO: Pod "downward-api-3382564c-ce64-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 25.34569ms
Sep  3 16:02:18.836: INFO: Pod "downward-api-3382564c-ce64-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.031632257s
STEP: Saw pod success
Sep  3 16:02:18.836: INFO: Pod "downward-api-3382564c-ce64-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 16:02:18.841: INFO: Trying to get logs from node 10.0.10.2 pod downward-api-3382564c-ce64-11e9-a956-0a580af40009 container dapi-container: <nil>
STEP: delete the pod
Sep  3 16:02:18.916: INFO: Waiting for pod downward-api-3382564c-ce64-11e9-a956-0a580af40009 to disappear
Sep  3 16:02:18.944: INFO: Pod downward-api-3382564c-ce64-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:02:18.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-wxd89" for this suite.
Sep  3 16:02:25.017: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:02:25.150: INFO: namespace: e2e-tests-downward-api-wxd89, resource: bindings, ignored listing per whitelist
Sep  3 16:02:25.904: INFO: namespace e2e-tests-downward-api-wxd89 deletion completed in 6.953645091s

• [SLOW TEST:9.288 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:02:25.904: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-390753cd-ce64-11e9-a956-0a580af40009
STEP: Creating secret with name secret-projected-all-test-volume-390753a0-ce64-11e9-a956-0a580af40009
STEP: Creating a pod to test Check all projections for projected volume plugin
Sep  3 16:02:26.124: INFO: Waiting up to 5m0s for pod "projected-volume-39075343-ce64-11e9-a956-0a580af40009" in namespace "e2e-tests-projected-m6wsp" to be "success or failure"
Sep  3 16:02:26.150: INFO: Pod "projected-volume-39075343-ce64-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 26.297418ms
Sep  3 16:02:28.156: INFO: Pod "projected-volume-39075343-ce64-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.032412733s
STEP: Saw pod success
Sep  3 16:02:28.156: INFO: Pod "projected-volume-39075343-ce64-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 16:02:28.162: INFO: Trying to get logs from node 10.0.10.2 pod projected-volume-39075343-ce64-11e9-a956-0a580af40009 container projected-all-volume-test: <nil>
STEP: delete the pod
Sep  3 16:02:28.246: INFO: Waiting for pod projected-volume-39075343-ce64-11e9-a956-0a580af40009 to disappear
Sep  3 16:02:28.274: INFO: Pod projected-volume-39075343-ce64-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:02:28.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-m6wsp" for this suite.
Sep  3 16:02:34.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:02:35.049: INFO: namespace: e2e-tests-projected-m6wsp, resource: bindings, ignored listing per whitelist
Sep  3 16:02:35.216: INFO: namespace e2e-tests-projected-m6wsp deletion completed in 6.936189751s

• [SLOW TEST:9.312 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:02:35.216: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Sep  3 16:02:35.392: INFO: Waiting up to 5m0s for pod "pod-3e9637dd-ce64-11e9-a956-0a580af40009" in namespace "e2e-tests-emptydir-sdlqz" to be "success or failure"
Sep  3 16:02:35.426: INFO: Pod "pod-3e9637dd-ce64-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 34.356131ms
Sep  3 16:02:37.434: INFO: Pod "pod-3e9637dd-ce64-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.042133674s
STEP: Saw pod success
Sep  3 16:02:37.434: INFO: Pod "pod-3e9637dd-ce64-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 16:02:37.439: INFO: Trying to get logs from node 10.0.10.2 pod pod-3e9637dd-ce64-11e9-a956-0a580af40009 container test-container: <nil>
STEP: delete the pod
Sep  3 16:02:37.517: INFO: Waiting for pod pod-3e9637dd-ce64-11e9-a956-0a580af40009 to disappear
Sep  3 16:02:37.545: INFO: Pod pod-3e9637dd-ce64-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:02:37.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-sdlqz" for this suite.
Sep  3 16:02:43.620: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:02:44.145: INFO: namespace: e2e-tests-emptydir-sdlqz, resource: bindings, ignored listing per whitelist
Sep  3 16:02:44.512: INFO: namespace e2e-tests-emptydir-sdlqz deletion completed in 6.961607529s

• [SLOW TEST:9.296 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:02:44.513: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-9225s
Sep  3 16:02:46.712: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-9225s
STEP: checking the pod's current state and verifying that restartCount is present
Sep  3 16:02:46.718: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:06:47.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-9225s" for this suite.
Sep  3 16:06:53.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:06:54.593: INFO: namespace: e2e-tests-container-probe-9225s, resource: bindings, ignored listing per whitelist
Sep  3 16:06:54.986: INFO: namespace e2e-tests-container-probe-9225s deletion completed in 7.226352732s

• [SLOW TEST:250.473 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:06:54.986: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-9s4hl
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-9s4hl
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-9s4hl
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-9s4hl
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-9s4hl
Sep  3 16:06:57.293: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-9s4hl, name: ss-0, uid: da508ac1-ce64-11e9-9b93-0a580aed0c4f, status phase: Pending. Waiting for statefulset controller to delete.
Sep  3 16:06:57.808: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-9s4hl, name: ss-0, uid: da508ac1-ce64-11e9-9b93-0a580aed0c4f, status phase: Failed. Waiting for statefulset controller to delete.
Sep  3 16:06:57.818: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-9s4hl, name: ss-0, uid: da508ac1-ce64-11e9-9b93-0a580aed0c4f, status phase: Failed. Waiting for statefulset controller to delete.
Sep  3 16:06:57.823: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-9s4hl
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-9s4hl
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-9s4hl and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Sep  3 16:07:01.897: INFO: Deleting all statefulset in ns e2e-tests-statefulset-9s4hl
Sep  3 16:07:01.931: INFO: Scaling statefulset ss to 0
Sep  3 16:07:12.029: INFO: Waiting for statefulset status.replicas updated to 0
Sep  3 16:07:12.034: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:07:12.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-9s4hl" for this suite.
Sep  3 16:07:18.185: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:07:18.642: INFO: namespace: e2e-tests-statefulset-9s4hl, resource: bindings, ignored listing per whitelist
Sep  3 16:07:18.972: INFO: namespace e2e-tests-statefulset-9s4hl deletion completed in 6.849236496s

• [SLOW TEST:23.986 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:07:18.973: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Sep  3 16:07:19.136: INFO: Waiting up to 5m0s for pod "var-expansion-e7b69555-ce64-11e9-a956-0a580af40009" in namespace "e2e-tests-var-expansion-bsb5m" to be "success or failure"
Sep  3 16:07:19.163: INFO: Pod "var-expansion-e7b69555-ce64-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 27.351953ms
Sep  3 16:07:21.169: INFO: Pod "var-expansion-e7b69555-ce64-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.033575314s
STEP: Saw pod success
Sep  3 16:07:21.169: INFO: Pod "var-expansion-e7b69555-ce64-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 16:07:21.175: INFO: Trying to get logs from node 10.0.10.2 pod var-expansion-e7b69555-ce64-11e9-a956-0a580af40009 container dapi-container: <nil>
STEP: delete the pod
Sep  3 16:07:21.285: INFO: Waiting for pod var-expansion-e7b69555-ce64-11e9-a956-0a580af40009 to disappear
Sep  3 16:07:21.309: INFO: Pod var-expansion-e7b69555-ce64-11e9-a956-0a580af40009 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:07:21.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-bsb5m" for this suite.
Sep  3 16:07:27.380: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:07:27.485: INFO: namespace: e2e-tests-var-expansion-bsb5m, resource: bindings, ignored listing per whitelist
Sep  3 16:07:28.230: INFO: namespace e2e-tests-var-expansion-bsb5m deletion completed in 6.915027256s

• [SLOW TEST:9.257 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:07:28.230: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Sep  3 16:07:28.537: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-hcpww,SelfLink:/api/v1/namespaces/e2e-tests-watch-hcpww/configmaps/e2e-watch-test-resource-version,UID:ed42a3bc-ce64-11e9-9b93-0a580aed0c4f,ResourceVersion:623376,Generation:0,CreationTimestamp:2019-09-03 16:07:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep  3 16:07:28.537: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-hcpww,SelfLink:/api/v1/namespaces/e2e-tests-watch-hcpww/configmaps/e2e-watch-test-resource-version,UID:ed42a3bc-ce64-11e9-9b93-0a580aed0c4f,ResourceVersion:623377,Generation:0,CreationTimestamp:2019-09-03 16:07:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:07:28.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-hcpww" for this suite.
Sep  3 16:07:34.625: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:07:34.660: INFO: namespace: e2e-tests-watch-hcpww, resource: bindings, ignored listing per whitelist
Sep  3 16:07:35.904: INFO: namespace e2e-tests-watch-hcpww deletion completed in 7.361727321s

• [SLOW TEST:7.674 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:07:35.905: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0903 16:07:42.204634      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep  3 16:07:42.204: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:07:42.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-7bffn" for this suite.
Sep  3 16:07:48.278: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:07:48.880: INFO: namespace: e2e-tests-gc-7bffn, resource: bindings, ignored listing per whitelist
Sep  3 16:07:49.190: INFO: namespace e2e-tests-gc-7bffn deletion completed in 6.979646393s

• [SLOW TEST:13.285 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:07:49.190: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-f9b8d5d1-ce64-11e9-a956-0a580af40009
STEP: Creating a pod to test consume configMaps
Sep  3 16:07:49.378: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f9bd3ecc-ce64-11e9-a956-0a580af40009" in namespace "e2e-tests-projected-8bkgt" to be "success or failure"
Sep  3 16:07:49.409: INFO: Pod "pod-projected-configmaps-f9bd3ecc-ce64-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 30.173463ms
Sep  3 16:07:51.415: INFO: Pod "pod-projected-configmaps-f9bd3ecc-ce64-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.036807782s
STEP: Saw pod success
Sep  3 16:07:51.415: INFO: Pod "pod-projected-configmaps-f9bd3ecc-ce64-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 16:07:51.422: INFO: Trying to get logs from node 10.0.10.2 pod pod-projected-configmaps-f9bd3ecc-ce64-11e9-a956-0a580af40009 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  3 16:07:51.515: INFO: Waiting for pod pod-projected-configmaps-f9bd3ecc-ce64-11e9-a956-0a580af40009 to disappear
Sep  3 16:07:51.539: INFO: Pod pod-projected-configmaps-f9bd3ecc-ce64-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:07:51.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8bkgt" for this suite.
Sep  3 16:07:57.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:07:58.135: INFO: namespace: e2e-tests-projected-8bkgt, resource: bindings, ignored listing per whitelist
Sep  3 16:07:58.508: INFO: namespace e2e-tests-projected-8bkgt deletion completed in 6.963684434s

• [SLOW TEST:9.318 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:07:58.509: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:08:00.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-w7j9x" for this suite.
Sep  3 16:08:56.927: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:08:56.938: INFO: namespace: e2e-tests-kubelet-test-w7j9x, resource: bindings, ignored listing per whitelist
Sep  3 16:08:58.052: INFO: namespace e2e-tests-kubelet-test-w7j9x deletion completed in 57.195647729s

• [SLOW TEST:59.544 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:08:58.052: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-22c666e3-ce65-11e9-a956-0a580af40009
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:09:00.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-9kjs8" for this suite.
Sep  3 16:09:22.435: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:09:23.415: INFO: namespace: e2e-tests-configmap-9kjs8, resource: bindings, ignored listing per whitelist
Sep  3 16:09:23.415: INFO: namespace e2e-tests-configmap-9kjs8 deletion completed in 23.058528487s

• [SLOW TEST:25.363 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:09:23.415: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-31e33ebe-ce65-11e9-a956-0a580af40009
STEP: Creating a pod to test consume configMaps
Sep  3 16:09:23.613: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-31e7ab42-ce65-11e9-a956-0a580af40009" in namespace "e2e-tests-projected-pk66q" to be "success or failure"
Sep  3 16:09:23.637: INFO: Pod "pod-projected-configmaps-31e7ab42-ce65-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 24.554673ms
Sep  3 16:09:25.644: INFO: Pod "pod-projected-configmaps-31e7ab42-ce65-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030930097s
STEP: Saw pod success
Sep  3 16:09:25.644: INFO: Pod "pod-projected-configmaps-31e7ab42-ce65-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 16:09:25.649: INFO: Trying to get logs from node 10.0.10.2 pod pod-projected-configmaps-31e7ab42-ce65-11e9-a956-0a580af40009 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  3 16:09:25.872: INFO: Waiting for pod pod-projected-configmaps-31e7ab42-ce65-11e9-a956-0a580af40009 to disappear
Sep  3 16:09:25.901: INFO: Pod pod-projected-configmaps-31e7ab42-ce65-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:09:25.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pk66q" for this suite.
Sep  3 16:09:31.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:09:32.747: INFO: namespace: e2e-tests-projected-pk66q, resource: bindings, ignored listing per whitelist
Sep  3 16:09:32.851: INFO: namespace e2e-tests-projected-pk66q deletion completed in 6.944420302s

• [SLOW TEST:9.436 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:09:32.851: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Sep  3 16:09:34.501: INFO: Number of nodes with available pods: 0
Sep  3 16:09:34.501: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 16:09:35.727: INFO: Number of nodes with available pods: 0
Sep  3 16:09:35.727: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 16:09:36.513: INFO: Number of nodes with available pods: 1
Sep  3 16:09:36.513: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Sep  3 16:09:36.586: INFO: Number of nodes with available pods: 0
Sep  3 16:09:36.586: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 16:09:37.598: INFO: Number of nodes with available pods: 0
Sep  3 16:09:37.598: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 16:09:38.598: INFO: Number of nodes with available pods: 1
Sep  3 16:09:38.598: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-7lcxw, will wait for the garbage collector to delete the pods
Sep  3 16:09:38.767: INFO: Deleting DaemonSet.extensions daemon-set took: 30.781324ms
Sep  3 16:09:38.867: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.203445ms
Sep  3 16:10:11.979: INFO: Number of nodes with available pods: 0
Sep  3 16:10:11.979: INFO: Number of running nodes: 0, number of available pods: 0
Sep  3 16:10:11.984: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-7lcxw/daemonsets","resourceVersion":"624017"},"items":null}

Sep  3 16:10:11.989: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-7lcxw/pods","resourceVersion":"624017"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:10:12.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-7lcxw" for this suite.
Sep  3 16:10:18.055: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:10:18.260: INFO: namespace: e2e-tests-daemonsets-7lcxw, resource: bindings, ignored listing per whitelist
Sep  3 16:10:18.864: INFO: namespace e2e-tests-daemonsets-7lcxw deletion completed in 6.85755163s

• [SLOW TEST:46.013 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:10:18.864: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Sep  3 16:10:19.589: INFO: Waiting up to 5m0s for pod "pod-service-account-5345758c-ce65-11e9-a956-0a580af40009-5jh64" in namespace "e2e-tests-svcaccounts-8lqrg" to be "success or failure"
Sep  3 16:10:19.615: INFO: Pod "pod-service-account-5345758c-ce65-11e9-a956-0a580af40009-5jh64": Phase="Pending", Reason="", readiness=false. Elapsed: 25.658147ms
Sep  3 16:10:21.621: INFO: Pod "pod-service-account-5345758c-ce65-11e9-a956-0a580af40009-5jh64": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.032402236s
STEP: Saw pod success
Sep  3 16:10:21.622: INFO: Pod "pod-service-account-5345758c-ce65-11e9-a956-0a580af40009-5jh64" satisfied condition "success or failure"
Sep  3 16:10:21.627: INFO: Trying to get logs from node 10.0.10.2 pod pod-service-account-5345758c-ce65-11e9-a956-0a580af40009-5jh64 container token-test: <nil>
STEP: delete the pod
Sep  3 16:10:21.844: INFO: Waiting for pod pod-service-account-5345758c-ce65-11e9-a956-0a580af40009-5jh64 to disappear
Sep  3 16:10:21.873: INFO: Pod pod-service-account-5345758c-ce65-11e9-a956-0a580af40009-5jh64 no longer exists
STEP: Creating a pod to test consume service account root CA
Sep  3 16:10:21.900: INFO: Waiting up to 5m0s for pod "pod-service-account-5345758c-ce65-11e9-a956-0a580af40009-5mjfs" in namespace "e2e-tests-svcaccounts-8lqrg" to be "success or failure"
Sep  3 16:10:21.928: INFO: Pod "pod-service-account-5345758c-ce65-11e9-a956-0a580af40009-5mjfs": Phase="Pending", Reason="", readiness=false. Elapsed: 28.380017ms
Sep  3 16:10:23.941: INFO: Pod "pod-service-account-5345758c-ce65-11e9-a956-0a580af40009-5mjfs": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041303559s
Sep  3 16:10:25.948: INFO: Pod "pod-service-account-5345758c-ce65-11e9-a956-0a580af40009-5mjfs": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047872935s
STEP: Saw pod success
Sep  3 16:10:25.948: INFO: Pod "pod-service-account-5345758c-ce65-11e9-a956-0a580af40009-5mjfs" satisfied condition "success or failure"
Sep  3 16:10:25.953: INFO: Trying to get logs from node 10.0.10.2 pod pod-service-account-5345758c-ce65-11e9-a956-0a580af40009-5mjfs container root-ca-test: <nil>
STEP: delete the pod
Sep  3 16:10:26.089: INFO: Waiting for pod pod-service-account-5345758c-ce65-11e9-a956-0a580af40009-5mjfs to disappear
Sep  3 16:10:26.094: INFO: Pod pod-service-account-5345758c-ce65-11e9-a956-0a580af40009-5mjfs no longer exists
STEP: Creating a pod to test consume service account namespace
Sep  3 16:10:26.101: INFO: Waiting up to 5m0s for pod "pod-service-account-5345758c-ce65-11e9-a956-0a580af40009-ph7js" in namespace "e2e-tests-svcaccounts-8lqrg" to be "success or failure"
Sep  3 16:10:26.128: INFO: Pod "pod-service-account-5345758c-ce65-11e9-a956-0a580af40009-ph7js": Phase="Pending", Reason="", readiness=false. Elapsed: 27.052744ms
Sep  3 16:10:28.135: INFO: Pod "pod-service-account-5345758c-ce65-11e9-a956-0a580af40009-ph7js": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033573078s
Sep  3 16:10:30.141: INFO: Pod "pod-service-account-5345758c-ce65-11e9-a956-0a580af40009-ph7js": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039676475s
STEP: Saw pod success
Sep  3 16:10:30.141: INFO: Pod "pod-service-account-5345758c-ce65-11e9-a956-0a580af40009-ph7js" satisfied condition "success or failure"
Sep  3 16:10:30.147: INFO: Trying to get logs from node 10.0.10.2 pod pod-service-account-5345758c-ce65-11e9-a956-0a580af40009-ph7js container namespace-test: <nil>
STEP: delete the pod
Sep  3 16:10:30.225: INFO: Waiting for pod pod-service-account-5345758c-ce65-11e9-a956-0a580af40009-ph7js to disappear
Sep  3 16:10:30.230: INFO: Pod pod-service-account-5345758c-ce65-11e9-a956-0a580af40009-ph7js no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:10:30.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-8lqrg" for this suite.
Sep  3 16:10:36.296: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:10:37.648: INFO: namespace: e2e-tests-svcaccounts-8lqrg, resource: bindings, ignored listing per whitelist
Sep  3 16:10:38.099: INFO: namespace e2e-tests-svcaccounts-8lqrg deletion completed in 7.862629128s

• [SLOW TEST:19.235 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:10:38.100: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Sep  3 16:10:38.239: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Sep  3 16:10:38.239: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 create -f - --namespace=e2e-tests-kubectl-89gm2'
Sep  3 16:10:38.690: INFO: stderr: ""
Sep  3 16:10:38.690: INFO: stdout: "service/redis-slave created\n"
Sep  3 16:10:38.690: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Sep  3 16:10:38.691: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 create -f - --namespace=e2e-tests-kubectl-89gm2'
Sep  3 16:10:39.011: INFO: stderr: ""
Sep  3 16:10:39.011: INFO: stdout: "service/redis-master created\n"
Sep  3 16:10:39.011: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Sep  3 16:10:39.011: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 create -f - --namespace=e2e-tests-kubectl-89gm2'
Sep  3 16:10:39.245: INFO: stderr: ""
Sep  3 16:10:39.245: INFO: stdout: "service/frontend created\n"
Sep  3 16:10:39.245: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Sep  3 16:10:39.245: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 create -f - --namespace=e2e-tests-kubectl-89gm2'
Sep  3 16:10:39.518: INFO: stderr: ""
Sep  3 16:10:39.518: INFO: stdout: "deployment.extensions/frontend created\n"
Sep  3 16:10:39.518: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Sep  3 16:10:39.518: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 create -f - --namespace=e2e-tests-kubectl-89gm2'
Sep  3 16:10:39.807: INFO: stderr: ""
Sep  3 16:10:39.807: INFO: stdout: "deployment.extensions/redis-master created\n"
Sep  3 16:10:39.807: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Sep  3 16:10:39.807: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 create -f - --namespace=e2e-tests-kubectl-89gm2'
Sep  3 16:10:40.156: INFO: stderr: ""
Sep  3 16:10:40.156: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Sep  3 16:10:40.156: INFO: Waiting for all frontend pods to be Running.
Sep  3 16:11:10.212: INFO: Waiting for frontend to serve content.
Sep  3 16:11:10.313: INFO: Trying to add a new entry to the guestbook.
Sep  3 16:11:10.407: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Sep  3 16:11:10.425: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-89gm2'
Sep  3 16:11:10.661: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  3 16:11:10.661: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Sep  3 16:11:10.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-89gm2'
Sep  3 16:11:10.813: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  3 16:11:10.813: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Sep  3 16:11:10.813: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-89gm2'
Sep  3 16:11:10.960: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  3 16:11:10.960: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Sep  3 16:11:10.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-89gm2'
Sep  3 16:11:11.104: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  3 16:11:11.104: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Sep  3 16:11:11.104: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-89gm2'
Sep  3 16:11:11.566: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  3 16:11:11.566: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Sep  3 16:11:11.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-89gm2'
Sep  3 16:11:11.863: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  3 16:11:11.863: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:11:11.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-89gm2" for this suite.
Sep  3 16:11:51.928: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:11:52.018: INFO: namespace: e2e-tests-kubectl-89gm2, resource: bindings, ignored listing per whitelist
Sep  3 16:11:52.730: INFO: namespace e2e-tests-kubectl-89gm2 deletion completed in 40.860574193s

• [SLOW TEST:74.630 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:11:52.730: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Sep  3 16:11:55.544: INFO: Successfully updated pod "annotationupdate8ae2b698-ce65-11e9-a956-0a580af40009"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:11:59.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-dvjs9" for this suite.
Sep  3 16:12:21.680: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:12:21.770: INFO: namespace: e2e-tests-downward-api-dvjs9, resource: bindings, ignored listing per whitelist
Sep  3 16:12:22.603: INFO: namespace e2e-tests-downward-api-dvjs9 deletion completed in 22.978816101s

• [SLOW TEST:29.873 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:12:22.604: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Sep  3 16:12:22.801: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9cb56227-ce65-11e9-a956-0a580af40009" in namespace "e2e-tests-projected-f52cc" to be "success or failure"
Sep  3 16:12:22.830: INFO: Pod "downwardapi-volume-9cb56227-ce65-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 28.883783ms
Sep  3 16:12:24.836: INFO: Pod "downwardapi-volume-9cb56227-ce65-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.03487034s
STEP: Saw pod success
Sep  3 16:12:24.836: INFO: Pod "downwardapi-volume-9cb56227-ce65-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 16:12:24.842: INFO: Trying to get logs from node 10.0.10.2 pod downwardapi-volume-9cb56227-ce65-11e9-a956-0a580af40009 container client-container: <nil>
STEP: delete the pod
Sep  3 16:12:24.986: INFO: Waiting for pod downwardapi-volume-9cb56227-ce65-11e9-a956-0a580af40009 to disappear
Sep  3 16:12:25.010: INFO: Pod downwardapi-volume-9cb56227-ce65-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:12:25.010: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-f52cc" for this suite.
Sep  3 16:12:31.080: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:12:31.512: INFO: namespace: e2e-tests-projected-f52cc, resource: bindings, ignored listing per whitelist
Sep  3 16:12:31.915: INFO: namespace e2e-tests-projected-f52cc deletion completed in 6.899779506s

• [SLOW TEST:9.311 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:12:31.916: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Sep  3 16:12:32.047: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep  3 16:12:32.059: INFO: Waiting for terminating namespaces to be deleted...
Sep  3 16:12:32.088: INFO: 
Logging pods the kubelet thinks is on node 10.0.10.2 before test
Sep  3 16:12:32.126: INFO: proxymux-client-10.0.10.2 from kube-system started at <nil> (0 container statuses recorded)
Sep  3 16:12:32.126: INFO: sonobuoy from heptio-sonobuoy started at 2019-09-03 15:20:23 +0000 UTC (1 container statuses recorded)
Sep  3 16:12:32.126: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep  3 16:12:32.126: INFO: sonobuoy-e2e-job-a1e56c6fdf4c4de0 from heptio-sonobuoy started at 2019-09-03 15:20:25 +0000 UTC (2 container statuses recorded)
Sep  3 16:12:32.126: INFO: 	Container e2e ready: true, restart count 0
Sep  3 16:12:32.126: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  3 16:12:32.126: INFO: kube-flannel-ds-vsts9 from kube-system started at 2019-08-30 21:27:39 +0000 UTC (1 container statuses recorded)
Sep  3 16:12:32.126: INFO: 	Container kube-flannel ready: true, restart count 1
Sep  3 16:12:32.126: INFO: kube-dns-autoscaler-84cf5956b-9dvmg from kube-system started at 2019-08-30 21:27:59 +0000 UTC (1 container statuses recorded)
Sep  3 16:12:32.126: INFO: 	Container autoscaler ready: true, restart count 0
Sep  3 16:12:32.126: INFO: sonobuoy-systemd-logs-daemon-set-6c7ccfc0384b4617-nlhk5 from heptio-sonobuoy started at 2019-09-03 15:20:25 +0000 UTC (2 container statuses recorded)
Sep  3 16:12:32.126: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  3 16:12:32.126: INFO: 	Container systemd-logs ready: true, restart count 0
Sep  3 16:12:32.126: INFO: kube-dns-6b7d4d8994-8bv4d from kube-system started at 2019-08-30 21:27:59 +0000 UTC (3 container statuses recorded)
Sep  3 16:12:32.126: INFO: 	Container dnsmasq ready: true, restart count 0
Sep  3 16:12:32.126: INFO: 	Container kubedns ready: true, restart count 0
Sep  3 16:12:32.126: INFO: 	Container sidecar ready: true, restart count 0
Sep  3 16:12:32.126: INFO: tiller-deploy-b6d55488-ddll4 from kube-system started at 2019-08-30 21:27:59 +0000 UTC (1 container statuses recorded)
Sep  3 16:12:32.126: INFO: 	Container tiller ready: true, restart count 0
Sep  3 16:12:32.126: INFO: kubernetes-dashboard-697c7958df-6qjlq from kube-system started at 2019-08-30 21:27:59 +0000 UTC (1 container statuses recorded)
Sep  3 16:12:32.126: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Sep  3 16:12:32.126: INFO: kube-proxy-p5865 from kube-system started at 2019-08-30 21:27:39 +0000 UTC (1 container statuses recorded)
Sep  3 16:12:32.126: INFO: 	Container kube-proxy ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node 10.0.10.2
Sep  3 16:12:32.216: INFO: Pod sonobuoy requesting resource cpu=0m on Node 10.0.10.2
Sep  3 16:12:32.216: INFO: Pod sonobuoy-e2e-job-a1e56c6fdf4c4de0 requesting resource cpu=0m on Node 10.0.10.2
Sep  3 16:12:32.216: INFO: Pod sonobuoy-systemd-logs-daemon-set-6c7ccfc0384b4617-nlhk5 requesting resource cpu=0m on Node 10.0.10.2
Sep  3 16:12:32.216: INFO: Pod kube-dns-6b7d4d8994-8bv4d requesting resource cpu=260m on Node 10.0.10.2
Sep  3 16:12:32.216: INFO: Pod kube-dns-autoscaler-84cf5956b-9dvmg requesting resource cpu=20m on Node 10.0.10.2
Sep  3 16:12:32.216: INFO: Pod kube-flannel-ds-vsts9 requesting resource cpu=100m on Node 10.0.10.2
Sep  3 16:12:32.216: INFO: Pod kube-proxy-p5865 requesting resource cpu=0m on Node 10.0.10.2
Sep  3 16:12:32.216: INFO: Pod kubernetes-dashboard-697c7958df-6qjlq requesting resource cpu=0m on Node 10.0.10.2
Sep  3 16:12:32.216: INFO: Pod proxymux-client-10.0.10.2 requesting resource cpu=50m on Node 10.0.10.2
Sep  3 16:12:32.216: INFO: Pod tiller-deploy-b6d55488-ddll4 requesting resource cpu=0m on Node 10.0.10.2
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a257694a-ce65-11e9-a956-0a580af40009.15c0f9a3cdd97889], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-qwhc7/filler-pod-a257694a-ce65-11e9-a956-0a580af40009 to 10.0.10.2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a257694a-ce65-11e9-a956-0a580af40009.15c0f9a3fb43f7b0], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a257694a-ce65-11e9-a956-0a580af40009.15c0f9a3fd7b1094], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a257694a-ce65-11e9-a956-0a580af40009.15c0f9a4061ea88b], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15c0f9a449f2d6e3], Reason = [FailedScheduling], Message = [0/1 nodes are available: 1 Insufficient cpu.]
STEP: removing the label node off the node 10.0.10.2
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:12:35.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-qwhc7" for this suite.
Sep  3 16:12:41.497: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:12:41.922: INFO: namespace: e2e-tests-sched-pred-qwhc7, resource: bindings, ignored listing per whitelist
Sep  3 16:12:42.345: INFO: namespace e2e-tests-sched-pred-qwhc7 deletion completed in 6.921052913s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:10.430 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:12:42.347: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Sep  3 16:12:46.654: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  3 16:12:46.678: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  3 16:12:48.678: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  3 16:12:48.685: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  3 16:12:50.678: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  3 16:12:50.694: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  3 16:12:52.678: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  3 16:12:52.691: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  3 16:12:54.678: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  3 16:12:54.685: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  3 16:12:56.679: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  3 16:12:56.685: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  3 16:12:58.678: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  3 16:12:58.685: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  3 16:13:00.678: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  3 16:13:00.685: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  3 16:13:02.678: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  3 16:13:02.685: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  3 16:13:04.678: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  3 16:13:04.693: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  3 16:13:06.678: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  3 16:13:06.685: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  3 16:13:08.678: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  3 16:13:08.685: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  3 16:13:10.678: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  3 16:13:10.685: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:13:10.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-w7cfh" for this suite.
Sep  3 16:13:32.835: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:13:33.093: INFO: namespace: e2e-tests-container-lifecycle-hook-w7cfh, resource: bindings, ignored listing per whitelist
Sep  3 16:13:33.809: INFO: namespace e2e-tests-container-lifecycle-hook-w7cfh deletion completed in 23.052158409s

• [SLOW TEST:51.462 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:13:33.809: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Sep  3 16:13:33.942: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep  3 16:13:33.953: INFO: Waiting for terminating namespaces to be deleted...
Sep  3 16:13:33.958: INFO: 
Logging pods the kubelet thinks is on node 10.0.10.2 before test
Sep  3 16:13:33.971: INFO: kube-dns-autoscaler-84cf5956b-9dvmg from kube-system started at 2019-08-30 21:27:59 +0000 UTC (1 container statuses recorded)
Sep  3 16:13:33.971: INFO: 	Container autoscaler ready: true, restart count 0
Sep  3 16:13:33.971: INFO: sonobuoy-systemd-logs-daemon-set-6c7ccfc0384b4617-nlhk5 from heptio-sonobuoy started at 2019-09-03 15:20:25 +0000 UTC (2 container statuses recorded)
Sep  3 16:13:33.971: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  3 16:13:33.971: INFO: 	Container systemd-logs ready: true, restart count 0
Sep  3 16:13:33.971: INFO: kube-dns-6b7d4d8994-8bv4d from kube-system started at 2019-08-30 21:27:59 +0000 UTC (3 container statuses recorded)
Sep  3 16:13:33.971: INFO: 	Container dnsmasq ready: true, restart count 0
Sep  3 16:13:33.971: INFO: 	Container kubedns ready: true, restart count 0
Sep  3 16:13:33.971: INFO: 	Container sidecar ready: true, restart count 0
Sep  3 16:13:33.971: INFO: tiller-deploy-b6d55488-ddll4 from kube-system started at 2019-08-30 21:27:59 +0000 UTC (1 container statuses recorded)
Sep  3 16:13:33.971: INFO: 	Container tiller ready: true, restart count 0
Sep  3 16:13:33.971: INFO: kubernetes-dashboard-697c7958df-6qjlq from kube-system started at 2019-08-30 21:27:59 +0000 UTC (1 container statuses recorded)
Sep  3 16:13:33.971: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Sep  3 16:13:33.971: INFO: kube-proxy-p5865 from kube-system started at 2019-08-30 21:27:39 +0000 UTC (1 container statuses recorded)
Sep  3 16:13:33.971: INFO: 	Container kube-proxy ready: true, restart count 0
Sep  3 16:13:33.971: INFO: proxymux-client-10.0.10.2 from kube-system started at <nil> (0 container statuses recorded)
Sep  3 16:13:33.971: INFO: sonobuoy from heptio-sonobuoy started at 2019-09-03 15:20:23 +0000 UTC (1 container statuses recorded)
Sep  3 16:13:33.971: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep  3 16:13:33.971: INFO: sonobuoy-e2e-job-a1e56c6fdf4c4de0 from heptio-sonobuoy started at 2019-09-03 15:20:25 +0000 UTC (2 container statuses recorded)
Sep  3 16:13:33.971: INFO: 	Container e2e ready: true, restart count 0
Sep  3 16:13:33.971: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  3 16:13:33.971: INFO: kube-flannel-ds-vsts9 from kube-system started at 2019-08-30 21:27:39 +0000 UTC (1 container statuses recorded)
Sep  3 16:13:33.971: INFO: 	Container kube-flannel ready: true, restart count 1
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15c0f9b231a8db4b], Reason = [FailedScheduling], Message = [0/1 nodes are available: 1 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:13:35.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-s4k4h" for this suite.
Sep  3 16:13:41.155: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:13:41.833: INFO: namespace: e2e-tests-sched-pred-s4k4h, resource: bindings, ignored listing per whitelist
Sep  3 16:13:41.990: INFO: namespace e2e-tests-sched-pred-s4k4h deletion completed in 6.899476578s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:8.181 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:13:41.991: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Sep  3 16:13:42.124: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 create -f - --namespace=e2e-tests-kubectl-wzlrc'
Sep  3 16:13:42.387: INFO: stderr: ""
Sep  3 16:13:42.387: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep  3 16:13:42.387: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-wzlrc'
Sep  3 16:13:42.582: INFO: stderr: ""
Sep  3 16:13:42.582: INFO: stdout: "update-demo-nautilus-fjs7x update-demo-nautilus-xdd67 "
Sep  3 16:13:42.582: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 get pods update-demo-nautilus-fjs7x -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wzlrc'
Sep  3 16:13:42.716: INFO: stderr: ""
Sep  3 16:13:42.716: INFO: stdout: ""
Sep  3 16:13:42.716: INFO: update-demo-nautilus-fjs7x is created but not running
Sep  3 16:13:47.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-wzlrc'
Sep  3 16:13:47.839: INFO: stderr: ""
Sep  3 16:13:47.839: INFO: stdout: "update-demo-nautilus-fjs7x update-demo-nautilus-xdd67 "
Sep  3 16:13:47.839: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 get pods update-demo-nautilus-fjs7x -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wzlrc'
Sep  3 16:13:47.928: INFO: stderr: ""
Sep  3 16:13:47.928: INFO: stdout: "true"
Sep  3 16:13:47.928: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 get pods update-demo-nautilus-fjs7x -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wzlrc'
Sep  3 16:13:48.008: INFO: stderr: ""
Sep  3 16:13:48.008: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  3 16:13:48.008: INFO: validating pod update-demo-nautilus-fjs7x
Sep  3 16:13:48.099: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  3 16:13:48.099: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  3 16:13:48.099: INFO: update-demo-nautilus-fjs7x is verified up and running
Sep  3 16:13:48.099: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 get pods update-demo-nautilus-xdd67 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wzlrc'
Sep  3 16:13:48.201: INFO: stderr: ""
Sep  3 16:13:48.201: INFO: stdout: "true"
Sep  3 16:13:48.201: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 get pods update-demo-nautilus-xdd67 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wzlrc'
Sep  3 16:13:48.307: INFO: stderr: ""
Sep  3 16:13:48.307: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  3 16:13:48.307: INFO: validating pod update-demo-nautilus-xdd67
Sep  3 16:13:48.452: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  3 16:13:48.452: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  3 16:13:48.452: INFO: update-demo-nautilus-xdd67 is verified up and running
STEP: rolling-update to new replication controller
Sep  3 16:13:48.454: INFO: scanned /root for discovery docs: <nil>
Sep  3 16:13:48.454: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-wzlrc'
Sep  3 16:14:11.171: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Sep  3 16:14:11.171: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep  3 16:14:11.172: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-wzlrc'
Sep  3 16:14:11.270: INFO: stderr: ""
Sep  3 16:14:11.270: INFO: stdout: "update-demo-kitten-c88m8 update-demo-kitten-mgf46 "
Sep  3 16:14:11.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 get pods update-demo-kitten-c88m8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wzlrc'
Sep  3 16:14:11.389: INFO: stderr: ""
Sep  3 16:14:11.389: INFO: stdout: "true"
Sep  3 16:14:11.389: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 get pods update-demo-kitten-c88m8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wzlrc'
Sep  3 16:14:11.480: INFO: stderr: ""
Sep  3 16:14:11.480: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Sep  3 16:14:11.480: INFO: validating pod update-demo-kitten-c88m8
Sep  3 16:14:11.590: INFO: got data: {
  "image": "kitten.jpg"
}

Sep  3 16:14:11.590: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Sep  3 16:14:11.590: INFO: update-demo-kitten-c88m8 is verified up and running
Sep  3 16:14:11.590: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 get pods update-demo-kitten-mgf46 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wzlrc'
Sep  3 16:14:11.699: INFO: stderr: ""
Sep  3 16:14:11.699: INFO: stdout: "true"
Sep  3 16:14:11.699: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 get pods update-demo-kitten-mgf46 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wzlrc'
Sep  3 16:14:11.813: INFO: stderr: ""
Sep  3 16:14:11.813: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Sep  3 16:14:11.813: INFO: validating pod update-demo-kitten-mgf46
Sep  3 16:14:11.921: INFO: got data: {
  "image": "kitten.jpg"
}

Sep  3 16:14:11.921: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Sep  3 16:14:11.921: INFO: update-demo-kitten-mgf46 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:14:11.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wzlrc" for this suite.
Sep  3 16:14:35.987: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:14:36.498: INFO: namespace: e2e-tests-kubectl-wzlrc, resource: bindings, ignored listing per whitelist
Sep  3 16:14:36.923: INFO: namespace e2e-tests-kubectl-wzlrc deletion completed in 24.994744004s

• [SLOW TEST:54.932 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:14:36.923: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-ece2454e-ce65-11e9-a956-0a580af40009
STEP: Creating a pod to test consume configMaps
Sep  3 16:14:37.338: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ece6a209-ce65-11e9-a956-0a580af40009" in namespace "e2e-tests-projected-ztj8m" to be "success or failure"
Sep  3 16:14:37.372: INFO: Pod "pod-projected-configmaps-ece6a209-ce65-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 34.330922ms
Sep  3 16:14:39.379: INFO: Pod "pod-projected-configmaps-ece6a209-ce65-11e9-a956-0a580af40009": Phase="Running", Reason="", readiness=true. Elapsed: 2.040513073s
Sep  3 16:14:41.385: INFO: Pod "pod-projected-configmaps-ece6a209-ce65-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.046848752s
STEP: Saw pod success
Sep  3 16:14:41.385: INFO: Pod "pod-projected-configmaps-ece6a209-ce65-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 16:14:41.391: INFO: Trying to get logs from node 10.0.10.2 pod pod-projected-configmaps-ece6a209-ce65-11e9-a956-0a580af40009 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  3 16:14:41.461: INFO: Waiting for pod pod-projected-configmaps-ece6a209-ce65-11e9-a956-0a580af40009 to disappear
Sep  3 16:14:41.489: INFO: Pod pod-projected-configmaps-ece6a209-ce65-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:14:41.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ztj8m" for this suite.
Sep  3 16:14:47.563: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:14:47.787: INFO: namespace: e2e-tests-projected-ztj8m, resource: bindings, ignored listing per whitelist
Sep  3 16:14:48.431: INFO: namespace e2e-tests-projected-ztj8m deletion completed in 6.936721083s

• [SLOW TEST:11.508 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:14:48.432: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-csbf
STEP: Creating a pod to test atomic-volume-subpath
Sep  3 16:14:48.651: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-csbf" in namespace "e2e-tests-subpath-6l6wh" to be "success or failure"
Sep  3 16:14:48.677: INFO: Pod "pod-subpath-test-configmap-csbf": Phase="Pending", Reason="", readiness=false. Elapsed: 26.046859ms
Sep  3 16:14:50.684: INFO: Pod "pod-subpath-test-configmap-csbf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032898083s
Sep  3 16:14:52.690: INFO: Pod "pod-subpath-test-configmap-csbf": Phase="Running", Reason="", readiness=false. Elapsed: 4.038949196s
Sep  3 16:14:54.696: INFO: Pod "pod-subpath-test-configmap-csbf": Phase="Running", Reason="", readiness=false. Elapsed: 6.045277914s
Sep  3 16:14:56.709: INFO: Pod "pod-subpath-test-configmap-csbf": Phase="Running", Reason="", readiness=false. Elapsed: 8.058273195s
Sep  3 16:14:58.716: INFO: Pod "pod-subpath-test-configmap-csbf": Phase="Running", Reason="", readiness=false. Elapsed: 10.064913568s
Sep  3 16:15:00.722: INFO: Pod "pod-subpath-test-configmap-csbf": Phase="Running", Reason="", readiness=false. Elapsed: 12.071393109s
Sep  3 16:15:02.728: INFO: Pod "pod-subpath-test-configmap-csbf": Phase="Running", Reason="", readiness=false. Elapsed: 14.077446163s
Sep  3 16:15:04.735: INFO: Pod "pod-subpath-test-configmap-csbf": Phase="Running", Reason="", readiness=false. Elapsed: 16.083967779s
Sep  3 16:15:06.748: INFO: Pod "pod-subpath-test-configmap-csbf": Phase="Running", Reason="", readiness=false. Elapsed: 18.096629616s
Sep  3 16:15:08.754: INFO: Pod "pod-subpath-test-configmap-csbf": Phase="Running", Reason="", readiness=false. Elapsed: 20.102912609s
Sep  3 16:15:10.760: INFO: Pod "pod-subpath-test-configmap-csbf": Phase="Running", Reason="", readiness=false. Elapsed: 22.109225628s
Sep  3 16:15:12.766: INFO: Pod "pod-subpath-test-configmap-csbf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.115448907s
STEP: Saw pod success
Sep  3 16:15:12.766: INFO: Pod "pod-subpath-test-configmap-csbf" satisfied condition "success or failure"
Sep  3 16:15:12.773: INFO: Trying to get logs from node 10.0.10.2 pod pod-subpath-test-configmap-csbf container test-container-subpath-configmap-csbf: <nil>
STEP: delete the pod
Sep  3 16:15:12.854: INFO: Waiting for pod pod-subpath-test-configmap-csbf to disappear
Sep  3 16:15:12.881: INFO: Pod pod-subpath-test-configmap-csbf no longer exists
STEP: Deleting pod pod-subpath-test-configmap-csbf
Sep  3 16:15:12.881: INFO: Deleting pod "pod-subpath-test-configmap-csbf" in namespace "e2e-tests-subpath-6l6wh"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:15:12.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-6l6wh" for this suite.
Sep  3 16:15:18.952: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:15:19.681: INFO: namespace: e2e-tests-subpath-6l6wh, resource: bindings, ignored listing per whitelist
Sep  3 16:15:19.805: INFO: namespace e2e-tests-subpath-6l6wh deletion completed in 6.913029227s

• [SLOW TEST:31.373 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:15:19.805: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-06504a55-ce66-11e9-a956-0a580af40009
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-06504a55-ce66-11e9-a956-0a580af40009
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:15:24.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-f4bbc" for this suite.
Sep  3 16:15:46.324: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:15:46.879: INFO: namespace: e2e-tests-projected-f4bbc, resource: bindings, ignored listing per whitelist
Sep  3 16:15:47.421: INFO: namespace e2e-tests-projected-f4bbc deletion completed in 23.164432338s

• [SLOW TEST:27.616 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:15:47.422: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-5tm7x
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep  3 16:15:47.553: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep  3 16:16:07.747: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.0.202:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-5tm7x PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  3 16:16:07.747: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
Sep  3 16:16:08.080: INFO: Found all expected endpoints: [netserver-0]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:16:08.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-5tm7x" for this suite.
Sep  3 16:16:32.157: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:16:32.259: INFO: namespace: e2e-tests-pod-network-test-5tm7x, resource: bindings, ignored listing per whitelist
Sep  3 16:16:33.060: INFO: namespace e2e-tests-pod-network-test-5tm7x deletion completed in 24.973605002s

• [SLOW TEST:45.639 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:16:33.061: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Sep  3 16:16:33.191: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:16:36.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-kw96k" for this suite.
Sep  3 16:16:42.565: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:16:42.734: INFO: namespace: e2e-tests-init-container-kw96k, resource: bindings, ignored listing per whitelist
Sep  3 16:16:43.474: INFO: namespace e2e-tests-init-container-kw96k deletion completed in 6.973522526s

• [SLOW TEST:10.413 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:16:43.474: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Sep  3 16:16:43.609: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-043111098 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:16:43.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-tmvht" for this suite.
Sep  3 16:16:49.746: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:16:50.342: INFO: namespace: e2e-tests-kubectl-tmvht, resource: bindings, ignored listing per whitelist
Sep  3 16:16:50.640: INFO: namespace e2e-tests-kubectl-tmvht deletion completed in 6.955227368s

• [SLOW TEST:7.166 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:16:50.640: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-zsg7m
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Sep  3 16:16:50.853: INFO: Found 1 stateful pods, waiting for 3
Sep  3 16:17:00.867: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep  3 16:17:00.867: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep  3 16:17:00.867: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Sep  3 16:17:00.970: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Sep  3 16:17:11.023: INFO: Updating stateful set ss2
Sep  3 16:17:11.036: INFO: Waiting for Pod e2e-tests-statefulset-zsg7m/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Sep  3 16:17:21.156: INFO: Found 2 stateful pods, waiting for 3
Sep  3 16:17:31.170: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep  3 16:17:31.170: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep  3 16:17:31.170: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Sep  3 16:17:31.202: INFO: Updating stateful set ss2
Sep  3 16:17:31.213: INFO: Waiting for Pod e2e-tests-statefulset-zsg7m/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Sep  3 16:17:41.254: INFO: Updating stateful set ss2
Sep  3 16:17:41.265: INFO: Waiting for StatefulSet e2e-tests-statefulset-zsg7m/ss2 to complete update
Sep  3 16:17:41.265: INFO: Waiting for Pod e2e-tests-statefulset-zsg7m/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Sep  3 16:17:51.284: INFO: Waiting for StatefulSet e2e-tests-statefulset-zsg7m/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Sep  3 16:18:01.278: INFO: Deleting all statefulset in ns e2e-tests-statefulset-zsg7m
Sep  3 16:18:01.319: INFO: Scaling statefulset ss2 to 0
Sep  3 16:18:11.352: INFO: Waiting for statefulset status.replicas updated to 0
Sep  3 16:18:11.358: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:18:11.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-zsg7m" for this suite.
Sep  3 16:18:17.555: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:18:18.093: INFO: namespace: e2e-tests-statefulset-zsg7m, resource: bindings, ignored listing per whitelist
Sep  3 16:18:18.473: INFO: namespace e2e-tests-statefulset-zsg7m deletion completed in 6.988481686s

• [SLOW TEST:87.834 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:18:18.474: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-70d2a49d-ce66-11e9-a956-0a580af40009
STEP: Creating a pod to test consume secrets
Sep  3 16:18:18.697: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-70d6f281-ce66-11e9-a956-0a580af40009" in namespace "e2e-tests-projected-svcjk" to be "success or failure"
Sep  3 16:18:18.725: INFO: Pod "pod-projected-secrets-70d6f281-ce66-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 27.940791ms
Sep  3 16:18:20.732: INFO: Pod "pod-projected-secrets-70d6f281-ce66-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034155512s
Sep  3 16:18:22.745: INFO: Pod "pod-projected-secrets-70d6f281-ce66-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047346643s
STEP: Saw pod success
Sep  3 16:18:22.745: INFO: Pod "pod-projected-secrets-70d6f281-ce66-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 16:18:22.750: INFO: Trying to get logs from node 10.0.10.2 pod pod-projected-secrets-70d6f281-ce66-11e9-a956-0a580af40009 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep  3 16:18:22.903: INFO: Waiting for pod pod-projected-secrets-70d6f281-ce66-11e9-a956-0a580af40009 to disappear
Sep  3 16:18:22.931: INFO: Pod pod-projected-secrets-70d6f281-ce66-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:18:22.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-svcjk" for this suite.
Sep  3 16:18:29.013: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:18:29.137: INFO: namespace: e2e-tests-projected-svcjk, resource: bindings, ignored listing per whitelist
Sep  3 16:18:29.894: INFO: namespace e2e-tests-projected-svcjk deletion completed in 6.956436665s

• [SLOW TEST:11.420 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:18:29.894: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Sep  3 16:18:30.047: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep  3 16:18:30.058: INFO: Waiting for terminating namespaces to be deleted...
Sep  3 16:18:30.082: INFO: 
Logging pods the kubelet thinks is on node 10.0.10.2 before test
Sep  3 16:18:30.115: INFO: proxymux-client-10.0.10.2 from kube-system started at <nil> (0 container statuses recorded)
Sep  3 16:18:30.115: INFO: sonobuoy from heptio-sonobuoy started at 2019-09-03 15:20:23 +0000 UTC (1 container statuses recorded)
Sep  3 16:18:30.115: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep  3 16:18:30.115: INFO: sonobuoy-e2e-job-a1e56c6fdf4c4de0 from heptio-sonobuoy started at 2019-09-03 15:20:25 +0000 UTC (2 container statuses recorded)
Sep  3 16:18:30.115: INFO: 	Container e2e ready: true, restart count 0
Sep  3 16:18:30.115: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  3 16:18:30.115: INFO: kube-flannel-ds-vsts9 from kube-system started at 2019-08-30 21:27:39 +0000 UTC (1 container statuses recorded)
Sep  3 16:18:30.115: INFO: 	Container kube-flannel ready: true, restart count 1
Sep  3 16:18:30.115: INFO: kube-dns-autoscaler-84cf5956b-9dvmg from kube-system started at 2019-08-30 21:27:59 +0000 UTC (1 container statuses recorded)
Sep  3 16:18:30.115: INFO: 	Container autoscaler ready: true, restart count 0
Sep  3 16:18:30.115: INFO: sonobuoy-systemd-logs-daemon-set-6c7ccfc0384b4617-nlhk5 from heptio-sonobuoy started at 2019-09-03 15:20:25 +0000 UTC (2 container statuses recorded)
Sep  3 16:18:30.115: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  3 16:18:30.115: INFO: 	Container systemd-logs ready: true, restart count 0
Sep  3 16:18:30.115: INFO: kube-dns-6b7d4d8994-8bv4d from kube-system started at 2019-08-30 21:27:59 +0000 UTC (3 container statuses recorded)
Sep  3 16:18:30.115: INFO: 	Container dnsmasq ready: true, restart count 0
Sep  3 16:18:30.115: INFO: 	Container kubedns ready: true, restart count 0
Sep  3 16:18:30.115: INFO: 	Container sidecar ready: true, restart count 0
Sep  3 16:18:30.115: INFO: tiller-deploy-b6d55488-ddll4 from kube-system started at 2019-08-30 21:27:59 +0000 UTC (1 container statuses recorded)
Sep  3 16:18:30.116: INFO: 	Container tiller ready: true, restart count 0
Sep  3 16:18:30.116: INFO: kubernetes-dashboard-697c7958df-6qjlq from kube-system started at 2019-08-30 21:27:59 +0000 UTC (1 container statuses recorded)
Sep  3 16:18:30.116: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Sep  3 16:18:30.116: INFO: kube-proxy-p5865 from kube-system started at 2019-08-30 21:27:39 +0000 UTC (1 container statuses recorded)
Sep  3 16:18:30.116: INFO: 	Container kube-proxy ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-78ebbf80-ce66-11e9-a956-0a580af40009 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-78ebbf80-ce66-11e9-a956-0a580af40009 off the node 10.0.10.2
STEP: verifying the node doesn't have the label kubernetes.io/e2e-78ebbf80-ce66-11e9-a956-0a580af40009
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:18:34.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-jmlp6" for this suite.
Sep  3 16:18:54.650: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:18:55.295: INFO: namespace: e2e-tests-sched-pred-jmlp6, resource: bindings, ignored listing per whitelist
Sep  3 16:18:55.550: INFO: namespace e2e-tests-sched-pred-jmlp6 deletion completed in 20.967168918s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:25.656 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:18:55.550: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-fq88d in namespace e2e-tests-proxy-cctzb
I0903 16:18:55.768017      16 runners.go:184] Created replication controller with name: proxy-service-fq88d, namespace: e2e-tests-proxy-cctzb, replica count: 1
I0903 16:18:56.818709      16 runners.go:184] proxy-service-fq88d Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0903 16:18:57.818924      16 runners.go:184] proxy-service-fq88d Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0903 16:18:58.819223      16 runners.go:184] proxy-service-fq88d Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0903 16:18:59.819427      16 runners.go:184] proxy-service-fq88d Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0903 16:19:00.819714      16 runners.go:184] proxy-service-fq88d Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0903 16:19:01.819944      16 runners.go:184] proxy-service-fq88d Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0903 16:19:02.820216      16 runners.go:184] proxy-service-fq88d Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0903 16:19:03.820424      16 runners.go:184] proxy-service-fq88d Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0903 16:19:04.820643      16 runners.go:184] proxy-service-fq88d Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0903 16:19:05.820906      16 runners.go:184] proxy-service-fq88d Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0903 16:19:06.821174      16 runners.go:184] proxy-service-fq88d Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0903 16:19:07.821403      16 runners.go:184] proxy-service-fq88d Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep  3 16:19:07.860: INFO: setup took 12.164636805s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Sep  3 16:19:08.016: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/proxy-service-fq88d:portname1/proxy/: foo (200; 156.442191ms)
Sep  3 16:19:08.067: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:162/proxy/: bar (200; 206.605581ms)
Sep  3 16:19:08.067: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:160/proxy/: foo (200; 206.99427ms)
Sep  3 16:19:08.067: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:1080/proxy/... (200; 206.779676ms)
Sep  3 16:19:08.067: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:162/proxy/: bar (200; 206.771065ms)
Sep  3 16:19:08.067: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:160/proxy/: foo (200; 206.947066ms)
Sep  3 16:19:08.067: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/proxy-service-fq88d:portname2/proxy/: bar (200; 207.081869ms)
Sep  3 16:19:08.067: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/http:proxy-service-fq88d:portname2/proxy/: bar (200; 207.265483ms)
Sep  3 16:19:08.076: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:443/proxy/... (200; 216.02375ms)
Sep  3 16:19:08.076: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/http:proxy-service-fq88d:portname1/proxy/: foo (200; 215.737697ms)
Sep  3 16:19:08.076: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:1080/proxy/rewri... (200; 216.020394ms)
Sep  3 16:19:08.076: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5/proxy/rewriteme"... (200; 216.227484ms)
Sep  3 16:19:08.079: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:462/proxy/: tls qux (200; 219.67041ms)
Sep  3 16:19:08.080: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:460/proxy/: tls baz (200; 219.663713ms)
Sep  3 16:19:08.083: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/https:proxy-service-fq88d:tlsportname2/proxy/: tls qux (200; 222.791594ms)
Sep  3 16:19:08.084: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/https:proxy-service-fq88d:tlsportname1/proxy/: tls baz (200; 224.205361ms)
Sep  3 16:19:08.093: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:162/proxy/: bar (200; 8.451952ms)
Sep  3 16:19:08.095: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:160/proxy/: foo (200; 9.740228ms)
Sep  3 16:19:08.101: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5/proxy/rewriteme"... (200; 16.562424ms)
Sep  3 16:19:08.102: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:462/proxy/: tls qux (200; 17.410258ms)
Sep  3 16:19:08.102: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/https:proxy-service-fq88d:tlsportname2/proxy/: tls qux (200; 17.284222ms)
Sep  3 16:19:08.103: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/proxy-service-fq88d:portname2/proxy/: bar (200; 18.140885ms)
Sep  3 16:19:08.103: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:162/proxy/: bar (200; 18.074182ms)
Sep  3 16:19:08.103: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/http:proxy-service-fq88d:portname1/proxy/: foo (200; 18.167649ms)
Sep  3 16:19:08.103: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:460/proxy/: tls baz (200; 18.286859ms)
Sep  3 16:19:08.103: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:443/proxy/... (200; 18.608366ms)
Sep  3 16:19:08.103: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:160/proxy/: foo (200; 18.667346ms)
Sep  3 16:19:08.103: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:1080/proxy/rewri... (200; 17.994274ms)
Sep  3 16:19:08.103: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/https:proxy-service-fq88d:tlsportname1/proxy/: tls baz (200; 18.363788ms)
Sep  3 16:19:08.103: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:1080/proxy/... (200; 18.269372ms)
Sep  3 16:19:08.111: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/proxy-service-fq88d:portname1/proxy/: foo (200; 26.473979ms)
Sep  3 16:19:08.111: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/http:proxy-service-fq88d:portname2/proxy/: bar (200; 26.222705ms)
Sep  3 16:19:08.121: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:160/proxy/: foo (200; 10.146055ms)
Sep  3 16:19:08.122: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:162/proxy/: bar (200; 10.932735ms)
Sep  3 16:19:08.123: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:1080/proxy/... (200; 11.719842ms)
Sep  3 16:19:08.123: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:460/proxy/: tls baz (200; 12.080663ms)
Sep  3 16:19:08.123: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:1080/proxy/rewri... (200; 12.094075ms)
Sep  3 16:19:08.124: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5/proxy/rewriteme"... (200; 12.340487ms)
Sep  3 16:19:08.124: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:160/proxy/: foo (200; 12.37936ms)
Sep  3 16:19:08.124: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:443/proxy/... (200; 12.644949ms)
Sep  3 16:19:08.124: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:462/proxy/: tls qux (200; 12.977182ms)
Sep  3 16:19:08.124: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:162/proxy/: bar (200; 12.719145ms)
Sep  3 16:19:08.124: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/https:proxy-service-fq88d:tlsportname1/proxy/: tls baz (200; 13.293991ms)
Sep  3 16:19:08.125: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/https:proxy-service-fq88d:tlsportname2/proxy/: tls qux (200; 13.760331ms)
Sep  3 16:19:08.125: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/http:proxy-service-fq88d:portname2/proxy/: bar (200; 14.190171ms)
Sep  3 16:19:08.125: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/proxy-service-fq88d:portname2/proxy/: bar (200; 14.21578ms)
Sep  3 16:19:08.125: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/proxy-service-fq88d:portname1/proxy/: foo (200; 14.438806ms)
Sep  3 16:19:08.125: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/http:proxy-service-fq88d:portname1/proxy/: foo (200; 13.958113ms)
Sep  3 16:19:08.136: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:1080/proxy/rewri... (200; 9.337278ms)
Sep  3 16:19:08.136: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:162/proxy/: bar (200; 9.10262ms)
Sep  3 16:19:08.136: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:460/proxy/: tls baz (200; 9.646285ms)
Sep  3 16:19:08.137: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:443/proxy/... (200; 10.831846ms)
Sep  3 16:19:08.137: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:160/proxy/: foo (200; 10.870319ms)
Sep  3 16:19:08.138: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:160/proxy/: foo (200; 11.374842ms)
Sep  3 16:19:08.138: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:462/proxy/: tls qux (200; 11.986313ms)
Sep  3 16:19:08.138: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:1080/proxy/... (200; 11.076338ms)
Sep  3 16:19:08.138: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5/proxy/rewriteme"... (200; 11.279018ms)
Sep  3 16:19:08.138: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:162/proxy/: bar (200; 10.958869ms)
Sep  3 16:19:08.138: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/proxy-service-fq88d:portname2/proxy/: bar (200; 12.062682ms)
Sep  3 16:19:08.139: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/http:proxy-service-fq88d:portname1/proxy/: foo (200; 12.363232ms)
Sep  3 16:19:08.139: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/proxy-service-fq88d:portname1/proxy/: foo (200; 13.579482ms)
Sep  3 16:19:08.139: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/http:proxy-service-fq88d:portname2/proxy/: bar (200; 13.535481ms)
Sep  3 16:19:08.140: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/https:proxy-service-fq88d:tlsportname1/proxy/: tls baz (200; 13.539052ms)
Sep  3 16:19:08.140: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/https:proxy-service-fq88d:tlsportname2/proxy/: tls qux (200; 13.455805ms)
Sep  3 16:19:08.149: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:162/proxy/: bar (200; 9.307618ms)
Sep  3 16:19:08.150: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:160/proxy/: foo (200; 10.130828ms)
Sep  3 16:19:08.150: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:1080/proxy/... (200; 9.629334ms)
Sep  3 16:19:08.150: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:443/proxy/... (200; 10.130547ms)
Sep  3 16:19:08.150: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:162/proxy/: bar (200; 9.93015ms)
Sep  3 16:19:08.150: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:160/proxy/: foo (200; 10.276089ms)
Sep  3 16:19:08.150: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:462/proxy/: tls qux (200; 9.868632ms)
Sep  3 16:19:08.150: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:1080/proxy/rewri... (200; 9.718717ms)
Sep  3 16:19:08.150: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5/proxy/rewriteme"... (200; 10.094569ms)
Sep  3 16:19:08.151: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:460/proxy/: tls baz (200; 11.186812ms)
Sep  3 16:19:08.152: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/proxy-service-fq88d:portname1/proxy/: foo (200; 12.052206ms)
Sep  3 16:19:08.152: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/http:proxy-service-fq88d:portname2/proxy/: bar (200; 11.821226ms)
Sep  3 16:19:08.153: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/https:proxy-service-fq88d:tlsportname2/proxy/: tls qux (200; 12.732766ms)
Sep  3 16:19:08.153: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/http:proxy-service-fq88d:portname1/proxy/: foo (200; 13.283102ms)
Sep  3 16:19:08.153: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/proxy-service-fq88d:portname2/proxy/: bar (200; 13.596354ms)
Sep  3 16:19:08.154: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/https:proxy-service-fq88d:tlsportname1/proxy/: tls baz (200; 13.697928ms)
Sep  3 16:19:08.164: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:462/proxy/: tls qux (200; 9.850303ms)
Sep  3 16:19:08.165: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:160/proxy/: foo (200; 10.766694ms)
Sep  3 16:19:08.166: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:1080/proxy/rewri... (200; 12.028022ms)
Sep  3 16:19:08.166: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:1080/proxy/... (200; 11.756111ms)
Sep  3 16:19:08.166: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5/proxy/rewriteme"... (200; 11.647621ms)
Sep  3 16:19:08.166: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:460/proxy/: tls baz (200; 11.829747ms)
Sep  3 16:19:08.166: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:162/proxy/: bar (200; 11.765152ms)
Sep  3 16:19:08.167: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:160/proxy/: foo (200; 12.12745ms)
Sep  3 16:19:08.167: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:162/proxy/: bar (200; 12.180283ms)
Sep  3 16:19:08.167: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:443/proxy/... (200; 12.333682ms)
Sep  3 16:19:08.167: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/https:proxy-service-fq88d:tlsportname2/proxy/: tls qux (200; 12.777729ms)
Sep  3 16:19:08.168: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/https:proxy-service-fq88d:tlsportname1/proxy/: tls baz (200; 13.457658ms)
Sep  3 16:19:08.169: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/proxy-service-fq88d:portname1/proxy/: foo (200; 14.085884ms)
Sep  3 16:19:08.169: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/http:proxy-service-fq88d:portname2/proxy/: bar (200; 14.647237ms)
Sep  3 16:19:08.169: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/proxy-service-fq88d:portname2/proxy/: bar (200; 14.852205ms)
Sep  3 16:19:08.169: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/http:proxy-service-fq88d:portname1/proxy/: foo (200; 14.624923ms)
Sep  3 16:19:08.180: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:162/proxy/: bar (200; 10.99934ms)
Sep  3 16:19:08.181: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:460/proxy/: tls baz (200; 11.224311ms)
Sep  3 16:19:08.182: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5/proxy/rewriteme"... (200; 12.470387ms)
Sep  3 16:19:08.182: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:443/proxy/... (200; 12.994536ms)
Sep  3 16:19:08.183: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:462/proxy/: tls qux (200; 12.95698ms)
Sep  3 16:19:08.183: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:1080/proxy/... (200; 12.713632ms)
Sep  3 16:19:08.183: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:162/proxy/: bar (200; 13.22253ms)
Sep  3 16:19:08.183: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:160/proxy/: foo (200; 13.081928ms)
Sep  3 16:19:08.183: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:160/proxy/: foo (200; 13.542195ms)
Sep  3 16:19:08.183: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:1080/proxy/rewri... (200; 13.076203ms)
Sep  3 16:19:08.184: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/proxy-service-fq88d:portname2/proxy/: bar (200; 13.814175ms)
Sep  3 16:19:08.185: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/https:proxy-service-fq88d:tlsportname1/proxy/: tls baz (200; 15.14387ms)
Sep  3 16:19:08.185: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/https:proxy-service-fq88d:tlsportname2/proxy/: tls qux (200; 15.701173ms)
Sep  3 16:19:08.186: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/proxy-service-fq88d:portname1/proxy/: foo (200; 16.384102ms)
Sep  3 16:19:08.186: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/http:proxy-service-fq88d:portname1/proxy/: foo (200; 16.708822ms)
Sep  3 16:19:08.187: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/http:proxy-service-fq88d:portname2/proxy/: bar (200; 16.952817ms)
Sep  3 16:19:08.195: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:443/proxy/... (200; 7.951944ms)
Sep  3 16:19:08.196: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5/proxy/rewriteme"... (200; 9.146618ms)
Sep  3 16:19:08.197: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:1080/proxy/... (200; 9.60464ms)
Sep  3 16:19:08.197: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:162/proxy/: bar (200; 9.39654ms)
Sep  3 16:19:08.197: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:162/proxy/: bar (200; 9.410867ms)
Sep  3 16:19:08.197: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:460/proxy/: tls baz (200; 10.047103ms)
Sep  3 16:19:08.197: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:1080/proxy/rewri... (200; 9.901937ms)
Sep  3 16:19:08.197: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:160/proxy/: foo (200; 9.64594ms)
Sep  3 16:19:08.200: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/https:proxy-service-fq88d:tlsportname2/proxy/: tls qux (200; 13.29162ms)
Sep  3 16:19:08.201: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/proxy-service-fq88d:portname1/proxy/: foo (200; 13.69518ms)
Sep  3 16:19:08.201: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/https:proxy-service-fq88d:tlsportname1/proxy/: tls baz (200; 13.748263ms)
Sep  3 16:19:08.201: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:462/proxy/: tls qux (200; 14.285559ms)
Sep  3 16:19:08.201: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:160/proxy/: foo (200; 14.034923ms)
Sep  3 16:19:08.201: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/http:proxy-service-fq88d:portname2/proxy/: bar (200; 13.913085ms)
Sep  3 16:19:08.201: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/proxy-service-fq88d:portname2/proxy/: bar (200; 14.171538ms)
Sep  3 16:19:08.203: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/http:proxy-service-fq88d:portname1/proxy/: foo (200; 15.318382ms)
Sep  3 16:19:08.214: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:443/proxy/... (200; 11.268526ms)
Sep  3 16:19:08.215: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:162/proxy/: bar (200; 12.057297ms)
Sep  3 16:19:08.215: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:1080/proxy/rewri... (200; 11.867603ms)
Sep  3 16:19:08.215: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:160/proxy/: foo (200; 12.690922ms)
Sep  3 16:19:08.215: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:1080/proxy/... (200; 12.294015ms)
Sep  3 16:19:08.216: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:162/proxy/: bar (200; 12.126893ms)
Sep  3 16:19:08.215: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:460/proxy/: tls baz (200; 12.175015ms)
Sep  3 16:19:08.216: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5/proxy/rewriteme"... (200; 12.532194ms)
Sep  3 16:19:08.216: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:160/proxy/: foo (200; 12.497181ms)
Sep  3 16:19:08.216: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/http:proxy-service-fq88d:portname1/proxy/: foo (200; 13.280636ms)
Sep  3 16:19:08.216: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/https:proxy-service-fq88d:tlsportname1/proxy/: tls baz (200; 13.17107ms)
Sep  3 16:19:08.216: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:462/proxy/: tls qux (200; 13.2669ms)
Sep  3 16:19:08.217: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/proxy-service-fq88d:portname1/proxy/: foo (200; 13.298008ms)
Sep  3 16:19:08.218: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/http:proxy-service-fq88d:portname2/proxy/: bar (200; 14.645388ms)
Sep  3 16:19:08.218: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/proxy-service-fq88d:portname2/proxy/: bar (200; 14.797838ms)
Sep  3 16:19:08.220: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/https:proxy-service-fq88d:tlsportname2/proxy/: tls qux (200; 16.611726ms)
Sep  3 16:19:08.240: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:160/proxy/: foo (200; 19.56691ms)
Sep  3 16:19:08.241: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5/proxy/rewriteme"... (200; 20.248932ms)
Sep  3 16:19:08.241: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:1080/proxy/... (200; 20.642749ms)
Sep  3 16:19:08.241: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:162/proxy/: bar (200; 20.571127ms)
Sep  3 16:19:08.242: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:462/proxy/: tls qux (200; 20.515232ms)
Sep  3 16:19:08.242: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/https:proxy-service-fq88d:tlsportname2/proxy/: tls qux (200; 20.326465ms)
Sep  3 16:19:08.242: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/https:proxy-service-fq88d:tlsportname1/proxy/: tls baz (200; 20.514068ms)
Sep  3 16:19:08.242: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:1080/proxy/rewri... (200; 21.380672ms)
Sep  3 16:19:08.242: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:460/proxy/: tls baz (200; 21.821268ms)
Sep  3 16:19:08.242: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:160/proxy/: foo (200; 22.144493ms)
Sep  3 16:19:08.242: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:443/proxy/... (200; 21.643495ms)
Sep  3 16:19:08.242: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:162/proxy/: bar (200; 21.505692ms)
Sep  3 16:19:08.243: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/proxy-service-fq88d:portname1/proxy/: foo (200; 22.584895ms)
Sep  3 16:19:08.243: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/proxy-service-fq88d:portname2/proxy/: bar (200; 23.224619ms)
Sep  3 16:19:08.245: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/http:proxy-service-fq88d:portname2/proxy/: bar (200; 23.647636ms)
Sep  3 16:19:08.245: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/http:proxy-service-fq88d:portname1/proxy/: foo (200; 24.180483ms)
Sep  3 16:19:08.254: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:462/proxy/: tls qux (200; 9.04869ms)
Sep  3 16:19:08.255: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:1080/proxy/rewri... (200; 9.050315ms)
Sep  3 16:19:08.257: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:160/proxy/: foo (200; 10.451956ms)
Sep  3 16:19:08.257: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:160/proxy/: foo (200; 11.269766ms)
Sep  3 16:19:08.257: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:162/proxy/: bar (200; 11.006648ms)
Sep  3 16:19:08.257: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:460/proxy/: tls baz (200; 11.034028ms)
Sep  3 16:19:08.258: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:443/proxy/... (200; 11.500168ms)
Sep  3 16:19:08.258: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5/proxy/rewriteme"... (200; 12.167593ms)
Sep  3 16:19:08.258: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:162/proxy/: bar (200; 13.090285ms)
Sep  3 16:19:08.259: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/https:proxy-service-fq88d:tlsportname2/proxy/: tls qux (200; 13.144555ms)
Sep  3 16:19:08.259: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:1080/proxy/... (200; 13.555969ms)
Sep  3 16:19:08.260: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/http:proxy-service-fq88d:portname2/proxy/: bar (200; 15.250371ms)
Sep  3 16:19:08.264: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/proxy-service-fq88d:portname2/proxy/: bar (200; 17.751933ms)
Sep  3 16:19:08.264: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/http:proxy-service-fq88d:portname1/proxy/: foo (200; 18.698434ms)
Sep  3 16:19:08.264: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/proxy-service-fq88d:portname1/proxy/: foo (200; 19.270343ms)
Sep  3 16:19:08.264: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/https:proxy-service-fq88d:tlsportname1/proxy/: tls baz (200; 18.645991ms)
Sep  3 16:19:08.275: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:462/proxy/: tls qux (200; 10.386979ms)
Sep  3 16:19:08.275: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:443/proxy/... (200; 10.367689ms)
Sep  3 16:19:08.276: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:160/proxy/: foo (200; 10.744606ms)
Sep  3 16:19:08.276: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:1080/proxy/... (200; 11.409753ms)
Sep  3 16:19:08.276: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:160/proxy/: foo (200; 11.21799ms)
Sep  3 16:19:08.276: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5/proxy/rewriteme"... (200; 11.232415ms)
Sep  3 16:19:08.276: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:1080/proxy/rewri... (200; 11.765632ms)
Sep  3 16:19:08.276: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:162/proxy/: bar (200; 11.540639ms)
Sep  3 16:19:08.277: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:460/proxy/: tls baz (200; 12.128194ms)
Sep  3 16:19:08.278: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/proxy-service-fq88d:portname1/proxy/: foo (200; 13.075261ms)
Sep  3 16:19:08.278: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/https:proxy-service-fq88d:tlsportname2/proxy/: tls qux (200; 12.920644ms)
Sep  3 16:19:08.279: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:162/proxy/: bar (200; 13.611957ms)
Sep  3 16:19:08.279: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/proxy-service-fq88d:portname2/proxy/: bar (200; 14.695676ms)
Sep  3 16:19:08.280: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/https:proxy-service-fq88d:tlsportname1/proxy/: tls baz (200; 14.782548ms)
Sep  3 16:19:08.280: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/http:proxy-service-fq88d:portname1/proxy/: foo (200; 15.151271ms)
Sep  3 16:19:08.281: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/http:proxy-service-fq88d:portname2/proxy/: bar (200; 15.868227ms)
Sep  3 16:19:08.292: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:160/proxy/: foo (200; 10.103654ms)
Sep  3 16:19:08.292: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:1080/proxy/... (200; 10.19716ms)
Sep  3 16:19:08.292: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:1080/proxy/rewri... (200; 10.989219ms)
Sep  3 16:19:08.292: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5/proxy/rewriteme"... (200; 11.213458ms)
Sep  3 16:19:08.293: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:162/proxy/: bar (200; 10.901523ms)
Sep  3 16:19:08.294: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:160/proxy/: foo (200; 12.177005ms)
Sep  3 16:19:08.294: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/https:proxy-service-fq88d:tlsportname2/proxy/: tls qux (200; 12.909789ms)
Sep  3 16:19:08.294: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:460/proxy/: tls baz (200; 12.182544ms)
Sep  3 16:19:08.294: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:443/proxy/... (200; 12.387683ms)
Sep  3 16:19:08.294: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:462/proxy/: tls qux (200; 12.986104ms)
Sep  3 16:19:08.292: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:162/proxy/: bar (200; 10.597117ms)
Sep  3 16:19:08.298: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/proxy-service-fq88d:portname1/proxy/: foo (200; 16.390782ms)
Sep  3 16:19:08.299: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/https:proxy-service-fq88d:tlsportname1/proxy/: tls baz (200; 16.986357ms)
Sep  3 16:19:08.299: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/proxy-service-fq88d:portname2/proxy/: bar (200; 17.009776ms)
Sep  3 16:19:08.299: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/http:proxy-service-fq88d:portname2/proxy/: bar (200; 17.29559ms)
Sep  3 16:19:08.299: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/http:proxy-service-fq88d:portname1/proxy/: foo (200; 17.862904ms)
Sep  3 16:19:08.311: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:460/proxy/: tls baz (200; 10.440253ms)
Sep  3 16:19:08.312: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:1080/proxy/... (200; 12.075326ms)
Sep  3 16:19:08.313: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:162/proxy/: bar (200; 12.06788ms)
Sep  3 16:19:08.313: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:160/proxy/: foo (200; 13.015881ms)
Sep  3 16:19:08.313: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:162/proxy/: bar (200; 12.640764ms)
Sep  3 16:19:08.313: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5/proxy/rewriteme"... (200; 12.890352ms)
Sep  3 16:19:08.313: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:462/proxy/: tls qux (200; 12.321658ms)
Sep  3 16:19:08.313: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:160/proxy/: foo (200; 12.846091ms)
Sep  3 16:19:08.313: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:443/proxy/... (200; 12.845538ms)
Sep  3 16:19:08.314: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:1080/proxy/rewri... (200; 13.613207ms)
Sep  3 16:19:08.314: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/https:proxy-service-fq88d:tlsportname2/proxy/: tls qux (200; 14.573795ms)
Sep  3 16:19:08.315: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/https:proxy-service-fq88d:tlsportname1/proxy/: tls baz (200; 15.193173ms)
Sep  3 16:19:08.320: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/proxy-service-fq88d:portname2/proxy/: bar (200; 20.662334ms)
Sep  3 16:19:08.321: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/proxy-service-fq88d:portname1/proxy/: foo (200; 20.048357ms)
Sep  3 16:19:08.321: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/http:proxy-service-fq88d:portname2/proxy/: bar (200; 20.998394ms)
Sep  3 16:19:08.321: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/http:proxy-service-fq88d:portname1/proxy/: foo (200; 21.667779ms)
Sep  3 16:19:08.331: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:462/proxy/: tls qux (200; 9.748969ms)
Sep  3 16:19:08.332: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:162/proxy/: bar (200; 10.380929ms)
Sep  3 16:19:08.332: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5/proxy/rewriteme"... (200; 10.395198ms)
Sep  3 16:19:08.332: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:1080/proxy/... (200; 10.79175ms)
Sep  3 16:19:08.332: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:443/proxy/... (200; 10.65489ms)
Sep  3 16:19:08.332: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:1080/proxy/rewri... (200; 10.909122ms)
Sep  3 16:19:08.332: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:160/proxy/: foo (200; 10.495912ms)
Sep  3 16:19:08.333: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:160/proxy/: foo (200; 12.076681ms)
Sep  3 16:19:08.334: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:162/proxy/: bar (200; 12.671999ms)
Sep  3 16:19:08.335: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/proxy-service-fq88d:portname1/proxy/: foo (200; 13.408431ms)
Sep  3 16:19:08.334: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:460/proxy/: tls baz (200; 12.562974ms)
Sep  3 16:19:08.335: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/https:proxy-service-fq88d:tlsportname1/proxy/: tls baz (200; 13.808547ms)
Sep  3 16:19:08.337: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/http:proxy-service-fq88d:portname1/proxy/: foo (200; 14.850748ms)
Sep  3 16:19:08.337: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/proxy-service-fq88d:portname2/proxy/: bar (200; 16.199014ms)
Sep  3 16:19:08.337: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/https:proxy-service-fq88d:tlsportname2/proxy/: tls qux (200; 15.652403ms)
Sep  3 16:19:08.338: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/http:proxy-service-fq88d:portname2/proxy/: bar (200; 15.732943ms)
Sep  3 16:19:08.352: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:162/proxy/: bar (200; 13.714151ms)
Sep  3 16:19:08.353: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:1080/proxy/... (200; 14.404363ms)
Sep  3 16:19:08.353: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:160/proxy/: foo (200; 15.055419ms)
Sep  3 16:19:08.353: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:462/proxy/: tls qux (200; 14.299254ms)
Sep  3 16:19:08.353: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:443/proxy/... (200; 14.515704ms)
Sep  3 16:19:08.353: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5/proxy/rewriteme"... (200; 15.061385ms)
Sep  3 16:19:08.353: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:162/proxy/: bar (200; 14.545172ms)
Sep  3 16:19:08.353: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:160/proxy/: foo (200; 14.994703ms)
Sep  3 16:19:08.353: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:1080/proxy/rewri... (200; 15.229113ms)
Sep  3 16:19:08.353: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:460/proxy/: tls baz (200; 14.926285ms)
Sep  3 16:19:08.356: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/proxy-service-fq88d:portname1/proxy/: foo (200; 17.516924ms)
Sep  3 16:19:08.356: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/http:proxy-service-fq88d:portname1/proxy/: foo (200; 16.988608ms)
Sep  3 16:19:08.356: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/https:proxy-service-fq88d:tlsportname1/proxy/: tls baz (200; 16.894733ms)
Sep  3 16:19:08.356: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/http:proxy-service-fq88d:portname2/proxy/: bar (200; 17.047378ms)
Sep  3 16:19:08.356: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/proxy-service-fq88d:portname2/proxy/: bar (200; 17.982643ms)
Sep  3 16:19:08.356: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/https:proxy-service-fq88d:tlsportname2/proxy/: tls qux (200; 17.232657ms)
Sep  3 16:19:08.380: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:162/proxy/: bar (200; 23.388768ms)
Sep  3 16:19:08.380: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:162/proxy/: bar (200; 23.985967ms)
Sep  3 16:19:08.381: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:1080/proxy/rewri... (200; 23.409845ms)
Sep  3 16:19:08.381: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:443/proxy/... (200; 24.424713ms)
Sep  3 16:19:08.381: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/https:proxy-service-fq88d:tlsportname1/proxy/: tls baz (200; 23.803345ms)
Sep  3 16:19:08.381: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:1080/proxy/... (200; 24.981454ms)
Sep  3 16:19:08.381: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:160/proxy/: foo (200; 24.459965ms)
Sep  3 16:19:08.381: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/https:proxy-service-fq88d:tlsportname2/proxy/: tls qux (200; 23.96714ms)
Sep  3 16:19:08.381: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:460/proxy/: tls baz (200; 24.679137ms)
Sep  3 16:19:08.381: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:462/proxy/: tls qux (200; 24.478744ms)
Sep  3 16:19:08.381: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:160/proxy/: foo (200; 25.375122ms)
Sep  3 16:19:08.382: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5/proxy/rewriteme"... (200; 24.525606ms)
Sep  3 16:19:08.391: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/http:proxy-service-fq88d:portname2/proxy/: bar (200; 34.113198ms)
Sep  3 16:19:08.391: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/proxy-service-fq88d:portname1/proxy/: foo (200; 34.535078ms)
Sep  3 16:19:08.391: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/proxy-service-fq88d:portname2/proxy/: bar (200; 34.938216ms)
Sep  3 16:19:08.391: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/http:proxy-service-fq88d:portname1/proxy/: foo (200; 34.490059ms)
Sep  3 16:19:08.410: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:462/proxy/: tls qux (200; 18.602049ms)
Sep  3 16:19:08.416: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/https:proxy-service-fq88d:tlsportname1/proxy/: tls baz (200; 23.741054ms)
Sep  3 16:19:08.416: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:160/proxy/: foo (200; 23.885047ms)
Sep  3 16:19:08.416: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:162/proxy/: bar (200; 23.949755ms)
Sep  3 16:19:08.416: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5/proxy/rewriteme"... (200; 24.136629ms)
Sep  3 16:19:08.416: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:443/proxy/... (200; 24.770074ms)
Sep  3 16:19:08.416: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:1080/proxy/rewri... (200; 24.269918ms)
Sep  3 16:19:08.417: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:460/proxy/: tls baz (200; 24.940882ms)
Sep  3 16:19:08.417: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:162/proxy/: bar (200; 24.942285ms)
Sep  3 16:19:08.417: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/https:proxy-service-fq88d:tlsportname2/proxy/: tls qux (200; 24.713134ms)
Sep  3 16:19:08.417: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:160/proxy/: foo (200; 24.781928ms)
Sep  3 16:19:08.417: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:1080/proxy/... (200; 24.974114ms)
Sep  3 16:19:08.418: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/proxy-service-fq88d:portname1/proxy/: foo (200; 25.582626ms)
Sep  3 16:19:08.418: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/http:proxy-service-fq88d:portname1/proxy/: foo (200; 26.465308ms)
Sep  3 16:19:08.418: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/proxy-service-fq88d:portname2/proxy/: bar (200; 27.075052ms)
Sep  3 16:19:08.418: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/http:proxy-service-fq88d:portname2/proxy/: bar (200; 26.719605ms)
Sep  3 16:19:08.429: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:160/proxy/: foo (200; 9.955469ms)
Sep  3 16:19:08.434: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:160/proxy/: foo (200; 14.386538ms)
Sep  3 16:19:08.434: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:1080/proxy/rewri... (200; 14.51511ms)
Sep  3 16:19:08.434: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:1080/proxy/... (200; 14.785914ms)
Sep  3 16:19:08.434: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:460/proxy/: tls baz (200; 15.182723ms)
Sep  3 16:19:08.434: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:443/proxy/... (200; 14.9729ms)
Sep  3 16:19:08.434: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5/proxy/rewriteme"... (200; 15.240117ms)
Sep  3 16:19:08.434: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:162/proxy/: bar (200; 15.224207ms)
Sep  3 16:19:08.434: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:462/proxy/: tls qux (200; 15.84186ms)
Sep  3 16:19:08.434: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:162/proxy/: bar (200; 15.023467ms)
Sep  3 16:19:08.435: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/http:proxy-service-fq88d:portname1/proxy/: foo (200; 16.182807ms)
Sep  3 16:19:08.436: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/https:proxy-service-fq88d:tlsportname1/proxy/: tls baz (200; 16.811544ms)
Sep  3 16:19:08.436: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/https:proxy-service-fq88d:tlsportname2/proxy/: tls qux (200; 16.745894ms)
Sep  3 16:19:08.438: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/proxy-service-fq88d:portname1/proxy/: foo (200; 19.172875ms)
Sep  3 16:19:08.439: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/proxy-service-fq88d:portname2/proxy/: bar (200; 19.645621ms)
Sep  3 16:19:08.439: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/http:proxy-service-fq88d:portname2/proxy/: bar (200; 19.860089ms)
Sep  3 16:19:08.449: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:443/proxy/... (200; 9.685078ms)
Sep  3 16:19:08.449: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:1080/proxy/... (200; 10.592534ms)
Sep  3 16:19:08.450: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:160/proxy/: foo (200; 10.617424ms)
Sep  3 16:19:08.450: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:162/proxy/: bar (200; 10.585045ms)
Sep  3 16:19:08.450: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:460/proxy/: tls baz (200; 10.443084ms)
Sep  3 16:19:08.450: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:1080/proxy/rewri... (200; 10.444611ms)
Sep  3 16:19:08.450: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5:160/proxy/: foo (200; 10.441462ms)
Sep  3 16:19:08.450: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/http:proxy-service-fq88d-kddc5:162/proxy/: bar (200; 10.93355ms)
Sep  3 16:19:08.452: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cctzb/pods/proxy-service-fq88d-kddc5/proxy/rewriteme"... (200; 12.271458ms)
Sep  3 16:19:08.452: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-cctzb/pods/https:proxy-service-fq88d-kddc5:462/proxy/: tls qux (200; 11.805492ms)
Sep  3 16:19:08.453: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/https:proxy-service-fq88d:tlsportname2/proxy/: tls qux (200; 13.054583ms)
Sep  3 16:19:08.453: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/https:proxy-service-fq88d:tlsportname1/proxy/: tls baz (200; 13.59637ms)
Sep  3 16:19:08.454: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/proxy-service-fq88d:portname2/proxy/: bar (200; 15.163323ms)
Sep  3 16:19:08.454: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/http:proxy-service-fq88d:portname2/proxy/: bar (200; 14.175458ms)
Sep  3 16:19:08.454: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/proxy-service-fq88d:portname1/proxy/: foo (200; 14.995648ms)
Sep  3 16:19:08.454: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-cctzb/services/http:proxy-service-fq88d:portname1/proxy/: foo (200; 14.794907ms)
STEP: deleting ReplicationController proxy-service-fq88d in namespace e2e-tests-proxy-cctzb, will wait for the garbage collector to delete the pods
Sep  3 16:19:08.560: INFO: Deleting ReplicationController proxy-service-fq88d took: 30.157065ms
Sep  3 16:19:08.664: INFO: Terminating ReplicationController proxy-service-fq88d pods took: 103.786974ms
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:19:19.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-cctzb" for this suite.
Sep  3 16:19:25.551: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:19:26.175: INFO: namespace: e2e-tests-proxy-cctzb, resource: bindings, ignored listing per whitelist
Sep  3 16:19:26.447: INFO: namespace e2e-tests-proxy-cctzb deletion completed in 6.969791679s

• [SLOW TEST:30.897 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:19:26.448: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Sep  3 16:19:26.607: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9951f83d-ce66-11e9-a956-0a580af40009" in namespace "e2e-tests-projected-6n2gb" to be "success or failure"
Sep  3 16:19:26.668: INFO: Pod "downwardapi-volume-9951f83d-ce66-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 61.458115ms
Sep  3 16:19:28.674: INFO: Pod "downwardapi-volume-9951f83d-ce66-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.067565471s
STEP: Saw pod success
Sep  3 16:19:28.674: INFO: Pod "downwardapi-volume-9951f83d-ce66-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 16:19:28.680: INFO: Trying to get logs from node 10.0.10.2 pod downwardapi-volume-9951f83d-ce66-11e9-a956-0a580af40009 container client-container: <nil>
STEP: delete the pod
Sep  3 16:19:28.760: INFO: Waiting for pod downwardapi-volume-9951f83d-ce66-11e9-a956-0a580af40009 to disappear
Sep  3 16:19:28.786: INFO: Pod downwardapi-volume-9951f83d-ce66-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:19:28.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6n2gb" for this suite.
Sep  3 16:19:34.857: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:19:35.669: INFO: namespace: e2e-tests-projected-6n2gb, resource: bindings, ignored listing per whitelist
Sep  3 16:19:35.719: INFO: namespace e2e-tests-projected-6n2gb deletion completed in 6.928084778s

• [SLOW TEST:9.272 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:19:35.720: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  3 16:19:35.859: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:19:37.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-pt6bq" for this suite.
Sep  3 16:19:43.114: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:19:43.749: INFO: namespace: e2e-tests-custom-resource-definition-pt6bq, resource: bindings, ignored listing per whitelist
Sep  3 16:19:44.025: INFO: namespace e2e-tests-custom-resource-definition-pt6bq deletion completed in 6.975891712s

• [SLOW TEST:8.306 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:19:44.027: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Sep  3 16:19:44.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 create -f - --namespace=e2e-tests-kubectl-fnl76'
Sep  3 16:19:44.413: INFO: stderr: ""
Sep  3 16:19:44.413: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Sep  3 16:19:45.453: INFO: Selector matched 1 pods for map[app:redis]
Sep  3 16:19:45.453: INFO: Found 0 / 1
Sep  3 16:19:46.419: INFO: Selector matched 1 pods for map[app:redis]
Sep  3 16:19:46.419: INFO: Found 1 / 1
Sep  3 16:19:46.419: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Sep  3 16:19:46.425: INFO: Selector matched 1 pods for map[app:redis]
Sep  3 16:19:46.425: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep  3 16:19:46.425: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 patch pod redis-master-pvpk5 --namespace=e2e-tests-kubectl-fnl76 -p {"metadata":{"annotations":{"x":"y"}}}'
Sep  3 16:19:46.568: INFO: stderr: ""
Sep  3 16:19:46.568: INFO: stdout: "pod/redis-master-pvpk5 patched\n"
STEP: checking annotations
Sep  3 16:19:46.574: INFO: Selector matched 1 pods for map[app:redis]
Sep  3 16:19:46.574: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:19:46.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-fnl76" for this suite.
Sep  3 16:20:08.647: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:20:09.398: INFO: namespace: e2e-tests-kubectl-fnl76, resource: bindings, ignored listing per whitelist
Sep  3 16:20:09.523: INFO: namespace e2e-tests-kubectl-fnl76 deletion completed in 22.944060649s

• [SLOW TEST:25.497 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:20:09.524: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-mkvt
STEP: Creating a pod to test atomic-volume-subpath
Sep  3 16:20:09.742: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-mkvt" in namespace "e2e-tests-subpath-lwzh9" to be "success or failure"
Sep  3 16:20:09.769: INFO: Pod "pod-subpath-test-projected-mkvt": Phase="Pending", Reason="", readiness=false. Elapsed: 26.184941ms
Sep  3 16:20:11.775: INFO: Pod "pod-subpath-test-projected-mkvt": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03233156s
Sep  3 16:20:13.781: INFO: Pod "pod-subpath-test-projected-mkvt": Phase="Running", Reason="", readiness=false. Elapsed: 4.038486285s
Sep  3 16:20:15.794: INFO: Pod "pod-subpath-test-projected-mkvt": Phase="Running", Reason="", readiness=false. Elapsed: 6.051913102s
Sep  3 16:20:17.801: INFO: Pod "pod-subpath-test-projected-mkvt": Phase="Running", Reason="", readiness=false. Elapsed: 8.057994923s
Sep  3 16:20:19.807: INFO: Pod "pod-subpath-test-projected-mkvt": Phase="Running", Reason="", readiness=false. Elapsed: 10.064301353s
Sep  3 16:20:21.813: INFO: Pod "pod-subpath-test-projected-mkvt": Phase="Running", Reason="", readiness=false. Elapsed: 12.070686888s
Sep  3 16:20:23.820: INFO: Pod "pod-subpath-test-projected-mkvt": Phase="Running", Reason="", readiness=false. Elapsed: 14.077351288s
Sep  3 16:20:25.833: INFO: Pod "pod-subpath-test-projected-mkvt": Phase="Running", Reason="", readiness=false. Elapsed: 16.090492066s
Sep  3 16:20:27.839: INFO: Pod "pod-subpath-test-projected-mkvt": Phase="Running", Reason="", readiness=false. Elapsed: 18.096709498s
Sep  3 16:20:29.845: INFO: Pod "pod-subpath-test-projected-mkvt": Phase="Running", Reason="", readiness=false. Elapsed: 20.102745734s
Sep  3 16:20:31.851: INFO: Pod "pod-subpath-test-projected-mkvt": Phase="Running", Reason="", readiness=false. Elapsed: 22.108941158s
Sep  3 16:20:33.857: INFO: Pod "pod-subpath-test-projected-mkvt": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.114928521s
STEP: Saw pod success
Sep  3 16:20:33.858: INFO: Pod "pod-subpath-test-projected-mkvt" satisfied condition "success or failure"
Sep  3 16:20:33.863: INFO: Trying to get logs from node 10.0.10.2 pod pod-subpath-test-projected-mkvt container test-container-subpath-projected-mkvt: <nil>
STEP: delete the pod
Sep  3 16:20:33.994: INFO: Waiting for pod pod-subpath-test-projected-mkvt to disappear
Sep  3 16:20:34.028: INFO: Pod pod-subpath-test-projected-mkvt no longer exists
STEP: Deleting pod pod-subpath-test-projected-mkvt
Sep  3 16:20:34.028: INFO: Deleting pod "pod-subpath-test-projected-mkvt" in namespace "e2e-tests-subpath-lwzh9"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:20:34.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-lwzh9" for this suite.
Sep  3 16:20:40.121: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:20:40.826: INFO: namespace: e2e-tests-subpath-lwzh9, resource: bindings, ignored listing per whitelist
Sep  3 16:20:41.009: INFO: namespace e2e-tests-subpath-lwzh9 deletion completed in 6.969259365s

• [SLOW TEST:31.486 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:20:41.009: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Sep  3 16:20:41.546: INFO: Pod name wrapped-volume-race-c5f6d5b9-ce66-11e9-a956-0a580af40009: Found 3 pods out of 5
Sep  3 16:20:46.562: INFO: Pod name wrapped-volume-race-c5f6d5b9-ce66-11e9-a956-0a580af40009: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-c5f6d5b9-ce66-11e9-a956-0a580af40009 in namespace e2e-tests-emptydir-wrapper-86ggt, will wait for the garbage collector to delete the pods
Sep  3 16:22:34.836: INFO: Deleting ReplicationController wrapped-volume-race-c5f6d5b9-ce66-11e9-a956-0a580af40009 took: 30.21488ms
Sep  3 16:22:34.936: INFO: Terminating ReplicationController wrapped-volume-race-c5f6d5b9-ce66-11e9-a956-0a580af40009 pods took: 100.2869ms
STEP: Creating RC which spawns configmap-volume pods
Sep  3 16:23:12.499: INFO: Pod name wrapped-volume-race-1ff13cf1-ce67-11e9-a956-0a580af40009: Found 0 pods out of 5
Sep  3 16:23:17.508: INFO: Pod name wrapped-volume-race-1ff13cf1-ce67-11e9-a956-0a580af40009: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-1ff13cf1-ce67-11e9-a956-0a580af40009 in namespace e2e-tests-emptydir-wrapper-86ggt, will wait for the garbage collector to delete the pods
Sep  3 16:25:05.901: INFO: Deleting ReplicationController wrapped-volume-race-1ff13cf1-ce67-11e9-a956-0a580af40009 took: 37.921659ms
Sep  3 16:25:06.001: INFO: Terminating ReplicationController wrapped-volume-race-1ff13cf1-ce67-11e9-a956-0a580af40009 pods took: 100.246067ms
STEP: Creating RC which spawns configmap-volume pods
Sep  3 16:25:50.489: INFO: Pod name wrapped-volume-race-7e18c391-ce67-11e9-a956-0a580af40009: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-7e18c391-ce67-11e9-a956-0a580af40009 in namespace e2e-tests-emptydir-wrapper-86ggt, will wait for the garbage collector to delete the pods
Sep  3 16:27:42.772: INFO: Deleting ReplicationController wrapped-volume-race-7e18c391-ce67-11e9-a956-0a580af40009 took: 35.131463ms
Sep  3 16:27:42.872: INFO: Terminating ReplicationController wrapped-volume-race-7e18c391-ce67-11e9-a956-0a580af40009 pods took: 100.249383ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:28:21.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-86ggt" for this suite.
Sep  3 16:28:29.514: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:28:29.729: INFO: namespace: e2e-tests-emptydir-wrapper-86ggt, resource: bindings, ignored listing per whitelist
Sep  3 16:28:30.399: INFO: namespace e2e-tests-emptydir-wrapper-86ggt deletion completed in 8.946958257s

• [SLOW TEST:469.390 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:28:30.400: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-dd8eb1a0-ce67-11e9-a956-0a580af40009
STEP: Creating a pod to test consume configMaps
Sep  3 16:28:30.620: INFO: Waiting up to 5m0s for pod "pod-configmaps-dd929615-ce67-11e9-a956-0a580af40009" in namespace "e2e-tests-configmap-xsk75" to be "success or failure"
Sep  3 16:28:30.646: INFO: Pod "pod-configmaps-dd929615-ce67-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 26.594196ms
Sep  3 16:28:32.663: INFO: Pod "pod-configmaps-dd929615-ce67-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.04281771s
STEP: Saw pod success
Sep  3 16:28:32.663: INFO: Pod "pod-configmaps-dd929615-ce67-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 16:28:32.668: INFO: Trying to get logs from node 10.0.10.2 pod pod-configmaps-dd929615-ce67-11e9-a956-0a580af40009 container configmap-volume-test: <nil>
STEP: delete the pod
Sep  3 16:28:32.739: INFO: Waiting for pod pod-configmaps-dd929615-ce67-11e9-a956-0a580af40009 to disappear
Sep  3 16:28:32.766: INFO: Pod pod-configmaps-dd929615-ce67-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:28:32.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-xsk75" for this suite.
Sep  3 16:28:38.836: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:28:39.236: INFO: namespace: e2e-tests-configmap-xsk75, resource: bindings, ignored listing per whitelist
Sep  3 16:28:39.677: INFO: namespace e2e-tests-configmap-xsk75 deletion completed in 6.905086428s

• [SLOW TEST:9.277 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:28:39.677: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:28:41.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-lqkhh" for this suite.
Sep  3 16:29:36.002: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:29:36.723: INFO: namespace: e2e-tests-kubelet-test-lqkhh, resource: bindings, ignored listing per whitelist
Sep  3 16:29:36.897: INFO: namespace e2e-tests-kubelet-test-lqkhh deletion completed in 54.955239057s

• [SLOW TEST:57.220 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:29:36.897: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0903 16:30:07.221864      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep  3 16:30:07.221: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:30:07.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-m6bts" for this suite.
Sep  3 16:30:13.304: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:30:13.851: INFO: namespace: e2e-tests-gc-m6bts, resource: bindings, ignored listing per whitelist
Sep  3 16:30:14.229: INFO: namespace e2e-tests-gc-m6bts deletion completed in 7.0020768s

• [SLOW TEST:37.332 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:30:14.229: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-1b6f09bc-ce68-11e9-a956-0a580af40009
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-1b6f09bc-ce68-11e9-a956-0a580af40009
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:31:40.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-rfj46" for this suite.
Sep  3 16:32:02.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:32:03.113: INFO: namespace: e2e-tests-configmap-rfj46, resource: bindings, ignored listing per whitelist
Sep  3 16:32:03.780: INFO: namespace e2e-tests-configmap-rfj46 deletion completed in 23.023906665s

• [SLOW TEST:109.551 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:32:03.781: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Sep  3 16:32:05.978: INFO: Pod pod-hostip-5cb9709f-ce68-11e9-a956-0a580af40009 has hostIP: 10.0.10.2
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:32:05.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-299zb" for this suite.
Sep  3 16:32:28.046: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:32:28.262: INFO: namespace: e2e-tests-pods-299zb, resource: bindings, ignored listing per whitelist
Sep  3 16:32:28.988: INFO: namespace e2e-tests-pods-299zb deletion completed in 23.003407395s

• [SLOW TEST:25.207 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:32:28.988: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-6bc03650-ce68-11e9-a956-0a580af40009
STEP: Creating a pod to test consume secrets
Sep  3 16:32:29.179: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-6bc478e6-ce68-11e9-a956-0a580af40009" in namespace "e2e-tests-projected-q9fpl" to be "success or failure"
Sep  3 16:32:29.207: INFO: Pod "pod-projected-secrets-6bc478e6-ce68-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 28.399163ms
Sep  3 16:32:31.213: INFO: Pod "pod-projected-secrets-6bc478e6-ce68-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.034425548s
STEP: Saw pod success
Sep  3 16:32:31.213: INFO: Pod "pod-projected-secrets-6bc478e6-ce68-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 16:32:31.218: INFO: Trying to get logs from node 10.0.10.2 pod pod-projected-secrets-6bc478e6-ce68-11e9-a956-0a580af40009 container secret-volume-test: <nil>
STEP: delete the pod
Sep  3 16:32:31.291: INFO: Waiting for pod pod-projected-secrets-6bc478e6-ce68-11e9-a956-0a580af40009 to disappear
Sep  3 16:32:31.318: INFO: Pod pod-projected-secrets-6bc478e6-ce68-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:32:31.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-q9fpl" for this suite.
Sep  3 16:32:37.394: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:32:38.279: INFO: namespace: e2e-tests-projected-q9fpl, resource: bindings, ignored listing per whitelist
Sep  3 16:32:38.306: INFO: namespace e2e-tests-projected-q9fpl deletion completed in 6.98180458s

• [SLOW TEST:9.318 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:32:38.306: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-8mxws
Sep  3 16:32:40.516: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-8mxws
STEP: checking the pod's current state and verifying that restartCount is present
Sep  3 16:32:40.522: INFO: Initial restart count of pod liveness-http is 0
Sep  3 16:33:02.609: INFO: Restart count of pod e2e-tests-container-probe-8mxws/liveness-http is now 1 (22.086682276s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:33:02.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-8mxws" for this suite.
Sep  3 16:33:08.746: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:33:09.513: INFO: namespace: e2e-tests-container-probe-8mxws, resource: bindings, ignored listing per whitelist
Sep  3 16:33:09.792: INFO: namespace e2e-tests-container-probe-8mxws deletion completed in 7.134371887s

• [SLOW TEST:31.486 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:33:09.793: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Sep  3 16:33:09.926: INFO: namespace e2e-tests-kubectl-gwcdr
Sep  3 16:33:09.926: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 create -f - --namespace=e2e-tests-kubectl-gwcdr'
Sep  3 16:33:10.402: INFO: stderr: ""
Sep  3 16:33:10.402: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Sep  3 16:33:11.530: INFO: Selector matched 1 pods for map[app:redis]
Sep  3 16:33:11.530: INFO: Found 0 / 1
Sep  3 16:33:12.409: INFO: Selector matched 1 pods for map[app:redis]
Sep  3 16:33:12.409: INFO: Found 1 / 1
Sep  3 16:33:12.409: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Sep  3 16:33:12.415: INFO: Selector matched 1 pods for map[app:redis]
Sep  3 16:33:12.415: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep  3 16:33:12.415: INFO: wait on redis-master startup in e2e-tests-kubectl-gwcdr 
Sep  3 16:33:12.415: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 logs redis-master-dqqdr redis-master --namespace=e2e-tests-kubectl-gwcdr'
Sep  3 16:33:12.752: INFO: stderr: ""
Sep  3 16:33:12.752: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 03 Sep 16:33:11.330 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 03 Sep 16:33:11.330 # Server started, Redis version 3.2.12\n1:M 03 Sep 16:33:11.331 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 03 Sep 16:33:11.331 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Sep  3 16:33:12.753: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-gwcdr'
Sep  3 16:33:12.918: INFO: stderr: ""
Sep  3 16:33:12.918: INFO: stdout: "service/rm2 exposed\n"
Sep  3 16:33:12.944: INFO: Service rm2 in namespace e2e-tests-kubectl-gwcdr found.
STEP: exposing service
Sep  3 16:33:14.976: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-gwcdr'
Sep  3 16:33:15.094: INFO: stderr: ""
Sep  3 16:33:15.094: INFO: stdout: "service/rm3 exposed\n"
Sep  3 16:33:15.119: INFO: Service rm3 in namespace e2e-tests-kubectl-gwcdr found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:33:17.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-gwcdr" for this suite.
Sep  3 16:33:33.221: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:33:33.461: INFO: namespace: e2e-tests-kubectl-gwcdr, resource: bindings, ignored listing per whitelist
Sep  3 16:33:34.100: INFO: namespace e2e-tests-kubectl-gwcdr deletion completed in 16.941948444s

• [SLOW TEST:24.308 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:33:34.100: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-wxwk6 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-wxwk6;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-wxwk6 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-wxwk6;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-wxwk6.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-wxwk6.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-wxwk6.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-wxwk6.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-wxwk6.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-wxwk6.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-wxwk6.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-wxwk6.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-wxwk6.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-wxwk6.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-wxwk6.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-wxwk6.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-wxwk6.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 219.204.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.204.219_udp@PTR;check="$$(dig +tcp +noall +answer +search 219.204.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.204.219_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-wxwk6 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-wxwk6;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-wxwk6 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-wxwk6;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-wxwk6.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-wxwk6.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-wxwk6.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-wxwk6.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-wxwk6.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-wxwk6.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-wxwk6.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-wxwk6.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-wxwk6.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-wxwk6.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-wxwk6.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-wxwk6.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-wxwk6.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 219.204.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.204.219_udp@PTR;check="$$(dig +tcp +noall +answer +search 219.204.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.204.219_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep  3 16:33:50.566: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-wxwk6/dns-test-929883da-ce68-11e9-a956-0a580af40009: the server could not find the requested resource (get pods dns-test-929883da-ce68-11e9-a956-0a580af40009)
Sep  3 16:33:50.575: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-wxwk6/dns-test-929883da-ce68-11e9-a956-0a580af40009: the server could not find the requested resource (get pods dns-test-929883da-ce68-11e9-a956-0a580af40009)
Sep  3 16:33:50.583: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-wxwk6 from pod e2e-tests-dns-wxwk6/dns-test-929883da-ce68-11e9-a956-0a580af40009: the server could not find the requested resource (get pods dns-test-929883da-ce68-11e9-a956-0a580af40009)
Sep  3 16:33:50.591: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-wxwk6 from pod e2e-tests-dns-wxwk6/dns-test-929883da-ce68-11e9-a956-0a580af40009: the server could not find the requested resource (get pods dns-test-929883da-ce68-11e9-a956-0a580af40009)
Sep  3 16:33:50.599: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-wxwk6.svc from pod e2e-tests-dns-wxwk6/dns-test-929883da-ce68-11e9-a956-0a580af40009: the server could not find the requested resource (get pods dns-test-929883da-ce68-11e9-a956-0a580af40009)
Sep  3 16:33:50.608: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-wxwk6.svc from pod e2e-tests-dns-wxwk6/dns-test-929883da-ce68-11e9-a956-0a580af40009: the server could not find the requested resource (get pods dns-test-929883da-ce68-11e9-a956-0a580af40009)
Sep  3 16:33:50.616: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-wxwk6.svc from pod e2e-tests-dns-wxwk6/dns-test-929883da-ce68-11e9-a956-0a580af40009: the server could not find the requested resource (get pods dns-test-929883da-ce68-11e9-a956-0a580af40009)
Sep  3 16:33:50.625: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-wxwk6.svc from pod e2e-tests-dns-wxwk6/dns-test-929883da-ce68-11e9-a956-0a580af40009: the server could not find the requested resource (get pods dns-test-929883da-ce68-11e9-a956-0a580af40009)
Sep  3 16:33:50.674: INFO: Lookups using e2e-tests-dns-wxwk6/dns-test-929883da-ce68-11e9-a956-0a580af40009 failed for: [jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-wxwk6 jessie_tcp@dns-test-service.e2e-tests-dns-wxwk6 jessie_udp@dns-test-service.e2e-tests-dns-wxwk6.svc jessie_tcp@dns-test-service.e2e-tests-dns-wxwk6.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-wxwk6.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-wxwk6.svc]

Sep  3 16:33:55.960: INFO: DNS probes using e2e-tests-dns-wxwk6/dns-test-929883da-ce68-11e9-a956-0a580af40009 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:33:56.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-wxwk6" for this suite.
Sep  3 16:34:02.199: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:34:02.933: INFO: namespace: e2e-tests-dns-wxwk6, resource: bindings, ignored listing per whitelist
Sep  3 16:34:03.120: INFO: namespace e2e-tests-dns-wxwk6 deletion completed in 6.981591338s

• [SLOW TEST:29.020 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:34:03.120: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-a3dc2d93-ce68-11e9-a956-0a580af40009
STEP: Creating a pod to test consume secrets
Sep  3 16:34:03.377: INFO: Waiting up to 5m0s for pod "pod-secrets-a3ea75f2-ce68-11e9-a956-0a580af40009" in namespace "e2e-tests-secrets-l5bq7" to be "success or failure"
Sep  3 16:34:03.401: INFO: Pod "pod-secrets-a3ea75f2-ce68-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 23.622301ms
Sep  3 16:34:05.407: INFO: Pod "pod-secrets-a3ea75f2-ce68-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029874577s
Sep  3 16:34:07.420: INFO: Pod "pod-secrets-a3ea75f2-ce68-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042819993s
STEP: Saw pod success
Sep  3 16:34:07.420: INFO: Pod "pod-secrets-a3ea75f2-ce68-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 16:34:07.426: INFO: Trying to get logs from node 10.0.10.2 pod pod-secrets-a3ea75f2-ce68-11e9-a956-0a580af40009 container secret-volume-test: <nil>
STEP: delete the pod
Sep  3 16:34:07.498: INFO: Waiting for pod pod-secrets-a3ea75f2-ce68-11e9-a956-0a580af40009 to disappear
Sep  3 16:34:07.522: INFO: Pod pod-secrets-a3ea75f2-ce68-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:34:07.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-l5bq7" for this suite.
Sep  3 16:34:13.586: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:34:14.207: INFO: namespace: e2e-tests-secrets-l5bq7, resource: bindings, ignored listing per whitelist
Sep  3 16:34:14.450: INFO: namespace e2e-tests-secrets-l5bq7 deletion completed in 6.921865348s
STEP: Destroying namespace "e2e-tests-secret-namespace-kr47j" for this suite.
Sep  3 16:34:20.509: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:34:21.155: INFO: namespace: e2e-tests-secret-namespace-kr47j, resource: bindings, ignored listing per whitelist
Sep  3 16:34:21.449: INFO: namespace e2e-tests-secret-namespace-kr47j deletion completed in 6.999403757s

• [SLOW TEST:18.329 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:34:21.449: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  3 16:34:47.649: INFO: Container started at 2019-09-03 16:34:22 +0000 UTC, pod became ready at 2019-09-03 16:34:46 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:34:47.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-6sgxw" for this suite.
Sep  3 16:35:09.730: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:35:10.522: INFO: namespace: e2e-tests-container-probe-6sgxw, resource: bindings, ignored listing per whitelist
Sep  3 16:35:10.600: INFO: namespace e2e-tests-container-probe-6sgxw deletion completed in 22.945148588s

• [SLOW TEST:49.151 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:35:10.600: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Sep  3 16:35:10.758: INFO: Waiting up to 5m0s for pod "pod-cc141ce5-ce68-11e9-a956-0a580af40009" in namespace "e2e-tests-emptydir-dbvmm" to be "success or failure"
Sep  3 16:35:10.783: INFO: Pod "pod-cc141ce5-ce68-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 24.724259ms
Sep  3 16:35:12.788: INFO: Pod "pod-cc141ce5-ce68-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030685802s
STEP: Saw pod success
Sep  3 16:35:12.789: INFO: Pod "pod-cc141ce5-ce68-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 16:35:12.794: INFO: Trying to get logs from node 10.0.10.2 pod pod-cc141ce5-ce68-11e9-a956-0a580af40009 container test-container: <nil>
STEP: delete the pod
Sep  3 16:35:12.867: INFO: Waiting for pod pod-cc141ce5-ce68-11e9-a956-0a580af40009 to disappear
Sep  3 16:35:12.892: INFO: Pod pod-cc141ce5-ce68-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:35:12.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-dbvmm" for this suite.
Sep  3 16:35:18.956: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:35:19.787: INFO: namespace: e2e-tests-emptydir-dbvmm, resource: bindings, ignored listing per whitelist
Sep  3 16:35:19.888: INFO: namespace e2e-tests-emptydir-dbvmm deletion completed in 6.990741714s

• [SLOW TEST:9.288 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:35:19.889: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-ktvl
STEP: Creating a pod to test atomic-volume-subpath
Sep  3 16:35:20.100: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-ktvl" in namespace "e2e-tests-subpath-2b4l9" to be "success or failure"
Sep  3 16:35:20.123: INFO: Pod "pod-subpath-test-configmap-ktvl": Phase="Pending", Reason="", readiness=false. Elapsed: 23.767033ms
Sep  3 16:35:22.130: INFO: Pod "pod-subpath-test-configmap-ktvl": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029985236s
Sep  3 16:35:24.136: INFO: Pod "pod-subpath-test-configmap-ktvl": Phase="Running", Reason="", readiness=false. Elapsed: 4.035964402s
Sep  3 16:35:26.149: INFO: Pod "pod-subpath-test-configmap-ktvl": Phase="Running", Reason="", readiness=false. Elapsed: 6.049350054s
Sep  3 16:35:28.155: INFO: Pod "pod-subpath-test-configmap-ktvl": Phase="Running", Reason="", readiness=false. Elapsed: 8.055551254s
Sep  3 16:35:30.161: INFO: Pod "pod-subpath-test-configmap-ktvl": Phase="Running", Reason="", readiness=false. Elapsed: 10.061830336s
Sep  3 16:35:32.168: INFO: Pod "pod-subpath-test-configmap-ktvl": Phase="Running", Reason="", readiness=false. Elapsed: 12.068197716s
Sep  3 16:35:34.174: INFO: Pod "pod-subpath-test-configmap-ktvl": Phase="Running", Reason="", readiness=false. Elapsed: 14.074295105s
Sep  3 16:35:36.186: INFO: Pod "pod-subpath-test-configmap-ktvl": Phase="Running", Reason="", readiness=false. Elapsed: 16.086889474s
Sep  3 16:35:38.192: INFO: Pod "pod-subpath-test-configmap-ktvl": Phase="Running", Reason="", readiness=false. Elapsed: 18.092754936s
Sep  3 16:35:40.199: INFO: Pod "pod-subpath-test-configmap-ktvl": Phase="Running", Reason="", readiness=false. Elapsed: 20.099429365s
Sep  3 16:35:42.205: INFO: Pod "pod-subpath-test-configmap-ktvl": Phase="Running", Reason="", readiness=false. Elapsed: 22.105457937s
Sep  3 16:35:44.421: INFO: Pod "pod-subpath-test-configmap-ktvl": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.32161537s
STEP: Saw pod success
Sep  3 16:35:44.421: INFO: Pod "pod-subpath-test-configmap-ktvl" satisfied condition "success or failure"
Sep  3 16:35:44.427: INFO: Trying to get logs from node 10.0.10.2 pod pod-subpath-test-configmap-ktvl container test-container-subpath-configmap-ktvl: <nil>
STEP: delete the pod
Sep  3 16:35:44.505: INFO: Waiting for pod pod-subpath-test-configmap-ktvl to disappear
Sep  3 16:35:44.535: INFO: Pod pod-subpath-test-configmap-ktvl no longer exists
STEP: Deleting pod pod-subpath-test-configmap-ktvl
Sep  3 16:35:44.535: INFO: Deleting pod "pod-subpath-test-configmap-ktvl" in namespace "e2e-tests-subpath-2b4l9"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:35:44.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-2b4l9" for this suite.
Sep  3 16:35:50.617: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:35:51.467: INFO: namespace: e2e-tests-subpath-2b4l9, resource: bindings, ignored listing per whitelist
Sep  3 16:35:51.552: INFO: namespace e2e-tests-subpath-2b4l9 deletion completed in 7.006134884s

• [SLOW TEST:31.663 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:35:51.552: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Sep  3 16:35:51.689: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 create -f - --namespace=e2e-tests-kubectl-xd75t'
Sep  3 16:35:51.953: INFO: stderr: ""
Sep  3 16:35:51.953: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep  3 16:35:51.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-xd75t'
Sep  3 16:35:52.154: INFO: stderr: ""
Sep  3 16:35:52.154: INFO: stdout: "update-demo-nautilus-87fnt update-demo-nautilus-9mfpx "
Sep  3 16:35:52.154: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 get pods update-demo-nautilus-87fnt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-xd75t'
Sep  3 16:35:52.286: INFO: stderr: ""
Sep  3 16:35:52.286: INFO: stdout: ""
Sep  3 16:35:52.286: INFO: update-demo-nautilus-87fnt is created but not running
Sep  3 16:35:57.286: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-xd75t'
Sep  3 16:35:57.618: INFO: stderr: ""
Sep  3 16:35:57.618: INFO: stdout: "update-demo-nautilus-87fnt update-demo-nautilus-9mfpx "
Sep  3 16:35:57.619: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 get pods update-demo-nautilus-87fnt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-xd75t'
Sep  3 16:35:57.733: INFO: stderr: ""
Sep  3 16:35:57.733: INFO: stdout: "true"
Sep  3 16:35:57.733: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 get pods update-demo-nautilus-87fnt -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-xd75t'
Sep  3 16:35:57.814: INFO: stderr: ""
Sep  3 16:35:57.814: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  3 16:35:57.814: INFO: validating pod update-demo-nautilus-87fnt
Sep  3 16:35:57.904: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  3 16:35:57.904: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  3 16:35:57.904: INFO: update-demo-nautilus-87fnt is verified up and running
Sep  3 16:35:57.904: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 get pods update-demo-nautilus-9mfpx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-xd75t'
Sep  3 16:35:58.008: INFO: stderr: ""
Sep  3 16:35:58.008: INFO: stdout: "true"
Sep  3 16:35:58.008: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 get pods update-demo-nautilus-9mfpx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-xd75t'
Sep  3 16:35:58.113: INFO: stderr: ""
Sep  3 16:35:58.113: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  3 16:35:58.113: INFO: validating pod update-demo-nautilus-9mfpx
Sep  3 16:35:58.251: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  3 16:35:58.251: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  3 16:35:58.251: INFO: update-demo-nautilus-9mfpx is verified up and running
STEP: using delete to clean up resources
Sep  3 16:35:58.251: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-xd75t'
Sep  3 16:35:58.394: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  3 16:35:58.394: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Sep  3 16:35:58.394: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-xd75t'
Sep  3 16:35:58.676: INFO: stderr: "No resources found.\n"
Sep  3 16:35:58.676: INFO: stdout: ""
Sep  3 16:35:58.676: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 get pods -l name=update-demo --namespace=e2e-tests-kubectl-xd75t -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep  3 16:35:58.898: INFO: stderr: ""
Sep  3 16:35:58.898: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:35:58.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xd75t" for this suite.
Sep  3 16:36:20.973: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:36:21.703: INFO: namespace: e2e-tests-kubectl-xd75t, resource: bindings, ignored listing per whitelist
Sep  3 16:36:21.841: INFO: namespace e2e-tests-kubectl-xd75t deletion completed in 22.937563528s

• [SLOW TEST:30.290 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:36:21.842: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Sep  3 16:36:24.111: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-f68c0e97-ce68-11e9-a956-0a580af40009", GenerateName:"", Namespace:"e2e-tests-pods-hww97", SelfLink:"/api/v1/namespaces/e2e-tests-pods-hww97/pods/pod-submit-remove-f68c0e97-ce68-11e9-a956-0a580af40009", UID:"f698b9fb-ce68-11e9-9b93-0a580aed0c4f", ResourceVersion:"629215", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63703125382, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"980540088"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-f4v6w", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001426080), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-f4v6w", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0015595a8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10.0.10.2", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00200baa0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001559660)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001559680)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001559688), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00155968c)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703125382, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703125383, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703125383, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703125382, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.0.10.2", PodIP:"10.244.0.251", StartTime:(*v1.Time)(0xc001c5e120), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc001c5e140), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7", ContainerID:"docker://47f5088357e8a7d7f9c4d9afd1f97820170fab1d4ae8c70c243969f7d00f5d68"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Sep  3 16:36:29.213: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:36:29.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-hww97" for this suite.
Sep  3 16:36:35.302: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:36:35.781: INFO: namespace: e2e-tests-pods-hww97, resource: bindings, ignored listing per whitelist
Sep  3 16:36:36.193: INFO: namespace e2e-tests-pods-hww97 deletion completed in 6.96870712s

• [SLOW TEST:14.352 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:36:36.193: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Sep  3 16:36:36.360: INFO: Waiting up to 5m0s for pod "pod-ff1992ba-ce68-11e9-a956-0a580af40009" in namespace "e2e-tests-emptydir-f6thz" to be "success or failure"
Sep  3 16:36:36.386: INFO: Pod "pod-ff1992ba-ce68-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 25.770368ms
Sep  3 16:36:38.392: INFO: Pod "pod-ff1992ba-ce68-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.032114494s
STEP: Saw pod success
Sep  3 16:36:38.392: INFO: Pod "pod-ff1992ba-ce68-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 16:36:38.397: INFO: Trying to get logs from node 10.0.10.2 pod pod-ff1992ba-ce68-11e9-a956-0a580af40009 container test-container: <nil>
STEP: delete the pod
Sep  3 16:36:38.467: INFO: Waiting for pod pod-ff1992ba-ce68-11e9-a956-0a580af40009 to disappear
Sep  3 16:36:38.492: INFO: Pod pod-ff1992ba-ce68-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:36:38.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-f6thz" for this suite.
Sep  3 16:36:44.558: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:36:45.355: INFO: namespace: e2e-tests-emptydir-f6thz, resource: bindings, ignored listing per whitelist
Sep  3 16:36:45.386: INFO: namespace e2e-tests-emptydir-f6thz deletion completed in 6.885681513s

• [SLOW TEST:9.192 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:36:45.386: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Sep  3 16:36:45.689: INFO: Number of nodes with available pods: 0
Sep  3 16:36:45.689: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 16:36:46.703: INFO: Number of nodes with available pods: 0
Sep  3 16:36:46.703: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 16:36:47.708: INFO: Number of nodes with available pods: 1
Sep  3 16:36:47.708: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Stop a daemon pod, check that the daemon pod is revived.
Sep  3 16:36:47.780: INFO: Number of nodes with available pods: 0
Sep  3 16:36:47.780: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 16:36:48.792: INFO: Number of nodes with available pods: 0
Sep  3 16:36:48.792: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 16:36:49.792: INFO: Number of nodes with available pods: 0
Sep  3 16:36:49.792: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 16:36:50.792: INFO: Number of nodes with available pods: 0
Sep  3 16:36:50.792: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 16:36:51.804: INFO: Number of nodes with available pods: 0
Sep  3 16:36:51.804: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 16:36:52.799: INFO: Number of nodes with available pods: 0
Sep  3 16:36:52.799: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 16:36:54.012: INFO: Number of nodes with available pods: 0
Sep  3 16:36:54.012: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 16:36:54.793: INFO: Number of nodes with available pods: 0
Sep  3 16:36:54.793: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 16:36:55.793: INFO: Number of nodes with available pods: 0
Sep  3 16:36:55.793: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 16:36:56.792: INFO: Number of nodes with available pods: 0
Sep  3 16:36:56.792: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 16:36:57.792: INFO: Number of nodes with available pods: 0
Sep  3 16:36:57.792: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 16:36:58.792: INFO: Number of nodes with available pods: 0
Sep  3 16:36:58.792: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 16:36:59.792: INFO: Number of nodes with available pods: 0
Sep  3 16:36:59.792: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 16:37:00.792: INFO: Number of nodes with available pods: 0
Sep  3 16:37:00.792: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 16:37:01.793: INFO: Number of nodes with available pods: 0
Sep  3 16:37:01.793: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 16:37:02.792: INFO: Number of nodes with available pods: 0
Sep  3 16:37:02.792: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 16:37:03.799: INFO: Number of nodes with available pods: 0
Sep  3 16:37:03.799: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 16:37:04.793: INFO: Number of nodes with available pods: 0
Sep  3 16:37:04.793: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 16:37:05.792: INFO: Number of nodes with available pods: 0
Sep  3 16:37:05.792: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 16:37:06.792: INFO: Number of nodes with available pods: 0
Sep  3 16:37:06.792: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 16:37:07.792: INFO: Number of nodes with available pods: 0
Sep  3 16:37:07.792: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 16:37:08.792: INFO: Number of nodes with available pods: 0
Sep  3 16:37:08.792: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 16:37:09.792: INFO: Number of nodes with available pods: 0
Sep  3 16:37:09.792: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 16:37:10.813: INFO: Number of nodes with available pods: 0
Sep  3 16:37:10.813: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 16:37:11.793: INFO: Number of nodes with available pods: 0
Sep  3 16:37:11.793: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 16:37:12.792: INFO: Number of nodes with available pods: 0
Sep  3 16:37:12.792: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 16:37:13.792: INFO: Number of nodes with available pods: 0
Sep  3 16:37:13.792: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 16:37:14.799: INFO: Number of nodes with available pods: 0
Sep  3 16:37:14.799: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 16:37:15.792: INFO: Number of nodes with available pods: 0
Sep  3 16:37:15.792: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 16:37:16.792: INFO: Number of nodes with available pods: 0
Sep  3 16:37:16.792: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 16:37:17.792: INFO: Number of nodes with available pods: 0
Sep  3 16:37:17.792: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 16:37:18.792: INFO: Number of nodes with available pods: 0
Sep  3 16:37:18.792: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 16:37:19.794: INFO: Number of nodes with available pods: 0
Sep  3 16:37:19.794: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 16:37:20.792: INFO: Number of nodes with available pods: 0
Sep  3 16:37:20.792: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 16:37:21.792: INFO: Number of nodes with available pods: 0
Sep  3 16:37:21.792: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 16:37:22.792: INFO: Number of nodes with available pods: 0
Sep  3 16:37:22.792: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 16:37:23.792: INFO: Number of nodes with available pods: 0
Sep  3 16:37:23.792: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 16:37:24.792: INFO: Number of nodes with available pods: 0
Sep  3 16:37:24.792: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 16:37:25.798: INFO: Number of nodes with available pods: 0
Sep  3 16:37:25.798: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 16:37:26.792: INFO: Number of nodes with available pods: 0
Sep  3 16:37:26.792: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 16:37:27.792: INFO: Number of nodes with available pods: 0
Sep  3 16:37:27.792: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 16:37:28.791: INFO: Number of nodes with available pods: 0
Sep  3 16:37:28.791: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 16:37:29.793: INFO: Number of nodes with available pods: 0
Sep  3 16:37:29.793: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 16:37:30.792: INFO: Number of nodes with available pods: 0
Sep  3 16:37:30.792: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 16:37:31.792: INFO: Number of nodes with available pods: 1
Sep  3 16:37:31.792: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-h8t4z, will wait for the garbage collector to delete the pods
Sep  3 16:37:31.938: INFO: Deleting DaemonSet.extensions daemon-set took: 39.330668ms
Sep  3 16:37:32.038: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.229099ms
Sep  3 16:38:09.451: INFO: Number of nodes with available pods: 0
Sep  3 16:38:09.451: INFO: Number of running nodes: 0, number of available pods: 0
Sep  3 16:38:09.456: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-h8t4z/daemonsets","resourceVersion":"629496"},"items":null}

Sep  3 16:38:09.461: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-h8t4z/pods","resourceVersion":"629496"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:38:09.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-h8t4z" for this suite.
Sep  3 16:38:15.524: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:38:15.980: INFO: namespace: e2e-tests-daemonsets-h8t4z, resource: bindings, ignored listing per whitelist
Sep  3 16:38:16.290: INFO: namespace e2e-tests-daemonsets-h8t4z deletion completed in 6.812796026s

• [SLOW TEST:90.904 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:38:16.291: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-3ac4dee3-ce69-11e9-a956-0a580af40009
STEP: Creating a pod to test consume secrets
Sep  3 16:38:16.491: INFO: Waiting up to 5m0s for pod "pod-secrets-3ac8afc1-ce69-11e9-a956-0a580af40009" in namespace "e2e-tests-secrets-7gf5b" to be "success or failure"
Sep  3 16:38:16.528: INFO: Pod "pod-secrets-3ac8afc1-ce69-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 37.037174ms
Sep  3 16:38:18.534: INFO: Pod "pod-secrets-3ac8afc1-ce69-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.042958118s
STEP: Saw pod success
Sep  3 16:38:18.534: INFO: Pod "pod-secrets-3ac8afc1-ce69-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 16:38:18.539: INFO: Trying to get logs from node 10.0.10.2 pod pod-secrets-3ac8afc1-ce69-11e9-a956-0a580af40009 container secret-volume-test: <nil>
STEP: delete the pod
Sep  3 16:38:18.614: INFO: Waiting for pod pod-secrets-3ac8afc1-ce69-11e9-a956-0a580af40009 to disappear
Sep  3 16:38:18.643: INFO: Pod pod-secrets-3ac8afc1-ce69-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:38:18.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-7gf5b" for this suite.
Sep  3 16:38:24.704: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:38:25.169: INFO: namespace: e2e-tests-secrets-7gf5b, resource: bindings, ignored listing per whitelist
Sep  3 16:38:25.528: INFO: namespace e2e-tests-secrets-7gf5b deletion completed in 6.87841787s

• [SLOW TEST:9.237 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:38:25.528: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-tkkvd/configmap-test-40444703-ce69-11e9-a956-0a580af40009
STEP: Creating a pod to test consume configMaps
Sep  3 16:38:25.714: INFO: Waiting up to 5m0s for pod "pod-configmaps-40482299-ce69-11e9-a956-0a580af40009" in namespace "e2e-tests-configmap-tkkvd" to be "success or failure"
Sep  3 16:38:25.737: INFO: Pod "pod-configmaps-40482299-ce69-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 23.003756ms
Sep  3 16:38:27.743: INFO: Pod "pod-configmaps-40482299-ce69-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02889076s
STEP: Saw pod success
Sep  3 16:38:27.743: INFO: Pod "pod-configmaps-40482299-ce69-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 16:38:27.749: INFO: Trying to get logs from node 10.0.10.2 pod pod-configmaps-40482299-ce69-11e9-a956-0a580af40009 container env-test: <nil>
STEP: delete the pod
Sep  3 16:38:27.818: INFO: Waiting for pod pod-configmaps-40482299-ce69-11e9-a956-0a580af40009 to disappear
Sep  3 16:38:27.845: INFO: Pod pod-configmaps-40482299-ce69-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:38:27.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-tkkvd" for this suite.
Sep  3 16:38:33.909: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:38:34.273: INFO: namespace: e2e-tests-configmap-tkkvd, resource: bindings, ignored listing per whitelist
Sep  3 16:38:34.794: INFO: namespace e2e-tests-configmap-tkkvd deletion completed in 6.943210717s

• [SLOW TEST:9.265 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:38:34.794: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-llrsh
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Sep  3 16:38:35.071: INFO: Found 1 stateful pods, waiting for 3
Sep  3 16:38:45.085: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep  3 16:38:45.085: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep  3 16:38:45.085: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Sep  3 16:38:45.129: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 exec --namespace=e2e-tests-statefulset-llrsh ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  3 16:38:45.506: INFO: stderr: ""
Sep  3 16:38:45.506: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  3 16:38:45.506: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Sep  3 16:38:55.584: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Sep  3 16:39:05.621: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 exec --namespace=e2e-tests-statefulset-llrsh ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  3 16:39:06.081: INFO: stderr: ""
Sep  3 16:39:06.081: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  3 16:39:06.081: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  3 16:39:16.122: INFO: Waiting for StatefulSet e2e-tests-statefulset-llrsh/ss2 to complete update
Sep  3 16:39:16.122: INFO: Waiting for Pod e2e-tests-statefulset-llrsh/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Sep  3 16:39:16.122: INFO: Waiting for Pod e2e-tests-statefulset-llrsh/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Sep  3 16:39:16.122: INFO: Waiting for Pod e2e-tests-statefulset-llrsh/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Sep  3 16:39:26.142: INFO: Waiting for StatefulSet e2e-tests-statefulset-llrsh/ss2 to complete update
Sep  3 16:39:26.142: INFO: Waiting for Pod e2e-tests-statefulset-llrsh/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Sep  3 16:39:26.142: INFO: Waiting for Pod e2e-tests-statefulset-llrsh/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Sep  3 16:39:36.135: INFO: Waiting for StatefulSet e2e-tests-statefulset-llrsh/ss2 to complete update
Sep  3 16:39:36.135: INFO: Waiting for Pod e2e-tests-statefulset-llrsh/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Sep  3 16:39:46.211: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 exec --namespace=e2e-tests-statefulset-llrsh ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  3 16:39:46.584: INFO: stderr: ""
Sep  3 16:39:46.584: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  3 16:39:46.584: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  3 16:39:56.639: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Sep  3 16:40:06.674: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 exec --namespace=e2e-tests-statefulset-llrsh ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  3 16:40:06.986: INFO: stderr: ""
Sep  3 16:40:06.986: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  3 16:40:06.986: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  3 16:40:17.030: INFO: Waiting for StatefulSet e2e-tests-statefulset-llrsh/ss2 to complete update
Sep  3 16:40:17.030: INFO: Waiting for Pod e2e-tests-statefulset-llrsh/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Sep  3 16:40:17.030: INFO: Waiting for Pod e2e-tests-statefulset-llrsh/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Sep  3 16:40:17.030: INFO: Waiting for Pod e2e-tests-statefulset-llrsh/ss2-2 to have revision ss2-787997d666 update revision ss2-c79899b9
Sep  3 16:40:27.048: INFO: Waiting for StatefulSet e2e-tests-statefulset-llrsh/ss2 to complete update
Sep  3 16:40:27.048: INFO: Waiting for Pod e2e-tests-statefulset-llrsh/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Sep  3 16:40:27.048: INFO: Waiting for Pod e2e-tests-statefulset-llrsh/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Sep  3 16:40:37.042: INFO: Deleting all statefulset in ns e2e-tests-statefulset-llrsh
Sep  3 16:40:37.084: INFO: Scaling statefulset ss2 to 0
Sep  3 16:41:17.108: INFO: Waiting for statefulset status.replicas updated to 0
Sep  3 16:41:17.113: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:41:17.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-llrsh" for this suite.
Sep  3 16:41:23.334: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:41:24.115: INFO: namespace: e2e-tests-statefulset-llrsh, resource: bindings, ignored listing per whitelist
Sep  3 16:41:24.180: INFO: namespace e2e-tests-statefulset-llrsh deletion completed in 6.92798919s

• [SLOW TEST:169.385 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:41:24.180: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  3 16:41:24.333: INFO: (0) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 12.390406ms)
Sep  3 16:41:24.342: INFO: (1) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 8.904141ms)
Sep  3 16:41:24.351: INFO: (2) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 9.055701ms)
Sep  3 16:41:24.360: INFO: (3) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 9.284278ms)
Sep  3 16:41:24.369: INFO: (4) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 8.844044ms)
Sep  3 16:41:24.378: INFO: (5) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 8.711363ms)
Sep  3 16:41:24.386: INFO: (6) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 8.32925ms)
Sep  3 16:41:24.395: INFO: (7) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 8.544356ms)
Sep  3 16:41:24.403: INFO: (8) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 8.228488ms)
Sep  3 16:41:24.412: INFO: (9) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 8.555677ms)
Sep  3 16:41:24.421: INFO: (10) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 9.130983ms)
Sep  3 16:41:24.429: INFO: (11) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 8.364108ms)
Sep  3 16:41:24.438: INFO: (12) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 8.741258ms)
Sep  3 16:41:24.446: INFO: (13) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 8.471141ms)
Sep  3 16:41:24.455: INFO: (14) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 8.343554ms)
Sep  3 16:41:24.464: INFO: (15) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 8.656666ms)
Sep  3 16:41:24.472: INFO: (16) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 8.692755ms)
Sep  3 16:41:24.481: INFO: (17) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 8.398042ms)
Sep  3 16:41:24.489: INFO: (18) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 8.436746ms)
Sep  3 16:41:24.498: INFO: (19) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 8.478068ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:41:24.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-64wx4" for this suite.
Sep  3 16:41:30.563: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:41:30.574: INFO: namespace: e2e-tests-proxy-64wx4, resource: bindings, ignored listing per whitelist
Sep  3 16:41:31.719: INFO: namespace e2e-tests-proxy-64wx4 deletion completed in 7.216014335s

• [SLOW TEST:7.539 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:41:31.719: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Sep  3 16:41:31.883: INFO: Waiting up to 5m0s for pod "downwardapi-volume-af3e862c-ce69-11e9-a956-0a580af40009" in namespace "e2e-tests-downward-api-sxhtz" to be "success or failure"
Sep  3 16:41:31.909: INFO: Pod "downwardapi-volume-af3e862c-ce69-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 26.11526ms
Sep  3 16:41:33.916: INFO: Pod "downwardapi-volume-af3e862c-ce69-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.03244763s
STEP: Saw pod success
Sep  3 16:41:33.916: INFO: Pod "downwardapi-volume-af3e862c-ce69-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 16:41:33.921: INFO: Trying to get logs from node 10.0.10.2 pod downwardapi-volume-af3e862c-ce69-11e9-a956-0a580af40009 container client-container: <nil>
STEP: delete the pod
Sep  3 16:41:33.996: INFO: Waiting for pod downwardapi-volume-af3e862c-ce69-11e9-a956-0a580af40009 to disappear
Sep  3 16:41:34.024: INFO: Pod downwardapi-volume-af3e862c-ce69-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:41:34.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-sxhtz" for this suite.
Sep  3 16:41:40.102: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:41:40.169: INFO: namespace: e2e-tests-downward-api-sxhtz, resource: bindings, ignored listing per whitelist
Sep  3 16:41:41.027: INFO: namespace e2e-tests-downward-api-sxhtz deletion completed in 6.996766053s

• [SLOW TEST:9.308 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:41:41.027: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Sep  3 16:41:45.387: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  3 16:41:45.411: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  3 16:41:47.411: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  3 16:41:47.418: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  3 16:41:49.411: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  3 16:41:49.418: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  3 16:41:51.411: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  3 16:41:51.425: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  3 16:41:53.411: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  3 16:41:53.437: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  3 16:41:55.411: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  3 16:41:55.421: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  3 16:41:57.411: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  3 16:41:57.417: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  3 16:41:59.411: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  3 16:41:59.417: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  3 16:42:01.411: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  3 16:42:01.418: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  3 16:42:03.411: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  3 16:42:03.424: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  3 16:42:05.411: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  3 16:42:05.417: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  3 16:42:07.411: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  3 16:42:07.417: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  3 16:42:09.411: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  3 16:42:09.418: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:42:09.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-x5rbh" for this suite.
Sep  3 16:42:31.498: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:42:31.905: INFO: namespace: e2e-tests-container-lifecycle-hook-x5rbh, resource: bindings, ignored listing per whitelist
Sep  3 16:42:32.454: INFO: namespace e2e-tests-container-lifecycle-hook-x5rbh deletion completed in 23.030368369s

• [SLOW TEST:51.426 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:42:32.454: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Sep  3 16:42:32.691: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d37cd9ca-ce69-11e9-a956-0a580af40009" in namespace "e2e-tests-projected-hrghw" to be "success or failure"
Sep  3 16:42:32.718: INFO: Pod "downwardapi-volume-d37cd9ca-ce69-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 26.955221ms
Sep  3 16:42:34.724: INFO: Pod "downwardapi-volume-d37cd9ca-ce69-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033605589s
Sep  3 16:42:36.738: INFO: Pod "downwardapi-volume-d37cd9ca-ce69-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047061516s
STEP: Saw pod success
Sep  3 16:42:36.738: INFO: Pod "downwardapi-volume-d37cd9ca-ce69-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 16:42:36.743: INFO: Trying to get logs from node 10.0.10.2 pod downwardapi-volume-d37cd9ca-ce69-11e9-a956-0a580af40009 container client-container: <nil>
STEP: delete the pod
Sep  3 16:42:36.888: INFO: Waiting for pod downwardapi-volume-d37cd9ca-ce69-11e9-a956-0a580af40009 to disappear
Sep  3 16:42:36.915: INFO: Pod downwardapi-volume-d37cd9ca-ce69-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:42:36.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hrghw" for this suite.
Sep  3 16:42:42.986: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:42:43.228: INFO: namespace: e2e-tests-projected-hrghw, resource: bindings, ignored listing per whitelist
Sep  3 16:42:43.888: INFO: namespace e2e-tests-projected-hrghw deletion completed in 6.967049419s

• [SLOW TEST:11.434 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:42:43.889: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1134
STEP: creating an rc
Sep  3 16:42:44.029: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 create -f - --namespace=e2e-tests-kubectl-5lmjz'
Sep  3 16:42:44.256: INFO: stderr: ""
Sep  3 16:42:44.256: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Sep  3 16:42:45.282: INFO: Selector matched 1 pods for map[app:redis]
Sep  3 16:42:45.282: INFO: Found 0 / 1
Sep  3 16:42:46.263: INFO: Selector matched 1 pods for map[app:redis]
Sep  3 16:42:46.263: INFO: Found 1 / 1
Sep  3 16:42:46.263: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Sep  3 16:42:46.268: INFO: Selector matched 1 pods for map[app:redis]
Sep  3 16:42:46.268: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Sep  3 16:42:46.268: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 logs redis-master-kdkwv redis-master --namespace=e2e-tests-kubectl-5lmjz'
Sep  3 16:42:46.453: INFO: stderr: ""
Sep  3 16:42:46.453: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 03 Sep 16:42:45.156 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 03 Sep 16:42:45.156 # Server started, Redis version 3.2.12\n1:M 03 Sep 16:42:45.157 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 03 Sep 16:42:45.157 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Sep  3 16:42:46.453: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 log redis-master-kdkwv redis-master --namespace=e2e-tests-kubectl-5lmjz --tail=1'
Sep  3 16:42:46.566: INFO: stderr: ""
Sep  3 16:42:46.566: INFO: stdout: "1:M 03 Sep 16:42:45.157 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Sep  3 16:42:46.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 log redis-master-kdkwv redis-master --namespace=e2e-tests-kubectl-5lmjz --limit-bytes=1'
Sep  3 16:42:46.720: INFO: stderr: ""
Sep  3 16:42:46.720: INFO: stdout: " "
STEP: exposing timestamps
Sep  3 16:42:46.720: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 log redis-master-kdkwv redis-master --namespace=e2e-tests-kubectl-5lmjz --tail=1 --timestamps'
Sep  3 16:42:46.818: INFO: stderr: ""
Sep  3 16:42:46.818: INFO: stdout: "2019-09-03T16:42:45.157543116Z 1:M 03 Sep 16:42:45.157 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Sep  3 16:42:49.318: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 log redis-master-kdkwv redis-master --namespace=e2e-tests-kubectl-5lmjz --since=1s'
Sep  3 16:42:49.456: INFO: stderr: ""
Sep  3 16:42:49.456: INFO: stdout: ""
Sep  3 16:42:49.456: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 log redis-master-kdkwv redis-master --namespace=e2e-tests-kubectl-5lmjz --since=24h'
Sep  3 16:42:49.576: INFO: stderr: ""
Sep  3 16:42:49.576: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 03 Sep 16:42:45.156 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 03 Sep 16:42:45.156 # Server started, Redis version 3.2.12\n1:M 03 Sep 16:42:45.157 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 03 Sep 16:42:45.157 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1140
STEP: using delete to clean up resources
Sep  3 16:42:49.577: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-5lmjz'
Sep  3 16:42:49.707: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  3 16:42:49.707: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Sep  3 16:42:49.707: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-5lmjz'
Sep  3 16:42:49.882: INFO: stderr: "No resources found.\n"
Sep  3 16:42:49.882: INFO: stdout: ""
Sep  3 16:42:49.882: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 get pods -l name=nginx --namespace=e2e-tests-kubectl-5lmjz -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep  3 16:42:50.082: INFO: stderr: ""
Sep  3 16:42:50.082: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:42:50.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5lmjz" for this suite.
Sep  3 16:42:56.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:42:56.338: INFO: namespace: e2e-tests-kubectl-5lmjz, resource: bindings, ignored listing per whitelist
Sep  3 16:42:57.042: INFO: namespace e2e-tests-kubectl-5lmjz deletion completed in 6.952863833s

• [SLOW TEST:13.154 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:42:57.043: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Sep  3 16:42:57.228: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:42:58.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-jt6vj" for this suite.
Sep  3 16:43:06.353: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:43:06.708: INFO: namespace: e2e-tests-replication-controller-jt6vj, resource: bindings, ignored listing per whitelist
Sep  3 16:43:07.235: INFO: namespace e2e-tests-replication-controller-jt6vj deletion completed in 8.938717428s

• [SLOW TEST:10.192 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:43:07.235: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-e82d554a-ce69-11e9-a956-0a580af40009
STEP: Creating a pod to test consume secrets
Sep  3 16:43:07.421: INFO: Waiting up to 5m0s for pod "pod-secrets-e8311cd9-ce69-11e9-a956-0a580af40009" in namespace "e2e-tests-secrets-hz8kc" to be "success or failure"
Sep  3 16:43:07.449: INFO: Pod "pod-secrets-e8311cd9-ce69-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 27.850414ms
Sep  3 16:43:09.455: INFO: Pod "pod-secrets-e8311cd9-ce69-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033885891s
Sep  3 16:43:11.469: INFO: Pod "pod-secrets-e8311cd9-ce69-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047842884s
STEP: Saw pod success
Sep  3 16:43:11.469: INFO: Pod "pod-secrets-e8311cd9-ce69-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 16:43:11.474: INFO: Trying to get logs from node 10.0.10.2 pod pod-secrets-e8311cd9-ce69-11e9-a956-0a580af40009 container secret-volume-test: <nil>
STEP: delete the pod
Sep  3 16:43:11.548: INFO: Waiting for pod pod-secrets-e8311cd9-ce69-11e9-a956-0a580af40009 to disappear
Sep  3 16:43:11.571: INFO: Pod pod-secrets-e8311cd9-ce69-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:43:11.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-hz8kc" for this suite.
Sep  3 16:43:17.634: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:43:18.251: INFO: namespace: e2e-tests-secrets-hz8kc, resource: bindings, ignored listing per whitelist
Sep  3 16:43:18.648: INFO: namespace e2e-tests-secrets-hz8kc deletion completed in 7.071862795s

• [SLOW TEST:11.413 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:43:18.648: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-eefc78cc-ce69-11e9-a956-0a580af40009
STEP: Creating configMap with name cm-test-opt-upd-eefc7937-ce69-11e9-a956-0a580af40009
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-eefc78cc-ce69-11e9-a956-0a580af40009
STEP: Updating configmap cm-test-opt-upd-eefc7937-ce69-11e9-a956-0a580af40009
STEP: Creating configMap with name cm-test-opt-create-eefc795f-ce69-11e9-a956-0a580af40009
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:43:23.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ljtfk" for this suite.
Sep  3 16:43:45.228: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:43:45.959: INFO: namespace: e2e-tests-projected-ljtfk, resource: bindings, ignored listing per whitelist
Sep  3 16:43:46.194: INFO: namespace e2e-tests-projected-ljtfk deletion completed in 23.037073737s

• [SLOW TEST:27.545 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:43:46.194: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-ff699a7f-ce69-11e9-a956-0a580af40009
STEP: Creating configMap with name cm-test-opt-upd-ff699ac5-ce69-11e9-a956-0a580af40009
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-ff699a7f-ce69-11e9-a956-0a580af40009
STEP: Updating configmap cm-test-opt-upd-ff699ac5-ce69-11e9-a956-0a580af40009
STEP: Creating configMap with name cm-test-opt-create-ff699adb-ce69-11e9-a956-0a580af40009
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:43:52.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-q8s5m" for this suite.
Sep  3 16:44:14.766: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:44:14.949: INFO: namespace: e2e-tests-configmap-q8s5m, resource: bindings, ignored listing per whitelist
Sep  3 16:44:15.782: INFO: namespace e2e-tests-configmap-q8s5m deletion completed in 23.072627293s

• [SLOW TEST:29.588 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:44:15.782: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Sep  3 16:44:15.917: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 --namespace=e2e-tests-kubectl-98lbb run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Sep  3 16:44:18.266: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Sep  3 16:44:18.266: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:44:20.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-98lbb" for this suite.
Sep  3 16:44:26.350: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:44:27.187: INFO: namespace: e2e-tests-kubectl-98lbb, resource: bindings, ignored listing per whitelist
Sep  3 16:44:27.212: INFO: namespace e2e-tests-kubectl-98lbb deletion completed in 6.922092792s

• [SLOW TEST:11.430 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:44:27.212: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:44:31.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-x494q" for this suite.
Sep  3 16:44:37.501: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:44:37.916: INFO: namespace: e2e-tests-kubelet-test-x494q, resource: bindings, ignored listing per whitelist
Sep  3 16:44:38.337: INFO: namespace e2e-tests-kubelet-test-x494q deletion completed in 6.900207062s

• [SLOW TEST:11.125 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:44:38.337: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-1e7ca32e-ce6a-11e9-a956-0a580af40009
STEP: Creating secret with name s-test-opt-upd-1e7ca36b-ce6a-11e9-a956-0a580af40009
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-1e7ca32e-ce6a-11e9-a956-0a580af40009
STEP: Updating secret s-test-opt-upd-1e7ca36b-ce6a-11e9-a956-0a580af40009
STEP: Creating secret with name s-test-opt-create-1e7ca39d-ce6a-11e9-a956-0a580af40009
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:46:07.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-d97dm" for this suite.
Sep  3 16:46:29.353: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:46:29.580: INFO: namespace: e2e-tests-secrets-d97dm, resource: bindings, ignored listing per whitelist
Sep  3 16:46:30.278: INFO: namespace e2e-tests-secrets-d97dm deletion completed in 23.004616391s

• [SLOW TEST:111.941 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:46:30.278: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Sep  3 16:46:30.513: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-zmjmz,SelfLink:/api/v1/namespaces/e2e-tests-watch-zmjmz/configmaps/e2e-watch-test-watch-closed,UID:613a2dbd-ce6a-11e9-9b93-0a580aed0c4f,ResourceVersion:631249,Generation:0,CreationTimestamp:2019-09-03 16:46:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep  3 16:46:30.513: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-zmjmz,SelfLink:/api/v1/namespaces/e2e-tests-watch-zmjmz/configmaps/e2e-watch-test-watch-closed,UID:613a2dbd-ce6a-11e9-9b93-0a580aed0c4f,ResourceVersion:631250,Generation:0,CreationTimestamp:2019-09-03 16:46:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Sep  3 16:46:30.556: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-zmjmz,SelfLink:/api/v1/namespaces/e2e-tests-watch-zmjmz/configmaps/e2e-watch-test-watch-closed,UID:613a2dbd-ce6a-11e9-9b93-0a580aed0c4f,ResourceVersion:631251,Generation:0,CreationTimestamp:2019-09-03 16:46:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep  3 16:46:30.556: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-zmjmz,SelfLink:/api/v1/namespaces/e2e-tests-watch-zmjmz/configmaps/e2e-watch-test-watch-closed,UID:613a2dbd-ce6a-11e9-9b93-0a580aed0c4f,ResourceVersion:631252,Generation:0,CreationTimestamp:2019-09-03 16:46:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:46:30.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-zmjmz" for this suite.
Sep  3 16:46:36.646: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:46:36.976: INFO: namespace: e2e-tests-watch-zmjmz, resource: bindings, ignored listing per whitelist
Sep  3 16:46:37.552: INFO: namespace e2e-tests-watch-zmjmz deletion completed in 6.971011291s

• [SLOW TEST:7.274 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:46:37.552: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-658bb278-ce6a-11e9-a956-0a580af40009
STEP: Creating a pod to test consume secrets
Sep  3 16:46:37.763: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-658feff9-ce6a-11e9-a956-0a580af40009" in namespace "e2e-tests-projected-j2qdp" to be "success or failure"
Sep  3 16:46:37.795: INFO: Pod "pod-projected-secrets-658feff9-ce6a-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 32.020412ms
Sep  3 16:46:39.801: INFO: Pod "pod-projected-secrets-658feff9-ce6a-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.038300428s
STEP: Saw pod success
Sep  3 16:46:39.801: INFO: Pod "pod-projected-secrets-658feff9-ce6a-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 16:46:39.807: INFO: Trying to get logs from node 10.0.10.2 pod pod-projected-secrets-658feff9-ce6a-11e9-a956-0a580af40009 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep  3 16:46:40.119: INFO: Waiting for pod pod-projected-secrets-658feff9-ce6a-11e9-a956-0a580af40009 to disappear
Sep  3 16:46:40.148: INFO: Pod pod-projected-secrets-658feff9-ce6a-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:46:40.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-j2qdp" for this suite.
Sep  3 16:46:46.221: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:46:46.903: INFO: namespace: e2e-tests-projected-j2qdp, resource: bindings, ignored listing per whitelist
Sep  3 16:46:47.088: INFO: namespace e2e-tests-projected-j2qdp deletion completed in 6.934180246s

• [SLOW TEST:9.535 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:46:47.088: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-6b386eb3-ce6a-11e9-a956-0a580af40009
STEP: Creating a pod to test consume configMaps
Sep  3 16:46:47.445: INFO: Waiting up to 5m0s for pod "pod-configmaps-6b553874-ce6a-11e9-a956-0a580af40009" in namespace "e2e-tests-configmap-7ps2f" to be "success or failure"
Sep  3 16:46:47.472: INFO: Pod "pod-configmaps-6b553874-ce6a-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 26.716958ms
Sep  3 16:46:49.478: INFO: Pod "pod-configmaps-6b553874-ce6a-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.032815779s
STEP: Saw pod success
Sep  3 16:46:49.478: INFO: Pod "pod-configmaps-6b553874-ce6a-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 16:46:49.484: INFO: Trying to get logs from node 10.0.10.2 pod pod-configmaps-6b553874-ce6a-11e9-a956-0a580af40009 container configmap-volume-test: <nil>
STEP: delete the pod
Sep  3 16:46:49.555: INFO: Waiting for pod pod-configmaps-6b553874-ce6a-11e9-a956-0a580af40009 to disappear
Sep  3 16:46:49.581: INFO: Pod pod-configmaps-6b553874-ce6a-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:46:49.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-7ps2f" for this suite.
Sep  3 16:46:55.646: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:46:56.367: INFO: namespace: e2e-tests-configmap-7ps2f, resource: bindings, ignored listing per whitelist
Sep  3 16:46:56.733: INFO: namespace e2e-tests-configmap-7ps2f deletion completed in 7.146074633s

• [SLOW TEST:9.645 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:46:56.740: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-vqzct
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-vqzct
STEP: Deleting pre-stop pod
Sep  3 16:47:10.174: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:47:10.203: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-vqzct" for this suite.
Sep  3 16:47:50.269: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:47:50.774: INFO: namespace: e2e-tests-prestop-vqzct, resource: bindings, ignored listing per whitelist
Sep  3 16:47:51.290: INFO: namespace e2e-tests-prestop-vqzct deletion completed in 41.081016184s

• [SLOW TEST:54.550 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:47:51.290: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Sep  3 16:47:51.476: INFO: Waiting up to 5m0s for pod "pod-917fe693-ce6a-11e9-a956-0a580af40009" in namespace "e2e-tests-emptydir-62pvs" to be "success or failure"
Sep  3 16:47:51.504: INFO: Pod "pod-917fe693-ce6a-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 27.511047ms
Sep  3 16:47:53.509: INFO: Pod "pod-917fe693-ce6a-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.033419982s
STEP: Saw pod success
Sep  3 16:47:53.510: INFO: Pod "pod-917fe693-ce6a-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 16:47:53.515: INFO: Trying to get logs from node 10.0.10.2 pod pod-917fe693-ce6a-11e9-a956-0a580af40009 container test-container: <nil>
STEP: delete the pod
Sep  3 16:47:54.245: INFO: Waiting for pod pod-917fe693-ce6a-11e9-a956-0a580af40009 to disappear
Sep  3 16:47:54.414: INFO: Pod pod-917fe693-ce6a-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:47:54.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-62pvs" for this suite.
Sep  3 16:48:00.486: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:48:00.823: INFO: namespace: e2e-tests-emptydir-62pvs, resource: bindings, ignored listing per whitelist
Sep  3 16:48:01.357: INFO: namespace e2e-tests-emptydir-62pvs deletion completed in 6.930407268s

• [SLOW TEST:10.067 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:48:01.357: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-9fn2
STEP: Creating a pod to test atomic-volume-subpath
Sep  3 16:48:01.579: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-9fn2" in namespace "e2e-tests-subpath-n4g6l" to be "success or failure"
Sep  3 16:48:01.618: INFO: Pod "pod-subpath-test-secret-9fn2": Phase="Pending", Reason="", readiness=false. Elapsed: 39.370583ms
Sep  3 16:48:03.625: INFO: Pod "pod-subpath-test-secret-9fn2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.045626112s
Sep  3 16:48:05.638: INFO: Pod "pod-subpath-test-secret-9fn2": Phase="Running", Reason="", readiness=false. Elapsed: 4.058746523s
Sep  3 16:48:07.644: INFO: Pod "pod-subpath-test-secret-9fn2": Phase="Running", Reason="", readiness=false. Elapsed: 6.06508024s
Sep  3 16:48:09.652: INFO: Pod "pod-subpath-test-secret-9fn2": Phase="Running", Reason="", readiness=false. Elapsed: 8.073225339s
Sep  3 16:48:11.658: INFO: Pod "pod-subpath-test-secret-9fn2": Phase="Running", Reason="", readiness=false. Elapsed: 10.079050469s
Sep  3 16:48:13.664: INFO: Pod "pod-subpath-test-secret-9fn2": Phase="Running", Reason="", readiness=false. Elapsed: 12.085038986s
Sep  3 16:48:15.677: INFO: Pod "pod-subpath-test-secret-9fn2": Phase="Running", Reason="", readiness=false. Elapsed: 14.098451574s
Sep  3 16:48:17.683: INFO: Pod "pod-subpath-test-secret-9fn2": Phase="Running", Reason="", readiness=false. Elapsed: 16.104507433s
Sep  3 16:48:19.689: INFO: Pod "pod-subpath-test-secret-9fn2": Phase="Running", Reason="", readiness=false. Elapsed: 18.110460592s
Sep  3 16:48:21.699: INFO: Pod "pod-subpath-test-secret-9fn2": Phase="Running", Reason="", readiness=false. Elapsed: 20.119842163s
Sep  3 16:48:23.705: INFO: Pod "pod-subpath-test-secret-9fn2": Phase="Running", Reason="", readiness=false. Elapsed: 22.126071231s
Sep  3 16:48:25.718: INFO: Pod "pod-subpath-test-secret-9fn2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.139490757s
STEP: Saw pod success
Sep  3 16:48:25.718: INFO: Pod "pod-subpath-test-secret-9fn2" satisfied condition "success or failure"
Sep  3 16:48:25.725: INFO: Trying to get logs from node 10.0.10.2 pod pod-subpath-test-secret-9fn2 container test-container-subpath-secret-9fn2: <nil>
STEP: delete the pod
Sep  3 16:48:25.820: INFO: Waiting for pod pod-subpath-test-secret-9fn2 to disappear
Sep  3 16:48:25.855: INFO: Pod pod-subpath-test-secret-9fn2 no longer exists
STEP: Deleting pod pod-subpath-test-secret-9fn2
Sep  3 16:48:25.855: INFO: Deleting pod "pod-subpath-test-secret-9fn2" in namespace "e2e-tests-subpath-n4g6l"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:48:25.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-n4g6l" for this suite.
Sep  3 16:48:31.939: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:48:32.693: INFO: namespace: e2e-tests-subpath-n4g6l, resource: bindings, ignored listing per whitelist
Sep  3 16:48:32.820: INFO: namespace e2e-tests-subpath-n4g6l deletion completed in 6.952855612s

• [SLOW TEST:31.463 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:48:32.822: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-j2gxf/secret-test-aa3eb919-ce6a-11e9-a956-0a580af40009
STEP: Creating a pod to test consume secrets
Sep  3 16:48:33.016: INFO: Waiting up to 5m0s for pod "pod-configmaps-aa42d1a2-ce6a-11e9-a956-0a580af40009" in namespace "e2e-tests-secrets-j2gxf" to be "success or failure"
Sep  3 16:48:33.041: INFO: Pod "pod-configmaps-aa42d1a2-ce6a-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 24.585235ms
Sep  3 16:48:35.047: INFO: Pod "pod-configmaps-aa42d1a2-ce6a-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030992083s
Sep  3 16:48:37.061: INFO: Pod "pod-configmaps-aa42d1a2-ce6a-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044753839s
STEP: Saw pod success
Sep  3 16:48:37.061: INFO: Pod "pod-configmaps-aa42d1a2-ce6a-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 16:48:37.066: INFO: Trying to get logs from node 10.0.10.2 pod pod-configmaps-aa42d1a2-ce6a-11e9-a956-0a580af40009 container env-test: <nil>
STEP: delete the pod
Sep  3 16:48:37.206: INFO: Waiting for pod pod-configmaps-aa42d1a2-ce6a-11e9-a956-0a580af40009 to disappear
Sep  3 16:48:37.230: INFO: Pod pod-configmaps-aa42d1a2-ce6a-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:48:37.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-j2gxf" for this suite.
Sep  3 16:48:43.297: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:48:43.519: INFO: namespace: e2e-tests-secrets-j2gxf, resource: bindings, ignored listing per whitelist
Sep  3 16:48:44.168: INFO: namespace e2e-tests-secrets-j2gxf deletion completed in 6.932129927s

• [SLOW TEST:11.346 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:48:44.169: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-b1012a5e-ce6a-11e9-a956-0a580af40009
STEP: Creating a pod to test consume secrets
Sep  3 16:48:44.356: INFO: Waiting up to 5m0s for pod "pod-secrets-b10524f7-ce6a-11e9-a956-0a580af40009" in namespace "e2e-tests-secrets-7ldrn" to be "success or failure"
Sep  3 16:48:44.384: INFO: Pod "pod-secrets-b10524f7-ce6a-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 28.471981ms
Sep  3 16:48:46.390: INFO: Pod "pod-secrets-b10524f7-ce6a-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.034365116s
STEP: Saw pod success
Sep  3 16:48:46.390: INFO: Pod "pod-secrets-b10524f7-ce6a-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 16:48:46.396: INFO: Trying to get logs from node 10.0.10.2 pod pod-secrets-b10524f7-ce6a-11e9-a956-0a580af40009 container secret-volume-test: <nil>
STEP: delete the pod
Sep  3 16:48:46.467: INFO: Waiting for pod pod-secrets-b10524f7-ce6a-11e9-a956-0a580af40009 to disappear
Sep  3 16:48:46.491: INFO: Pod pod-secrets-b10524f7-ce6a-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:48:46.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-7ldrn" for this suite.
Sep  3 16:48:52.554: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:48:53.489: INFO: namespace: e2e-tests-secrets-7ldrn, resource: bindings, ignored listing per whitelist
Sep  3 16:48:53.489: INFO: namespace e2e-tests-secrets-7ldrn deletion completed in 6.991558587s

• [SLOW TEST:9.320 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:48:53.489: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  3 16:48:53.680: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Sep  3 16:48:53.732: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep  3 16:48:55.768: INFO: Creating deployment "test-rolling-update-deployment"
Sep  3 16:48:55.794: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Sep  3 16:48:55.851: INFO: deployment "test-rolling-update-deployment" doesn't have the required revision set
Sep  3 16:48:57.863: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Sep  3 16:48:57.868: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Sep  3 16:48:57.906: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-hmtqf,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-hmtqf/deployments/test-rolling-update-deployment,UID:b7da2c7f-ce6a-11e9-9b93-0a580aed0c4f,ResourceVersion:631791,Generation:1,CreationTimestamp:2019-09-03 16:48:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-09-03 16:48:55 +0000 UTC 2019-09-03 16:48:55 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-09-03 16:48:56 +0000 UTC 2019-09-03 16:48:55 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-68b55d7bc6" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Sep  3 16:48:57.912: INFO: New ReplicaSet "test-rolling-update-deployment-68b55d7bc6" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6,GenerateName:,Namespace:e2e-tests-deployment-hmtqf,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-hmtqf/replicasets/test-rolling-update-deployment-68b55d7bc6,UID:b7ddf036-ce6a-11e9-9b93-0a580aed0c4f,ResourceVersion:631782,Generation:1,CreationTimestamp:2019-09-03 16:48:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment b7da2c7f-ce6a-11e9-9b93-0a580aed0c4f 0xc0023bdc17 0xc0023bdc18}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Sep  3 16:48:57.912: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Sep  3 16:48:57.912: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-hmtqf,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-hmtqf/replicasets/test-rolling-update-controller,UID:b69bb3b8-ce6a-11e9-9b93-0a580aed0c4f,ResourceVersion:631790,Generation:2,CreationTimestamp:2019-09-03 16:48:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment b7da2c7f-ce6a-11e9-9b93-0a580aed0c4f 0xc0023bdb47 0xc0023bdb48}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep  3 16:48:57.918: INFO: Pod "test-rolling-update-deployment-68b55d7bc6-td7p4" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6-td7p4,GenerateName:test-rolling-update-deployment-68b55d7bc6-,Namespace:e2e-tests-deployment-hmtqf,SelfLink:/api/v1/namespaces/e2e-tests-deployment-hmtqf/pods/test-rolling-update-deployment-68b55d7bc6-td7p4,UID:b7deec20-ce6a-11e9-9b93-0a580aed0c4f,ResourceVersion:631781,Generation:0,CreationTimestamp:2019-09-03 16:48:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-68b55d7bc6 b7ddf036-ce6a-11e9-9b93-0a580aed0c4f 0xc002583417 0xc002583418}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4jkx9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4jkx9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-4jkx9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002583490} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025834c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 16:48:55 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 16:48:56 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 16:48:56 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 16:48:55 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.2,PodIP:10.244.0.41,StartTime:2019-09-03 16:48:55 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-09-03 16:48:56 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://f8174a2a688c37a885c3390af980c40004e628df0be168188a844d18b2608368}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:48:57.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-hmtqf" for this suite.
Sep  3 16:49:03.987: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:49:04.986: INFO: namespace: e2e-tests-deployment-hmtqf, resource: bindings, ignored listing per whitelist
Sep  3 16:49:05.107: INFO: namespace e2e-tests-deployment-hmtqf deletion completed in 7.18309495s

• [SLOW TEST:11.618 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:49:05.107: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Sep  3 16:49:05.305: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fq474,SelfLink:/api/v1/namespaces/e2e-tests-watch-fq474/configmaps/e2e-watch-test-configmap-a,UID:bd859143-ce6a-11e9-9b93-0a580aed0c4f,ResourceVersion:631837,Generation:0,CreationTimestamp:2019-09-03 16:49:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep  3 16:49:05.305: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fq474,SelfLink:/api/v1/namespaces/e2e-tests-watch-fq474/configmaps/e2e-watch-test-configmap-a,UID:bd859143-ce6a-11e9-9b93-0a580aed0c4f,ResourceVersion:631837,Generation:0,CreationTimestamp:2019-09-03 16:49:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Sep  3 16:49:15.387: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fq474,SelfLink:/api/v1/namespaces/e2e-tests-watch-fq474/configmaps/e2e-watch-test-configmap-a,UID:bd859143-ce6a-11e9-9b93-0a580aed0c4f,ResourceVersion:631858,Generation:0,CreationTimestamp:2019-09-03 16:49:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Sep  3 16:49:15.387: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fq474,SelfLink:/api/v1/namespaces/e2e-tests-watch-fq474/configmaps/e2e-watch-test-configmap-a,UID:bd859143-ce6a-11e9-9b93-0a580aed0c4f,ResourceVersion:631858,Generation:0,CreationTimestamp:2019-09-03 16:49:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Sep  3 16:49:25.408: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fq474,SelfLink:/api/v1/namespaces/e2e-tests-watch-fq474/configmaps/e2e-watch-test-configmap-a,UID:bd859143-ce6a-11e9-9b93-0a580aed0c4f,ResourceVersion:631878,Generation:0,CreationTimestamp:2019-09-03 16:49:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep  3 16:49:25.408: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fq474,SelfLink:/api/v1/namespaces/e2e-tests-watch-fq474/configmaps/e2e-watch-test-configmap-a,UID:bd859143-ce6a-11e9-9b93-0a580aed0c4f,ResourceVersion:631878,Generation:0,CreationTimestamp:2019-09-03 16:49:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Sep  3 16:49:35.456: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fq474,SelfLink:/api/v1/namespaces/e2e-tests-watch-fq474/configmaps/e2e-watch-test-configmap-a,UID:bd859143-ce6a-11e9-9b93-0a580aed0c4f,ResourceVersion:631898,Generation:0,CreationTimestamp:2019-09-03 16:49:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep  3 16:49:35.456: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fq474,SelfLink:/api/v1/namespaces/e2e-tests-watch-fq474/configmaps/e2e-watch-test-configmap-a,UID:bd859143-ce6a-11e9-9b93-0a580aed0c4f,ResourceVersion:631898,Generation:0,CreationTimestamp:2019-09-03 16:49:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Sep  3 16:49:45.473: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-fq474,SelfLink:/api/v1/namespaces/e2e-tests-watch-fq474/configmaps/e2e-watch-test-configmap-b,UID:d5763668-ce6a-11e9-9b93-0a580aed0c4f,ResourceVersion:631918,Generation:0,CreationTimestamp:2019-09-03 16:49:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep  3 16:49:45.473: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-fq474,SelfLink:/api/v1/namespaces/e2e-tests-watch-fq474/configmaps/e2e-watch-test-configmap-b,UID:d5763668-ce6a-11e9-9b93-0a580aed0c4f,ResourceVersion:631918,Generation:0,CreationTimestamp:2019-09-03 16:49:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Sep  3 16:49:55.520: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-fq474,SelfLink:/api/v1/namespaces/e2e-tests-watch-fq474/configmaps/e2e-watch-test-configmap-b,UID:d5763668-ce6a-11e9-9b93-0a580aed0c4f,ResourceVersion:631938,Generation:0,CreationTimestamp:2019-09-03 16:49:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep  3 16:49:55.520: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-fq474,SelfLink:/api/v1/namespaces/e2e-tests-watch-fq474/configmaps/e2e-watch-test-configmap-b,UID:d5763668-ce6a-11e9-9b93-0a580aed0c4f,ResourceVersion:631938,Generation:0,CreationTimestamp:2019-09-03 16:49:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:50:05.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-fq474" for this suite.
Sep  3 16:50:11.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:50:12.107: INFO: namespace: e2e-tests-watch-fq474, resource: bindings, ignored listing per whitelist
Sep  3 16:50:12.443: INFO: namespace e2e-tests-watch-fq474 deletion completed in 6.909152499s

• [SLOW TEST:67.336 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:50:12.443: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Sep  3 16:50:12.602: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e59ea026-ce6a-11e9-a956-0a580af40009" in namespace "e2e-tests-downward-api-56bp4" to be "success or failure"
Sep  3 16:50:12.626: INFO: Pod "downwardapi-volume-e59ea026-ce6a-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 24.011196ms
Sep  3 16:50:14.632: INFO: Pod "downwardapi-volume-e59ea026-ce6a-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.03011169s
STEP: Saw pod success
Sep  3 16:50:14.632: INFO: Pod "downwardapi-volume-e59ea026-ce6a-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 16:50:14.638: INFO: Trying to get logs from node 10.0.10.2 pod downwardapi-volume-e59ea026-ce6a-11e9-a956-0a580af40009 container client-container: <nil>
STEP: delete the pod
Sep  3 16:50:14.712: INFO: Waiting for pod downwardapi-volume-e59ea026-ce6a-11e9-a956-0a580af40009 to disappear
Sep  3 16:50:14.950: INFO: Pod downwardapi-volume-e59ea026-ce6a-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:50:14.950: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-56bp4" for this suite.
Sep  3 16:50:21.022: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:50:21.275: INFO: namespace: e2e-tests-downward-api-56bp4, resource: bindings, ignored listing per whitelist
Sep  3 16:50:21.867: INFO: namespace e2e-tests-downward-api-56bp4 deletion completed in 6.910929397s

• [SLOW TEST:9.424 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:50:21.867: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-xxzjx
Sep  3 16:50:24.063: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-xxzjx
STEP: checking the pod's current state and verifying that restartCount is present
Sep  3 16:50:24.068: INFO: Initial restart count of pod liveness-exec is 0
Sep  3 16:51:09.147: INFO: Restart count of pod e2e-tests-container-probe-xxzjx/liveness-exec is now 1 (45.078365091s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:51:09.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-xxzjx" for this suite.
Sep  3 16:51:15.278: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:51:16.153: INFO: namespace: e2e-tests-container-probe-xxzjx, resource: bindings, ignored listing per whitelist
Sep  3 16:51:16.182: INFO: namespace e2e-tests-container-probe-xxzjx deletion completed in 6.981584858s

• [SLOW TEST:54.314 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:51:16.182: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-0b9c9e9c-ce6b-11e9-a956-0a580af40009
STEP: Creating a pod to test consume configMaps
Sep  3 16:51:16.378: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0ba12fd2-ce6b-11e9-a956-0a580af40009" in namespace "e2e-tests-projected-dr2wt" to be "success or failure"
Sep  3 16:51:16.403: INFO: Pod "pod-projected-configmaps-0ba12fd2-ce6b-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 24.99734ms
Sep  3 16:51:18.410: INFO: Pod "pod-projected-configmaps-0ba12fd2-ce6b-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.031298682s
STEP: Saw pod success
Sep  3 16:51:18.410: INFO: Pod "pod-projected-configmaps-0ba12fd2-ce6b-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 16:51:18.415: INFO: Trying to get logs from node 10.0.10.2 pod pod-projected-configmaps-0ba12fd2-ce6b-11e9-a956-0a580af40009 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  3 16:51:18.498: INFO: Waiting for pod pod-projected-configmaps-0ba12fd2-ce6b-11e9-a956-0a580af40009 to disappear
Sep  3 16:51:18.523: INFO: Pod pod-projected-configmaps-0ba12fd2-ce6b-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:51:18.523: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dr2wt" for this suite.
Sep  3 16:51:24.596: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:51:24.753: INFO: namespace: e2e-tests-projected-dr2wt, resource: bindings, ignored listing per whitelist
Sep  3 16:51:25.513: INFO: namespace e2e-tests-projected-dr2wt deletion completed in 6.98417285s

• [SLOW TEST:9.331 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:51:25.513: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0903 16:51:35.981573      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep  3 16:51:35.981: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:51:35.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-njdw8" for this suite.
Sep  3 16:51:42.062: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:51:42.582: INFO: namespace: e2e-tests-gc-njdw8, resource: bindings, ignored listing per whitelist
Sep  3 16:51:42.965: INFO: namespace e2e-tests-gc-njdw8 deletion completed in 6.978228527s

• [SLOW TEST:17.452 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:51:42.965: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  3 16:51:43.094: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-sdc6z'
Sep  3 16:51:43.223: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep  3 16:51:43.223: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1268
Sep  3 16:51:43.249: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-sdc6z'
Sep  3 16:51:43.392: INFO: stderr: ""
Sep  3 16:51:43.392: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:51:43.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-sdc6z" for this suite.
Sep  3 16:52:05.469: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:52:05.546: INFO: namespace: e2e-tests-kubectl-sdc6z, resource: bindings, ignored listing per whitelist
Sep  3 16:52:06.348: INFO: namespace e2e-tests-kubectl-sdc6z deletion completed in 22.949435767s

• [SLOW TEST:23.383 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:52:06.348: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Sep  3 16:52:06.510: INFO: Waiting up to 5m0s for pod "pod-29830faf-ce6b-11e9-a956-0a580af40009" in namespace "e2e-tests-emptydir-xhxk7" to be "success or failure"
Sep  3 16:52:06.536: INFO: Pod "pod-29830faf-ce6b-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 26.1549ms
Sep  3 16:52:08.542: INFO: Pod "pod-29830faf-ce6b-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.032019302s
STEP: Saw pod success
Sep  3 16:52:08.542: INFO: Pod "pod-29830faf-ce6b-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 16:52:08.547: INFO: Trying to get logs from node 10.0.10.2 pod pod-29830faf-ce6b-11e9-a956-0a580af40009 container test-container: <nil>
STEP: delete the pod
Sep  3 16:52:08.687: INFO: Waiting for pod pod-29830faf-ce6b-11e9-a956-0a580af40009 to disappear
Sep  3 16:52:08.714: INFO: Pod pod-29830faf-ce6b-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:52:08.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-xhxk7" for this suite.
Sep  3 16:52:14.782: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:52:15.509: INFO: namespace: e2e-tests-emptydir-xhxk7, resource: bindings, ignored listing per whitelist
Sep  3 16:52:15.674: INFO: namespace e2e-tests-emptydir-xhxk7 deletion completed in 6.954298696s

• [SLOW TEST:9.326 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:52:15.675: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-2f12392e-ce6b-11e9-a956-0a580af40009
STEP: Creating a pod to test consume configMaps
Sep  3 16:52:15.863: INFO: Waiting up to 5m0s for pod "pod-configmaps-2f162612-ce6b-11e9-a956-0a580af40009" in namespace "e2e-tests-configmap-mq4km" to be "success or failure"
Sep  3 16:52:15.888: INFO: Pod "pod-configmaps-2f162612-ce6b-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 24.4759ms
Sep  3 16:52:17.894: INFO: Pod "pod-configmaps-2f162612-ce6b-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030391842s
STEP: Saw pod success
Sep  3 16:52:17.894: INFO: Pod "pod-configmaps-2f162612-ce6b-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 16:52:17.899: INFO: Trying to get logs from node 10.0.10.2 pod pod-configmaps-2f162612-ce6b-11e9-a956-0a580af40009 container configmap-volume-test: <nil>
STEP: delete the pod
Sep  3 16:52:17.975: INFO: Waiting for pod pod-configmaps-2f162612-ce6b-11e9-a956-0a580af40009 to disappear
Sep  3 16:52:17.999: INFO: Pod pod-configmaps-2f162612-ce6b-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:52:18.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-mq4km" for this suite.
Sep  3 16:52:24.065: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:52:24.853: INFO: namespace: e2e-tests-configmap-mq4km, resource: bindings, ignored listing per whitelist
Sep  3 16:52:24.937: INFO: namespace e2e-tests-configmap-mq4km deletion completed in 6.93130101s

• [SLOW TEST:9.262 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:52:24.937: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-3497906f-ce6b-11e9-a956-0a580af40009
STEP: Creating a pod to test consume secrets
Sep  3 16:52:25.127: INFO: Waiting up to 5m0s for pod "pod-secrets-349bc505-ce6b-11e9-a956-0a580af40009" in namespace "e2e-tests-secrets-rxvq9" to be "success or failure"
Sep  3 16:52:25.153: INFO: Pod "pod-secrets-349bc505-ce6b-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 26.490091ms
Sep  3 16:52:27.168: INFO: Pod "pod-secrets-349bc505-ce6b-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.041709099s
STEP: Saw pod success
Sep  3 16:52:27.169: INFO: Pod "pod-secrets-349bc505-ce6b-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 16:52:27.174: INFO: Trying to get logs from node 10.0.10.2 pod pod-secrets-349bc505-ce6b-11e9-a956-0a580af40009 container secret-volume-test: <nil>
STEP: delete the pod
Sep  3 16:52:27.249: INFO: Waiting for pod pod-secrets-349bc505-ce6b-11e9-a956-0a580af40009 to disappear
Sep  3 16:52:27.276: INFO: Pod pod-secrets-349bc505-ce6b-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:52:27.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-rxvq9" for this suite.
Sep  3 16:52:33.356: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:52:33.688: INFO: namespace: e2e-tests-secrets-rxvq9, resource: bindings, ignored listing per whitelist
Sep  3 16:52:34.263: INFO: namespace e2e-tests-secrets-rxvq9 deletion completed in 6.9820661s

• [SLOW TEST:9.326 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:52:34.263: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-3a25f8e3-ce6b-11e9-a956-0a580af40009
STEP: Creating a pod to test consume secrets
Sep  3 16:52:34.447: INFO: Waiting up to 5m0s for pod "pod-secrets-3a29ddae-ce6b-11e9-a956-0a580af40009" in namespace "e2e-tests-secrets-hpj5f" to be "success or failure"
Sep  3 16:52:34.473: INFO: Pod "pod-secrets-3a29ddae-ce6b-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 26.719419ms
Sep  3 16:52:36.480: INFO: Pod "pod-secrets-3a29ddae-ce6b-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.033010177s
STEP: Saw pod success
Sep  3 16:52:36.480: INFO: Pod "pod-secrets-3a29ddae-ce6b-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 16:52:36.485: INFO: Trying to get logs from node 10.0.10.2 pod pod-secrets-3a29ddae-ce6b-11e9-a956-0a580af40009 container secret-volume-test: <nil>
STEP: delete the pod
Sep  3 16:52:36.567: INFO: Waiting for pod pod-secrets-3a29ddae-ce6b-11e9-a956-0a580af40009 to disappear
Sep  3 16:52:36.592: INFO: Pod pod-secrets-3a29ddae-ce6b-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:52:36.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-hpj5f" for this suite.
Sep  3 16:52:42.665: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:52:43.691: INFO: namespace: e2e-tests-secrets-hpj5f, resource: bindings, ignored listing per whitelist
Sep  3 16:52:43.733: INFO: namespace e2e-tests-secrets-hpj5f deletion completed in 7.134951316s

• [SLOW TEST:9.469 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:52:43.733: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-h5dl
STEP: Creating a pod to test atomic-volume-subpath
Sep  3 16:52:43.946: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-h5dl" in namespace "e2e-tests-subpath-cl4pb" to be "success or failure"
Sep  3 16:52:43.972: INFO: Pod "pod-subpath-test-downwardapi-h5dl": Phase="Pending", Reason="", readiness=false. Elapsed: 25.176272ms
Sep  3 16:52:45.978: INFO: Pod "pod-subpath-test-downwardapi-h5dl": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031486925s
Sep  3 16:52:47.984: INFO: Pod "pod-subpath-test-downwardapi-h5dl": Phase="Running", Reason="", readiness=false. Elapsed: 4.037655868s
Sep  3 16:52:49.997: INFO: Pod "pod-subpath-test-downwardapi-h5dl": Phase="Running", Reason="", readiness=false. Elapsed: 6.050475288s
Sep  3 16:52:52.003: INFO: Pod "pod-subpath-test-downwardapi-h5dl": Phase="Running", Reason="", readiness=false. Elapsed: 8.057039945s
Sep  3 16:52:54.010: INFO: Pod "pod-subpath-test-downwardapi-h5dl": Phase="Running", Reason="", readiness=false. Elapsed: 10.063952298s
Sep  3 16:52:56.021: INFO: Pod "pod-subpath-test-downwardapi-h5dl": Phase="Running", Reason="", readiness=false. Elapsed: 12.074749505s
Sep  3 16:52:58.027: INFO: Pod "pod-subpath-test-downwardapi-h5dl": Phase="Running", Reason="", readiness=false. Elapsed: 14.080749092s
Sep  3 16:53:00.041: INFO: Pod "pod-subpath-test-downwardapi-h5dl": Phase="Running", Reason="", readiness=false. Elapsed: 16.094173231s
Sep  3 16:53:02.047: INFO: Pod "pod-subpath-test-downwardapi-h5dl": Phase="Running", Reason="", readiness=false. Elapsed: 18.100293095s
Sep  3 16:53:04.053: INFO: Pod "pod-subpath-test-downwardapi-h5dl": Phase="Running", Reason="", readiness=false. Elapsed: 20.106959509s
Sep  3 16:53:06.060: INFO: Pod "pod-subpath-test-downwardapi-h5dl": Phase="Running", Reason="", readiness=false. Elapsed: 22.113165651s
Sep  3 16:53:08.066: INFO: Pod "pod-subpath-test-downwardapi-h5dl": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.119321259s
STEP: Saw pod success
Sep  3 16:53:08.066: INFO: Pod "pod-subpath-test-downwardapi-h5dl" satisfied condition "success or failure"
Sep  3 16:53:08.071: INFO: Trying to get logs from node 10.0.10.2 pod pod-subpath-test-downwardapi-h5dl container test-container-subpath-downwardapi-h5dl: <nil>
STEP: delete the pod
Sep  3 16:53:08.161: INFO: Waiting for pod pod-subpath-test-downwardapi-h5dl to disappear
Sep  3 16:53:08.190: INFO: Pod pod-subpath-test-downwardapi-h5dl no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-h5dl
Sep  3 16:53:08.190: INFO: Deleting pod "pod-subpath-test-downwardapi-h5dl" in namespace "e2e-tests-subpath-cl4pb"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:53:08.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-cl4pb" for this suite.
Sep  3 16:53:14.269: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:53:14.569: INFO: namespace: e2e-tests-subpath-cl4pb, resource: bindings, ignored listing per whitelist
Sep  3 16:53:15.192: INFO: namespace e2e-tests-subpath-cl4pb deletion completed in 6.991855725s

• [SLOW TEST:31.459 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:53:15.193: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Sep  3 16:53:15.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 api-versions'
Sep  3 16:53:15.439: INFO: stderr: ""
Sep  3 16:53:15.439: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:53:15.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5tjfr" for this suite.
Sep  3 16:53:21.560: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:53:21.604: INFO: namespace: e2e-tests-kubectl-5tjfr, resource: bindings, ignored listing per whitelist
Sep  3 16:53:22.462: INFO: namespace e2e-tests-kubectl-5tjfr deletion completed in 7.016541922s

• [SLOW TEST:7.270 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:53:22.463: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Sep  3 16:53:22.620: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:53:26.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-drgnd" for this suite.
Sep  3 16:53:48.120: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:53:48.431: INFO: namespace: e2e-tests-init-container-drgnd, resource: bindings, ignored listing per whitelist
Sep  3 16:53:49.126: INFO: namespace e2e-tests-init-container-drgnd deletion completed in 23.070465258s

• [SLOW TEST:26.663 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:53:49.126: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  3 16:53:49.364: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Sep  3 16:53:49.427: INFO: Number of nodes with available pods: 0
Sep  3 16:53:49.430: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 16:53:50.442: INFO: Number of nodes with available pods: 1
Sep  3 16:53:50.442: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Sep  3 16:53:50.559: INFO: Wrong image for pod: daemon-set-xs4rm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  3 16:53:51.571: INFO: Wrong image for pod: daemon-set-xs4rm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  3 16:53:52.572: INFO: Wrong image for pod: daemon-set-xs4rm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  3 16:53:53.571: INFO: Wrong image for pod: daemon-set-xs4rm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  3 16:53:54.578: INFO: Wrong image for pod: daemon-set-xs4rm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  3 16:53:55.571: INFO: Wrong image for pod: daemon-set-xs4rm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  3 16:53:56.571: INFO: Wrong image for pod: daemon-set-xs4rm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  3 16:53:57.572: INFO: Wrong image for pod: daemon-set-xs4rm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  3 16:53:58.572: INFO: Wrong image for pod: daemon-set-xs4rm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  3 16:53:59.572: INFO: Wrong image for pod: daemon-set-xs4rm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  3 16:54:00.572: INFO: Wrong image for pod: daemon-set-xs4rm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  3 16:54:01.571: INFO: Wrong image for pod: daemon-set-xs4rm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  3 16:54:02.571: INFO: Wrong image for pod: daemon-set-xs4rm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  3 16:54:03.571: INFO: Wrong image for pod: daemon-set-xs4rm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  3 16:54:04.572: INFO: Wrong image for pod: daemon-set-xs4rm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  3 16:54:05.580: INFO: Wrong image for pod: daemon-set-xs4rm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  3 16:54:06.572: INFO: Wrong image for pod: daemon-set-xs4rm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  3 16:54:07.572: INFO: Wrong image for pod: daemon-set-xs4rm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  3 16:54:08.572: INFO: Wrong image for pod: daemon-set-xs4rm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  3 16:54:09.572: INFO: Wrong image for pod: daemon-set-xs4rm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  3 16:54:10.572: INFO: Wrong image for pod: daemon-set-xs4rm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  3 16:54:11.572: INFO: Wrong image for pod: daemon-set-xs4rm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  3 16:54:12.573: INFO: Wrong image for pod: daemon-set-xs4rm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  3 16:54:13.572: INFO: Wrong image for pod: daemon-set-xs4rm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  3 16:54:14.572: INFO: Wrong image for pod: daemon-set-xs4rm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  3 16:54:15.572: INFO: Wrong image for pod: daemon-set-xs4rm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  3 16:54:16.579: INFO: Wrong image for pod: daemon-set-xs4rm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  3 16:54:17.572: INFO: Wrong image for pod: daemon-set-xs4rm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  3 16:54:18.572: INFO: Wrong image for pod: daemon-set-xs4rm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  3 16:54:19.572: INFO: Wrong image for pod: daemon-set-xs4rm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  3 16:54:20.572: INFO: Wrong image for pod: daemon-set-xs4rm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  3 16:54:21.572: INFO: Wrong image for pod: daemon-set-xs4rm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  3 16:54:22.572: INFO: Wrong image for pod: daemon-set-xs4rm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  3 16:54:23.572: INFO: Wrong image for pod: daemon-set-xs4rm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  3 16:54:23.572: INFO: Pod daemon-set-xs4rm is not available
Sep  3 16:54:24.572: INFO: Pod daemon-set-n244p is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Sep  3 16:54:24.604: INFO: Number of nodes with available pods: 0
Sep  3 16:54:24.604: INFO: Node 10.0.10.2 is running more than one daemon pod
Sep  3 16:54:25.616: INFO: Number of nodes with available pods: 1
Sep  3 16:54:25.616: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-twj2z, will wait for the garbage collector to delete the pods
Sep  3 16:54:25.789: INFO: Deleting DaemonSet.extensions daemon-set took: 31.396477ms
Sep  3 16:54:25.889: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.224485ms
Sep  3 16:54:39.404: INFO: Number of nodes with available pods: 0
Sep  3 16:54:39.404: INFO: Number of running nodes: 0, number of available pods: 0
Sep  3 16:54:39.410: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-twj2z/daemonsets","resourceVersion":"633028"},"items":null}

Sep  3 16:54:39.415: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-twj2z/pods","resourceVersion":"633028"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:54:39.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-twj2z" for this suite.
Sep  3 16:54:45.474: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:54:46.067: INFO: namespace: e2e-tests-daemonsets-twj2z, resource: bindings, ignored listing per whitelist
Sep  3 16:54:46.366: INFO: namespace e2e-tests-daemonsets-twj2z deletion completed in 6.934957543s

• [SLOW TEST:57.240 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:54:46.367: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  3 16:54:46.519: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-r7qg2'
Sep  3 16:54:46.847: INFO: stderr: ""
Sep  3 16:54:46.847: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Sep  3 16:54:51.898: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-r7qg2 -o json'
Sep  3 16:54:52.022: INFO: stderr: ""
Sep  3 16:54:52.022: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-09-03T16:54:46Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-r7qg2\",\n        \"resourceVersion\": \"633074\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-r7qg2/pods/e2e-test-nginx-pod\",\n        \"uid\": \"8913f139-ce6b-11e9-b12b-0a580aed0e79\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-tlxnv\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"10.0.10.2\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-tlxnv\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-tlxnv\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-03T16:54:46Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-03T16:54:48Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-03T16:54:48Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-03T16:54:46Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://256711421a896a53ffb26d369f5a197467df6214231c31fbee15854e19b22dae\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-09-03T16:54:47Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.0.10.2\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.244.0.65\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-09-03T16:54:46Z\"\n    }\n}\n"
STEP: replace the image in the pod
Sep  3 16:54:52.022: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 replace -f - --namespace=e2e-tests-kubectl-r7qg2'
Sep  3 16:54:52.295: INFO: stderr: ""
Sep  3 16:54:52.295: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
Sep  3 16:54:52.333: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-r7qg2'
Sep  3 16:54:59.373: INFO: stderr: ""
Sep  3 16:54:59.373: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:54:59.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-r7qg2" for this suite.
Sep  3 16:55:07.447: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:55:08.139: INFO: namespace: e2e-tests-kubectl-r7qg2, resource: bindings, ignored listing per whitelist
Sep  3 16:55:08.406: INFO: namespace e2e-tests-kubectl-r7qg2 deletion completed in 9.027372231s

• [SLOW TEST:22.040 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:55:08.406: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  3 16:55:08.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-h4x9x'
Sep  3 16:55:08.653: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep  3 16:55:08.653: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Sep  3 16:55:08.703: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-r4wzh]
Sep  3 16:55:08.703: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-r4wzh" in namespace "e2e-tests-kubectl-h4x9x" to be "running and ready"
Sep  3 16:55:08.729: INFO: Pod "e2e-test-nginx-rc-r4wzh": Phase="Pending", Reason="", readiness=false. Elapsed: 26.491213ms
Sep  3 16:55:10.736: INFO: Pod "e2e-test-nginx-rc-r4wzh": Phase="Running", Reason="", readiness=true. Elapsed: 2.033184156s
Sep  3 16:55:10.736: INFO: Pod "e2e-test-nginx-rc-r4wzh" satisfied condition "running and ready"
Sep  3 16:55:10.736: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-r4wzh]
Sep  3 16:55:10.736: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-h4x9x'
Sep  3 16:55:10.927: INFO: stderr: ""
Sep  3 16:55:10.927: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1303
Sep  3 16:55:10.927: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-h4x9x'
Sep  3 16:55:11.049: INFO: stderr: ""
Sep  3 16:55:11.049: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:55:11.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-h4x9x" for this suite.
Sep  3 16:55:33.121: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:55:33.314: INFO: namespace: e2e-tests-kubectl-h4x9x, resource: bindings, ignored listing per whitelist
Sep  3 16:55:34.026: INFO: namespace e2e-tests-kubectl-h4x9x deletion completed in 22.97130535s

• [SLOW TEST:25.620 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:55:34.026: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Sep  3 16:55:36.810: INFO: Successfully updated pod "pod-update-a54cc27d-ce6b-11e9-a956-0a580af40009"
STEP: verifying the updated pod is in kubernetes
Sep  3 16:55:36.821: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:55:36.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-6z569" for this suite.
Sep  3 16:55:58.889: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:55:59.349: INFO: namespace: e2e-tests-pods-6z569, resource: bindings, ignored listing per whitelist
Sep  3 16:55:59.711: INFO: namespace e2e-tests-pods-6z569 deletion completed in 22.884318047s

• [SLOW TEST:25.685 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:55:59.712: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Sep  3 16:55:59.871: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b49b72df-ce6b-11e9-a956-0a580af40009" in namespace "e2e-tests-downward-api-n99fl" to be "success or failure"
Sep  3 16:55:59.896: INFO: Pod "downwardapi-volume-b49b72df-ce6b-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 24.834763ms
Sep  3 16:56:01.908: INFO: Pod "downwardapi-volume-b49b72df-ce6b-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037408872s
Sep  3 16:56:03.914: INFO: Pod "downwardapi-volume-b49b72df-ce6b-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.043159999s
STEP: Saw pod success
Sep  3 16:56:03.914: INFO: Pod "downwardapi-volume-b49b72df-ce6b-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 16:56:03.920: INFO: Trying to get logs from node 10.0.10.2 pod downwardapi-volume-b49b72df-ce6b-11e9-a956-0a580af40009 container client-container: <nil>
STEP: delete the pod
Sep  3 16:56:03.984: INFO: Waiting for pod downwardapi-volume-b49b72df-ce6b-11e9-a956-0a580af40009 to disappear
Sep  3 16:56:04.015: INFO: Pod downwardapi-volume-b49b72df-ce6b-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:56:04.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-n99fl" for this suite.
Sep  3 16:56:10.082: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:56:10.314: INFO: namespace: e2e-tests-downward-api-n99fl, resource: bindings, ignored listing per whitelist
Sep  3 16:56:11.139: INFO: namespace e2e-tests-downward-api-n99fl deletion completed in 7.118315028s

• [SLOW TEST:11.427 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:56:11.139: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-bb6bd9c6-ce6b-11e9-a956-0a580af40009
STEP: Creating a pod to test consume secrets
Sep  3 16:56:11.329: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-bb6fce14-ce6b-11e9-a956-0a580af40009" in namespace "e2e-tests-projected-hvfg6" to be "success or failure"
Sep  3 16:56:11.355: INFO: Pod "pod-projected-secrets-bb6fce14-ce6b-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 26.096176ms
Sep  3 16:56:13.370: INFO: Pod "pod-projected-secrets-bb6fce14-ce6b-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.041007292s
STEP: Saw pod success
Sep  3 16:56:13.370: INFO: Pod "pod-projected-secrets-bb6fce14-ce6b-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 16:56:13.376: INFO: Trying to get logs from node 10.0.10.2 pod pod-projected-secrets-bb6fce14-ce6b-11e9-a956-0a580af40009 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep  3 16:56:13.446: INFO: Waiting for pod pod-projected-secrets-bb6fce14-ce6b-11e9-a956-0a580af40009 to disappear
Sep  3 16:56:13.471: INFO: Pod pod-projected-secrets-bb6fce14-ce6b-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:56:13.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hvfg6" for this suite.
Sep  3 16:56:19.543: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:56:19.797: INFO: namespace: e2e-tests-projected-hvfg6, resource: bindings, ignored listing per whitelist
Sep  3 16:56:20.383: INFO: namespace e2e-tests-projected-hvfg6 deletion completed in 6.904951715s

• [SLOW TEST:9.244 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:56:20.384: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  3 16:56:20.517: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 version --client'
Sep  3 16:56:20.575: INFO: stderr: ""
Sep  3 16:56:20.575: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Sep  3 16:56:20.581: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 create -f - --namespace=e2e-tests-kubectl-c4c8t'
Sep  3 16:56:20.793: INFO: stderr: ""
Sep  3 16:56:20.793: INFO: stdout: "replicationcontroller/redis-master created\n"
Sep  3 16:56:20.794: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 create -f - --namespace=e2e-tests-kubectl-c4c8t'
Sep  3 16:56:21.095: INFO: stderr: ""
Sep  3 16:56:21.095: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Sep  3 16:56:22.121: INFO: Selector matched 1 pods for map[app:redis]
Sep  3 16:56:22.121: INFO: Found 0 / 1
Sep  3 16:56:23.102: INFO: Selector matched 1 pods for map[app:redis]
Sep  3 16:56:23.102: INFO: Found 1 / 1
Sep  3 16:56:23.102: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Sep  3 16:56:23.108: INFO: Selector matched 1 pods for map[app:redis]
Sep  3 16:56:23.108: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep  3 16:56:23.108: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 describe pod redis-master-24xhz --namespace=e2e-tests-kubectl-c4c8t'
Sep  3 16:56:23.255: INFO: stderr: ""
Sep  3 16:56:23.255: INFO: stdout: "Name:               redis-master-24xhz\nNamespace:          e2e-tests-kubectl-c4c8t\nPriority:           0\nPriorityClassName:  <none>\nNode:               10.0.10.2/10.0.10.2\nStart Time:         Tue, 03 Sep 2019 16:56:20 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.244.0.70\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://c9a12e650f1e572212fab140585dbdf40c257234311c4faf43cecbb2ca7b89fb\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 03 Sep 2019 16:56:21 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-475cg (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-475cg:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-475cg\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                Message\n  ----    ------     ----  ----                -------\n  Normal  Scheduled  3s    default-scheduler   Successfully assigned e2e-tests-kubectl-c4c8t/redis-master-24xhz to 10.0.10.2\n  Normal  Pulled     2s    kubelet, 10.0.10.2  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, 10.0.10.2  Created container\n  Normal  Started    2s    kubelet, 10.0.10.2  Started container\n"
Sep  3 16:56:23.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 describe rc redis-master --namespace=e2e-tests-kubectl-c4c8t'
Sep  3 16:56:23.428: INFO: stderr: ""
Sep  3 16:56:23.428: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-c4c8t\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-24xhz\n"
Sep  3 16:56:23.428: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 describe service redis-master --namespace=e2e-tests-kubectl-c4c8t'
Sep  3 16:56:23.594: INFO: stderr: ""
Sep  3 16:56:23.594: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-c4c8t\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.96.168.125\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.244.0.70:6379\nSession Affinity:  None\nEvents:            <none>\n"
Sep  3 16:56:23.608: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 describe node 10.0.10.2'
Sep  3 16:56:23.805: INFO: stderr: ""
Sep  3 16:56:23.805: INFO: stdout: "Name:               10.0.10.2\nRoles:              node\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=VM.Standard2.1\n                    beta.kubernetes.io/os=linux\n                    displayName=oke-cstanzzmnrt-n3dqmtgmnsg-smq5thfwgmq-0\n                    failure-domain.beta.kubernetes.io/region=uk-london-1\n                    failure-domain.beta.kubernetes.io/zone=UK-LONDON-1-AD-1\n                    hostname=oke-cstanzzmnrt-n3dqmtgmnsg-smq5thfwgmq-0\n                    internal_addr=10.0.10.2\n                    kubernetes.io/hostname=10.0.10.2\n                    name=\n                    node-role.kubernetes.io/node=\n                    node.info/compartment.id_prefix=ocid1.compartment.oc1\n                    node.info/compartment.id_suffix=aaaaaaaaxlbamuo3pb2hhkit5grw3ccjufxon3lsvpzv2rthr32rl4gj6jgq\n                    node.info/compartment.name=al\n                    node.info/kubeletVersion=v1.13\n                    node.info/node.id_prefix=ocid1.instance.oc1.uk-london-1\n                    node.info/node.id_suffix=abwgiljsgg4fb7ngimgms2ngmarpraqq5f77fiz7shktkz5eusieh4sqclqa\n                    oke.oraclecloud.com/node.info.private_subnet=true\n                    oke.oraclecloud.com/node.info.private_worker=true\n                    oke.oraclecloud.com/tenant_agent.version=1.8.1-d5c8cec-678\nAnnotations:        alpha.kubernetes.io/provided-node-ip: 10.0.10.2\n                    flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"a6:b3:4f:1f:39:8b\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 10.0.10.2\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Fri, 30 Aug 2019 21:27:39 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Tue, 03 Sep 2019 16:56:18 +0000   Fri, 30 Aug 2019 21:27:39 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Tue, 03 Sep 2019 16:56:18 +0000   Fri, 30 Aug 2019 21:27:39 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Tue, 03 Sep 2019 16:56:18 +0000   Fri, 30 Aug 2019 21:27:39 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Tue, 03 Sep 2019 16:56:18 +0000   Fri, 30 Aug 2019 21:27:59 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  10.0.10.2\nCapacity:\n cpu:                2\n ephemeral-storage:  40223552Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             15116084Ki\n pods:               110\nAllocatable:\n cpu:                2\n ephemeral-storage:  37070025462\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             15013684Ki\n pods:               110\nSystem Info:\n Machine ID:                 f55882225d9147c598d6cfcca167e226\n System UUID:                0D99CA76-FC08-4CAC-9D2A-D5D8D4F65F54\n Boot ID:                    1d3cfb43-e850-4b28-9301-331adc8f7e90\n Kernel Version:             4.14.35-1902.2.0.el7uek.x86_64\n OS Image:                   Oracle Linux Server 7.6\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.9.1\n Kubelet Version:            v1.13.5\n Kube-Proxy Version:         v1.13.5\nPodCIDR:                     10.244.0.0/24\nProviderID:                  ocid1.instance.oc1.uk-london-1.abwgiljsgg4fb7ngimgms2ngmarpraqq5f77fiz7shktkz5eusieh4sqclqa\nNon-terminated Pods:         (11 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  e2e-tests-kubectl-c4c8t    redis-master-24xhz                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         3s\n  heptio-sonobuoy            sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         96m\n  heptio-sonobuoy            sonobuoy-e2e-job-a1e56c6fdf4c4de0                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         95m\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-6c7ccfc0384b4617-nlhk5    0 (0%)        0 (0%)      0 (0%)           0 (0%)         95m\n  kube-system                kube-dns-6b7d4d8994-8bv4d                                  260m (13%)    0 (0%)      110Mi (0%)       170Mi (1%)     3d19h\n  kube-system                kube-dns-autoscaler-84cf5956b-9dvmg                        20m (1%)      0 (0%)      10Mi (0%)        0 (0%)         3d19h\n  kube-system                kube-flannel-ds-vsts9                                      100m (5%)     1 (50%)     50Mi (0%)        500Mi (3%)     3d19h\n  kube-system                kube-proxy-p5865                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         3d19h\n  kube-system                kubernetes-dashboard-697c7958df-6qjlq                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         3d19h\n  kube-system                proxymux-client-10.0.10.2                                  50m (2%)      500m (25%)  64Mi (0%)        256Mi (1%)     3d19h\n  kube-system                tiller-deploy-b6d55488-ddll4                               0 (0%)        0 (0%)      0 (0%)           0 (0%)         3d19h\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                430m (21%)  1500m (75%)\n  memory             234Mi (1%)  926Mi (6%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:              <none>\n"
Sep  3 16:56:23.806: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043111098 describe namespace e2e-tests-kubectl-c4c8t'
Sep  3 16:56:23.971: INFO: stderr: ""
Sep  3 16:56:23.971: INFO: stdout: "Name:         e2e-tests-kubectl-c4c8t\nLabels:       e2e-framework=kubectl\n              e2e-run=715463bb-ce5e-11e9-a956-0a580af40009\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:56:23.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-c4c8t" for this suite.
Sep  3 16:56:46.046: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:56:46.860: INFO: namespace: e2e-tests-kubectl-c4c8t, resource: bindings, ignored listing per whitelist
Sep  3 16:56:46.964: INFO: namespace e2e-tests-kubectl-c4c8t deletion completed in 22.987038242s

• [SLOW TEST:26.580 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:56:46.964: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  3 16:56:47.163: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep  3 16:56:49.195: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Sep  3 16:56:51.349: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-ctbpx,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-ctbpx/deployments/test-cleanup-deployment,UID:d20e87a1-ce6b-11e9-9b93-0a580aed0c4f,ResourceVersion:633522,Generation:1,CreationTimestamp:2019-09-03 16:56:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 1,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-09-03 16:56:49 +0000 UTC 2019-09-03 16:56:49 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-09-03 16:56:51 +0000 UTC 2019-09-03 16:56:49 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-cleanup-deployment-7dbbfcf846" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Sep  3 16:56:51.355: INFO: New ReplicaSet "test-cleanup-deployment-7dbbfcf846" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-7dbbfcf846,GenerateName:,Namespace:e2e-tests-deployment-ctbpx,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-ctbpx/replicasets/test-cleanup-deployment-7dbbfcf846,UID:d2123db9-ce6b-11e9-9b93-0a580aed0c4f,ResourceVersion:633513,Generation:1,CreationTimestamp:2019-09-03 16:56:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment d20e87a1-ce6b-11e9-9b93-0a580aed0c4f 0xc001bf7ac7 0xc001bf7ac8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Sep  3 16:56:51.362: INFO: Pod "test-cleanup-deployment-7dbbfcf846-8hwpr" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-7dbbfcf846-8hwpr,GenerateName:test-cleanup-deployment-7dbbfcf846-,Namespace:e2e-tests-deployment-ctbpx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ctbpx/pods/test-cleanup-deployment-7dbbfcf846-8hwpr,UID:d2133c29-ce6b-11e9-9b93-0a580aed0c4f,ResourceVersion:633512,Generation:0,CreationTimestamp:2019-09-03 16:56:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-7dbbfcf846 d2123db9-ce6b-11e9-9b93-0a580aed0c4f 0xc0027fc0f7 0xc0027fc0f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-kctfs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kctfs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-kctfs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0027fc170} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0027fc190}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 16:56:49 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 16:56:51 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 16:56:51 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 16:56:49 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.2,PodIP:10.244.0.72,StartTime:2019-09-03 16:56:49 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-09-03 16:56:50 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://c7da4a00f0d9c64be4cd67fef8e2d007c1d9cb2ffa8759398a0bdf0cfaed2ac4}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:56:51.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-ctbpx" for this suite.
Sep  3 16:56:57.467: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:56:58.300: INFO: namespace: e2e-tests-deployment-ctbpx, resource: bindings, ignored listing per whitelist
Sep  3 16:56:58.300: INFO: namespace e2e-tests-deployment-ctbpx deletion completed in 6.90569583s

• [SLOW TEST:11.335 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:56:58.300: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-d788c509-ce6b-11e9-a956-0a580af40009
Sep  3 16:56:58.492: INFO: Pod name my-hostname-basic-d788c509-ce6b-11e9-a956-0a580af40009: Found 1 pods out of 1
Sep  3 16:56:58.492: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-d788c509-ce6b-11e9-a956-0a580af40009" are running
Sep  3 16:57:00.523: INFO: Pod "my-hostname-basic-d788c509-ce6b-11e9-a956-0a580af40009-fkkvm" is running (conditions: [{Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-03 16:56:58 +0000 UTC Reason: Message:}])
Sep  3 16:57:00.523: INFO: Trying to dial the pod
Sep  3 16:57:05.653: INFO: Controller my-hostname-basic-d788c509-ce6b-11e9-a956-0a580af40009: Got expected result from replica 1 [my-hostname-basic-d788c509-ce6b-11e9-a956-0a580af40009-fkkvm]: "my-hostname-basic-d788c509-ce6b-11e9-a956-0a580af40009-fkkvm", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:57:05.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-h9mrd" for this suite.
Sep  3 16:57:11.724: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:57:12.078: INFO: namespace: e2e-tests-replication-controller-h9mrd, resource: bindings, ignored listing per whitelist
Sep  3 16:57:12.615: INFO: namespace e2e-tests-replication-controller-h9mrd deletion completed in 6.955209648s

• [SLOW TEST:14.315 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:57:12.615: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Sep  3 16:57:15.386: INFO: Successfully updated pod "pod-update-activedeadlineseconds-e01176ab-ce6b-11e9-a956-0a580af40009"
Sep  3 16:57:15.386: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-e01176ab-ce6b-11e9-a956-0a580af40009" in namespace "e2e-tests-pods-xmfmk" to be "terminated due to deadline exceeded"
Sep  3 16:57:15.392: INFO: Pod "pod-update-activedeadlineseconds-e01176ab-ce6b-11e9-a956-0a580af40009": Phase="Running", Reason="", readiness=true. Elapsed: 5.307369ms
Sep  3 16:57:17.397: INFO: Pod "pod-update-activedeadlineseconds-e01176ab-ce6b-11e9-a956-0a580af40009": Phase="Running", Reason="", readiness=true. Elapsed: 2.011055951s
Sep  3 16:57:19.411: INFO: Pod "pod-update-activedeadlineseconds-e01176ab-ce6b-11e9-a956-0a580af40009": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.02432998s
Sep  3 16:57:19.411: INFO: Pod "pod-update-activedeadlineseconds-e01176ab-ce6b-11e9-a956-0a580af40009" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:57:19.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-xmfmk" for this suite.
Sep  3 16:57:25.489: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:57:25.501: INFO: namespace: e2e-tests-pods-xmfmk, resource: bindings, ignored listing per whitelist
Sep  3 16:57:26.290: INFO: namespace e2e-tests-pods-xmfmk deletion completed in 6.873576129s

• [SLOW TEST:13.675 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:57:26.290: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Sep  3 16:57:31.593: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:57:32.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-rfpjz" for this suite.
Sep  3 16:57:54.698: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:57:55.054: INFO: namespace: e2e-tests-replicaset-rfpjz, resource: bindings, ignored listing per whitelist
Sep  3 16:57:55.562: INFO: namespace e2e-tests-replicaset-rfpjz deletion completed in 22.921120665s

• [SLOW TEST:29.272 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:57:55.562: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-m5tvp.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-m5tvp.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-m5tvp.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-m5tvp.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-m5tvp.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-m5tvp.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep  3 16:57:58.116: INFO: DNS probes using e2e-tests-dns-m5tvp/dns-test-f9a95e00-ce6b-11e9-a956-0a580af40009 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:57:58.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-m5tvp" for this suite.
Sep  3 16:58:04.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:58:04.684: INFO: namespace: e2e-tests-dns-m5tvp, resource: bindings, ignored listing per whitelist
Sep  3 16:58:05.106: INFO: namespace e2e-tests-dns-m5tvp deletion completed in 6.942510125s

• [SLOW TEST:9.544 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:58:05.106: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-jslxq
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-jslxq to expose endpoints map[]
Sep  3 16:58:05.340: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-jslxq exposes endpoints map[] (23.251342ms elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-jslxq
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-jslxq to expose endpoints map[pod1:[80]]
Sep  3 16:58:07.431: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-jslxq exposes endpoints map[pod1:[80]] (2.054563365s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-jslxq
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-jslxq to expose endpoints map[pod1:[80] pod2:[80]]
Sep  3 16:58:09.512: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-jslxq exposes endpoints map[pod1:[80] pod2:[80]] (2.075145483s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-jslxq
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-jslxq to expose endpoints map[pod2:[80]]
Sep  3 16:58:09.556: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-jslxq exposes endpoints map[pod2:[80]] (12.970805ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-jslxq
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-jslxq to expose endpoints map[]
Sep  3 16:58:10.603: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-jslxq exposes endpoints map[] (1.013403652s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:58:10.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-jslxq" for this suite.
Sep  3 16:58:32.714: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:58:33.584: INFO: namespace: e2e-tests-services-jslxq, resource: bindings, ignored listing per whitelist
Sep  3 16:58:33.633: INFO: namespace e2e-tests-services-jslxq deletion completed in 22.978292085s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:28.526 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:58:33.633: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-4grgp
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep  3 16:58:33.767: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep  3 16:58:47.951: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.0.81:8080/dial?request=hostName&protocol=udp&host=10.244.0.80&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-4grgp PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  3 16:58:47.951: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
Sep  3 16:58:48.314: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:58:48.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-4grgp" for this suite.
Sep  3 16:59:10.392: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:59:10.714: INFO: namespace: e2e-tests-pod-network-test-4grgp, resource: bindings, ignored listing per whitelist
Sep  3 16:59:11.386: INFO: namespace e2e-tests-pod-network-test-4grgp deletion completed in 23.06462358s

• [SLOW TEST:37.753 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:59:11.386: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Sep  3 16:59:11.546: INFO: Waiting up to 5m0s for pod "pod-26dad3b7-ce6c-11e9-a956-0a580af40009" in namespace "e2e-tests-emptydir-5nnl5" to be "success or failure"
Sep  3 16:59:11.573: INFO: Pod "pod-26dad3b7-ce6c-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 27.349229ms
Sep  3 16:59:13.583: INFO: Pod "pod-26dad3b7-ce6c-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.036814105s
STEP: Saw pod success
Sep  3 16:59:13.583: INFO: Pod "pod-26dad3b7-ce6c-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 16:59:13.590: INFO: Trying to get logs from node 10.0.10.2 pod pod-26dad3b7-ce6c-11e9-a956-0a580af40009 container test-container: <nil>
STEP: delete the pod
Sep  3 16:59:13.665: INFO: Waiting for pod pod-26dad3b7-ce6c-11e9-a956-0a580af40009 to disappear
Sep  3 16:59:13.691: INFO: Pod pod-26dad3b7-ce6c-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:59:13.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-5nnl5" for this suite.
Sep  3 16:59:21.762: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:59:22.502: INFO: namespace: e2e-tests-emptydir-5nnl5, resource: bindings, ignored listing per whitelist
Sep  3 16:59:22.628: INFO: namespace e2e-tests-emptydir-5nnl5 deletion completed in 8.931096004s

• [SLOW TEST:11.242 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:59:22.628: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Sep  3 16:59:22.793: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2d8f2323-ce6c-11e9-a956-0a580af40009" in namespace "e2e-tests-projected-8zxrh" to be "success or failure"
Sep  3 16:59:22.820: INFO: Pod "downwardapi-volume-2d8f2323-ce6c-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 26.50353ms
Sep  3 16:59:24.826: INFO: Pod "downwardapi-volume-2d8f2323-ce6c-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.032714889s
STEP: Saw pod success
Sep  3 16:59:24.826: INFO: Pod "downwardapi-volume-2d8f2323-ce6c-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 16:59:24.831: INFO: Trying to get logs from node 10.0.10.2 pod downwardapi-volume-2d8f2323-ce6c-11e9-a956-0a580af40009 container client-container: <nil>
STEP: delete the pod
Sep  3 16:59:24.900: INFO: Waiting for pod downwardapi-volume-2d8f2323-ce6c-11e9-a956-0a580af40009 to disappear
Sep  3 16:59:24.926: INFO: Pod downwardapi-volume-2d8f2323-ce6c-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:59:24.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8zxrh" for this suite.
Sep  3 16:59:30.992: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:59:31.366: INFO: namespace: e2e-tests-projected-8zxrh, resource: bindings, ignored listing per whitelist
Sep  3 16:59:31.855: INFO: namespace e2e-tests-projected-8zxrh deletion completed in 6.922131168s

• [SLOW TEST:9.227 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:59:31.856: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-330e4399-ce6c-11e9-a956-0a580af40009
STEP: Creating a pod to test consume configMaps
Sep  3 16:59:32.044: INFO: Waiting up to 5m0s for pod "pod-configmaps-33127f31-ce6c-11e9-a956-0a580af40009" in namespace "e2e-tests-configmap-x2v4v" to be "success or failure"
Sep  3 16:59:32.068: INFO: Pod "pod-configmaps-33127f31-ce6c-11e9-a956-0a580af40009": Phase="Pending", Reason="", readiness=false. Elapsed: 23.524281ms
Sep  3 16:59:34.074: INFO: Pod "pod-configmaps-33127f31-ce6c-11e9-a956-0a580af40009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.029490907s
STEP: Saw pod success
Sep  3 16:59:34.074: INFO: Pod "pod-configmaps-33127f31-ce6c-11e9-a956-0a580af40009" satisfied condition "success or failure"
Sep  3 16:59:34.079: INFO: Trying to get logs from node 10.0.10.2 pod pod-configmaps-33127f31-ce6c-11e9-a956-0a580af40009 container configmap-volume-test: <nil>
STEP: delete the pod
Sep  3 16:59:34.157: INFO: Waiting for pod pod-configmaps-33127f31-ce6c-11e9-a956-0a580af40009 to disappear
Sep  3 16:59:34.181: INFO: Pod pod-configmaps-33127f31-ce6c-11e9-a956-0a580af40009 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 16:59:34.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-x2v4v" for this suite.
Sep  3 16:59:40.246: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 16:59:40.801: INFO: namespace: e2e-tests-configmap-x2v4v, resource: bindings, ignored listing per whitelist
Sep  3 16:59:41.280: INFO: namespace e2e-tests-configmap-x2v4v deletion completed in 7.09363855s

• [SLOW TEST:9.425 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  3 16:59:41.281: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-lwkqk
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep  3 16:59:41.423: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep  3 17:00:01.624: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.0.86:8080/dial?request=hostName&protocol=http&host=10.244.0.85&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-lwkqk PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  3 17:00:01.624: INFO: >>> kubeConfig: /tmp/kubeconfig-043111098
Sep  3 17:00:01.905: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  3 17:00:01.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-lwkqk" for this suite.
Sep  3 17:00:24.014: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 17:00:24.756: INFO: namespace: e2e-tests-pod-network-test-lwkqk, resource: bindings, ignored listing per whitelist
Sep  3 17:00:24.931: INFO: namespace e2e-tests-pod-network-test-lwkqk deletion completed in 23.020189928s

• [SLOW TEST:43.651 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSep  3 17:00:24.932: INFO: Running AfterSuite actions on all nodes
Sep  3 17:00:24.932: INFO: Running AfterSuite actions on node 1
Sep  3 17:00:24.932: INFO: Skipping dumping logs from cluster

Ran 200 of 1946 Specs in 5959.498 seconds
SUCCESS! -- 200 Passed | 0 Failed | 0 Pending | 1746 Skipped PASS

Ginkgo ran 1 suite in 1h39m21.701563235s
Test Suite Passed
