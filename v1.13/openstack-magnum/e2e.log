I0801 07:26:42.322800      12 test_context.go:358] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-683321083
I0801 07:26:42.399353      12 e2e.go:224] Starting e2e run "b507996a-b42d-11e9-aec8-12de527cd1b8" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1564644401 - Will randomize all specs
Will run 201 of 1946 specs

Aug  1 07:26:42.696: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
Aug  1 07:26:42.699: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Aug  1 07:26:42.845: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Aug  1 07:26:43.007: INFO: 10 / 10 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Aug  1 07:26:43.007: INFO: expected 5 pod replicas in namespace 'kube-system', 5 are Running and Ready.
Aug  1 07:26:43.007: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Aug  1 07:26:43.019: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Aug  1 07:26:43.019: INFO: 1 / 1 pods ready in namespace 'kube-system' in daemonset 'k8s-keystone-auth' (0 seconds elapsed)
Aug  1 07:26:43.019: INFO: 1 / 1 pods ready in namespace 'kube-system' in daemonset 'npd' (0 seconds elapsed)
Aug  1 07:26:43.019: INFO: 1 / 1 pods ready in namespace 'kube-system' in daemonset 'openstack-cloud-controller-manager' (0 seconds elapsed)
Aug  1 07:26:43.019: INFO: e2e test version: v1.13.0
Aug  1 07:26:43.021: INFO: kube-apiserver version: v1.13.7
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 07:26:43.024: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename kubectl
Aug  1 07:26:43.555: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Aug  1 07:26:43.558: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 create -f - --namespace=e2e-tests-kubectl-6594j'
Aug  1 07:26:46.846: INFO: stderr: ""
Aug  1 07:26:46.846: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug  1 07:26:46.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6594j'
Aug  1 07:26:47.039: INFO: stderr: ""
Aug  1 07:26:47.040: INFO: stdout: "update-demo-nautilus-lbcmh update-demo-nautilus-tqg6l "
Aug  1 07:26:47.040: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods update-demo-nautilus-lbcmh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6594j'
Aug  1 07:26:47.281: INFO: stderr: ""
Aug  1 07:26:47.281: INFO: stdout: ""
Aug  1 07:26:47.281: INFO: update-demo-nautilus-lbcmh is created but not running
Aug  1 07:26:52.282: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6594j'
Aug  1 07:26:53.204: INFO: stderr: ""
Aug  1 07:26:53.204: INFO: stdout: "update-demo-nautilus-lbcmh update-demo-nautilus-tqg6l "
Aug  1 07:26:53.204: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods update-demo-nautilus-lbcmh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6594j'
Aug  1 07:26:54.014: INFO: stderr: ""
Aug  1 07:26:54.014: INFO: stdout: ""
Aug  1 07:26:54.014: INFO: update-demo-nautilus-lbcmh is created but not running
Aug  1 07:26:59.014: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6594j'
Aug  1 07:26:59.798: INFO: stderr: ""
Aug  1 07:26:59.798: INFO: stdout: "update-demo-nautilus-lbcmh update-demo-nautilus-tqg6l "
Aug  1 07:26:59.798: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods update-demo-nautilus-lbcmh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6594j'
Aug  1 07:26:59.920: INFO: stderr: ""
Aug  1 07:26:59.920: INFO: stdout: ""
Aug  1 07:26:59.920: INFO: update-demo-nautilus-lbcmh is created but not running
Aug  1 07:27:04.921: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6594j'
Aug  1 07:27:05.466: INFO: stderr: ""
Aug  1 07:27:05.466: INFO: stdout: "update-demo-nautilus-lbcmh update-demo-nautilus-tqg6l "
Aug  1 07:27:05.466: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods update-demo-nautilus-lbcmh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6594j'
Aug  1 07:27:05.642: INFO: stderr: ""
Aug  1 07:27:05.642: INFO: stdout: ""
Aug  1 07:27:05.642: INFO: update-demo-nautilus-lbcmh is created but not running
Aug  1 07:27:10.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6594j'
Aug  1 07:27:10.810: INFO: stderr: ""
Aug  1 07:27:10.810: INFO: stdout: "update-demo-nautilus-lbcmh update-demo-nautilus-tqg6l "
Aug  1 07:27:10.810: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods update-demo-nautilus-lbcmh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6594j'
Aug  1 07:27:11.267: INFO: stderr: ""
Aug  1 07:27:11.267: INFO: stdout: ""
Aug  1 07:27:11.267: INFO: update-demo-nautilus-lbcmh is created but not running
Aug  1 07:27:16.267: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6594j'
Aug  1 07:27:16.385: INFO: stderr: ""
Aug  1 07:27:16.385: INFO: stdout: "update-demo-nautilus-lbcmh update-demo-nautilus-tqg6l "
Aug  1 07:27:16.385: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods update-demo-nautilus-lbcmh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6594j'
Aug  1 07:27:16.537: INFO: stderr: ""
Aug  1 07:27:16.537: INFO: stdout: ""
Aug  1 07:27:16.537: INFO: update-demo-nautilus-lbcmh is created but not running
Aug  1 07:27:21.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6594j'
Aug  1 07:27:21.671: INFO: stderr: ""
Aug  1 07:27:21.671: INFO: stdout: "update-demo-nautilus-lbcmh update-demo-nautilus-tqg6l "
Aug  1 07:27:21.671: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods update-demo-nautilus-lbcmh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6594j'
Aug  1 07:27:21.831: INFO: stderr: ""
Aug  1 07:27:21.831: INFO: stdout: ""
Aug  1 07:27:21.831: INFO: update-demo-nautilus-lbcmh is created but not running
Aug  1 07:27:26.831: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6594j'
Aug  1 07:27:27.038: INFO: stderr: ""
Aug  1 07:27:27.038: INFO: stdout: "update-demo-nautilus-lbcmh update-demo-nautilus-tqg6l "
Aug  1 07:27:27.038: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods update-demo-nautilus-lbcmh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6594j'
Aug  1 07:27:27.160: INFO: stderr: ""
Aug  1 07:27:27.160: INFO: stdout: "true"
Aug  1 07:27:27.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods update-demo-nautilus-lbcmh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6594j'
Aug  1 07:27:27.294: INFO: stderr: ""
Aug  1 07:27:27.294: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug  1 07:27:27.294: INFO: validating pod update-demo-nautilus-lbcmh
Aug  1 07:27:27.417: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug  1 07:27:27.417: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug  1 07:27:27.417: INFO: update-demo-nautilus-lbcmh is verified up and running
Aug  1 07:27:27.417: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods update-demo-nautilus-tqg6l -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6594j'
Aug  1 07:27:27.530: INFO: stderr: ""
Aug  1 07:27:27.530: INFO: stdout: ""
Aug  1 07:27:27.530: INFO: update-demo-nautilus-tqg6l is created but not running
Aug  1 07:27:32.530: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6594j'
Aug  1 07:27:32.658: INFO: stderr: ""
Aug  1 07:27:32.658: INFO: stdout: "update-demo-nautilus-lbcmh update-demo-nautilus-tqg6l "
Aug  1 07:27:32.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods update-demo-nautilus-lbcmh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6594j'
Aug  1 07:27:32.804: INFO: stderr: ""
Aug  1 07:27:32.804: INFO: stdout: "true"
Aug  1 07:27:32.804: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods update-demo-nautilus-lbcmh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6594j'
Aug  1 07:27:32.929: INFO: stderr: ""
Aug  1 07:27:32.929: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug  1 07:27:32.929: INFO: validating pod update-demo-nautilus-lbcmh
Aug  1 07:27:32.933: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug  1 07:27:32.933: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug  1 07:27:32.933: INFO: update-demo-nautilus-lbcmh is verified up and running
Aug  1 07:27:32.933: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods update-demo-nautilus-tqg6l -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6594j'
Aug  1 07:27:33.125: INFO: stderr: ""
Aug  1 07:27:33.125: INFO: stdout: "true"
Aug  1 07:27:33.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods update-demo-nautilus-tqg6l -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6594j'
Aug  1 07:27:33.296: INFO: stderr: ""
Aug  1 07:27:33.296: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug  1 07:27:33.296: INFO: validating pod update-demo-nautilus-tqg6l
Aug  1 07:27:33.300: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug  1 07:27:33.301: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug  1 07:27:33.301: INFO: update-demo-nautilus-tqg6l is verified up and running
STEP: using delete to clean up resources
Aug  1 07:27:33.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-6594j'
Aug  1 07:27:33.448: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug  1 07:27:33.448: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Aug  1 07:27:33.448: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-6594j'
Aug  1 07:27:33.666: INFO: stderr: "No resources found.\n"
Aug  1 07:27:33.666: INFO: stdout: ""
Aug  1 07:27:33.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods -l name=update-demo --namespace=e2e-tests-kubectl-6594j -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug  1 07:27:33.843: INFO: stderr: ""
Aug  1 07:27:33.843: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 07:27:33.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6594j" for this suite.
Aug  1 07:27:42.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 07:27:42.419: INFO: namespace: e2e-tests-kubectl-6594j, resource: bindings, ignored listing per whitelist
Aug  1 07:27:42.460: INFO: namespace e2e-tests-kubectl-6594j deletion completed in 8.301993438s

• [SLOW TEST:59.437 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 07:27:42.485: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-d9cf5901-b42d-11e9-aec8-12de527cd1b8
STEP: Creating a pod to test consume secrets
Aug  1 07:27:43.527: INFO: Waiting up to 5m0s for pod "pod-secrets-d9dab008-b42d-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-secrets-hg8fq" to be "success or failure"
Aug  1 07:27:43.763: INFO: Pod "pod-secrets-d9dab008-b42d-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 235.870275ms
Aug  1 07:27:45.768: INFO: Pod "pod-secrets-d9dab008-b42d-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.240315709s
Aug  1 07:27:47.831: INFO: Pod "pod-secrets-d9dab008-b42d-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.303488206s
Aug  1 07:27:49.833: INFO: Pod "pod-secrets-d9dab008-b42d-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.305495175s
Aug  1 07:27:51.941: INFO: Pod "pod-secrets-d9dab008-b42d-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 8.414117027s
Aug  1 07:27:53.943: INFO: Pod "pod-secrets-d9dab008-b42d-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 10.416214414s
Aug  1 07:27:56.018: INFO: Pod "pod-secrets-d9dab008-b42d-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 12.49096262s
Aug  1 07:27:58.021: INFO: Pod "pod-secrets-d9dab008-b42d-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 14.493784046s
STEP: Saw pod success
Aug  1 07:27:58.021: INFO: Pod "pod-secrets-d9dab008-b42d-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 07:27:58.023: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod pod-secrets-d9dab008-b42d-11e9-aec8-12de527cd1b8 container secret-env-test: <nil>
STEP: delete the pod
Aug  1 07:27:58.335: INFO: Waiting for pod pod-secrets-d9dab008-b42d-11e9-aec8-12de527cd1b8 to disappear
Aug  1 07:27:58.362: INFO: Pod pod-secrets-d9dab008-b42d-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 07:27:58.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-hg8fq" for this suite.
Aug  1 07:28:06.601: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 07:28:06.681: INFO: namespace: e2e-tests-secrets-hg8fq, resource: bindings, ignored listing per whitelist
Aug  1 07:28:06.704: INFO: namespace e2e-tests-secrets-hg8fq deletion completed in 8.291267195s

• [SLOW TEST:24.219 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 07:28:06.710: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 07:28:13.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-qqchg" for this suite.
Aug  1 07:28:53.243: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 07:28:53.486: INFO: namespace: e2e-tests-kubelet-test-qqchg, resource: bindings, ignored listing per whitelist
Aug  1 07:28:53.497: INFO: namespace e2e-tests-kubelet-test-qqchg deletion completed in 40.28909987s

• [SLOW TEST:46.788 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 07:28:53.500: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug  1 07:28:54.017: INFO: Waiting up to 5m0s for pod "downwardapi-volume-03db6bee-b42e-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-projected-pmldf" to be "success or failure"
Aug  1 07:28:54.077: INFO: Pod "downwardapi-volume-03db6bee-b42e-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 59.516096ms
Aug  1 07:28:56.295: INFO: Pod "downwardapi-volume-03db6bee-b42e-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.278423649s
Aug  1 07:28:58.298: INFO: Pod "downwardapi-volume-03db6bee-b42e-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.281309557s
Aug  1 07:29:00.302: INFO: Pod "downwardapi-volume-03db6bee-b42e-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.285448612s
Aug  1 07:29:02.306: INFO: Pod "downwardapi-volume-03db6bee-b42e-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 8.288871357s
Aug  1 07:29:04.309: INFO: Pod "downwardapi-volume-03db6bee-b42e-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 10.292370632s
Aug  1 07:29:06.313: INFO: Pod "downwardapi-volume-03db6bee-b42e-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 12.2964632s
Aug  1 07:29:08.318: INFO: Pod "downwardapi-volume-03db6bee-b42e-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 14.30117759s
Aug  1 07:29:10.322: INFO: Pod "downwardapi-volume-03db6bee-b42e-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 16.305062853s
STEP: Saw pod success
Aug  1 07:29:10.322: INFO: Pod "downwardapi-volume-03db6bee-b42e-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 07:29:10.325: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod downwardapi-volume-03db6bee-b42e-11e9-aec8-12de527cd1b8 container client-container: <nil>
STEP: delete the pod
Aug  1 07:29:10.633: INFO: Waiting for pod downwardapi-volume-03db6bee-b42e-11e9-aec8-12de527cd1b8 to disappear
Aug  1 07:29:10.678: INFO: Pod downwardapi-volume-03db6bee-b42e-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 07:29:10.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pmldf" for this suite.
Aug  1 07:29:16.804: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 07:29:17.045: INFO: namespace: e2e-tests-projected-pmldf, resource: bindings, ignored listing per whitelist
Aug  1 07:29:17.085: INFO: namespace e2e-tests-projected-pmldf deletion completed in 6.403578166s

• [SLOW TEST:23.585 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 07:29:17.088: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Aug  1 07:29:47.754: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug  1 07:29:47.840: INFO: Pod pod-with-prestop-http-hook still exists
Aug  1 07:29:49.840: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug  1 07:29:49.844: INFO: Pod pod-with-prestop-http-hook still exists
Aug  1 07:29:51.840: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug  1 07:29:51.843: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 07:29:51.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-7wm2f" for this suite.
Aug  1 07:30:16.019: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 07:30:16.121: INFO: namespace: e2e-tests-container-lifecycle-hook-7wm2f, resource: bindings, ignored listing per whitelist
Aug  1 07:30:16.147: INFO: namespace e2e-tests-container-lifecycle-hook-7wm2f deletion completed in 24.282229393s

• [SLOW TEST:59.059 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 07:30:16.150: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Aug  1 07:30:16.500: INFO: Waiting up to 5m0s for pod "pod-351aae54-b42e-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-emptydir-66lxl" to be "success or failure"
Aug  1 07:30:16.524: INFO: Pod "pod-351aae54-b42e-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 23.884431ms
Aug  1 07:30:18.548: INFO: Pod "pod-351aae54-b42e-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.048134919s
Aug  1 07:30:20.552: INFO: Pod "pod-351aae54-b42e-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.05242585s
Aug  1 07:30:22.556: INFO: Pod "pod-351aae54-b42e-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.056119375s
Aug  1 07:30:24.560: INFO: Pod "pod-351aae54-b42e-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 8.06042238s
Aug  1 07:30:26.565: INFO: Pod "pod-351aae54-b42e-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 10.0649602s
Aug  1 07:30:28.568: INFO: Pod "pod-351aae54-b42e-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 12.0677552s
Aug  1 07:30:30.662: INFO: Pod "pod-351aae54-b42e-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 14.162172103s
STEP: Saw pod success
Aug  1 07:30:30.662: INFO: Pod "pod-351aae54-b42e-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 07:30:30.687: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod pod-351aae54-b42e-11e9-aec8-12de527cd1b8 container test-container: <nil>
STEP: delete the pod
Aug  1 07:30:30.823: INFO: Waiting for pod pod-351aae54-b42e-11e9-aec8-12de527cd1b8 to disappear
Aug  1 07:30:30.855: INFO: Pod pod-351aae54-b42e-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 07:30:30.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-66lxl" for this suite.
Aug  1 07:30:36.924: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 07:30:36.960: INFO: namespace: e2e-tests-emptydir-66lxl, resource: bindings, ignored listing per whitelist
Aug  1 07:30:37.051: INFO: namespace e2e-tests-emptydir-66lxl deletion completed in 6.189945212s

• [SLOW TEST:20.901 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 07:30:37.055: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-41abdf6a-b42e-11e9-aec8-12de527cd1b8
STEP: Creating a pod to test consume configMaps
Aug  1 07:30:37.511: INFO: Waiting up to 5m0s for pod "pod-configmaps-41aca842-b42e-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-configmap-lzvhb" to be "success or failure"
Aug  1 07:30:37.564: INFO: Pod "pod-configmaps-41aca842-b42e-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 52.024802ms
Aug  1 07:30:39.567: INFO: Pod "pod-configmaps-41aca842-b42e-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.055030509s
Aug  1 07:30:41.570: INFO: Pod "pod-configmaps-41aca842-b42e-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.057774757s
STEP: Saw pod success
Aug  1 07:30:41.570: INFO: Pod "pod-configmaps-41aca842-b42e-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 07:30:41.572: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod pod-configmaps-41aca842-b42e-11e9-aec8-12de527cd1b8 container configmap-volume-test: <nil>
STEP: delete the pod
Aug  1 07:30:41.871: INFO: Waiting for pod pod-configmaps-41aca842-b42e-11e9-aec8-12de527cd1b8 to disappear
Aug  1 07:30:41.911: INFO: Pod pod-configmaps-41aca842-b42e-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 07:30:41.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-lzvhb" for this suite.
Aug  1 07:30:48.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 07:30:48.348: INFO: namespace: e2e-tests-configmap-lzvhb, resource: bindings, ignored listing per whitelist
Aug  1 07:30:48.370: INFO: namespace e2e-tests-configmap-lzvhb deletion completed in 6.453339119s

• [SLOW TEST:11.315 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 07:30:48.373: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug  1 07:30:48.723: INFO: Creating deployment "test-recreate-deployment"
Aug  1 07:30:48.769: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Aug  1 07:30:49.300: INFO: Waiting deployment "test-recreate-deployment" to complete
Aug  1 07:30:49.461: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241448, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241448, loc:(*time.Location)(0x7b33b80)}}, Reason:"NewReplicaSetCreated", Message:"Created new replica set \"test-recreate-deployment-5dfdcc846d\""}, v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241448, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241448, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}}, CollisionCount:(*int32)(nil)}
Aug  1 07:30:51.475: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241448, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241448, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241449, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241448, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-5dfdcc846d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  1 07:30:53.592: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241448, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241448, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241449, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241448, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-5dfdcc846d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  1 07:30:55.465: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241448, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241448, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241449, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241448, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-5dfdcc846d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  1 07:30:57.466: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241448, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241448, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241449, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241448, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-5dfdcc846d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  1 07:30:59.465: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241448, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241448, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241449, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241448, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-5dfdcc846d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  1 07:31:01.467: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241448, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241448, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241449, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241448, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-5dfdcc846d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  1 07:31:03.506: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241448, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241448, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241449, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241448, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-5dfdcc846d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  1 07:31:05.467: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Aug  1 07:31:05.476: INFO: Updating deployment test-recreate-deployment
Aug  1 07:31:05.476: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Aug  1 07:31:07.598: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-lc4fp,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-lc4fp/deployments/test-recreate-deployment,UID:4818d8fa-b42e-11e9-8923-fa163ec474fb,ResourceVersion:3205,Generation:2,CreationTimestamp:2019-08-01 07:30:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-08-01 07:31:06 +0000 UTC 2019-08-01 07:31:06 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-08-01 07:31:07 +0000 UTC 2019-08-01 07:30:48 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-697fbf54bf" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Aug  1 07:31:07.601: INFO: New ReplicaSet "test-recreate-deployment-697fbf54bf" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf,GenerateName:,Namespace:e2e-tests-deployment-lc4fp,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-lc4fp/replicasets/test-recreate-deployment-697fbf54bf,UID:52c5eddc-b42e-11e9-8923-fa163ec474fb,ResourceVersion:3202,Generation:1,CreationTimestamp:2019-08-01 07:31:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 4818d8fa-b42e-11e9-8923-fa163ec474fb 0xc000ac5ea7 0xc000ac5ea8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug  1 07:31:07.601: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Aug  1 07:31:07.601: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5dfdcc846d,GenerateName:,Namespace:e2e-tests-deployment-lc4fp,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-lc4fp/replicasets/test-recreate-deployment-5dfdcc846d,UID:48194c4f-b42e-11e9-8923-fa163ec474fb,ResourceVersion:3192,Generation:2,CreationTimestamp:2019-08-01 07:30:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 4818d8fa-b42e-11e9-8923-fa163ec474fb 0xc000ac5de7 0xc000ac5de8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug  1 07:31:07.608: INFO: Pod "test-recreate-deployment-697fbf54bf-fphnp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf-fphnp,GenerateName:test-recreate-deployment-697fbf54bf-,Namespace:e2e-tests-deployment-lc4fp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lc4fp/pods/test-recreate-deployment-697fbf54bf-fphnp,UID:52f2a1f7-b42e-11e9-8923-fa163ec474fb,ResourceVersion:3203,Generation:0,CreationTimestamp:2019-08-01 07:31:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-697fbf54bf 52c5eddc-b42e-11e9-8923-fa163ec474fb 0xc003bccb87 0xc003bccb88}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ll9xm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ll9xm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ll9xm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-6lh7zebx7k5q-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003bccbf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003bccc10}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:31:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:31:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:31:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:31:06 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.23,PodIP:,StartTime:2019-08-01 07:31:07 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 07:31:07.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-lc4fp" for this suite.
Aug  1 07:31:17.812: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 07:31:18.073: INFO: namespace: e2e-tests-deployment-lc4fp, resource: bindings, ignored listing per whitelist
Aug  1 07:31:18.110: INFO: namespace e2e-tests-deployment-lc4fp deletion completed in 10.497886577s

• [SLOW TEST:29.738 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 07:31:18.114: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug  1 07:31:18.931: INFO: Pod name rollover-pod: Found 0 pods out of 1
Aug  1 07:31:24.009: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug  1 07:31:26.111: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Aug  1 07:31:28.115: INFO: Creating deployment "test-rollover-deployment"
Aug  1 07:31:28.153: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Aug  1 07:31:30.158: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Aug  1 07:31:30.168: INFO: Ensure that both replica sets have 1 created replica
Aug  1 07:31:30.172: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Aug  1 07:31:30.180: INFO: Updating deployment test-rollover-deployment
Aug  1 07:31:30.180: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Aug  1 07:31:32.232: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Aug  1 07:31:32.238: INFO: Make sure deployment "test-rollover-deployment" is complete
Aug  1 07:31:32.307: INFO: all replica sets need to contain the pod-template-hash label
Aug  1 07:31:32.308: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241488, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241488, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241491, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241487, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  1 07:31:34.314: INFO: all replica sets need to contain the pod-template-hash label
Aug  1 07:31:34.314: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241488, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241488, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241491, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241487, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  1 07:31:36.334: INFO: all replica sets need to contain the pod-template-hash label
Aug  1 07:31:36.334: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241488, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241488, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241495, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241487, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  1 07:31:38.353: INFO: all replica sets need to contain the pod-template-hash label
Aug  1 07:31:38.354: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241488, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241488, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241495, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241487, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  1 07:31:40.328: INFO: all replica sets need to contain the pod-template-hash label
Aug  1 07:31:40.328: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241488, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241488, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241495, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241487, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  1 07:31:42.324: INFO: all replica sets need to contain the pod-template-hash label
Aug  1 07:31:42.325: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241488, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241488, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241495, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241487, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  1 07:31:44.339: INFO: all replica sets need to contain the pod-template-hash label
Aug  1 07:31:44.339: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241488, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241488, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241495, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241487, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  1 07:31:46.547: INFO: 
Aug  1 07:31:46.547: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:2, UnavailableReplicas:0, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241488, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241488, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241505, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700241487, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  1 07:31:48.545: INFO: 
Aug  1 07:31:48.545: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Aug  1 07:31:48.551: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-wsf4v,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-wsf4v/deployments/test-rollover-deployment,UID:5f9113ee-b42e-11e9-8923-fa163ec474fb,ResourceVersion:3379,Generation:2,CreationTimestamp:2019-08-01 07:31:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-08-01 07:31:28 +0000 UTC 2019-08-01 07:31:28 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-08-01 07:31:46 +0000 UTC 2019-08-01 07:31:27 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-6b7f9d6597" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Aug  1 07:31:48.553: INFO: New ReplicaSet "test-rollover-deployment-6b7f9d6597" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597,GenerateName:,Namespace:e2e-tests-deployment-wsf4v,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-wsf4v/replicasets/test-rollover-deployment-6b7f9d6597,UID:60cc0324-b42e-11e9-8923-fa163ec474fb,ResourceVersion:3368,Generation:2,CreationTimestamp:2019-08-01 07:31:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 5f9113ee-b42e-11e9-8923-fa163ec474fb 0xc000d6b817 0xc000d6b818}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Aug  1 07:31:48.553: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Aug  1 07:31:48.553: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-wsf4v,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-wsf4v/replicasets/test-rollover-controller,UID:59e600e4-b42e-11e9-8923-fa163ec474fb,ResourceVersion:3377,Generation:2,CreationTimestamp:2019-08-01 07:31:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 5f9113ee-b42e-11e9-8923-fa163ec474fb 0xc000d6b68f 0xc000d6b6a0}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug  1 07:31:48.553: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6586df867b,GenerateName:,Namespace:e2e-tests-deployment-wsf4v,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-wsf4v/replicasets/test-rollover-deployment-6586df867b,UID:5f979e9b-b42e-11e9-8923-fa163ec474fb,ResourceVersion:3325,Generation:2,CreationTimestamp:2019-08-01 07:31:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 5f9113ee-b42e-11e9-8923-fa163ec474fb 0xc000d6b757 0xc000d6b758}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug  1 07:31:48.555: INFO: Pod "test-rollover-deployment-6b7f9d6597-8bqwz" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597-8bqwz,GenerateName:test-rollover-deployment-6b7f9d6597-,Namespace:e2e-tests-deployment-wsf4v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wsf4v/pods/test-rollover-deployment-6b7f9d6597-8bqwz,UID:613df705-b42e-11e9-8923-fa163ec474fb,ResourceVersion:3346,Generation:0,CreationTimestamp:2019-08-01 07:31:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.23/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-6b7f9d6597 60cc0324-b42e-11e9-8923-fa163ec474fb 0xc000b00347 0xc000b00348}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-s284b {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-s284b,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-s284b true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-6lh7zebx7k5q-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000b003b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000b003d0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:31:31 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:31:35 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:31:35 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:31:30 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.23,PodIP:192.168.1.23,StartTime:2019-08-01 07:31:31 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-08-01 07:31:34 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://3839db253e2466269415bdd3ad524845f359df5d8b811a3e9a7bf6bcad609c66}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 07:31:48.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-wsf4v" for this suite.
Aug  1 07:31:58.597: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 07:31:58.854: INFO: namespace: e2e-tests-deployment-wsf4v, resource: bindings, ignored listing per whitelist
Aug  1 07:31:58.860: INFO: namespace e2e-tests-deployment-wsf4v deletion completed in 10.301066114s

• [SLOW TEST:40.746 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 07:31:58.862: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Aug  1 07:31:59.298: INFO: Waiting up to 5m0s for pod "downward-api-726f4a54-b42e-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-downward-api-x64r6" to be "success or failure"
Aug  1 07:31:59.339: INFO: Pod "downward-api-726f4a54-b42e-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 40.649412ms
Aug  1 07:32:01.441: INFO: Pod "downward-api-726f4a54-b42e-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.14283393s
Aug  1 07:32:03.485: INFO: Pod "downward-api-726f4a54-b42e-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.186769764s
STEP: Saw pod success
Aug  1 07:32:03.485: INFO: Pod "downward-api-726f4a54-b42e-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 07:32:03.487: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod downward-api-726f4a54-b42e-11e9-aec8-12de527cd1b8 container dapi-container: <nil>
STEP: delete the pod
Aug  1 07:32:03.928: INFO: Waiting for pod downward-api-726f4a54-b42e-11e9-aec8-12de527cd1b8 to disappear
Aug  1 07:32:04.142: INFO: Pod downward-api-726f4a54-b42e-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 07:32:04.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-x64r6" for this suite.
Aug  1 07:32:10.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 07:32:10.344: INFO: namespace: e2e-tests-downward-api-x64r6, resource: bindings, ignored listing per whitelist
Aug  1 07:32:10.425: INFO: namespace e2e-tests-downward-api-x64r6 deletion completed in 6.215772984s

• [SLOW TEST:11.564 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 07:32:10.431: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug  1 07:32:10.861: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Aug  1 07:32:11.093: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:32:11.143: INFO: Number of nodes with available pods: 0
Aug  1 07:32:11.144: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 07:32:12.216: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:32:12.218: INFO: Number of nodes with available pods: 0
Aug  1 07:32:12.218: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 07:32:13.152: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:32:13.276: INFO: Number of nodes with available pods: 0
Aug  1 07:32:13.277: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 07:32:14.153: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:32:14.156: INFO: Number of nodes with available pods: 0
Aug  1 07:32:14.156: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 07:32:15.149: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:32:15.154: INFO: Number of nodes with available pods: 0
Aug  1 07:32:15.154: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 07:32:16.261: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:32:16.264: INFO: Number of nodes with available pods: 0
Aug  1 07:32:16.264: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 07:32:17.147: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:32:17.151: INFO: Number of nodes with available pods: 0
Aug  1 07:32:17.151: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 07:32:18.149: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:32:18.153: INFO: Number of nodes with available pods: 0
Aug  1 07:32:18.153: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 07:32:19.151: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:32:19.153: INFO: Number of nodes with available pods: 0
Aug  1 07:32:19.154: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 07:32:20.172: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:32:20.175: INFO: Number of nodes with available pods: 0
Aug  1 07:32:20.175: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 07:32:21.147: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:32:21.150: INFO: Number of nodes with available pods: 0
Aug  1 07:32:21.150: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 07:32:22.148: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:32:22.154: INFO: Number of nodes with available pods: 0
Aug  1 07:32:22.154: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 07:32:23.148: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:32:23.152: INFO: Number of nodes with available pods: 0
Aug  1 07:32:23.152: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 07:32:24.413: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:32:24.464: INFO: Number of nodes with available pods: 0
Aug  1 07:32:24.464: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 07:32:25.426: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:32:25.511: INFO: Number of nodes with available pods: 0
Aug  1 07:32:25.511: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 07:32:26.358: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:32:26.360: INFO: Number of nodes with available pods: 0
Aug  1 07:32:26.360: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 07:32:27.193: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:32:27.196: INFO: Number of nodes with available pods: 0
Aug  1 07:32:27.196: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 07:32:28.149: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:32:28.152: INFO: Number of nodes with available pods: 1
Aug  1 07:32:28.152: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Aug  1 07:32:28.386: INFO: Wrong image for pod: daemon-set-wcmhm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  1 07:32:28.389: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:32:29.407: INFO: Wrong image for pod: daemon-set-wcmhm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  1 07:32:29.409: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:32:30.393: INFO: Wrong image for pod: daemon-set-wcmhm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  1 07:32:30.396: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:32:31.394: INFO: Wrong image for pod: daemon-set-wcmhm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  1 07:32:31.398: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:32:32.392: INFO: Wrong image for pod: daemon-set-wcmhm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  1 07:32:32.394: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:32:33.393: INFO: Wrong image for pod: daemon-set-wcmhm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  1 07:32:33.396: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:32:34.393: INFO: Wrong image for pod: daemon-set-wcmhm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  1 07:32:34.397: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:32:35.393: INFO: Wrong image for pod: daemon-set-wcmhm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  1 07:32:35.395: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:32:36.391: INFO: Wrong image for pod: daemon-set-wcmhm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  1 07:32:36.394: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:32:37.392: INFO: Wrong image for pod: daemon-set-wcmhm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  1 07:32:37.396: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:32:38.392: INFO: Wrong image for pod: daemon-set-wcmhm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  1 07:32:38.395: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:32:39.393: INFO: Wrong image for pod: daemon-set-wcmhm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  1 07:32:39.396: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:32:40.392: INFO: Wrong image for pod: daemon-set-wcmhm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  1 07:32:40.414: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:32:41.425: INFO: Wrong image for pod: daemon-set-wcmhm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  1 07:32:41.428: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:32:42.392: INFO: Wrong image for pod: daemon-set-wcmhm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  1 07:32:42.394: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:32:43.392: INFO: Wrong image for pod: daemon-set-wcmhm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  1 07:32:43.395: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:32:44.391: INFO: Wrong image for pod: daemon-set-wcmhm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  1 07:32:44.393: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:32:45.393: INFO: Wrong image for pod: daemon-set-wcmhm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  1 07:32:45.396: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:32:46.393: INFO: Wrong image for pod: daemon-set-wcmhm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  1 07:32:46.395: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:32:47.392: INFO: Wrong image for pod: daemon-set-wcmhm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  1 07:32:47.394: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:32:48.393: INFO: Wrong image for pod: daemon-set-wcmhm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  1 07:32:48.395: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:32:49.400: INFO: Wrong image for pod: daemon-set-wcmhm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  1 07:32:49.404: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:32:50.395: INFO: Wrong image for pod: daemon-set-wcmhm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  1 07:32:50.398: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:32:51.422: INFO: Wrong image for pod: daemon-set-wcmhm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  1 07:32:51.425: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:32:52.394: INFO: Wrong image for pod: daemon-set-wcmhm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  1 07:32:52.398: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:32:53.415: INFO: Wrong image for pod: daemon-set-wcmhm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  1 07:32:53.448: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:32:54.395: INFO: Wrong image for pod: daemon-set-wcmhm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  1 07:32:54.400: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:32:55.394: INFO: Wrong image for pod: daemon-set-wcmhm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  1 07:32:55.397: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:32:56.394: INFO: Wrong image for pod: daemon-set-wcmhm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  1 07:32:56.398: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:32:57.425: INFO: Wrong image for pod: daemon-set-wcmhm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  1 07:32:57.427: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:32:58.419: INFO: Wrong image for pod: daemon-set-wcmhm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  1 07:32:58.421: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:32:59.394: INFO: Wrong image for pod: daemon-set-wcmhm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  1 07:32:59.399: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:33:00.421: INFO: Wrong image for pod: daemon-set-wcmhm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  1 07:33:00.424: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:33:01.495: INFO: Wrong image for pod: daemon-set-wcmhm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  1 07:33:01.495: INFO: Pod daemon-set-wcmhm is not available
Aug  1 07:33:01.497: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:33:02.599: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:33:03.532: INFO: Pod daemon-set-6xjs6 is not available
Aug  1 07:33:03.535: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Aug  1 07:33:03.539: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:33:03.541: INFO: Number of nodes with available pods: 0
Aug  1 07:33:03.542: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 07:33:04.674: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:33:04.845: INFO: Number of nodes with available pods: 0
Aug  1 07:33:04.845: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 07:33:05.642: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:33:05.646: INFO: Number of nodes with available pods: 0
Aug  1 07:33:05.646: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 07:33:06.603: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 07:33:06.607: INFO: Number of nodes with available pods: 1
Aug  1 07:33:06.607: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-t5zww, will wait for the garbage collector to delete the pods
Aug  1 07:33:06.879: INFO: Deleting DaemonSet.extensions daemon-set took: 42.269762ms
Aug  1 07:33:07.002: INFO: Terminating DaemonSet.extensions daemon-set pods took: 122.893835ms
Aug  1 07:33:10.662: INFO: Number of nodes with available pods: 0
Aug  1 07:33:10.663: INFO: Number of running nodes: 0, number of available pods: 0
Aug  1 07:33:10.664: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-t5zww/daemonsets","resourceVersion":"3639"},"items":null}

Aug  1 07:33:10.667: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-t5zww/pods","resourceVersion":"3639"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 07:33:10.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-t5zww" for this suite.
Aug  1 07:33:18.718: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 07:33:18.837: INFO: namespace: e2e-tests-daemonsets-t5zww, resource: bindings, ignored listing per whitelist
Aug  1 07:33:18.837: INFO: namespace e2e-tests-daemonsets-t5zww deletion completed in 8.159829294s

• [SLOW TEST:68.407 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 07:33:18.840: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug  1 07:33:19.266: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
Aug  1 07:33:19.288: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-hq2zt/daemonsets","resourceVersion":"3680"},"items":null}

Aug  1 07:33:19.292: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-hq2zt/pods","resourceVersion":"3680"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 07:33:19.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-hq2zt" for this suite.
Aug  1 07:33:25.393: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 07:33:25.619: INFO: namespace: e2e-tests-daemonsets-hq2zt, resource: bindings, ignored listing per whitelist
Aug  1 07:33:25.753: INFO: namespace e2e-tests-daemonsets-hq2zt deletion completed in 6.453441468s

S [SKIPPING] [6.913 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Aug  1 07:33:19.266: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 07:33:25.758: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug  1 07:33:26.248: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-4rx9c'
Aug  1 07:33:26.472: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug  1 07:33:26.472: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Aug  1 07:33:26.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-4rx9c'
Aug  1 07:33:27.293: INFO: stderr: ""
Aug  1 07:33:27.293: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 07:33:27.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-4rx9c" for this suite.
Aug  1 07:33:34.093: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 07:33:34.140: INFO: namespace: e2e-tests-kubectl-4rx9c, resource: bindings, ignored listing per whitelist
Aug  1 07:33:34.191: INFO: namespace e2e-tests-kubectl-4rx9c deletion completed in 6.608828409s

• [SLOW TEST:8.435 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 07:33:34.196: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-2qwls
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-2qwls to expose endpoints map[]
Aug  1 07:33:34.893: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-2qwls exposes endpoints map[] (207.875252ms elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-2qwls
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-2qwls to expose endpoints map[pod1:[80]]
Aug  1 07:33:39.471: INFO: Unexpected endpoints: found map[], expected map[pod1:[80]] (4.564322867s elapsed, will retry)
Aug  1 07:33:40.628: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-2qwls exposes endpoints map[pod1:[80]] (5.721212347s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-2qwls
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-2qwls to expose endpoints map[pod1:[80] pod2:[80]]
Aug  1 07:33:45.202: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-2qwls exposes endpoints map[pod1:[80] pod2:[80]] (4.568917018s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-2qwls
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-2qwls to expose endpoints map[pod2:[80]]
Aug  1 07:33:46.184: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-2qwls exposes endpoints map[pod2:[80]] (943.351354ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-2qwls
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-2qwls to expose endpoints map[]
Aug  1 07:33:47.501: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-2qwls exposes endpoints map[] (1.075521531s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 07:33:48.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-2qwls" for this suite.
Aug  1 07:34:13.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 07:34:13.452: INFO: namespace: e2e-tests-services-2qwls, resource: bindings, ignored listing per whitelist
Aug  1 07:34:13.507: INFO: namespace e2e-tests-services-2qwls deletion completed in 24.577820695s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:39.312 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 07:34:13.510: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Aug  1 07:34:14.248: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-fps45,SelfLink:/api/v1/namespaces/e2e-tests-watch-fps45/configmaps/e2e-watch-test-label-changed,UID:c27d35de-b42e-11e9-8923-fa163ec474fb,ResourceVersion:3869,Generation:0,CreationTimestamp:2019-08-01 07:34:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug  1 07:34:14.248: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-fps45,SelfLink:/api/v1/namespaces/e2e-tests-watch-fps45/configmaps/e2e-watch-test-label-changed,UID:c27d35de-b42e-11e9-8923-fa163ec474fb,ResourceVersion:3870,Generation:0,CreationTimestamp:2019-08-01 07:34:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Aug  1 07:34:14.248: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-fps45,SelfLink:/api/v1/namespaces/e2e-tests-watch-fps45/configmaps/e2e-watch-test-label-changed,UID:c27d35de-b42e-11e9-8923-fa163ec474fb,ResourceVersion:3871,Generation:0,CreationTimestamp:2019-08-01 07:34:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Aug  1 07:34:24.345: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-fps45,SelfLink:/api/v1/namespaces/e2e-tests-watch-fps45/configmaps/e2e-watch-test-label-changed,UID:c27d35de-b42e-11e9-8923-fa163ec474fb,ResourceVersion:3891,Generation:0,CreationTimestamp:2019-08-01 07:34:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug  1 07:34:24.345: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-fps45,SelfLink:/api/v1/namespaces/e2e-tests-watch-fps45/configmaps/e2e-watch-test-label-changed,UID:c27d35de-b42e-11e9-8923-fa163ec474fb,ResourceVersion:3892,Generation:0,CreationTimestamp:2019-08-01 07:34:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Aug  1 07:34:24.346: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-fps45,SelfLink:/api/v1/namespaces/e2e-tests-watch-fps45/configmaps/e2e-watch-test-label-changed,UID:c27d35de-b42e-11e9-8923-fa163ec474fb,ResourceVersion:3893,Generation:0,CreationTimestamp:2019-08-01 07:34:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 07:34:24.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-fps45" for this suite.
Aug  1 07:34:30.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 07:34:30.545: INFO: namespace: e2e-tests-watch-fps45, resource: bindings, ignored listing per whitelist
Aug  1 07:34:30.563: INFO: namespace e2e-tests-watch-fps45 deletion completed in 6.159920664s

• [SLOW TEST:17.054 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 07:34:30.566: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-sxp6w
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-sxp6w
STEP: Deleting pre-stop pod
Aug  1 07:34:58.228: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 07:34:58.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-sxp6w" for this suite.
Aug  1 07:35:38.553: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 07:35:38.681: INFO: namespace: e2e-tests-prestop-sxp6w, resource: bindings, ignored listing per whitelist
Aug  1 07:35:38.694: INFO: namespace e2e-tests-prestop-sxp6w deletion completed in 40.424269608s

• [SLOW TEST:68.129 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 07:35:38.697: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Aug  1 07:35:42.820: INFO: Pod name wrapped-volume-race-f74c935b-b42e-11e9-aec8-12de527cd1b8: Found 0 pods out of 5
Aug  1 07:35:47.828: INFO: Pod name wrapped-volume-race-f74c935b-b42e-11e9-aec8-12de527cd1b8: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-f74c935b-b42e-11e9-aec8-12de527cd1b8 in namespace e2e-tests-emptydir-wrapper-d76gz, will wait for the garbage collector to delete the pods
Aug  1 07:37:32.046: INFO: Deleting ReplicationController wrapped-volume-race-f74c935b-b42e-11e9-aec8-12de527cd1b8 took: 7.763852ms
Aug  1 07:37:32.447: INFO: Terminating ReplicationController wrapped-volume-race-f74c935b-b42e-11e9-aec8-12de527cd1b8 pods took: 400.733351ms
STEP: Creating RC which spawns configmap-volume pods
Aug  1 07:38:21.433: INFO: Pod name wrapped-volume-race-56198b41-b42f-11e9-aec8-12de527cd1b8: Found 0 pods out of 5
Aug  1 07:38:26.442: INFO: Pod name wrapped-volume-race-56198b41-b42f-11e9-aec8-12de527cd1b8: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-56198b41-b42f-11e9-aec8-12de527cd1b8 in namespace e2e-tests-emptydir-wrapper-d76gz, will wait for the garbage collector to delete the pods
Aug  1 07:40:40.564: INFO: Deleting ReplicationController wrapped-volume-race-56198b41-b42f-11e9-aec8-12de527cd1b8 took: 16.674718ms
Aug  1 07:40:40.965: INFO: Terminating ReplicationController wrapped-volume-race-56198b41-b42f-11e9-aec8-12de527cd1b8 pods took: 401.085825ms
STEP: Creating RC which spawns configmap-volume pods
Aug  1 07:41:21.608: INFO: Pod name wrapped-volume-race-c1851b04-b42f-11e9-aec8-12de527cd1b8: Found 0 pods out of 5
Aug  1 07:41:26.618: INFO: Pod name wrapped-volume-race-c1851b04-b42f-11e9-aec8-12de527cd1b8: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-c1851b04-b42f-11e9-aec8-12de527cd1b8 in namespace e2e-tests-emptydir-wrapper-d76gz, will wait for the garbage collector to delete the pods
Aug  1 07:43:32.819: INFO: Deleting ReplicationController wrapped-volume-race-c1851b04-b42f-11e9-aec8-12de527cd1b8 took: 5.819607ms
Aug  1 07:43:33.224: INFO: Terminating ReplicationController wrapped-volume-race-c1851b04-b42f-11e9-aec8-12de527cd1b8 pods took: 404.84472ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 07:44:15.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-d76gz" for this suite.
Aug  1 07:44:27.937: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 07:44:28.018: INFO: namespace: e2e-tests-emptydir-wrapper-d76gz, resource: bindings, ignored listing per whitelist
Aug  1 07:44:28.186: INFO: namespace e2e-tests-emptydir-wrapper-d76gz deletion completed in 12.496949887s

• [SLOW TEST:529.490 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 07:44:28.189: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Aug  1 07:44:28.541: INFO: Waiting up to 5m0s for pod "client-containers-310337a7-b430-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-containers-xlzl8" to be "success or failure"
Aug  1 07:44:28.578: INFO: Pod "client-containers-310337a7-b430-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 36.550669ms
Aug  1 07:44:30.582: INFO: Pod "client-containers-310337a7-b430-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040033176s
Aug  1 07:44:32.586: INFO: Pod "client-containers-310337a7-b430-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.043879613s
Aug  1 07:44:34.589: INFO: Pod "client-containers-310337a7-b430-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.046816588s
Aug  1 07:44:36.592: INFO: Pod "client-containers-310337a7-b430-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 8.050534178s
Aug  1 07:44:38.596: INFO: Pod "client-containers-310337a7-b430-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 10.054364449s
Aug  1 07:44:40.600: INFO: Pod "client-containers-310337a7-b430-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 12.058675643s
Aug  1 07:44:42.605: INFO: Pod "client-containers-310337a7-b430-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 14.062817775s
Aug  1 07:44:44.608: INFO: Pod "client-containers-310337a7-b430-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 16.066351121s
Aug  1 07:44:46.748: INFO: Pod "client-containers-310337a7-b430-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 18.205757107s
STEP: Saw pod success
Aug  1 07:44:46.748: INFO: Pod "client-containers-310337a7-b430-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 07:44:46.751: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod client-containers-310337a7-b430-11e9-aec8-12de527cd1b8 container test-container: <nil>
STEP: delete the pod
Aug  1 07:44:46.971: INFO: Waiting for pod client-containers-310337a7-b430-11e9-aec8-12de527cd1b8 to disappear
Aug  1 07:44:47.000: INFO: Pod client-containers-310337a7-b430-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 07:44:47.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-xlzl8" for this suite.
Aug  1 07:44:53.137: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 07:44:53.286: INFO: namespace: e2e-tests-containers-xlzl8, resource: bindings, ignored listing per whitelist
Aug  1 07:44:53.328: INFO: namespace e2e-tests-containers-xlzl8 deletion completed in 6.322201767s

• [SLOW TEST:25.139 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 07:44:53.331: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug  1 07:44:53.787: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Aug  1 07:44:58.791: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug  1 07:44:58.792: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Aug  1 07:45:03.395: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-bckfc,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-bckfc/deployments/test-cleanup-deployment,UID:42d44c02-b430-11e9-8923-fa163ec474fb,ResourceVersion:5626,Generation:1,CreationTimestamp:2019-08-01 07:44:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 1,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-08-01 07:44:58 +0000 UTC 2019-08-01 07:44:58 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-08-01 07:45:02 +0000 UTC 2019-08-01 07:44:58 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-cleanup-deployment-7dbbfcf846" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Aug  1 07:45:03.602: INFO: New ReplicaSet "test-cleanup-deployment-7dbbfcf846" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-7dbbfcf846,GenerateName:,Namespace:e2e-tests-deployment-bckfc,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-bckfc/replicasets/test-cleanup-deployment-7dbbfcf846,UID:42dbb7e1-b430-11e9-8923-fa163ec474fb,ResourceVersion:5617,Generation:1,CreationTimestamp:2019-08-01 07:44:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 42d44c02-b430-11e9-8923-fa163ec474fb 0xc001252627 0xc001252628}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Aug  1 07:45:03.675: INFO: Pod "test-cleanup-deployment-7dbbfcf846-kj7lh" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-7dbbfcf846-kj7lh,GenerateName:test-cleanup-deployment-7dbbfcf846-,Namespace:e2e-tests-deployment-bckfc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bckfc/pods/test-cleanup-deployment-7dbbfcf846-kj7lh,UID:42efc9b2-b430-11e9-8923-fa163ec474fb,ResourceVersion:5616,Generation:0,CreationTimestamp:2019-08-01 07:44:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.48/32,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-7dbbfcf846 42dbb7e1-b430-11e9-8923-fa163ec474fb 0xc001253127 0xc001253128}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-frtfg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-frtfg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-frtfg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-6lh7zebx7k5q-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0012531f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001253210}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:44:59 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:01 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:01 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:44:58 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.23,PodIP:192.168.1.48,StartTime:2019-08-01 07:44:59 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-08-01 07:45:01 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://81fa19751db468734c9479779b166e15a2a520bce94eb7204a85f2bec64c0b60}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 07:45:03.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-bckfc" for this suite.
Aug  1 07:45:13.904: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 07:45:13.929: INFO: namespace: e2e-tests-deployment-bckfc, resource: bindings, ignored listing per whitelist
Aug  1 07:45:13.987: INFO: namespace e2e-tests-deployment-bckfc deletion completed in 10.161475438s

• [SLOW TEST:20.656 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 07:45:13.991: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug  1 07:45:14.334: INFO: Creating deployment "nginx-deployment"
Aug  1 07:45:14.451: INFO: Waiting for observed generation 1
Aug  1 07:45:16.871: INFO: Waiting for all required pods to come up
Aug  1 07:45:17.207: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Aug  1 07:45:45.715: INFO: Waiting for deployment "nginx-deployment" to complete
Aug  1 07:45:45.733: INFO: Updating deployment "nginx-deployment" with a non-existent image
Aug  1 07:45:45.740: INFO: Updating deployment nginx-deployment
Aug  1 07:45:45.741: INFO: Waiting for observed generation 2
Aug  1 07:45:48.540: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Aug  1 07:45:48.854: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Aug  1 07:45:49.179: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Aug  1 07:45:50.333: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Aug  1 07:45:50.333: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Aug  1 07:45:50.341: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Aug  1 07:45:50.349: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Aug  1 07:45:50.349: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Aug  1 07:45:50.376: INFO: Updating deployment nginx-deployment
Aug  1 07:45:50.376: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Aug  1 07:45:51.503: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Aug  1 07:45:54.324: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Aug  1 07:45:55.013: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-4wr9l,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-4wr9l/deployments/nginx-deployment,UID:4c0840a7-b430-11e9-8923-fa163ec474fb,ResourceVersion:5984,Generation:3,CreationTimestamp:2019-08-01 07:45:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-08-01 07:45:50 +0000 UTC 2019-08-01 07:45:50 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-08-01 07:45:52 +0000 UTC 2019-08-01 07:45:14 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-65bbdb5f8" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Aug  1 07:45:55.332: INFO: New ReplicaSet "nginx-deployment-65bbdb5f8" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8,GenerateName:,Namespace:e2e-tests-deployment-4wr9l,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-4wr9l/replicasets/nginx-deployment-65bbdb5f8,UID:5ec0198b-b430-11e9-8923-fa163ec474fb,ResourceVersion:5982,Generation:3,CreationTimestamp:2019-08-01 07:45:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 4c0840a7-b430-11e9-8923-fa163ec474fb 0xc0013532b7 0xc0013532b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug  1 07:45:55.332: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Aug  1 07:45:55.332: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965,GenerateName:,Namespace:e2e-tests-deployment-4wr9l,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-4wr9l/replicasets/nginx-deployment-555b55d965,UID:4c19af93-b430-11e9-8923-fa163ec474fb,ResourceVersion:5976,Generation:3,CreationTimestamp:2019-08-01 07:45:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 4c0840a7-b430-11e9-8923-fa163ec474fb 0xc001353167 0xc001353168}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Aug  1 07:45:55.642: INFO: Pod "nginx-deployment-555b55d965-42hxt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-42hxt,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-4wr9l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4wr9l/pods/nginx-deployment-555b55d965-42hxt,UID:61bb94e0-b430-11e9-8923-fa163ec474fb,ResourceVersion:5923,Generation:0,CreationTimestamp:2019-08-01 07:45:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 4c19af93-b430-11e9-8923-fa163ec474fb 0xc0024500a0 0xc0024500a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mrsfr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mrsfr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-mrsfr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-6lh7zebx7k5q-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002450100} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002450120}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:50 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  1 07:45:55.642: INFO: Pod "nginx-deployment-555b55d965-4vkqv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-4vkqv,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-4wr9l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4wr9l/pods/nginx-deployment-555b55d965-4vkqv,UID:61f24868-b430-11e9-8923-fa163ec474fb,ResourceVersion:5943,Generation:0,CreationTimestamp:2019-08-01 07:45:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 4c19af93-b430-11e9-8923-fa163ec474fb 0xc0024501f0 0xc0024501f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mrsfr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mrsfr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-mrsfr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-6lh7zebx7k5q-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002450250} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002450270}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:51 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  1 07:45:55.643: INFO: Pod "nginx-deployment-555b55d965-6hsnc" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-6hsnc,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-4wr9l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4wr9l/pods/nginx-deployment-555b55d965-6hsnc,UID:4c5ea4df-b430-11e9-8923-fa163ec474fb,ResourceVersion:5826,Generation:0,CreationTimestamp:2019-08-01 07:45:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.55/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 4c19af93-b430-11e9-8923-fa163ec474fb 0xc0024502f0 0xc0024502f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mrsfr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mrsfr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-mrsfr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-6lh7zebx7k5q-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002450350} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002450370}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:17 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:39 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:39 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:14 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.23,PodIP:192.168.1.55,StartTime:2019-08-01 07:45:17 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-01 07:45:38 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/nginx:1.14-alpine docker-pullable://docker.io/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://01679c9924dd0b1f490f3dedca905142db8553b9099667079481b2ca04eff476}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  1 07:45:55.643: INFO: Pod "nginx-deployment-555b55d965-82697" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-82697,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-4wr9l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4wr9l/pods/nginx-deployment-555b55d965-82697,UID:4c447b14-b430-11e9-8923-fa163ec474fb,ResourceVersion:5830,Generation:0,CreationTimestamp:2019-08-01 07:45:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.58/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 4c19af93-b430-11e9-8923-fa163ec474fb 0xc002450430 0xc002450431}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mrsfr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mrsfr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-mrsfr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-6lh7zebx7k5q-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002450490} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024504b0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:15 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:39 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:39 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:14 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.23,PodIP:192.168.1.58,StartTime:2019-08-01 07:45:15 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-01 07:45:39 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/nginx:1.14-alpine docker-pullable://docker.io/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://13f88ac6d918bb4aa1b92b3fc09ea233c3cbb9b2ccb5cf0df47b6841be5d3128}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  1 07:45:55.643: INFO: Pod "nginx-deployment-555b55d965-85d2z" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-85d2z,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-4wr9l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4wr9l/pods/nginx-deployment-555b55d965-85d2z,UID:61f2595f-b430-11e9-8923-fa163ec474fb,ResourceVersion:5952,Generation:0,CreationTimestamp:2019-08-01 07:45:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 4c19af93-b430-11e9-8923-fa163ec474fb 0xc002450560 0xc002450561}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mrsfr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mrsfr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-mrsfr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-6lh7zebx7k5q-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024505c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024505f0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:51 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  1 07:45:55.643: INFO: Pod "nginx-deployment-555b55d965-8htvm" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-8htvm,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-4wr9l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4wr9l/pods/nginx-deployment-555b55d965-8htvm,UID:4c44a341-b430-11e9-8923-fa163ec474fb,ResourceVersion:5809,Generation:0,CreationTimestamp:2019-08-01 07:45:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.50/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 4c19af93-b430-11e9-8923-fa163ec474fb 0xc0024506d0 0xc0024506d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mrsfr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mrsfr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-mrsfr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-6lh7zebx7k5q-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002450730} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002450750}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:15 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:35 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:35 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:14 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.23,PodIP:192.168.1.50,StartTime:2019-08-01 07:45:15 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-01 07:45:27 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/nginx:1.14-alpine docker-pullable://docker.io/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://df3fe23d5097aa0860f719e4d7a62873b85afb1cc8784b2c736d84a956165b7e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  1 07:45:55.643: INFO: Pod "nginx-deployment-555b55d965-8rkhh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-8rkhh,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-4wr9l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4wr9l/pods/nginx-deployment-555b55d965-8rkhh,UID:61c097c7-b430-11e9-8923-fa163ec474fb,ResourceVersion:5933,Generation:0,CreationTimestamp:2019-08-01 07:45:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 4c19af93-b430-11e9-8923-fa163ec474fb 0xc002450800 0xc002450801}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mrsfr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mrsfr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-mrsfr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-6lh7zebx7k5q-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024509f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002450a10}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:50 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  1 07:45:55.643: INFO: Pod "nginx-deployment-555b55d965-9lchq" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-9lchq,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-4wr9l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4wr9l/pods/nginx-deployment-555b55d965-9lchq,UID:4c44c1e6-b430-11e9-8923-fa163ec474fb,ResourceVersion:5834,Generation:0,CreationTimestamp:2019-08-01 07:45:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.52/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 4c19af93-b430-11e9-8923-fa163ec474fb 0xc002450dc0 0xc002450dc1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mrsfr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mrsfr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-mrsfr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-6lh7zebx7k5q-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002450e90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002450f30}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:15 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:39 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:39 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:14 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.23,PodIP:192.168.1.52,StartTime:2019-08-01 07:45:15 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-01 07:45:33 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/nginx:1.14-alpine docker-pullable://docker.io/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://1e625c2ed3bb1c14209ba23cfcc5d30e63e307812587985e3667a128d9abef02}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  1 07:45:55.643: INFO: Pod "nginx-deployment-555b55d965-bqzpr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-bqzpr,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-4wr9l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4wr9l/pods/nginx-deployment-555b55d965-bqzpr,UID:623202a2-b430-11e9-8923-fa163ec474fb,ResourceVersion:5966,Generation:0,CreationTimestamp:2019-08-01 07:45:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 4c19af93-b430-11e9-8923-fa163ec474fb 0xc002451000 0xc002451001}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mrsfr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mrsfr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-mrsfr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-6lh7zebx7k5q-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002451060} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002451080}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:51 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  1 07:45:55.643: INFO: Pod "nginx-deployment-555b55d965-jn9nm" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-jn9nm,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-4wr9l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4wr9l/pods/nginx-deployment-555b55d965-jn9nm,UID:4c39eced-b430-11e9-8923-fa163ec474fb,ResourceVersion:5798,Generation:0,CreationTimestamp:2019-08-01 07:45:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.49/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 4c19af93-b430-11e9-8923-fa163ec474fb 0xc0024510f0 0xc0024510f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mrsfr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mrsfr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-mrsfr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-6lh7zebx7k5q-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002451170} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002451190}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:14 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:35 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:35 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:14 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.23,PodIP:192.168.1.49,StartTime:2019-08-01 07:45:14 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-01 07:45:24 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/nginx:1.14-alpine docker-pullable://docker.io/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://32e85e5ec9aaa436f3f1d1fee6072f2198efa49e1792d8605c7de41f84cb9e03}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  1 07:45:55.644: INFO: Pod "nginx-deployment-555b55d965-jpggv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-jpggv,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-4wr9l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4wr9l/pods/nginx-deployment-555b55d965-jpggv,UID:61f23cfb-b430-11e9-8923-fa163ec474fb,ResourceVersion:5956,Generation:0,CreationTimestamp:2019-08-01 07:45:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 4c19af93-b430-11e9-8923-fa163ec474fb 0xc0024512a0 0xc0024512a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mrsfr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mrsfr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-mrsfr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-6lh7zebx7k5q-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002451340} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002451390}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:51 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  1 07:45:55.644: INFO: Pod "nginx-deployment-555b55d965-mflsx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-mflsx,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-4wr9l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4wr9l/pods/nginx-deployment-555b55d965-mflsx,UID:6231d997-b430-11e9-8923-fa163ec474fb,ResourceVersion:5967,Generation:0,CreationTimestamp:2019-08-01 07:45:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 4c19af93-b430-11e9-8923-fa163ec474fb 0xc002451470 0xc002451471}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mrsfr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mrsfr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-mrsfr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-6lh7zebx7k5q-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002451560} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024515b0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:51 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  1 07:45:55.644: INFO: Pod "nginx-deployment-555b55d965-nf4nn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-nf4nn,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-4wr9l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4wr9l/pods/nginx-deployment-555b55d965-nf4nn,UID:6231e43b-b430-11e9-8923-fa163ec474fb,ResourceVersion:5968,Generation:0,CreationTimestamp:2019-08-01 07:45:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 4c19af93-b430-11e9-8923-fa163ec474fb 0xc002451650 0xc002451651}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mrsfr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mrsfr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-mrsfr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-6lh7zebx7k5q-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024516f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024517c0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:51 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  1 07:45:55.644: INFO: Pod "nginx-deployment-555b55d965-nrwcv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-nrwcv,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-4wr9l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4wr9l/pods/nginx-deployment-555b55d965-nrwcv,UID:6231a227-b430-11e9-8923-fa163ec474fb,ResourceVersion:5962,Generation:0,CreationTimestamp:2019-08-01 07:45:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 4c19af93-b430-11e9-8923-fa163ec474fb 0xc002451830 0xc002451831}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mrsfr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mrsfr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-mrsfr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-6lh7zebx7k5q-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024518d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024518f0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:51 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  1 07:45:55.644: INFO: Pod "nginx-deployment-555b55d965-p75xx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-p75xx,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-4wr9l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4wr9l/pods/nginx-deployment-555b55d965-p75xx,UID:62322f48-b430-11e9-8923-fa163ec474fb,ResourceVersion:5965,Generation:0,CreationTimestamp:2019-08-01 07:45:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 4c19af93-b430-11e9-8923-fa163ec474fb 0xc002451a10 0xc002451a11}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mrsfr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mrsfr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-mrsfr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-6lh7zebx7k5q-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002451ad0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002451af0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:51 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  1 07:45:55.644: INFO: Pod "nginx-deployment-555b55d965-r8hc9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-r8hc9,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-4wr9l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4wr9l/pods/nginx-deployment-555b55d965-r8hc9,UID:4c5ed357-b430-11e9-8923-fa163ec474fb,ResourceVersion:5838,Generation:0,CreationTimestamp:2019-08-01 07:45:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.57/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 4c19af93-b430-11e9-8923-fa163ec474fb 0xc002451c20 0xc002451c21}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mrsfr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mrsfr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-mrsfr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-6lh7zebx7k5q-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002451cb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002451d20}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:18 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:39 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:39 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:14 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.23,PodIP:192.168.1.57,StartTime:2019-08-01 07:45:18 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-01 07:45:39 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/nginx:1.14-alpine docker-pullable://docker.io/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://3a8210f43d6c800f4ac73ea94cf0f63ce71672fd44ebf24b5cd026fc79a65f6c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  1 07:45:55.644: INFO: Pod "nginx-deployment-555b55d965-s5mml" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-s5mml,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-4wr9l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4wr9l/pods/nginx-deployment-555b55d965-s5mml,UID:4c447e4d-b430-11e9-8923-fa163ec474fb,ResourceVersion:5847,Generation:0,CreationTimestamp:2019-08-01 07:45:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.54/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 4c19af93-b430-11e9-8923-fa163ec474fb 0xc002451ea0 0xc002451ea1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mrsfr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mrsfr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-mrsfr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-6lh7zebx7k5q-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002451f40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002451f80}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:15 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:39 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:39 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:14 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.23,PodIP:192.168.1.54,StartTime:2019-08-01 07:45:15 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-01 07:45:36 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/nginx:1.14-alpine docker-pullable://docker.io/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://b483ea1691bb33479f24158f18cbdc507265deb21769be09ddbebdec56189b64}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  1 07:45:55.644: INFO: Pod "nginx-deployment-555b55d965-t9djv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-t9djv,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-4wr9l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4wr9l/pods/nginx-deployment-555b55d965-t9djv,UID:61f22fc2-b430-11e9-8923-fa163ec474fb,ResourceVersion:5955,Generation:0,CreationTimestamp:2019-08-01 07:45:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 4c19af93-b430-11e9-8923-fa163ec474fb 0xc000ac4110 0xc000ac4111}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mrsfr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mrsfr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-mrsfr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-6lh7zebx7k5q-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000ac41e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000ac4200}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:51 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  1 07:45:55.645: INFO: Pod "nginx-deployment-555b55d965-vjx9p" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-vjx9p,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-4wr9l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4wr9l/pods/nginx-deployment-555b55d965-vjx9p,UID:61c0e8d7-b430-11e9-8923-fa163ec474fb,ResourceVersion:5931,Generation:0,CreationTimestamp:2019-08-01 07:45:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 4c19af93-b430-11e9-8923-fa163ec474fb 0xc000ac42c0 0xc000ac42c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mrsfr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mrsfr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-mrsfr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-6lh7zebx7k5q-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000ac4360} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000ac43a0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:50 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  1 07:45:55.645: INFO: Pod "nginx-deployment-555b55d965-xflh2" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-xflh2,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-4wr9l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4wr9l/pods/nginx-deployment-555b55d965-xflh2,UID:4c3afb32-b430-11e9-8923-fa163ec474fb,ResourceVersion:5802,Generation:0,CreationTimestamp:2019-08-01 07:45:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.51/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 4c19af93-b430-11e9-8923-fa163ec474fb 0xc000ac4470 0xc000ac4471}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mrsfr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mrsfr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-mrsfr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-6lh7zebx7k5q-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000ac44d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000ac4500}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:14 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:35 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:35 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:14 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.23,PodIP:192.168.1.51,StartTime:2019-08-01 07:45:14 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-01 07:45:33 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/nginx:1.14-alpine docker-pullable://docker.io/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://c5be92a9659cab3d5130cc870f7e8f3b1576b313abcfc82b21de38cafbd1f120}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  1 07:45:55.645: INFO: Pod "nginx-deployment-65bbdb5f8-5jhv4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-5jhv4,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-4wr9l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4wr9l/pods/nginx-deployment-65bbdb5f8-5jhv4,UID:5f13d5e1-b430-11e9-8923-fa163ec474fb,ResourceVersion:5887,Generation:0,CreationTimestamp:2019-08-01 07:45:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 5ec0198b-b430-11e9-8923-fa163ec474fb 0xc000ac46a0 0xc000ac46a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mrsfr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mrsfr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-mrsfr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-6lh7zebx7k5q-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000ac4770} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000ac4790}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:45 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.23,PodIP:,StartTime:2019-08-01 07:45:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  1 07:45:55.645: INFO: Pod "nginx-deployment-65bbdb5f8-5klbm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-5klbm,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-4wr9l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4wr9l/pods/nginx-deployment-65bbdb5f8-5klbm,UID:61f10c36-b430-11e9-8923-fa163ec474fb,ResourceVersion:5942,Generation:0,CreationTimestamp:2019-08-01 07:45:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 5ec0198b-b430-11e9-8923-fa163ec474fb 0xc000ac4840 0xc000ac4841}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mrsfr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mrsfr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-mrsfr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-6lh7zebx7k5q-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000ac48b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000ac48d0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:51 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  1 07:45:55.645: INFO: Pod "nginx-deployment-65bbdb5f8-8vb99" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-8vb99,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-4wr9l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4wr9l/pods/nginx-deployment-65bbdb5f8-8vb99,UID:5ee83444-b430-11e9-8923-fa163ec474fb,ResourceVersion:5881,Generation:0,CreationTimestamp:2019-08-01 07:45:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 5ec0198b-b430-11e9-8923-fa163ec474fb 0xc000ac4930 0xc000ac4931}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mrsfr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mrsfr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-mrsfr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-6lh7zebx7k5q-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000ac49a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000ac49c0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:45 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.23,PodIP:,StartTime:2019-08-01 07:45:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  1 07:45:55.647: INFO: Pod "nginx-deployment-65bbdb5f8-dj7cj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-dj7cj,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-4wr9l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4wr9l/pods/nginx-deployment-65bbdb5f8-dj7cj,UID:6231c158-b430-11e9-8923-fa163ec474fb,ResourceVersion:5964,Generation:0,CreationTimestamp:2019-08-01 07:45:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 5ec0198b-b430-11e9-8923-fa163ec474fb 0xc000ac4a70 0xc000ac4a71}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mrsfr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mrsfr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-mrsfr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-6lh7zebx7k5q-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000ac4ae0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000ac4b00}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:51 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  1 07:45:55.647: INFO: Pod "nginx-deployment-65bbdb5f8-gsd4p" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-gsd4p,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-4wr9l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4wr9l/pods/nginx-deployment-65bbdb5f8-gsd4p,UID:6231cd7c-b430-11e9-8923-fa163ec474fb,ResourceVersion:5960,Generation:0,CreationTimestamp:2019-08-01 07:45:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 5ec0198b-b430-11e9-8923-fa163ec474fb 0xc000ac4b60 0xc000ac4b61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mrsfr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mrsfr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-mrsfr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-6lh7zebx7k5q-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000ac4bd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000ac4bf0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:51 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  1 07:45:55.647: INFO: Pod "nginx-deployment-65bbdb5f8-hsb4k" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-hsb4k,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-4wr9l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4wr9l/pods/nginx-deployment-65bbdb5f8-hsb4k,UID:6231ae2d-b430-11e9-8923-fa163ec474fb,ResourceVersion:5963,Generation:0,CreationTimestamp:2019-08-01 07:45:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 5ec0198b-b430-11e9-8923-fa163ec474fb 0xc000ac4c50 0xc000ac4c51}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mrsfr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mrsfr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-mrsfr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-6lh7zebx7k5q-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000ac4cc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000ac4ce0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:51 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  1 07:45:55.647: INFO: Pod "nginx-deployment-65bbdb5f8-nknlr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-nknlr,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-4wr9l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4wr9l/pods/nginx-deployment-65bbdb5f8-nknlr,UID:61f26485-b430-11e9-8923-fa163ec474fb,ResourceVersion:5953,Generation:0,CreationTimestamp:2019-08-01 07:45:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 5ec0198b-b430-11e9-8923-fa163ec474fb 0xc000ac4d40 0xc000ac4d41}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mrsfr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mrsfr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-mrsfr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-6lh7zebx7k5q-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000ac4db0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000ac4dd0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:51 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  1 07:45:55.647: INFO: Pod "nginx-deployment-65bbdb5f8-prxpr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-prxpr,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-4wr9l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4wr9l/pods/nginx-deployment-65bbdb5f8-prxpr,UID:61c0d0ad-b430-11e9-8923-fa163ec474fb,ResourceVersion:5938,Generation:0,CreationTimestamp:2019-08-01 07:45:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 5ec0198b-b430-11e9-8923-fa163ec474fb 0xc000ac4e30 0xc000ac4e31}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mrsfr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mrsfr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-mrsfr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-6lh7zebx7k5q-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000ac4f50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000ac4f70}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:50 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  1 07:45:55.648: INFO: Pod "nginx-deployment-65bbdb5f8-qg72q" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-qg72q,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-4wr9l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4wr9l/pods/nginx-deployment-65bbdb5f8-qg72q,UID:5faf7585-b430-11e9-8923-fa163ec474fb,ResourceVersion:5915,Generation:0,CreationTimestamp:2019-08-01 07:45:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 5ec0198b-b430-11e9-8923-fa163ec474fb 0xc000ac5010 0xc000ac5011}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mrsfr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mrsfr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-mrsfr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-6lh7zebx7k5q-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000ac50b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000ac50d0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:46 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.23,PodIP:,StartTime:2019-08-01 07:45:49 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  1 07:45:55.648: INFO: Pod "nginx-deployment-65bbdb5f8-s4knf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-s4knf,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-4wr9l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4wr9l/pods/nginx-deployment-65bbdb5f8-s4knf,UID:623c6a6a-b430-11e9-8923-fa163ec474fb,ResourceVersion:5969,Generation:0,CreationTimestamp:2019-08-01 07:45:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 5ec0198b-b430-11e9-8923-fa163ec474fb 0xc000ac5210 0xc000ac5211}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mrsfr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mrsfr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-mrsfr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-6lh7zebx7k5q-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000ac52c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000ac52e0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:51 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  1 07:45:55.648: INFO: Pod "nginx-deployment-65bbdb5f8-tn8gs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-tn8gs,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-4wr9l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4wr9l/pods/nginx-deployment-65bbdb5f8-tn8gs,UID:62318979-b430-11e9-8923-fa163ec474fb,ResourceVersion:5961,Generation:0,CreationTimestamp:2019-08-01 07:45:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 5ec0198b-b430-11e9-8923-fa163ec474fb 0xc000ac5340 0xc000ac5341}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mrsfr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mrsfr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-mrsfr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-6lh7zebx7k5q-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000ac5420} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000ac5440}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:51 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  1 07:45:55.648: INFO: Pod "nginx-deployment-65bbdb5f8-wsnxc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-wsnxc,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-4wr9l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4wr9l/pods/nginx-deployment-65bbdb5f8-wsnxc,UID:5f141428-b430-11e9-8923-fa163ec474fb,ResourceVersion:5906,Generation:0,CreationTimestamp:2019-08-01 07:45:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 5ec0198b-b430-11e9-8923-fa163ec474fb 0xc000ac54e0 0xc000ac54e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mrsfr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mrsfr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-mrsfr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-6lh7zebx7k5q-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000ac55c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000ac55e0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:45 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.23,PodIP:,StartTime:2019-08-01 07:45:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  1 07:45:55.648: INFO: Pod "nginx-deployment-65bbdb5f8-z7nwl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-z7nwl,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-4wr9l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4wr9l/pods/nginx-deployment-65bbdb5f8-z7nwl,UID:5fbae4c0-b430-11e9-8923-fa163ec474fb,ResourceVersion:5990,Generation:0,CreationTimestamp:2019-08-01 07:45:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 5ec0198b-b430-11e9-8923-fa163ec474fb 0xc000ac5700 0xc000ac5701}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mrsfr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mrsfr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-mrsfr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-6lh7zebx7k5q-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000ac5770} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000ac5790}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 07:45:47 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.23,PodIP:,StartTime:2019-08-01 07:45:53 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 07:45:55.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-4wr9l" for this suite.
Aug  1 07:46:54.505: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 07:46:54.596: INFO: namespace: e2e-tests-deployment-4wr9l, resource: bindings, ignored listing per whitelist
Aug  1 07:46:54.619: INFO: namespace e2e-tests-deployment-4wr9l deletion completed in 58.514309873s

• [SLOW TEST:100.629 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 07:46:54.621: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Aug  1 07:46:55.672: INFO: Waiting up to 5m0s for pod "pod-888a0836-b430-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-emptydir-fk5rb" to be "success or failure"
Aug  1 07:46:56.065: INFO: Pod "pod-888a0836-b430-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 393.112679ms
Aug  1 07:46:58.353: INFO: Pod "pod-888a0836-b430-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.680564639s
Aug  1 07:47:00.549: INFO: Pod "pod-888a0836-b430-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.876795852s
Aug  1 07:47:03.005: INFO: Pod "pod-888a0836-b430-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 7.333323115s
Aug  1 07:47:05.010: INFO: Pod "pod-888a0836-b430-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 9.337847113s
Aug  1 07:47:07.015: INFO: Pod "pod-888a0836-b430-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 11.343122711s
Aug  1 07:47:09.020: INFO: Pod "pod-888a0836-b430-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 13.348144873s
Aug  1 07:47:11.297: INFO: Pod "pod-888a0836-b430-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 15.624783074s
Aug  1 07:47:13.301: INFO: Pod "pod-888a0836-b430-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 17.628617375s
Aug  1 07:47:15.303: INFO: Pod "pod-888a0836-b430-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 19.631421649s
Aug  1 07:47:17.307: INFO: Pod "pod-888a0836-b430-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 21.634640154s
Aug  1 07:47:19.309: INFO: Pod "pod-888a0836-b430-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 23.63692717s
Aug  1 07:47:21.313: INFO: Pod "pod-888a0836-b430-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 25.640616153s
STEP: Saw pod success
Aug  1 07:47:21.313: INFO: Pod "pod-888a0836-b430-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 07:47:21.316: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod pod-888a0836-b430-11e9-aec8-12de527cd1b8 container test-container: <nil>
STEP: delete the pod
Aug  1 07:47:21.472: INFO: Waiting for pod pod-888a0836-b430-11e9-aec8-12de527cd1b8 to disappear
Aug  1 07:47:21.503: INFO: Pod pod-888a0836-b430-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 07:47:21.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-fk5rb" for this suite.
Aug  1 07:47:27.572: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 07:47:27.630: INFO: namespace: e2e-tests-emptydir-fk5rb, resource: bindings, ignored listing per whitelist
Aug  1 07:47:27.798: INFO: namespace e2e-tests-emptydir-fk5rb deletion completed in 6.27187528s

• [SLOW TEST:33.178 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 07:47:27.803: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Aug  1 07:47:28.174: INFO: Waiting up to 5m0s for pod "pod-9c16fb15-b430-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-emptydir-fnv4t" to be "success or failure"
Aug  1 07:47:28.205: INFO: Pod "pod-9c16fb15-b430-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 29.933376ms
Aug  1 07:47:30.327: INFO: Pod "pod-9c16fb15-b430-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.152213081s
Aug  1 07:47:32.391: INFO: Pod "pod-9c16fb15-b430-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.21670749s
STEP: Saw pod success
Aug  1 07:47:32.391: INFO: Pod "pod-9c16fb15-b430-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 07:47:32.394: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod pod-9c16fb15-b430-11e9-aec8-12de527cd1b8 container test-container: <nil>
STEP: delete the pod
Aug  1 07:47:32.789: INFO: Waiting for pod pod-9c16fb15-b430-11e9-aec8-12de527cd1b8 to disappear
Aug  1 07:47:32.880: INFO: Pod pod-9c16fb15-b430-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 07:47:32.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-fnv4t" for this suite.
Aug  1 07:47:39.300: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 07:47:39.653: INFO: namespace: e2e-tests-emptydir-fnv4t, resource: bindings, ignored listing per whitelist
Aug  1 07:47:39.699: INFO: namespace e2e-tests-emptydir-fnv4t deletion completed in 6.491044652s

• [SLOW TEST:11.898 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 07:47:39.704: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug  1 07:47:40.199: INFO: (0) /api/v1/nodes/k8s-1-6lh7zebx7k5q-node-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 46.550716ms)
Aug  1 07:47:40.202: INFO: (1) /api/v1/nodes/k8s-1-6lh7zebx7k5q-node-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 2.91579ms)
Aug  1 07:47:40.205: INFO: (2) /api/v1/nodes/k8s-1-6lh7zebx7k5q-node-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 2.362912ms)
Aug  1 07:47:40.207: INFO: (3) /api/v1/nodes/k8s-1-6lh7zebx7k5q-node-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 2.287935ms)
Aug  1 07:47:40.210: INFO: (4) /api/v1/nodes/k8s-1-6lh7zebx7k5q-node-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 2.820195ms)
Aug  1 07:47:40.213: INFO: (5) /api/v1/nodes/k8s-1-6lh7zebx7k5q-node-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 2.543715ms)
Aug  1 07:47:40.215: INFO: (6) /api/v1/nodes/k8s-1-6lh7zebx7k5q-node-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 2.492215ms)
Aug  1 07:47:40.218: INFO: (7) /api/v1/nodes/k8s-1-6lh7zebx7k5q-node-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 2.559377ms)
Aug  1 07:47:40.220: INFO: (8) /api/v1/nodes/k8s-1-6lh7zebx7k5q-node-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 2.029933ms)
Aug  1 07:47:40.222: INFO: (9) /api/v1/nodes/k8s-1-6lh7zebx7k5q-node-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 1.97129ms)
Aug  1 07:47:40.224: INFO: (10) /api/v1/nodes/k8s-1-6lh7zebx7k5q-node-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 2.278923ms)
Aug  1 07:47:40.227: INFO: (11) /api/v1/nodes/k8s-1-6lh7zebx7k5q-node-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 2.240294ms)
Aug  1 07:47:40.229: INFO: (12) /api/v1/nodes/k8s-1-6lh7zebx7k5q-node-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 1.997593ms)
Aug  1 07:47:40.231: INFO: (13) /api/v1/nodes/k8s-1-6lh7zebx7k5q-node-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 1.869114ms)
Aug  1 07:47:40.233: INFO: (14) /api/v1/nodes/k8s-1-6lh7zebx7k5q-node-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 1.933467ms)
Aug  1 07:47:40.235: INFO: (15) /api/v1/nodes/k8s-1-6lh7zebx7k5q-node-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 2.238601ms)
Aug  1 07:47:40.237: INFO: (16) /api/v1/nodes/k8s-1-6lh7zebx7k5q-node-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 2.157236ms)
Aug  1 07:47:40.239: INFO: (17) /api/v1/nodes/k8s-1-6lh7zebx7k5q-node-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 1.915037ms)
Aug  1 07:47:40.241: INFO: (18) /api/v1/nodes/k8s-1-6lh7zebx7k5q-node-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 2.117776ms)
Aug  1 07:47:40.243: INFO: (19) /api/v1/nodes/k8s-1-6lh7zebx7k5q-node-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 1.976297ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 07:47:40.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-4g6zr" for this suite.
Aug  1 07:47:46.410: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 07:47:46.487: INFO: namespace: e2e-tests-proxy-4g6zr, resource: bindings, ignored listing per whitelist
Aug  1 07:47:46.525: INFO: namespace e2e-tests-proxy-4g6zr deletion completed in 6.280302417s

• [SLOW TEST:6.822 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 07:47:46.532: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-2ddrt in namespace e2e-tests-proxy-l7r88
I0801 07:47:47.244679      12 runners.go:184] Created replication controller with name: proxy-service-2ddrt, namespace: e2e-tests-proxy-l7r88, replica count: 1
I0801 07:47:48.295374      12 runners.go:184] proxy-service-2ddrt Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0801 07:47:49.462453      12 runners.go:184] proxy-service-2ddrt Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0801 07:47:50.462762      12 runners.go:184] proxy-service-2ddrt Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0801 07:47:51.463460      12 runners.go:184] proxy-service-2ddrt Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0801 07:47:52.463872      12 runners.go:184] proxy-service-2ddrt Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0801 07:47:53.464351      12 runners.go:184] proxy-service-2ddrt Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0801 07:47:54.464781      12 runners.go:184] proxy-service-2ddrt Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0801 07:47:55.465131      12 runners.go:184] proxy-service-2ddrt Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0801 07:47:56.465399      12 runners.go:184] proxy-service-2ddrt Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0801 07:47:57.465736      12 runners.go:184] proxy-service-2ddrt Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0801 07:47:58.466208      12 runners.go:184] proxy-service-2ddrt Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0801 07:47:59.466508      12 runners.go:184] proxy-service-2ddrt Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0801 07:48:00.466738      12 runners.go:184] proxy-service-2ddrt Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0801 07:48:01.467084      12 runners.go:184] proxy-service-2ddrt Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0801 07:48:02.467573      12 runners.go:184] proxy-service-2ddrt Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0801 07:48:03.467943      12 runners.go:184] proxy-service-2ddrt Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0801 07:48:04.468196      12 runners.go:184] proxy-service-2ddrt Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0801 07:48:05.468443      12 runners.go:184] proxy-service-2ddrt Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0801 07:48:06.468794      12 runners.go:184] proxy-service-2ddrt Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0801 07:48:07.469169      12 runners.go:184] proxy-service-2ddrt Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0801 07:48:08.469543      12 runners.go:184] proxy-service-2ddrt Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0801 07:48:09.469944      12 runners.go:184] proxy-service-2ddrt Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0801 07:48:10.470353      12 runners.go:184] proxy-service-2ddrt Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0801 07:48:11.470928      12 runners.go:184] proxy-service-2ddrt Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0801 07:48:12.471403      12 runners.go:184] proxy-service-2ddrt Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0801 07:48:13.472158      12 runners.go:184] proxy-service-2ddrt Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0801 07:48:14.472539      12 runners.go:184] proxy-service-2ddrt Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0801 07:48:15.473002      12 runners.go:184] proxy-service-2ddrt Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0801 07:48:16.473434      12 runners.go:184] proxy-service-2ddrt Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug  1 07:48:16.485: INFO: setup took 29.716882693s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Aug  1 07:48:16.526: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:1080/proxy/... (200; 21.359905ms)
Aug  1 07:48:16.529: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:160/proxy/: foo (200; 24.428887ms)
Aug  1 07:48:16.535: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/proxy-service-2ddrt:portname2/proxy/: bar (200; 30.82693ms)
Aug  1 07:48:16.535: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8/proxy/rewriteme"... (200; 30.975787ms)
Aug  1 07:48:16.545: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/proxy-service-2ddrt:portname1/proxy/: foo (200; 40.914688ms)
Aug  1 07:48:16.545: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/http:proxy-service-2ddrt:portname1/proxy/: foo (200; 40.813552ms)
Aug  1 07:48:16.549: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:1080/proxy/rewri... (200; 43.95523ms)
Aug  1 07:48:16.553: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:443/proxy/... (200; 49.226837ms)
Aug  1 07:48:16.553: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/http:proxy-service-2ddrt:portname2/proxy/: bar (200; 54.688551ms)
Aug  1 07:48:16.553: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:462/proxy/: tls qux (200; 49.415968ms)
Aug  1 07:48:16.553: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:162/proxy/: bar (200; 48.765727ms)
Aug  1 07:48:16.554: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:162/proxy/: bar (200; 49.062948ms)
Aug  1 07:48:16.554: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:160/proxy/: foo (200; 48.814738ms)
Aug  1 07:48:16.555: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/https:proxy-service-2ddrt:tlsportname2/proxy/: tls qux (200; 51.516725ms)
Aug  1 07:48:16.555: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/https:proxy-service-2ddrt:tlsportname1/proxy/: tls baz (200; 50.274365ms)
Aug  1 07:48:16.555: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:460/proxy/: tls baz (200; 51.727407ms)
Aug  1 07:48:16.559: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:160/proxy/: foo (200; 3.812984ms)
Aug  1 07:48:16.561: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/proxy-service-2ddrt:portname1/proxy/: foo (200; 5.028342ms)
Aug  1 07:48:16.564: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/http:proxy-service-2ddrt:portname2/proxy/: bar (200; 8.2351ms)
Aug  1 07:48:16.565: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:443/proxy/... (200; 8.797599ms)
Aug  1 07:48:16.565: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/https:proxy-service-2ddrt:tlsportname2/proxy/: tls qux (200; 8.909114ms)
Aug  1 07:48:16.567: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:462/proxy/: tls qux (200; 10.608531ms)
Aug  1 07:48:16.567: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:460/proxy/: tls baz (200; 10.78875ms)
Aug  1 07:48:16.568: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8/proxy/rewriteme"... (200; 11.954951ms)
Aug  1 07:48:16.569: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:1080/proxy/rewri... (200; 12.204262ms)
Aug  1 07:48:16.569: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:160/proxy/: foo (200; 12.367192ms)
Aug  1 07:48:16.570: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/proxy-service-2ddrt:portname2/proxy/: bar (200; 13.402896ms)
Aug  1 07:48:16.570: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:162/proxy/: bar (200; 13.697088ms)
Aug  1 07:48:16.571: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:162/proxy/: bar (200; 14.165707ms)
Aug  1 07:48:16.572: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/https:proxy-service-2ddrt:tlsportname1/proxy/: tls baz (200; 14.884323ms)
Aug  1 07:48:16.572: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:1080/proxy/... (200; 15.257411ms)
Aug  1 07:48:16.573: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/http:proxy-service-2ddrt:portname1/proxy/: foo (200; 16.900913ms)
Aug  1 07:48:16.577: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:160/proxy/: foo (200; 2.78132ms)
Aug  1 07:48:16.580: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/https:proxy-service-2ddrt:tlsportname1/proxy/: tls baz (200; 6.573917ms)
Aug  1 07:48:16.581: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:462/proxy/: tls qux (200; 6.573031ms)
Aug  1 07:48:16.581: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:1080/proxy/... (200; 7.161271ms)
Aug  1 07:48:16.582: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:162/proxy/: bar (200; 8.155596ms)
Aug  1 07:48:16.582: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:460/proxy/: tls baz (200; 7.891568ms)
Aug  1 07:48:16.582: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:443/proxy/... (200; 7.3684ms)
Aug  1 07:48:16.584: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:160/proxy/: foo (200; 8.99953ms)
Aug  1 07:48:16.584: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/https:proxy-service-2ddrt:tlsportname2/proxy/: tls qux (200; 9.917794ms)
Aug  1 07:48:16.585: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/http:proxy-service-2ddrt:portname2/proxy/: bar (200; 10.275859ms)
Aug  1 07:48:16.585: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/proxy-service-2ddrt:portname2/proxy/: bar (200; 9.897271ms)
Aug  1 07:48:16.585: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8/proxy/rewriteme"... (200; 9.959355ms)
Aug  1 07:48:16.585: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:162/proxy/: bar (200; 9.838801ms)
Aug  1 07:48:16.587: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/http:proxy-service-2ddrt:portname1/proxy/: foo (200; 10.439896ms)
Aug  1 07:48:16.587: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:1080/proxy/rewri... (200; 12.152335ms)
Aug  1 07:48:16.587: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/proxy-service-2ddrt:portname1/proxy/: foo (200; 13.287881ms)
Aug  1 07:48:16.592: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:162/proxy/: bar (200; 4.39987ms)
Aug  1 07:48:16.593: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:160/proxy/: foo (200; 4.718672ms)
Aug  1 07:48:16.595: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/https:proxy-service-2ddrt:tlsportname1/proxy/: tls baz (200; 6.618054ms)
Aug  1 07:48:16.597: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:1080/proxy/... (200; 8.496745ms)
Aug  1 07:48:16.597: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:462/proxy/: tls qux (200; 7.81192ms)
Aug  1 07:48:16.597: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/https:proxy-service-2ddrt:tlsportname2/proxy/: tls qux (200; 8.498141ms)
Aug  1 07:48:16.597: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/proxy-service-2ddrt:portname1/proxy/: foo (200; 9.172181ms)
Aug  1 07:48:16.598: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8/proxy/rewriteme"... (200; 8.37999ms)
Aug  1 07:48:16.598: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:443/proxy/... (200; 9.171453ms)
Aug  1 07:48:16.598: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/http:proxy-service-2ddrt:portname2/proxy/: bar (200; 9.617755ms)
Aug  1 07:48:16.598: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:1080/proxy/rewri... (200; 8.980871ms)
Aug  1 07:48:16.599: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:460/proxy/: tls baz (200; 9.58313ms)
Aug  1 07:48:16.599: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:160/proxy/: foo (200; 9.956149ms)
Aug  1 07:48:16.600: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/http:proxy-service-2ddrt:portname1/proxy/: foo (200; 10.784162ms)
Aug  1 07:48:16.600: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/proxy-service-2ddrt:portname2/proxy/: bar (200; 11.025865ms)
Aug  1 07:48:16.600: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:162/proxy/: bar (200; 10.875925ms)
Aug  1 07:48:16.610: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:1080/proxy/rewri... (200; 9.371211ms)
Aug  1 07:48:16.611: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:162/proxy/: bar (200; 10.087854ms)
Aug  1 07:48:16.611: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8/proxy/rewriteme"... (200; 10.588315ms)
Aug  1 07:48:16.611: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:160/proxy/: foo (200; 10.247475ms)
Aug  1 07:48:16.614: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:160/proxy/: foo (200; 12.787872ms)
Aug  1 07:48:16.615: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:462/proxy/: tls qux (200; 13.339678ms)
Aug  1 07:48:16.615: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:1080/proxy/... (200; 13.72811ms)
Aug  1 07:48:16.615: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:460/proxy/: tls baz (200; 13.625196ms)
Aug  1 07:48:16.615: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:162/proxy/: bar (200; 14.147452ms)
Aug  1 07:48:16.617: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/proxy-service-2ddrt:portname1/proxy/: foo (200; 14.689404ms)
Aug  1 07:48:16.620: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/http:proxy-service-2ddrt:portname1/proxy/: foo (200; 17.837753ms)
Aug  1 07:48:16.621: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/https:proxy-service-2ddrt:tlsportname1/proxy/: tls baz (200; 19.358433ms)
Aug  1 07:48:16.621: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:443/proxy/... (200; 19.273585ms)
Aug  1 07:48:16.621: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/http:proxy-service-2ddrt:portname2/proxy/: bar (200; 19.52017ms)
Aug  1 07:48:16.622: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/proxy-service-2ddrt:portname2/proxy/: bar (200; 19.769689ms)
Aug  1 07:48:16.623: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/https:proxy-service-2ddrt:tlsportname2/proxy/: tls qux (200; 20.777099ms)
Aug  1 07:48:16.631: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8/proxy/rewriteme"... (200; 8.374868ms)
Aug  1 07:48:16.634: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:160/proxy/: foo (200; 9.995298ms)
Aug  1 07:48:16.634: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:1080/proxy/rewri... (200; 10.275031ms)
Aug  1 07:48:16.634: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:160/proxy/: foo (200; 10.144694ms)
Aug  1 07:48:16.637: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/proxy-service-2ddrt:portname1/proxy/: foo (200; 12.06651ms)
Aug  1 07:48:16.637: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:162/proxy/: bar (200; 12.632426ms)
Aug  1 07:48:16.637: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:162/proxy/: bar (200; 13.21078ms)
Aug  1 07:48:16.637: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:443/proxy/... (200; 12.167886ms)
Aug  1 07:48:16.637: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:1080/proxy/... (200; 13.087145ms)
Aug  1 07:48:16.637: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/https:proxy-service-2ddrt:tlsportname1/proxy/: tls baz (200; 13.238448ms)
Aug  1 07:48:16.637: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:460/proxy/: tls baz (200; 12.515512ms)
Aug  1 07:48:16.638: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/https:proxy-service-2ddrt:tlsportname2/proxy/: tls qux (200; 12.801823ms)
Aug  1 07:48:16.638: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/http:proxy-service-2ddrt:portname2/proxy/: bar (200; 12.976808ms)
Aug  1 07:48:16.638: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:462/proxy/: tls qux (200; 12.542928ms)
Aug  1 07:48:16.638: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/http:proxy-service-2ddrt:portname1/proxy/: foo (200; 12.939569ms)
Aug  1 07:48:16.638: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/proxy-service-2ddrt:portname2/proxy/: bar (200; 13.176637ms)
Aug  1 07:48:16.649: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:160/proxy/: foo (200; 10.385979ms)
Aug  1 07:48:16.654: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:462/proxy/: tls qux (200; 13.984895ms)
Aug  1 07:48:16.655: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:162/proxy/: bar (200; 15.295476ms)
Aug  1 07:48:16.656: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:162/proxy/: bar (200; 16.00558ms)
Aug  1 07:48:16.656: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8/proxy/rewriteme"... (200; 16.354875ms)
Aug  1 07:48:16.656: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/http:proxy-service-2ddrt:portname2/proxy/: bar (200; 17.230773ms)
Aug  1 07:48:16.656: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:1080/proxy/... (200; 16.37045ms)
Aug  1 07:48:16.656: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/proxy-service-2ddrt:portname1/proxy/: foo (200; 17.374135ms)
Aug  1 07:48:16.656: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:160/proxy/: foo (200; 16.537717ms)
Aug  1 07:48:16.656: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/https:proxy-service-2ddrt:tlsportname2/proxy/: tls qux (200; 17.193572ms)
Aug  1 07:48:16.656: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/https:proxy-service-2ddrt:tlsportname1/proxy/: tls baz (200; 16.478066ms)
Aug  1 07:48:16.656: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:460/proxy/: tls baz (200; 16.825937ms)
Aug  1 07:48:16.656: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:443/proxy/... (200; 17.100533ms)
Aug  1 07:48:16.656: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/proxy-service-2ddrt:portname2/proxy/: bar (200; 16.763546ms)
Aug  1 07:48:16.657: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/http:proxy-service-2ddrt:portname1/proxy/: foo (200; 16.800915ms)
Aug  1 07:48:16.658: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:1080/proxy/rewri... (200; 18.572548ms)
Aug  1 07:48:16.662: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:162/proxy/: bar (200; 3.795026ms)
Aug  1 07:48:16.663: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:1080/proxy/... (200; 4.288835ms)
Aug  1 07:48:16.664: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/https:proxy-service-2ddrt:tlsportname1/proxy/: tls baz (200; 5.47556ms)
Aug  1 07:48:16.666: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:460/proxy/: tls baz (200; 6.558983ms)
Aug  1 07:48:16.666: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:462/proxy/: tls qux (200; 6.514773ms)
Aug  1 07:48:16.666: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:443/proxy/... (200; 7.110637ms)
Aug  1 07:48:16.667: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:160/proxy/: foo (200; 7.541552ms)
Aug  1 07:48:16.668: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/proxy-service-2ddrt:portname2/proxy/: bar (200; 8.788788ms)
Aug  1 07:48:16.669: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:1080/proxy/rewri... (200; 8.617996ms)
Aug  1 07:48:16.669: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:162/proxy/: bar (200; 8.998578ms)
Aug  1 07:48:16.669: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/http:proxy-service-2ddrt:portname1/proxy/: foo (200; 9.423466ms)
Aug  1 07:48:16.669: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8/proxy/rewriteme"... (200; 9.283324ms)
Aug  1 07:48:16.669: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/proxy-service-2ddrt:portname1/proxy/: foo (200; 9.972807ms)
Aug  1 07:48:16.669: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/http:proxy-service-2ddrt:portname2/proxy/: bar (200; 9.913254ms)
Aug  1 07:48:16.670: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:160/proxy/: foo (200; 9.780418ms)
Aug  1 07:48:16.670: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/https:proxy-service-2ddrt:tlsportname2/proxy/: tls qux (200; 10.411411ms)
Aug  1 07:48:16.674: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:462/proxy/: tls qux (200; 2.875342ms)
Aug  1 07:48:16.675: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:460/proxy/: tls baz (200; 3.756868ms)
Aug  1 07:48:16.676: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/https:proxy-service-2ddrt:tlsportname1/proxy/: tls baz (200; 6.125196ms)
Aug  1 07:48:16.677: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:160/proxy/: foo (200; 6.806165ms)
Aug  1 07:48:16.677: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:160/proxy/: foo (200; 7.062801ms)
Aug  1 07:48:16.678: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:443/proxy/... (200; 6.798691ms)
Aug  1 07:48:16.678: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:1080/proxy/... (200; 7.331818ms)
Aug  1 07:48:16.682: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:1080/proxy/rewri... (200; 10.38587ms)
Aug  1 07:48:16.682: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8/proxy/rewriteme"... (200; 10.840188ms)
Aug  1 07:48:16.682: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/https:proxy-service-2ddrt:tlsportname2/proxy/: tls qux (200; 11.872011ms)
Aug  1 07:48:16.683: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:162/proxy/: bar (200; 10.706433ms)
Aug  1 07:48:16.683: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:162/proxy/: bar (200; 10.683218ms)
Aug  1 07:48:16.684: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/proxy-service-2ddrt:portname1/proxy/: foo (200; 12.518768ms)
Aug  1 07:48:16.684: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/proxy-service-2ddrt:portname2/proxy/: bar (200; 12.336477ms)
Aug  1 07:48:16.684: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/http:proxy-service-2ddrt:portname2/proxy/: bar (200; 12.829263ms)
Aug  1 07:48:16.684: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/http:proxy-service-2ddrt:portname1/proxy/: foo (200; 12.683182ms)
Aug  1 07:48:16.690: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:1080/proxy/... (200; 5.305937ms)
Aug  1 07:48:16.691: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:160/proxy/: foo (200; 5.824765ms)
Aug  1 07:48:16.691: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:162/proxy/: bar (200; 6.258089ms)
Aug  1 07:48:16.692: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:460/proxy/: tls baz (200; 6.579552ms)
Aug  1 07:48:16.693: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/http:proxy-service-2ddrt:portname2/proxy/: bar (200; 7.650463ms)
Aug  1 07:48:16.693: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/https:proxy-service-2ddrt:tlsportname1/proxy/: tls baz (200; 8.31547ms)
Aug  1 07:48:16.693: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/proxy-service-2ddrt:portname1/proxy/: foo (200; 7.840802ms)
Aug  1 07:48:16.695: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/https:proxy-service-2ddrt:tlsportname2/proxy/: tls qux (200; 9.457887ms)
Aug  1 07:48:16.695: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:462/proxy/: tls qux (200; 9.81154ms)
Aug  1 07:48:16.696: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8/proxy/rewriteme"... (200; 10.452302ms)
Aug  1 07:48:16.697: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/proxy-service-2ddrt:portname2/proxy/: bar (200; 10.970674ms)
Aug  1 07:48:16.697: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/http:proxy-service-2ddrt:portname1/proxy/: foo (200; 11.350879ms)
Aug  1 07:48:16.698: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:160/proxy/: foo (200; 11.838069ms)
Aug  1 07:48:16.698: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:443/proxy/... (200; 12.552746ms)
Aug  1 07:48:16.698: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:162/proxy/: bar (200; 12.125537ms)
Aug  1 07:48:16.699: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:1080/proxy/rewri... (200; 12.578994ms)
Aug  1 07:48:16.705: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/https:proxy-service-2ddrt:tlsportname1/proxy/: tls baz (200; 5.511826ms)
Aug  1 07:48:16.707: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8/proxy/rewriteme"... (200; 7.327098ms)
Aug  1 07:48:16.708: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:462/proxy/: tls qux (200; 8.06427ms)
Aug  1 07:48:16.708: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:460/proxy/: tls baz (200; 8.41898ms)
Aug  1 07:48:16.708: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/proxy-service-2ddrt:portname2/proxy/: bar (200; 9.664893ms)
Aug  1 07:48:16.709: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:1080/proxy/... (200; 9.383637ms)
Aug  1 07:48:16.709: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:160/proxy/: foo (200; 9.86011ms)
Aug  1 07:48:16.710: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:162/proxy/: bar (200; 10.701911ms)
Aug  1 07:48:16.710: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:443/proxy/... (200; 10.068127ms)
Aug  1 07:48:16.712: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/http:proxy-service-2ddrt:portname1/proxy/: foo (200; 11.915999ms)
Aug  1 07:48:16.712: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/https:proxy-service-2ddrt:tlsportname2/proxy/: tls qux (200; 12.681419ms)
Aug  1 07:48:16.712: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:1080/proxy/rewri... (200; 13.292259ms)
Aug  1 07:48:16.713: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:162/proxy/: bar (200; 13.587799ms)
Aug  1 07:48:16.713: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:160/proxy/: foo (200; 13.677766ms)
Aug  1 07:48:16.713: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/http:proxy-service-2ddrt:portname2/proxy/: bar (200; 13.152623ms)
Aug  1 07:48:16.713: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/proxy-service-2ddrt:portname1/proxy/: foo (200; 13.485197ms)
Aug  1 07:48:16.720: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8/proxy/rewriteme"... (200; 4.892228ms)
Aug  1 07:48:16.721: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:160/proxy/: foo (200; 7.953997ms)
Aug  1 07:48:16.722: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:162/proxy/: bar (200; 6.25108ms)
Aug  1 07:48:16.722: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:460/proxy/: tls baz (200; 7.423941ms)
Aug  1 07:48:16.722: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/proxy-service-2ddrt:portname1/proxy/: foo (200; 8.042888ms)
Aug  1 07:48:16.722: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:1080/proxy/... (200; 6.118327ms)
Aug  1 07:48:16.722: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:1080/proxy/rewri... (200; 6.813511ms)
Aug  1 07:48:16.722: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:443/proxy/... (200; 7.702364ms)
Aug  1 07:48:16.724: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/proxy-service-2ddrt:portname2/proxy/: bar (200; 9.713917ms)
Aug  1 07:48:16.724: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:160/proxy/: foo (200; 9.307712ms)
Aug  1 07:48:16.724: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:162/proxy/: bar (200; 9.209436ms)
Aug  1 07:48:16.724: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:462/proxy/: tls qux (200; 10.102454ms)
Aug  1 07:48:16.724: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/https:proxy-service-2ddrt:tlsportname2/proxy/: tls qux (200; 10.465503ms)
Aug  1 07:48:16.724: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/https:proxy-service-2ddrt:tlsportname1/proxy/: tls baz (200; 9.031926ms)
Aug  1 07:48:16.724: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/http:proxy-service-2ddrt:portname2/proxy/: bar (200; 10.686139ms)
Aug  1 07:48:16.725: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/http:proxy-service-2ddrt:portname1/proxy/: foo (200; 9.969408ms)
Aug  1 07:48:16.731: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8/proxy/rewriteme"... (200; 4.228971ms)
Aug  1 07:48:16.731: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:460/proxy/: tls baz (200; 4.727167ms)
Aug  1 07:48:16.736: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:160/proxy/: foo (200; 8.894919ms)
Aug  1 07:48:16.736: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/proxy-service-2ddrt:portname2/proxy/: bar (200; 9.815612ms)
Aug  1 07:48:16.736: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:162/proxy/: bar (200; 9.399018ms)
Aug  1 07:48:16.736: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:1080/proxy/... (200; 9.12842ms)
Aug  1 07:48:16.736: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/https:proxy-service-2ddrt:tlsportname2/proxy/: tls qux (200; 8.663401ms)
Aug  1 07:48:16.736: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:160/proxy/: foo (200; 9.602173ms)
Aug  1 07:48:16.736: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/https:proxy-service-2ddrt:tlsportname1/proxy/: tls baz (200; 9.31ms)
Aug  1 07:48:16.736: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:1080/proxy/rewri... (200; 9.754952ms)
Aug  1 07:48:16.736: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/http:proxy-service-2ddrt:portname1/proxy/: foo (200; 10.141869ms)
Aug  1 07:48:16.737: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:162/proxy/: bar (200; 9.479751ms)
Aug  1 07:48:16.738: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:443/proxy/... (200; 9.952746ms)
Aug  1 07:48:16.738: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:462/proxy/: tls qux (200; 10.724676ms)
Aug  1 07:48:16.738: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/http:proxy-service-2ddrt:portname2/proxy/: bar (200; 10.791931ms)
Aug  1 07:48:16.739: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/proxy-service-2ddrt:portname1/proxy/: foo (200; 11.083319ms)
Aug  1 07:48:16.743: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:460/proxy/: tls baz (200; 4.559366ms)
Aug  1 07:48:16.748: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:1080/proxy/... (200; 8.28972ms)
Aug  1 07:48:16.749: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/proxy-service-2ddrt:portname2/proxy/: bar (200; 9.860435ms)
Aug  1 07:48:16.749: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/https:proxy-service-2ddrt:tlsportname1/proxy/: tls baz (200; 9.437749ms)
Aug  1 07:48:16.749: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:160/proxy/: foo (200; 9.239393ms)
Aug  1 07:48:16.749: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:160/proxy/: foo (200; 9.985338ms)
Aug  1 07:48:16.752: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:462/proxy/: tls qux (200; 11.7602ms)
Aug  1 07:48:16.752: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:443/proxy/... (200; 10.790758ms)
Aug  1 07:48:16.753: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/proxy-service-2ddrt:portname1/proxy/: foo (200; 11.989553ms)
Aug  1 07:48:16.753: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:1080/proxy/rewri... (200; 13.375335ms)
Aug  1 07:48:16.753: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/http:proxy-service-2ddrt:portname1/proxy/: foo (200; 13.766252ms)
Aug  1 07:48:16.753: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8/proxy/rewriteme"... (200; 13.523843ms)
Aug  1 07:48:16.753: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/http:proxy-service-2ddrt:portname2/proxy/: bar (200; 11.494111ms)
Aug  1 07:48:16.753: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/https:proxy-service-2ddrt:tlsportname2/proxy/: tls qux (200; 11.386228ms)
Aug  1 07:48:16.753: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:162/proxy/: bar (200; 12.942742ms)
Aug  1 07:48:16.753: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:162/proxy/: bar (200; 13.089198ms)
Aug  1 07:48:16.760: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:1080/proxy/... (200; 5.419362ms)
Aug  1 07:48:16.760: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:162/proxy/: bar (200; 5.973725ms)
Aug  1 07:48:16.761: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:162/proxy/: bar (200; 6.452129ms)
Aug  1 07:48:16.761: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/https:proxy-service-2ddrt:tlsportname1/proxy/: tls baz (200; 6.60463ms)
Aug  1 07:48:16.762: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:1080/proxy/rewri... (200; 7.327734ms)
Aug  1 07:48:16.762: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8/proxy/rewriteme"... (200; 7.902982ms)
Aug  1 07:48:16.762: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:160/proxy/: foo (200; 7.894945ms)
Aug  1 07:48:16.765: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:160/proxy/: foo (200; 10.202851ms)
Aug  1 07:48:16.766: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:462/proxy/: tls qux (200; 10.536459ms)
Aug  1 07:48:16.766: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:443/proxy/... (200; 10.367094ms)
Aug  1 07:48:16.766: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/https:proxy-service-2ddrt:tlsportname2/proxy/: tls qux (200; 10.724954ms)
Aug  1 07:48:16.766: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:460/proxy/: tls baz (200; 11.297586ms)
Aug  1 07:48:16.766: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/proxy-service-2ddrt:portname1/proxy/: foo (200; 11.264441ms)
Aug  1 07:48:16.767: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/proxy-service-2ddrt:portname2/proxy/: bar (200; 11.794591ms)
Aug  1 07:48:16.768: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/http:proxy-service-2ddrt:portname1/proxy/: foo (200; 12.026192ms)
Aug  1 07:48:16.768: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/http:proxy-service-2ddrt:portname2/proxy/: bar (200; 12.503636ms)
Aug  1 07:48:16.774: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8/proxy/rewriteme"... (200; 5.848142ms)
Aug  1 07:48:16.775: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/proxy-service-2ddrt:portname1/proxy/: foo (200; 6.84656ms)
Aug  1 07:48:16.776: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/proxy-service-2ddrt:portname2/proxy/: bar (200; 7.593685ms)
Aug  1 07:48:16.776: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:162/proxy/: bar (200; 7.783615ms)
Aug  1 07:48:16.777: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:160/proxy/: foo (200; 8.041282ms)
Aug  1 07:48:16.778: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:1080/proxy/... (200; 8.707593ms)
Aug  1 07:48:16.778: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:162/proxy/: bar (200; 9.75356ms)
Aug  1 07:48:16.779: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/http:proxy-service-2ddrt:portname1/proxy/: foo (200; 10.214966ms)
Aug  1 07:48:16.779: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:1080/proxy/rewri... (200; 10.079255ms)
Aug  1 07:48:16.779: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:160/proxy/: foo (200; 10.247788ms)
Aug  1 07:48:16.781: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/https:proxy-service-2ddrt:tlsportname2/proxy/: tls qux (200; 11.770521ms)
Aug  1 07:48:16.781: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:443/proxy/... (200; 11.882888ms)
Aug  1 07:48:16.781: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/http:proxy-service-2ddrt:portname2/proxy/: bar (200; 12.222544ms)
Aug  1 07:48:16.782: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:460/proxy/: tls baz (200; 12.209635ms)
Aug  1 07:48:16.782: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/https:proxy-service-2ddrt:tlsportname1/proxy/: tls baz (200; 12.605183ms)
Aug  1 07:48:16.782: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:462/proxy/: tls qux (200; 12.215179ms)
Aug  1 07:48:16.786: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:1080/proxy/... (200; 3.867323ms)
Aug  1 07:48:16.789: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:443/proxy/... (200; 6.885812ms)
Aug  1 07:48:16.791: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8/proxy/rewriteme"... (200; 8.342435ms)
Aug  1 07:48:16.792: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:160/proxy/: foo (200; 8.515575ms)
Aug  1 07:48:16.792: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:460/proxy/: tls baz (200; 9.428733ms)
Aug  1 07:48:16.792: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:162/proxy/: bar (200; 8.81895ms)
Aug  1 07:48:16.792: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:462/proxy/: tls qux (200; 9.398843ms)
Aug  1 07:48:16.792: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/https:proxy-service-2ddrt:tlsportname2/proxy/: tls qux (200; 9.770218ms)
Aug  1 07:48:16.792: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/https:proxy-service-2ddrt:tlsportname1/proxy/: tls baz (200; 8.572977ms)
Aug  1 07:48:16.792: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/proxy-service-2ddrt:portname1/proxy/: foo (200; 9.406131ms)
Aug  1 07:48:16.792: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:162/proxy/: bar (200; 9.074168ms)
Aug  1 07:48:16.794: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/http:proxy-service-2ddrt:portname2/proxy/: bar (200; 10.550064ms)
Aug  1 07:48:16.794: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:160/proxy/: foo (200; 9.992772ms)
Aug  1 07:48:16.794: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:1080/proxy/rewri... (200; 10.08138ms)
Aug  1 07:48:16.794: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/proxy-service-2ddrt:portname2/proxy/: bar (200; 10.360351ms)
Aug  1 07:48:16.794: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/http:proxy-service-2ddrt:portname1/proxy/: foo (200; 10.447736ms)
Aug  1 07:48:16.799: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:160/proxy/: foo (200; 3.275393ms)
Aug  1 07:48:16.799: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:462/proxy/: tls qux (200; 3.461965ms)
Aug  1 07:48:16.801: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/proxy-service-2ddrt:portname1/proxy/: foo (200; 5.669663ms)
Aug  1 07:48:16.802: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/https:proxy-service-2ddrt:tlsportname2/proxy/: tls qux (200; 5.857639ms)
Aug  1 07:48:16.802: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/http:proxy-service-2ddrt:portname2/proxy/: bar (200; 6.680829ms)
Aug  1 07:48:16.804: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:460/proxy/: tls baz (200; 7.597402ms)
Aug  1 07:48:16.804: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:443/proxy/... (200; 8.19692ms)
Aug  1 07:48:16.805: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8/proxy/rewriteme"... (200; 8.632908ms)
Aug  1 07:48:16.805: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/http:proxy-service-2ddrt:portname1/proxy/: foo (200; 8.947977ms)
Aug  1 07:48:16.806: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:160/proxy/: foo (200; 8.998135ms)
Aug  1 07:48:16.806: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:1080/proxy/rewri... (200; 9.110121ms)
Aug  1 07:48:16.806: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:162/proxy/: bar (200; 8.954824ms)
Aug  1 07:48:16.806: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:162/proxy/: bar (200; 9.757053ms)
Aug  1 07:48:16.807: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/proxy-service-2ddrt:portname2/proxy/: bar (200; 10.665448ms)
Aug  1 07:48:16.807: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:1080/proxy/... (200; 10.263899ms)
Aug  1 07:48:16.808: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/https:proxy-service-2ddrt:tlsportname1/proxy/: tls baz (200; 11.627891ms)
Aug  1 07:48:16.813: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:1080/proxy/... (200; 3.657731ms)
Aug  1 07:48:16.813: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:162/proxy/: bar (200; 4.48384ms)
Aug  1 07:48:16.814: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/proxy-service-2ddrt:portname1/proxy/: foo (200; 4.742768ms)
Aug  1 07:48:16.814: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/http:proxy-service-2ddrt:portname2/proxy/: bar (200; 4.491247ms)
Aug  1 07:48:16.815: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:462/proxy/: tls qux (200; 5.344871ms)
Aug  1 07:48:16.815: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:160/proxy/: foo (200; 5.766692ms)
Aug  1 07:48:16.817: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:1080/proxy/rewri... (200; 6.331868ms)
Aug  1 07:48:16.818: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/https:proxy-service-2ddrt:tlsportname1/proxy/: tls baz (200; 8.684761ms)
Aug  1 07:48:16.818: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:443/proxy/... (200; 7.629844ms)
Aug  1 07:48:16.818: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:160/proxy/: foo (200; 7.139011ms)
Aug  1 07:48:16.818: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8/proxy/rewriteme"... (200; 7.541756ms)
Aug  1 07:48:16.818: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/https:proxy-service-2ddrt:tlsportname2/proxy/: tls qux (200; 8.414793ms)
Aug  1 07:48:16.818: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:460/proxy/: tls baz (200; 8.167809ms)
Aug  1 07:48:16.819: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/http:proxy-service-2ddrt:portname1/proxy/: foo (200; 8.921276ms)
Aug  1 07:48:16.820: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/proxy-service-2ddrt:portname2/proxy/: bar (200; 9.319651ms)
Aug  1 07:48:16.820: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:162/proxy/: bar (200; 8.959801ms)
Aug  1 07:48:16.825: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:443/proxy/... (200; 4.758336ms)
Aug  1 07:48:16.827: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8/proxy/rewriteme"... (200; 5.653002ms)
Aug  1 07:48:16.827: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:1080/proxy/... (200; 5.484952ms)
Aug  1 07:48:16.827: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:162/proxy/: bar (200; 5.874366ms)
Aug  1 07:48:16.828: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/proxy-service-2ddrt:portname2/proxy/: bar (200; 7.023754ms)
Aug  1 07:48:16.828: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:160/proxy/: foo (200; 7.188941ms)
Aug  1 07:48:16.828: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:1080/proxy/rewri... (200; 7.280346ms)
Aug  1 07:48:16.829: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/proxy-service-2ddrt-4dvn8:162/proxy/: bar (200; 7.529392ms)
Aug  1 07:48:16.831: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:462/proxy/: tls qux (200; 8.794554ms)
Aug  1 07:48:16.831: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/proxy-service-2ddrt:portname1/proxy/: foo (200; 8.754062ms)
Aug  1 07:48:16.831: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/http:proxy-service-2ddrt-4dvn8:160/proxy/: foo (200; 9.149831ms)
Aug  1 07:48:16.831: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/https:proxy-service-2ddrt:tlsportname1/proxy/: tls baz (200; 9.344167ms)
Aug  1 07:48:16.831: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/http:proxy-service-2ddrt:portname1/proxy/: foo (200; 10.242741ms)
Aug  1 07:48:16.831: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/https:proxy-service-2ddrt:tlsportname2/proxy/: tls qux (200; 8.682432ms)
Aug  1 07:48:16.832: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-l7r88/services/http:proxy-service-2ddrt:portname2/proxy/: bar (200; 9.645819ms)
Aug  1 07:48:16.832: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-l7r88/pods/https:proxy-service-2ddrt-4dvn8:460/proxy/: tls baz (200; 10.102827ms)
STEP: deleting ReplicationController proxy-service-2ddrt in namespace e2e-tests-proxy-l7r88, will wait for the garbage collector to delete the pods
Aug  1 07:48:16.894: INFO: Deleting ReplicationController proxy-service-2ddrt took: 8.945727ms
Aug  1 07:48:17.094: INFO: Terminating ReplicationController proxy-service-2ddrt pods took: 200.246778ms
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 07:48:20.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-l7r88" for this suite.
Aug  1 07:48:28.793: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 07:48:28.888: INFO: namespace: e2e-tests-proxy-l7r88, resource: bindings, ignored listing per whitelist
Aug  1 07:48:28.901: INFO: namespace e2e-tests-proxy-l7r88 deletion completed in 8.20005344s

• [SLOW TEST:42.369 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 07:48:28.906: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug  1 07:48:29.328: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 07:48:33.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-mh2xp" for this suite.
Aug  1 07:49:13.908: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 07:49:14.024: INFO: namespace: e2e-tests-pods-mh2xp, resource: bindings, ignored listing per whitelist
Aug  1 07:49:14.039: INFO: namespace e2e-tests-pods-mh2xp deletion completed in 40.195141803s

• [SLOW TEST:45.133 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 07:49:14.043: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-db7fd169-b430-11e9-aec8-12de527cd1b8
STEP: Creating a pod to test consume secrets
Aug  1 07:49:14.799: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-db8b7c77-b430-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-projected-7fz8f" to be "success or failure"
Aug  1 07:49:14.831: INFO: Pod "pod-projected-secrets-db8b7c77-b430-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 31.716826ms
Aug  1 07:49:16.834: INFO: Pod "pod-projected-secrets-db8b7c77-b430-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034170744s
Aug  1 07:49:19.010: INFO: Pod "pod-projected-secrets-db8b7c77-b430-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.210605998s
STEP: Saw pod success
Aug  1 07:49:19.010: INFO: Pod "pod-projected-secrets-db8b7c77-b430-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 07:49:19.013: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod pod-projected-secrets-db8b7c77-b430-11e9-aec8-12de527cd1b8 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug  1 07:49:19.272: INFO: Waiting for pod pod-projected-secrets-db8b7c77-b430-11e9-aec8-12de527cd1b8 to disappear
Aug  1 07:49:19.349: INFO: Pod pod-projected-secrets-db8b7c77-b430-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 07:49:19.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7fz8f" for this suite.
Aug  1 07:49:25.603: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 07:49:25.620: INFO: namespace: e2e-tests-projected-7fz8f, resource: bindings, ignored listing per whitelist
Aug  1 07:49:25.722: INFO: namespace e2e-tests-projected-7fz8f deletion completed in 6.36811213s

• [SLOW TEST:11.680 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 07:49:25.728: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Aug  1 07:49:25.966: INFO: Waiting up to 5m0s for pod "var-expansion-e2498b30-b430-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-var-expansion-fn8lt" to be "success or failure"
Aug  1 07:49:26.017: INFO: Pod "var-expansion-e2498b30-b430-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 51.291154ms
Aug  1 07:49:28.157: INFO: Pod "var-expansion-e2498b30-b430-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.191339977s
Aug  1 07:49:30.160: INFO: Pod "var-expansion-e2498b30-b430-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.194230996s
STEP: Saw pod success
Aug  1 07:49:30.160: INFO: Pod "var-expansion-e2498b30-b430-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 07:49:30.162: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod var-expansion-e2498b30-b430-11e9-aec8-12de527cd1b8 container dapi-container: <nil>
STEP: delete the pod
Aug  1 07:49:30.470: INFO: Waiting for pod var-expansion-e2498b30-b430-11e9-aec8-12de527cd1b8 to disappear
Aug  1 07:49:30.787: INFO: Pod var-expansion-e2498b30-b430-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 07:49:30.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-fn8lt" for this suite.
Aug  1 07:49:37.465: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 07:49:37.743: INFO: namespace: e2e-tests-var-expansion-fn8lt, resource: bindings, ignored listing per whitelist
Aug  1 07:49:37.776: INFO: namespace e2e-tests-var-expansion-fn8lt deletion completed in 6.644650486s

• [SLOW TEST:12.049 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 07:49:37.779: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Aug  1 07:49:38.782: INFO: Waiting up to 5m0s for pod "pod-service-account-e9d53d69-b430-11e9-aec8-12de527cd1b8-q2mwg" in namespace "e2e-tests-svcaccounts-fx6l5" to be "success or failure"
Aug  1 07:49:38.802: INFO: Pod "pod-service-account-e9d53d69-b430-11e9-aec8-12de527cd1b8-q2mwg": Phase="Pending", Reason="", readiness=false. Elapsed: 19.738185ms
Aug  1 07:49:40.971: INFO: Pod "pod-service-account-e9d53d69-b430-11e9-aec8-12de527cd1b8-q2mwg": Phase="Pending", Reason="", readiness=false. Elapsed: 2.188223747s
Aug  1 07:49:43.264: INFO: Pod "pod-service-account-e9d53d69-b430-11e9-aec8-12de527cd1b8-q2mwg": Phase="Pending", Reason="", readiness=false. Elapsed: 4.481402374s
Aug  1 07:49:45.270: INFO: Pod "pod-service-account-e9d53d69-b430-11e9-aec8-12de527cd1b8-q2mwg": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.487112213s
STEP: Saw pod success
Aug  1 07:49:45.270: INFO: Pod "pod-service-account-e9d53d69-b430-11e9-aec8-12de527cd1b8-q2mwg" satisfied condition "success or failure"
Aug  1 07:49:45.273: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod pod-service-account-e9d53d69-b430-11e9-aec8-12de527cd1b8-q2mwg container token-test: <nil>
STEP: delete the pod
Aug  1 07:49:45.430: INFO: Waiting for pod pod-service-account-e9d53d69-b430-11e9-aec8-12de527cd1b8-q2mwg to disappear
Aug  1 07:49:45.460: INFO: Pod pod-service-account-e9d53d69-b430-11e9-aec8-12de527cd1b8-q2mwg no longer exists
STEP: Creating a pod to test consume service account root CA
Aug  1 07:49:45.475: INFO: Waiting up to 5m0s for pod "pod-service-account-e9d53d69-b430-11e9-aec8-12de527cd1b8-ps67c" in namespace "e2e-tests-svcaccounts-fx6l5" to be "success or failure"
Aug  1 07:49:45.505: INFO: Pod "pod-service-account-e9d53d69-b430-11e9-aec8-12de527cd1b8-ps67c": Phase="Pending", Reason="", readiness=false. Elapsed: 29.882162ms
Aug  1 07:49:47.509: INFO: Pod "pod-service-account-e9d53d69-b430-11e9-aec8-12de527cd1b8-ps67c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033218113s
Aug  1 07:49:49.511: INFO: Pod "pod-service-account-e9d53d69-b430-11e9-aec8-12de527cd1b8-ps67c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.035863858s
Aug  1 07:49:51.516: INFO: Pod "pod-service-account-e9d53d69-b430-11e9-aec8-12de527cd1b8-ps67c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.040281767s
Aug  1 07:49:53.519: INFO: Pod "pod-service-account-e9d53d69-b430-11e9-aec8-12de527cd1b8-ps67c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.042974577s
STEP: Saw pod success
Aug  1 07:49:53.519: INFO: Pod "pod-service-account-e9d53d69-b430-11e9-aec8-12de527cd1b8-ps67c" satisfied condition "success or failure"
Aug  1 07:49:53.520: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod pod-service-account-e9d53d69-b430-11e9-aec8-12de527cd1b8-ps67c container root-ca-test: <nil>
STEP: delete the pod
Aug  1 07:49:53.846: INFO: Waiting for pod pod-service-account-e9d53d69-b430-11e9-aec8-12de527cd1b8-ps67c to disappear
Aug  1 07:49:53.915: INFO: Pod pod-service-account-e9d53d69-b430-11e9-aec8-12de527cd1b8-ps67c no longer exists
STEP: Creating a pod to test consume service account namespace
Aug  1 07:49:53.921: INFO: Waiting up to 5m0s for pod "pod-service-account-e9d53d69-b430-11e9-aec8-12de527cd1b8-4nc5d" in namespace "e2e-tests-svcaccounts-fx6l5" to be "success or failure"
Aug  1 07:49:54.395: INFO: Pod "pod-service-account-e9d53d69-b430-11e9-aec8-12de527cd1b8-4nc5d": Phase="Pending", Reason="", readiness=false. Elapsed: 473.056372ms
Aug  1 07:49:56.467: INFO: Pod "pod-service-account-e9d53d69-b430-11e9-aec8-12de527cd1b8-4nc5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.545142705s
Aug  1 07:49:58.470: INFO: Pod "pod-service-account-e9d53d69-b430-11e9-aec8-12de527cd1b8-4nc5d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.548184897s
Aug  1 07:50:00.474: INFO: Pod "pod-service-account-e9d53d69-b430-11e9-aec8-12de527cd1b8-4nc5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.551753829s
STEP: Saw pod success
Aug  1 07:50:00.474: INFO: Pod "pod-service-account-e9d53d69-b430-11e9-aec8-12de527cd1b8-4nc5d" satisfied condition "success or failure"
Aug  1 07:50:00.476: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod pod-service-account-e9d53d69-b430-11e9-aec8-12de527cd1b8-4nc5d container namespace-test: <nil>
STEP: delete the pod
Aug  1 07:50:00.741: INFO: Waiting for pod pod-service-account-e9d53d69-b430-11e9-aec8-12de527cd1b8-4nc5d to disappear
Aug  1 07:50:00.801: INFO: Pod pod-service-account-e9d53d69-b430-11e9-aec8-12de527cd1b8-4nc5d no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 07:50:00.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-fx6l5" for this suite.
Aug  1 07:50:10.984: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 07:50:11.075: INFO: namespace: e2e-tests-svcaccounts-fx6l5, resource: bindings, ignored listing per whitelist
Aug  1 07:50:11.084: INFO: namespace e2e-tests-svcaccounts-fx6l5 deletion completed in 10.275896567s

• [SLOW TEST:33.305 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 07:50:11.087: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-9dtwb/configmap-test-fd5aaac5-b430-11e9-aec8-12de527cd1b8
STEP: Creating a pod to test consume configMaps
Aug  1 07:50:11.577: INFO: Waiting up to 5m0s for pod "pod-configmaps-fd72bf5d-b430-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-configmap-9dtwb" to be "success or failure"
Aug  1 07:50:11.674: INFO: Pod "pod-configmaps-fd72bf5d-b430-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 97.146041ms
Aug  1 07:50:13.751: INFO: Pod "pod-configmaps-fd72bf5d-b430-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.17369229s
Aug  1 07:50:15.753: INFO: Pod "pod-configmaps-fd72bf5d-b430-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.176338828s
STEP: Saw pod success
Aug  1 07:50:15.753: INFO: Pod "pod-configmaps-fd72bf5d-b430-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 07:50:15.756: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod pod-configmaps-fd72bf5d-b430-11e9-aec8-12de527cd1b8 container env-test: <nil>
STEP: delete the pod
Aug  1 07:50:15.905: INFO: Waiting for pod pod-configmaps-fd72bf5d-b430-11e9-aec8-12de527cd1b8 to disappear
Aug  1 07:50:15.937: INFO: Pod pod-configmaps-fd72bf5d-b430-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 07:50:15.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-9dtwb" for this suite.
Aug  1 07:50:23.981: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 07:50:24.064: INFO: namespace: e2e-tests-configmap-9dtwb, resource: bindings, ignored listing per whitelist
Aug  1 07:50:24.084: INFO: namespace e2e-tests-configmap-9dtwb deletion completed in 8.143194876s

• [SLOW TEST:12.997 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 07:50:24.096: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug  1 07:50:24.482: INFO: Waiting up to 5m0s for pod "downwardapi-volume-052b96e9-b431-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-projected-6x44k" to be "success or failure"
Aug  1 07:50:24.519: INFO: Pod "downwardapi-volume-052b96e9-b431-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 36.625982ms
Aug  1 07:50:26.621: INFO: Pod "downwardapi-volume-052b96e9-b431-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.138664649s
Aug  1 07:50:28.624: INFO: Pod "downwardapi-volume-052b96e9-b431-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.141344226s
STEP: Saw pod success
Aug  1 07:50:28.624: INFO: Pod "downwardapi-volume-052b96e9-b431-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 07:50:28.658: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod downwardapi-volume-052b96e9-b431-11e9-aec8-12de527cd1b8 container client-container: <nil>
STEP: delete the pod
Aug  1 07:50:28.761: INFO: Waiting for pod downwardapi-volume-052b96e9-b431-11e9-aec8-12de527cd1b8 to disappear
Aug  1 07:50:28.782: INFO: Pod downwardapi-volume-052b96e9-b431-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 07:50:28.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6x44k" for this suite.
Aug  1 07:50:34.854: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 07:50:34.978: INFO: namespace: e2e-tests-projected-6x44k, resource: bindings, ignored listing per whitelist
Aug  1 07:50:34.978: INFO: namespace e2e-tests-projected-6x44k deletion completed in 6.193247342s

• [SLOW TEST:10.882 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 07:50:34.978: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug  1 07:50:35.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-fz67h'
Aug  1 07:50:39.278: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug  1 07:50:39.278: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1404
Aug  1 07:50:43.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-fz67h'
Aug  1 07:50:43.790: INFO: stderr: ""
Aug  1 07:50:43.790: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 07:50:43.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-fz67h" for this suite.
Aug  1 07:50:50.209: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 07:50:50.422: INFO: namespace: e2e-tests-kubectl-fz67h, resource: bindings, ignored listing per whitelist
Aug  1 07:50:50.452: INFO: namespace e2e-tests-kubectl-fz67h deletion completed in 6.505816944s

• [SLOW TEST:15.474 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 07:50:50.476: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug  1 07:50:50.982: INFO: Waiting up to 5m0s for pod "downwardapi-volume-14e183c6-b431-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-projected-2mfrc" to be "success or failure"
Aug  1 07:50:51.246: INFO: Pod "downwardapi-volume-14e183c6-b431-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 263.77528ms
Aug  1 07:50:53.249: INFO: Pod "downwardapi-volume-14e183c6-b431-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.266399899s
Aug  1 07:50:55.252: INFO: Pod "downwardapi-volume-14e183c6-b431-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.269938819s
Aug  1 07:50:57.317: INFO: Pod "downwardapi-volume-14e183c6-b431-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.335084415s
STEP: Saw pod success
Aug  1 07:50:57.318: INFO: Pod "downwardapi-volume-14e183c6-b431-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 07:50:57.320: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod downwardapi-volume-14e183c6-b431-11e9-aec8-12de527cd1b8 container client-container: <nil>
STEP: delete the pod
Aug  1 07:50:57.409: INFO: Waiting for pod downwardapi-volume-14e183c6-b431-11e9-aec8-12de527cd1b8 to disappear
Aug  1 07:50:57.493: INFO: Pod downwardapi-volume-14e183c6-b431-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 07:50:57.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2mfrc" for this suite.
Aug  1 07:51:03.581: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 07:51:03.764: INFO: namespace: e2e-tests-projected-2mfrc, resource: bindings, ignored listing per whitelist
Aug  1 07:51:03.857: INFO: namespace e2e-tests-projected-2mfrc deletion completed in 6.361639897s

• [SLOW TEST:13.381 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 07:51:03.860: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-1cd9a74b-b431-11e9-aec8-12de527cd1b8
STEP: Creating a pod to test consume secrets
Aug  1 07:51:04.345: INFO: Waiting up to 5m0s for pod "pod-secrets-1ce9da92-b431-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-secrets-2msjn" to be "success or failure"
Aug  1 07:51:04.371: INFO: Pod "pod-secrets-1ce9da92-b431-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 25.1054ms
Aug  1 07:51:06.470: INFO: Pod "pod-secrets-1ce9da92-b431-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.124747635s
Aug  1 07:51:08.478: INFO: Pod "pod-secrets-1ce9da92-b431-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.132817106s
STEP: Saw pod success
Aug  1 07:51:08.479: INFO: Pod "pod-secrets-1ce9da92-b431-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 07:51:08.482: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod pod-secrets-1ce9da92-b431-11e9-aec8-12de527cd1b8 container secret-volume-test: <nil>
STEP: delete the pod
Aug  1 07:51:08.892: INFO: Waiting for pod pod-secrets-1ce9da92-b431-11e9-aec8-12de527cd1b8 to disappear
Aug  1 07:51:08.914: INFO: Pod pod-secrets-1ce9da92-b431-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 07:51:08.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-2msjn" for this suite.
Aug  1 07:51:15.215: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 07:51:15.411: INFO: namespace: e2e-tests-secrets-2msjn, resource: bindings, ignored listing per whitelist
Aug  1 07:51:15.418: INFO: namespace e2e-tests-secrets-2msjn deletion completed in 6.468794956s

• [SLOW TEST:11.559 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 07:51:15.423: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug  1 07:51:15.832: INFO: Waiting up to 5m0s for pod "downwardapi-volume-23c58a7a-b431-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-downward-api-vrgpx" to be "success or failure"
Aug  1 07:51:15.853: INFO: Pod "downwardapi-volume-23c58a7a-b431-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 20.159826ms
Aug  1 07:51:17.858: INFO: Pod "downwardapi-volume-23c58a7a-b431-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025793128s
Aug  1 07:51:19.863: INFO: Pod "downwardapi-volume-23c58a7a-b431-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030217038s
STEP: Saw pod success
Aug  1 07:51:19.863: INFO: Pod "downwardapi-volume-23c58a7a-b431-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 07:51:19.870: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod downwardapi-volume-23c58a7a-b431-11e9-aec8-12de527cd1b8 container client-container: <nil>
STEP: delete the pod
Aug  1 07:51:20.149: INFO: Waiting for pod downwardapi-volume-23c58a7a-b431-11e9-aec8-12de527cd1b8 to disappear
Aug  1 07:51:20.190: INFO: Pod downwardapi-volume-23c58a7a-b431-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 07:51:20.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-vrgpx" for this suite.
Aug  1 07:51:26.381: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 07:51:26.437: INFO: namespace: e2e-tests-downward-api-vrgpx, resource: bindings, ignored listing per whitelist
Aug  1 07:51:26.518: INFO: namespace e2e-tests-downward-api-vrgpx deletion completed in 6.319835895s

• [SLOW TEST:11.096 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 07:51:26.521: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug  1 07:51:31.103: INFO: Waiting up to 5m0s for pod "client-envvars-2cd30385-b431-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-pods-8p5z6" to be "success or failure"
Aug  1 07:51:31.150: INFO: Pod "client-envvars-2cd30385-b431-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 47.334784ms
Aug  1 07:51:33.154: INFO: Pod "client-envvars-2cd30385-b431-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.050429509s
Aug  1 07:51:35.156: INFO: Pod "client-envvars-2cd30385-b431-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053229528s
STEP: Saw pod success
Aug  1 07:51:35.156: INFO: Pod "client-envvars-2cd30385-b431-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 07:51:35.158: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod client-envvars-2cd30385-b431-11e9-aec8-12de527cd1b8 container env3cont: <nil>
STEP: delete the pod
Aug  1 07:51:35.341: INFO: Waiting for pod client-envvars-2cd30385-b431-11e9-aec8-12de527cd1b8 to disappear
Aug  1 07:51:35.398: INFO: Pod client-envvars-2cd30385-b431-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 07:51:35.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-8p5z6" for this suite.
Aug  1 07:52:15.537: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 07:52:15.578: INFO: namespace: e2e-tests-pods-8p5z6, resource: bindings, ignored listing per whitelist
Aug  1 07:52:15.680: INFO: namespace e2e-tests-pods-8p5z6 deletion completed in 40.278706771s

• [SLOW TEST:49.159 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 07:52:15.689: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1134
STEP: creating an rc
Aug  1 07:52:16.185: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 create -f - --namespace=e2e-tests-kubectl-mxtcc'
Aug  1 07:52:16.961: INFO: stderr: ""
Aug  1 07:52:16.961: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Aug  1 07:52:17.975: INFO: Selector matched 1 pods for map[app:redis]
Aug  1 07:52:17.975: INFO: Found 0 / 1
Aug  1 07:52:18.965: INFO: Selector matched 1 pods for map[app:redis]
Aug  1 07:52:18.965: INFO: Found 0 / 1
Aug  1 07:52:19.980: INFO: Selector matched 1 pods for map[app:redis]
Aug  1 07:52:19.980: INFO: Found 1 / 1
Aug  1 07:52:19.980: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug  1 07:52:19.985: INFO: Selector matched 1 pods for map[app:redis]
Aug  1 07:52:19.985: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Aug  1 07:52:19.985: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 logs redis-master-pq9mv redis-master --namespace=e2e-tests-kubectl-mxtcc'
Aug  1 07:52:20.213: INFO: stderr: ""
Aug  1 07:52:20.213: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 01 Aug 07:52:19.752 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 01 Aug 07:52:19.758 # Server started, Redis version 3.2.12\n1:M 01 Aug 07:52:19.759 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 01 Aug 07:52:19.759 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Aug  1 07:52:20.213: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 log redis-master-pq9mv redis-master --namespace=e2e-tests-kubectl-mxtcc --tail=1'
Aug  1 07:52:20.399: INFO: stderr: ""
Aug  1 07:52:20.400: INFO: stdout: "1:M 01 Aug 07:52:19.759 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Aug  1 07:52:20.400: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 log redis-master-pq9mv redis-master --namespace=e2e-tests-kubectl-mxtcc --limit-bytes=1'
Aug  1 07:52:20.638: INFO: stderr: ""
Aug  1 07:52:20.638: INFO: stdout: " "
STEP: exposing timestamps
Aug  1 07:52:20.638: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 log redis-master-pq9mv redis-master --namespace=e2e-tests-kubectl-mxtcc --tail=1 --timestamps'
Aug  1 07:52:20.756: INFO: stderr: ""
Aug  1 07:52:20.756: INFO: stdout: "2019-08-01T07:52:19.759546145Z 1:M 01 Aug 07:52:19.759 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Aug  1 07:52:23.257: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 log redis-master-pq9mv redis-master --namespace=e2e-tests-kubectl-mxtcc --since=1s'
Aug  1 07:52:23.372: INFO: stderr: ""
Aug  1 07:52:23.372: INFO: stdout: ""
Aug  1 07:52:23.372: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 log redis-master-pq9mv redis-master --namespace=e2e-tests-kubectl-mxtcc --since=24h'
Aug  1 07:52:23.511: INFO: stderr: ""
Aug  1 07:52:23.511: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 01 Aug 07:52:19.752 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 01 Aug 07:52:19.758 # Server started, Redis version 3.2.12\n1:M 01 Aug 07:52:19.759 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 01 Aug 07:52:19.759 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1140
STEP: using delete to clean up resources
Aug  1 07:52:23.512: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-mxtcc'
Aug  1 07:52:23.673: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug  1 07:52:23.673: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Aug  1 07:52:23.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-mxtcc'
Aug  1 07:52:23.877: INFO: stderr: "No resources found.\n"
Aug  1 07:52:23.877: INFO: stdout: ""
Aug  1 07:52:23.877: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods -l name=nginx --namespace=e2e-tests-kubectl-mxtcc -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug  1 07:52:24.044: INFO: stderr: ""
Aug  1 07:52:24.045: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 07:52:24.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-mxtcc" for this suite.
Aug  1 07:52:30.604: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 07:52:30.827: INFO: namespace: e2e-tests-kubectl-mxtcc, resource: bindings, ignored listing per whitelist
Aug  1 07:52:30.849: INFO: namespace e2e-tests-kubectl-mxtcc deletion completed in 6.797171579s

• [SLOW TEST:15.161 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 07:52:30.852: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Aug  1 07:52:35.748: INFO: Successfully updated pod "pod-update-activedeadlineseconds-50a3b14d-b431-11e9-aec8-12de527cd1b8"
Aug  1 07:52:35.763: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-50a3b14d-b431-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-pods-zrdkd" to be "terminated due to deadline exceeded"
Aug  1 07:52:35.799: INFO: Pod "pod-update-activedeadlineseconds-50a3b14d-b431-11e9-aec8-12de527cd1b8": Phase="Running", Reason="", readiness=true. Elapsed: 36.571849ms
Aug  1 07:52:37.889: INFO: Pod "pod-update-activedeadlineseconds-50a3b14d-b431-11e9-aec8-12de527cd1b8": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.126284592s
Aug  1 07:52:37.889: INFO: Pod "pod-update-activedeadlineseconds-50a3b14d-b431-11e9-aec8-12de527cd1b8" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 07:52:37.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-zrdkd" for this suite.
Aug  1 07:52:44.231: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 07:52:44.243: INFO: namespace: e2e-tests-pods-zrdkd, resource: bindings, ignored listing per whitelist
Aug  1 07:52:44.329: INFO: namespace e2e-tests-pods-zrdkd deletion completed in 6.437295975s

• [SLOW TEST:13.477 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 07:52:44.333: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-58bf2005-b431-11e9-aec8-12de527cd1b8
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 07:52:51.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-lmn4b" for this suite.
Aug  1 07:53:15.227: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 07:53:15.270: INFO: namespace: e2e-tests-configmap-lmn4b, resource: bindings, ignored listing per whitelist
Aug  1 07:53:15.318: INFO: namespace e2e-tests-configmap-lmn4b deletion completed in 24.152989275s

• [SLOW TEST:30.986 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 07:53:15.320: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-k2jhv A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-k2jhv;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-k2jhv A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-k2jhv;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-k2jhv.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-k2jhv.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-k2jhv.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-k2jhv.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-k2jhv.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-k2jhv.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-k2jhv.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-k2jhv.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-k2jhv.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-k2jhv.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-k2jhv.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-k2jhv.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-k2jhv.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 70.112.254.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.254.112.70_udp@PTR;check="$$(dig +tcp +noall +answer +search 70.112.254.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.254.112.70_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-k2jhv A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-k2jhv;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-k2jhv A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-k2jhv;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-k2jhv.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-k2jhv.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-k2jhv.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-k2jhv.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-k2jhv.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-k2jhv.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-k2jhv.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-k2jhv.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-k2jhv.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-k2jhv.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-k2jhv.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-k2jhv.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-k2jhv.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 70.112.254.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.254.112.70_udp@PTR;check="$$(dig +tcp +noall +answer +search 70.112.254.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.254.112.70_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug  1 07:54:24.321: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-k2jhv/dns-test-6b586a8a-b431-11e9-aec8-12de527cd1b8: the server could not find the requested resource (get pods dns-test-6b586a8a-b431-11e9-aec8-12de527cd1b8)
Aug  1 07:54:24.335: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-k2jhv/dns-test-6b586a8a-b431-11e9-aec8-12de527cd1b8: the server could not find the requested resource (get pods dns-test-6b586a8a-b431-11e9-aec8-12de527cd1b8)
Aug  1 07:54:24.343: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-k2jhv from pod e2e-tests-dns-k2jhv/dns-test-6b586a8a-b431-11e9-aec8-12de527cd1b8: the server could not find the requested resource (get pods dns-test-6b586a8a-b431-11e9-aec8-12de527cd1b8)
Aug  1 07:54:24.348: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-k2jhv from pod e2e-tests-dns-k2jhv/dns-test-6b586a8a-b431-11e9-aec8-12de527cd1b8: the server could not find the requested resource (get pods dns-test-6b586a8a-b431-11e9-aec8-12de527cd1b8)
Aug  1 07:54:24.353: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-k2jhv.svc from pod e2e-tests-dns-k2jhv/dns-test-6b586a8a-b431-11e9-aec8-12de527cd1b8: the server could not find the requested resource (get pods dns-test-6b586a8a-b431-11e9-aec8-12de527cd1b8)
Aug  1 07:54:24.356: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-k2jhv.svc from pod e2e-tests-dns-k2jhv/dns-test-6b586a8a-b431-11e9-aec8-12de527cd1b8: the server could not find the requested resource (get pods dns-test-6b586a8a-b431-11e9-aec8-12de527cd1b8)
Aug  1 07:54:24.360: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-k2jhv.svc from pod e2e-tests-dns-k2jhv/dns-test-6b586a8a-b431-11e9-aec8-12de527cd1b8: the server could not find the requested resource (get pods dns-test-6b586a8a-b431-11e9-aec8-12de527cd1b8)
Aug  1 07:54:24.367: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-k2jhv.svc from pod e2e-tests-dns-k2jhv/dns-test-6b586a8a-b431-11e9-aec8-12de527cd1b8: the server could not find the requested resource (get pods dns-test-6b586a8a-b431-11e9-aec8-12de527cd1b8)
Aug  1 07:54:24.382: INFO: Unable to read wheezy_udp@PodARecord from pod e2e-tests-dns-k2jhv/dns-test-6b586a8a-b431-11e9-aec8-12de527cd1b8: the server could not find the requested resource (get pods dns-test-6b586a8a-b431-11e9-aec8-12de527cd1b8)
Aug  1 07:54:24.386: INFO: Unable to read wheezy_tcp@PodARecord from pod e2e-tests-dns-k2jhv/dns-test-6b586a8a-b431-11e9-aec8-12de527cd1b8: the server could not find the requested resource (get pods dns-test-6b586a8a-b431-11e9-aec8-12de527cd1b8)
Aug  1 07:54:24.392: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-k2jhv/dns-test-6b586a8a-b431-11e9-aec8-12de527cd1b8: the server could not find the requested resource (get pods dns-test-6b586a8a-b431-11e9-aec8-12de527cd1b8)
Aug  1 07:54:24.394: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-k2jhv/dns-test-6b586a8a-b431-11e9-aec8-12de527cd1b8: the server could not find the requested resource (get pods dns-test-6b586a8a-b431-11e9-aec8-12de527cd1b8)
Aug  1 07:54:24.395: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-k2jhv from pod e2e-tests-dns-k2jhv/dns-test-6b586a8a-b431-11e9-aec8-12de527cd1b8: the server could not find the requested resource (get pods dns-test-6b586a8a-b431-11e9-aec8-12de527cd1b8)
Aug  1 07:54:24.397: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-k2jhv from pod e2e-tests-dns-k2jhv/dns-test-6b586a8a-b431-11e9-aec8-12de527cd1b8: the server could not find the requested resource (get pods dns-test-6b586a8a-b431-11e9-aec8-12de527cd1b8)
Aug  1 07:54:24.399: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-k2jhv.svc from pod e2e-tests-dns-k2jhv/dns-test-6b586a8a-b431-11e9-aec8-12de527cd1b8: the server could not find the requested resource (get pods dns-test-6b586a8a-b431-11e9-aec8-12de527cd1b8)
Aug  1 07:54:24.401: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-k2jhv.svc from pod e2e-tests-dns-k2jhv/dns-test-6b586a8a-b431-11e9-aec8-12de527cd1b8: the server could not find the requested resource (get pods dns-test-6b586a8a-b431-11e9-aec8-12de527cd1b8)
Aug  1 07:54:24.403: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-k2jhv.svc from pod e2e-tests-dns-k2jhv/dns-test-6b586a8a-b431-11e9-aec8-12de527cd1b8: the server could not find the requested resource (get pods dns-test-6b586a8a-b431-11e9-aec8-12de527cd1b8)
Aug  1 07:54:24.405: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-k2jhv.svc from pod e2e-tests-dns-k2jhv/dns-test-6b586a8a-b431-11e9-aec8-12de527cd1b8: the server could not find the requested resource (get pods dns-test-6b586a8a-b431-11e9-aec8-12de527cd1b8)
Aug  1 07:54:24.411: INFO: Unable to read jessie_udp@PodARecord from pod e2e-tests-dns-k2jhv/dns-test-6b586a8a-b431-11e9-aec8-12de527cd1b8: the server could not find the requested resource (get pods dns-test-6b586a8a-b431-11e9-aec8-12de527cd1b8)
Aug  1 07:54:24.413: INFO: Unable to read jessie_tcp@PodARecord from pod e2e-tests-dns-k2jhv/dns-test-6b586a8a-b431-11e9-aec8-12de527cd1b8: the server could not find the requested resource (get pods dns-test-6b586a8a-b431-11e9-aec8-12de527cd1b8)
Aug  1 07:54:24.416: INFO: Lookups using e2e-tests-dns-k2jhv/dns-test-6b586a8a-b431-11e9-aec8-12de527cd1b8 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-k2jhv wheezy_tcp@dns-test-service.e2e-tests-dns-k2jhv wheezy_udp@dns-test-service.e2e-tests-dns-k2jhv.svc wheezy_tcp@dns-test-service.e2e-tests-dns-k2jhv.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-k2jhv.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-k2jhv.svc wheezy_udp@PodARecord wheezy_tcp@PodARecord jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-k2jhv jessie_tcp@dns-test-service.e2e-tests-dns-k2jhv jessie_udp@dns-test-service.e2e-tests-dns-k2jhv.svc jessie_tcp@dns-test-service.e2e-tests-dns-k2jhv.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-k2jhv.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-k2jhv.svc jessie_udp@PodARecord jessie_tcp@PodARecord]

Aug  1 07:54:29.569: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-k2jhv.svc from pod e2e-tests-dns-k2jhv/dns-test-6b586a8a-b431-11e9-aec8-12de527cd1b8: the server could not find the requested resource (get pods dns-test-6b586a8a-b431-11e9-aec8-12de527cd1b8)
Aug  1 07:54:29.582: INFO: Lookups using e2e-tests-dns-k2jhv/dns-test-6b586a8a-b431-11e9-aec8-12de527cd1b8 failed for: [jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-k2jhv.svc]

Aug  1 07:54:34.573: INFO: DNS probes using e2e-tests-dns-k2jhv/dns-test-6b586a8a-b431-11e9-aec8-12de527cd1b8 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 07:54:36.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-k2jhv" for this suite.
Aug  1 07:54:45.318: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 07:54:45.438: INFO: namespace: e2e-tests-dns-k2jhv, resource: bindings, ignored listing per whitelist
Aug  1 07:54:45.450: INFO: namespace e2e-tests-dns-k2jhv deletion completed in 8.582277244s

• [SLOW TEST:90.131 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 07:54:45.467: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 07:54:46.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-tbrm6" for this suite.
Aug  1 07:54:52.983: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 07:54:52.992: INFO: namespace: e2e-tests-kubelet-test-tbrm6, resource: bindings, ignored listing per whitelist
Aug  1 07:54:53.082: INFO: namespace e2e-tests-kubelet-test-tbrm6 deletion completed in 6.39975512s

• [SLOW TEST:7.616 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 07:54:53.131: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Aug  1 07:54:53.777: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-kctst,SelfLink:/api/v1/namespaces/e2e-tests-watch-kctst/configmaps/e2e-watch-test-resource-version,UID:a53c59c7-b431-11e9-8923-fa163ec474fb,ResourceVersion:7878,Generation:0,CreationTimestamp:2019-08-01 07:54:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug  1 07:54:54.235: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-kctst,SelfLink:/api/v1/namespaces/e2e-tests-watch-kctst/configmaps/e2e-watch-test-resource-version,UID:a53c59c7-b431-11e9-8923-fa163ec474fb,ResourceVersion:7879,Generation:0,CreationTimestamp:2019-08-01 07:54:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 07:54:54.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-kctst" for this suite.
Aug  1 07:55:00.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 07:55:00.474: INFO: namespace: e2e-tests-watch-kctst, resource: bindings, ignored listing per whitelist
Aug  1 07:55:00.480: INFO: namespace e2e-tests-watch-kctst deletion completed in 6.240918854s

• [SLOW TEST:7.349 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 07:55:00.484: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-447cd
Aug  1 07:55:18.888: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-447cd
STEP: checking the pod's current state and verifying that restartCount is present
Aug  1 07:55:18.891: INFO: Initial restart count of pod liveness-http is 0
Aug  1 07:55:38.968: INFO: Restart count of pod e2e-tests-container-probe-447cd/liveness-http is now 1 (20.076564897s elapsed)
Aug  1 07:55:59.024: INFO: Restart count of pod e2e-tests-container-probe-447cd/liveness-http is now 2 (40.13204639s elapsed)
Aug  1 07:56:19.363: INFO: Restart count of pod e2e-tests-container-probe-447cd/liveness-http is now 3 (1m0.470675489s elapsed)
Aug  1 07:56:39.477: INFO: Restart count of pod e2e-tests-container-probe-447cd/liveness-http is now 4 (1m20.585376391s elapsed)
Aug  1 07:57:39.598: INFO: Restart count of pod e2e-tests-container-probe-447cd/liveness-http is now 5 (2m20.706061187s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 07:57:39.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-447cd" for this suite.
Aug  1 07:57:46.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 07:57:46.317: INFO: namespace: e2e-tests-container-probe-447cd, resource: bindings, ignored listing per whitelist
Aug  1 07:57:46.559: INFO: namespace e2e-tests-container-probe-447cd deletion completed in 6.749412361s

• [SLOW TEST:166.076 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 07:57:46.568: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-0cd8ce59-b432-11e9-aec8-12de527cd1b8
STEP: Creating a pod to test consume secrets
Aug  1 07:57:46.889: INFO: Waiting up to 5m0s for pod "pod-secrets-0cdc13b9-b432-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-secrets-8cxv2" to be "success or failure"
Aug  1 07:57:46.916: INFO: Pod "pod-secrets-0cdc13b9-b432-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 25.819745ms
Aug  1 07:57:48.976: INFO: Pod "pod-secrets-0cdc13b9-b432-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.085939912s
Aug  1 07:57:50.979: INFO: Pod "pod-secrets-0cdc13b9-b432-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.089026234s
STEP: Saw pod success
Aug  1 07:57:50.979: INFO: Pod "pod-secrets-0cdc13b9-b432-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 07:57:50.981: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod pod-secrets-0cdc13b9-b432-11e9-aec8-12de527cd1b8 container secret-volume-test: <nil>
STEP: delete the pod
Aug  1 07:57:51.250: INFO: Waiting for pod pod-secrets-0cdc13b9-b432-11e9-aec8-12de527cd1b8 to disappear
Aug  1 07:57:51.274: INFO: Pod pod-secrets-0cdc13b9-b432-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 07:57:51.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-8cxv2" for this suite.
Aug  1 07:57:57.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 07:57:57.534: INFO: namespace: e2e-tests-secrets-8cxv2, resource: bindings, ignored listing per whitelist
Aug  1 07:57:57.577: INFO: namespace e2e-tests-secrets-8cxv2 deletion completed in 6.269060325s

• [SLOW TEST:11.009 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 07:57:57.595: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Aug  1 07:57:57.909: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug  1 07:57:58.096: INFO: Waiting for terminating namespaces to be deleted...
Aug  1 07:57:58.102: INFO: 
Logging pods the kubelet thinks is on node k8s-1-6lh7zebx7k5q-node-0 before test
Aug  1 07:57:58.444: INFO: sonobuoy-systemd-logs-daemon-set-2a51f081063e4123-xc965 from heptio-sonobuoy started at 2019-08-01 07:24:21 +0000 UTC (2 container statuses recorded)
Aug  1 07:57:58.445: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Aug  1 07:57:58.445: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug  1 07:57:58.445: INFO: coredns-5f559b869-jcg4r from kube-system started at 2019-08-01 07:18:52 +0000 UTC (1 container statuses recorded)
Aug  1 07:57:58.445: INFO: 	Container coredns ready: true, restart count 0
Aug  1 07:57:58.446: INFO: npd-q8998 from kube-system started at 2019-08-01 07:18:52 +0000 UTC (1 container statuses recorded)
Aug  1 07:57:58.446: INFO: 	Container node-problem-detector ready: true, restart count 0
Aug  1 07:57:58.447: INFO: sonobuoy from heptio-sonobuoy started at 2019-08-01 07:23:57 +0000 UTC (1 container statuses recorded)
Aug  1 07:57:58.447: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug  1 07:57:58.447: INFO: kube-dns-autoscaler-845f56f67b-s24x9 from kube-system started at 2019-08-01 07:18:52 +0000 UTC (1 container statuses recorded)
Aug  1 07:57:58.447: INFO: 	Container autoscaler ready: true, restart count 0
Aug  1 07:57:58.448: INFO: kubernetes-dashboard-f5496d66d-j22q5 from kube-system started at 2019-08-01 07:18:52 +0000 UTC (1 container statuses recorded)
Aug  1 07:57:58.448: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Aug  1 07:57:58.448: INFO: sonobuoy-e2e-job-d28e9b7acb7844b7 from heptio-sonobuoy started at 2019-08-01 07:24:19 +0000 UTC (2 container statuses recorded)
Aug  1 07:57:58.448: INFO: 	Container e2e ready: true, restart count 0
Aug  1 07:57:58.448: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug  1 07:57:58.448: INFO: calico-node-5v77h from kube-system started at 2019-08-01 07:18:04 +0000 UTC (2 container statuses recorded)
Aug  1 07:57:58.448: INFO: 	Container calico-node ready: true, restart count 0
Aug  1 07:57:58.448: INFO: 	Container install-cni ready: true, restart count 0
Aug  1 07:57:58.448: INFO: coredns-5f559b869-f68db from kube-system started at 2019-08-01 07:18:52 +0000 UTC (1 container statuses recorded)
Aug  1 07:57:58.449: INFO: 	Container coredns ready: true, restart count 0
Aug  1 07:57:58.449: INFO: heapster-796547984d-vjt7z from kube-system started at 2019-08-01 07:18:52 +0000 UTC (1 container statuses recorded)
Aug  1 07:57:58.449: INFO: 	Container heapster ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node k8s-1-6lh7zebx7k5q-node-0
Aug  1 07:57:58.606: INFO: Pod sonobuoy requesting resource cpu=0m on Node k8s-1-6lh7zebx7k5q-node-0
Aug  1 07:57:58.607: INFO: Pod sonobuoy-e2e-job-d28e9b7acb7844b7 requesting resource cpu=0m on Node k8s-1-6lh7zebx7k5q-node-0
Aug  1 07:57:58.607: INFO: Pod sonobuoy-systemd-logs-daemon-set-2a51f081063e4123-xc965 requesting resource cpu=0m on Node k8s-1-6lh7zebx7k5q-node-0
Aug  1 07:57:58.608: INFO: Pod calico-node-5v77h requesting resource cpu=250m on Node k8s-1-6lh7zebx7k5q-node-0
Aug  1 07:57:58.608: INFO: Pod coredns-5f559b869-f68db requesting resource cpu=100m on Node k8s-1-6lh7zebx7k5q-node-0
Aug  1 07:57:58.609: INFO: Pod coredns-5f559b869-jcg4r requesting resource cpu=100m on Node k8s-1-6lh7zebx7k5q-node-0
Aug  1 07:57:58.609: INFO: Pod heapster-796547984d-vjt7z requesting resource cpu=0m on Node k8s-1-6lh7zebx7k5q-node-0
Aug  1 07:57:58.611: INFO: Pod kube-dns-autoscaler-845f56f67b-s24x9 requesting resource cpu=20m on Node k8s-1-6lh7zebx7k5q-node-0
Aug  1 07:57:58.611: INFO: Pod kubernetes-dashboard-f5496d66d-j22q5 requesting resource cpu=0m on Node k8s-1-6lh7zebx7k5q-node-0
Aug  1 07:57:58.611: INFO: Pod npd-q8998 requesting resource cpu=20m on Node k8s-1-6lh7zebx7k5q-node-0
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-13dcd31d-b432-11e9-aec8-12de527cd1b8.15b6bd80129d7a78], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-p27mk/filler-pod-13dcd31d-b432-11e9-aec8-12de527cd1b8 to k8s-1-6lh7zebx7k5q-node-0]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-13dcd31d-b432-11e9-aec8-12de527cd1b8.15b6bd809daed3d7], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-13dcd31d-b432-11e9-aec8-12de527cd1b8.15b6bd80cbdcf131], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-13dcd31d-b432-11e9-aec8-12de527cd1b8.15b6bd80d67e37cd], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15b6bd810a647c87], Reason = [FailedScheduling], Message = [0/2 nodes are available: 1 Insufficient cpu, 1 node(s) had taints that the pod didn't tolerate.]
STEP: removing the label node off the node k8s-1-6lh7zebx7k5q-node-0
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 07:58:04.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-p27mk" for this suite.
Aug  1 07:58:12.267: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 07:58:12.732: INFO: namespace: e2e-tests-sched-pred-p27mk, resource: bindings, ignored listing per whitelist
Aug  1 07:58:12.764: INFO: namespace e2e-tests-sched-pred-p27mk deletion completed in 8.552302404s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:15.170 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 07:58:12.768: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-rb98
STEP: Creating a pod to test atomic-volume-subpath
Aug  1 07:58:13.406: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-rb98" in namespace "e2e-tests-subpath-lsfs9" to be "success or failure"
Aug  1 07:58:13.457: INFO: Pod "pod-subpath-test-secret-rb98": Phase="Pending", Reason="", readiness=false. Elapsed: 48.814325ms
Aug  1 07:58:15.523: INFO: Pod "pod-subpath-test-secret-rb98": Phase="Pending", Reason="", readiness=false. Elapsed: 2.115233855s
Aug  1 07:58:17.597: INFO: Pod "pod-subpath-test-secret-rb98": Phase="Pending", Reason="", readiness=false. Elapsed: 4.189108777s
Aug  1 07:58:19.600: INFO: Pod "pod-subpath-test-secret-rb98": Phase="Pending", Reason="", readiness=false. Elapsed: 6.191928486s
Aug  1 07:58:21.634: INFO: Pod "pod-subpath-test-secret-rb98": Phase="Running", Reason="", readiness=false. Elapsed: 8.225532379s
Aug  1 07:58:23.637: INFO: Pod "pod-subpath-test-secret-rb98": Phase="Running", Reason="", readiness=false. Elapsed: 10.228960959s
Aug  1 07:58:25.641: INFO: Pod "pod-subpath-test-secret-rb98": Phase="Running", Reason="", readiness=false. Elapsed: 12.232579431s
Aug  1 07:58:27.647: INFO: Pod "pod-subpath-test-secret-rb98": Phase="Running", Reason="", readiness=false. Elapsed: 14.238610143s
Aug  1 07:58:29.651: INFO: Pod "pod-subpath-test-secret-rb98": Phase="Running", Reason="", readiness=false. Elapsed: 16.243304293s
Aug  1 07:58:31.656: INFO: Pod "pod-subpath-test-secret-rb98": Phase="Running", Reason="", readiness=false. Elapsed: 18.247914232s
Aug  1 07:58:33.660: INFO: Pod "pod-subpath-test-secret-rb98": Phase="Running", Reason="", readiness=false. Elapsed: 20.251444442s
Aug  1 07:58:35.663: INFO: Pod "pod-subpath-test-secret-rb98": Phase="Running", Reason="", readiness=false. Elapsed: 22.254786041s
Aug  1 07:58:37.668: INFO: Pod "pod-subpath-test-secret-rb98": Phase="Running", Reason="", readiness=false. Elapsed: 24.259820039s
Aug  1 07:58:39.717: INFO: Pod "pod-subpath-test-secret-rb98": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.30856803s
STEP: Saw pod success
Aug  1 07:58:39.717: INFO: Pod "pod-subpath-test-secret-rb98" satisfied condition "success or failure"
Aug  1 07:58:39.718: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod pod-subpath-test-secret-rb98 container test-container-subpath-secret-rb98: <nil>
STEP: delete the pod
Aug  1 07:58:39.893: INFO: Waiting for pod pod-subpath-test-secret-rb98 to disappear
Aug  1 07:58:39.965: INFO: Pod pod-subpath-test-secret-rb98 no longer exists
STEP: Deleting pod pod-subpath-test-secret-rb98
Aug  1 07:58:39.975: INFO: Deleting pod "pod-subpath-test-secret-rb98" in namespace "e2e-tests-subpath-lsfs9"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 07:58:40.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-lsfs9" for this suite.
Aug  1 07:58:48.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 07:58:48.331: INFO: namespace: e2e-tests-subpath-lsfs9, resource: bindings, ignored listing per whitelist
Aug  1 07:58:48.389: INFO: namespace e2e-tests-subpath-lsfs9 deletion completed in 8.218876366s

• [SLOW TEST:35.622 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 07:58:48.394: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-31b417f4-b432-11e9-aec8-12de527cd1b8
Aug  1 07:58:48.916: INFO: Pod name my-hostname-basic-31b417f4-b432-11e9-aec8-12de527cd1b8: Found 0 pods out of 1
Aug  1 07:58:53.937: INFO: Pod name my-hostname-basic-31b417f4-b432-11e9-aec8-12de527cd1b8: Found 1 pods out of 1
Aug  1 07:58:53.937: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-31b417f4-b432-11e9-aec8-12de527cd1b8" are running
Aug  1 07:58:53.971: INFO: Pod "my-hostname-basic-31b417f4-b432-11e9-aec8-12de527cd1b8-rkmlr" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-01 07:58:49 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-01 07:58:53 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-01 07:58:53 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-01 07:58:48 +0000 UTC Reason: Message:}])
Aug  1 07:58:53.971: INFO: Trying to dial the pod
Aug  1 07:58:58.980: INFO: Controller my-hostname-basic-31b417f4-b432-11e9-aec8-12de527cd1b8: Got expected result from replica 1 [my-hostname-basic-31b417f4-b432-11e9-aec8-12de527cd1b8-rkmlr]: "my-hostname-basic-31b417f4-b432-11e9-aec8-12de527cd1b8-rkmlr", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 07:58:58.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-vmks7" for this suite.
Aug  1 07:59:07.025: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 07:59:07.125: INFO: namespace: e2e-tests-replication-controller-vmks7, resource: bindings, ignored listing per whitelist
Aug  1 07:59:07.172: INFO: namespace e2e-tests-replication-controller-vmks7 deletion completed in 8.189494049s

• [SLOW TEST:18.778 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 07:59:07.174: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-3cf07582-b432-11e9-aec8-12de527cd1b8
STEP: Creating a pod to test consume secrets
Aug  1 07:59:09.201: INFO: Waiting up to 5m0s for pod "pod-secrets-3de7ae5d-b432-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-secrets-vj2z5" to be "success or failure"
Aug  1 07:59:09.237: INFO: Pod "pod-secrets-3de7ae5d-b432-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 35.253766ms
Aug  1 07:59:11.260: INFO: Pod "pod-secrets-3de7ae5d-b432-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.058841119s
Aug  1 07:59:13.263: INFO: Pod "pod-secrets-3de7ae5d-b432-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.061340938s
STEP: Saw pod success
Aug  1 07:59:13.263: INFO: Pod "pod-secrets-3de7ae5d-b432-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 07:59:13.265: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod pod-secrets-3de7ae5d-b432-11e9-aec8-12de527cd1b8 container secret-volume-test: <nil>
STEP: delete the pod
Aug  1 07:59:13.302: INFO: Waiting for pod pod-secrets-3de7ae5d-b432-11e9-aec8-12de527cd1b8 to disappear
Aug  1 07:59:13.327: INFO: Pod pod-secrets-3de7ae5d-b432-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 07:59:13.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-vj2z5" for this suite.
Aug  1 07:59:21.421: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 07:59:21.501: INFO: namespace: e2e-tests-secrets-vj2z5, resource: bindings, ignored listing per whitelist
Aug  1 07:59:21.547: INFO: namespace e2e-tests-secrets-vj2z5 deletion completed in 8.215893087s
STEP: Destroying namespace "e2e-tests-secret-namespace-zgg9j" for this suite.
Aug  1 07:59:27.655: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 07:59:27.703: INFO: namespace: e2e-tests-secret-namespace-zgg9j, resource: bindings, ignored listing per whitelist
Aug  1 07:59:27.762: INFO: namespace e2e-tests-secret-namespace-zgg9j deletion completed in 6.214213411s

• [SLOW TEST:20.588 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 07:59:27.783: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-493d1b1e-b432-11e9-aec8-12de527cd1b8
STEP: Creating a pod to test consume configMaps
Aug  1 07:59:28.350: INFO: Waiting up to 5m0s for pod "pod-configmaps-4951cb85-b432-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-configmap-w4vc5" to be "success or failure"
Aug  1 07:59:28.519: INFO: Pod "pod-configmaps-4951cb85-b432-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 168.467728ms
Aug  1 07:59:30.590: INFO: Pod "pod-configmaps-4951cb85-b432-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.239470018s
Aug  1 07:59:32.593: INFO: Pod "pod-configmaps-4951cb85-b432-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.242065823s
STEP: Saw pod success
Aug  1 07:59:32.593: INFO: Pod "pod-configmaps-4951cb85-b432-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 07:59:32.594: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod pod-configmaps-4951cb85-b432-11e9-aec8-12de527cd1b8 container configmap-volume-test: <nil>
STEP: delete the pod
Aug  1 07:59:32.867: INFO: Waiting for pod pod-configmaps-4951cb85-b432-11e9-aec8-12de527cd1b8 to disappear
Aug  1 07:59:32.893: INFO: Pod pod-configmaps-4951cb85-b432-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 07:59:32.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-w4vc5" for this suite.
Aug  1 07:59:38.963: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 07:59:39.326: INFO: namespace: e2e-tests-configmap-w4vc5, resource: bindings, ignored listing per whitelist
Aug  1 07:59:39.330: INFO: namespace e2e-tests-configmap-w4vc5 deletion completed in 6.432142397s

• [SLOW TEST:11.548 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 07:59:39.334: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-50204749-b432-11e9-aec8-12de527cd1b8
STEP: Creating a pod to test consume configMaps
Aug  1 07:59:39.753: INFO: Waiting up to 5m0s for pod "pod-configmaps-5020d59b-b432-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-configmap-2qcw7" to be "success or failure"
Aug  1 07:59:39.810: INFO: Pod "pod-configmaps-5020d59b-b432-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 57.171255ms
Aug  1 07:59:41.974: INFO: Pod "pod-configmaps-5020d59b-b432-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.220714229s
Aug  1 07:59:43.977: INFO: Pod "pod-configmaps-5020d59b-b432-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.223350808s
STEP: Saw pod success
Aug  1 07:59:43.977: INFO: Pod "pod-configmaps-5020d59b-b432-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 07:59:43.978: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod pod-configmaps-5020d59b-b432-11e9-aec8-12de527cd1b8 container configmap-volume-test: <nil>
STEP: delete the pod
Aug  1 07:59:44.341: INFO: Waiting for pod pod-configmaps-5020d59b-b432-11e9-aec8-12de527cd1b8 to disappear
Aug  1 07:59:44.412: INFO: Pod pod-configmaps-5020d59b-b432-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 07:59:44.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-2qcw7" for this suite.
Aug  1 07:59:51.356: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 07:59:51.532: INFO: namespace: e2e-tests-configmap-2qcw7, resource: bindings, ignored listing per whitelist
Aug  1 07:59:51.731: INFO: namespace e2e-tests-configmap-2qcw7 deletion completed in 7.006579063s

• [SLOW TEST:12.401 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 07:59:51.736: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-n84n8
Aug  1 07:59:56.431: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-n84n8
STEP: checking the pod's current state and verifying that restartCount is present
Aug  1 07:59:56.436: INFO: Initial restart count of pod liveness-exec is 0
Aug  1 08:00:48.983: INFO: Restart count of pod e2e-tests-container-probe-n84n8/liveness-exec is now 1 (52.547334137s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:00:49.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-n84n8" for this suite.
Aug  1 08:00:55.204: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:00:55.302: INFO: namespace: e2e-tests-container-probe-n84n8, resource: bindings, ignored listing per whitelist
Aug  1 08:00:55.324: INFO: namespace e2e-tests-container-probe-n84n8 deletion completed in 6.156741613s

• [SLOW TEST:63.589 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:00:55.330: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-7d70493e-b432-11e9-aec8-12de527cd1b8
STEP: Creating a pod to test consume secrets
Aug  1 08:00:55.914: INFO: Waiting up to 5m0s for pod "pod-secrets-7d7150aa-b432-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-secrets-tqvvt" to be "success or failure"
Aug  1 08:00:56.300: INFO: Pod "pod-secrets-7d7150aa-b432-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 385.183645ms
Aug  1 08:00:58.302: INFO: Pod "pod-secrets-7d7150aa-b432-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.387877272s
Aug  1 08:01:00.306: INFO: Pod "pod-secrets-7d7150aa-b432-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.391574238s
STEP: Saw pod success
Aug  1 08:01:00.306: INFO: Pod "pod-secrets-7d7150aa-b432-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 08:01:00.308: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod pod-secrets-7d7150aa-b432-11e9-aec8-12de527cd1b8 container secret-volume-test: <nil>
STEP: delete the pod
Aug  1 08:01:00.627: INFO: Waiting for pod pod-secrets-7d7150aa-b432-11e9-aec8-12de527cd1b8 to disappear
Aug  1 08:01:00.685: INFO: Pod pod-secrets-7d7150aa-b432-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:01:00.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-tqvvt" for this suite.
Aug  1 08:01:06.790: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:01:06.858: INFO: namespace: e2e-tests-secrets-tqvvt, resource: bindings, ignored listing per whitelist
Aug  1 08:01:06.901: INFO: namespace e2e-tests-secrets-tqvvt deletion completed in 6.213397338s

• [SLOW TEST:11.571 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:01:06.906: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-84500ba1-b432-11e9-aec8-12de527cd1b8
STEP: Creating a pod to test consume configMaps
Aug  1 08:01:07.378: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-84544e42-b432-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-projected-658pj" to be "success or failure"
Aug  1 08:01:07.525: INFO: Pod "pod-projected-configmaps-84544e42-b432-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 147.090348ms
Aug  1 08:01:09.877: INFO: Pod "pod-projected-configmaps-84544e42-b432-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.49865703s
Aug  1 08:01:11.881: INFO: Pod "pod-projected-configmaps-84544e42-b432-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.50302581s
STEP: Saw pod success
Aug  1 08:01:11.882: INFO: Pod "pod-projected-configmaps-84544e42-b432-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 08:01:11.885: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod pod-projected-configmaps-84544e42-b432-11e9-aec8-12de527cd1b8 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug  1 08:01:12.335: INFO: Waiting for pod pod-projected-configmaps-84544e42-b432-11e9-aec8-12de527cd1b8 to disappear
Aug  1 08:01:12.489: INFO: Pod pod-projected-configmaps-84544e42-b432-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:01:12.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-658pj" for this suite.
Aug  1 08:01:18.574: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:01:18.655: INFO: namespace: e2e-tests-projected-658pj, resource: bindings, ignored listing per whitelist
Aug  1 08:01:18.683: INFO: namespace e2e-tests-projected-658pj deletion completed in 6.184361076s

• [SLOW TEST:11.779 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:01:18.687: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Aug  1 08:01:19.326: INFO: Waiting up to 5m0s for pod "var-expansion-8b6b8347-b432-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-var-expansion-m769q" to be "success or failure"
Aug  1 08:01:19.331: INFO: Pod "var-expansion-8b6b8347-b432-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 5.541406ms
Aug  1 08:01:21.371: INFO: Pod "var-expansion-8b6b8347-b432-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.045314983s
Aug  1 08:01:23.375: INFO: Pod "var-expansion-8b6b8347-b432-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.049525474s
STEP: Saw pod success
Aug  1 08:01:23.375: INFO: Pod "var-expansion-8b6b8347-b432-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 08:01:23.379: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod var-expansion-8b6b8347-b432-11e9-aec8-12de527cd1b8 container dapi-container: <nil>
STEP: delete the pod
Aug  1 08:01:23.657: INFO: Waiting for pod var-expansion-8b6b8347-b432-11e9-aec8-12de527cd1b8 to disappear
Aug  1 08:01:23.739: INFO: Pod var-expansion-8b6b8347-b432-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:01:23.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-m769q" for this suite.
Aug  1 08:01:29.943: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:01:30.095: INFO: namespace: e2e-tests-var-expansion-m769q, resource: bindings, ignored listing per whitelist
Aug  1 08:01:30.233: INFO: namespace e2e-tests-var-expansion-m769q deletion completed in 6.376792369s

• [SLOW TEST:11.547 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:01:30.236: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug  1 08:01:30.624: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 version'
Aug  1 08:01:31.189: INFO: stderr: ""
Aug  1 08:01:31.189: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.7\", GitCommit:\"4683545293d792934a7a7e12f2cc47d20b2dd01b\", GitTreeState:\"clean\", BuildDate:\"2019-06-06T01:39:30Z\", GoVersion:\"go1.11.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:01:31.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-lzbgl" for this suite.
Aug  1 08:01:37.233: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:01:37.320: INFO: namespace: e2e-tests-kubectl-lzbgl, resource: bindings, ignored listing per whitelist
Aug  1 08:01:37.340: INFO: namespace e2e-tests-kubectl-lzbgl deletion completed in 6.147918512s

• [SLOW TEST:7.104 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:01:37.341: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-966b82bf-b432-11e9-aec8-12de527cd1b8
STEP: Creating secret with name s-test-opt-upd-966b83ed-b432-11e9-aec8-12de527cd1b8
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-966b82bf-b432-11e9-aec8-12de527cd1b8
STEP: Updating secret s-test-opt-upd-966b83ed-b432-11e9-aec8-12de527cd1b8
STEP: Creating secret with name s-test-opt-create-966b843c-b432-11e9-aec8-12de527cd1b8
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:03:15.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-shk2x" for this suite.
Aug  1 08:03:39.221: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:03:39.287: INFO: namespace: e2e-tests-secrets-shk2x, resource: bindings, ignored listing per whitelist
Aug  1 08:03:39.331: INFO: namespace e2e-tests-secrets-shk2x deletion completed in 24.206698596s

• [SLOW TEST:121.991 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:03:39.357: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Aug  1 08:03:47.958: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug  1 08:03:47.977: INFO: Pod pod-with-poststart-http-hook still exists
Aug  1 08:03:49.977: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug  1 08:03:50.002: INFO: Pod pod-with-poststart-http-hook still exists
Aug  1 08:03:51.978: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug  1 08:03:51.981: INFO: Pod pod-with-poststart-http-hook still exists
Aug  1 08:03:53.978: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug  1 08:03:53.980: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:03:53.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-5246r" for this suite.
Aug  1 08:04:20.031: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:04:20.077: INFO: namespace: e2e-tests-container-lifecycle-hook-5246r, resource: bindings, ignored listing per whitelist
Aug  1 08:04:20.181: INFO: namespace e2e-tests-container-lifecycle-hook-5246r deletion completed in 26.197005739s

• [SLOW TEST:40.826 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:04:20.185: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0801 08:04:30.915315      12 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug  1 08:04:30.923: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:04:30.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-jz5lr" for this suite.
Aug  1 08:04:38.983: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:04:39.063: INFO: namespace: e2e-tests-gc-jz5lr, resource: bindings, ignored listing per whitelist
Aug  1 08:04:39.112: INFO: namespace e2e-tests-gc-jz5lr deletion completed in 8.185090459s

• [SLOW TEST:18.927 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:04:39.113: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug  1 08:04:39.512: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Aug  1 08:04:39.726: INFO: Number of nodes with available pods: 0
Aug  1 08:04:39.726: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Aug  1 08:04:39.894: INFO: Number of nodes with available pods: 0
Aug  1 08:04:39.895: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:04:40.899: INFO: Number of nodes with available pods: 0
Aug  1 08:04:40.899: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:04:41.965: INFO: Number of nodes with available pods: 0
Aug  1 08:04:41.965: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:04:43.014: INFO: Number of nodes with available pods: 0
Aug  1 08:04:43.015: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:04:43.899: INFO: Number of nodes with available pods: 0
Aug  1 08:04:43.899: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:04:44.902: INFO: Number of nodes with available pods: 1
Aug  1 08:04:44.902: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Aug  1 08:04:44.973: INFO: Number of nodes with available pods: 1
Aug  1 08:04:44.974: INFO: Number of running nodes: 0, number of available pods: 1
Aug  1 08:04:46.165: INFO: Number of nodes with available pods: 0
Aug  1 08:04:46.165: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Aug  1 08:04:46.259: INFO: Number of nodes with available pods: 0
Aug  1 08:04:46.259: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:04:47.265: INFO: Number of nodes with available pods: 0
Aug  1 08:04:47.265: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:04:48.326: INFO: Number of nodes with available pods: 0
Aug  1 08:04:48.326: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:04:49.263: INFO: Number of nodes with available pods: 0
Aug  1 08:04:49.263: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:04:50.265: INFO: Number of nodes with available pods: 0
Aug  1 08:04:50.265: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:04:51.264: INFO: Number of nodes with available pods: 0
Aug  1 08:04:51.264: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:04:52.285: INFO: Number of nodes with available pods: 0
Aug  1 08:04:52.285: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:04:53.264: INFO: Number of nodes with available pods: 0
Aug  1 08:04:53.264: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:04:54.265: INFO: Number of nodes with available pods: 0
Aug  1 08:04:54.265: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:04:55.265: INFO: Number of nodes with available pods: 0
Aug  1 08:04:55.265: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:04:56.262: INFO: Number of nodes with available pods: 0
Aug  1 08:04:56.263: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:04:57.263: INFO: Number of nodes with available pods: 0
Aug  1 08:04:57.264: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:04:58.289: INFO: Number of nodes with available pods: 0
Aug  1 08:04:58.289: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:04:59.323: INFO: Number of nodes with available pods: 0
Aug  1 08:04:59.324: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:05:00.281: INFO: Number of nodes with available pods: 0
Aug  1 08:05:00.281: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:05:01.263: INFO: Number of nodes with available pods: 0
Aug  1 08:05:01.263: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:05:02.300: INFO: Number of nodes with available pods: 0
Aug  1 08:05:02.300: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:05:03.276: INFO: Number of nodes with available pods: 0
Aug  1 08:05:03.276: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:05:04.262: INFO: Number of nodes with available pods: 0
Aug  1 08:05:04.263: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:05:05.264: INFO: Number of nodes with available pods: 0
Aug  1 08:05:05.264: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:05:06.264: INFO: Number of nodes with available pods: 0
Aug  1 08:05:06.264: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:05:07.289: INFO: Number of nodes with available pods: 0
Aug  1 08:05:07.289: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:05:08.262: INFO: Number of nodes with available pods: 0
Aug  1 08:05:08.262: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:05:09.264: INFO: Number of nodes with available pods: 0
Aug  1 08:05:09.265: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:05:10.265: INFO: Number of nodes with available pods: 0
Aug  1 08:05:10.265: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:05:11.265: INFO: Number of nodes with available pods: 0
Aug  1 08:05:11.265: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:05:12.262: INFO: Number of nodes with available pods: 0
Aug  1 08:05:12.262: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:05:13.265: INFO: Number of nodes with available pods: 0
Aug  1 08:05:13.265: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:05:14.265: INFO: Number of nodes with available pods: 0
Aug  1 08:05:14.265: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:05:15.265: INFO: Number of nodes with available pods: 0
Aug  1 08:05:15.265: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:05:16.276: INFO: Number of nodes with available pods: 0
Aug  1 08:05:16.276: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:05:17.262: INFO: Number of nodes with available pods: 0
Aug  1 08:05:17.262: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:05:18.264: INFO: Number of nodes with available pods: 0
Aug  1 08:05:18.264: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:05:19.338: INFO: Number of nodes with available pods: 0
Aug  1 08:05:19.338: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:05:20.300: INFO: Number of nodes with available pods: 0
Aug  1 08:05:20.300: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:05:21.312: INFO: Number of nodes with available pods: 0
Aug  1 08:05:21.312: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:05:22.264: INFO: Number of nodes with available pods: 1
Aug  1 08:05:22.271: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-vhf2r, will wait for the garbage collector to delete the pods
Aug  1 08:05:22.594: INFO: Deleting DaemonSet.extensions daemon-set took: 47.111003ms
Aug  1 08:05:22.695: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.508755ms
Aug  1 08:05:57.198: INFO: Number of nodes with available pods: 0
Aug  1 08:05:57.198: INFO: Number of running nodes: 0, number of available pods: 0
Aug  1 08:05:57.201: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-vhf2r/daemonsets","resourceVersion":"9674"},"items":null}

Aug  1 08:05:57.202: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-vhf2r/pods","resourceVersion":"9674"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:05:57.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-vhf2r" for this suite.
Aug  1 08:06:05.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:06:05.442: INFO: namespace: e2e-tests-daemonsets-vhf2r, resource: bindings, ignored listing per whitelist
Aug  1 08:06:05.459: INFO: namespace e2e-tests-daemonsets-vhf2r deletion completed in 8.133778059s

• [SLOW TEST:86.347 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:06:05.462: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:06:12.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-8ld4m" for this suite.
Aug  1 08:06:19.174: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:06:19.451: INFO: namespace: e2e-tests-namespaces-8ld4m, resource: bindings, ignored listing per whitelist
Aug  1 08:06:19.503: INFO: namespace e2e-tests-namespaces-8ld4m deletion completed in 6.702415353s
STEP: Destroying namespace "e2e-tests-nsdeletetest-wpsqf" for this suite.
Aug  1 08:06:19.505: INFO: Namespace e2e-tests-nsdeletetest-wpsqf was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-nlbtl" for this suite.
Aug  1 08:06:25.798: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:06:25.863: INFO: namespace: e2e-tests-nsdeletetest-nlbtl, resource: bindings, ignored listing per whitelist
Aug  1 08:06:25.899: INFO: namespace e2e-tests-nsdeletetest-nlbtl deletion completed in 6.393942563s

• [SLOW TEST:20.438 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:06:25.903: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-zqrdz
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug  1 08:06:26.301: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug  1 08:07:06.587: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.1.105:8080/dial?request=hostName&protocol=http&host=192.168.1.104&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-zqrdz PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  1 08:07:06.587: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
Aug  1 08:07:07.407: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:07:07.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-zqrdz" for this suite.
Aug  1 08:07:33.715: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:07:33.801: INFO: namespace: e2e-tests-pod-network-test-zqrdz, resource: bindings, ignored listing per whitelist
Aug  1 08:07:33.890: INFO: namespace e2e-tests-pod-network-test-zqrdz deletion completed in 26.467846779s

• [SLOW TEST:67.987 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:07:33.891: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Aug  1 08:07:34.329: INFO: Waiting up to 5m0s for pod "pod-6afefa39-b433-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-emptydir-q2w5h" to be "success or failure"
Aug  1 08:07:34.354: INFO: Pod "pod-6afefa39-b433-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 24.71922ms
Aug  1 08:07:36.582: INFO: Pod "pod-6afefa39-b433-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.25232746s
Aug  1 08:07:38.585: INFO: Pod "pod-6afefa39-b433-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.255170854s
STEP: Saw pod success
Aug  1 08:07:38.585: INFO: Pod "pod-6afefa39-b433-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 08:07:38.587: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod pod-6afefa39-b433-11e9-aec8-12de527cd1b8 container test-container: <nil>
STEP: delete the pod
Aug  1 08:07:38.852: INFO: Waiting for pod pod-6afefa39-b433-11e9-aec8-12de527cd1b8 to disappear
Aug  1 08:07:39.250: INFO: Pod pod-6afefa39-b433-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:07:39.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-q2w5h" for this suite.
Aug  1 08:07:46.247: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:07:46.303: INFO: namespace: e2e-tests-emptydir-q2w5h, resource: bindings, ignored listing per whitelist
Aug  1 08:07:46.339: INFO: namespace e2e-tests-emptydir-q2w5h deletion completed in 6.468173066s

• [SLOW TEST:12.449 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:07:46.343: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:08:46.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-5bfb9" for this suite.
Aug  1 08:09:10.796: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:09:10.846: INFO: namespace: e2e-tests-container-probe-5bfb9, resource: bindings, ignored listing per whitelist
Aug  1 08:09:10.935: INFO: namespace e2e-tests-container-probe-5bfb9 deletion completed in 24.229376482s

• [SLOW TEST:84.593 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:09:10.937: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Aug  1 08:09:11.394: INFO: Waiting up to 5m0s for pod "client-containers-a4cdfd9e-b433-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-containers-rnqgg" to be "success or failure"
Aug  1 08:09:11.436: INFO: Pod "client-containers-a4cdfd9e-b433-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 42.274904ms
Aug  1 08:09:13.440: INFO: Pod "client-containers-a4cdfd9e-b433-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.046164331s
Aug  1 08:09:15.445: INFO: Pod "client-containers-a4cdfd9e-b433-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.050765744s
Aug  1 08:09:17.449: INFO: Pod "client-containers-a4cdfd9e-b433-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.055148363s
STEP: Saw pod success
Aug  1 08:09:17.449: INFO: Pod "client-containers-a4cdfd9e-b433-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 08:09:17.453: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod client-containers-a4cdfd9e-b433-11e9-aec8-12de527cd1b8 container test-container: <nil>
STEP: delete the pod
Aug  1 08:09:17.524: INFO: Waiting for pod client-containers-a4cdfd9e-b433-11e9-aec8-12de527cd1b8 to disappear
Aug  1 08:09:17.552: INFO: Pod client-containers-a4cdfd9e-b433-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:09:17.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-rnqgg" for this suite.
Aug  1 08:09:25.671: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:09:25.782: INFO: namespace: e2e-tests-containers-rnqgg, resource: bindings, ignored listing per whitelist
Aug  1 08:09:25.790: INFO: namespace e2e-tests-containers-rnqgg deletion completed in 8.230597617s

• [SLOW TEST:14.853 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:09:25.795: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Aug  1 08:09:26.084: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-6ntn2" to be "success or failure"
Aug  1 08:09:26.344: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 257.964203ms
Aug  1 08:09:28.682: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.5957497s
Aug  1 08:09:30.689: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 4.602870319s
Aug  1 08:09:32.692: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.60594782s
STEP: Saw pod success
Aug  1 08:09:32.692: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Aug  1 08:09:32.695: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Aug  1 08:09:32.864: INFO: Waiting for pod pod-host-path-test to disappear
Aug  1 08:09:32.889: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:09:32.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-6ntn2" for this suite.
Aug  1 08:09:38.943: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:09:39.379: INFO: namespace: e2e-tests-hostpath-6ntn2, resource: bindings, ignored listing per whitelist
Aug  1 08:09:39.425: INFO: namespace e2e-tests-hostpath-6ntn2 deletion completed in 6.533028348s

• [SLOW TEST:13.630 seconds]
[sig-storage] HostPath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:09:39.430: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-b5d17c61-b433-11e9-aec8-12de527cd1b8
STEP: Creating configMap with name cm-test-opt-upd-b5d17caa-b433-11e9-aec8-12de527cd1b8
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-b5d17c61-b433-11e9-aec8-12de527cd1b8
STEP: Updating configmap cm-test-opt-upd-b5d17caa-b433-11e9-aec8-12de527cd1b8
STEP: Creating configMap with name cm-test-opt-create-b5d17d29-b433-11e9-aec8-12de527cd1b8
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:10:51.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-76p2c" for this suite.
Aug  1 08:11:15.363: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:11:15.393: INFO: namespace: e2e-tests-projected-76p2c, resource: bindings, ignored listing per whitelist
Aug  1 08:11:15.501: INFO: namespace e2e-tests-projected-76p2c deletion completed in 24.221504396s

• [SLOW TEST:96.071 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:11:15.501: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Aug  1 08:11:22.202: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-ef00cb64-b433-11e9-aec8-12de527cd1b8", GenerateName:"", Namespace:"e2e-tests-pods-nkgb5", SelfLink:"/api/v1/namespaces/e2e-tests-pods-nkgb5/pods/pod-submit-remove-ef00cb64-b433-11e9-aec8-12de527cd1b8", UID:"eec95907-b433-11e9-8923-fa163ec474fb", ResourceVersion:"10538", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63700243875, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"764935684"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"192.168.1.111/32"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-75zcm", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001211a40), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-75zcm", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0015a5d28), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"k8s-1-6lh7zebx7k5q-node-0", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001d75ce0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0015a5d60)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0015a5d80)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0015a5d88)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700243876, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700243880, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700243880, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700243875, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.0.0.23", PodIP:"192.168.1.111", StartTime:(*v1.Time)(0xc0026f8860), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc0026f8880), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"docker.io/nginx:1.14-alpine", ImageID:"docker-pullable://docker.io/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7", ContainerID:"docker://4877cd23cace1157da9275073be68b5effad68a6c500e112647b745873e87964"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Aug  1 08:11:27.241: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:11:27.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-nkgb5" for this suite.
Aug  1 08:11:35.362: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:11:35.430: INFO: namespace: e2e-tests-pods-nkgb5, resource: bindings, ignored listing per whitelist
Aug  1 08:11:35.497: INFO: namespace e2e-tests-pods-nkgb5 deletion completed in 8.245965878s

• [SLOW TEST:19.995 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:11:35.501: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug  1 08:11:35.807: INFO: Waiting up to 5m0s for pod "downwardapi-volume-faf17bc6-b433-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-downward-api-frs7g" to be "success or failure"
Aug  1 08:11:35.871: INFO: Pod "downwardapi-volume-faf17bc6-b433-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 50.578834ms
Aug  1 08:11:37.875: INFO: Pod "downwardapi-volume-faf17bc6-b433-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05389045s
Aug  1 08:11:39.880: INFO: Pod "downwardapi-volume-faf17bc6-b433-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.059208848s
Aug  1 08:11:41.888: INFO: Pod "downwardapi-volume-faf17bc6-b433-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.067626913s
STEP: Saw pod success
Aug  1 08:11:41.889: INFO: Pod "downwardapi-volume-faf17bc6-b433-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 08:11:41.893: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod downwardapi-volume-faf17bc6-b433-11e9-aec8-12de527cd1b8 container client-container: <nil>
STEP: delete the pod
Aug  1 08:11:41.946: INFO: Waiting for pod downwardapi-volume-faf17bc6-b433-11e9-aec8-12de527cd1b8 to disappear
Aug  1 08:11:41.980: INFO: Pod downwardapi-volume-faf17bc6-b433-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:11:41.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-frs7g" for this suite.
Aug  1 08:11:48.108: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:11:48.207: INFO: namespace: e2e-tests-downward-api-frs7g, resource: bindings, ignored listing per whitelist
Aug  1 08:11:48.218: INFO: namespace e2e-tests-downward-api-frs7g deletion completed in 6.234055663s

• [SLOW TEST:12.717 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:11:48.224: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Aug  1 08:11:48.544: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 --namespace=e2e-tests-kubectl-f6njl run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Aug  1 08:11:58.018: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Aug  1 08:11:58.018: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:12:00.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-f6njl" for this suite.
Aug  1 08:12:06.150: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:12:06.240: INFO: namespace: e2e-tests-kubectl-f6njl, resource: bindings, ignored listing per whitelist
Aug  1 08:12:06.350: INFO: namespace e2e-tests-kubectl-f6njl deletion completed in 6.319889909s

• [SLOW TEST:18.127 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:12:06.352: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Aug  1 08:12:06.686: INFO: Waiting up to 5m0s for pod "downward-api-0d558ae8-b434-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-downward-api-l4w9k" to be "success or failure"
Aug  1 08:12:06.720: INFO: Pod "downward-api-0d558ae8-b434-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 33.849837ms
Aug  1 08:12:08.726: INFO: Pod "downward-api-0d558ae8-b434-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039332919s
Aug  1 08:12:10.732: INFO: Pod "downward-api-0d558ae8-b434-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.045454778s
STEP: Saw pod success
Aug  1 08:12:10.732: INFO: Pod "downward-api-0d558ae8-b434-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 08:12:10.738: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod downward-api-0d558ae8-b434-11e9-aec8-12de527cd1b8 container dapi-container: <nil>
STEP: delete the pod
Aug  1 08:12:10.940: INFO: Waiting for pod downward-api-0d558ae8-b434-11e9-aec8-12de527cd1b8 to disappear
Aug  1 08:12:10.963: INFO: Pod downward-api-0d558ae8-b434-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:12:10.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-l4w9k" for this suite.
Aug  1 08:12:17.098: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:12:17.190: INFO: namespace: e2e-tests-downward-api-l4w9k, resource: bindings, ignored listing per whitelist
Aug  1 08:12:17.259: INFO: namespace e2e-tests-downward-api-l4w9k deletion completed in 6.255635848s

• [SLOW TEST:10.908 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:12:17.264: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-13d107b5-b434-11e9-aec8-12de527cd1b8
STEP: Creating a pod to test consume configMaps
Aug  1 08:12:17.661: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-13e04976-b434-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-projected-plxr8" to be "success or failure"
Aug  1 08:12:17.798: INFO: Pod "pod-projected-configmaps-13e04976-b434-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 136.066945ms
Aug  1 08:12:19.854: INFO: Pod "pod-projected-configmaps-13e04976-b434-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.192056858s
Aug  1 08:12:21.881: INFO: Pod "pod-projected-configmaps-13e04976-b434-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.219615381s
STEP: Saw pod success
Aug  1 08:12:21.881: INFO: Pod "pod-projected-configmaps-13e04976-b434-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 08:12:21.887: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod pod-projected-configmaps-13e04976-b434-11e9-aec8-12de527cd1b8 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug  1 08:12:22.411: INFO: Waiting for pod pod-projected-configmaps-13e04976-b434-11e9-aec8-12de527cd1b8 to disappear
Aug  1 08:12:23.009: INFO: Pod pod-projected-configmaps-13e04976-b434-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:12:23.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-plxr8" for this suite.
Aug  1 08:12:29.302: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:12:29.485: INFO: namespace: e2e-tests-projected-plxr8, resource: bindings, ignored listing per whitelist
Aug  1 08:12:29.509: INFO: namespace e2e-tests-projected-plxr8 deletion completed in 6.495692664s

• [SLOW TEST:12.246 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:12:29.514: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Aug  1 08:12:34.386: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:13:02.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-4brmg" for this suite.
Aug  1 08:13:08.488: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:13:08.862: INFO: namespace: e2e-tests-namespaces-4brmg, resource: bindings, ignored listing per whitelist
Aug  1 08:13:08.869: INFO: namespace e2e-tests-namespaces-4brmg deletion completed in 6.536771394s
STEP: Destroying namespace "e2e-tests-nsdeletetest-lmct6" for this suite.
Aug  1 08:13:08.875: INFO: Namespace e2e-tests-nsdeletetest-lmct6 was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-hf6df" for this suite.
Aug  1 08:13:14.918: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:13:15.016: INFO: namespace: e2e-tests-nsdeletetest-hf6df, resource: bindings, ignored listing per whitelist
Aug  1 08:13:15.161: INFO: namespace e2e-tests-nsdeletetest-hf6df deletion completed in 6.286178625s

• [SLOW TEST:45.648 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:13:15.167: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-fg9lk
Aug  1 08:13:19.622: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-fg9lk
STEP: checking the pod's current state and verifying that restartCount is present
Aug  1 08:13:19.626: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:17:20.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-fg9lk" for this suite.
Aug  1 08:17:26.175: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:17:26.287: INFO: namespace: e2e-tests-container-probe-fg9lk, resource: bindings, ignored listing per whitelist
Aug  1 08:17:26.410: INFO: namespace e2e-tests-container-probe-fg9lk deletion completed in 6.348464159s

• [SLOW TEST:251.243 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:17:26.413: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Aug  1 08:17:26.761: INFO: Waiting up to 5m0s for pod "client-containers-cc15c9f8-b434-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-containers-x66sg" to be "success or failure"
Aug  1 08:17:26.961: INFO: Pod "client-containers-cc15c9f8-b434-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 199.930264ms
Aug  1 08:17:29.236: INFO: Pod "client-containers-cc15c9f8-b434-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.4749225s
Aug  1 08:17:31.241: INFO: Pod "client-containers-cc15c9f8-b434-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.480455885s
STEP: Saw pod success
Aug  1 08:17:31.241: INFO: Pod "client-containers-cc15c9f8-b434-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 08:17:31.245: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod client-containers-cc15c9f8-b434-11e9-aec8-12de527cd1b8 container test-container: <nil>
STEP: delete the pod
Aug  1 08:17:31.307: INFO: Waiting for pod client-containers-cc15c9f8-b434-11e9-aec8-12de527cd1b8 to disappear
Aug  1 08:17:31.329: INFO: Pod client-containers-cc15c9f8-b434-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:17:31.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-x66sg" for this suite.
Aug  1 08:17:37.458: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:17:37.588: INFO: namespace: e2e-tests-containers-x66sg, resource: bindings, ignored listing per whitelist
Aug  1 08:17:37.588: INFO: namespace e2e-tests-containers-x66sg deletion completed in 6.199217451s

• [SLOW TEST:11.175 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:17:37.591: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-d2bc4f9e-b434-11e9-aec8-12de527cd1b8
STEP: Creating a pod to test consume secrets
Aug  1 08:17:38.018: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d2bfe995-b434-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-projected-ts2tl" to be "success or failure"
Aug  1 08:17:38.629: INFO: Pod "pod-projected-secrets-d2bfe995-b434-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 610.695093ms
Aug  1 08:17:40.632: INFO: Pod "pod-projected-secrets-d2bfe995-b434-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.613095256s
Aug  1 08:17:42.636: INFO: Pod "pod-projected-secrets-d2bfe995-b434-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.6175973s
Aug  1 08:17:44.788: INFO: Pod "pod-projected-secrets-d2bfe995-b434-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.769202981s
STEP: Saw pod success
Aug  1 08:17:44.788: INFO: Pod "pod-projected-secrets-d2bfe995-b434-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 08:17:44.790: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod pod-projected-secrets-d2bfe995-b434-11e9-aec8-12de527cd1b8 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug  1 08:17:45.525: INFO: Waiting for pod pod-projected-secrets-d2bfe995-b434-11e9-aec8-12de527cd1b8 to disappear
Aug  1 08:17:45.750: INFO: Pod pod-projected-secrets-d2bfe995-b434-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:17:45.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ts2tl" for this suite.
Aug  1 08:17:51.820: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:17:51.899: INFO: namespace: e2e-tests-projected-ts2tl, resource: bindings, ignored listing per whitelist
Aug  1 08:17:52.050: INFO: namespace e2e-tests-projected-ts2tl deletion completed in 6.296049108s

• [SLOW TEST:14.460 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:17:52.056: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Aug  1 08:17:52.529: INFO: namespace e2e-tests-kubectl-f9k87
Aug  1 08:17:52.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 create -f - --namespace=e2e-tests-kubectl-f9k87'
Aug  1 08:17:53.744: INFO: stderr: ""
Aug  1 08:17:53.745: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Aug  1 08:17:54.749: INFO: Selector matched 1 pods for map[app:redis]
Aug  1 08:17:54.749: INFO: Found 0 / 1
Aug  1 08:17:55.748: INFO: Selector matched 1 pods for map[app:redis]
Aug  1 08:17:55.748: INFO: Found 0 / 1
Aug  1 08:17:56.893: INFO: Selector matched 1 pods for map[app:redis]
Aug  1 08:17:56.893: INFO: Found 0 / 1
Aug  1 08:17:57.748: INFO: Selector matched 1 pods for map[app:redis]
Aug  1 08:17:57.748: INFO: Found 0 / 1
Aug  1 08:17:58.800: INFO: Selector matched 1 pods for map[app:redis]
Aug  1 08:17:58.801: INFO: Found 1 / 1
Aug  1 08:17:58.801: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug  1 08:17:58.804: INFO: Selector matched 1 pods for map[app:redis]
Aug  1 08:17:58.804: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug  1 08:17:58.805: INFO: wait on redis-master startup in e2e-tests-kubectl-f9k87 
Aug  1 08:17:58.805: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 logs redis-master-zzg9b redis-master --namespace=e2e-tests-kubectl-f9k87'
Aug  1 08:17:59.159: INFO: stderr: ""
Aug  1 08:17:59.159: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 01 Aug 08:17:57.502 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 01 Aug 08:17:57.513 # Server started, Redis version 3.2.12\n1:M 01 Aug 08:17:57.513 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 01 Aug 08:17:57.513 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Aug  1 08:17:59.159: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-f9k87'
Aug  1 08:17:59.535: INFO: stderr: ""
Aug  1 08:17:59.535: INFO: stdout: "service/rm2 exposed\n"
Aug  1 08:17:59.560: INFO: Service rm2 in namespace e2e-tests-kubectl-f9k87 found.
STEP: exposing service
Aug  1 08:18:01.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-f9k87'
Aug  1 08:18:01.787: INFO: stderr: ""
Aug  1 08:18:01.787: INFO: stdout: "service/rm3 exposed\n"
Aug  1 08:18:01.954: INFO: Service rm3 in namespace e2e-tests-kubectl-f9k87 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:18:03.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-f9k87" for this suite.
Aug  1 08:18:28.015: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:18:28.163: INFO: namespace: e2e-tests-kubectl-f9k87, resource: bindings, ignored listing per whitelist
Aug  1 08:18:28.169: INFO: namespace e2e-tests-kubectl-f9k87 deletion completed in 24.204674942s

• [SLOW TEST:36.114 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:18:28.178: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug  1 08:18:28.618: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f0fbd3f2-b434-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-downward-api-zth7x" to be "success or failure"
Aug  1 08:18:28.649: INFO: Pod "downwardapi-volume-f0fbd3f2-b434-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 30.218635ms
Aug  1 08:18:30.659: INFO: Pod "downwardapi-volume-f0fbd3f2-b434-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040503056s
Aug  1 08:18:32.669: INFO: Pod "downwardapi-volume-f0fbd3f2-b434-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050043296s
STEP: Saw pod success
Aug  1 08:18:32.675: INFO: Pod "downwardapi-volume-f0fbd3f2-b434-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 08:18:32.697: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod downwardapi-volume-f0fbd3f2-b434-11e9-aec8-12de527cd1b8 container client-container: <nil>
STEP: delete the pod
Aug  1 08:18:32.825: INFO: Waiting for pod downwardapi-volume-f0fbd3f2-b434-11e9-aec8-12de527cd1b8 to disappear
Aug  1 08:18:32.839: INFO: Pod downwardapi-volume-f0fbd3f2-b434-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:18:32.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-zth7x" for this suite.
Aug  1 08:18:38.942: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:18:39.202: INFO: namespace: e2e-tests-downward-api-zth7x, resource: bindings, ignored listing per whitelist
Aug  1 08:18:39.205: INFO: namespace e2e-tests-downward-api-zth7x deletion completed in 6.363336482s

• [SLOW TEST:11.027 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:18:39.210: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-f7863591-b434-11e9-aec8-12de527cd1b8
STEP: Creating a pod to test consume configMaps
Aug  1 08:18:39.647: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f78a9880-b434-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-projected-vh6nw" to be "success or failure"
Aug  1 08:18:39.772: INFO: Pod "pod-projected-configmaps-f78a9880-b434-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 124.204418ms
Aug  1 08:18:41.774: INFO: Pod "pod-projected-configmaps-f78a9880-b434-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.126929787s
Aug  1 08:18:43.781: INFO: Pod "pod-projected-configmaps-f78a9880-b434-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.133361411s
STEP: Saw pod success
Aug  1 08:18:43.782: INFO: Pod "pod-projected-configmaps-f78a9880-b434-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 08:18:43.786: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod pod-projected-configmaps-f78a9880-b434-11e9-aec8-12de527cd1b8 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug  1 08:18:43.899: INFO: Waiting for pod pod-projected-configmaps-f78a9880-b434-11e9-aec8-12de527cd1b8 to disappear
Aug  1 08:18:43.922: INFO: Pod pod-projected-configmaps-f78a9880-b434-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:18:43.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vh6nw" for this suite.
Aug  1 08:18:50.059: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:18:50.166: INFO: namespace: e2e-tests-projected-vh6nw, resource: bindings, ignored listing per whitelist
Aug  1 08:18:50.381: INFO: namespace e2e-tests-projected-vh6nw deletion completed in 6.454325936s

• [SLOW TEST:11.172 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:18:50.387: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Aug  1 08:19:00.849: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug  1 08:19:00.995: INFO: Pod pod-with-prestop-exec-hook still exists
Aug  1 08:19:02.995: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug  1 08:19:03.000: INFO: Pod pod-with-prestop-exec-hook still exists
Aug  1 08:19:04.995: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug  1 08:19:05.000: INFO: Pod pod-with-prestop-exec-hook still exists
Aug  1 08:19:06.995: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug  1 08:19:07.000: INFO: Pod pod-with-prestop-exec-hook still exists
Aug  1 08:19:08.995: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug  1 08:19:08.999: INFO: Pod pod-with-prestop-exec-hook still exists
Aug  1 08:19:10.995: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug  1 08:19:11.000: INFO: Pod pod-with-prestop-exec-hook still exists
Aug  1 08:19:12.995: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug  1 08:19:12.999: INFO: Pod pod-with-prestop-exec-hook still exists
Aug  1 08:19:14.995: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug  1 08:19:14.998: INFO: Pod pod-with-prestop-exec-hook still exists
Aug  1 08:19:16.995: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug  1 08:19:16.998: INFO: Pod pod-with-prestop-exec-hook still exists
Aug  1 08:19:18.995: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug  1 08:19:19.053: INFO: Pod pod-with-prestop-exec-hook still exists
Aug  1 08:19:20.995: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug  1 08:19:20.998: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:19:21.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-fxgck" for this suite.
Aug  1 08:19:45.107: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:19:45.160: INFO: namespace: e2e-tests-container-lifecycle-hook-fxgck, resource: bindings, ignored listing per whitelist
Aug  1 08:19:45.263: INFO: namespace e2e-tests-container-lifecycle-hook-fxgck deletion completed in 24.241494973s

• [SLOW TEST:54.878 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:19:45.267: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-1eeeee6b-b435-11e9-aec8-12de527cd1b8
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-1eeeee6b-b435-11e9-aec8-12de527cd1b8
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:19:53.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-fzs74" for this suite.
Aug  1 08:20:15.981: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:20:16.164: INFO: namespace: e2e-tests-configmap-fzs74, resource: bindings, ignored listing per whitelist
Aug  1 08:20:16.205: INFO: namespace e2e-tests-configmap-fzs74 deletion completed in 22.349660643s

• [SLOW TEST:30.939 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:20:16.208: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug  1 08:20:16.418: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Aug  1 08:20:16.637: INFO: Pod name sample-pod: Found 0 pods out of 1
Aug  1 08:20:21.641: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug  1 08:20:21.641: INFO: Creating deployment "test-rolling-update-deployment"
Aug  1 08:20:21.648: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Aug  1 08:20:21.907: INFO: deployment "test-rolling-update-deployment" doesn't have the required revision set
Aug  1 08:20:24.272: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Aug  1 08:20:24.274: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700244421, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700244421, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700244421, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700244421, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-68b55d7bc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  1 08:20:26.302: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700244421, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700244421, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700244421, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700244421, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-68b55d7bc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  1 08:20:28.315: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Aug  1 08:20:28.399: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-bg7rb,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-bg7rb/deployments/test-rolling-update-deployment,UID:3415f07a-b435-11e9-8923-fa163ec474fb,ResourceVersion:12003,Generation:1,CreationTimestamp:2019-08-01 08:20:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-08-01 08:20:21 +0000 UTC 2019-08-01 08:20:21 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-08-01 08:20:26 +0000 UTC 2019-08-01 08:20:21 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-68b55d7bc6" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Aug  1 08:20:28.451: INFO: New ReplicaSet "test-rolling-update-deployment-68b55d7bc6" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6,GenerateName:,Namespace:e2e-tests-deployment-bg7rb,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-bg7rb/replicasets/test-rolling-update-deployment-68b55d7bc6,UID:341c7587-b435-11e9-8923-fa163ec474fb,ResourceVersion:11994,Generation:1,CreationTimestamp:2019-08-01 08:20:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 3415f07a-b435-11e9-8923-fa163ec474fb 0xc002466007 0xc002466008}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Aug  1 08:20:28.451: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Aug  1 08:20:28.451: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-bg7rb,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-bg7rb/replicasets/test-rolling-update-controller,UID:30fd22ab-b435-11e9-8923-fa163ec474fb,ResourceVersion:12002,Generation:2,CreationTimestamp:2019-08-01 08:20:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 3415f07a-b435-11e9-8923-fa163ec474fb 0xc0008c3f47 0xc0008c3f48}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug  1 08:20:28.457: INFO: Pod "test-rolling-update-deployment-68b55d7bc6-n65n6" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6-n65n6,GenerateName:test-rolling-update-deployment-68b55d7bc6-,Namespace:e2e-tests-deployment-bg7rb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bg7rb/pods/test-rolling-update-deployment-68b55d7bc6-n65n6,UID:3435bb82-b435-11e9-8923-fa163ec474fb,ResourceVersion:11993,Generation:0,CreationTimestamp:2019-08-01 08:20:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.128/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-68b55d7bc6 341c7587-b435-11e9-8923-fa163ec474fb 0xc0024668e7 0xc0024668e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fpzqt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fpzqt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-fpzqt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-6lh7zebx7k5q-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002466950} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002466970}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:20:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:20:26 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:20:26 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:20:21 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.23,PodIP:192.168.1.128,StartTime:2019-08-01 08:20:22 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-08-01 08:20:26 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://1ff12d7aa5cb96768ab8986473516f3e0fb48593c259a9700fface6047bcd402}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:20:28.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-bg7rb" for this suite.
Aug  1 08:20:38.531: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:20:38.546: INFO: namespace: e2e-tests-deployment-bg7rb, resource: bindings, ignored listing per whitelist
Aug  1 08:20:38.714: INFO: namespace e2e-tests-deployment-bg7rb deletion completed in 10.250788018s

• [SLOW TEST:22.506 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:20:38.720: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Aug  1 08:20:39.008: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:20:48.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-g82n4" for this suite.
Aug  1 08:20:56.597: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:20:56.642: INFO: namespace: e2e-tests-init-container-g82n4, resource: bindings, ignored listing per whitelist
Aug  1 08:20:56.734: INFO: namespace e2e-tests-init-container-g82n4 deletion completed in 8.173319151s

• [SLOW TEST:18.014 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:20:56.734: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug  1 08:20:57.130: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 version --client'
Aug  1 08:20:57.205: INFO: stderr: ""
Aug  1 08:20:57.205: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Aug  1 08:20:57.225: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 create -f - --namespace=e2e-tests-kubectl-vdtkp'
Aug  1 08:20:57.780: INFO: stderr: ""
Aug  1 08:20:57.780: INFO: stdout: "replicationcontroller/redis-master created\n"
Aug  1 08:20:57.780: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 create -f - --namespace=e2e-tests-kubectl-vdtkp'
Aug  1 08:20:58.708: INFO: stderr: ""
Aug  1 08:20:58.708: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Aug  1 08:20:59.713: INFO: Selector matched 1 pods for map[app:redis]
Aug  1 08:20:59.713: INFO: Found 0 / 1
Aug  1 08:21:00.743: INFO: Selector matched 1 pods for map[app:redis]
Aug  1 08:21:00.743: INFO: Found 0 / 1
Aug  1 08:21:01.765: INFO: Selector matched 1 pods for map[app:redis]
Aug  1 08:21:01.766: INFO: Found 0 / 1
Aug  1 08:21:02.712: INFO: Selector matched 1 pods for map[app:redis]
Aug  1 08:21:02.713: INFO: Found 1 / 1
Aug  1 08:21:02.713: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug  1 08:21:02.717: INFO: Selector matched 1 pods for map[app:redis]
Aug  1 08:21:02.717: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug  1 08:21:02.718: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 describe pod redis-master-stcjs --namespace=e2e-tests-kubectl-vdtkp'
Aug  1 08:21:03.023: INFO: stderr: ""
Aug  1 08:21:03.023: INFO: stdout: "Name:           redis-master-stcjs\nNamespace:      e2e-tests-kubectl-vdtkp\nNode:           k8s-1-6lh7zebx7k5q-node-0/10.0.0.23\nStart Time:     Thu, 01 Aug 2019 08:20:58 +0000\nLabels:         app=redis\n                role=master\nAnnotations:    cni.projectcalico.org/podIP: 192.168.1.130/32\nStatus:         Running\nIP:             192.168.1.130\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://eb8d9ebf7d67633fc3fb716742553f26d74ae07422335e43f79df7d1cee3f144\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Thu, 01 Aug 2019 08:21:01 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-mvjp6 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-mvjp6:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-mvjp6\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                Message\n  ----    ------     ----  ----                                -------\n  Normal  Scheduled  6s    default-scheduler                   Successfully assigned e2e-tests-kubectl-vdtkp/redis-master-stcjs to k8s-1-6lh7zebx7k5q-node-0\n  Normal  Pulled     3s    kubelet, k8s-1-6lh7zebx7k5q-node-0  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, k8s-1-6lh7zebx7k5q-node-0  Created container\n  Normal  Started    2s    kubelet, k8s-1-6lh7zebx7k5q-node-0  Started container\n"
Aug  1 08:21:03.071: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 describe rc redis-master --namespace=e2e-tests-kubectl-vdtkp'
Aug  1 08:21:03.226: INFO: stderr: ""
Aug  1 08:21:03.226: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-vdtkp\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  6s    replication-controller  Created pod: redis-master-stcjs\n"
Aug  1 08:21:03.226: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 describe service redis-master --namespace=e2e-tests-kubectl-vdtkp'
Aug  1 08:21:03.384: INFO: stderr: ""
Aug  1 08:21:03.384: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-vdtkp\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.254.47.158\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         192.168.1.130:6379\nSession Affinity:  None\nEvents:            <none>\n"
Aug  1 08:21:03.394: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 describe node k8s-1-6lh7zebx7k5q-master-0'
Aug  1 08:21:03.566: INFO: stderr: ""
Aug  1 08:21:03.566: INFO: stdout: "Name:               k8s-1-6lh7zebx7k5q-master-0\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=d3\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=RegionOne\n                    failure-domain.beta.kubernetes.io/zone=nova\n                    kubernetes.io/hostname=k8s-1-6lh7zebx7k5q-master-0\n                    node-role.kubernetes.io/master=\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.0.0.4/24\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Thu, 01 Aug 2019 07:09:41 +0000\nTaints:             CriticalAddonsOnly=True:NoSchedule\n                    dedicated=master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Thu, 01 Aug 2019 08:20:59 +0000   Thu, 01 Aug 2019 07:09:36 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Thu, 01 Aug 2019 08:20:59 +0000   Thu, 01 Aug 2019 07:09:36 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Thu, 01 Aug 2019 08:20:59 +0000   Thu, 01 Aug 2019 07:09:36 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Thu, 01 Aug 2019 08:20:59 +0000   Thu, 01 Aug 2019 07:11:33 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  10.0.0.4\n  ExternalIP:  172.24.4.5\nCapacity:\n cpu:                2\n ephemeral-storage:  9202Mi\n hugepages-2Mi:      0\n memory:             2040472Ki\n pods:               110\nAllocatable:\n cpu:                2\n ephemeral-storage:  8684096703\n hugepages-2Mi:      0\n memory:             1938072Ki\n pods:               110\nSystem Info:\n Machine ID:                 79b694381d1f4c49807ca0f5806cafa8\n System UUID:                79B69438-1D1F-4C49-807C-A0F5806CAFA8\n Boot ID:                    a509fd23-1cc4-403e-90af-f8910efccb6b\n Kernel Version:             4.15.8-300.fc27.x86_64\n OS Image:                   Debian GNU/Linux 9 (stretch)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://1.13.1\n Kubelet Version:            v1.13.7\n Kube-Proxy Version:         v1.13.7\nPodCIDR:                     192.168.0.0/24\nProviderID:                  openstack:///79b69438-1d1f-4c49-807c-a0f5806cafa8\nNon-terminated Pods:         (4 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-2a51f081063e4123-xxxdw    0 (0%)        0 (0%)      0 (0%)           0 (0%)         56m\n  kube-system                calico-node-nzslb                                          250m (12%)    0 (0%)      0 (0%)           0 (0%)         70m\n  kube-system                k8s-keystone-auth-4c59m                                    200m (10%)    0 (0%)      0 (0%)           0 (0%)         70m\n  kube-system                openstack-cloud-controller-manager-pvrhc                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         70m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                450m (22%)  0 (0%)\n  memory             0 (0%)      0 (0%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:              <none>\n"
Aug  1 08:21:03.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 describe namespace e2e-tests-kubectl-vdtkp'
Aug  1 08:21:03.701: INFO: stderr: ""
Aug  1 08:21:03.701: INFO: stdout: "Name:         e2e-tests-kubectl-vdtkp\nLabels:       e2e-framework=kubectl\n              e2e-run=b507996a-b42d-11e9-aec8-12de527cd1b8\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:21:03.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-vdtkp" for this suite.
Aug  1 08:21:27.815: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:21:27.932: INFO: namespace: e2e-tests-kubectl-vdtkp, resource: bindings, ignored listing per whitelist
Aug  1 08:21:27.994: INFO: namespace e2e-tests-kubectl-vdtkp deletion completed in 24.290215891s

• [SLOW TEST:31.260 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:21:27.997: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-5c1f137e-b435-11e9-aec8-12de527cd1b8
STEP: Creating a pod to test consume configMaps
Aug  1 08:21:28.378: INFO: Waiting up to 5m0s for pod "pod-configmaps-5c211198-b435-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-configmap-jlfbx" to be "success or failure"
Aug  1 08:21:28.412: INFO: Pod "pod-configmaps-5c211198-b435-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 33.224118ms
Aug  1 08:21:30.416: INFO: Pod "pod-configmaps-5c211198-b435-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037885103s
Aug  1 08:21:32.475: INFO: Pod "pod-configmaps-5c211198-b435-11e9-aec8-12de527cd1b8": Phase="Running", Reason="", readiness=true. Elapsed: 4.096514886s
Aug  1 08:21:34.483: INFO: Pod "pod-configmaps-5c211198-b435-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.104702873s
STEP: Saw pod success
Aug  1 08:21:34.483: INFO: Pod "pod-configmaps-5c211198-b435-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 08:21:34.486: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod pod-configmaps-5c211198-b435-11e9-aec8-12de527cd1b8 container configmap-volume-test: <nil>
STEP: delete the pod
Aug  1 08:21:34.543: INFO: Waiting for pod pod-configmaps-5c211198-b435-11e9-aec8-12de527cd1b8 to disappear
Aug  1 08:21:34.575: INFO: Pod pod-configmaps-5c211198-b435-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:21:34.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-jlfbx" for this suite.
Aug  1 08:21:40.762: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:21:40.862: INFO: namespace: e2e-tests-configmap-jlfbx, resource: bindings, ignored listing per whitelist
Aug  1 08:21:40.980: INFO: namespace e2e-tests-configmap-jlfbx deletion completed in 6.398543672s

• [SLOW TEST:12.983 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:21:40.981: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-skvgs
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug  1 08:21:41.311: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug  1 08:22:09.548: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.1.132:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-skvgs PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  1 08:22:09.549: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
Aug  1 08:22:09.748: INFO: Found all expected endpoints: [netserver-0]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:22:09.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-skvgs" for this suite.
Aug  1 08:22:35.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:22:35.939: INFO: namespace: e2e-tests-pod-network-test-skvgs, resource: bindings, ignored listing per whitelist
Aug  1 08:22:35.945: INFO: namespace e2e-tests-pod-network-test-skvgs deletion completed in 26.193118533s

• [SLOW TEST:54.965 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:22:35.945: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-kr7mn
I0801 08:22:36.327266      12 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-kr7mn, replica count: 1
I0801 08:22:37.377901      12 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0801 08:22:38.381933      12 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0801 08:22:39.382225      12 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0801 08:22:40.382502      12 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0801 08:22:41.382712      12 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug  1 08:22:41.659: INFO: Created: latency-svc-ql8st
Aug  1 08:22:41.704: INFO: Got endpoints: latency-svc-ql8st [221.183538ms]
Aug  1 08:22:41.999: INFO: Created: latency-svc-455r6
Aug  1 08:22:42.128: INFO: Got endpoints: latency-svc-455r6 [363.137752ms]
Aug  1 08:22:42.181: INFO: Created: latency-svc-lrmhs
Aug  1 08:22:42.387: INFO: Got endpoints: latency-svc-lrmhs [622.049186ms]
Aug  1 08:22:42.454: INFO: Created: latency-svc-49z4d
Aug  1 08:22:42.605: INFO: Got endpoints: latency-svc-49z4d [839.987865ms]
Aug  1 08:22:42.697: INFO: Created: latency-svc-x5ct9
Aug  1 08:22:42.900: INFO: Got endpoints: latency-svc-x5ct9 [1.134245308s]
Aug  1 08:22:42.965: INFO: Created: latency-svc-7vxf4
Aug  1 08:22:43.391: INFO: Got endpoints: latency-svc-7vxf4 [1.624659236s]
Aug  1 08:22:43.591: INFO: Created: latency-svc-wgr6g
Aug  1 08:22:43.800: INFO: Got endpoints: latency-svc-wgr6g [2.034368187s]
Aug  1 08:22:43.804: INFO: Created: latency-svc-k6g54
Aug  1 08:22:43.850: INFO: Got endpoints: latency-svc-k6g54 [458.871665ms]
Aug  1 08:22:43.991: INFO: Created: latency-svc-v7pld
Aug  1 08:22:44.049: INFO: Got endpoints: latency-svc-v7pld [2.282589179s]
Aug  1 08:22:44.049: INFO: Created: latency-svc-f2dgc
Aug  1 08:22:44.341: INFO: Got endpoints: latency-svc-f2dgc [2.575537771s]
Aug  1 08:22:44.366: INFO: Created: latency-svc-t4sz2
Aug  1 08:22:44.393: INFO: Got endpoints: latency-svc-t4sz2 [2.626165487s]
Aug  1 08:22:44.668: INFO: Created: latency-svc-c8lsh
Aug  1 08:22:44.736: INFO: Got endpoints: latency-svc-c8lsh [2.96974727s]
Aug  1 08:22:45.427: INFO: Created: latency-svc-7vm72
Aug  1 08:22:45.502: INFO: Got endpoints: latency-svc-7vm72 [3.735130783s]
Aug  1 08:22:45.504: INFO: Created: latency-svc-m26g4
Aug  1 08:22:45.701: INFO: Got endpoints: latency-svc-m26g4 [3.971932095s]
Aug  1 08:22:45.735: INFO: Created: latency-svc-nj66t
Aug  1 08:22:45.769: INFO: Got endpoints: latency-svc-nj66t [4.001612259s]
Aug  1 08:22:45.958: INFO: Created: latency-svc-k7mqv
Aug  1 08:22:46.194: INFO: Got endpoints: latency-svc-k7mqv [4.426582014s]
Aug  1 08:22:46.201: INFO: Created: latency-svc-2gg7x
Aug  1 08:22:46.268: INFO: Got endpoints: latency-svc-2gg7x [4.50128128s]
Aug  1 08:22:46.530: INFO: Created: latency-svc-9pl24
Aug  1 08:22:46.669: INFO: Got endpoints: latency-svc-9pl24 [4.541242771s]
Aug  1 08:22:46.676: INFO: Created: latency-svc-htzwv
Aug  1 08:22:46.705: INFO: Got endpoints: latency-svc-htzwv [4.317237927s]
Aug  1 08:22:46.992: INFO: Created: latency-svc-q7vzx
Aug  1 08:22:47.064: INFO: Got endpoints: latency-svc-q7vzx [4.459195664s]
Aug  1 08:22:47.067: INFO: Created: latency-svc-4zvhm
Aug  1 08:22:47.322: INFO: Got endpoints: latency-svc-4zvhm [4.421536624s]
Aug  1 08:22:47.355: INFO: Created: latency-svc-gt4vb
Aug  1 08:22:47.406: INFO: Got endpoints: latency-svc-gt4vb [3.605421646s]
Aug  1 08:22:47.589: INFO: Created: latency-svc-tpnff
Aug  1 08:22:47.612: INFO: Got endpoints: latency-svc-tpnff [3.761718447s]
Aug  1 08:22:47.845: INFO: Created: latency-svc-jsfjc
Aug  1 08:22:47.899: INFO: Created: latency-svc-8w4qf
Aug  1 08:22:47.902: INFO: Got endpoints: latency-svc-jsfjc [3.852064589s]
Aug  1 08:22:48.057: INFO: Got endpoints: latency-svc-8w4qf [3.716344002s]
Aug  1 08:22:48.144: INFO: Created: latency-svc-w7fnw
Aug  1 08:22:48.324: INFO: Got endpoints: latency-svc-w7fnw [3.930585953s]
Aug  1 08:22:48.349: INFO: Created: latency-svc-52xp9
Aug  1 08:22:48.373: INFO: Got endpoints: latency-svc-52xp9 [3.636743542s]
Aug  1 08:22:48.595: INFO: Created: latency-svc-mjf4w
Aug  1 08:22:48.792: INFO: Got endpoints: latency-svc-mjf4w [3.290325922s]
Aug  1 08:22:48.793: INFO: Created: latency-svc-knjpj
Aug  1 08:22:48.866: INFO: Got endpoints: latency-svc-knjpj [3.164973486s]
Aug  1 08:22:48.870: INFO: Created: latency-svc-pvlq5
Aug  1 08:22:49.117: INFO: Got endpoints: latency-svc-pvlq5 [3.348069432s]
Aug  1 08:22:49.152: INFO: Created: latency-svc-vqmqd
Aug  1 08:22:49.369: INFO: Got endpoints: latency-svc-vqmqd [3.174671864s]
Aug  1 08:22:49.435: INFO: Created: latency-svc-qnpmw
Aug  1 08:22:49.468: INFO: Got endpoints: latency-svc-qnpmw [3.199734109s]
Aug  1 08:22:49.620: INFO: Created: latency-svc-x7kfq
Aug  1 08:22:49.651: INFO: Got endpoints: latency-svc-x7kfq [2.982167923s]
Aug  1 08:22:49.854: INFO: Created: latency-svc-6m9mx
Aug  1 08:22:49.887: INFO: Got endpoints: latency-svc-6m9mx [3.182682212s]
Aug  1 08:22:50.074: INFO: Created: latency-svc-sdhwm
Aug  1 08:22:50.306: INFO: Created: latency-svc-x9ptc
Aug  1 08:22:50.309: INFO: Got endpoints: latency-svc-sdhwm [3.244358996s]
Aug  1 08:22:50.379: INFO: Got endpoints: latency-svc-x9ptc [3.057451788s]
Aug  1 08:22:50.382: INFO: Created: latency-svc-kknl5
Aug  1 08:22:50.562: INFO: Got endpoints: latency-svc-kknl5 [3.155618598s]
Aug  1 08:22:50.629: INFO: Created: latency-svc-x6c6x
Aug  1 08:22:50.805: INFO: Got endpoints: latency-svc-x6c6x [3.193042621s]
Aug  1 08:22:50.837: INFO: Created: latency-svc-77nmb
Aug  1 08:22:50.871: INFO: Got endpoints: latency-svc-77nmb [2.968671822s]
Aug  1 08:22:51.129: INFO: Created: latency-svc-kf82j
Aug  1 08:22:51.164: INFO: Got endpoints: latency-svc-kf82j [3.106817352s]
Aug  1 08:22:51.407: INFO: Created: latency-svc-v8742
Aug  1 08:22:51.480: INFO: Got endpoints: latency-svc-v8742 [3.155948879s]
Aug  1 08:22:51.639: INFO: Created: latency-svc-522qc
Aug  1 08:22:51.886: INFO: Got endpoints: latency-svc-522qc [3.512139714s]
Aug  1 08:22:51.930: INFO: Created: latency-svc-bjrh8
Aug  1 08:22:51.956: INFO: Got endpoints: latency-svc-bjrh8 [3.163548809s]
Aug  1 08:22:52.157: INFO: Created: latency-svc-5ht2c
Aug  1 08:22:52.201: INFO: Got endpoints: latency-svc-5ht2c [3.334818567s]
Aug  1 08:22:52.249: INFO: Created: latency-svc-pjwss
Aug  1 08:22:52.366: INFO: Got endpoints: latency-svc-pjwss [3.248955803s]
Aug  1 08:22:52.393: INFO: Created: latency-svc-8kt8d
Aug  1 08:22:52.441: INFO: Got endpoints: latency-svc-8kt8d [3.072474619s]
Aug  1 08:22:52.569: INFO: Created: latency-svc-2dg9g
Aug  1 08:22:52.595: INFO: Got endpoints: latency-svc-2dg9g [3.126347166s]
Aug  1 08:22:52.666: INFO: Created: latency-svc-wn972
Aug  1 08:22:52.874: INFO: Created: latency-svc-98szb
Aug  1 08:22:52.877: INFO: Got endpoints: latency-svc-wn972 [3.225399038s]
Aug  1 08:22:53.141: INFO: Got endpoints: latency-svc-98szb [3.253846184s]
Aug  1 08:22:53.351: INFO: Created: latency-svc-k7hcj
Aug  1 08:22:53.409: INFO: Created: latency-svc-7vs8z
Aug  1 08:22:53.410: INFO: Got endpoints: latency-svc-k7hcj [3.101640137s]
Aug  1 08:22:53.443: INFO: Got endpoints: latency-svc-7vs8z [3.063108544s]
Aug  1 08:22:53.602: INFO: Created: latency-svc-vxn94
Aug  1 08:22:53.636: INFO: Got endpoints: latency-svc-vxn94 [3.07426003s]
Aug  1 08:22:53.835: INFO: Created: latency-svc-ggqdn
Aug  1 08:22:53.869: INFO: Got endpoints: latency-svc-ggqdn [3.063379472s]
Aug  1 08:22:53.937: INFO: Created: latency-svc-bztms
Aug  1 08:22:54.079: INFO: Got endpoints: latency-svc-bztms [3.208343924s]
Aug  1 08:22:54.116: INFO: Created: latency-svc-4wf85
Aug  1 08:22:54.145: INFO: Got endpoints: latency-svc-4wf85 [2.98071585s]
Aug  1 08:22:54.403: INFO: Created: latency-svc-9d4rv
Aug  1 08:22:54.445: INFO: Got endpoints: latency-svc-9d4rv [2.965209165s]
Aug  1 08:22:54.621: INFO: Created: latency-svc-gwwdk
Aug  1 08:22:54.688: INFO: Got endpoints: latency-svc-gwwdk [2.801888556s]
Aug  1 08:22:54.897: INFO: Created: latency-svc-cfxlk
Aug  1 08:22:54.932: INFO: Got endpoints: latency-svc-cfxlk [2.975813084s]
Aug  1 08:22:55.202: INFO: Created: latency-svc-dzfzm
Aug  1 08:22:55.203: INFO: Got endpoints: latency-svc-dzfzm [3.00215122s]
Aug  1 08:22:55.366: INFO: Created: latency-svc-8bnb4
Aug  1 08:22:55.388: INFO: Got endpoints: latency-svc-8bnb4 [3.02181465s]
Aug  1 08:22:55.575: INFO: Created: latency-svc-h6j6f
Aug  1 08:22:55.591: INFO: Got endpoints: latency-svc-h6j6f [3.149576312s]
Aug  1 08:22:55.877: INFO: Created: latency-svc-4nrg9
Aug  1 08:22:55.931: INFO: Created: latency-svc-pmkwf
Aug  1 08:22:55.943: INFO: Got endpoints: latency-svc-4nrg9 [3.348445146s]
Aug  1 08:22:55.957: INFO: Got endpoints: latency-svc-pmkwf [3.080389744s]
Aug  1 08:22:56.126: INFO: Created: latency-svc-wtgdq
Aug  1 08:22:56.215: INFO: Got endpoints: latency-svc-wtgdq [3.073241026s]
Aug  1 08:22:56.374: INFO: Created: latency-svc-gkszb
Aug  1 08:22:56.426: INFO: Got endpoints: latency-svc-gkszb [3.015262333s]
Aug  1 08:22:56.665: INFO: Created: latency-svc-fcg49
Aug  1 08:22:56.691: INFO: Got endpoints: latency-svc-fcg49 [3.247926405s]
Aug  1 08:22:56.834: INFO: Created: latency-svc-x6m4b
Aug  1 08:22:56.900: INFO: Got endpoints: latency-svc-x6m4b [3.264202083s]
Aug  1 08:22:56.901: INFO: Created: latency-svc-c4jjc
Aug  1 08:22:56.924: INFO: Got endpoints: latency-svc-c4jjc [3.055019631s]
Aug  1 08:22:57.043: INFO: Created: latency-svc-cs444
Aug  1 08:22:57.106: INFO: Got endpoints: latency-svc-cs444 [3.026720601s]
Aug  1 08:22:57.558: INFO: Created: latency-svc-zcgtm
Aug  1 08:22:57.583: INFO: Got endpoints: latency-svc-zcgtm [3.438202504s]
Aug  1 08:22:57.642: INFO: Created: latency-svc-fzfpj
Aug  1 08:22:57.768: INFO: Got endpoints: latency-svc-fzfpj [3.322436534s]
Aug  1 08:22:57.802: INFO: Created: latency-svc-nsvqg
Aug  1 08:22:57.835: INFO: Got endpoints: latency-svc-nsvqg [3.146909977s]
Aug  1 08:22:57.994: INFO: Created: latency-svc-w5n4c
Aug  1 08:22:58.027: INFO: Got endpoints: latency-svc-w5n4c [3.094768384s]
Aug  1 08:22:58.252: INFO: Created: latency-svc-9rr82
Aug  1 08:22:58.287: INFO: Created: latency-svc-ktk9f
Aug  1 08:22:58.290: INFO: Got endpoints: latency-svc-9rr82 [3.086653252s]
Aug  1 08:22:58.322: INFO: Got endpoints: latency-svc-ktk9f [2.933805606s]
Aug  1 08:22:58.503: INFO: Created: latency-svc-5tv9n
Aug  1 08:22:58.570: INFO: Got endpoints: latency-svc-5tv9n [2.978164616s]
Aug  1 08:22:58.739: INFO: Created: latency-svc-td4n5
Aug  1 08:22:58.771: INFO: Got endpoints: latency-svc-td4n5 [2.827043903s]
Aug  1 08:22:58.971: INFO: Created: latency-svc-2w9zr
Aug  1 08:22:59.005: INFO: Got endpoints: latency-svc-2w9zr [3.047763425s]
Aug  1 08:22:59.198: INFO: Created: latency-svc-876bj
Aug  1 08:22:59.256: INFO: Created: latency-svc-vb6zg
Aug  1 08:22:59.262: INFO: Got endpoints: latency-svc-876bj [3.046737549s]
Aug  1 08:22:59.288: INFO: Got endpoints: latency-svc-vb6zg [2.862311773s]
Aug  1 08:22:59.447: INFO: Created: latency-svc-g465w
Aug  1 08:22:59.506: INFO: Got endpoints: latency-svc-g465w [2.814575963s]
Aug  1 08:22:59.680: INFO: Created: latency-svc-xjwc6
Aug  1 08:22:59.716: INFO: Got endpoints: latency-svc-xjwc6 [2.815909893s]
Aug  1 08:22:59.918: INFO: Created: latency-svc-xk62l
Aug  1 08:23:00.121: INFO: Got endpoints: latency-svc-xk62l [3.197331592s]
Aug  1 08:23:00.127: INFO: Created: latency-svc-jcsqs
Aug  1 08:23:00.146: INFO: Got endpoints: latency-svc-jcsqs [3.039533064s]
Aug  1 08:23:00.220: INFO: Created: latency-svc-vnp9g
Aug  1 08:23:00.382: INFO: Got endpoints: latency-svc-vnp9g [2.798693521s]
Aug  1 08:23:00.386: INFO: Created: latency-svc-8q75q
Aug  1 08:23:00.406: INFO: Got endpoints: latency-svc-8q75q [2.638377287s]
Aug  1 08:23:00.535: INFO: Created: latency-svc-fzfsx
Aug  1 08:23:00.563: INFO: Got endpoints: latency-svc-fzfsx [2.728476501s]
Aug  1 08:23:00.640: INFO: Created: latency-svc-x9jcp
Aug  1 08:23:00.758: INFO: Got endpoints: latency-svc-x9jcp [2.730570928s]
Aug  1 08:23:00.792: INFO: Created: latency-svc-fgf85
Aug  1 08:23:00.817: INFO: Got endpoints: latency-svc-fgf85 [2.495199791s]
Aug  1 08:23:00.961: INFO: Created: latency-svc-r69jl
Aug  1 08:23:01.142: INFO: Got endpoints: latency-svc-r69jl [2.572007305s]
Aug  1 08:23:01.175: INFO: Created: latency-svc-vj2d8
Aug  1 08:23:01.202: INFO: Got endpoints: latency-svc-vj2d8 [2.91242208s]
Aug  1 08:23:01.378: INFO: Created: latency-svc-fxr2v
Aug  1 08:23:01.426: INFO: Got endpoints: latency-svc-fxr2v [2.655202472s]
Aug  1 08:23:01.577: INFO: Created: latency-svc-bv9zs
Aug  1 08:23:01.654: INFO: Created: latency-svc-v4bdd
Aug  1 08:23:01.657: INFO: Got endpoints: latency-svc-bv9zs [2.651840414s]
Aug  1 08:23:01.835: INFO: Got endpoints: latency-svc-v4bdd [2.572609124s]
Aug  1 08:23:01.869: INFO: Created: latency-svc-dl4wj
Aug  1 08:23:01.894: INFO: Got endpoints: latency-svc-dl4wj [2.605763354s]
Aug  1 08:23:02.020: INFO: Created: latency-svc-pgfcf
Aug  1 08:23:02.214: INFO: Got endpoints: latency-svc-pgfcf [2.708253355s]
Aug  1 08:23:02.214: INFO: Created: latency-svc-nsdbc
Aug  1 08:23:02.219: INFO: Got endpoints: latency-svc-nsdbc [2.502313738s]
Aug  1 08:23:02.496: INFO: Created: latency-svc-qqgbg
Aug  1 08:23:02.504: INFO: Got endpoints: latency-svc-qqgbg [2.382056275s]
Aug  1 08:23:02.762: INFO: Created: latency-svc-lxm79
Aug  1 08:23:02.857: INFO: Got endpoints: latency-svc-lxm79 [2.71040861s]
Aug  1 08:23:02.857: INFO: Created: latency-svc-v7z8x
Aug  1 08:23:03.149: INFO: Got endpoints: latency-svc-v7z8x [2.766381512s]
Aug  1 08:23:03.489: INFO: Created: latency-svc-bls54
Aug  1 08:23:03.517: INFO: Got endpoints: latency-svc-bls54 [3.110485236s]
Aug  1 08:23:03.575: INFO: Created: latency-svc-dkdwc
Aug  1 08:23:03.765: INFO: Got endpoints: latency-svc-dkdwc [3.201498483s]
Aug  1 08:23:03.839: INFO: Created: latency-svc-lfxgt
Aug  1 08:23:03.861: INFO: Got endpoints: latency-svc-lfxgt [3.102568926s]
Aug  1 08:23:04.083: INFO: Created: latency-svc-q854x
Aug  1 08:23:04.122: INFO: Got endpoints: latency-svc-q854x [3.305251671s]
Aug  1 08:23:04.177: INFO: Created: latency-svc-zpz92
Aug  1 08:23:04.424: INFO: Got endpoints: latency-svc-zpz92 [3.281445075s]
Aug  1 08:23:04.457: INFO: Created: latency-svc-w757p
Aug  1 08:23:04.483: INFO: Got endpoints: latency-svc-w757p [3.280328565s]
Aug  1 08:23:04.750: INFO: Created: latency-svc-6gnln
Aug  1 08:23:04.810: INFO: Got endpoints: latency-svc-6gnln [3.383363874s]
Aug  1 08:23:04.811: INFO: Created: latency-svc-xpwsc
Aug  1 08:23:04.835: INFO: Got endpoints: latency-svc-xpwsc [3.177639703s]
Aug  1 08:23:05.009: INFO: Created: latency-svc-mwv89
Aug  1 08:23:05.078: INFO: Created: latency-svc-2r8bv
Aug  1 08:23:05.079: INFO: Got endpoints: latency-svc-mwv89 [3.244125428s]
Aug  1 08:23:05.103: INFO: Got endpoints: latency-svc-2r8bv [3.209131618s]
Aug  1 08:23:05.284: INFO: Created: latency-svc-vkgzr
Aug  1 08:23:05.347: INFO: Created: latency-svc-5rjmr
Aug  1 08:23:05.347: INFO: Got endpoints: latency-svc-vkgzr [3.132807055s]
Aug  1 08:23:05.535: INFO: Got endpoints: latency-svc-5rjmr [3.316300769s]
Aug  1 08:23:05.582: INFO: Created: latency-svc-k7gc6
Aug  1 08:23:05.604: INFO: Got endpoints: latency-svc-k7gc6 [3.100247514s]
Aug  1 08:23:05.805: INFO: Created: latency-svc-xplrd
Aug  1 08:23:05.837: INFO: Got endpoints: latency-svc-xplrd [2.980539383s]
Aug  1 08:23:05.895: INFO: Created: latency-svc-v22th
Aug  1 08:23:06.070: INFO: Got endpoints: latency-svc-v22th [2.921176488s]
Aug  1 08:23:06.072: INFO: Created: latency-svc-gmzvq
Aug  1 08:23:06.094: INFO: Got endpoints: latency-svc-gmzvq [2.576797428s]
Aug  1 08:23:06.489: INFO: Created: latency-svc-5rkjb
Aug  1 08:23:06.498: INFO: Created: latency-svc-5cmqv
Aug  1 08:23:06.672: INFO: Got endpoints: latency-svc-5rkjb [2.906928254s]
Aug  1 08:23:06.679: INFO: Got endpoints: latency-svc-5cmqv [2.817937119s]
Aug  1 08:23:06.941: INFO: Created: latency-svc-clhp5
Aug  1 08:23:06.998: INFO: Created: latency-svc-2tqf8
Aug  1 08:23:07.000: INFO: Got endpoints: latency-svc-clhp5 [2.877069508s]
Aug  1 08:23:07.031: INFO: Got endpoints: latency-svc-2tqf8 [2.606667473s]
Aug  1 08:23:07.228: INFO: Created: latency-svc-l9sws
Aug  1 08:23:07.297: INFO: Got endpoints: latency-svc-l9sws [2.813931325s]
Aug  1 08:23:07.457: INFO: Created: latency-svc-q828s
Aug  1 08:23:07.801: INFO: Got endpoints: latency-svc-q828s [2.991348653s]
Aug  1 08:23:07.805: INFO: Created: latency-svc-hh8xp
Aug  1 08:23:08.016: INFO: Created: latency-svc-sj9dj
Aug  1 08:23:08.020: INFO: Got endpoints: latency-svc-hh8xp [3.184710846s]
Aug  1 08:23:08.090: INFO: Got endpoints: latency-svc-sj9dj [3.011376068s]
Aug  1 08:23:08.094: INFO: Created: latency-svc-jm7br
Aug  1 08:23:08.457: INFO: Got endpoints: latency-svc-jm7br [3.353611272s]
Aug  1 08:23:08.528: INFO: Created: latency-svc-qws9x
Aug  1 08:23:08.680: INFO: Got endpoints: latency-svc-qws9x [3.332903034s]
Aug  1 08:23:08.741: INFO: Created: latency-svc-w2n87
Aug  1 08:23:08.776: INFO: Got endpoints: latency-svc-w2n87 [3.240253706s]
Aug  1 08:23:08.934: INFO: Created: latency-svc-zldnc
Aug  1 08:23:09.002: INFO: Created: latency-svc-6k9bk
Aug  1 08:23:09.002: INFO: Got endpoints: latency-svc-zldnc [3.397894432s]
Aug  1 08:23:09.025: INFO: Got endpoints: latency-svc-6k9bk [3.18775853s]
Aug  1 08:23:09.327: INFO: Created: latency-svc-np46t
Aug  1 08:23:09.393: INFO: Got endpoints: latency-svc-np46t [3.322366565s]
Aug  1 08:23:09.394: INFO: Created: latency-svc-45277
Aug  1 08:23:09.543: INFO: Got endpoints: latency-svc-45277 [3.448663901s]
Aug  1 08:23:09.580: INFO: Created: latency-svc-t89dr
Aug  1 08:23:09.618: INFO: Got endpoints: latency-svc-t89dr [2.945410911s]
Aug  1 08:23:09.777: INFO: Created: latency-svc-8x89l
Aug  1 08:23:09.845: INFO: Created: latency-svc-bcznk
Aug  1 08:23:09.846: INFO: Got endpoints: latency-svc-8x89l [3.167176382s]
Aug  1 08:23:10.162: INFO: Got endpoints: latency-svc-bcznk [3.162063478s]
Aug  1 08:23:10.262: INFO: Created: latency-svc-mgxmp
Aug  1 08:23:10.654: INFO: Got endpoints: latency-svc-mgxmp [3.623081117s]
Aug  1 08:23:11.156: INFO: Created: latency-svc-nt5l5
Aug  1 08:23:11.183: INFO: Got endpoints: latency-svc-nt5l5 [3.886053037s]
Aug  1 08:23:11.590: INFO: Created: latency-svc-w6xhz
Aug  1 08:23:12.008: INFO: Created: latency-svc-tffg9
Aug  1 08:23:12.008: INFO: Got endpoints: latency-svc-w6xhz [4.206819162s]
Aug  1 08:23:12.414: INFO: Created: latency-svc-dnv49
Aug  1 08:23:12.432: INFO: Got endpoints: latency-svc-dnv49 [4.341798888s]
Aug  1 08:23:12.433: INFO: Got endpoints: latency-svc-tffg9 [4.412623212s]
Aug  1 08:23:12.840: INFO: Created: latency-svc-2vs9j
Aug  1 08:23:13.170: INFO: Got endpoints: latency-svc-2vs9j [4.711337473s]
Aug  1 08:23:13.556: INFO: Created: latency-svc-2s6bj
Aug  1 08:23:14.330: INFO: Created: latency-svc-5rg8v
Aug  1 08:23:14.333: INFO: Got endpoints: latency-svc-2s6bj [5.652995917s]
Aug  1 08:23:14.339: INFO: Got endpoints: latency-svc-5rg8v [5.563727459s]
Aug  1 08:23:14.765: INFO: Created: latency-svc-nnbcc
Aug  1 08:23:15.137: INFO: Got endpoints: latency-svc-nnbcc [6.135102306s]
Aug  1 08:23:15.476: INFO: Created: latency-svc-rq8c2
Aug  1 08:23:15.828: INFO: Created: latency-svc-sgc98
Aug  1 08:23:15.830: INFO: Got endpoints: latency-svc-rq8c2 [6.804395575s]
Aug  1 08:23:16.146: INFO: Got endpoints: latency-svc-sgc98 [6.753853263s]
Aug  1 08:23:16.149: INFO: Created: latency-svc-m7qcb
Aug  1 08:23:16.424: INFO: Created: latency-svc-ddtfv
Aug  1 08:23:16.428: INFO: Got endpoints: latency-svc-m7qcb [6.884448068s]
Aug  1 08:23:16.526: INFO: Got endpoints: latency-svc-ddtfv [6.90831624s]
Aug  1 08:23:16.527: INFO: Created: latency-svc-2vshg
Aug  1 08:23:16.747: INFO: Got endpoints: latency-svc-2vshg [6.900591094s]
Aug  1 08:23:17.149: INFO: Created: latency-svc-kzzr7
Aug  1 08:23:17.438: INFO: Got endpoints: latency-svc-kzzr7 [7.275659671s]
Aug  1 08:23:17.443: INFO: Created: latency-svc-m85kb
Aug  1 08:23:17.893: INFO: Got endpoints: latency-svc-m85kb [7.238498462s]
Aug  1 08:23:17.897: INFO: Created: latency-svc-5dqck
Aug  1 08:23:17.904: INFO: Got endpoints: latency-svc-5dqck [6.720562318s]
Aug  1 08:23:18.159: INFO: Created: latency-svc-2rrtc
Aug  1 08:23:18.184: INFO: Got endpoints: latency-svc-2rrtc [6.176100928s]
Aug  1 08:23:18.326: INFO: Created: latency-svc-jflxl
Aug  1 08:23:18.360: INFO: Got endpoints: latency-svc-jflxl [5.921796096s]
Aug  1 08:23:18.631: INFO: Created: latency-svc-d7dfs
Aug  1 08:23:18.700: INFO: Created: latency-svc-s9z5d
Aug  1 08:23:18.703: INFO: Got endpoints: latency-svc-d7dfs [6.264662936s]
Aug  1 08:23:18.902: INFO: Got endpoints: latency-svc-s9z5d [5.732050074s]
Aug  1 08:23:18.905: INFO: Created: latency-svc-j2f6w
Aug  1 08:23:18.968: INFO: Got endpoints: latency-svc-j2f6w [4.635144545s]
Aug  1 08:23:19.142: INFO: Created: latency-svc-572kw
Aug  1 08:23:19.173: INFO: Got endpoints: latency-svc-572kw [4.833476331s]
Aug  1 08:23:19.378: INFO: Created: latency-svc-xm2ld
Aug  1 08:23:19.452: INFO: Got endpoints: latency-svc-xm2ld [4.314620925s]
Aug  1 08:23:19.453: INFO: Created: latency-svc-92tt2
Aug  1 08:23:19.662: INFO: Got endpoints: latency-svc-92tt2 [3.8319698s]
Aug  1 08:23:19.674: INFO: Created: latency-svc-lbrzb
Aug  1 08:23:19.704: INFO: Got endpoints: latency-svc-lbrzb [3.557257926s]
Aug  1 08:23:19.761: INFO: Created: latency-svc-c56sg
Aug  1 08:23:19.920: INFO: Got endpoints: latency-svc-c56sg [3.49170607s]
Aug  1 08:23:19.924: INFO: Created: latency-svc-cx25w
Aug  1 08:23:19.953: INFO: Got endpoints: latency-svc-cx25w [3.42709688s]
Aug  1 08:23:20.178: INFO: Created: latency-svc-55fvg
Aug  1 08:23:20.246: INFO: Created: latency-svc-jtrmh
Aug  1 08:23:20.249: INFO: Got endpoints: latency-svc-55fvg [3.50172884s]
Aug  1 08:23:20.280: INFO: Got endpoints: latency-svc-jtrmh [2.842225867s]
Aug  1 08:23:20.473: INFO: Created: latency-svc-4hgj4
Aug  1 08:23:20.530: INFO: Got endpoints: latency-svc-4hgj4 [2.637113936s]
Aug  1 08:23:20.531: INFO: Created: latency-svc-chhjm
Aug  1 08:23:20.563: INFO: Got endpoints: latency-svc-chhjm [2.65958857s]
Aug  1 08:23:20.704: INFO: Created: latency-svc-vwlwv
Aug  1 08:23:20.765: INFO: Created: latency-svc-gbtzw
Aug  1 08:23:20.766: INFO: Got endpoints: latency-svc-vwlwv [2.580888529s]
Aug  1 08:23:20.980: INFO: Got endpoints: latency-svc-gbtzw [2.620526294s]
Aug  1 08:23:20.984: INFO: Created: latency-svc-sw9vp
Aug  1 08:23:21.014: INFO: Got endpoints: latency-svc-sw9vp [2.31087369s]
Aug  1 08:23:21.266: INFO: Created: latency-svc-qbbbb
Aug  1 08:23:21.274: INFO: Got endpoints: latency-svc-qbbbb [2.372177093s]
Aug  1 08:23:21.323: INFO: Created: latency-svc-5x9vx
Aug  1 08:23:21.473: INFO: Got endpoints: latency-svc-5x9vx [2.50466531s]
Aug  1 08:23:21.475: INFO: Created: latency-svc-9htrs
Aug  1 08:23:21.534: INFO: Got endpoints: latency-svc-9htrs [2.36083316s]
Aug  1 08:23:21.749: INFO: Created: latency-svc-8d98r
Aug  1 08:23:21.807: INFO: Created: latency-svc-wfdbz
Aug  1 08:23:21.813: INFO: Got endpoints: latency-svc-8d98r [2.36066435s]
Aug  1 08:23:21.836: INFO: Got endpoints: latency-svc-wfdbz [2.173550118s]
Aug  1 08:23:21.983: INFO: Created: latency-svc-9ml67
Aug  1 08:23:22.200: INFO: Created: latency-svc-tbjpl
Aug  1 08:23:22.202: INFO: Got endpoints: latency-svc-9ml67 [2.497937235s]
Aug  1 08:23:22.227: INFO: Got endpoints: latency-svc-tbjpl [2.30677352s]
Aug  1 08:23:22.284: INFO: Created: latency-svc-zfgds
Aug  1 08:23:22.442: INFO: Got endpoints: latency-svc-zfgds [2.488692191s]
Aug  1 08:23:22.448: INFO: Created: latency-svc-5rbdn
Aug  1 08:23:22.469: INFO: Got endpoints: latency-svc-5rbdn [2.219278808s]
Aug  1 08:23:22.682: INFO: Created: latency-svc-x78qf
Aug  1 08:23:22.747: INFO: Created: latency-svc-2v245
Aug  1 08:23:22.752: INFO: Got endpoints: latency-svc-x78qf [2.472005407s]
Aug  1 08:23:22.971: INFO: Got endpoints: latency-svc-2v245 [2.441051097s]
Aug  1 08:23:22.973: INFO: Created: latency-svc-rldft
Aug  1 08:23:23.027: INFO: Got endpoints: latency-svc-rldft [2.463549615s]
Aug  1 08:23:23.296: INFO: Created: latency-svc-65fpb
Aug  1 08:23:23.496: INFO: Got endpoints: latency-svc-65fpb [2.730245819s]
Aug  1 08:23:23.497: INFO: Created: latency-svc-vvql6
Aug  1 08:23:23.554: INFO: Got endpoints: latency-svc-vvql6 [2.57379532s]
Aug  1 08:23:23.557: INFO: Created: latency-svc-rbf9x
Aug  1 08:23:23.863: INFO: Got endpoints: latency-svc-rbf9x [2.848717752s]
Aug  1 08:23:23.874: INFO: Created: latency-svc-4gfs5
Aug  1 08:23:23.903: INFO: Got endpoints: latency-svc-4gfs5 [2.629049873s]
Aug  1 08:23:24.175: INFO: Created: latency-svc-xj8bh
Aug  1 08:23:24.263: INFO: Got endpoints: latency-svc-xj8bh [2.789973195s]
Aug  1 08:23:24.264: INFO: Created: latency-svc-9qwrx
Aug  1 08:23:24.406: INFO: Got endpoints: latency-svc-9qwrx [2.87216593s]
Aug  1 08:23:24.409: INFO: Created: latency-svc-fdr98
Aug  1 08:23:24.439: INFO: Got endpoints: latency-svc-fdr98 [2.625512647s]
Aug  1 08:23:24.665: INFO: Created: latency-svc-8vl9t
Aug  1 08:23:24.939: INFO: Created: latency-svc-6pd4f
Aug  1 08:23:24.944: INFO: Got endpoints: latency-svc-8vl9t [3.107697885s]
Aug  1 08:23:25.271: INFO: Got endpoints: latency-svc-6pd4f [3.069303106s]
Aug  1 08:23:25.272: INFO: Created: latency-svc-dwnwf
Aug  1 08:23:25.299: INFO: Got endpoints: latency-svc-dwnwf [3.072517975s]
Aug  1 08:23:25.300: INFO: Created: latency-svc-n5rkk
Aug  1 08:23:25.441: INFO: Got endpoints: latency-svc-n5rkk [2.998983929s]
Aug  1 08:23:25.444: INFO: Created: latency-svc-hr2pt
Aug  1 08:23:25.482: INFO: Got endpoints: latency-svc-hr2pt [3.013357393s]
Aug  1 08:23:25.725: INFO: Created: latency-svc-xkh79
Aug  1 08:23:25.783: INFO: Created: latency-svc-6kwwz
Aug  1 08:23:25.784: INFO: Got endpoints: latency-svc-xkh79 [3.032006289s]
Aug  1 08:23:25.808: INFO: Got endpoints: latency-svc-6kwwz [2.836710551s]
Aug  1 08:23:26.042: INFO: Created: latency-svc-wjnng
Aug  1 08:23:26.110: INFO: Created: latency-svc-r9ztp
Aug  1 08:23:26.110: INFO: Got endpoints: latency-svc-wjnng [3.083416405s]
Aug  1 08:23:26.285: INFO: Got endpoints: latency-svc-r9ztp [2.788745306s]
Aug  1 08:23:26.287: INFO: Created: latency-svc-lgp24
Aug  1 08:23:26.317: INFO: Got endpoints: latency-svc-lgp24 [2.762305951s]
Aug  1 08:23:26.541: INFO: Created: latency-svc-zbcn5
Aug  1 08:23:26.627: INFO: Got endpoints: latency-svc-zbcn5 [2.763890868s]
Aug  1 08:23:26.627: INFO: Created: latency-svc-4hqbv
Aug  1 08:23:26.936: INFO: Got endpoints: latency-svc-4hqbv [3.032454103s]
Aug  1 08:23:26.997: INFO: Created: latency-svc-kmbhn
Aug  1 08:23:27.018: INFO: Got endpoints: latency-svc-kmbhn [2.754776386s]
Aug  1 08:23:27.043: INFO: Latencies: [363.137752ms 458.871665ms 622.049186ms 839.987865ms 1.134245308s 1.624659236s 2.034368187s 2.173550118s 2.219278808s 2.282589179s 2.30677352s 2.31087369s 2.36066435s 2.36083316s 2.372177093s 2.382056275s 2.441051097s 2.463549615s 2.472005407s 2.488692191s 2.495199791s 2.497937235s 2.502313738s 2.50466531s 2.572007305s 2.572609124s 2.57379532s 2.575537771s 2.576797428s 2.580888529s 2.605763354s 2.606667473s 2.620526294s 2.625512647s 2.626165487s 2.629049873s 2.637113936s 2.638377287s 2.651840414s 2.655202472s 2.65958857s 2.708253355s 2.71040861s 2.728476501s 2.730245819s 2.730570928s 2.754776386s 2.762305951s 2.763890868s 2.766381512s 2.788745306s 2.789973195s 2.798693521s 2.801888556s 2.813931325s 2.814575963s 2.815909893s 2.817937119s 2.827043903s 2.836710551s 2.842225867s 2.848717752s 2.862311773s 2.87216593s 2.877069508s 2.906928254s 2.91242208s 2.921176488s 2.933805606s 2.945410911s 2.965209165s 2.968671822s 2.96974727s 2.975813084s 2.978164616s 2.980539383s 2.98071585s 2.982167923s 2.991348653s 2.998983929s 3.00215122s 3.011376068s 3.013357393s 3.015262333s 3.02181465s 3.026720601s 3.032006289s 3.032454103s 3.039533064s 3.046737549s 3.047763425s 3.055019631s 3.057451788s 3.063108544s 3.063379472s 3.069303106s 3.072474619s 3.072517975s 3.073241026s 3.07426003s 3.080389744s 3.083416405s 3.086653252s 3.094768384s 3.100247514s 3.101640137s 3.102568926s 3.106817352s 3.107697885s 3.110485236s 3.126347166s 3.132807055s 3.146909977s 3.149576312s 3.155618598s 3.155948879s 3.162063478s 3.163548809s 3.164973486s 3.167176382s 3.174671864s 3.177639703s 3.182682212s 3.184710846s 3.18775853s 3.193042621s 3.197331592s 3.199734109s 3.201498483s 3.208343924s 3.209131618s 3.225399038s 3.240253706s 3.244125428s 3.244358996s 3.247926405s 3.248955803s 3.253846184s 3.264202083s 3.280328565s 3.281445075s 3.290325922s 3.305251671s 3.316300769s 3.322366565s 3.322436534s 3.332903034s 3.334818567s 3.348069432s 3.348445146s 3.353611272s 3.383363874s 3.397894432s 3.42709688s 3.438202504s 3.448663901s 3.49170607s 3.50172884s 3.512139714s 3.557257926s 3.605421646s 3.623081117s 3.636743542s 3.716344002s 3.735130783s 3.761718447s 3.8319698s 3.852064589s 3.886053037s 3.930585953s 3.971932095s 4.001612259s 4.206819162s 4.314620925s 4.317237927s 4.341798888s 4.412623212s 4.421536624s 4.426582014s 4.459195664s 4.50128128s 4.541242771s 4.635144545s 4.711337473s 4.833476331s 5.563727459s 5.652995917s 5.732050074s 5.921796096s 6.135102306s 6.176100928s 6.264662936s 6.720562318s 6.753853263s 6.804395575s 6.884448068s 6.900591094s 6.90831624s 7.238498462s 7.275659671s]
Aug  1 08:23:27.044: INFO: 50 %ile: 3.080389744s
Aug  1 08:23:27.044: INFO: 90 %ile: 4.50128128s
Aug  1 08:23:27.044: INFO: 99 %ile: 7.238498462s
Aug  1 08:23:27.044: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:23:27.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-kr7mn" for this suite.
Aug  1 08:26:21.267: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:26:21.447: INFO: namespace: e2e-tests-svc-latency-kr7mn, resource: bindings, ignored listing per whitelist
Aug  1 08:26:21.707: INFO: namespace e2e-tests-svc-latency-kr7mn deletion completed in 2m54.517390273s

• [SLOW TEST:225.761 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:26:21.708: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-gv2w
STEP: Creating a pod to test atomic-volume-subpath
Aug  1 08:26:22.771: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-gv2w" in namespace "e2e-tests-subpath-rqbpg" to be "success or failure"
Aug  1 08:26:22.995: INFO: Pod "pod-subpath-test-configmap-gv2w": Phase="Pending", Reason="", readiness=false. Elapsed: 224.088392ms
Aug  1 08:26:25.008: INFO: Pod "pod-subpath-test-configmap-gv2w": Phase="Pending", Reason="", readiness=false. Elapsed: 2.237007616s
Aug  1 08:26:27.013: INFO: Pod "pod-subpath-test-configmap-gv2w": Phase="Pending", Reason="", readiness=false. Elapsed: 4.242250118s
Aug  1 08:26:29.138: INFO: Pod "pod-subpath-test-configmap-gv2w": Phase="Pending", Reason="", readiness=false. Elapsed: 6.36648483s
Aug  1 08:26:31.140: INFO: Pod "pod-subpath-test-configmap-gv2w": Phase="Running", Reason="", readiness=false. Elapsed: 8.369158089s
Aug  1 08:26:33.144: INFO: Pod "pod-subpath-test-configmap-gv2w": Phase="Running", Reason="", readiness=false. Elapsed: 10.372900101s
Aug  1 08:26:35.146: INFO: Pod "pod-subpath-test-configmap-gv2w": Phase="Running", Reason="", readiness=false. Elapsed: 12.374988662s
Aug  1 08:26:37.152: INFO: Pod "pod-subpath-test-configmap-gv2w": Phase="Running", Reason="", readiness=false. Elapsed: 14.380328463s
Aug  1 08:26:39.156: INFO: Pod "pod-subpath-test-configmap-gv2w": Phase="Running", Reason="", readiness=false. Elapsed: 16.384790773s
Aug  1 08:26:41.159: INFO: Pod "pod-subpath-test-configmap-gv2w": Phase="Running", Reason="", readiness=false. Elapsed: 18.387780411s
Aug  1 08:26:43.162: INFO: Pod "pod-subpath-test-configmap-gv2w": Phase="Running", Reason="", readiness=false. Elapsed: 20.390354032s
Aug  1 08:26:45.165: INFO: Pod "pod-subpath-test-configmap-gv2w": Phase="Running", Reason="", readiness=false. Elapsed: 22.393796632s
Aug  1 08:26:47.168: INFO: Pod "pod-subpath-test-configmap-gv2w": Phase="Running", Reason="", readiness=false. Elapsed: 24.396469805s
Aug  1 08:26:49.170: INFO: Pod "pod-subpath-test-configmap-gv2w": Phase="Running", Reason="", readiness=false. Elapsed: 26.398905635s
Aug  1 08:26:51.173: INFO: Pod "pod-subpath-test-configmap-gv2w": Phase="Succeeded", Reason="", readiness=false. Elapsed: 28.40196933s
STEP: Saw pod success
Aug  1 08:26:51.173: INFO: Pod "pod-subpath-test-configmap-gv2w" satisfied condition "success or failure"
Aug  1 08:26:51.175: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod pod-subpath-test-configmap-gv2w container test-container-subpath-configmap-gv2w: <nil>
STEP: delete the pod
Aug  1 08:26:51.347: INFO: Waiting for pod pod-subpath-test-configmap-gv2w to disappear
Aug  1 08:26:51.357: INFO: Pod pod-subpath-test-configmap-gv2w no longer exists
STEP: Deleting pod pod-subpath-test-configmap-gv2w
Aug  1 08:26:51.357: INFO: Deleting pod "pod-subpath-test-configmap-gv2w" in namespace "e2e-tests-subpath-rqbpg"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:26:51.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-rqbpg" for this suite.
Aug  1 08:26:57.725: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:26:58.037: INFO: namespace: e2e-tests-subpath-rqbpg, resource: bindings, ignored listing per whitelist
Aug  1 08:26:58.085: INFO: namespace e2e-tests-subpath-rqbpg deletion completed in 6.722546033s

• [SLOW TEST:36.378 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:26:58.089: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug  1 08:26:58.613: INFO: Waiting up to 5m0s for pod "downwardapi-volume-20f81de9-b436-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-projected-5zh4f" to be "success or failure"
Aug  1 08:26:58.904: INFO: Pod "downwardapi-volume-20f81de9-b436-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 291.010411ms
Aug  1 08:27:00.948: INFO: Pod "downwardapi-volume-20f81de9-b436-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.335232053s
Aug  1 08:27:02.952: INFO: Pod "downwardapi-volume-20f81de9-b436-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.339212742s
STEP: Saw pod success
Aug  1 08:27:02.952: INFO: Pod "downwardapi-volume-20f81de9-b436-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 08:27:02.955: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod downwardapi-volume-20f81de9-b436-11e9-aec8-12de527cd1b8 container client-container: <nil>
STEP: delete the pod
Aug  1 08:27:03.146: INFO: Waiting for pod downwardapi-volume-20f81de9-b436-11e9-aec8-12de527cd1b8 to disappear
Aug  1 08:27:03.185: INFO: Pod downwardapi-volume-20f81de9-b436-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:27:03.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5zh4f" for this suite.
Aug  1 08:27:09.403: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:27:09.479: INFO: namespace: e2e-tests-projected-5zh4f, resource: bindings, ignored listing per whitelist
Aug  1 08:27:09.650: INFO: namespace e2e-tests-projected-5zh4f deletion completed in 6.462361406s

• [SLOW TEST:11.561 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:27:09.654: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-5pbzt
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-5pbzt to expose endpoints map[]
Aug  1 08:27:10.913: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-5pbzt exposes endpoints map[] (284.537481ms elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-5pbzt
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-5pbzt to expose endpoints map[pod1:[100]]
Aug  1 08:27:15.797: INFO: Unexpected endpoints: found map[], expected map[pod1:[100]] (4.863252748s elapsed, will retry)
Aug  1 08:27:16.843: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-5pbzt exposes endpoints map[pod1:[100]] (5.909504896s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-5pbzt
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-5pbzt to expose endpoints map[pod1:[100] pod2:[101]]
Aug  1 08:27:21.949: INFO: Unexpected endpoints: found map[2809f2bb-b436-11e9-8923-fa163ec474fb:[100]], expected map[pod1:[100] pod2:[101]] (5.099920802s elapsed, will retry)
Aug  1 08:27:23.316: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-5pbzt exposes endpoints map[pod1:[100] pod2:[101]] (6.467184291s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-5pbzt
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-5pbzt to expose endpoints map[pod2:[101]]
Aug  1 08:27:23.818: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-5pbzt exposes endpoints map[pod2:[101]] (490.07139ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-5pbzt
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-5pbzt to expose endpoints map[]
Aug  1 08:27:24.209: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-5pbzt exposes endpoints map[] (293.152922ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:27:24.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-5pbzt" for this suite.
Aug  1 08:27:51.842: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:27:51.915: INFO: namespace: e2e-tests-services-5pbzt, resource: bindings, ignored listing per whitelist
Aug  1 08:27:51.967: INFO: namespace e2e-tests-services-5pbzt deletion completed in 27.054809562s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:42.314 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:27:51.997: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:28:32.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-runtime-tfttq" for this suite.
Aug  1 08:28:39.640: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:28:39.838: INFO: namespace: e2e-tests-container-runtime-tfttq, resource: bindings, ignored listing per whitelist
Aug  1 08:28:39.889: INFO: namespace e2e-tests-container-runtime-tfttq deletion completed in 7.130303098s

• [SLOW TEST:47.893 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  blackbox test
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:28:39.900: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0801 08:29:20.566991      12 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug  1 08:29:20.567: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:29:20.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-5c6h9" for this suite.
Aug  1 08:29:34.661: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:29:34.707: INFO: namespace: e2e-tests-gc-5c6h9, resource: bindings, ignored listing per whitelist
Aug  1 08:29:35.260: INFO: namespace e2e-tests-gc-5c6h9 deletion completed in 14.687660993s

• [SLOW TEST:55.360 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:29:35.260: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Aug  1 08:29:37.347: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 08:29:37.855: INFO: Number of nodes with available pods: 0
Aug  1 08:29:37.856: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:29:38.880: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 08:29:39.200: INFO: Number of nodes with available pods: 0
Aug  1 08:29:39.200: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:29:39.860: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 08:29:39.864: INFO: Number of nodes with available pods: 0
Aug  1 08:29:39.864: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:29:40.983: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 08:29:41.244: INFO: Number of nodes with available pods: 0
Aug  1 08:29:41.245: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:29:41.862: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 08:29:41.867: INFO: Number of nodes with available pods: 0
Aug  1 08:29:41.867: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:29:43.298: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 08:29:43.560: INFO: Number of nodes with available pods: 0
Aug  1 08:29:43.560: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:29:43.861: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 08:29:43.866: INFO: Number of nodes with available pods: 0
Aug  1 08:29:43.866: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:29:45.032: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 08:29:45.034: INFO: Number of nodes with available pods: 0
Aug  1 08:29:45.034: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:29:45.861: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 08:29:45.866: INFO: Number of nodes with available pods: 0
Aug  1 08:29:45.867: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:29:47.049: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 08:29:47.051: INFO: Number of nodes with available pods: 0
Aug  1 08:29:47.051: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:29:47.863: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 08:29:47.867: INFO: Number of nodes with available pods: 0
Aug  1 08:29:47.867: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:29:48.889: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 08:29:49.125: INFO: Number of nodes with available pods: 0
Aug  1 08:29:49.125: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:29:49.862: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 08:29:49.867: INFO: Number of nodes with available pods: 0
Aug  1 08:29:49.867: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:29:50.862: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 08:29:50.865: INFO: Number of nodes with available pods: 1
Aug  1 08:29:50.866: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Stop a daemon pod, check that the daemon pod is revived.
Aug  1 08:29:51.306: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 08:29:51.345: INFO: Number of nodes with available pods: 0
Aug  1 08:29:51.345: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:29:52.350: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 08:29:52.353: INFO: Number of nodes with available pods: 0
Aug  1 08:29:52.353: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:29:53.489: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 08:29:53.496: INFO: Number of nodes with available pods: 0
Aug  1 08:29:53.496: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:29:54.373: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 08:29:54.377: INFO: Number of nodes with available pods: 0
Aug  1 08:29:54.377: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:29:55.413: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 08:29:55.417: INFO: Number of nodes with available pods: 0
Aug  1 08:29:55.417: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:29:56.351: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 08:29:56.355: INFO: Number of nodes with available pods: 0
Aug  1 08:29:56.355: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:29:57.364: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 08:29:57.367: INFO: Number of nodes with available pods: 0
Aug  1 08:29:57.367: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:29:58.349: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 08:29:58.353: INFO: Number of nodes with available pods: 0
Aug  1 08:29:58.353: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:29:59.373: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 08:29:59.376: INFO: Number of nodes with available pods: 0
Aug  1 08:29:59.376: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:30:00.350: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 08:30:00.355: INFO: Number of nodes with available pods: 0
Aug  1 08:30:00.355: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:30:01.474: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 08:30:01.476: INFO: Number of nodes with available pods: 0
Aug  1 08:30:01.476: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:30:02.349: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 08:30:02.351: INFO: Number of nodes with available pods: 0
Aug  1 08:30:02.352: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:30:03.349: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 08:30:03.351: INFO: Number of nodes with available pods: 0
Aug  1 08:30:03.351: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:30:04.462: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 08:30:04.527: INFO: Number of nodes with available pods: 0
Aug  1 08:30:04.527: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:30:05.355: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 08:30:05.362: INFO: Number of nodes with available pods: 0
Aug  1 08:30:05.363: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:30:06.351: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 08:30:06.354: INFO: Number of nodes with available pods: 0
Aug  1 08:30:06.354: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:30:07.351: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 08:30:07.354: INFO: Number of nodes with available pods: 0
Aug  1 08:30:07.354: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:30:08.352: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 08:30:08.356: INFO: Number of nodes with available pods: 0
Aug  1 08:30:08.356: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:30:09.353: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 08:30:09.356: INFO: Number of nodes with available pods: 0
Aug  1 08:30:09.356: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:30:10.352: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 08:30:10.358: INFO: Number of nodes with available pods: 0
Aug  1 08:30:10.359: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:30:11.351: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 08:30:11.356: INFO: Number of nodes with available pods: 0
Aug  1 08:30:11.356: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:30:12.351: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 08:30:12.355: INFO: Number of nodes with available pods: 0
Aug  1 08:30:12.356: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:30:13.354: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 08:30:13.357: INFO: Number of nodes with available pods: 0
Aug  1 08:30:13.357: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:30:14.433: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 08:30:14.438: INFO: Number of nodes with available pods: 0
Aug  1 08:30:14.438: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:30:15.349: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 08:30:15.351: INFO: Number of nodes with available pods: 0
Aug  1 08:30:15.352: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:30:16.351: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 08:30:16.355: INFO: Number of nodes with available pods: 0
Aug  1 08:30:16.355: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:30:17.351: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 08:30:17.355: INFO: Number of nodes with available pods: 0
Aug  1 08:30:17.355: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:30:18.351: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 08:30:18.355: INFO: Number of nodes with available pods: 0
Aug  1 08:30:18.355: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:30:19.350: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 08:30:19.353: INFO: Number of nodes with available pods: 0
Aug  1 08:30:19.354: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:30:20.349: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 08:30:20.352: INFO: Number of nodes with available pods: 0
Aug  1 08:30:20.352: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:30:21.350: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 08:30:21.352: INFO: Number of nodes with available pods: 0
Aug  1 08:30:21.352: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:30:22.351: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 08:30:22.354: INFO: Number of nodes with available pods: 0
Aug  1 08:30:22.354: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:30:23.349: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 08:30:23.352: INFO: Number of nodes with available pods: 0
Aug  1 08:30:23.352: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:30:24.528: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 08:30:24.531: INFO: Number of nodes with available pods: 0
Aug  1 08:30:24.531: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:30:25.350: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 08:30:25.353: INFO: Number of nodes with available pods: 0
Aug  1 08:30:25.354: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:30:26.350: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 08:30:26.353: INFO: Number of nodes with available pods: 0
Aug  1 08:30:26.353: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:30:27.349: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 08:30:27.352: INFO: Number of nodes with available pods: 0
Aug  1 08:30:27.352: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:30:28.351: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 08:30:28.354: INFO: Number of nodes with available pods: 0
Aug  1 08:30:28.354: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:30:29.350: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 08:30:29.352: INFO: Number of nodes with available pods: 0
Aug  1 08:30:29.352: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 08:30:30.349: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 08:30:30.351: INFO: Number of nodes with available pods: 1
Aug  1 08:30:30.351: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-m7c6c, will wait for the garbage collector to delete the pods
Aug  1 08:30:30.418: INFO: Deleting DaemonSet.extensions daemon-set took: 9.886636ms
Aug  1 08:30:30.532: INFO: Terminating DaemonSet.extensions daemon-set pods took: 114.473867ms
Aug  1 08:31:04.620: INFO: Number of nodes with available pods: 0
Aug  1 08:31:04.620: INFO: Number of running nodes: 0, number of available pods: 0
Aug  1 08:31:04.633: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-m7c6c/daemonsets","resourceVersion":"15028"},"items":null}

Aug  1 08:31:04.637: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-m7c6c/pods","resourceVersion":"15028"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:31:04.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-m7c6c" for this suite.
Aug  1 08:31:12.681: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:31:12.736: INFO: namespace: e2e-tests-daemonsets-m7c6c, resource: bindings, ignored listing per whitelist
Aug  1 08:31:12.816: INFO: namespace e2e-tests-daemonsets-m7c6c deletion completed in 8.167369772s

• [SLOW TEST:97.556 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:31:12.822: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Aug  1 08:31:22.112: INFO: Successfully updated pod "annotationupdateb8ac93e3-b436-11e9-aec8-12de527cd1b8"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:31:24.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-kfx2j" for this suite.
Aug  1 08:31:48.414: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:31:48.535: INFO: namespace: e2e-tests-downward-api-kfx2j, resource: bindings, ignored listing per whitelist
Aug  1 08:31:48.543: INFO: namespace e2e-tests-downward-api-kfx2j deletion completed in 24.173223379s

• [SLOW TEST:35.722 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:31:48.549: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Aug  1 08:31:48.838: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug  1 08:31:48.845: INFO: Waiting for terminating namespaces to be deleted...
Aug  1 08:31:48.848: INFO: 
Logging pods the kubelet thinks is on node k8s-1-6lh7zebx7k5q-node-0 before test
Aug  1 08:31:48.896: INFO: heapster-796547984d-vjt7z from kube-system started at 2019-08-01 07:18:52 +0000 UTC (1 container statuses recorded)
Aug  1 08:31:48.896: INFO: 	Container heapster ready: true, restart count 0
Aug  1 08:31:48.896: INFO: sonobuoy-systemd-logs-daemon-set-2a51f081063e4123-xc965 from heptio-sonobuoy started at 2019-08-01 07:24:21 +0000 UTC (2 container statuses recorded)
Aug  1 08:31:48.896: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Aug  1 08:31:48.898: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug  1 08:31:48.898: INFO: coredns-5f559b869-jcg4r from kube-system started at 2019-08-01 07:18:52 +0000 UTC (1 container statuses recorded)
Aug  1 08:31:48.898: INFO: 	Container coredns ready: true, restart count 0
Aug  1 08:31:48.898: INFO: npd-q8998 from kube-system started at 2019-08-01 07:18:52 +0000 UTC (1 container statuses recorded)
Aug  1 08:31:48.898: INFO: 	Container node-problem-detector ready: true, restart count 0
Aug  1 08:31:48.898: INFO: sonobuoy from heptio-sonobuoy started at 2019-08-01 07:23:57 +0000 UTC (1 container statuses recorded)
Aug  1 08:31:48.898: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug  1 08:31:48.898: INFO: kube-dns-autoscaler-845f56f67b-s24x9 from kube-system started at 2019-08-01 07:18:52 +0000 UTC (1 container statuses recorded)
Aug  1 08:31:48.898: INFO: 	Container autoscaler ready: true, restart count 0
Aug  1 08:31:48.898: INFO: kubernetes-dashboard-f5496d66d-j22q5 from kube-system started at 2019-08-01 07:18:52 +0000 UTC (1 container statuses recorded)
Aug  1 08:31:48.898: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Aug  1 08:31:48.898: INFO: sonobuoy-e2e-job-d28e9b7acb7844b7 from heptio-sonobuoy started at 2019-08-01 07:24:19 +0000 UTC (2 container statuses recorded)
Aug  1 08:31:48.898: INFO: 	Container e2e ready: true, restart count 0
Aug  1 08:31:48.898: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug  1 08:31:48.898: INFO: calico-node-5v77h from kube-system started at 2019-08-01 07:18:04 +0000 UTC (2 container statuses recorded)
Aug  1 08:31:48.898: INFO: 	Container calico-node ready: true, restart count 0
Aug  1 08:31:48.899: INFO: 	Container install-cni ready: true, restart count 0
Aug  1 08:31:48.900: INFO: coredns-5f559b869-f68db from kube-system started at 2019-08-01 07:18:52 +0000 UTC (1 container statuses recorded)
Aug  1 08:31:48.900: INFO: 	Container coredns ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-d1c3057a-b436-11e9-aec8-12de527cd1b8 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-d1c3057a-b436-11e9-aec8-12de527cd1b8 off the node k8s-1-6lh7zebx7k5q-node-0
STEP: verifying the node doesn't have the label kubernetes.io/e2e-d1c3057a-b436-11e9-aec8-12de527cd1b8
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:32:02.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-d8cxn" for this suite.
Aug  1 08:32:12.748: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:32:12.864: INFO: namespace: e2e-tests-sched-pred-d8cxn, resource: bindings, ignored listing per whitelist
Aug  1 08:32:12.882: INFO: namespace e2e-tests-sched-pred-d8cxn deletion completed in 10.20603477s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:24.334 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:32:12.886: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Aug  1 08:32:19.985: INFO: Successfully updated pod "annotationupdatedc7476e2-b436-11e9-aec8-12de527cd1b8"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:32:22.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-cxm7j" for this suite.
Aug  1 08:32:46.223: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:32:46.257: INFO: namespace: e2e-tests-projected-cxm7j, resource: bindings, ignored listing per whitelist
Aug  1 08:32:46.360: INFO: namespace e2e-tests-projected-cxm7j deletion completed in 24.299687896s

• [SLOW TEST:33.475 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:32:46.368: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-5dpws/secret-test-f07d0306-b436-11e9-aec8-12de527cd1b8
STEP: Creating a pod to test consume secrets
Aug  1 08:32:46.961: INFO: Waiting up to 5m0s for pod "pod-configmaps-f08001de-b436-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-secrets-5dpws" to be "success or failure"
Aug  1 08:32:47.167: INFO: Pod "pod-configmaps-f08001de-b436-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 205.467556ms
Aug  1 08:32:49.170: INFO: Pod "pod-configmaps-f08001de-b436-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.208689455s
Aug  1 08:32:51.261: INFO: Pod "pod-configmaps-f08001de-b436-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.299411232s
Aug  1 08:32:53.265: INFO: Pod "pod-configmaps-f08001de-b436-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.303563209s
STEP: Saw pod success
Aug  1 08:32:53.265: INFO: Pod "pod-configmaps-f08001de-b436-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 08:32:53.267: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod pod-configmaps-f08001de-b436-11e9-aec8-12de527cd1b8 container env-test: <nil>
STEP: delete the pod
Aug  1 08:32:53.323: INFO: Waiting for pod pod-configmaps-f08001de-b436-11e9-aec8-12de527cd1b8 to disappear
Aug  1 08:32:53.354: INFO: Pod pod-configmaps-f08001de-b436-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:32:53.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-5dpws" for this suite.
Aug  1 08:32:59.451: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:32:59.488: INFO: namespace: e2e-tests-secrets-5dpws, resource: bindings, ignored listing per whitelist
Aug  1 08:32:59.570: INFO: namespace e2e-tests-secrets-5dpws deletion completed in 6.211892624s

• [SLOW TEST:13.203 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:32:59.575: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Aug  1 08:33:03.983: INFO: Pod pod-hostip-f84b9b33-b436-11e9-aec8-12de527cd1b8 has hostIP: 10.0.0.23
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:33:03.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-xsk9n" for this suite.
Aug  1 08:33:28.026: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:33:28.096: INFO: namespace: e2e-tests-pods-xsk9n, resource: bindings, ignored listing per whitelist
Aug  1 08:33:28.162: INFO: namespace e2e-tests-pods-xsk9n deletion completed in 24.177235972s

• [SLOW TEST:28.588 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:33:28.180: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug  1 08:33:28.663: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0974b147-b437-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-projected-wgfhg" to be "success or failure"
Aug  1 08:33:28.686: INFO: Pod "downwardapi-volume-0974b147-b437-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 23.043204ms
Aug  1 08:33:30.871: INFO: Pod "downwardapi-volume-0974b147-b437-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.20751108s
Aug  1 08:33:32.928: INFO: Pod "downwardapi-volume-0974b147-b437-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.264790695s
STEP: Saw pod success
Aug  1 08:33:32.928: INFO: Pod "downwardapi-volume-0974b147-b437-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 08:33:32.929: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod downwardapi-volume-0974b147-b437-11e9-aec8-12de527cd1b8 container client-container: <nil>
STEP: delete the pod
Aug  1 08:33:33.183: INFO: Waiting for pod downwardapi-volume-0974b147-b437-11e9-aec8-12de527cd1b8 to disappear
Aug  1 08:33:33.254: INFO: Pod downwardapi-volume-0974b147-b437-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:33:33.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wgfhg" for this suite.
Aug  1 08:33:39.533: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:33:39.554: INFO: namespace: e2e-tests-projected-wgfhg, resource: bindings, ignored listing per whitelist
Aug  1 08:33:39.658: INFO: namespace e2e-tests-projected-wgfhg deletion completed in 6.400949347s

• [SLOW TEST:11.479 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:33:39.666: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Aug  1 08:33:40.079: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ld69n,SelfLink:/api/v1/namespaces/e2e-tests-watch-ld69n/configmaps/e2e-watch-test-configmap-a,UID:0fe66db8-b437-11e9-8923-fa163ec474fb,ResourceVersion:15506,Generation:0,CreationTimestamp:2019-08-01 08:33:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug  1 08:33:40.079: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ld69n,SelfLink:/api/v1/namespaces/e2e-tests-watch-ld69n/configmaps/e2e-watch-test-configmap-a,UID:0fe66db8-b437-11e9-8923-fa163ec474fb,ResourceVersion:15506,Generation:0,CreationTimestamp:2019-08-01 08:33:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Aug  1 08:33:50.094: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ld69n,SelfLink:/api/v1/namespaces/e2e-tests-watch-ld69n/configmaps/e2e-watch-test-configmap-a,UID:0fe66db8-b437-11e9-8923-fa163ec474fb,ResourceVersion:15525,Generation:0,CreationTimestamp:2019-08-01 08:33:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Aug  1 08:33:50.094: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ld69n,SelfLink:/api/v1/namespaces/e2e-tests-watch-ld69n/configmaps/e2e-watch-test-configmap-a,UID:0fe66db8-b437-11e9-8923-fa163ec474fb,ResourceVersion:15525,Generation:0,CreationTimestamp:2019-08-01 08:33:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Aug  1 08:34:00.108: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ld69n,SelfLink:/api/v1/namespaces/e2e-tests-watch-ld69n/configmaps/e2e-watch-test-configmap-a,UID:0fe66db8-b437-11e9-8923-fa163ec474fb,ResourceVersion:15544,Generation:0,CreationTimestamp:2019-08-01 08:33:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug  1 08:34:00.109: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ld69n,SelfLink:/api/v1/namespaces/e2e-tests-watch-ld69n/configmaps/e2e-watch-test-configmap-a,UID:0fe66db8-b437-11e9-8923-fa163ec474fb,ResourceVersion:15544,Generation:0,CreationTimestamp:2019-08-01 08:33:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Aug  1 08:34:10.124: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ld69n,SelfLink:/api/v1/namespaces/e2e-tests-watch-ld69n/configmaps/e2e-watch-test-configmap-a,UID:0fe66db8-b437-11e9-8923-fa163ec474fb,ResourceVersion:15563,Generation:0,CreationTimestamp:2019-08-01 08:33:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug  1 08:34:10.124: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ld69n,SelfLink:/api/v1/namespaces/e2e-tests-watch-ld69n/configmaps/e2e-watch-test-configmap-a,UID:0fe66db8-b437-11e9-8923-fa163ec474fb,ResourceVersion:15563,Generation:0,CreationTimestamp:2019-08-01 08:33:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Aug  1 08:34:20.136: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-ld69n,SelfLink:/api/v1/namespaces/e2e-tests-watch-ld69n/configmaps/e2e-watch-test-configmap-b,UID:27dc73bb-b437-11e9-8923-fa163ec474fb,ResourceVersion:15583,Generation:0,CreationTimestamp:2019-08-01 08:34:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug  1 08:34:20.137: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-ld69n,SelfLink:/api/v1/namespaces/e2e-tests-watch-ld69n/configmaps/e2e-watch-test-configmap-b,UID:27dc73bb-b437-11e9-8923-fa163ec474fb,ResourceVersion:15583,Generation:0,CreationTimestamp:2019-08-01 08:34:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Aug  1 08:34:30.143: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-ld69n,SelfLink:/api/v1/namespaces/e2e-tests-watch-ld69n/configmaps/e2e-watch-test-configmap-b,UID:27dc73bb-b437-11e9-8923-fa163ec474fb,ResourceVersion:15602,Generation:0,CreationTimestamp:2019-08-01 08:34:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug  1 08:34:30.143: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-ld69n,SelfLink:/api/v1/namespaces/e2e-tests-watch-ld69n/configmaps/e2e-watch-test-configmap-b,UID:27dc73bb-b437-11e9-8923-fa163ec474fb,ResourceVersion:15602,Generation:0,CreationTimestamp:2019-08-01 08:34:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:34:40.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-ld69n" for this suite.
Aug  1 08:34:48.246: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:34:48.285: INFO: namespace: e2e-tests-watch-ld69n, resource: bindings, ignored listing per whitelist
Aug  1 08:34:48.376: INFO: namespace e2e-tests-watch-ld69n deletion completed in 8.209313989s

• [SLOW TEST:68.711 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:34:48.380: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-flkch/configmap-test-39333e4c-b437-11e9-aec8-12de527cd1b8
STEP: Creating a pod to test consume configMaps
Aug  1 08:34:48.787: INFO: Waiting up to 5m0s for pod "pod-configmaps-39342be8-b437-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-configmap-flkch" to be "success or failure"
Aug  1 08:34:48.936: INFO: Pod "pod-configmaps-39342be8-b437-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 147.369722ms
Aug  1 08:34:51.092: INFO: Pod "pod-configmaps-39342be8-b437-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.304207147s
Aug  1 08:34:53.095: INFO: Pod "pod-configmaps-39342be8-b437-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.30703263s
STEP: Saw pod success
Aug  1 08:34:53.095: INFO: Pod "pod-configmaps-39342be8-b437-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 08:34:53.097: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod pod-configmaps-39342be8-b437-11e9-aec8-12de527cd1b8 container env-test: <nil>
STEP: delete the pod
Aug  1 08:34:53.428: INFO: Waiting for pod pod-configmaps-39342be8-b437-11e9-aec8-12de527cd1b8 to disappear
Aug  1 08:34:53.485: INFO: Pod pod-configmaps-39342be8-b437-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:34:53.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-flkch" for this suite.
Aug  1 08:34:59.690: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:34:59.819: INFO: namespace: e2e-tests-configmap-flkch, resource: bindings, ignored listing per whitelist
Aug  1 08:34:59.902: INFO: namespace e2e-tests-configmap-flkch deletion completed in 6.41521028s

• [SLOW TEST:11.523 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:34:59.905: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Aug  1 08:35:00.416: INFO: Waiting up to 5m0s for pod "pod-400a7efb-b437-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-emptydir-c98nd" to be "success or failure"
Aug  1 08:35:00.647: INFO: Pod "pod-400a7efb-b437-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 230.666767ms
Aug  1 08:35:02.693: INFO: Pod "pod-400a7efb-b437-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.277346439s
Aug  1 08:35:04.845: INFO: Pod "pod-400a7efb-b437-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.429380371s
STEP: Saw pod success
Aug  1 08:35:04.846: INFO: Pod "pod-400a7efb-b437-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 08:35:04.847: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod pod-400a7efb-b437-11e9-aec8-12de527cd1b8 container test-container: <nil>
STEP: delete the pod
Aug  1 08:35:05.217: INFO: Waiting for pod pod-400a7efb-b437-11e9-aec8-12de527cd1b8 to disappear
Aug  1 08:35:05.733: INFO: Pod pod-400a7efb-b437-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:35:05.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-c98nd" for this suite.
Aug  1 08:35:11.902: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:35:11.993: INFO: namespace: e2e-tests-emptydir-c98nd, resource: bindings, ignored listing per whitelist
Aug  1 08:35:12.035: INFO: namespace e2e-tests-emptydir-c98nd deletion completed in 6.298686166s

• [SLOW TEST:12.130 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:35:12.038: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Aug  1 08:35:12.461: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 cluster-info'
Aug  1 08:35:15.653: INFO: stderr: ""
Aug  1 08:35:15.653: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.254.0.1:443\x1b[0m\n\x1b[0;32mHeapster\x1b[0m is running at \x1b[0;33mhttps://10.254.0.1:443/api/v1/namespaces/kube-system/services/heapster/proxy\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://10.254.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:35:15.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-lztrz" for this suite.
Aug  1 08:35:21.833: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:35:21.954: INFO: namespace: e2e-tests-kubectl-lztrz, resource: bindings, ignored listing per whitelist
Aug  1 08:35:21.961: INFO: namespace e2e-tests-kubectl-lztrz deletion completed in 6.303546011s

• [SLOW TEST:9.923 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:35:21.966: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug  1 08:35:22.321: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4d362d48-b437-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-projected-2nbk6" to be "success or failure"
Aug  1 08:35:22.382: INFO: Pod "downwardapi-volume-4d362d48-b437-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 60.273677ms
Aug  1 08:35:24.437: INFO: Pod "downwardapi-volume-4d362d48-b437-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.115617528s
Aug  1 08:35:26.441: INFO: Pod "downwardapi-volume-4d362d48-b437-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.119768978s
Aug  1 08:35:28.469: INFO: Pod "downwardapi-volume-4d362d48-b437-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.147239895s
STEP: Saw pod success
Aug  1 08:35:28.469: INFO: Pod "downwardapi-volume-4d362d48-b437-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 08:35:28.471: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod downwardapi-volume-4d362d48-b437-11e9-aec8-12de527cd1b8 container client-container: <nil>
STEP: delete the pod
Aug  1 08:35:28.733: INFO: Waiting for pod downwardapi-volume-4d362d48-b437-11e9-aec8-12de527cd1b8 to disappear
Aug  1 08:35:28.783: INFO: Pod downwardapi-volume-4d362d48-b437-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:35:28.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2nbk6" for this suite.
Aug  1 08:35:35.140: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:35:35.156: INFO: namespace: e2e-tests-projected-2nbk6, resource: bindings, ignored listing per whitelist
Aug  1 08:35:35.486: INFO: namespace e2e-tests-projected-2nbk6 deletion completed in 6.696351931s

• [SLOW TEST:13.521 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:35:35.490: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-8xnn7
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-8xnn7
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-8xnn7
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-8xnn7
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-8xnn7
Aug  1 08:35:42.572: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-8xnn7, name: ss-0, uid: 58e2fcc2-b437-11e9-8923-fa163ec474fb, status phase: Pending. Waiting for statefulset controller to delete.
Aug  1 08:35:42.592: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-8xnn7, name: ss-0, uid: 58e2fcc2-b437-11e9-8923-fa163ec474fb, status phase: Pending. Waiting for statefulset controller to delete.
Aug  1 08:35:50.928: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-8xnn7, name: ss-0, uid: 58e2fcc2-b437-11e9-8923-fa163ec474fb, status phase: Failed. Waiting for statefulset controller to delete.
Aug  1 08:35:51.023: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-8xnn7, name: ss-0, uid: 58e2fcc2-b437-11e9-8923-fa163ec474fb, status phase: Failed. Waiting for statefulset controller to delete.
Aug  1 08:35:51.093: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-8xnn7
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-8xnn7
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-8xnn7 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Aug  1 08:36:08.031: INFO: Deleting all statefulset in ns e2e-tests-statefulset-8xnn7
Aug  1 08:36:08.081: INFO: Scaling statefulset ss to 0
Aug  1 08:36:18.237: INFO: Waiting for statefulset status.replicas updated to 0
Aug  1 08:36:18.258: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:36:18.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-8xnn7" for this suite.
Aug  1 08:36:26.526: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:36:26.739: INFO: namespace: e2e-tests-statefulset-8xnn7, resource: bindings, ignored listing per whitelist
Aug  1 08:36:26.746: INFO: namespace e2e-tests-statefulset-8xnn7 deletion completed in 8.409017966s

• [SLOW TEST:51.256 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:36:26.748: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug  1 08:36:27.691: INFO: Waiting up to 5m0s for pod "downwardapi-volume-74293f96-b437-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-projected-htj4k" to be "success or failure"
Aug  1 08:36:27.746: INFO: Pod "downwardapi-volume-74293f96-b437-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 52.22091ms
Aug  1 08:36:29.856: INFO: Pod "downwardapi-volume-74293f96-b437-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.16220889s
Aug  1 08:36:31.859: INFO: Pod "downwardapi-volume-74293f96-b437-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.165417319s
STEP: Saw pod success
Aug  1 08:36:31.859: INFO: Pod "downwardapi-volume-74293f96-b437-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 08:36:31.861: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod downwardapi-volume-74293f96-b437-11e9-aec8-12de527cd1b8 container client-container: <nil>
STEP: delete the pod
Aug  1 08:36:31.992: INFO: Waiting for pod downwardapi-volume-74293f96-b437-11e9-aec8-12de527cd1b8 to disappear
Aug  1 08:36:32.016: INFO: Pod downwardapi-volume-74293f96-b437-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:36:32.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-htj4k" for this suite.
Aug  1 08:36:38.054: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:36:38.125: INFO: namespace: e2e-tests-projected-htj4k, resource: bindings, ignored listing per whitelist
Aug  1 08:36:38.196: INFO: namespace e2e-tests-projected-htj4k deletion completed in 6.176741243s

• [SLOW TEST:11.448 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:36:38.199: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Aug  1 08:36:38.525: INFO: Waiting up to 5m0s for pod "downward-api-7a9ca113-b437-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-downward-api-55bjb" to be "success or failure"
Aug  1 08:36:38.551: INFO: Pod "downward-api-7a9ca113-b437-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 25.695777ms
Aug  1 08:36:40.597: INFO: Pod "downward-api-7a9ca113-b437-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.071549472s
Aug  1 08:36:42.756: INFO: Pod "downward-api-7a9ca113-b437-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.230931524s
Aug  1 08:36:44.763: INFO: Pod "downward-api-7a9ca113-b437-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.237346137s
STEP: Saw pod success
Aug  1 08:36:44.763: INFO: Pod "downward-api-7a9ca113-b437-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 08:36:44.767: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod downward-api-7a9ca113-b437-11e9-aec8-12de527cd1b8 container dapi-container: <nil>
STEP: delete the pod
Aug  1 08:36:44.850: INFO: Waiting for pod downward-api-7a9ca113-b437-11e9-aec8-12de527cd1b8 to disappear
Aug  1 08:36:44.944: INFO: Pod downward-api-7a9ca113-b437-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:36:44.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-55bjb" for this suite.
Aug  1 08:36:50.998: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:36:51.057: INFO: namespace: e2e-tests-downward-api-55bjb, resource: bindings, ignored listing per whitelist
Aug  1 08:36:51.199: INFO: namespace e2e-tests-downward-api-55bjb deletion completed in 6.252929799s

• [SLOW TEST:13.002 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:36:51.204: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:36:57.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-d6q4q" for this suite.
Aug  1 08:37:37.777: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:37:37.964: INFO: namespace: e2e-tests-kubelet-test-d6q4q, resource: bindings, ignored listing per whitelist
Aug  1 08:37:38.041: INFO: namespace e2e-tests-kubelet-test-d6q4q deletion completed in 40.308976535s

• [SLOW TEST:46.837 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:37:38.048: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-9e495e39-b437-11e9-aec8-12de527cd1b8
STEP: Creating a pod to test consume secrets
Aug  1 08:37:38.583: INFO: Waiting up to 5m0s for pod "pod-secrets-9e63fe2a-b437-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-secrets-sx65n" to be "success or failure"
Aug  1 08:37:38.717: INFO: Pod "pod-secrets-9e63fe2a-b437-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 133.345188ms
Aug  1 08:37:40.719: INFO: Pod "pod-secrets-9e63fe2a-b437-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.13626324s
Aug  1 08:37:42.908: INFO: Pod "pod-secrets-9e63fe2a-b437-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.325225422s
Aug  1 08:37:44.913: INFO: Pod "pod-secrets-9e63fe2a-b437-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.330078511s
STEP: Saw pod success
Aug  1 08:37:44.913: INFO: Pod "pod-secrets-9e63fe2a-b437-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 08:37:44.915: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod pod-secrets-9e63fe2a-b437-11e9-aec8-12de527cd1b8 container secret-volume-test: <nil>
STEP: delete the pod
Aug  1 08:37:45.068: INFO: Waiting for pod pod-secrets-9e63fe2a-b437-11e9-aec8-12de527cd1b8 to disappear
Aug  1 08:37:45.099: INFO: Pod pod-secrets-9e63fe2a-b437-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:37:45.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-sx65n" for this suite.
Aug  1 08:37:51.300: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:37:51.470: INFO: namespace: e2e-tests-secrets-sx65n, resource: bindings, ignored listing per whitelist
Aug  1 08:37:51.483: INFO: namespace e2e-tests-secrets-sx65n deletion completed in 6.379784916s

• [SLOW TEST:13.436 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:37:51.486: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0801 08:37:55.126061      12 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug  1 08:37:55.126: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:37:55.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-rmspm" for this suite.
Aug  1 08:38:01.401: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:38:01.479: INFO: namespace: e2e-tests-gc-rmspm, resource: bindings, ignored listing per whitelist
Aug  1 08:38:01.523: INFO: namespace e2e-tests-gc-rmspm deletion completed in 6.192398514s

• [SLOW TEST:10.037 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:38:01.524: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug  1 08:38:01.894: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ac52c4d9-b437-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-downward-api-7pfnq" to be "success or failure"
Aug  1 08:38:01.929: INFO: Pod "downwardapi-volume-ac52c4d9-b437-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 35.373502ms
Aug  1 08:38:04.197: INFO: Pod "downwardapi-volume-ac52c4d9-b437-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.302969965s
Aug  1 08:38:06.202: INFO: Pod "downwardapi-volume-ac52c4d9-b437-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.307806019s
STEP: Saw pod success
Aug  1 08:38:06.202: INFO: Pod "downwardapi-volume-ac52c4d9-b437-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 08:38:06.239: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod downwardapi-volume-ac52c4d9-b437-11e9-aec8-12de527cd1b8 container client-container: <nil>
STEP: delete the pod
Aug  1 08:38:06.415: INFO: Waiting for pod downwardapi-volume-ac52c4d9-b437-11e9-aec8-12de527cd1b8 to disappear
Aug  1 08:38:06.458: INFO: Pod downwardapi-volume-ac52c4d9-b437-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:38:06.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7pfnq" for this suite.
Aug  1 08:38:12.501: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:38:12.604: INFO: namespace: e2e-tests-downward-api-7pfnq, resource: bindings, ignored listing per whitelist
Aug  1 08:38:12.614: INFO: namespace e2e-tests-downward-api-7pfnq deletion completed in 6.151362261s

• [SLOW TEST:11.090 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:38:12.616: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug  1 08:38:12.990: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:38:14.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-jjnlq" for this suite.
Aug  1 08:38:20.643: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:38:20.735: INFO: namespace: e2e-tests-custom-resource-definition-jjnlq, resource: bindings, ignored listing per whitelist
Aug  1 08:38:20.749: INFO: namespace e2e-tests-custom-resource-definition-jjnlq deletion completed in 6.140729878s

• [SLOW TEST:8.133 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:38:20.754: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-2j4mg
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug  1 08:38:20.988: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug  1 08:38:51.508: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.1.172:8080/dial?request=hostName&protocol=udp&host=192.168.1.171&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-2j4mg PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  1 08:38:51.509: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
Aug  1 08:38:52.098: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:38:52.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-2j4mg" for this suite.
Aug  1 08:39:16.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:39:16.175: INFO: namespace: e2e-tests-pod-network-test-2j4mg, resource: bindings, ignored listing per whitelist
Aug  1 08:39:16.264: INFO: namespace e2e-tests-pod-network-test-2j4mg deletion completed in 24.162009364s

• [SLOW TEST:55.511 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:39:16.269: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:39:16.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-rrw8b" for this suite.
Aug  1 08:39:22.654: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:39:22.777: INFO: namespace: e2e-tests-services-rrw8b, resource: bindings, ignored listing per whitelist
Aug  1 08:39:22.779: INFO: namespace e2e-tests-services-rrw8b deletion completed in 6.227286944s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:6.511 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:39:22.784: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-dcc5d720-b437-11e9-aec8-12de527cd1b8
STEP: Creating a pod to test consume secrets
Aug  1 08:39:23.218: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-dcc94b4f-b437-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-projected-ft7fh" to be "success or failure"
Aug  1 08:39:23.258: INFO: Pod "pod-projected-secrets-dcc94b4f-b437-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 39.80839ms
Aug  1 08:39:25.381: INFO: Pod "pod-projected-secrets-dcc94b4f-b437-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.162931372s
Aug  1 08:39:27.393: INFO: Pod "pod-projected-secrets-dcc94b4f-b437-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.174891229s
Aug  1 08:39:29.436: INFO: Pod "pod-projected-secrets-dcc94b4f-b437-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.217617485s
STEP: Saw pod success
Aug  1 08:39:29.436: INFO: Pod "pod-projected-secrets-dcc94b4f-b437-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 08:39:29.439: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod pod-projected-secrets-dcc94b4f-b437-11e9-aec8-12de527cd1b8 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug  1 08:39:29.500: INFO: Waiting for pod pod-projected-secrets-dcc94b4f-b437-11e9-aec8-12de527cd1b8 to disappear
Aug  1 08:39:29.527: INFO: Pod pod-projected-secrets-dcc94b4f-b437-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:39:29.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ft7fh" for this suite.
Aug  1 08:39:35.621: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:39:35.860: INFO: namespace: e2e-tests-projected-ft7fh, resource: bindings, ignored listing per whitelist
Aug  1 08:39:35.891: INFO: namespace e2e-tests-projected-ft7fh deletion completed in 6.358893069s

• [SLOW TEST:13.108 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:39:35.896: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Aug  1 08:39:36.144: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:39:43.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-jcfcp" for this suite.
Aug  1 08:39:49.836: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:39:49.918: INFO: namespace: e2e-tests-init-container-jcfcp, resource: bindings, ignored listing per whitelist
Aug  1 08:39:50.059: INFO: namespace e2e-tests-init-container-jcfcp deletion completed in 6.367959423s

• [SLOW TEST:14.164 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:39:50.065: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-qqkp5.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-qqkp5.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-qqkp5.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-qqkp5.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-qqkp5.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-qqkp5.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug  1 08:39:58.787: INFO: Unable to read wheezy_udp@PodARecord from pod e2e-tests-dns-qqkp5/dns-test-ed0bb36b-b437-11e9-aec8-12de527cd1b8: the server could not find the requested resource (get pods dns-test-ed0bb36b-b437-11e9-aec8-12de527cd1b8)
Aug  1 08:39:58.789: INFO: Unable to read wheezy_tcp@PodARecord from pod e2e-tests-dns-qqkp5/dns-test-ed0bb36b-b437-11e9-aec8-12de527cd1b8: the server could not find the requested resource (get pods dns-test-ed0bb36b-b437-11e9-aec8-12de527cd1b8)
Aug  1 08:39:58.791: INFO: Unable to read jessie_udp@kubernetes.default from pod e2e-tests-dns-qqkp5/dns-test-ed0bb36b-b437-11e9-aec8-12de527cd1b8: the server could not find the requested resource (get pods dns-test-ed0bb36b-b437-11e9-aec8-12de527cd1b8)
Aug  1 08:39:58.794: INFO: Unable to read jessie_tcp@kubernetes.default from pod e2e-tests-dns-qqkp5/dns-test-ed0bb36b-b437-11e9-aec8-12de527cd1b8: the server could not find the requested resource (get pods dns-test-ed0bb36b-b437-11e9-aec8-12de527cd1b8)
Aug  1 08:39:58.796: INFO: Unable to read jessie_udp@kubernetes.default.svc from pod e2e-tests-dns-qqkp5/dns-test-ed0bb36b-b437-11e9-aec8-12de527cd1b8: the server could not find the requested resource (get pods dns-test-ed0bb36b-b437-11e9-aec8-12de527cd1b8)
Aug  1 08:39:58.798: INFO: Unable to read jessie_tcp@kubernetes.default.svc from pod e2e-tests-dns-qqkp5/dns-test-ed0bb36b-b437-11e9-aec8-12de527cd1b8: the server could not find the requested resource (get pods dns-test-ed0bb36b-b437-11e9-aec8-12de527cd1b8)
Aug  1 08:39:58.800: INFO: Unable to read jessie_udp@kubernetes.default.svc.cluster.local from pod e2e-tests-dns-qqkp5/dns-test-ed0bb36b-b437-11e9-aec8-12de527cd1b8: the server could not find the requested resource (get pods dns-test-ed0bb36b-b437-11e9-aec8-12de527cd1b8)
Aug  1 08:39:58.802: INFO: Unable to read jessie_tcp@kubernetes.default.svc.cluster.local from pod e2e-tests-dns-qqkp5/dns-test-ed0bb36b-b437-11e9-aec8-12de527cd1b8: the server could not find the requested resource (get pods dns-test-ed0bb36b-b437-11e9-aec8-12de527cd1b8)
Aug  1 08:39:58.804: INFO: Unable to read jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-qqkp5.svc.cluster.local from pod e2e-tests-dns-qqkp5/dns-test-ed0bb36b-b437-11e9-aec8-12de527cd1b8: the server could not find the requested resource (get pods dns-test-ed0bb36b-b437-11e9-aec8-12de527cd1b8)
Aug  1 08:39:58.807: INFO: Unable to read jessie_hosts@dns-querier-1 from pod e2e-tests-dns-qqkp5/dns-test-ed0bb36b-b437-11e9-aec8-12de527cd1b8: the server could not find the requested resource (get pods dns-test-ed0bb36b-b437-11e9-aec8-12de527cd1b8)
Aug  1 08:39:58.809: INFO: Unable to read jessie_udp@PodARecord from pod e2e-tests-dns-qqkp5/dns-test-ed0bb36b-b437-11e9-aec8-12de527cd1b8: the server could not find the requested resource (get pods dns-test-ed0bb36b-b437-11e9-aec8-12de527cd1b8)
Aug  1 08:39:58.812: INFO: Unable to read jessie_tcp@PodARecord from pod e2e-tests-dns-qqkp5/dns-test-ed0bb36b-b437-11e9-aec8-12de527cd1b8: the server could not find the requested resource (get pods dns-test-ed0bb36b-b437-11e9-aec8-12de527cd1b8)
Aug  1 08:39:58.812: INFO: Lookups using e2e-tests-dns-qqkp5/dns-test-ed0bb36b-b437-11e9-aec8-12de527cd1b8 failed for: [wheezy_udp@PodARecord wheezy_tcp@PodARecord jessie_udp@kubernetes.default jessie_tcp@kubernetes.default jessie_udp@kubernetes.default.svc jessie_tcp@kubernetes.default.svc jessie_udp@kubernetes.default.svc.cluster.local jessie_tcp@kubernetes.default.svc.cluster.local jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-qqkp5.svc.cluster.local jessie_hosts@dns-querier-1 jessie_udp@PodARecord jessie_tcp@PodARecord]

Aug  1 08:40:03.871: INFO: DNS probes using e2e-tests-dns-qqkp5/dns-test-ed0bb36b-b437-11e9-aec8-12de527cd1b8 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:40:04.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-qqkp5" for this suite.
Aug  1 08:40:12.720: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:40:12.893: INFO: namespace: e2e-tests-dns-qqkp5, resource: bindings, ignored listing per whitelist
Aug  1 08:40:12.959: INFO: namespace e2e-tests-dns-qqkp5 deletion completed in 8.542692793s

• [SLOW TEST:22.894 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:40:12.959: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug  1 08:40:13.465: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-rdk5d'
Aug  1 08:40:13.682: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug  1 08:40:13.682: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Aug  1 08:40:13.805: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-2n2k9]
Aug  1 08:40:13.829: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-2n2k9" in namespace "e2e-tests-kubectl-rdk5d" to be "running and ready"
Aug  1 08:40:14.070: INFO: Pod "e2e-test-nginx-rc-2n2k9": Phase="Pending", Reason="", readiness=false. Elapsed: 240.930072ms
Aug  1 08:40:16.110: INFO: Pod "e2e-test-nginx-rc-2n2k9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.281033977s
Aug  1 08:40:18.211: INFO: Pod "e2e-test-nginx-rc-2n2k9": Phase="Running", Reason="", readiness=true. Elapsed: 4.382540515s
Aug  1 08:40:18.211: INFO: Pod "e2e-test-nginx-rc-2n2k9" satisfied condition "running and ready"
Aug  1 08:40:18.211: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-2n2k9]
Aug  1 08:40:18.211: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-rdk5d'
Aug  1 08:40:19.253: INFO: stderr: ""
Aug  1 08:40:19.253: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1303
Aug  1 08:40:19.253: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-rdk5d'
Aug  1 08:40:19.548: INFO: stderr: ""
Aug  1 08:40:19.549: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:40:19.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-rdk5d" for this suite.
Aug  1 08:40:25.744: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:40:25.959: INFO: namespace: e2e-tests-kubectl-rdk5d, resource: bindings, ignored listing per whitelist
Aug  1 08:40:26.057: INFO: namespace e2e-tests-kubectl-rdk5d deletion completed in 6.427477608s

• [SLOW TEST:13.098 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:40:26.058: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug  1 08:40:26.517: INFO: (0) /api/v1/nodes/k8s-1-6lh7zebx7k5q-node-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 29.466889ms)
Aug  1 08:40:26.528: INFO: (1) /api/v1/nodes/k8s-1-6lh7zebx7k5q-node-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 4.625423ms)
Aug  1 08:40:26.533: INFO: (2) /api/v1/nodes/k8s-1-6lh7zebx7k5q-node-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 4.620727ms)
Aug  1 08:40:26.538: INFO: (3) /api/v1/nodes/k8s-1-6lh7zebx7k5q-node-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 4.901323ms)
Aug  1 08:40:26.542: INFO: (4) /api/v1/nodes/k8s-1-6lh7zebx7k5q-node-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 3.825529ms)
Aug  1 08:40:26.547: INFO: (5) /api/v1/nodes/k8s-1-6lh7zebx7k5q-node-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 4.832356ms)
Aug  1 08:40:26.552: INFO: (6) /api/v1/nodes/k8s-1-6lh7zebx7k5q-node-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 4.606532ms)
Aug  1 08:40:26.556: INFO: (7) /api/v1/nodes/k8s-1-6lh7zebx7k5q-node-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 4.068928ms)
Aug  1 08:40:26.561: INFO: (8) /api/v1/nodes/k8s-1-6lh7zebx7k5q-node-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 4.938329ms)
Aug  1 08:40:26.593: INFO: (9) /api/v1/nodes/k8s-1-6lh7zebx7k5q-node-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 31.87453ms)
Aug  1 08:40:26.607: INFO: (10) /api/v1/nodes/k8s-1-6lh7zebx7k5q-node-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 13.062284ms)
Aug  1 08:40:26.621: INFO: (11) /api/v1/nodes/k8s-1-6lh7zebx7k5q-node-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 13.353047ms)
Aug  1 08:40:26.629: INFO: (12) /api/v1/nodes/k8s-1-6lh7zebx7k5q-node-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 7.753597ms)
Aug  1 08:40:26.633: INFO: (13) /api/v1/nodes/k8s-1-6lh7zebx7k5q-node-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 3.501086ms)
Aug  1 08:40:26.644: INFO: (14) /api/v1/nodes/k8s-1-6lh7zebx7k5q-node-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 11.144997ms)
Aug  1 08:40:26.649: INFO: (15) /api/v1/nodes/k8s-1-6lh7zebx7k5q-node-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 4.157071ms)
Aug  1 08:40:26.653: INFO: (16) /api/v1/nodes/k8s-1-6lh7zebx7k5q-node-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 3.782186ms)
Aug  1 08:40:26.657: INFO: (17) /api/v1/nodes/k8s-1-6lh7zebx7k5q-node-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 3.700784ms)
Aug  1 08:40:26.662: INFO: (18) /api/v1/nodes/k8s-1-6lh7zebx7k5q-node-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 4.028873ms)
Aug  1 08:40:26.666: INFO: (19) /api/v1/nodes/k8s-1-6lh7zebx7k5q-node-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 4.245625ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:40:26.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-j5dbj" for this suite.
Aug  1 08:40:32.750: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:40:32.772: INFO: namespace: e2e-tests-proxy-j5dbj, resource: bindings, ignored listing per whitelist
Aug  1 08:40:32.858: INFO: namespace e2e-tests-proxy-j5dbj deletion completed in 6.187954271s

• [SLOW TEST:6.800 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:40:32.944: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug  1 08:40:33.277: INFO: Waiting up to 5m0s for pod "downwardapi-volume-06833e28-b438-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-downward-api-hh827" to be "success or failure"
Aug  1 08:40:33.300: INFO: Pod "downwardapi-volume-06833e28-b438-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 22.876426ms
Aug  1 08:40:35.563: INFO: Pod "downwardapi-volume-06833e28-b438-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.286447715s
Aug  1 08:40:37.578: INFO: Pod "downwardapi-volume-06833e28-b438-11e9-aec8-12de527cd1b8": Phase="Running", Reason="", readiness=true. Elapsed: 4.301329076s
Aug  1 08:40:39.581: INFO: Pod "downwardapi-volume-06833e28-b438-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.304098084s
STEP: Saw pod success
Aug  1 08:40:39.581: INFO: Pod "downwardapi-volume-06833e28-b438-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 08:40:39.582: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod downwardapi-volume-06833e28-b438-11e9-aec8-12de527cd1b8 container client-container: <nil>
STEP: delete the pod
Aug  1 08:40:39.667: INFO: Waiting for pod downwardapi-volume-06833e28-b438-11e9-aec8-12de527cd1b8 to disappear
Aug  1 08:40:39.816: INFO: Pod downwardapi-volume-06833e28-b438-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:40:39.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-hh827" for this suite.
Aug  1 08:40:46.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:40:46.354: INFO: namespace: e2e-tests-downward-api-hh827, resource: bindings, ignored listing per whitelist
Aug  1 08:40:46.433: INFO: namespace e2e-tests-downward-api-hh827 deletion completed in 6.373610876s

• [SLOW TEST:13.489 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:40:46.437: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Aug  1 08:40:46.840: INFO: Waiting up to 5m0s for pod "pod-0e9feea0-b438-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-emptydir-f8gbj" to be "success or failure"
Aug  1 08:40:46.874: INFO: Pod "pod-0e9feea0-b438-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 34.111881ms
Aug  1 08:40:49.082: INFO: Pod "pod-0e9feea0-b438-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.241906662s
Aug  1 08:40:51.084: INFO: Pod "pod-0e9feea0-b438-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.244596137s
STEP: Saw pod success
Aug  1 08:40:51.084: INFO: Pod "pod-0e9feea0-b438-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 08:40:51.086: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod pod-0e9feea0-b438-11e9-aec8-12de527cd1b8 container test-container: <nil>
STEP: delete the pod
Aug  1 08:40:51.476: INFO: Waiting for pod pod-0e9feea0-b438-11e9-aec8-12de527cd1b8 to disappear
Aug  1 08:40:51.557: INFO: Pod pod-0e9feea0-b438-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:40:51.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-f8gbj" for this suite.
Aug  1 08:40:57.743: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:40:57.778: INFO: namespace: e2e-tests-emptydir-f8gbj, resource: bindings, ignored listing per whitelist
Aug  1 08:40:57.873: INFO: namespace e2e-tests-emptydir-f8gbj deletion completed in 6.313899293s

• [SLOW TEST:11.438 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:40:57.877: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
Aug  1 08:41:06.539: INFO: 10 pods remaining
Aug  1 08:41:06.539: INFO: 9 pods has nil DeletionTimestamp
Aug  1 08:41:06.539: INFO: 
Aug  1 08:41:07.258: INFO: 7 pods remaining
Aug  1 08:41:07.258: INFO: 0 pods has nil DeletionTimestamp
Aug  1 08:41:07.258: INFO: 
Aug  1 08:41:08.030: INFO: 0 pods remaining
Aug  1 08:41:08.030: INFO: 0 pods has nil DeletionTimestamp
Aug  1 08:41:08.030: INFO: 
STEP: Gathering metrics
W0801 08:41:08.627959      12 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug  1 08:41:08.628: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:41:08.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-pzp4d" for this suite.
Aug  1 08:41:23.294: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:41:23.635: INFO: namespace: e2e-tests-gc-pzp4d, resource: bindings, ignored listing per whitelist
Aug  1 08:41:23.652: INFO: namespace e2e-tests-gc-pzp4d deletion completed in 15.020542905s

• [SLOW TEST:25.776 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:41:23.827: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug  1 08:41:24.797: INFO: Creating ReplicaSet my-hostname-basic-25453a10-b438-11e9-aec8-12de527cd1b8
Aug  1 08:41:26.196: INFO: Pod name my-hostname-basic-25453a10-b438-11e9-aec8-12de527cd1b8: Found 1 pods out of 1
Aug  1 08:41:26.196: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-25453a10-b438-11e9-aec8-12de527cd1b8" is running
Aug  1 08:41:36.216: INFO: Pod "my-hostname-basic-25453a10-b438-11e9-aec8-12de527cd1b8-9hslk" is running (conditions: [{Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-01 08:41:24 +0000 UTC Reason: Message:}])
Aug  1 08:41:36.216: INFO: Trying to dial the pod
Aug  1 08:41:41.411: INFO: Controller my-hostname-basic-25453a10-b438-11e9-aec8-12de527cd1b8: Got expected result from replica 1 [my-hostname-basic-25453a10-b438-11e9-aec8-12de527cd1b8-9hslk]: "my-hostname-basic-25453a10-b438-11e9-aec8-12de527cd1b8-9hslk", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:41:41.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-56fpc" for this suite.
Aug  1 08:41:49.477: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:41:49.989: INFO: namespace: e2e-tests-replicaset-56fpc, resource: bindings, ignored listing per whitelist
Aug  1 08:41:50.558: INFO: namespace e2e-tests-replicaset-56fpc deletion completed in 9.142385567s

• [SLOW TEST:26.731 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:41:50.563: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-34e1e3f3-b438-11e9-aec8-12de527cd1b8
STEP: Creating a pod to test consume secrets
Aug  1 08:41:51.051: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-34e2a3bf-b438-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-projected-zlccl" to be "success or failure"
Aug  1 08:41:51.193: INFO: Pod "pod-projected-secrets-34e2a3bf-b438-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 141.676155ms
Aug  1 08:41:53.289: INFO: Pod "pod-projected-secrets-34e2a3bf-b438-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.237512398s
Aug  1 08:41:55.292: INFO: Pod "pod-projected-secrets-34e2a3bf-b438-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.240314474s
STEP: Saw pod success
Aug  1 08:41:55.292: INFO: Pod "pod-projected-secrets-34e2a3bf-b438-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 08:41:55.293: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod pod-projected-secrets-34e2a3bf-b438-11e9-aec8-12de527cd1b8 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug  1 08:41:55.587: INFO: Waiting for pod pod-projected-secrets-34e2a3bf-b438-11e9-aec8-12de527cd1b8 to disappear
Aug  1 08:41:55.867: INFO: Pod pod-projected-secrets-34e2a3bf-b438-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:41:55.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zlccl" for this suite.
Aug  1 08:42:02.433: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:42:02.650: INFO: namespace: e2e-tests-projected-zlccl, resource: bindings, ignored listing per whitelist
Aug  1 08:42:02.698: INFO: namespace e2e-tests-projected-zlccl deletion completed in 6.826809354s

• [SLOW TEST:12.136 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:42:02.718: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Aug  1 08:42:03.084: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:42:10.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-wcz9h" for this suite.
Aug  1 08:42:34.873: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:42:35.040: INFO: namespace: e2e-tests-init-container-wcz9h, resource: bindings, ignored listing per whitelist
Aug  1 08:42:35.126: INFO: namespace e2e-tests-init-container-wcz9h deletion completed in 24.29005298s

• [SLOW TEST:32.409 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:42:35.135: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Aug  1 08:42:47.893: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug  1 08:42:47.898: INFO: Pod pod-with-poststart-exec-hook still exists
Aug  1 08:42:49.898: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug  1 08:42:49.901: INFO: Pod pod-with-poststart-exec-hook still exists
Aug  1 08:42:51.898: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug  1 08:42:51.904: INFO: Pod pod-with-poststart-exec-hook still exists
Aug  1 08:42:53.898: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug  1 08:42:53.906: INFO: Pod pod-with-poststart-exec-hook still exists
Aug  1 08:42:55.898: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug  1 08:42:55.904: INFO: Pod pod-with-poststart-exec-hook still exists
Aug  1 08:42:57.898: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug  1 08:42:57.905: INFO: Pod pod-with-poststart-exec-hook still exists
Aug  1 08:42:59.898: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug  1 08:42:59.909: INFO: Pod pod-with-poststart-exec-hook still exists
Aug  1 08:43:01.898: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug  1 08:43:01.984: INFO: Pod pod-with-poststart-exec-hook still exists
Aug  1 08:43:03.899: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug  1 08:43:03.996: INFO: Pod pod-with-poststart-exec-hook still exists
Aug  1 08:43:05.898: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug  1 08:43:05.904: INFO: Pod pod-with-poststart-exec-hook still exists
Aug  1 08:43:07.898: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug  1 08:43:07.906: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:43:07.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-8mqdz" for this suite.
Aug  1 08:43:33.958: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:43:34.028: INFO: namespace: e2e-tests-container-lifecycle-hook-8mqdz, resource: bindings, ignored listing per whitelist
Aug  1 08:43:34.080: INFO: namespace e2e-tests-container-lifecycle-hook-8mqdz deletion completed in 26.164772399s

• [SLOW TEST:58.946 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:43:34.086: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Aug  1 08:43:34.565: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-683321083 proxy --unix-socket=/tmp/kubectl-proxy-unix123890718/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:43:34.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-s2p2g" for this suite.
Aug  1 08:43:41.062: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:43:41.092: INFO: namespace: e2e-tests-kubectl-s2p2g, resource: bindings, ignored listing per whitelist
Aug  1 08:43:41.176: INFO: namespace e2e-tests-kubectl-s2p2g deletion completed in 6.275545838s

• [SLOW TEST:7.091 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:43:41.181: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-d5fj
STEP: Creating a pod to test atomic-volume-subpath
Aug  1 08:43:41.871: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-d5fj" in namespace "e2e-tests-subpath-grtph" to be "success or failure"
Aug  1 08:43:41.944: INFO: Pod "pod-subpath-test-downwardapi-d5fj": Phase="Pending", Reason="", readiness=false. Elapsed: 72.334133ms
Aug  1 08:43:43.947: INFO: Pod "pod-subpath-test-downwardapi-d5fj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.075549977s
Aug  1 08:43:46.096: INFO: Pod "pod-subpath-test-downwardapi-d5fj": Phase="Pending", Reason="", readiness=false. Elapsed: 4.224599519s
Aug  1 08:43:48.114: INFO: Pod "pod-subpath-test-downwardapi-d5fj": Phase="Pending", Reason="", readiness=false. Elapsed: 6.242486588s
Aug  1 08:43:50.117: INFO: Pod "pod-subpath-test-downwardapi-d5fj": Phase="Running", Reason="", readiness=false. Elapsed: 8.245268604s
Aug  1 08:43:52.119: INFO: Pod "pod-subpath-test-downwardapi-d5fj": Phase="Running", Reason="", readiness=false. Elapsed: 10.24774861s
Aug  1 08:43:54.123: INFO: Pod "pod-subpath-test-downwardapi-d5fj": Phase="Running", Reason="", readiness=false. Elapsed: 12.251943131s
Aug  1 08:43:56.126: INFO: Pod "pod-subpath-test-downwardapi-d5fj": Phase="Running", Reason="", readiness=false. Elapsed: 14.254668525s
Aug  1 08:43:58.131: INFO: Pod "pod-subpath-test-downwardapi-d5fj": Phase="Running", Reason="", readiness=false. Elapsed: 16.259484318s
Aug  1 08:44:00.133: INFO: Pod "pod-subpath-test-downwardapi-d5fj": Phase="Running", Reason="", readiness=false. Elapsed: 18.26185814s
Aug  1 08:44:02.136: INFO: Pod "pod-subpath-test-downwardapi-d5fj": Phase="Running", Reason="", readiness=false. Elapsed: 20.265023133s
Aug  1 08:44:04.156: INFO: Pod "pod-subpath-test-downwardapi-d5fj": Phase="Running", Reason="", readiness=false. Elapsed: 22.284502743s
Aug  1 08:44:06.159: INFO: Pod "pod-subpath-test-downwardapi-d5fj": Phase="Running", Reason="", readiness=false. Elapsed: 24.287806433s
Aug  1 08:44:08.162: INFO: Pod "pod-subpath-test-downwardapi-d5fj": Phase="Running", Reason="", readiness=false. Elapsed: 26.290297145s
Aug  1 08:44:10.164: INFO: Pod "pod-subpath-test-downwardapi-d5fj": Phase="Succeeded", Reason="", readiness=false. Elapsed: 28.293041393s
STEP: Saw pod success
Aug  1 08:44:10.164: INFO: Pod "pod-subpath-test-downwardapi-d5fj" satisfied condition "success or failure"
Aug  1 08:44:10.166: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod pod-subpath-test-downwardapi-d5fj container test-container-subpath-downwardapi-d5fj: <nil>
STEP: delete the pod
Aug  1 08:44:10.816: INFO: Waiting for pod pod-subpath-test-downwardapi-d5fj to disappear
Aug  1 08:44:11.066: INFO: Pod pod-subpath-test-downwardapi-d5fj no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-d5fj
Aug  1 08:44:11.069: INFO: Deleting pod "pod-subpath-test-downwardapi-d5fj" in namespace "e2e-tests-subpath-grtph"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:44:11.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-grtph" for this suite.
Aug  1 08:44:17.927: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:44:18.275: INFO: namespace: e2e-tests-subpath-grtph, resource: bindings, ignored listing per whitelist
Aug  1 08:44:18.480: INFO: namespace e2e-tests-subpath-grtph deletion completed in 7.048268747s

• [SLOW TEST:37.299 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:44:18.480: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Aug  1 08:44:19.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 create -f - --namespace=e2e-tests-kubectl-75njt'
Aug  1 08:44:19.679: INFO: stderr: ""
Aug  1 08:44:19.679: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug  1 08:44:19.728: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-75njt'
Aug  1 08:44:20.106: INFO: stderr: ""
Aug  1 08:44:20.106: INFO: stdout: "update-demo-nautilus-79p4b update-demo-nautilus-d4c6c "
Aug  1 08:44:20.106: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods update-demo-nautilus-79p4b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-75njt'
Aug  1 08:44:20.243: INFO: stderr: ""
Aug  1 08:44:20.243: INFO: stdout: ""
Aug  1 08:44:20.243: INFO: update-demo-nautilus-79p4b is created but not running
Aug  1 08:44:25.263: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-75njt'
Aug  1 08:44:25.605: INFO: stderr: ""
Aug  1 08:44:25.605: INFO: stdout: "update-demo-nautilus-79p4b update-demo-nautilus-d4c6c "
Aug  1 08:44:25.605: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods update-demo-nautilus-79p4b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-75njt'
Aug  1 08:44:25.791: INFO: stderr: ""
Aug  1 08:44:25.791: INFO: stdout: ""
Aug  1 08:44:25.791: INFO: update-demo-nautilus-79p4b is created but not running
Aug  1 08:44:30.792: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-75njt'
Aug  1 08:44:30.937: INFO: stderr: ""
Aug  1 08:44:30.937: INFO: stdout: "update-demo-nautilus-79p4b update-demo-nautilus-d4c6c "
Aug  1 08:44:30.956: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods update-demo-nautilus-79p4b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-75njt'
Aug  1 08:44:31.178: INFO: stderr: ""
Aug  1 08:44:31.178: INFO: stdout: "true"
Aug  1 08:44:31.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods update-demo-nautilus-79p4b -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-75njt'
Aug  1 08:44:31.384: INFO: stderr: ""
Aug  1 08:44:31.384: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug  1 08:44:31.384: INFO: validating pod update-demo-nautilus-79p4b
Aug  1 08:44:31.422: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug  1 08:44:31.440: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug  1 08:44:31.441: INFO: update-demo-nautilus-79p4b is verified up and running
Aug  1 08:44:31.441: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods update-demo-nautilus-d4c6c -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-75njt'
Aug  1 08:44:31.565: INFO: stderr: ""
Aug  1 08:44:31.565: INFO: stdout: "true"
Aug  1 08:44:31.565: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods update-demo-nautilus-d4c6c -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-75njt'
Aug  1 08:44:31.751: INFO: stderr: ""
Aug  1 08:44:31.751: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug  1 08:44:31.751: INFO: validating pod update-demo-nautilus-d4c6c
Aug  1 08:44:31.759: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug  1 08:44:31.759: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug  1 08:44:31.759: INFO: update-demo-nautilus-d4c6c is verified up and running
STEP: rolling-update to new replication controller
Aug  1 08:44:31.762: INFO: scanned /root for discovery docs: <nil>
Aug  1 08:44:31.775: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-75njt'
Aug  1 08:45:11.264: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Aug  1 08:45:11.264: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug  1 08:45:11.264: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-75njt'
Aug  1 08:45:11.825: INFO: stderr: ""
Aug  1 08:45:11.825: INFO: stdout: "update-demo-kitten-28rbk update-demo-kitten-5rd28 "
Aug  1 08:45:11.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods update-demo-kitten-28rbk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-75njt'
Aug  1 08:45:11.999: INFO: stderr: ""
Aug  1 08:45:11.999: INFO: stdout: "true"
Aug  1 08:45:11.999: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods update-demo-kitten-28rbk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-75njt'
Aug  1 08:45:12.184: INFO: stderr: ""
Aug  1 08:45:12.184: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Aug  1 08:45:12.184: INFO: validating pod update-demo-kitten-28rbk
Aug  1 08:45:12.195: INFO: got data: {
  "image": "kitten.jpg"
}

Aug  1 08:45:12.195: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Aug  1 08:45:12.195: INFO: update-demo-kitten-28rbk is verified up and running
Aug  1 08:45:12.195: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods update-demo-kitten-5rd28 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-75njt'
Aug  1 08:45:12.309: INFO: stderr: ""
Aug  1 08:45:12.309: INFO: stdout: "true"
Aug  1 08:45:12.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods update-demo-kitten-5rd28 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-75njt'
Aug  1 08:45:12.435: INFO: stderr: ""
Aug  1 08:45:12.435: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Aug  1 08:45:12.435: INFO: validating pod update-demo-kitten-5rd28
Aug  1 08:45:12.440: INFO: got data: {
  "image": "kitten.jpg"
}

Aug  1 08:45:12.440: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Aug  1 08:45:12.440: INFO: update-demo-kitten-5rd28 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:45:12.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-75njt" for this suite.
Aug  1 08:45:38.485: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:45:38.567: INFO: namespace: e2e-tests-kubectl-75njt, resource: bindings, ignored listing per whitelist
Aug  1 08:45:38.597: INFO: namespace e2e-tests-kubectl-75njt deletion completed in 26.152127465s

• [SLOW TEST:80.117 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:45:38.648: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Aug  1 08:45:39.143: INFO: Waiting up to 5m0s for pod "pod-bcd994c7-b438-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-emptydir-wvfs4" to be "success or failure"
Aug  1 08:45:39.432: INFO: Pod "pod-bcd994c7-b438-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 288.884257ms
Aug  1 08:45:41.925: INFO: Pod "pod-bcd994c7-b438-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.781912846s
Aug  1 08:45:43.935: INFO: Pod "pod-bcd994c7-b438-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.791741609s
Aug  1 08:45:45.989: INFO: Pod "pod-bcd994c7-b438-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.845582756s
STEP: Saw pod success
Aug  1 08:45:45.989: INFO: Pod "pod-bcd994c7-b438-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 08:45:45.990: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod pod-bcd994c7-b438-11e9-aec8-12de527cd1b8 container test-container: <nil>
STEP: delete the pod
Aug  1 08:45:46.124: INFO: Waiting for pod pod-bcd994c7-b438-11e9-aec8-12de527cd1b8 to disappear
Aug  1 08:45:46.406: INFO: Pod pod-bcd994c7-b438-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:45:46.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wvfs4" for this suite.
Aug  1 08:45:52.454: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:45:52.482: INFO: namespace: e2e-tests-emptydir-wvfs4, resource: bindings, ignored listing per whitelist
Aug  1 08:45:52.557: INFO: namespace e2e-tests-emptydir-wvfs4 deletion completed in 6.146163629s

• [SLOW TEST:13.909 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:45:52.576: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug  1 08:45:52.848: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:45:57.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-5dnkj" for this suite.
Aug  1 08:46:37.714: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:46:37.834: INFO: namespace: e2e-tests-pods-5dnkj, resource: bindings, ignored listing per whitelist
Aug  1 08:46:37.893: INFO: namespace e2e-tests-pods-5dnkj deletion completed in 40.276190165s

• [SLOW TEST:45.318 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:46:37.908: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug  1 08:46:58.278: INFO: Container started at 2019-08-01 08:46:41 +0000 UTC, pod became ready at 2019-08-01 08:46:58 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:46:58.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-phtbs" for this suite.
Aug  1 08:47:20.378: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:47:20.510: INFO: namespace: e2e-tests-container-probe-phtbs, resource: bindings, ignored listing per whitelist
Aug  1 08:47:20.585: INFO: namespace e2e-tests-container-probe-phtbs deletion completed in 22.282222008s

• [SLOW TEST:42.677 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:47:20.588: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:47:26.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-mzl78" for this suite.
Aug  1 08:48:13.104: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:48:13.166: INFO: namespace: e2e-tests-kubelet-test-mzl78, resource: bindings, ignored listing per whitelist
Aug  1 08:48:13.237: INFO: namespace e2e-tests-kubelet-test-mzl78 deletion completed in 46.24808962s

• [SLOW TEST:52.649 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a read only busybox container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:186
    should not write to root filesystem [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:48:13.238: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1052
STEP: creating the pod
Aug  1 08:48:13.551: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 create -f - --namespace=e2e-tests-kubectl-snhvh'
Aug  1 08:48:16.666: INFO: stderr: ""
Aug  1 08:48:16.666: INFO: stdout: "pod/pause created\n"
Aug  1 08:48:16.666: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Aug  1 08:48:16.667: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-snhvh" to be "running and ready"
Aug  1 08:48:16.715: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 47.832045ms
Aug  1 08:48:19.021: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.354060232s
Aug  1 08:48:21.027: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.359824345s
Aug  1 08:48:21.027: INFO: Pod "pause" satisfied condition "running and ready"
Aug  1 08:48:21.027: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Aug  1 08:48:21.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-snhvh'
Aug  1 08:48:21.192: INFO: stderr: ""
Aug  1 08:48:21.192: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Aug  1 08:48:21.192: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pod pause -L testing-label --namespace=e2e-tests-kubectl-snhvh'
Aug  1 08:48:21.437: INFO: stderr: ""
Aug  1 08:48:21.437: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Aug  1 08:48:21.438: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 label pods pause testing-label- --namespace=e2e-tests-kubectl-snhvh'
Aug  1 08:48:21.591: INFO: stderr: ""
Aug  1 08:48:21.591: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Aug  1 08:48:21.591: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pod pause -L testing-label --namespace=e2e-tests-kubectl-snhvh'
Aug  1 08:48:21.717: INFO: stderr: ""
Aug  1 08:48:21.717: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1059
STEP: using delete to clean up resources
Aug  1 08:48:21.717: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-snhvh'
Aug  1 08:48:22.011: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug  1 08:48:22.011: INFO: stdout: "pod \"pause\" force deleted\n"
Aug  1 08:48:22.011: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-snhvh'
Aug  1 08:48:22.355: INFO: stderr: "No resources found.\n"
Aug  1 08:48:22.355: INFO: stdout: ""
Aug  1 08:48:22.355: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods -l name=pause --namespace=e2e-tests-kubectl-snhvh -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug  1 08:48:22.741: INFO: stderr: ""
Aug  1 08:48:22.741: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:48:22.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-snhvh" for this suite.
Aug  1 08:48:28.949: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:48:29.070: INFO: namespace: e2e-tests-kubectl-snhvh, resource: bindings, ignored listing per whitelist
Aug  1 08:48:29.087: INFO: namespace e2e-tests-kubectl-snhvh deletion completed in 6.172224069s

• [SLOW TEST:15.850 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:48:29.092: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:48:37.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-6t4sq" for this suite.
Aug  1 08:48:45.997: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:48:46.131: INFO: namespace: e2e-tests-kubelet-test-6t4sq, resource: bindings, ignored listing per whitelist
Aug  1 08:48:46.140: INFO: namespace e2e-tests-kubelet-test-6t4sq deletion completed in 8.279513059s

• [SLOW TEST:17.049 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:48:46.141: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug  1 08:48:46.419: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2c7b9249-b439-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-downward-api-lmwkx" to be "success or failure"
Aug  1 08:48:46.445: INFO: Pod "downwardapi-volume-2c7b9249-b439-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 26.374978ms
Aug  1 08:48:48.686: INFO: Pod "downwardapi-volume-2c7b9249-b439-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.267177179s
Aug  1 08:48:50.689: INFO: Pod "downwardapi-volume-2c7b9249-b439-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.27079122s
STEP: Saw pod success
Aug  1 08:48:50.690: INFO: Pod "downwardapi-volume-2c7b9249-b439-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 08:48:50.875: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod downwardapi-volume-2c7b9249-b439-11e9-aec8-12de527cd1b8 container client-container: <nil>
STEP: delete the pod
Aug  1 08:48:51.200: INFO: Waiting for pod downwardapi-volume-2c7b9249-b439-11e9-aec8-12de527cd1b8 to disappear
Aug  1 08:48:51.564: INFO: Pod downwardapi-volume-2c7b9249-b439-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:48:51.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-lmwkx" for this suite.
Aug  1 08:48:57.908: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:48:57.967: INFO: namespace: e2e-tests-downward-api-lmwkx, resource: bindings, ignored listing per whitelist
Aug  1 08:48:58.121: INFO: namespace e2e-tests-downward-api-lmwkx deletion completed in 6.459584887s

• [SLOW TEST:11.980 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:48:58.124: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-scbcm
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug  1 08:48:58.366: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug  1 08:49:34.827: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 192.168.1.196 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-scbcm PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  1 08:49:34.828: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
Aug  1 08:49:36.226: INFO: Found all expected endpoints: [netserver-0]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:49:36.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-scbcm" for this suite.
Aug  1 08:50:02.284: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:50:02.452: INFO: namespace: e2e-tests-pod-network-test-scbcm, resource: bindings, ignored listing per whitelist
Aug  1 08:50:02.552: INFO: namespace e2e-tests-pod-network-test-scbcm deletion completed in 26.296750183s

• [SLOW TEST:64.429 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:50:02.553: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug  1 08:50:03.044: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5a2a17ba-b439-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-downward-api-tpztf" to be "success or failure"
Aug  1 08:50:03.104: INFO: Pod "downwardapi-volume-5a2a17ba-b439-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 59.638408ms
Aug  1 08:50:05.172: INFO: Pod "downwardapi-volume-5a2a17ba-b439-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.127382897s
Aug  1 08:50:07.204: INFO: Pod "downwardapi-volume-5a2a17ba-b439-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.160027156s
Aug  1 08:50:09.211: INFO: Pod "downwardapi-volume-5a2a17ba-b439-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.166540201s
STEP: Saw pod success
Aug  1 08:50:09.212: INFO: Pod "downwardapi-volume-5a2a17ba-b439-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 08:50:09.215: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod downwardapi-volume-5a2a17ba-b439-11e9-aec8-12de527cd1b8 container client-container: <nil>
STEP: delete the pod
Aug  1 08:50:09.444: INFO: Waiting for pod downwardapi-volume-5a2a17ba-b439-11e9-aec8-12de527cd1b8 to disappear
Aug  1 08:50:09.475: INFO: Pod downwardapi-volume-5a2a17ba-b439-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:50:09.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-tpztf" for this suite.
Aug  1 08:50:15.518: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:50:15.641: INFO: namespace: e2e-tests-downward-api-tpztf, resource: bindings, ignored listing per whitelist
Aug  1 08:50:15.777: INFO: namespace e2e-tests-downward-api-tpztf deletion completed in 6.297704665s

• [SLOW TEST:13.224 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:50:15.795: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Aug  1 08:50:16.057: INFO: Waiting up to 5m0s for pod "pod-61e81a5c-b439-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-emptydir-24822" to be "success or failure"
Aug  1 08:50:16.106: INFO: Pod "pod-61e81a5c-b439-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 48.738264ms
Aug  1 08:50:18.115: INFO: Pod "pod-61e81a5c-b439-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05749205s
Aug  1 08:50:20.119: INFO: Pod "pod-61e81a5c-b439-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.061783757s
Aug  1 08:50:22.123: INFO: Pod "pod-61e81a5c-b439-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.065691003s
STEP: Saw pod success
Aug  1 08:50:22.123: INFO: Pod "pod-61e81a5c-b439-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 08:50:22.125: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod pod-61e81a5c-b439-11e9-aec8-12de527cd1b8 container test-container: <nil>
STEP: delete the pod
Aug  1 08:50:22.269: INFO: Waiting for pod pod-61e81a5c-b439-11e9-aec8-12de527cd1b8 to disappear
Aug  1 08:50:22.292: INFO: Pod pod-61e81a5c-b439-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:50:22.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-24822" for this suite.
Aug  1 08:50:28.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:50:28.380: INFO: namespace: e2e-tests-emptydir-24822, resource: bindings, ignored listing per whitelist
Aug  1 08:50:28.444: INFO: namespace e2e-tests-emptydir-24822 deletion completed in 6.148930261s

• [SLOW TEST:12.650 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:50:28.460: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug  1 08:50:28.694: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-2slcb'
Aug  1 08:50:28.831: INFO: stderr: ""
Aug  1 08:50:28.831: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Aug  1 08:50:33.985: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-2slcb -o json'
Aug  1 08:50:34.101: INFO: stderr: ""
Aug  1 08:50:34.101: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"192.168.1.200/32\"\n        },\n        \"creationTimestamp\": \"2019-08-01T08:50:28Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-2slcb\",\n        \"resourceVersion\": \"18705\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-2slcb/pods/e2e-test-nginx-pod\",\n        \"uid\": \"693e79b6-b439-11e9-8923-fa163ec474fb\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-zw4mv\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"k8s-1-6lh7zebx7k5q-node-0\",\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-zw4mv\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-zw4mv\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-01T08:50:28Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-01T08:50:32Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-01T08:50:32Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-01T08:50:28Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://3e282dcfa0bf130e3c439b0698e0b114623e1b73c256cb04a8dba925e6e4c965\",\n                \"image\": \"docker.io/nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://docker.io/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-08-01T08:50:32Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.0.0.23\",\n        \"phase\": \"Running\",\n        \"podIP\": \"192.168.1.200\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-08-01T08:50:28Z\"\n    }\n}\n"
STEP: replace the image in the pod
Aug  1 08:50:34.111: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 replace -f - --namespace=e2e-tests-kubectl-2slcb'
Aug  1 08:50:34.710: INFO: stderr: ""
Aug  1 08:50:34.710: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
Aug  1 08:50:34.816: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-2slcb'
Aug  1 08:50:38.772: INFO: stderr: ""
Aug  1 08:50:38.772: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:50:38.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2slcb" for this suite.
Aug  1 08:50:44.910: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:50:45.135: INFO: namespace: e2e-tests-kubectl-2slcb, resource: bindings, ignored listing per whitelist
Aug  1 08:50:45.194: INFO: namespace e2e-tests-kubectl-2slcb deletion completed in 6.416472855s

• [SLOW TEST:16.734 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:50:45.199: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-h9hsb
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Aug  1 08:50:45.990: INFO: Found 0 stateful pods, waiting for 3
Aug  1 08:50:56.162: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug  1 08:50:56.180: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug  1 08:50:56.180: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Aug  1 08:51:05.994: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug  1 08:51:05.994: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug  1 08:51:05.994: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Aug  1 08:51:06.035: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Aug  1 08:51:16.268: INFO: Updating stateful set ss2
Aug  1 08:51:16.427: INFO: Waiting for Pod e2e-tests-statefulset-h9hsb/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Aug  1 08:51:28.259: INFO: Found 2 stateful pods, waiting for 3
Aug  1 08:51:38.264: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug  1 08:51:38.264: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug  1 08:51:38.264: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Aug  1 08:51:48.267: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug  1 08:51:48.268: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug  1 08:51:48.268: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Aug  1 08:51:48.297: INFO: Updating stateful set ss2
Aug  1 08:51:48.365: INFO: Waiting for Pod e2e-tests-statefulset-h9hsb/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Aug  1 08:51:58.395: INFO: Updating stateful set ss2
Aug  1 08:51:58.582: INFO: Waiting for StatefulSet e2e-tests-statefulset-h9hsb/ss2 to complete update
Aug  1 08:51:58.582: INFO: Waiting for Pod e2e-tests-statefulset-h9hsb/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Aug  1 08:52:08.591: INFO: Waiting for StatefulSet e2e-tests-statefulset-h9hsb/ss2 to complete update
Aug  1 08:52:08.592: INFO: Waiting for Pod e2e-tests-statefulset-h9hsb/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Aug  1 08:52:18.590: INFO: Deleting all statefulset in ns e2e-tests-statefulset-h9hsb
Aug  1 08:52:18.604: INFO: Scaling statefulset ss2 to 0
Aug  1 08:52:38.643: INFO: Waiting for statefulset status.replicas updated to 0
Aug  1 08:52:38.645: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:52:38.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-h9hsb" for this suite.
Aug  1 08:52:48.912: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:52:48.946: INFO: namespace: e2e-tests-statefulset-h9hsb, resource: bindings, ignored listing per whitelist
Aug  1 08:52:49.079: INFO: namespace e2e-tests-statefulset-h9hsb deletion completed in 10.36152217s

• [SLOW TEST:123.881 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:52:49.091: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Aug  1 08:52:49.465: INFO: Waiting up to 5m0s for pod "pod-bd5c08e0-b439-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-emptydir-5rb9k" to be "success or failure"
Aug  1 08:52:49.504: INFO: Pod "pod-bd5c08e0-b439-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 39.255845ms
Aug  1 08:52:51.510: INFO: Pod "pod-bd5c08e0-b439-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.045193346s
Aug  1 08:52:53.548: INFO: Pod "pod-bd5c08e0-b439-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.083547653s
Aug  1 08:52:55.552: INFO: Pod "pod-bd5c08e0-b439-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.08691096s
STEP: Saw pod success
Aug  1 08:52:55.552: INFO: Pod "pod-bd5c08e0-b439-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 08:52:55.554: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod pod-bd5c08e0-b439-11e9-aec8-12de527cd1b8 container test-container: <nil>
STEP: delete the pod
Aug  1 08:52:56.296: INFO: Waiting for pod pod-bd5c08e0-b439-11e9-aec8-12de527cd1b8 to disappear
Aug  1 08:52:56.329: INFO: Pod pod-bd5c08e0-b439-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:52:56.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-5rb9k" for this suite.
Aug  1 08:53:02.500: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:53:02.519: INFO: namespace: e2e-tests-emptydir-5rb9k, resource: bindings, ignored listing per whitelist
Aug  1 08:53:02.725: INFO: namespace e2e-tests-emptydir-5rb9k deletion completed in 6.304703697s

• [SLOW TEST:13.634 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:53:02.728: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:53:33.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-bdblw" for this suite.
Aug  1 08:53:57.850: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:53:57.960: INFO: namespace: e2e-tests-replication-controller-bdblw, resource: bindings, ignored listing per whitelist
Aug  1 08:53:57.983: INFO: namespace e2e-tests-replication-controller-bdblw deletion completed in 24.387495371s

• [SLOW TEST:55.257 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:53:58.003: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-e66957de-b439-11e9-aec8-12de527cd1b8
STEP: Creating a pod to test consume configMaps
Aug  1 08:53:58.501: INFO: Waiting up to 5m0s for pod "pod-configmaps-e66afe82-b439-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-configmap-d6xv2" to be "success or failure"
Aug  1 08:53:58.693: INFO: Pod "pod-configmaps-e66afe82-b439-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 192.429319ms
Aug  1 08:54:00.914: INFO: Pod "pod-configmaps-e66afe82-b439-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.413461507s
Aug  1 08:54:02.979: INFO: Pod "pod-configmaps-e66afe82-b439-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.477971812s
STEP: Saw pod success
Aug  1 08:54:02.979: INFO: Pod "pod-configmaps-e66afe82-b439-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 08:54:03.015: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod pod-configmaps-e66afe82-b439-11e9-aec8-12de527cd1b8 container configmap-volume-test: <nil>
STEP: delete the pod
Aug  1 08:54:03.303: INFO: Waiting for pod pod-configmaps-e66afe82-b439-11e9-aec8-12de527cd1b8 to disappear
Aug  1 08:54:03.361: INFO: Pod pod-configmaps-e66afe82-b439-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:54:03.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-d6xv2" for this suite.
Aug  1 08:54:09.557: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:54:09.683: INFO: namespace: e2e-tests-configmap-d6xv2, resource: bindings, ignored listing per whitelist
Aug  1 08:54:09.683: INFO: namespace e2e-tests-configmap-d6xv2 deletion completed in 6.318784084s

• [SLOW TEST:11.681 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:54:09.688: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Aug  1 08:54:10.087: INFO: PodSpec: initContainers in spec.initContainers
Aug  1 08:55:01.579: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-ed6b3d67-b439-11e9-aec8-12de527cd1b8", GenerateName:"", Namespace:"e2e-tests-init-container-cgx9n", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-cgx9n/pods/pod-init-ed6b3d67-b439-11e9-aec8-12de527cd1b8", UID:"ed239e16-b439-11e9-8923-fa163ec474fb", ResourceVersion:"19595", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63700246449, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"87465508"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"192.168.1.212/32"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-r5zws", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001d56c00), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-r5zws", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-r5zws", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-r5zws", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc000eb3fb8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"k8s-1-6lh7zebx7k5q-node-0", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc000f6ca80), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0014d0030)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0014d0050)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0014d0058)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700246450, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700246450, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700246450, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700246449, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.0.0.23", PodIP:"192.168.1.212", StartTime:(*v1.Time)(0xc001fe9e40), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0021108c0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002110930)}, Ready:false, RestartCount:3, Image:"docker.io/busybox:1.29", ImageID:"docker-pullable://docker.io/busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://acaadc24cd999a53931c3e79554f683b825ab4d1c7d2211aa7c25cbab0be4871"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001fe9e80), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001fe9e60), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:55:02.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-cgx9n" for this suite.
Aug  1 08:55:26.333: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:55:26.500: INFO: namespace: e2e-tests-init-container-cgx9n, resource: bindings, ignored listing per whitelist
Aug  1 08:55:26.850: INFO: namespace e2e-tests-init-container-cgx9n deletion completed in 24.604931902s

• [SLOW TEST:77.163 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:55:26.878: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-1b58277d-b43a-11e9-aec8-12de527cd1b8
STEP: Creating a pod to test consume secrets
Aug  1 08:55:27.410: INFO: Waiting up to 5m0s for pod "pod-secrets-1b5b8992-b43a-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-secrets-7hzwl" to be "success or failure"
Aug  1 08:55:27.469: INFO: Pod "pod-secrets-1b5b8992-b43a-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 57.360312ms
Aug  1 08:55:29.535: INFO: Pod "pod-secrets-1b5b8992-b43a-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.123721415s
Aug  1 08:55:31.568: INFO: Pod "pod-secrets-1b5b8992-b43a-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.157038227s
Aug  1 08:55:33.582: INFO: Pod "pod-secrets-1b5b8992-b43a-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.170851671s
STEP: Saw pod success
Aug  1 08:55:33.583: INFO: Pod "pod-secrets-1b5b8992-b43a-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 08:55:33.585: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod pod-secrets-1b5b8992-b43a-11e9-aec8-12de527cd1b8 container secret-volume-test: <nil>
STEP: delete the pod
Aug  1 08:55:33.764: INFO: Waiting for pod pod-secrets-1b5b8992-b43a-11e9-aec8-12de527cd1b8 to disappear
Aug  1 08:55:33.823: INFO: Pod pod-secrets-1b5b8992-b43a-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:55:33.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-7hzwl" for this suite.
Aug  1 08:55:39.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:55:40.018: INFO: namespace: e2e-tests-secrets-7hzwl, resource: bindings, ignored listing per whitelist
Aug  1 08:55:40.056: INFO: namespace e2e-tests-secrets-7hzwl deletion completed in 6.226204577s

• [SLOW TEST:13.179 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:55:40.073: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-2bd4p
Aug  1 08:55:46.920: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-2bd4p
STEP: checking the pod's current state and verifying that restartCount is present
Aug  1 08:55:46.922: INFO: Initial restart count of pod liveness-http is 0
Aug  1 08:56:06.992: INFO: Restart count of pod e2e-tests-container-probe-2bd4p/liveness-http is now 1 (20.069357132s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:56:07.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-2bd4p" for this suite.
Aug  1 08:56:15.306: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:56:15.522: INFO: namespace: e2e-tests-container-probe-2bd4p, resource: bindings, ignored listing per whitelist
Aug  1 08:56:15.552: INFO: namespace e2e-tests-container-probe-2bd4p deletion completed in 8.302066017s

• [SLOW TEST:35.479 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:56:15.572: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-38770844-b43a-11e9-aec8-12de527cd1b8
STEP: Creating a pod to test consume configMaps
Aug  1 08:56:16.045: INFO: Waiting up to 5m0s for pod "pod-configmaps-3877c691-b43a-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-configmap-qwm2n" to be "success or failure"
Aug  1 08:56:16.075: INFO: Pod "pod-configmaps-3877c691-b43a-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 29.738065ms
Aug  1 08:56:18.080: INFO: Pod "pod-configmaps-3877c691-b43a-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034309011s
Aug  1 08:56:20.121: INFO: Pod "pod-configmaps-3877c691-b43a-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.075375171s
STEP: Saw pod success
Aug  1 08:56:20.121: INFO: Pod "pod-configmaps-3877c691-b43a-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 08:56:20.123: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod pod-configmaps-3877c691-b43a-11e9-aec8-12de527cd1b8 container configmap-volume-test: <nil>
STEP: delete the pod
Aug  1 08:56:20.281: INFO: Waiting for pod pod-configmaps-3877c691-b43a-11e9-aec8-12de527cd1b8 to disappear
Aug  1 08:56:20.319: INFO: Pod pod-configmaps-3877c691-b43a-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:56:20.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-qwm2n" for this suite.
Aug  1 08:56:26.752: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:56:27.167: INFO: namespace: e2e-tests-configmap-qwm2n, resource: bindings, ignored listing per whitelist
Aug  1 08:56:27.270: INFO: namespace e2e-tests-configmap-qwm2n deletion completed in 6.948346554s

• [SLOW TEST:11.698 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:56:27.273: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Aug  1 08:56:27.697: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 api-versions'
Aug  1 08:56:28.025: INFO: stderr: ""
Aug  1 08:56:28.025: INFO: stdout: "admissionregistration.k8s.io/v1alpha1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauditregistration.k8s.io/v1alpha1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\nbatch/v2alpha1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1alpha1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1alpha1\nscheduling.k8s.io/v1beta1\nsettings.k8s.io/v1alpha1\nstorage.k8s.io/v1\nstorage.k8s.io/v1alpha1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:56:28.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-4zp9q" for this suite.
Aug  1 08:56:34.161: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:56:34.274: INFO: namespace: e2e-tests-kubectl-4zp9q, resource: bindings, ignored listing per whitelist
Aug  1 08:56:34.280: INFO: namespace e2e-tests-kubectl-4zp9q deletion completed in 6.159921209s

• [SLOW TEST:7.008 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:56:34.285: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:56:41.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-nrfd8" for this suite.
Aug  1 08:56:47.461: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:56:47.517: INFO: namespace: e2e-tests-emptydir-wrapper-nrfd8, resource: bindings, ignored listing per whitelist
Aug  1 08:56:47.664: INFO: namespace e2e-tests-emptydir-wrapper-nrfd8 deletion completed in 6.36335377s

• [SLOW TEST:13.380 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:56:47.670: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0801 08:57:18.644526      12 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug  1 08:57:18.675: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 08:57:18.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-42www" for this suite.
Aug  1 08:57:30.734: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 08:57:30.844: INFO: namespace: e2e-tests-gc-42www, resource: bindings, ignored listing per whitelist
Aug  1 08:57:30.867: INFO: namespace e2e-tests-gc-42www deletion completed in 12.188841995s

• [SLOW TEST:43.198 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 08:57:30.871: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-jrtlb
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-jrtlb
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-jrtlb
Aug  1 08:57:31.399: INFO: Found 0 stateful pods, waiting for 1
Aug  1 08:57:41.404: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Aug  1 08:57:41.435: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug  1 08:57:43.176: INFO: stderr: ""
Aug  1 08:57:43.176: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug  1 08:57:43.176: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug  1 08:57:43.181: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Aug  1 08:57:53.188: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug  1 08:57:53.188: INFO: Waiting for statefulset status.replicas updated to 0
Aug  1 08:57:53.241: INFO: POD   NODE                       PHASE    GRACE  CONDITIONS
Aug  1 08:57:53.241: INFO: ss-0  k8s-1-6lh7zebx7k5q-node-0  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:57:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:57:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:57:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:57:31 +0000 UTC  }]
Aug  1 08:57:53.242: INFO: 
Aug  1 08:57:53.242: INFO: StatefulSet ss has not reached scale 3, at 1
Aug  1 08:57:54.383: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.953663588s
Aug  1 08:57:55.597: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.812746915s
Aug  1 08:57:56.622: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.598321788s
Aug  1 08:57:58.169: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.573660516s
Aug  1 08:57:59.241: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.026589612s
Aug  1 08:58:00.249: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.953204076s
Aug  1 08:58:01.367: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.946120455s
Aug  1 08:58:02.710: INFO: Verifying statefulset ss doesn't scale past 3 for another 828.018671ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-jrtlb
Aug  1 08:58:03.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  1 08:58:04.062: INFO: stderr: ""
Aug  1 08:58:04.062: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug  1 08:58:04.062: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug  1 08:58:04.062: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  1 08:58:04.357: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Aug  1 08:58:04.357: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug  1 08:58:04.357: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug  1 08:58:04.357: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  1 08:58:04.639: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Aug  1 08:58:04.639: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug  1 08:58:04.639: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug  1 08:58:04.642: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Aug  1 08:58:14.647: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Aug  1 08:58:14.647: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Aug  1 08:58:14.647: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Aug  1 08:58:14.648: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug  1 08:58:15.166: INFO: stderr: ""
Aug  1 08:58:15.166: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug  1 08:58:15.166: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug  1 08:58:15.166: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug  1 08:58:15.460: INFO: stderr: ""
Aug  1 08:58:15.460: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug  1 08:58:15.460: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug  1 08:58:15.460: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug  1 08:58:17.009: INFO: stderr: ""
Aug  1 08:58:17.009: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug  1 08:58:17.009: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug  1 08:58:17.009: INFO: Waiting for statefulset status.replicas updated to 0
Aug  1 08:58:17.150: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Aug  1 08:58:27.215: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug  1 08:58:27.215: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Aug  1 08:58:27.215: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Aug  1 08:58:27.500: INFO: POD   NODE                       PHASE    GRACE  CONDITIONS
Aug  1 08:58:27.500: INFO: ss-0  k8s-1-6lh7zebx7k5q-node-0  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:57:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:58:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:58:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:57:31 +0000 UTC  }]
Aug  1 08:58:27.501: INFO: ss-1  k8s-1-6lh7zebx7k5q-node-0  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:57:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:58:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:58:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:57:52 +0000 UTC  }]
Aug  1 08:58:27.501: INFO: ss-2  k8s-1-6lh7zebx7k5q-node-0  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:57:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:58:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:58:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:57:53 +0000 UTC  }]
Aug  1 08:58:27.501: INFO: 
Aug  1 08:58:27.501: INFO: StatefulSet ss has not reached scale 0, at 3
Aug  1 08:58:28.660: INFO: POD   NODE                       PHASE    GRACE  CONDITIONS
Aug  1 08:58:28.660: INFO: ss-0  k8s-1-6lh7zebx7k5q-node-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:57:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:58:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:58:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:57:31 +0000 UTC  }]
Aug  1 08:58:28.661: INFO: ss-1  k8s-1-6lh7zebx7k5q-node-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:57:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:58:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:58:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:57:52 +0000 UTC  }]
Aug  1 08:58:28.661: INFO: ss-2  k8s-1-6lh7zebx7k5q-node-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:57:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:58:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:58:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:57:53 +0000 UTC  }]
Aug  1 08:58:28.661: INFO: 
Aug  1 08:58:28.661: INFO: StatefulSet ss has not reached scale 0, at 3
Aug  1 08:58:30.045: INFO: POD   NODE                       PHASE    GRACE  CONDITIONS
Aug  1 08:58:30.045: INFO: ss-0  k8s-1-6lh7zebx7k5q-node-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:57:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:58:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:58:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:57:31 +0000 UTC  }]
Aug  1 08:58:30.058: INFO: ss-1  k8s-1-6lh7zebx7k5q-node-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:57:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:58:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:58:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:57:52 +0000 UTC  }]
Aug  1 08:58:30.059: INFO: ss-2  k8s-1-6lh7zebx7k5q-node-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:57:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:58:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:58:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:57:53 +0000 UTC  }]
Aug  1 08:58:30.059: INFO: 
Aug  1 08:58:30.059: INFO: StatefulSet ss has not reached scale 0, at 3
Aug  1 08:58:31.070: INFO: POD   NODE                       PHASE    GRACE  CONDITIONS
Aug  1 08:58:31.070: INFO: ss-0  k8s-1-6lh7zebx7k5q-node-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:57:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:58:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:58:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:57:31 +0000 UTC  }]
Aug  1 08:58:31.070: INFO: ss-1  k8s-1-6lh7zebx7k5q-node-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:57:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:58:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:58:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:57:52 +0000 UTC  }]
Aug  1 08:58:31.071: INFO: ss-2  k8s-1-6lh7zebx7k5q-node-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:57:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:58:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:58:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:57:53 +0000 UTC  }]
Aug  1 08:58:31.071: INFO: 
Aug  1 08:58:31.071: INFO: StatefulSet ss has not reached scale 0, at 3
Aug  1 08:58:32.226: INFO: POD   NODE                       PHASE    GRACE  CONDITIONS
Aug  1 08:58:32.226: INFO: ss-0  k8s-1-6lh7zebx7k5q-node-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:57:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:58:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:58:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:57:31 +0000 UTC  }]
Aug  1 08:58:32.226: INFO: ss-1  k8s-1-6lh7zebx7k5q-node-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:57:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:58:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:58:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:57:52 +0000 UTC  }]
Aug  1 08:58:32.226: INFO: ss-2  k8s-1-6lh7zebx7k5q-node-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:57:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:58:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:58:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:57:53 +0000 UTC  }]
Aug  1 08:58:32.226: INFO: 
Aug  1 08:58:32.226: INFO: StatefulSet ss has not reached scale 0, at 3
Aug  1 08:58:33.400: INFO: POD   NODE                       PHASE    GRACE  CONDITIONS
Aug  1 08:58:33.401: INFO: ss-0  k8s-1-6lh7zebx7k5q-node-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:57:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:58:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:58:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:57:31 +0000 UTC  }]
Aug  1 08:58:33.401: INFO: ss-1  k8s-1-6lh7zebx7k5q-node-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:57:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:58:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:58:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:57:52 +0000 UTC  }]
Aug  1 08:58:33.401: INFO: ss-2  k8s-1-6lh7zebx7k5q-node-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:57:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:58:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:58:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:57:53 +0000 UTC  }]
Aug  1 08:58:33.401: INFO: 
Aug  1 08:58:33.401: INFO: StatefulSet ss has not reached scale 0, at 3
Aug  1 08:58:34.493: INFO: POD   NODE                       PHASE    GRACE  CONDITIONS
Aug  1 08:58:34.493: INFO: ss-0  k8s-1-6lh7zebx7k5q-node-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:57:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:58:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:58:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:57:31 +0000 UTC  }]
Aug  1 08:58:34.493: INFO: ss-1  k8s-1-6lh7zebx7k5q-node-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:57:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:58:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:58:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:57:52 +0000 UTC  }]
Aug  1 08:58:34.493: INFO: ss-2  k8s-1-6lh7zebx7k5q-node-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:57:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:58:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:58:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:57:53 +0000 UTC  }]
Aug  1 08:58:34.493: INFO: 
Aug  1 08:58:34.493: INFO: StatefulSet ss has not reached scale 0, at 3
Aug  1 08:58:35.678: INFO: POD   NODE                       PHASE    GRACE  CONDITIONS
Aug  1 08:58:35.679: INFO: ss-0  k8s-1-6lh7zebx7k5q-node-0  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:57:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:58:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:58:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:57:31 +0000 UTC  }]
Aug  1 08:58:35.679: INFO: ss-1  k8s-1-6lh7zebx7k5q-node-0  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:57:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:58:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:58:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:57:52 +0000 UTC  }]
Aug  1 08:58:35.679: INFO: 
Aug  1 08:58:35.679: INFO: StatefulSet ss has not reached scale 0, at 2
Aug  1 08:58:36.685: INFO: POD   NODE                       PHASE    GRACE  CONDITIONS
Aug  1 08:58:36.685: INFO: ss-0  k8s-1-6lh7zebx7k5q-node-0  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:57:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:58:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:58:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:57:31 +0000 UTC  }]
Aug  1 08:58:36.686: INFO: ss-1  k8s-1-6lh7zebx7k5q-node-0  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:57:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:58:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:58:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 08:57:52 +0000 UTC  }]
Aug  1 08:58:36.686: INFO: 
Aug  1 08:58:36.686: INFO: StatefulSet ss has not reached scale 0, at 2
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-jrtlb
Aug  1 08:58:37.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  1 08:58:38.053: INFO: rc: 1
Aug  1 08:58:38.090: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc000afcb40 exit status 1 <nil> <nil> true [0xc000f376d8 0xc000f376f0 0xc000f37708] [0xc000f376d8 0xc000f376f0 0xc000f37708] [0xc000f376e8 0xc000f37700] [0x92f8e0 0x92f8e0] 0xc001f21560 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Aug  1 08:58:48.098: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  1 08:58:48.205: INFO: rc: 1
Aug  1 08:58:48.205: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000afcf90 exit status 1 <nil> <nil> true [0xc000f37710 0xc000f37728 0xc000f37740] [0xc000f37710 0xc000f37728 0xc000f37740] [0xc000f37720 0xc000f37738] [0x92f8e0 0x92f8e0] 0xc001f218c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug  1 08:58:58.206: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  1 08:58:58.348: INFO: rc: 1
Aug  1 08:58:58.348: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000afd3e0 exit status 1 <nil> <nil> true [0xc000f37748 0xc000f37760 0xc000f37780] [0xc000f37748 0xc000f37760 0xc000f37780] [0xc000f37758 0xc000f37770] [0x92f8e0 0x92f8e0] 0xc001f21bc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug  1 08:59:08.349: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  1 08:59:08.461: INFO: rc: 1
Aug  1 08:59:08.461: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000afdb00 exit status 1 <nil> <nil> true [0xc000f37788 0xc000f377a0 0xc000f377b8] [0xc000f37788 0xc000f377a0 0xc000f377b8] [0xc000f37798 0xc000f377b0] [0x92f8e0 0x92f8e0] 0xc001f21ec0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug  1 08:59:18.461: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  1 08:59:18.658: INFO: rc: 1
Aug  1 08:59:18.658: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001bc8030 exit status 1 <nil> <nil> true [0xc000f377c0 0xc000f377d8 0xc000f377f0] [0xc000f377c0 0xc000f377d8 0xc000f377f0] [0xc000f377d0 0xc000f377e8] [0x92f8e0 0x92f8e0] 0xc0011361e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug  1 08:59:28.659: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  1 08:59:28.798: INFO: rc: 1
Aug  1 08:59:28.798: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001bc8540 exit status 1 <nil> <nil> true [0xc000f377f8 0xc000f37810 0xc000f37828] [0xc000f377f8 0xc000f37810 0xc000f37828] [0xc000f37808 0xc000f37820] [0x92f8e0 0x92f8e0] 0xc001136540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug  1 08:59:38.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  1 08:59:38.958: INFO: rc: 1
Aug  1 08:59:38.959: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0039ca420 exit status 1 <nil> <nil> true [0xc000f36008 0xc000f36020 0xc000f36038] [0xc000f36008 0xc000f36020 0xc000f36038] [0xc000f36018 0xc000f36030] [0x92f8e0 0x92f8e0] 0xc0015dc240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug  1 08:59:48.959: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  1 08:59:49.116: INFO: rc: 1
Aug  1 08:59:49.116: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0039ca870 exit status 1 <nil> <nil> true [0xc000f36040 0xc000f36058 0xc000f36070] [0xc000f36040 0xc000f36058 0xc000f36070] [0xc000f36050 0xc000f36068] [0x92f8e0 0x92f8e0] 0xc0015dc540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug  1 08:59:59.117: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  1 08:59:59.285: INFO: rc: 1
Aug  1 08:59:59.285: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0039caf60 exit status 1 <nil> <nil> true [0xc000f36078 0xc000f36090 0xc000f360a8] [0xc000f36078 0xc000f36090 0xc000f360a8] [0xc000f36088 0xc000f360a0] [0x92f8e0 0x92f8e0] 0xc0015dca80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug  1 09:00:09.285: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  1 09:00:09.416: INFO: rc: 1
Aug  1 09:00:09.416: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0039cb380 exit status 1 <nil> <nil> true [0xc000f360b0 0xc000f360c8 0xc000f360e0] [0xc000f360b0 0xc000f360c8 0xc000f360e0] [0xc000f360c0 0xc000f360d8] [0x92f8e0 0x92f8e0] 0xc0015dd0e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug  1 09:00:19.417: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  1 09:00:19.528: INFO: rc: 1
Aug  1 09:00:19.528: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0039cb770 exit status 1 <nil> <nil> true [0xc000f360e8 0xc000f36100 0xc000f36118] [0xc000f360e8 0xc000f36100 0xc000f36118] [0xc000f360f8 0xc000f36110] [0x92f8e0 0x92f8e0] 0xc0015dd3e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug  1 09:00:29.528: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  1 09:00:29.662: INFO: rc: 1
Aug  1 09:00:29.662: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0039cbbf0 exit status 1 <nil> <nil> true [0xc000f36120 0xc000f36138 0xc000f36150] [0xc000f36120 0xc000f36138 0xc000f36150] [0xc000f36130 0xc000f36148] [0x92f8e0 0x92f8e0] 0xc0015dd6e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug  1 09:00:39.662: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  1 09:00:39.770: INFO: rc: 1
Aug  1 09:00:39.770: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000afc030 exit status 1 <nil> <nil> true [0xc000f36158 0xc000f36170 0xc000f36188] [0xc000f36158 0xc000f36170 0xc000f36188] [0xc000f36168 0xc000f36180] [0x92f8e0 0x92f8e0] 0xc0015dd9e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug  1 09:00:49.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  1 09:00:49.950: INFO: rc: 1
Aug  1 09:00:49.950: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000afc750 exit status 1 <nil> <nil> true [0xc000f36190 0xc000f361a8 0xc000f361c0] [0xc000f36190 0xc000f361a8 0xc000f361c0] [0xc000f361a0 0xc000f361b8] [0x92f8e0 0x92f8e0] 0xc0015ddce0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug  1 09:00:59.950: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  1 09:01:00.064: INFO: rc: 1
Aug  1 09:01:00.064: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000afcbd0 exit status 1 <nil> <nil> true [0xc000f361c8 0xc000f361e0 0xc000f361f8] [0xc000f361c8 0xc000f361e0 0xc000f361f8] [0xc000f361d8 0xc000f361f0] [0x92f8e0 0x92f8e0] 0xc001aee000 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug  1 09:01:10.064: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  1 09:01:10.167: INFO: rc: 1
Aug  1 09:01:10.167: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000afd080 exit status 1 <nil> <nil> true [0xc000f36200 0xc000f36218 0xc000f36230] [0xc000f36200 0xc000f36218 0xc000f36230] [0xc000f36210 0xc000f36228] [0x92f8e0 0x92f8e0] 0xc001aee540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug  1 09:01:20.167: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  1 09:01:20.265: INFO: rc: 1
Aug  1 09:01:20.265: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000afd680 exit status 1 <nil> <nil> true [0xc000f36238 0xc000f36250 0xc000f36268] [0xc000f36238 0xc000f36250 0xc000f36268] [0xc000f36248 0xc000f36260] [0x92f8e0 0x92f8e0] 0xc001aee960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug  1 09:01:30.266: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  1 09:01:30.480: INFO: rc: 1
Aug  1 09:01:30.480: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000afdc20 exit status 1 <nil> <nil> true [0xc000f36270 0xc000f36288 0xc000f362a0] [0xc000f36270 0xc000f36288 0xc000f362a0] [0xc000f36280 0xc000f36298] [0x92f8e0 0x92f8e0] 0xc001aeec60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug  1 09:01:40.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  1 09:01:40.612: INFO: rc: 1
Aug  1 09:01:40.612: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0039ca450 exit status 1 <nil> <nil> true [0xc000f36008 0xc000f36020 0xc000f36038] [0xc000f36008 0xc000f36020 0xc000f36038] [0xc000f36018 0xc000f36030] [0x92f8e0 0x92f8e0] 0xc0015dc240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug  1 09:01:50.613: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  1 09:01:50.724: INFO: rc: 1
Aug  1 09:01:50.724: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0039ca8d0 exit status 1 <nil> <nil> true [0xc000f36040 0xc000f36058 0xc000f36070] [0xc000f36040 0xc000f36058 0xc000f36070] [0xc000f36050 0xc000f36068] [0x92f8e0 0x92f8e0] 0xc0015dc540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug  1 09:02:00.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  1 09:02:00.880: INFO: rc: 1
Aug  1 09:02:00.880: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0039caff0 exit status 1 <nil> <nil> true [0xc000f36078 0xc000f36090 0xc000f360a8] [0xc000f36078 0xc000f36090 0xc000f360a8] [0xc000f36088 0xc000f360a0] [0x92f8e0 0x92f8e0] 0xc0015dca80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug  1 09:02:10.881: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  1 09:02:11.055: INFO: rc: 1
Aug  1 09:02:11.055: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0039cb440 exit status 1 <nil> <nil> true [0xc000f360b0 0xc000f360c8 0xc000f360e0] [0xc000f360b0 0xc000f360c8 0xc000f360e0] [0xc000f360c0 0xc000f360d8] [0x92f8e0 0x92f8e0] 0xc0015dd0e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug  1 09:02:21.056: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  1 09:02:21.166: INFO: rc: 1
Aug  1 09:02:21.166: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0039cb8c0 exit status 1 <nil> <nil> true [0xc000f360e8 0xc000f36100 0xc000f36118] [0xc000f360e8 0xc000f36100 0xc000f36118] [0xc000f360f8 0xc000f36110] [0x92f8e0 0x92f8e0] 0xc0015dd3e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug  1 09:02:31.167: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  1 09:02:31.480: INFO: rc: 1
Aug  1 09:02:31.480: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0039cbd10 exit status 1 <nil> <nil> true [0xc000f36120 0xc000f36138 0xc000f36150] [0xc000f36120 0xc000f36138 0xc000f36150] [0xc000f36130 0xc000f36148] [0x92f8e0 0x92f8e0] 0xc0015dd6e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug  1 09:02:41.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  1 09:02:41.669: INFO: rc: 1
Aug  1 09:02:41.669: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000afc180 exit status 1 <nil> <nil> true [0xc000f36158 0xc000f36170 0xc000f36188] [0xc000f36158 0xc000f36170 0xc000f36188] [0xc000f36168 0xc000f36180] [0x92f8e0 0x92f8e0] 0xc0015dd9e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug  1 09:02:51.670: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  1 09:02:51.772: INFO: rc: 1
Aug  1 09:02:51.772: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000afc8d0 exit status 1 <nil> <nil> true [0xc000f36190 0xc000f361a8 0xc000f361c0] [0xc000f36190 0xc000f361a8 0xc000f361c0] [0xc000f361a0 0xc000f361b8] [0x92f8e0 0x92f8e0] 0xc0015ddce0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug  1 09:03:01.773: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  1 09:03:01.919: INFO: rc: 1
Aug  1 09:03:01.919: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000afcd80 exit status 1 <nil> <nil> true [0xc000f361c8 0xc000f361e0 0xc000f361f8] [0xc000f361c8 0xc000f361e0 0xc000f361f8] [0xc000f361d8 0xc000f361f0] [0x92f8e0 0x92f8e0] 0xc001aee000 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug  1 09:03:11.919: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  1 09:03:12.073: INFO: rc: 1
Aug  1 09:03:12.073: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000afd230 exit status 1 <nil> <nil> true [0xc000f36200 0xc000f36218 0xc000f36230] [0xc000f36200 0xc000f36218 0xc000f36230] [0xc000f36210 0xc000f36228] [0x92f8e0 0x92f8e0] 0xc001aee540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug  1 09:03:22.073: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  1 09:03:22.190: INFO: rc: 1
Aug  1 09:03:22.190: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000afd980 exit status 1 <nil> <nil> true [0xc000f36238 0xc000f36250 0xc000f36268] [0xc000f36238 0xc000f36250 0xc000f36268] [0xc000f36248 0xc000f36260] [0x92f8e0 0x92f8e0] 0xc001aee960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug  1 09:03:32.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  1 09:03:32.311: INFO: rc: 1
Aug  1 09:03:32.312: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000afdda0 exit status 1 <nil> <nil> true [0xc000f36270 0xc000f36288 0xc000f362a0] [0xc000f36270 0xc000f36288 0xc000f362a0] [0xc000f36280 0xc000f36298] [0x92f8e0 0x92f8e0] 0xc001aeec60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug  1 09:03:42.312: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-jrtlb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  1 09:03:42.549: INFO: rc: 1
Aug  1 09:03:42.550: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: 
Aug  1 09:03:42.550: INFO: Scaling statefulset ss to 0
Aug  1 09:03:42.586: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Aug  1 09:03:42.589: INFO: Deleting all statefulset in ns e2e-tests-statefulset-jrtlb
Aug  1 09:03:42.593: INFO: Scaling statefulset ss to 0
Aug  1 09:03:42.601: INFO: Waiting for statefulset status.replicas updated to 0
Aug  1 09:03:42.603: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 09:03:42.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-jrtlb" for this suite.
Aug  1 09:03:50.846: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 09:03:50.880: INFO: namespace: e2e-tests-statefulset-jrtlb, resource: bindings, ignored listing per whitelist
Aug  1 09:03:51.055: INFO: namespace e2e-tests-statefulset-jrtlb deletion completed in 8.289856514s

• [SLOW TEST:380.185 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 09:03:51.059: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-hdht
STEP: Creating a pod to test atomic-volume-subpath
Aug  1 09:03:51.867: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-hdht" in namespace "e2e-tests-subpath-gnp2z" to be "success or failure"
Aug  1 09:03:51.908: INFO: Pod "pod-subpath-test-projected-hdht": Phase="Pending", Reason="", readiness=false. Elapsed: 40.217023ms
Aug  1 09:03:53.913: INFO: Pod "pod-subpath-test-projected-hdht": Phase="Pending", Reason="", readiness=false. Elapsed: 2.045915924s
Aug  1 09:03:55.970: INFO: Pod "pod-subpath-test-projected-hdht": Phase="Pending", Reason="", readiness=false. Elapsed: 4.102110745s
Aug  1 09:03:57.990: INFO: Pod "pod-subpath-test-projected-hdht": Phase="Pending", Reason="", readiness=false. Elapsed: 6.122107797s
Aug  1 09:03:59.996: INFO: Pod "pod-subpath-test-projected-hdht": Phase="Running", Reason="", readiness=false. Elapsed: 8.128313876s
Aug  1 09:04:02.002: INFO: Pod "pod-subpath-test-projected-hdht": Phase="Running", Reason="", readiness=false. Elapsed: 10.134034085s
Aug  1 09:04:04.005: INFO: Pod "pod-subpath-test-projected-hdht": Phase="Running", Reason="", readiness=false. Elapsed: 12.137262196s
Aug  1 09:04:06.012: INFO: Pod "pod-subpath-test-projected-hdht": Phase="Running", Reason="", readiness=false. Elapsed: 14.144088864s
Aug  1 09:04:08.018: INFO: Pod "pod-subpath-test-projected-hdht": Phase="Running", Reason="", readiness=false. Elapsed: 16.150103367s
Aug  1 09:04:10.023: INFO: Pod "pod-subpath-test-projected-hdht": Phase="Running", Reason="", readiness=false. Elapsed: 18.155581092s
Aug  1 09:04:12.028: INFO: Pod "pod-subpath-test-projected-hdht": Phase="Running", Reason="", readiness=false. Elapsed: 20.16009371s
Aug  1 09:04:14.032: INFO: Pod "pod-subpath-test-projected-hdht": Phase="Running", Reason="", readiness=false. Elapsed: 22.164289975s
Aug  1 09:04:16.035: INFO: Pod "pod-subpath-test-projected-hdht": Phase="Running", Reason="", readiness=false. Elapsed: 24.166989893s
Aug  1 09:04:18.041: INFO: Pod "pod-subpath-test-projected-hdht": Phase="Running", Reason="", readiness=false. Elapsed: 26.173625413s
Aug  1 09:04:20.051: INFO: Pod "pod-subpath-test-projected-hdht": Phase="Succeeded", Reason="", readiness=false. Elapsed: 28.183501021s
STEP: Saw pod success
Aug  1 09:04:20.051: INFO: Pod "pod-subpath-test-projected-hdht" satisfied condition "success or failure"
Aug  1 09:04:20.053: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod pod-subpath-test-projected-hdht container test-container-subpath-projected-hdht: <nil>
STEP: delete the pod
Aug  1 09:04:20.136: INFO: Waiting for pod pod-subpath-test-projected-hdht to disappear
Aug  1 09:04:20.234: INFO: Pod pod-subpath-test-projected-hdht no longer exists
STEP: Deleting pod pod-subpath-test-projected-hdht
Aug  1 09:04:20.234: INFO: Deleting pod "pod-subpath-test-projected-hdht" in namespace "e2e-tests-subpath-gnp2z"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 09:04:20.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-gnp2z" for this suite.
Aug  1 09:04:28.305: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 09:04:28.445: INFO: namespace: e2e-tests-subpath-gnp2z, resource: bindings, ignored listing per whitelist
Aug  1 09:04:28.446: INFO: namespace e2e-tests-subpath-gnp2z deletion completed in 8.206013582s

• [SLOW TEST:37.387 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 09:04:28.453: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Aug  1 09:04:28.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 create -f - --namespace=e2e-tests-kubectl-xwt66'
Aug  1 09:04:32.790: INFO: stderr: ""
Aug  1 09:04:32.790: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Aug  1 09:04:33.982: INFO: Selector matched 1 pods for map[app:redis]
Aug  1 09:04:33.982: INFO: Found 0 / 1
Aug  1 09:04:34.844: INFO: Selector matched 1 pods for map[app:redis]
Aug  1 09:04:34.845: INFO: Found 0 / 1
Aug  1 09:04:36.133: INFO: Selector matched 1 pods for map[app:redis]
Aug  1 09:04:36.134: INFO: Found 0 / 1
Aug  1 09:04:36.867: INFO: Selector matched 1 pods for map[app:redis]
Aug  1 09:04:36.868: INFO: Found 0 / 1
Aug  1 09:04:38.170: INFO: Selector matched 1 pods for map[app:redis]
Aug  1 09:04:38.170: INFO: Found 1 / 1
Aug  1 09:04:38.170: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Aug  1 09:04:38.172: INFO: Selector matched 1 pods for map[app:redis]
Aug  1 09:04:38.173: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug  1 09:04:38.173: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 patch pod redis-master-7rp2m --namespace=e2e-tests-kubectl-xwt66 -p {"metadata":{"annotations":{"x":"y"}}}'
Aug  1 09:04:38.358: INFO: stderr: ""
Aug  1 09:04:38.358: INFO: stdout: "pod/redis-master-7rp2m patched\n"
STEP: checking annotations
Aug  1 09:04:38.366: INFO: Selector matched 1 pods for map[app:redis]
Aug  1 09:04:38.366: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 09:04:38.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xwt66" for this suite.
Aug  1 09:05:02.524: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 09:05:02.694: INFO: namespace: e2e-tests-kubectl-xwt66, resource: bindings, ignored listing per whitelist
Aug  1 09:05:02.765: INFO: namespace e2e-tests-kubectl-xwt66 deletion completed in 24.391496678s

• [SLOW TEST:34.312 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 09:05:02.770: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-rgxdc
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-rgxdc
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-rgxdc
Aug  1 09:05:03.393: INFO: Found 0 stateful pods, waiting for 1
Aug  1 09:05:13.398: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Aug  1 09:05:13.404: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-rgxdc ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug  1 09:05:14.087: INFO: stderr: ""
Aug  1 09:05:14.087: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug  1 09:05:14.087: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug  1 09:05:14.090: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Aug  1 09:05:24.093: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug  1 09:05:24.093: INFO: Waiting for statefulset status.replicas updated to 0
Aug  1 09:05:24.267: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999065s
Aug  1 09:05:25.271: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.83449363s
Aug  1 09:05:26.277: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.830118982s
Aug  1 09:05:27.280: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.824523565s
Aug  1 09:05:28.334: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.821422376s
Aug  1 09:05:29.340: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.766770485s
Aug  1 09:05:30.346: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.760708728s
Aug  1 09:05:31.350: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.75510114s
Aug  1 09:05:32.355: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.750877349s
Aug  1 09:05:33.362: INFO: Verifying statefulset ss doesn't scale past 1 for another 746.348176ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-rgxdc
Aug  1 09:05:34.369: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-rgxdc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  1 09:05:34.662: INFO: stderr: ""
Aug  1 09:05:34.662: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug  1 09:05:34.662: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug  1 09:05:34.665: INFO: Found 1 stateful pods, waiting for 3
Aug  1 09:05:44.742: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Aug  1 09:05:44.742: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Aug  1 09:05:44.742: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Aug  1 09:05:44.910: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-rgxdc ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug  1 09:05:45.410: INFO: stderr: ""
Aug  1 09:05:45.410: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug  1 09:05:45.410: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug  1 09:05:45.410: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-rgxdc ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug  1 09:05:46.005: INFO: stderr: ""
Aug  1 09:05:46.005: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug  1 09:05:46.005: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug  1 09:05:46.005: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-rgxdc ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug  1 09:05:46.357: INFO: stderr: ""
Aug  1 09:05:46.357: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug  1 09:05:46.357: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug  1 09:05:46.357: INFO: Waiting for statefulset status.replicas updated to 0
Aug  1 09:05:46.360: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Aug  1 09:05:56.372: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug  1 09:05:56.372: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Aug  1 09:05:56.372: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Aug  1 09:05:56.445: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999452s
Aug  1 09:05:57.450: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.934056282s
Aug  1 09:05:58.456: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.929756176s
Aug  1 09:05:59.465: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.923475119s
Aug  1 09:06:00.468: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.913900729s
Aug  1 09:06:01.489: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.894443594s
Aug  1 09:06:02.494: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.890604819s
Aug  1 09:06:03.501: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.885352527s
Aug  1 09:06:04.510: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.878258161s
Aug  1 09:06:05.657: INFO: Verifying statefulset ss doesn't scale past 3 for another 868.631455ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-rgxdc
Aug  1 09:06:06.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-rgxdc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  1 09:06:07.027: INFO: stderr: ""
Aug  1 09:06:07.027: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug  1 09:06:07.027: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug  1 09:06:07.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-rgxdc ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  1 09:06:07.328: INFO: stderr: ""
Aug  1 09:06:07.328: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug  1 09:06:07.328: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug  1 09:06:07.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-rgxdc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  1 09:06:07.889: INFO: stderr: ""
Aug  1 09:06:07.889: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug  1 09:06:07.889: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug  1 09:06:07.889: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Aug  1 09:06:17.904: INFO: Deleting all statefulset in ns e2e-tests-statefulset-rgxdc
Aug  1 09:06:17.910: INFO: Scaling statefulset ss to 0
Aug  1 09:06:17.918: INFO: Waiting for statefulset status.replicas updated to 0
Aug  1 09:06:17.920: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 09:06:18.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-rgxdc" for this suite.
Aug  1 09:06:26.094: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 09:06:26.201: INFO: namespace: e2e-tests-statefulset-rgxdc, resource: bindings, ignored listing per whitelist
Aug  1 09:06:26.204: INFO: namespace e2e-tests-statefulset-rgxdc deletion completed in 8.144890223s

• [SLOW TEST:83.434 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 09:06:26.205: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-a45b15e9-b43b-11e9-aec8-12de527cd1b8
STEP: Creating configMap with name cm-test-opt-upd-a45b1771-b43b-11e9-aec8-12de527cd1b8
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-a45b15e9-b43b-11e9-aec8-12de527cd1b8
STEP: Updating configmap cm-test-opt-upd-a45b1771-b43b-11e9-aec8-12de527cd1b8
STEP: Creating configMap with name cm-test-opt-create-a45b1798-b43b-11e9-aec8-12de527cd1b8
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 09:06:37.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-tn2d6" for this suite.
Aug  1 09:07:01.288: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 09:07:01.380: INFO: namespace: e2e-tests-configmap-tn2d6, resource: bindings, ignored listing per whitelist
Aug  1 09:07:01.387: INFO: namespace e2e-tests-configmap-tn2d6 deletion completed in 24.142899194s

• [SLOW TEST:35.182 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 09:07:01.390: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Aug  1 09:07:01.767: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-683321083 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 09:07:02.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-pbmxt" for this suite.
Aug  1 09:07:08.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 09:07:08.382: INFO: namespace: e2e-tests-kubectl-pbmxt, resource: bindings, ignored listing per whitelist
Aug  1 09:07:08.386: INFO: namespace e2e-tests-kubectl-pbmxt deletion completed in 6.198135744s

• [SLOW TEST:6.997 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 09:07:08.393: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Aug  1 09:07:08.803: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 create -f - --namespace=e2e-tests-kubectl-nszcp'
Aug  1 09:07:09.318: INFO: stderr: ""
Aug  1 09:07:09.318: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug  1 09:07:09.319: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-nszcp'
Aug  1 09:07:09.549: INFO: stderr: ""
Aug  1 09:07:09.549: INFO: stdout: "update-demo-nautilus-qmk9k update-demo-nautilus-tdrcn "
Aug  1 09:07:09.549: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods update-demo-nautilus-qmk9k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nszcp'
Aug  1 09:07:09.782: INFO: stderr: ""
Aug  1 09:07:09.782: INFO: stdout: ""
Aug  1 09:07:09.782: INFO: update-demo-nautilus-qmk9k is created but not running
Aug  1 09:07:14.782: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-nszcp'
Aug  1 09:07:15.174: INFO: stderr: ""
Aug  1 09:07:15.174: INFO: stdout: "update-demo-nautilus-qmk9k update-demo-nautilus-tdrcn "
Aug  1 09:07:15.174: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods update-demo-nautilus-qmk9k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nszcp'
Aug  1 09:07:15.957: INFO: stderr: ""
Aug  1 09:07:15.957: INFO: stdout: ""
Aug  1 09:07:15.957: INFO: update-demo-nautilus-qmk9k is created but not running
Aug  1 09:07:20.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-nszcp'
Aug  1 09:07:21.122: INFO: stderr: ""
Aug  1 09:07:21.122: INFO: stdout: "update-demo-nautilus-qmk9k update-demo-nautilus-tdrcn "
Aug  1 09:07:21.122: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods update-demo-nautilus-qmk9k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nszcp'
Aug  1 09:07:21.261: INFO: stderr: ""
Aug  1 09:07:21.261: INFO: stdout: "true"
Aug  1 09:07:21.261: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods update-demo-nautilus-qmk9k -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nszcp'
Aug  1 09:07:21.404: INFO: stderr: ""
Aug  1 09:07:21.404: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug  1 09:07:21.404: INFO: validating pod update-demo-nautilus-qmk9k
Aug  1 09:07:21.436: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug  1 09:07:21.436: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug  1 09:07:21.436: INFO: update-demo-nautilus-qmk9k is verified up and running
Aug  1 09:07:21.436: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods update-demo-nautilus-tdrcn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nszcp'
Aug  1 09:07:21.561: INFO: stderr: ""
Aug  1 09:07:21.561: INFO: stdout: "true"
Aug  1 09:07:21.561: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods update-demo-nautilus-tdrcn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nszcp'
Aug  1 09:07:21.811: INFO: stderr: ""
Aug  1 09:07:21.811: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug  1 09:07:21.811: INFO: validating pod update-demo-nautilus-tdrcn
Aug  1 09:07:21.818: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug  1 09:07:21.818: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug  1 09:07:21.818: INFO: update-demo-nautilus-tdrcn is verified up and running
STEP: scaling down the replication controller
Aug  1 09:07:21.829: INFO: scanned /root for discovery docs: <nil>
Aug  1 09:07:21.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-nszcp'
Aug  1 09:07:23.134: INFO: stderr: ""
Aug  1 09:07:23.134: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug  1 09:07:23.134: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-nszcp'
Aug  1 09:07:23.324: INFO: stderr: ""
Aug  1 09:07:23.324: INFO: stdout: "update-demo-nautilus-qmk9k update-demo-nautilus-tdrcn "
STEP: Replicas for name=update-demo: expected=1 actual=2
Aug  1 09:07:28.336: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-nszcp'
Aug  1 09:07:28.465: INFO: stderr: ""
Aug  1 09:07:28.465: INFO: stdout: "update-demo-nautilus-qmk9k "
Aug  1 09:07:28.465: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods update-demo-nautilus-qmk9k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nszcp'
Aug  1 09:07:28.589: INFO: stderr: ""
Aug  1 09:07:28.589: INFO: stdout: "true"
Aug  1 09:07:28.589: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods update-demo-nautilus-qmk9k -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nszcp'
Aug  1 09:07:28.724: INFO: stderr: ""
Aug  1 09:07:28.724: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug  1 09:07:28.724: INFO: validating pod update-demo-nautilus-qmk9k
Aug  1 09:07:28.727: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug  1 09:07:28.727: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug  1 09:07:28.727: INFO: update-demo-nautilus-qmk9k is verified up and running
STEP: scaling up the replication controller
Aug  1 09:07:28.781: INFO: scanned /root for discovery docs: <nil>
Aug  1 09:07:28.782: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-nszcp'
Aug  1 09:07:30.010: INFO: stderr: ""
Aug  1 09:07:30.010: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug  1 09:07:30.011: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-nszcp'
Aug  1 09:07:30.136: INFO: stderr: ""
Aug  1 09:07:30.136: INFO: stdout: "update-demo-nautilus-f8nk5 update-demo-nautilus-qmk9k "
Aug  1 09:07:30.136: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods update-demo-nautilus-f8nk5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nszcp'
Aug  1 09:07:30.349: INFO: stderr: ""
Aug  1 09:07:30.349: INFO: stdout: ""
Aug  1 09:07:30.349: INFO: update-demo-nautilus-f8nk5 is created but not running
Aug  1 09:07:35.349: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-nszcp'
Aug  1 09:07:35.474: INFO: stderr: ""
Aug  1 09:07:35.474: INFO: stdout: "update-demo-nautilus-f8nk5 update-demo-nautilus-qmk9k "
Aug  1 09:07:35.474: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods update-demo-nautilus-f8nk5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nszcp'
Aug  1 09:07:35.584: INFO: stderr: ""
Aug  1 09:07:35.584: INFO: stdout: "true"
Aug  1 09:07:35.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods update-demo-nautilus-f8nk5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nszcp'
Aug  1 09:07:35.723: INFO: stderr: ""
Aug  1 09:07:35.723: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug  1 09:07:35.723: INFO: validating pod update-demo-nautilus-f8nk5
Aug  1 09:07:35.728: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug  1 09:07:35.728: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug  1 09:07:35.728: INFO: update-demo-nautilus-f8nk5 is verified up and running
Aug  1 09:07:35.728: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods update-demo-nautilus-qmk9k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nszcp'
Aug  1 09:07:35.882: INFO: stderr: ""
Aug  1 09:07:35.882: INFO: stdout: "true"
Aug  1 09:07:35.882: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods update-demo-nautilus-qmk9k -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nszcp'
Aug  1 09:07:36.004: INFO: stderr: ""
Aug  1 09:07:36.004: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug  1 09:07:36.004: INFO: validating pod update-demo-nautilus-qmk9k
Aug  1 09:07:36.007: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug  1 09:07:36.007: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug  1 09:07:36.007: INFO: update-demo-nautilus-qmk9k is verified up and running
STEP: using delete to clean up resources
Aug  1 09:07:36.008: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-nszcp'
Aug  1 09:07:36.146: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug  1 09:07:36.146: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Aug  1 09:07:36.146: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-nszcp'
Aug  1 09:07:36.806: INFO: stderr: "No resources found.\n"
Aug  1 09:07:36.806: INFO: stdout: ""
Aug  1 09:07:36.806: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods -l name=update-demo --namespace=e2e-tests-kubectl-nszcp -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug  1 09:07:36.920: INFO: stderr: ""
Aug  1 09:07:36.920: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 09:07:36.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-nszcp" for this suite.
Aug  1 09:08:01.749: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 09:08:01.822: INFO: namespace: e2e-tests-kubectl-nszcp, resource: bindings, ignored listing per whitelist
Aug  1 09:08:01.880: INFO: namespace e2e-tests-kubectl-nszcp deletion completed in 24.952793614s

• [SLOW TEST:53.487 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 09:08:01.882: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Aug  1 09:08:02.205: INFO: Waiting up to 5m0s for pod "pod-dd55200d-b43b-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-emptydir-n7fpq" to be "success or failure"
Aug  1 09:08:02.261: INFO: Pod "pod-dd55200d-b43b-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 55.923968ms
Aug  1 09:08:04.341: INFO: Pod "pod-dd55200d-b43b-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.135905092s
Aug  1 09:08:06.348: INFO: Pod "pod-dd55200d-b43b-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.142248639s
Aug  1 09:08:08.354: INFO: Pod "pod-dd55200d-b43b-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.148418871s
STEP: Saw pod success
Aug  1 09:08:08.354: INFO: Pod "pod-dd55200d-b43b-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 09:08:08.357: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod pod-dd55200d-b43b-11e9-aec8-12de527cd1b8 container test-container: <nil>
STEP: delete the pod
Aug  1 09:08:08.415: INFO: Waiting for pod pod-dd55200d-b43b-11e9-aec8-12de527cd1b8 to disappear
Aug  1 09:08:08.437: INFO: Pod pod-dd55200d-b43b-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 09:08:08.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-n7fpq" for this suite.
Aug  1 09:08:14.568: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 09:08:14.595: INFO: namespace: e2e-tests-emptydir-n7fpq, resource: bindings, ignored listing per whitelist
Aug  1 09:08:14.704: INFO: namespace e2e-tests-emptydir-n7fpq deletion completed in 6.262566496s

• [SLOW TEST:12.823 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 09:08:14.715: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Aug  1 09:08:15.118: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug  1 09:08:15.125: INFO: Waiting for terminating namespaces to be deleted...
Aug  1 09:08:15.130: INFO: 
Logging pods the kubelet thinks is on node k8s-1-6lh7zebx7k5q-node-0 before test
Aug  1 09:08:15.304: INFO: coredns-5f559b869-jcg4r from kube-system started at 2019-08-01 07:18:52 +0000 UTC (1 container statuses recorded)
Aug  1 09:08:15.305: INFO: 	Container coredns ready: true, restart count 0
Aug  1 09:08:15.305: INFO: npd-q8998 from kube-system started at 2019-08-01 07:18:52 +0000 UTC (1 container statuses recorded)
Aug  1 09:08:15.305: INFO: 	Container node-problem-detector ready: true, restart count 0
Aug  1 09:08:15.306: INFO: sonobuoy from heptio-sonobuoy started at 2019-08-01 07:23:57 +0000 UTC (1 container statuses recorded)
Aug  1 09:08:15.306: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug  1 09:08:15.306: INFO: kube-dns-autoscaler-845f56f67b-s24x9 from kube-system started at 2019-08-01 07:18:52 +0000 UTC (1 container statuses recorded)
Aug  1 09:08:15.306: INFO: 	Container autoscaler ready: true, restart count 0
Aug  1 09:08:15.306: INFO: kubernetes-dashboard-f5496d66d-j22q5 from kube-system started at 2019-08-01 07:18:52 +0000 UTC (1 container statuses recorded)
Aug  1 09:08:15.306: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Aug  1 09:08:15.306: INFO: sonobuoy-e2e-job-d28e9b7acb7844b7 from heptio-sonobuoy started at 2019-08-01 07:24:19 +0000 UTC (2 container statuses recorded)
Aug  1 09:08:15.306: INFO: 	Container e2e ready: true, restart count 0
Aug  1 09:08:15.306: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug  1 09:08:15.306: INFO: calico-node-5v77h from kube-system started at 2019-08-01 07:18:04 +0000 UTC (2 container statuses recorded)
Aug  1 09:08:15.306: INFO: 	Container calico-node ready: true, restart count 0
Aug  1 09:08:15.306: INFO: 	Container install-cni ready: true, restart count 0
Aug  1 09:08:15.307: INFO: coredns-5f559b869-f68db from kube-system started at 2019-08-01 07:18:52 +0000 UTC (1 container statuses recorded)
Aug  1 09:08:15.307: INFO: 	Container coredns ready: true, restart count 0
Aug  1 09:08:15.307: INFO: heapster-796547984d-vjt7z from kube-system started at 2019-08-01 07:18:52 +0000 UTC (1 container statuses recorded)
Aug  1 09:08:15.307: INFO: 	Container heapster ready: true, restart count 0
Aug  1 09:08:15.307: INFO: sonobuoy-systemd-logs-daemon-set-2a51f081063e4123-xc965 from heptio-sonobuoy started at 2019-08-01 07:24:21 +0000 UTC (2 container statuses recorded)
Aug  1 09:08:15.307: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Aug  1 09:08:15.307: INFO: 	Container sonobuoy-worker ready: true, restart count 1
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15b6c155e130da9f], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 09:08:16.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-nwfzp" for this suite.
Aug  1 09:08:22.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 09:08:22.743: INFO: namespace: e2e-tests-sched-pred-nwfzp, resource: bindings, ignored listing per whitelist
Aug  1 09:08:22.847: INFO: namespace e2e-tests-sched-pred-nwfzp deletion completed in 6.199844229s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:8.133 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 09:08:22.853: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Aug  1 09:08:36.621: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 09:08:36.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-9zgn4" for this suite.
Aug  1 09:09:01.066: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 09:09:01.218: INFO: namespace: e2e-tests-replicaset-9zgn4, resource: bindings, ignored listing per whitelist
Aug  1 09:09:01.221: INFO: namespace e2e-tests-replicaset-9zgn4 deletion completed in 24.379061372s

• [SLOW TEST:38.369 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 09:09:01.222: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Aug  1 09:09:01.908: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Aug  1 09:09:01.908: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 create -f - --namespace=e2e-tests-kubectl-p5xr9'
Aug  1 09:09:03.413: INFO: stderr: ""
Aug  1 09:09:03.413: INFO: stdout: "service/redis-slave created\n"
Aug  1 09:09:03.451: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Aug  1 09:09:03.452: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 create -f - --namespace=e2e-tests-kubectl-p5xr9'
Aug  1 09:09:04.162: INFO: stderr: ""
Aug  1 09:09:04.162: INFO: stdout: "service/redis-master created\n"
Aug  1 09:09:04.162: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Aug  1 09:09:04.162: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 create -f - --namespace=e2e-tests-kubectl-p5xr9'
Aug  1 09:09:04.795: INFO: stderr: ""
Aug  1 09:09:04.795: INFO: stdout: "service/frontend created\n"
Aug  1 09:09:04.795: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Aug  1 09:09:04.795: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 create -f - --namespace=e2e-tests-kubectl-p5xr9'
Aug  1 09:09:05.410: INFO: stderr: ""
Aug  1 09:09:05.410: INFO: stdout: "deployment.extensions/frontend created\n"
Aug  1 09:09:05.410: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Aug  1 09:09:05.410: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 create -f - --namespace=e2e-tests-kubectl-p5xr9'
Aug  1 09:09:06.180: INFO: stderr: ""
Aug  1 09:09:06.180: INFO: stdout: "deployment.extensions/redis-master created\n"
Aug  1 09:09:06.180: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Aug  1 09:09:06.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 create -f - --namespace=e2e-tests-kubectl-p5xr9'
Aug  1 09:09:07.224: INFO: stderr: ""
Aug  1 09:09:07.224: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Aug  1 09:09:07.224: INFO: Waiting for all frontend pods to be Running.
Aug  1 09:11:02.278: INFO: Waiting for frontend to serve content.
Aug  1 09:11:03.269: INFO: Trying to add a new entry to the guestbook.
Aug  1 09:11:03.284: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Aug  1 09:11:03.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-p5xr9'
Aug  1 09:11:06.846: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug  1 09:11:06.846: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Aug  1 09:11:06.847: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-p5xr9'
Aug  1 09:11:08.018: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug  1 09:11:08.018: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Aug  1 09:11:08.018: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-p5xr9'
Aug  1 09:11:08.860: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug  1 09:11:08.860: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Aug  1 09:11:08.897: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-p5xr9'
Aug  1 09:11:09.226: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug  1 09:11:09.227: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Aug  1 09:11:09.227: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-p5xr9'
Aug  1 09:11:10.329: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug  1 09:11:10.329: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Aug  1 09:11:10.639: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-p5xr9'
Aug  1 09:11:11.853: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug  1 09:11:11.853: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 09:11:12.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-p5xr9" for this suite.
Aug  1 09:11:59.906: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 09:12:00.402: INFO: namespace: e2e-tests-kubectl-p5xr9, resource: bindings, ignored listing per whitelist
Aug  1 09:12:00.420: INFO: namespace e2e-tests-kubectl-p5xr9 deletion completed in 46.926697318s

• [SLOW TEST:179.198 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 09:12:00.437: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Aug  1 09:12:00.914: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-qmrtv,SelfLink:/api/v1/namespaces/e2e-tests-watch-qmrtv/configmaps/e2e-watch-test-watch-closed,UID:6b547196-b43c-11e9-8923-fa163ec474fb,ResourceVersion:22505,Generation:0,CreationTimestamp:2019-08-01 09:12:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug  1 09:12:01.180: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-qmrtv,SelfLink:/api/v1/namespaces/e2e-tests-watch-qmrtv/configmaps/e2e-watch-test-watch-closed,UID:6b547196-b43c-11e9-8923-fa163ec474fb,ResourceVersion:22507,Generation:0,CreationTimestamp:2019-08-01 09:12:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Aug  1 09:12:01.302: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-qmrtv,SelfLink:/api/v1/namespaces/e2e-tests-watch-qmrtv/configmaps/e2e-watch-test-watch-closed,UID:6b547196-b43c-11e9-8923-fa163ec474fb,ResourceVersion:22508,Generation:0,CreationTimestamp:2019-08-01 09:12:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug  1 09:12:01.302: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-qmrtv,SelfLink:/api/v1/namespaces/e2e-tests-watch-qmrtv/configmaps/e2e-watch-test-watch-closed,UID:6b547196-b43c-11e9-8923-fa163ec474fb,ResourceVersion:22509,Generation:0,CreationTimestamp:2019-08-01 09:12:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 09:12:01.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-qmrtv" for this suite.
Aug  1 09:12:07.547: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 09:12:07.633: INFO: namespace: e2e-tests-watch-qmrtv, resource: bindings, ignored listing per whitelist
Aug  1 09:12:07.790: INFO: namespace e2e-tests-watch-qmrtv deletion completed in 6.464028198s

• [SLOW TEST:7.354 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 09:12:07.810: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-7009a248-b43c-11e9-aec8-12de527cd1b8
STEP: Creating a pod to test consume configMaps
Aug  1 09:12:08.357: INFO: Waiting up to 5m0s for pod "pod-configmaps-700ae5c8-b43c-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-configmap-27skp" to be "success or failure"
Aug  1 09:12:08.432: INFO: Pod "pod-configmaps-700ae5c8-b43c-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 74.465705ms
Aug  1 09:12:10.435: INFO: Pod "pod-configmaps-700ae5c8-b43c-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.078202948s
Aug  1 09:12:12.721: INFO: Pod "pod-configmaps-700ae5c8-b43c-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.364149198s
Aug  1 09:12:14.727: INFO: Pod "pod-configmaps-700ae5c8-b43c-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.370098788s
STEP: Saw pod success
Aug  1 09:12:14.728: INFO: Pod "pod-configmaps-700ae5c8-b43c-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 09:12:14.732: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod pod-configmaps-700ae5c8-b43c-11e9-aec8-12de527cd1b8 container configmap-volume-test: <nil>
STEP: delete the pod
Aug  1 09:12:15.210: INFO: Waiting for pod pod-configmaps-700ae5c8-b43c-11e9-aec8-12de527cd1b8 to disappear
Aug  1 09:12:15.300: INFO: Pod pod-configmaps-700ae5c8-b43c-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 09:12:15.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-27skp" for this suite.
Aug  1 09:12:21.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 09:12:21.990: INFO: namespace: e2e-tests-configmap-27skp, resource: bindings, ignored listing per whitelist
Aug  1 09:12:22.075: INFO: namespace e2e-tests-configmap-27skp deletion completed in 6.770219532s

• [SLOW TEST:14.266 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 09:12:22.099: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-789ff0fc-b43c-11e9-aec8-12de527cd1b8
STEP: Creating a pod to test consume configMaps
Aug  1 09:12:22.830: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-78b0dd64-b43c-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-projected-kvzd8" to be "success or failure"
Aug  1 09:12:23.036: INFO: Pod "pod-projected-configmaps-78b0dd64-b43c-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 205.601922ms
Aug  1 09:12:25.039: INFO: Pod "pod-projected-configmaps-78b0dd64-b43c-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.208858418s
Aug  1 09:12:27.042: INFO: Pod "pod-projected-configmaps-78b0dd64-b43c-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.211840578s
Aug  1 09:12:29.044: INFO: Pod "pod-projected-configmaps-78b0dd64-b43c-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.214226588s
STEP: Saw pod success
Aug  1 09:12:29.045: INFO: Pod "pod-projected-configmaps-78b0dd64-b43c-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 09:12:29.046: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod pod-projected-configmaps-78b0dd64-b43c-11e9-aec8-12de527cd1b8 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug  1 09:12:29.139: INFO: Waiting for pod pod-projected-configmaps-78b0dd64-b43c-11e9-aec8-12de527cd1b8 to disappear
Aug  1 09:12:29.163: INFO: Pod pod-projected-configmaps-78b0dd64-b43c-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 09:12:29.163: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-kvzd8" for this suite.
Aug  1 09:12:35.268: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 09:12:35.333: INFO: namespace: e2e-tests-projected-kvzd8, resource: bindings, ignored listing per whitelist
Aug  1 09:12:35.407: INFO: namespace e2e-tests-projected-kvzd8 deletion completed in 6.239665612s

• [SLOW TEST:13.309 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 09:12:35.412: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Aug  1 09:12:35.933: INFO: Waiting up to 5m0s for pod "downward-api-8080cd90-b43c-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-downward-api-847qw" to be "success or failure"
Aug  1 09:12:35.987: INFO: Pod "downward-api-8080cd90-b43c-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 53.1ms
Aug  1 09:12:37.993: INFO: Pod "downward-api-8080cd90-b43c-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.058162823s
Aug  1 09:12:40.065: INFO: Pod "downward-api-8080cd90-b43c-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.130615092s
Aug  1 09:12:42.069: INFO: Pod "downward-api-8080cd90-b43c-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.134501221s
STEP: Saw pod success
Aug  1 09:12:42.069: INFO: Pod "downward-api-8080cd90-b43c-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 09:12:42.071: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod downward-api-8080cd90-b43c-11e9-aec8-12de527cd1b8 container dapi-container: <nil>
STEP: delete the pod
Aug  1 09:12:42.330: INFO: Waiting for pod downward-api-8080cd90-b43c-11e9-aec8-12de527cd1b8 to disappear
Aug  1 09:12:42.390: INFO: Pod downward-api-8080cd90-b43c-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 09:12:42.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-847qw" for this suite.
Aug  1 09:12:48.645: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 09:12:48.718: INFO: namespace: e2e-tests-downward-api-847qw, resource: bindings, ignored listing per whitelist
Aug  1 09:12:48.867: INFO: namespace e2e-tests-downward-api-847qw deletion completed in 6.471519625s

• [SLOW TEST:13.456 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 09:12:48.871: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-8880ba95-b43c-11e9-aec8-12de527cd1b8
STEP: Creating a pod to test consume secrets
Aug  1 09:12:49.550: INFO: Waiting up to 5m0s for pod "pod-secrets-888294a4-b43c-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-secrets-rn949" to be "success or failure"
Aug  1 09:12:49.625: INFO: Pod "pod-secrets-888294a4-b43c-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 74.70715ms
Aug  1 09:12:51.804: INFO: Pod "pod-secrets-888294a4-b43c-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.253369695s
Aug  1 09:12:54.026: INFO: Pod "pod-secrets-888294a4-b43c-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.475388373s
Aug  1 09:12:56.031: INFO: Pod "pod-secrets-888294a4-b43c-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.481054971s
STEP: Saw pod success
Aug  1 09:12:56.031: INFO: Pod "pod-secrets-888294a4-b43c-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 09:12:56.034: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod pod-secrets-888294a4-b43c-11e9-aec8-12de527cd1b8 container secret-volume-test: <nil>
STEP: delete the pod
Aug  1 09:12:56.088: INFO: Waiting for pod pod-secrets-888294a4-b43c-11e9-aec8-12de527cd1b8 to disappear
Aug  1 09:12:56.185: INFO: Pod pod-secrets-888294a4-b43c-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 09:12:56.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-rn949" for this suite.
Aug  1 09:13:02.396: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 09:13:02.489: INFO: namespace: e2e-tests-secrets-rn949, resource: bindings, ignored listing per whitelist
Aug  1 09:13:02.493: INFO: namespace e2e-tests-secrets-rn949 deletion completed in 6.235174363s

• [SLOW TEST:13.622 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 09:13:02.509: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Aug  1 09:13:02.902: INFO: Waiting up to 5m0s for pod "var-expansion-908cb92a-b43c-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-var-expansion-kl9dt" to be "success or failure"
Aug  1 09:13:02.943: INFO: Pod "var-expansion-908cb92a-b43c-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 40.097246ms
Aug  1 09:13:05.307: INFO: Pod "var-expansion-908cb92a-b43c-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.404248901s
Aug  1 09:13:07.548: INFO: Pod "var-expansion-908cb92a-b43c-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.645769938s
Aug  1 09:13:09.796: INFO: Pod "var-expansion-908cb92a-b43c-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.893443932s
STEP: Saw pod success
Aug  1 09:13:09.796: INFO: Pod "var-expansion-908cb92a-b43c-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 09:13:09.801: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod var-expansion-908cb92a-b43c-11e9-aec8-12de527cd1b8 container dapi-container: <nil>
STEP: delete the pod
Aug  1 09:13:10.276: INFO: Waiting for pod var-expansion-908cb92a-b43c-11e9-aec8-12de527cd1b8 to disappear
Aug  1 09:13:10.339: INFO: Pod var-expansion-908cb92a-b43c-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 09:13:10.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-kl9dt" for this suite.
Aug  1 09:13:16.762: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 09:13:17.188: INFO: namespace: e2e-tests-var-expansion-kl9dt, resource: bindings, ignored listing per whitelist
Aug  1 09:13:17.388: INFO: namespace e2e-tests-var-expansion-kl9dt deletion completed in 7.042772146s

• [SLOW TEST:14.879 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 09:13:17.392: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Aug  1 09:13:18.093: INFO: Waiting up to 5m0s for pod "pod-99a601ff-b43c-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-emptydir-mtkb5" to be "success or failure"
Aug  1 09:13:18.247: INFO: Pod "pod-99a601ff-b43c-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 154.150234ms
Aug  1 09:13:20.642: INFO: Pod "pod-99a601ff-b43c-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.549092117s
Aug  1 09:13:22.648: INFO: Pod "pod-99a601ff-b43c-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.554180764s
STEP: Saw pod success
Aug  1 09:13:22.648: INFO: Pod "pod-99a601ff-b43c-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 09:13:22.650: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod pod-99a601ff-b43c-11e9-aec8-12de527cd1b8 container test-container: <nil>
STEP: delete the pod
Aug  1 09:13:22.932: INFO: Waiting for pod pod-99a601ff-b43c-11e9-aec8-12de527cd1b8 to disappear
Aug  1 09:13:23.030: INFO: Pod pod-99a601ff-b43c-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 09:13:23.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-mtkb5" for this suite.
Aug  1 09:13:29.832: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 09:13:29.902: INFO: namespace: e2e-tests-emptydir-mtkb5, resource: bindings, ignored listing per whitelist
Aug  1 09:13:30.083: INFO: namespace e2e-tests-emptydir-mtkb5 deletion completed in 6.916900517s

• [SLOW TEST:12.692 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 09:13:30.087: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug  1 09:13:30.574: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a0ff06bb-b43c-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-projected-j8n8h" to be "success or failure"
Aug  1 09:13:30.622: INFO: Pod "downwardapi-volume-a0ff06bb-b43c-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 47.402676ms
Aug  1 09:13:33.100: INFO: Pod "downwardapi-volume-a0ff06bb-b43c-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.525610914s
Aug  1 09:13:35.225: INFO: Pod "downwardapi-volume-a0ff06bb-b43c-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.650373351s
STEP: Saw pod success
Aug  1 09:13:35.225: INFO: Pod "downwardapi-volume-a0ff06bb-b43c-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 09:13:35.227: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod downwardapi-volume-a0ff06bb-b43c-11e9-aec8-12de527cd1b8 container client-container: <nil>
STEP: delete the pod
Aug  1 09:13:35.420: INFO: Waiting for pod downwardapi-volume-a0ff06bb-b43c-11e9-aec8-12de527cd1b8 to disappear
Aug  1 09:13:35.476: INFO: Pod downwardapi-volume-a0ff06bb-b43c-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 09:13:35.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-j8n8h" for this suite.
Aug  1 09:13:41.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 09:13:41.862: INFO: namespace: e2e-tests-projected-j8n8h, resource: bindings, ignored listing per whitelist
Aug  1 09:13:41.900: INFO: namespace e2e-tests-projected-j8n8h deletion completed in 6.419416157s

• [SLOW TEST:11.814 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 09:13:41.905: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Aug  1 09:13:42.334: INFO: Pod name pod-release: Found 0 pods out of 1
Aug  1 09:13:47.360: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 09:13:47.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-8wcz4" for this suite.
Aug  1 09:13:56.015: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 09:13:56.775: INFO: namespace: e2e-tests-replication-controller-8wcz4, resource: bindings, ignored listing per whitelist
Aug  1 09:13:56.816: INFO: namespace e2e-tests-replication-controller-8wcz4 deletion completed in 9.235898244s

• [SLOW TEST:14.912 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 09:13:56.820: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 09:13:58.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-chzgx" for this suite.
Aug  1 09:14:20.817: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 09:14:20.983: INFO: namespace: e2e-tests-pods-chzgx, resource: bindings, ignored listing per whitelist
Aug  1 09:14:21.138: INFO: namespace e2e-tests-pods-chzgx deletion completed in 22.642144896s

• [SLOW TEST:24.319 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 09:14:21.142: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-bfb1b3d3-b43c-11e9-aec8-12de527cd1b8
STEP: Creating a pod to test consume configMaps
Aug  1 09:14:22.099: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-bfb29f72-b43c-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-projected-z6qq7" to be "success or failure"
Aug  1 09:14:22.610: INFO: Pod "pod-projected-configmaps-bfb29f72-b43c-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 510.715334ms
Aug  1 09:14:24.614: INFO: Pod "pod-projected-configmaps-bfb29f72-b43c-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.515156135s
Aug  1 09:14:26.618: INFO: Pod "pod-projected-configmaps-bfb29f72-b43c-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.519335806s
Aug  1 09:14:28.622: INFO: Pod "pod-projected-configmaps-bfb29f72-b43c-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.522847451s
STEP: Saw pod success
Aug  1 09:14:28.622: INFO: Pod "pod-projected-configmaps-bfb29f72-b43c-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 09:14:28.625: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod pod-projected-configmaps-bfb29f72-b43c-11e9-aec8-12de527cd1b8 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug  1 09:14:29.057: INFO: Waiting for pod pod-projected-configmaps-bfb29f72-b43c-11e9-aec8-12de527cd1b8 to disappear
Aug  1 09:14:29.340: INFO: Pod pod-projected-configmaps-bfb29f72-b43c-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 09:14:29.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-z6qq7" for this suite.
Aug  1 09:14:35.647: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 09:14:35.802: INFO: namespace: e2e-tests-projected-z6qq7, resource: bindings, ignored listing per whitelist
Aug  1 09:14:35.835: INFO: namespace e2e-tests-projected-z6qq7 deletion completed in 6.226228671s

• [SLOW TEST:14.694 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 09:14:35.840: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Aug  1 09:14:36.278: INFO: Waiting up to 5m0s for pod "client-containers-c8393fd2-b43c-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-containers-xj92d" to be "success or failure"
Aug  1 09:14:36.528: INFO: Pod "client-containers-c8393fd2-b43c-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 249.43834ms
Aug  1 09:14:38.644: INFO: Pod "client-containers-c8393fd2-b43c-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.365525184s
Aug  1 09:14:40.668: INFO: Pod "client-containers-c8393fd2-b43c-11e9-aec8-12de527cd1b8": Phase="Running", Reason="", readiness=true. Elapsed: 4.389269014s
Aug  1 09:14:42.672: INFO: Pod "client-containers-c8393fd2-b43c-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.392842483s
STEP: Saw pod success
Aug  1 09:14:42.672: INFO: Pod "client-containers-c8393fd2-b43c-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 09:14:42.673: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod client-containers-c8393fd2-b43c-11e9-aec8-12de527cd1b8 container test-container: <nil>
STEP: delete the pod
Aug  1 09:14:42.824: INFO: Waiting for pod client-containers-c8393fd2-b43c-11e9-aec8-12de527cd1b8 to disappear
Aug  1 09:14:42.854: INFO: Pod client-containers-c8393fd2-b43c-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 09:14:42.854: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-xj92d" for this suite.
Aug  1 09:14:49.018: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 09:14:49.126: INFO: namespace: e2e-tests-containers-xj92d, resource: bindings, ignored listing per whitelist
Aug  1 09:14:49.130: INFO: namespace e2e-tests-containers-xj92d deletion completed in 6.245156766s

• [SLOW TEST:13.291 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 09:14:49.136: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1527
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug  1 09:14:49.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-mznnv'
Aug  1 09:14:52.212: INFO: stderr: ""
Aug  1 09:14:52.212: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1532
Aug  1 09:14:52.245: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-mznnv'
Aug  1 09:14:52.791: INFO: stderr: ""
Aug  1 09:14:52.791: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 09:14:52.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-mznnv" for this suite.
Aug  1 09:14:58.965: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 09:14:59.065: INFO: namespace: e2e-tests-kubectl-mznnv, resource: bindings, ignored listing per whitelist
Aug  1 09:14:59.093: INFO: namespace e2e-tests-kubectl-mznnv deletion completed in 6.272211394s

• [SLOW TEST:9.958 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 09:14:59.102: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Aug  1 09:15:06.295: INFO: Successfully updated pod "labelsupdated62839bc-b43c-11e9-aec8-12de527cd1b8"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 09:15:08.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4mw7j" for this suite.
Aug  1 09:15:32.467: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 09:15:32.521: INFO: namespace: e2e-tests-projected-4mw7j, resource: bindings, ignored listing per whitelist
Aug  1 09:15:32.622: INFO: namespace e2e-tests-projected-4mw7j deletion completed in 24.209974369s

• [SLOW TEST:33.521 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 09:15:32.626: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-ea26d44a-b43c-11e9-aec8-12de527cd1b8
STEP: Creating secret with name s-test-opt-upd-ea26d49e-b43c-11e9-aec8-12de527cd1b8
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-ea26d44a-b43c-11e9-aec8-12de527cd1b8
STEP: Updating secret s-test-opt-upd-ea26d49e-b43c-11e9-aec8-12de527cd1b8
STEP: Creating secret with name s-test-opt-create-ea26d4b1-b43c-11e9-aec8-12de527cd1b8
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 09:15:43.683: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ffpf4" for this suite.
Aug  1 09:16:07.734: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 09:16:07.884: INFO: namespace: e2e-tests-projected-ffpf4, resource: bindings, ignored listing per whitelist
Aug  1 09:16:07.892: INFO: namespace e2e-tests-projected-ffpf4 deletion completed in 24.204526913s

• [SLOW TEST:35.266 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 09:16:07.893: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-2bzg
STEP: Creating a pod to test atomic-volume-subpath
Aug  1 09:16:08.413: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-2bzg" in namespace "e2e-tests-subpath-wrhhw" to be "success or failure"
Aug  1 09:16:08.614: INFO: Pod "pod-subpath-test-configmap-2bzg": Phase="Pending", Reason="", readiness=false. Elapsed: 200.804019ms
Aug  1 09:16:10.640: INFO: Pod "pod-subpath-test-configmap-2bzg": Phase="Pending", Reason="", readiness=false. Elapsed: 2.226526169s
Aug  1 09:16:12.646: INFO: Pod "pod-subpath-test-configmap-2bzg": Phase="Pending", Reason="", readiness=false. Elapsed: 4.232156072s
Aug  1 09:16:14.838: INFO: Pod "pod-subpath-test-configmap-2bzg": Phase="Pending", Reason="", readiness=false. Elapsed: 6.423949324s
Aug  1 09:16:16.891: INFO: Pod "pod-subpath-test-configmap-2bzg": Phase="Running", Reason="", readiness=false. Elapsed: 8.477473057s
Aug  1 09:16:18.921: INFO: Pod "pod-subpath-test-configmap-2bzg": Phase="Running", Reason="", readiness=false. Elapsed: 10.507734413s
Aug  1 09:16:20.931: INFO: Pod "pod-subpath-test-configmap-2bzg": Phase="Running", Reason="", readiness=false. Elapsed: 12.517712754s
Aug  1 09:16:22.948: INFO: Pod "pod-subpath-test-configmap-2bzg": Phase="Running", Reason="", readiness=false. Elapsed: 14.53427887s
Aug  1 09:16:24.969: INFO: Pod "pod-subpath-test-configmap-2bzg": Phase="Running", Reason="", readiness=false. Elapsed: 16.555407554s
Aug  1 09:16:27.042: INFO: Pod "pod-subpath-test-configmap-2bzg": Phase="Running", Reason="", readiness=false. Elapsed: 18.628783798s
Aug  1 09:16:29.061: INFO: Pod "pod-subpath-test-configmap-2bzg": Phase="Running", Reason="", readiness=false. Elapsed: 20.647919471s
Aug  1 09:16:31.065: INFO: Pod "pod-subpath-test-configmap-2bzg": Phase="Running", Reason="", readiness=false. Elapsed: 22.651101706s
Aug  1 09:16:33.096: INFO: Pod "pod-subpath-test-configmap-2bzg": Phase="Running", Reason="", readiness=false. Elapsed: 24.682554567s
Aug  1 09:16:35.164: INFO: Pod "pod-subpath-test-configmap-2bzg": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.750711165s
STEP: Saw pod success
Aug  1 09:16:35.165: INFO: Pod "pod-subpath-test-configmap-2bzg" satisfied condition "success or failure"
Aug  1 09:16:35.168: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod pod-subpath-test-configmap-2bzg container test-container-subpath-configmap-2bzg: <nil>
STEP: delete the pod
Aug  1 09:16:35.629: INFO: Waiting for pod pod-subpath-test-configmap-2bzg to disappear
Aug  1 09:16:35.708: INFO: Pod pod-subpath-test-configmap-2bzg no longer exists
STEP: Deleting pod pod-subpath-test-configmap-2bzg
Aug  1 09:16:35.708: INFO: Deleting pod "pod-subpath-test-configmap-2bzg" in namespace "e2e-tests-subpath-wrhhw"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 09:16:36.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-wrhhw" for this suite.
Aug  1 09:16:44.314: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 09:16:44.583: INFO: namespace: e2e-tests-subpath-wrhhw, resource: bindings, ignored listing per whitelist
Aug  1 09:16:44.820: INFO: namespace e2e-tests-subpath-wrhhw deletion completed in 8.807621476s

• [SLOW TEST:36.928 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 09:16:44.826: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug  1 09:16:45.200: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-dpmvt'
Aug  1 09:16:45.385: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug  1 09:16:45.385: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1268
Aug  1 09:16:47.478: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-dpmvt'
Aug  1 09:16:48.024: INFO: stderr: ""
Aug  1 09:16:48.024: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 09:16:48.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-dpmvt" for this suite.
Aug  1 09:16:54.834: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 09:16:54.911: INFO: namespace: e2e-tests-kubectl-dpmvt, resource: bindings, ignored listing per whitelist
Aug  1 09:16:54.940: INFO: namespace e2e-tests-kubectl-dpmvt deletion completed in 6.852062612s

• [SLOW TEST:10.114 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 09:16:54.941: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Aug  1 09:16:56.022: INFO: created pod pod-service-account-defaultsa
Aug  1 09:16:56.023: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Aug  1 09:16:56.061: INFO: created pod pod-service-account-mountsa
Aug  1 09:16:56.061: INFO: pod pod-service-account-mountsa service account token volume mount: true
Aug  1 09:16:56.105: INFO: created pod pod-service-account-nomountsa
Aug  1 09:16:56.105: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Aug  1 09:16:56.206: INFO: created pod pod-service-account-defaultsa-mountspec
Aug  1 09:16:56.206: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Aug  1 09:16:56.513: INFO: created pod pod-service-account-mountsa-mountspec
Aug  1 09:16:56.513: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Aug  1 09:16:56.565: INFO: created pod pod-service-account-nomountsa-mountspec
Aug  1 09:16:56.565: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Aug  1 09:16:56.880: INFO: created pod pod-service-account-defaultsa-nomountspec
Aug  1 09:16:56.881: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Aug  1 09:16:57.272: INFO: created pod pod-service-account-mountsa-nomountspec
Aug  1 09:16:57.273: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Aug  1 09:16:57.602: INFO: created pod pod-service-account-nomountsa-nomountspec
Aug  1 09:16:57.602: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 09:16:57.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-qjzjz" for this suite.
Aug  1 09:17:38.321: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 09:17:38.597: INFO: namespace: e2e-tests-svcaccounts-qjzjz, resource: bindings, ignored listing per whitelist
Aug  1 09:17:38.662: INFO: namespace e2e-tests-svcaccounts-qjzjz deletion completed in 40.694519439s

• [SLOW TEST:43.723 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 09:17:38.669: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-352bf890-b43d-11e9-aec8-12de527cd1b8
STEP: Creating a pod to test consume configMaps
Aug  1 09:17:39.065: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-353b0b6b-b43d-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-projected-55wsk" to be "success or failure"
Aug  1 09:17:39.093: INFO: Pod "pod-projected-configmaps-353b0b6b-b43d-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 27.654ms
Aug  1 09:17:41.559: INFO: Pod "pod-projected-configmaps-353b0b6b-b43d-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.493968089s
Aug  1 09:17:43.563: INFO: Pod "pod-projected-configmaps-353b0b6b-b43d-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.497800514s
Aug  1 09:17:45.779: INFO: Pod "pod-projected-configmaps-353b0b6b-b43d-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.713403194s
STEP: Saw pod success
Aug  1 09:17:45.779: INFO: Pod "pod-projected-configmaps-353b0b6b-b43d-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 09:17:45.781: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod pod-projected-configmaps-353b0b6b-b43d-11e9-aec8-12de527cd1b8 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug  1 09:17:45.957: INFO: Waiting for pod pod-projected-configmaps-353b0b6b-b43d-11e9-aec8-12de527cd1b8 to disappear
Aug  1 09:17:45.996: INFO: Pod pod-projected-configmaps-353b0b6b-b43d-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 09:17:45.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-55wsk" for this suite.
Aug  1 09:17:52.233: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 09:17:52.377: INFO: namespace: e2e-tests-projected-55wsk, resource: bindings, ignored listing per whitelist
Aug  1 09:17:52.385: INFO: namespace e2e-tests-projected-55wsk deletion completed in 6.383281735s

• [SLOW TEST:13.717 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 09:17:52.385: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug  1 09:17:52.817: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3d6d2562-b43d-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-downward-api-9t5dc" to be "success or failure"
Aug  1 09:17:52.898: INFO: Pod "downwardapi-volume-3d6d2562-b43d-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 80.82159ms
Aug  1 09:17:55.146: INFO: Pod "downwardapi-volume-3d6d2562-b43d-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.328758063s
Aug  1 09:17:57.191: INFO: Pod "downwardapi-volume-3d6d2562-b43d-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.373837919s
STEP: Saw pod success
Aug  1 09:17:57.191: INFO: Pod "downwardapi-volume-3d6d2562-b43d-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 09:17:57.265: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod downwardapi-volume-3d6d2562-b43d-11e9-aec8-12de527cd1b8 container client-container: <nil>
STEP: delete the pod
Aug  1 09:17:57.615: INFO: Waiting for pod downwardapi-volume-3d6d2562-b43d-11e9-aec8-12de527cd1b8 to disappear
Aug  1 09:17:57.914: INFO: Pod downwardapi-volume-3d6d2562-b43d-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 09:17:57.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-9t5dc" for this suite.
Aug  1 09:18:04.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 09:18:04.506: INFO: namespace: e2e-tests-downward-api-9t5dc, resource: bindings, ignored listing per whitelist
Aug  1 09:18:04.541: INFO: namespace e2e-tests-downward-api-9t5dc deletion completed in 6.543747476s

• [SLOW TEST:12.156 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 09:18:04.559: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Aug  1 09:18:04.808: INFO: Waiting up to 5m0s for pod "pod-449329b4-b43d-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-emptydir-4lrx9" to be "success or failure"
Aug  1 09:18:04.868: INFO: Pod "pod-449329b4-b43d-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 60.089497ms
Aug  1 09:18:06.873: INFO: Pod "pod-449329b4-b43d-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.064479184s
Aug  1 09:18:08.876: INFO: Pod "pod-449329b4-b43d-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.068030375s
Aug  1 09:18:10.880: INFO: Pod "pod-449329b4-b43d-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.071829937s
STEP: Saw pod success
Aug  1 09:18:10.880: INFO: Pod "pod-449329b4-b43d-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 09:18:10.883: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod pod-449329b4-b43d-11e9-aec8-12de527cd1b8 container test-container: <nil>
STEP: delete the pod
Aug  1 09:18:11.248: INFO: Waiting for pod pod-449329b4-b43d-11e9-aec8-12de527cd1b8 to disappear
Aug  1 09:18:11.585: INFO: Pod pod-449329b4-b43d-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 09:18:11.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-4lrx9" for this suite.
Aug  1 09:18:17.665: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 09:18:17.758: INFO: namespace: e2e-tests-emptydir-4lrx9, resource: bindings, ignored listing per whitelist
Aug  1 09:18:17.834: INFO: namespace e2e-tests-emptydir-4lrx9 deletion completed in 6.205115351s

• [SLOW TEST:13.275 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 09:18:17.837: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-m7l9d
Aug  1 09:18:22.354: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-m7l9d
STEP: checking the pod's current state and verifying that restartCount is present
Aug  1 09:18:22.375: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 09:22:23.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-m7l9d" for this suite.
Aug  1 09:22:30.157: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 09:22:30.469: INFO: namespace: e2e-tests-container-probe-m7l9d, resource: bindings, ignored listing per whitelist
Aug  1 09:22:30.483: INFO: namespace e2e-tests-container-probe-m7l9d deletion completed in 6.510742749s

• [SLOW TEST:252.647 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 09:22:30.484: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-e330e5d3-b43d-11e9-aec8-12de527cd1b8
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-e330e5d3-b43d-11e9-aec8-12de527cd1b8
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 09:23:56.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8dwnp" for this suite.
Aug  1 09:24:20.626: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 09:24:20.723: INFO: namespace: e2e-tests-projected-8dwnp, resource: bindings, ignored listing per whitelist
Aug  1 09:24:20.739: INFO: namespace e2e-tests-projected-8dwnp deletion completed in 24.143861028s

• [SLOW TEST:110.256 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 09:24:20.744: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug  1 09:24:21.390: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"249ad0e0-b43e-11e9-8923-fa163ec474fb", Controller:(*bool)(0xc001fad276), BlockOwnerDeletion:(*bool)(0xc001fad277)}}
Aug  1 09:24:21.752: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"249556f7-b43e-11e9-8923-fa163ec474fb", Controller:(*bool)(0xc001fad70e), BlockOwnerDeletion:(*bool)(0xc001fad70f)}}
Aug  1 09:24:21.801: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"2496f1bb-b43e-11e9-8923-fa163ec474fb", Controller:(*bool)(0xc001fad8ee), BlockOwnerDeletion:(*bool)(0xc001fad8ef)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 09:24:27.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-xczch" for this suite.
Aug  1 09:24:34.244: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 09:24:34.311: INFO: namespace: e2e-tests-gc-xczch, resource: bindings, ignored listing per whitelist
Aug  1 09:24:34.415: INFO: namespace e2e-tests-gc-xczch deletion completed in 6.472098204s

• [SLOW TEST:13.672 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 09:24:34.420: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Aug  1 09:24:41.594: INFO: Successfully updated pod "labelsupdate2d0d7c52-b43e-11e9-aec8-12de527cd1b8"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 09:24:43.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-f9j5v" for this suite.
Aug  1 09:25:05.911: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 09:25:06.257: INFO: namespace: e2e-tests-downward-api-f9j5v, resource: bindings, ignored listing per whitelist
Aug  1 09:25:06.287: INFO: namespace e2e-tests-downward-api-f9j5v deletion completed in 22.535036758s

• [SLOW TEST:31.867 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 09:25:06.294: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Aug  1 09:25:11.296: INFO: Successfully updated pod "pod-update-3ff7e37d-b43e-11e9-aec8-12de527cd1b8"
STEP: verifying the updated pod is in kubernetes
Aug  1 09:25:11.467: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 09:25:11.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-plnvh" for this suite.
Aug  1 09:25:35.610: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 09:25:35.648: INFO: namespace: e2e-tests-pods-plnvh, resource: bindings, ignored listing per whitelist
Aug  1 09:25:35.771: INFO: namespace e2e-tests-pods-plnvh deletion completed in 24.296944043s

• [SLOW TEST:29.478 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 09:25:35.775: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Aug  1 09:25:36.166: INFO: Waiting up to 5m0s for pod "pod-5196f98c-b43e-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-emptydir-f82jf" to be "success or failure"
Aug  1 09:25:36.333: INFO: Pod "pod-5196f98c-b43e-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 165.590185ms
Aug  1 09:25:38.336: INFO: Pod "pod-5196f98c-b43e-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.168166916s
Aug  1 09:25:40.526: INFO: Pod "pod-5196f98c-b43e-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.358287365s
Aug  1 09:25:42.528: INFO: Pod "pod-5196f98c-b43e-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.360960457s
STEP: Saw pod success
Aug  1 09:25:42.529: INFO: Pod "pod-5196f98c-b43e-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 09:25:42.609: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod pod-5196f98c-b43e-11e9-aec8-12de527cd1b8 container test-container: <nil>
STEP: delete the pod
Aug  1 09:25:42.794: INFO: Waiting for pod pod-5196f98c-b43e-11e9-aec8-12de527cd1b8 to disappear
Aug  1 09:25:42.929: INFO: Pod pod-5196f98c-b43e-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 09:25:42.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-f82jf" for this suite.
Aug  1 09:25:48.996: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 09:25:49.099: INFO: namespace: e2e-tests-emptydir-f82jf, resource: bindings, ignored listing per whitelist
Aug  1 09:25:49.176: INFO: namespace e2e-tests-emptydir-f82jf deletion completed in 6.239027941s

• [SLOW TEST:13.402 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 09:25:49.195: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0801 09:26:04.100177      12 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug  1 09:26:04.125: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 09:26:04.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-4rwj4" for this suite.
Aug  1 09:26:20.694: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 09:26:21.043: INFO: namespace: e2e-tests-gc-4rwj4, resource: bindings, ignored listing per whitelist
Aug  1 09:26:21.085: INFO: namespace e2e-tests-gc-4rwj4 deletion completed in 16.598041763s

• [SLOW TEST:31.891 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 09:26:21.090: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-6d0c2aed-b43e-11e9-aec8-12de527cd1b8
STEP: Creating a pod to test consume secrets
Aug  1 09:26:22.443: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-6d2f1656-b43e-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-projected-7c5pb" to be "success or failure"
Aug  1 09:26:22.924: INFO: Pod "pod-projected-secrets-6d2f1656-b43e-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 481.625333ms
Aug  1 09:26:24.927: INFO: Pod "pod-projected-secrets-6d2f1656-b43e-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.484452303s
Aug  1 09:26:27.190: INFO: Pod "pod-projected-secrets-6d2f1656-b43e-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.747793817s
Aug  1 09:26:29.196: INFO: Pod "pod-projected-secrets-6d2f1656-b43e-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.753511334s
Aug  1 09:26:31.199: INFO: Pod "pod-projected-secrets-6d2f1656-b43e-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 8.75627643s
Aug  1 09:26:33.448: INFO: Pod "pod-projected-secrets-6d2f1656-b43e-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 11.005426868s
Aug  1 09:26:36.083: INFO: Pod "pod-projected-secrets-6d2f1656-b43e-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 13.640753072s
STEP: Saw pod success
Aug  1 09:26:36.083: INFO: Pod "pod-projected-secrets-6d2f1656-b43e-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 09:26:36.085: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod pod-projected-secrets-6d2f1656-b43e-11e9-aec8-12de527cd1b8 container secret-volume-test: <nil>
STEP: delete the pod
Aug  1 09:26:36.726: INFO: Waiting for pod pod-projected-secrets-6d2f1656-b43e-11e9-aec8-12de527cd1b8 to disappear
Aug  1 09:26:37.011: INFO: Pod pod-projected-secrets-6d2f1656-b43e-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 09:26:37.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7c5pb" for this suite.
Aug  1 09:26:43.393: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 09:26:43.452: INFO: namespace: e2e-tests-projected-7c5pb, resource: bindings, ignored listing per whitelist
Aug  1 09:26:43.660: INFO: namespace e2e-tests-projected-7c5pb deletion completed in 6.644368183s

• [SLOW TEST:22.573 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 09:26:43.664: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Aug  1 09:26:59.792: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-zl2cx PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  1 09:26:59.801: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
Aug  1 09:27:00.476: INFO: Exec stderr: ""
Aug  1 09:27:00.485: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-zl2cx PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  1 09:27:00.485: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
Aug  1 09:27:00.681: INFO: Exec stderr: ""
Aug  1 09:27:00.681: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-zl2cx PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  1 09:27:00.681: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
Aug  1 09:27:01.035: INFO: Exec stderr: ""
Aug  1 09:27:01.035: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-zl2cx PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  1 09:27:01.035: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
Aug  1 09:27:01.178: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Aug  1 09:27:01.178: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-zl2cx PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  1 09:27:01.178: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
Aug  1 09:27:01.345: INFO: Exec stderr: ""
Aug  1 09:27:01.345: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-zl2cx PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  1 09:27:01.345: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
Aug  1 09:27:01.551: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Aug  1 09:27:01.551: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-zl2cx PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  1 09:27:01.551: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
Aug  1 09:27:01.784: INFO: Exec stderr: ""
Aug  1 09:27:01.784: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-zl2cx PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  1 09:27:01.784: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
Aug  1 09:27:01.985: INFO: Exec stderr: ""
Aug  1 09:27:01.986: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-zl2cx PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  1 09:27:01.986: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
Aug  1 09:27:02.112: INFO: Exec stderr: ""
Aug  1 09:27:02.113: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-zl2cx PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  1 09:27:02.113: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
Aug  1 09:27:02.267: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 09:27:02.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-zl2cx" for this suite.
Aug  1 09:27:50.419: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 09:27:50.570: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-zl2cx, resource: bindings, ignored listing per whitelist
Aug  1 09:27:50.571: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-zl2cx deletion completed in 48.299344392s

• [SLOW TEST:66.908 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 09:27:50.602: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug  1 09:27:51.044: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a20007e8-b43e-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-projected-h9ssn" to be "success or failure"
Aug  1 09:27:51.098: INFO: Pod "downwardapi-volume-a20007e8-b43e-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 53.935753ms
Aug  1 09:27:53.298: INFO: Pod "downwardapi-volume-a20007e8-b43e-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.253981553s
Aug  1 09:27:55.301: INFO: Pod "downwardapi-volume-a20007e8-b43e-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.256520809s
Aug  1 09:27:57.305: INFO: Pod "downwardapi-volume-a20007e8-b43e-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.261084615s
STEP: Saw pod success
Aug  1 09:27:57.305: INFO: Pod "downwardapi-volume-a20007e8-b43e-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 09:27:57.308: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod downwardapi-volume-a20007e8-b43e-11e9-aec8-12de527cd1b8 container client-container: <nil>
STEP: delete the pod
Aug  1 09:27:57.530: INFO: Waiting for pod downwardapi-volume-a20007e8-b43e-11e9-aec8-12de527cd1b8 to disappear
Aug  1 09:27:57.551: INFO: Pod downwardapi-volume-a20007e8-b43e-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 09:27:57.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-h9ssn" for this suite.
Aug  1 09:28:03.739: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 09:28:03.821: INFO: namespace: e2e-tests-projected-h9ssn, resource: bindings, ignored listing per whitelist
Aug  1 09:28:03.899: INFO: namespace e2e-tests-projected-h9ssn deletion completed in 6.342909812s

• [SLOW TEST:13.299 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 09:28:03.906: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1358
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug  1 09:28:04.384: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-6p52m'
Aug  1 09:28:08.614: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug  1 09:28:08.614: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Aug  1 09:28:08.765: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Aug  1 09:28:08.845: INFO: scanned /root for discovery docs: <nil>
Aug  1 09:28:08.845: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-6p52m'
Aug  1 09:28:28.713: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Aug  1 09:28:28.713: INFO: stdout: "Created e2e-test-nginx-rc-a38518b0be86362444c24a2594bd8308\nScaling up e2e-test-nginx-rc-a38518b0be86362444c24a2594bd8308 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-a38518b0be86362444c24a2594bd8308 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-a38518b0be86362444c24a2594bd8308 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Aug  1 09:28:28.734: INFO: stdout: "Created e2e-test-nginx-rc-a38518b0be86362444c24a2594bd8308\nScaling up e2e-test-nginx-rc-a38518b0be86362444c24a2594bd8308 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-a38518b0be86362444c24a2594bd8308 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-a38518b0be86362444c24a2594bd8308 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Aug  1 09:28:28.767: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-6p52m'
Aug  1 09:28:28.966: INFO: stderr: ""
Aug  1 09:28:28.966: INFO: stdout: "e2e-test-nginx-rc-a38518b0be86362444c24a2594bd8308-jzq4h "
Aug  1 09:28:28.995: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods e2e-test-nginx-rc-a38518b0be86362444c24a2594bd8308-jzq4h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6p52m'
Aug  1 09:28:29.147: INFO: stderr: ""
Aug  1 09:28:29.148: INFO: stdout: "true"
Aug  1 09:28:29.148: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 get pods e2e-test-nginx-rc-a38518b0be86362444c24a2594bd8308-jzq4h -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6p52m'
Aug  1 09:28:29.259: INFO: stderr: ""
Aug  1 09:28:29.259: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Aug  1 09:28:29.259: INFO: e2e-test-nginx-rc-a38518b0be86362444c24a2594bd8308-jzq4h is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1364
Aug  1 09:28:29.259: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-6p52m'
Aug  1 09:28:29.453: INFO: stderr: ""
Aug  1 09:28:29.453: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 09:28:29.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6p52m" for this suite.
Aug  1 09:28:37.750: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 09:28:37.908: INFO: namespace: e2e-tests-kubectl-6p52m, resource: bindings, ignored listing per whitelist
Aug  1 09:28:37.913: INFO: namespace e2e-tests-kubectl-6p52m deletion completed in 8.276770204s

• [SLOW TEST:34.007 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 09:28:37.918: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug  1 09:28:38.296: INFO: Waiting up to 5m0s for pod "downwardapi-volume-be25741a-b43e-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-downward-api-sv2dz" to be "success or failure"
Aug  1 09:28:38.327: INFO: Pod "downwardapi-volume-be25741a-b43e-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 30.823847ms
Aug  1 09:28:40.346: INFO: Pod "downwardapi-volume-be25741a-b43e-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.049451854s
Aug  1 09:28:42.351: INFO: Pod "downwardapi-volume-be25741a-b43e-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.05472796s
STEP: Saw pod success
Aug  1 09:28:42.351: INFO: Pod "downwardapi-volume-be25741a-b43e-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 09:28:42.354: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod downwardapi-volume-be25741a-b43e-11e9-aec8-12de527cd1b8 container client-container: <nil>
STEP: delete the pod
Aug  1 09:28:42.557: INFO: Waiting for pod downwardapi-volume-be25741a-b43e-11e9-aec8-12de527cd1b8 to disappear
Aug  1 09:28:42.560: INFO: Pod downwardapi-volume-be25741a-b43e-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 09:28:42.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-sv2dz" for this suite.
Aug  1 09:28:50.619: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 09:28:50.733: INFO: namespace: e2e-tests-downward-api-sv2dz, resource: bindings, ignored listing per whitelist
Aug  1 09:28:50.753: INFO: namespace e2e-tests-downward-api-sv2dz deletion completed in 8.189415412s

• [SLOW TEST:12.835 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 09:28:50.756: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-c5d2f10d-b43e-11e9-aec8-12de527cd1b8
STEP: Creating a pod to test consume configMaps
Aug  1 09:28:51.205: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c5d737c8-b43e-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-projected-rkhkq" to be "success or failure"
Aug  1 09:28:51.373: INFO: Pod "pod-projected-configmaps-c5d737c8-b43e-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 167.704653ms
Aug  1 09:28:53.471: INFO: Pod "pod-projected-configmaps-c5d737c8-b43e-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.265344998s
Aug  1 09:28:55.476: INFO: Pod "pod-projected-configmaps-c5d737c8-b43e-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.270221914s
STEP: Saw pod success
Aug  1 09:28:55.476: INFO: Pod "pod-projected-configmaps-c5d737c8-b43e-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 09:28:55.479: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod pod-projected-configmaps-c5d737c8-b43e-11e9-aec8-12de527cd1b8 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug  1 09:28:55.695: INFO: Waiting for pod pod-projected-configmaps-c5d737c8-b43e-11e9-aec8-12de527cd1b8 to disappear
Aug  1 09:28:55.723: INFO: Pod pod-projected-configmaps-c5d737c8-b43e-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 09:28:55.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rkhkq" for this suite.
Aug  1 09:29:03.793: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 09:29:03.893: INFO: namespace: e2e-tests-projected-rkhkq, resource: bindings, ignored listing per whitelist
Aug  1 09:29:03.913: INFO: namespace e2e-tests-projected-rkhkq deletion completed in 8.155988669s

• [SLOW TEST:13.157 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 09:29:03.920: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Aug  1 09:29:04.743: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 09:29:05.003: INFO: Number of nodes with available pods: 0
Aug  1 09:29:05.003: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 09:29:06.180: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 09:29:06.253: INFO: Number of nodes with available pods: 0
Aug  1 09:29:06.253: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 09:29:07.163: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 09:29:07.169: INFO: Number of nodes with available pods: 0
Aug  1 09:29:07.169: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 09:29:08.163: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 09:29:08.236: INFO: Number of nodes with available pods: 1
Aug  1 09:29:08.236: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Aug  1 09:29:08.617: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 09:29:08.657: INFO: Number of nodes with available pods: 0
Aug  1 09:29:08.657: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 09:29:09.681: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 09:29:09.683: INFO: Number of nodes with available pods: 0
Aug  1 09:29:09.683: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 09:29:10.694: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 09:29:10.696: INFO: Number of nodes with available pods: 0
Aug  1 09:29:10.696: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 09:29:11.736: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 09:29:11.954: INFO: Number of nodes with available pods: 0
Aug  1 09:29:11.955: INFO: Node k8s-1-6lh7zebx7k5q-node-0 is running more than one daemon pod
Aug  1 09:29:12.665: INFO: DaemonSet pods can't tolerate node k8s-1-6lh7zebx7k5q-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  1 09:29:12.672: INFO: Number of nodes with available pods: 1
Aug  1 09:29:12.673: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-pdwzx, will wait for the garbage collector to delete the pods
Aug  1 09:29:12.934: INFO: Deleting DaemonSet.extensions daemon-set took: 26.602463ms
Aug  1 09:29:13.135: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.654601ms
Aug  1 09:29:46.400: INFO: Number of nodes with available pods: 0
Aug  1 09:29:46.400: INFO: Number of running nodes: 0, number of available pods: 0
Aug  1 09:29:46.404: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-pdwzx/daemonsets","resourceVersion":"25674"},"items":null}

Aug  1 09:29:46.406: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-pdwzx/pods","resourceVersion":"25674"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 09:29:46.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-pdwzx" for this suite.
Aug  1 09:29:54.483: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 09:29:54.574: INFO: namespace: e2e-tests-daemonsets-pdwzx, resource: bindings, ignored listing per whitelist
Aug  1 09:29:54.599: INFO: namespace e2e-tests-daemonsets-pdwzx deletion completed in 8.181740779s

• [SLOW TEST:50.680 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 09:29:54.605: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Aug  1 09:29:55.108: INFO: Waiting up to 5m0s for pod "pod-ebe56615-b43e-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-emptydir-rmbrv" to be "success or failure"
Aug  1 09:29:55.246: INFO: Pod "pod-ebe56615-b43e-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 138.647965ms
Aug  1 09:29:57.255: INFO: Pod "pod-ebe56615-b43e-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.147583477s
Aug  1 09:29:59.261: INFO: Pod "pod-ebe56615-b43e-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.153300323s
STEP: Saw pod success
Aug  1 09:29:59.261: INFO: Pod "pod-ebe56615-b43e-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 09:29:59.265: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod pod-ebe56615-b43e-11e9-aec8-12de527cd1b8 container test-container: <nil>
STEP: delete the pod
Aug  1 09:29:59.398: INFO: Waiting for pod pod-ebe56615-b43e-11e9-aec8-12de527cd1b8 to disappear
Aug  1 09:29:59.424: INFO: Pod pod-ebe56615-b43e-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 09:29:59.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-rmbrv" for this suite.
Aug  1 09:30:05.469: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 09:30:05.624: INFO: namespace: e2e-tests-emptydir-rmbrv, resource: bindings, ignored listing per whitelist
Aug  1 09:30:05.675: INFO: namespace e2e-tests-emptydir-rmbrv deletion completed in 6.247030749s

• [SLOW TEST:11.070 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 09:30:05.680: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-f2617f94-b43e-11e9-aec8-12de527cd1b8
STEP: Creating secret with name secret-projected-all-test-volume-f2617f87-b43e-11e9-aec8-12de527cd1b8
STEP: Creating a pod to test Check all projections for projected volume plugin
Aug  1 09:30:05.972: INFO: Waiting up to 5m0s for pod "projected-volume-f2617f4c-b43e-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-projected-twrzb" to be "success or failure"
Aug  1 09:30:06.101: INFO: Pod "projected-volume-f2617f4c-b43e-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 128.557252ms
Aug  1 09:30:08.122: INFO: Pod "projected-volume-f2617f4c-b43e-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.149755134s
Aug  1 09:30:10.126: INFO: Pod "projected-volume-f2617f4c-b43e-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.153930984s
STEP: Saw pod success
Aug  1 09:30:10.126: INFO: Pod "projected-volume-f2617f4c-b43e-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 09:30:10.174: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod projected-volume-f2617f4c-b43e-11e9-aec8-12de527cd1b8 container projected-all-volume-test: <nil>
STEP: delete the pod
Aug  1 09:30:10.332: INFO: Waiting for pod projected-volume-f2617f4c-b43e-11e9-aec8-12de527cd1b8 to disappear
Aug  1 09:30:10.365: INFO: Pod projected-volume-f2617f4c-b43e-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 09:30:10.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-twrzb" for this suite.
Aug  1 09:30:18.437: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 09:30:18.530: INFO: namespace: e2e-tests-projected-twrzb, resource: bindings, ignored listing per whitelist
Aug  1 09:30:18.596: INFO: namespace e2e-tests-projected-twrzb deletion completed in 8.228435312s

• [SLOW TEST:12.917 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 09:30:18.598: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-fa18bcf8-b43e-11e9-aec8-12de527cd1b8
STEP: Creating a pod to test consume secrets
Aug  1 09:30:19.000: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-fa2b840b-b43e-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-projected-vxtl4" to be "success or failure"
Aug  1 09:30:19.047: INFO: Pod "pod-projected-secrets-fa2b840b-b43e-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 46.606845ms
Aug  1 09:30:21.135: INFO: Pod "pod-projected-secrets-fa2b840b-b43e-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.135084945s
Aug  1 09:30:23.139: INFO: Pod "pod-projected-secrets-fa2b840b-b43e-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.138968676s
STEP: Saw pod success
Aug  1 09:30:23.139: INFO: Pod "pod-projected-secrets-fa2b840b-b43e-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 09:30:23.142: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod pod-projected-secrets-fa2b840b-b43e-11e9-aec8-12de527cd1b8 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug  1 09:30:23.356: INFO: Waiting for pod pod-projected-secrets-fa2b840b-b43e-11e9-aec8-12de527cd1b8 to disappear
Aug  1 09:30:23.361: INFO: Pod pod-projected-secrets-fa2b840b-b43e-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 09:30:23.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vxtl4" for this suite.
Aug  1 09:30:29.438: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 09:30:29.513: INFO: namespace: e2e-tests-projected-vxtl4, resource: bindings, ignored listing per whitelist
Aug  1 09:30:29.653: INFO: namespace e2e-tests-projected-vxtl4 deletion completed in 6.288175705s

• [SLOW TEST:11.056 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 09:30:29.658: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-96kxr
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Aug  1 09:30:30.324: INFO: Found 0 stateful pods, waiting for 3
Aug  1 09:30:40.331: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug  1 09:30:40.335: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug  1 09:30:40.335: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Aug  1 09:30:50.365: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug  1 09:30:50.366: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug  1 09:30:50.366: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Aug  1 09:30:50.374: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-96kxr ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug  1 09:30:50.737: INFO: stderr: ""
Aug  1 09:30:50.737: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug  1 09:30:50.737: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Aug  1 09:31:00.781: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Aug  1 09:31:11.161: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-96kxr ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  1 09:31:11.645: INFO: stderr: ""
Aug  1 09:31:11.645: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug  1 09:31:11.645: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug  1 09:31:31.840: INFO: Waiting for StatefulSet e2e-tests-statefulset-96kxr/ss2 to complete update
STEP: Rolling back to a previous revision
Aug  1 09:31:41.849: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-96kxr ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug  1 09:31:42.218: INFO: stderr: ""
Aug  1 09:31:42.218: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug  1 09:31:42.218: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug  1 09:31:52.259: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Aug  1 09:32:02.467: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-683321083 exec --namespace=e2e-tests-statefulset-96kxr ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  1 09:32:02.719: INFO: stderr: ""
Aug  1 09:32:02.719: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug  1 09:32:02.719: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug  1 09:32:22.911: INFO: Waiting for StatefulSet e2e-tests-statefulset-96kxr/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Aug  1 09:32:32.957: INFO: Deleting all statefulset in ns e2e-tests-statefulset-96kxr
Aug  1 09:32:32.964: INFO: Scaling statefulset ss2 to 0
Aug  1 09:32:43.133: INFO: Waiting for statefulset status.replicas updated to 0
Aug  1 09:32:43.135: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 09:32:43.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-96kxr" for this suite.
Aug  1 09:32:55.666: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 09:32:55.843: INFO: namespace: e2e-tests-statefulset-96kxr, resource: bindings, ignored listing per whitelist
Aug  1 09:32:55.895: INFO: namespace e2e-tests-statefulset-96kxr deletion completed in 12.458620644s

• [SLOW TEST:146.237 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 09:32:55.900: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Aug  1 09:32:56.187: INFO: Waiting up to 5m0s for pod "downward-api-57dd2e97-b43f-11e9-aec8-12de527cd1b8" in namespace "e2e-tests-downward-api-f79qb" to be "success or failure"
Aug  1 09:32:56.231: INFO: Pod "downward-api-57dd2e97-b43f-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 42.097628ms
Aug  1 09:32:58.254: INFO: Pod "downward-api-57dd2e97-b43f-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.06570049s
Aug  1 09:33:00.259: INFO: Pod "downward-api-57dd2e97-b43f-11e9-aec8-12de527cd1b8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.070449117s
Aug  1 09:33:02.263: INFO: Pod "downward-api-57dd2e97-b43f-11e9-aec8-12de527cd1b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.07499071s
STEP: Saw pod success
Aug  1 09:33:02.264: INFO: Pod "downward-api-57dd2e97-b43f-11e9-aec8-12de527cd1b8" satisfied condition "success or failure"
Aug  1 09:33:02.267: INFO: Trying to get logs from node k8s-1-6lh7zebx7k5q-node-0 pod downward-api-57dd2e97-b43f-11e9-aec8-12de527cd1b8 container dapi-container: <nil>
STEP: delete the pod
Aug  1 09:33:02.384: INFO: Waiting for pod downward-api-57dd2e97-b43f-11e9-aec8-12de527cd1b8 to disappear
Aug  1 09:33:02.428: INFO: Pod downward-api-57dd2e97-b43f-11e9-aec8-12de527cd1b8 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 09:33:02.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-f79qb" for this suite.
Aug  1 09:33:10.622: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 09:33:10.700: INFO: namespace: e2e-tests-downward-api-f79qb, resource: bindings, ignored listing per whitelist
Aug  1 09:33:10.766: INFO: namespace e2e-tests-downward-api-f79qb deletion completed in 8.333193678s

• [SLOW TEST:14.867 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  1 09:33:10.770: INFO: >>> kubeConfig: /tmp/kubeconfig-683321083
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Aug  1 09:33:15.167: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-60c5316e-b43f-11e9-aec8-12de527cd1b8,GenerateName:,Namespace:e2e-tests-events-zjl7b,SelfLink:/api/v1/namespaces/e2e-tests-events-zjl7b/pods/send-events-60c5316e-b43f-11e9-aec8-12de527cd1b8,UID:607ca894-b43f-11e9-8923-fa163ec474fb,ResourceVersion:26539,Generation:0,CreationTimestamp:2019-08-01 09:33:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 98625952,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.44/32,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-c7q62 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-c7q62,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-c7q62 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-6lh7zebx7k5q-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0011d1ce0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0011d1d00}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 09:33:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 09:33:13 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 09:33:13 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-01 09:33:10 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.23,PodIP:192.168.1.44,StartTime:2019-08-01 09:33:11 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-08-01 09:33:13 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://fdb5f2a16618b311ff20f71bc1778b0e2a018a23ea026654fec734d4f7255a43}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Aug  1 09:33:17.232: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Aug  1 09:33:19.234: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  1 09:33:19.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-zjl7b" for this suite.
Aug  1 09:33:57.563: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  1 09:33:57.641: INFO: namespace: e2e-tests-events-zjl7b, resource: bindings, ignored listing per whitelist
Aug  1 09:33:57.736: INFO: namespace e2e-tests-events-zjl7b deletion completed in 38.364135389s

• [SLOW TEST:46.967 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSAug  1 09:33:57.748: INFO: Running AfterSuite actions on all nodes
Aug  1 09:33:57.761: INFO: Running AfterSuite actions on node 1
Aug  1 09:33:57.762: INFO: Skipping dumping logs from cluster

Ran 200 of 1946 Specs in 7635.099 seconds
SUCCESS! -- 200 Passed | 0 Failed | 0 Pending | 1746 Skipped PASS

Ginkgo ran 1 suite in 2h7m16.688348857s
Test Suite Passed
